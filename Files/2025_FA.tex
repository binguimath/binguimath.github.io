% !TeX spellcheck = en_US
% !TEX program = pdflatex
\documentclass[12pt,b5paper,notitlepage]{article}
\usepackage[b5paper, margin={0.5in,0.65in}]{geometry}
%\usepackage{fullpage}
\usepackage{amsmath,amscd,amssymb,amsthm,mathrsfs,amsfonts,layout,indentfirst,graphicx,caption,mathabx, stmaryrd,appendix,calc,imakeidx,upgreek} % mathabx for \wtidecheck
%\usepackage{ulem} %wave underline
\usepackage[dvipsnames,table]{xcolor}
\usepackage{palatino}  %template

\usepackage{slashed} % Dirac operator
\usepackage{mathrsfs} % Enable using \mathscr
%\usepackage{eufrak}  another template/font
\usepackage{extarrows} % long equal sign, \xlongequal{blablabla}
\usepackage{enumitem} % enumerate label change e.g. [label=(\alph*)]  shows (a) (b) 

 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage{fontspec}
%\setmainfont{Palatino Linotype}
%\usepackage{emoji}


% emoji, use lualatex  remove \usepackage{palatino}

%%%%%%%%%%%%%


\usepackage{CJK}   % Chinese package





\usepackage{csquotes} % \begin{displayquote}   \begin{displaycquote}  for quotation
\usepackage{epigraph}   %\epigraph{}{}  for quotation
%\pmb  mandatory math bold 

\usepackage{fancyhdr} % date in footer

%\usepackage{soul}  %\ul underline break line automatically

\usepackage{ulem}  % \uline  underline break line   also    \uwave

\usepackage{relsize} % use \mathlarger \larger \text{\larger[2]$...$} to enlarge the size of math symbols

\usepackage{verbatim}  % comment environment


\usepackage{halloweenmath} % Interesting halloween math symbols

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tcolorbox}
\tcbuselibrary{theorems}
% box around equations   \tcboxmath
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\usepackage{float}

%%%%%%%%%%%%

% Force images and tables to be placed in a specified location.

%\begin{table}[H]

%\begin{figure}[H]

%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% circled colon and thick colon \hcolondel and \colondel

\usepackage{pdfrender}

\newcommand*{\hollowcolon}{%
	\textpdfrender{
		TextRenderingMode=Stroke,
		LineWidth=.1bp,
	}{:}%
}

\newcommand{\hcolondel}[1]{%
	\mathopen{\hollowcolon}#1\mathclose{\hollowcolon}%
}
\newcommand{\colondel}[1]{%
	\mathopen{:}#1\mathclose{:}%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\usepackage{tikz}
\usetikzlibrary{fadings}
\usetikzlibrary{patterns}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes}

\usepackage{tikz-cd}
\usepackage[nottoc]{tocbibind}   % Add  reference to ToC


\makeindex


% The following set up the line spaces between items in \thebibliography
\usepackage{lipsum}  
\let\OLDthebibliography\thebibliography
\renewcommand\thebibliography[1]{
	\OLDthebibliography{#1}
	\setlength{\parskip}{0pt}
	\setlength{\itemsep}{2pt} 
}


%\hyperref{page.10}{...}

\allowdisplaybreaks  %allow aligns to break between pages
\usepackage{latexsym}
\usepackage{chngcntr}
\usepackage[colorlinks,linkcolor=blue,anchorcolor=blue, linktocpage,
%pagebackref
]{hyperref}
\hypersetup{ urlcolor=cyan,
	citecolor=[rgb]{0,0.5,0}}


\setcounter{tocdepth}{2}	 %hide subsections in the content


\counterwithin{figure}{section}
\counterwithin{table}{section}

\counterwithin*{footnote}{section}   % Footnote numbering is recounted from the beginning of each subsection



\pagestyle{plain}

\captionsetup[figure]
{
	labelsep=none	
}













\theoremstyle{definition}
\newtheorem{df}{Definition}[section]
\newtheorem{eg}[df]{Example}
\newtheorem{exe}[df]{Exercise}
\newtheorem{rem}[df]{Remark}
\newtheorem{obs}[df]{Observation}
\newtheorem{ass}[df]{Assumption}
\newtheorem{cv}[df]{Convention}
\newtheorem{prin}[df]{Principle}
\newtheorem{nota}[df]{Notation}
\newtheorem{problem}[df]{Problem}
\newtheorem{question}[df]{Question}
\newtheorem{principle}[df]{Principle}
\newtheorem{coa}[df]{Theorem}
\newtheorem{srem}[df]{$\star$ Remark}
\newtheorem{seg}[df]{$\star$ Example}
\newtheorem{sexe}[df]{$\star$ Exercise}
\newtheorem{sdf}[df]{$\star$ Definition}




\newtheorem{prob}{\color{red}Problem}[section]
%\renewcommand*{\theprob}{{\color{red}\arabic{section}.\arabic{prob}}}
\newtheorem{sprob}[prob]{\color{red}$\star$ Problem}
%\renewcommand*{\thesprob}{{\color{red}\arabic{section}.\arabic{sprob}}}
% \newtheorem{ssprob}[prob]{$\star\star$ Problem}



\theoremstyle{plain}
\newtheorem{thm}[df]{Theorem}
\newtheorem{ccl}[df]{Conclusion}
\newtheorem{thd}[df]{Theorem-Definition}
\newtheorem{pp}[df]{Proposition}
\newtheorem{co}[df]{Corollary}
\newtheorem{lm}[df]{Lemma}
\newtheorem{sthm}[df]{$\star$ Theorem}
\newtheorem{slm}[df]{$\star$ Lemma}
\newtheorem{claim}[df]{Claim}
\newtheorem{spp}[df]{$\star$ Proposition}
\newtheorem{scorollary}[df]{$\star$ Corollary}


\newtheorem{cond}{Condition}
\newtheorem{Mthm}{Main Theorem}
\renewcommand{\thecond}{\Alph{cond}} % "letter-numbered" theorems
\renewcommand{\theMthm}{\Alph{Mthm}} % "letter-numbered" theorems


%\substack   multiple lines under sum
%\underset{b}{a}   b is under a


% Remind: \overline{L_0}



\usepackage{calligra}
\DeclareMathOperator{\shom}{\mathscr{H}\text{\kern -3pt {\calligra\large om}}\,}
\DeclareMathOperator{\sext}{\mathscr{E}\text{\kern -3pt {\calligra\large xt}}\,}
\DeclareMathOperator{\Rel}{\mathscr{R}\text{\kern -3pt {\calligra\large el}~}\,}
\DeclareMathOperator{\sann}{\mathscr{A}\text{\kern -3pt {\calligra\large nn}}\,}
\DeclareMathOperator{\send}{\mathscr{E}\text{\kern -3pt {\calligra\large nd}}\,}
\DeclareMathOperator{\stor}{\mathscr{T}\text{\kern -3pt {\calligra\large or}}\,}
\DeclareMathOperator{\Bor}{\mathscr{B}\text{\kern -2pt {\calligra\large or}}\,}


\usepackage{aurical}
\DeclareMathOperator{\VVir}{\text{\Fontlukas V}\text{\kern -0pt {\Fontlukas\large ir}}\,}
\DeclareMathOperator{\Ses}{\text{\Fontlukas S}\text{\kern -0pt {\Fontlukas\large es}}\,}

\newcommand{\vol}{\text{\Fontlukas V}}
\newcommand{\dvol}{d~\text{\Fontlukas V}}



\usepackage{aurical}
\usepackage[T1]{fontenc}








\newcommand{\fk}{\mathfrak}
\newcommand{\mc}{\mathcal}
\newcommand{\wtd}{\widetilde}
\newcommand{\wht}{\widehat}
\newcommand{\wch}{\widecheck}
\newcommand{\ovl}{\overline}
\newcommand{\udl}{\underline}
\newcommand{\tr}{\mathrm{t}} %transpose
\newcommand{\Tr}{\mathrm{Tr}}
\newcommand{\End}{\mathrm{End}} %endomorphism
\newcommand{\idt}{\mathbf{1}}
\newcommand{\id}{\mathrm{id}}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\Conf}{\mathrm{Conf}}
\newcommand{\Res}{\mathrm{Res}}
\newcommand{\res}{\mathrm{res}}
\newcommand{\KZ}{\mathrm{KZ}}
\newcommand{\ev}{\mathrm{ev}}
\newcommand{\coev}{\mathrm{coev}}
\newcommand{\opp}{\mathrm{opp}}
\newcommand{\Rep}{\mathrm{Rep}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\Dom}{\mathscr{D}}
\newcommand{\Domain}{\mathrm{Dom}}
\newcommand{\loc}{\mathrm{loc}}
\newcommand{\con}{\mathrm{c}}
\newcommand{\uni}{\mathrm{u}}
\newcommand{\ssp}{\mathrm{ss}}
\newcommand{\di}{\slashed d}
\newcommand{\Diffp}{\mathrm{Diff}^+}
\newcommand{\Diff}{\mathrm{Diff}}
\newcommand{\PSU}{\mathrm{PSU}(1,1)}
\newcommand{\Vir}{\mathrm{Vir}}
\newcommand{\Witt}{\mathscr W}
\newcommand{\Span}{\mathrm{Span}}
\newcommand{\pri}{\mathrm{p}}
\newcommand{\ER}{E^1(V)_{\mathbb R}}
\newcommand{\prth}[1]{( {#1})}
\newcommand{\bk}[1]{\langle {#1}\rangle}
\newcommand{\bigbk}[1]{\big\langle {#1}\big\rangle}
\newcommand{\Bigbk}[1]{\Big\langle {#1}\Big\rangle}
\newcommand{\biggbk}[1]{\bigg\langle {#1}\bigg\rangle}
\newcommand{\Biggbk}[1]{\Bigg\langle {#1}\Bigg\rangle}
\newcommand{\GA}{\mathscr G_{\mathcal A}}
\newcommand{\vs}{\varsigma}
\newcommand{\Vect}{\mathrm{Vec}}
\newcommand{\Vectc}{\mathrm{Vec}^{\mathbb C}}
\newcommand{\scr}{\mathscr}
\newcommand{\sjs}{\subset\joinrel\subset}
\newcommand{\Jtd}{\widetilde{\mathcal J}}
\newcommand{\gk}{\mathfrak g}
\newcommand{\hk}{\mathfrak h}
\newcommand{\xk}{\mathfrak x}
\newcommand{\yk}{\mathfrak y}
\newcommand{\zk}{\mathfrak z}
\newcommand{\pk}{\mathfrak p}
\newcommand{\hr}{\mathfrak h_{\mathbb R}}
\newcommand{\Ad}{\mathrm{Ad}}
\newcommand{\DHR}{\mathrm{DHR}_{I_0}}
\newcommand{\Repi}{\mathrm{Rep}_{\wtd I_0}}
\newcommand{\im}{\mathbf{i}}
\newcommand{\Co}{\complement}
%\newcommand{\Cu}{\mathcal C^{\mathrm u}}
\newcommand{\RepV}{\mathrm{Rep}^\uni(V)}
\newcommand{\RepA}{\mathrm{Rep}(\mathcal A)}
\newcommand{\RepN}{\mathrm{Rep}(\mathcal N)}
\newcommand{\RepfA}{\mathrm{Rep}^{\mathrm f}(\mathcal A)}
\newcommand{\RepAU}{\mathrm{Rep}^\uni(A_U)}
\newcommand{\RepU}{\mathrm{Rep}^\uni(U)}
\newcommand{\RepL}{\mathrm{Rep}^{\mathrm{L}}}
\newcommand{\HomL}{\mathrm{Hom}^{\mathrm{L}}}
\newcommand{\EndL}{\mathrm{End}^{\mathrm{L}}}
\newcommand{\Bim}{\mathrm{Bim}}
\newcommand{\BimA}{\mathrm{Bim}^\uni(A)}
%\newcommand{\shom}{\scr Hom}
\newcommand{\divi}{\mathrm{div}}
\newcommand{\sgm}{\varsigma}
\newcommand{\SX}{{S_{\fk X}}}
\newcommand{\DX}{D_{\fk X}}
\newcommand{\mbb}{\mathbb}
\newcommand{\mbf}{\mathbf}
\newcommand{\bsb}{\boldsymbol}
\newcommand{\blt}{\bullet}
\newcommand{\Vbb}{\mathbb V}
\newcommand{\Ubb}{\mathbb U}
\newcommand{\Xbb}{\mathbb X}
\newcommand{\Kbb}{\mathbb K}
\newcommand{\Abb}{\mathbb A}
\newcommand{\Wbb}{\mathbb W}
\newcommand{\Mbb}{\mathbb M}
\newcommand{\Gbb}{\mathbb G}
\newcommand{\Cbb}{\mathbb C}
\newcommand{\Nbb}{\mathbb N}
\newcommand{\Zbb}{\mathbb Z}
\newcommand{\Qbb}{\mathbb Q}
\newcommand{\Pbb}{\mathbb P}
\newcommand{\Rbb}{\mathbb R}
\newcommand{\Ebb}{\mathbb E}
\newcommand{\Dbb}{\mathbb D}
\newcommand{\Hbb}{\mathbb H}
\newcommand{\Tbb}{\mathbb T}
\newcommand{\cbf}{\mathbf c}
\newcommand{\Rbf}{\mathbf R}
\newcommand{\wt}{\mathrm{wt}}
\newcommand{\Lie}{\mathrm{Lie}}
\newcommand{\btl}{\blacktriangleleft}
\newcommand{\btr}{\blacktriangleright}
\newcommand{\svir}{\mathcal V\!\mathit{ir}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cok}{\mathrm{Coker}}
\newcommand{\Sbf}{\mathbf{S}}
\newcommand{\low}{\mathrm{low}}
\newcommand{\Sp}{\mathrm{Sp}}
\newcommand{\Rng}{\mathrm{Rng}}
\newcommand{\vN}{\mathrm{vN}}
\newcommand{\Ebf}{\mathbf E}
\newcommand{\Nbf}{\mathbf N}
\newcommand{\Stb}{\mathrm {Stb}}
\newcommand{\SXb}{{S_{\fk X_b}}}
\newcommand{\pr}{\mathrm {pr}}
\newcommand{\SXtd}{S_{\wtd{\fk X}}}
\newcommand{\univ}{\mathrm {univ}}
\newcommand{\vbf}{\mathbf v}
\newcommand{\ubf}{\mathbf u}
\newcommand{\wbf}{\mathbf w}
\newcommand{\CB}{\mathrm{CB}}
\newcommand{\Perm}{\mathrm{Perm}}
\newcommand{\Orb}{\mathrm{Orb}}
\newcommand{\Lss}{{L_{0,\mathrm{s}}}}
\newcommand{\Lni}{{L_{0,\mathrm{n}}}}
\newcommand{\UPSU}{\widetilde{\mathrm{PSU}}(1,1)}
\newcommand{\Sbb}{{\mathbb S}}
\newcommand{\Gc}{\mathscr G_c}
\newcommand{\Obj}{\mathrm{Obj}}
\newcommand{\bpr}{{}^\backprime}
\newcommand{\fin}{\mathrm{fin}}
\newcommand{\Ann}{\mathrm{Ann}}
\newcommand{\Real}{\mathrm{Re}}
\newcommand{\Imag}{\mathrm{Im}}
%\newcommand{\cl}{\mathrm{cl}}
\newcommand{\Ind}{\mathrm{Ind}}
\newcommand{\Supp}{\mathrm{Supp}}
\newcommand{\Specan}{\mathrm{Specan}}
\newcommand{\red}{\mathrm{red}}
\newcommand{\uph}{\upharpoonright}
\newcommand{\Mor}{\mathrm{Mor}}
\newcommand{\pre}{\mathrm{pre}}
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\Jac}{\mathrm{Jac}}
\newcommand{\emb}{\mathrm{emb}}
\newcommand{\Sg}{\mathrm{Sg}}
\newcommand{\Nzd}{\mathrm{Nzd}}
\newcommand{\Owht}{\widehat{\scr O}}
\newcommand{\Ext}{\mathrm{Ext}}
\newcommand{\Tor}{\mathrm{Tor}}
\newcommand{\Com}{\mathrm{Com}}
\newcommand{\Mod}{\mathrm{Mod}}
\newcommand{\nk}{\mathfrak n}
\newcommand{\mk}{\mathfrak m}
\newcommand{\Ass}{\mathrm{Ass}}
\newcommand{\depth}{\mathrm{depth}}
\newcommand{\Coh}{\mathrm{Coh}}
\newcommand{\Gode}{\mathrm{Gode}}
\newcommand{\Fbb}{\mathbb F}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\Modf}{\mathrm{Mod}^{\mathrm f}}
\newcommand{\codim}{\mathrm{codim}}
\newcommand{\card}{\mathrm{card}}
\newcommand{\dps}{\displaystyle}
\newcommand{\Int}{\mathrm{Int}}
\newcommand{\Nbh}{\mathrm{Nbh}}
\newcommand{\Pnbh}{\mathrm{PNbh}}
\newcommand{\Cl}{\mathrm{Cl}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\eps}{\varepsilon}
\newcommand{\Vol}{\mathrm{Vol}}
\newcommand{\LSC}{\mathrm{LSC}}
\newcommand{\USC}{\mathrm{USC}}
\newcommand{\Ess}{\mathrm{Rng}^{\mathrm{ess}}}
\newcommand{\Jbf}{\mathbf{J}}
\newcommand{\SL}{\mathrm{SL}}
\newcommand{\GL}{\mathrm{GL}}
\newcommand{\Lin}{\mathrm{Lin}}
\newcommand{\ALin}{\mathrm{ALin}}
\newcommand{\bwn}{\bigwedge\nolimits}
\newcommand{\nbf}{\mathbf n}
\newcommand{\dive}{\mathrm{div}}
\newcommand{\vkp}{\varkappa}
\newcommand{\MU}{\mathcal U}
\newcommand{\MV}{\mathcal V}
\newcommand{\MW}{\mathcal W}
\newcommand{\MB}{\mathcal B}
\newcommand{\MG}{\mathcal G}
\newcommand{\MD}{\mathcal D}
\newcommand{\MF}{\mathcal F}
\newcommand{\MH}{\mathcal H}
\newcommand{\MK}{\mathcal K}
\newcommand{\MM}{\mathcal M}
\newcommand{\RM}{\mathcal {RM}}
\newcommand{\Rp}{\mathbb R_{\geq0}}
%\newcommand{\Ses}{\mathrm{Sesq}_{\mathrm b}}






\newcommand{\hqed}{\hfill\qedsymbol}




\usepackage{tipa} % wierd symboles e.g. \textturnh
\newcommand{\tipar}{\text{\textrtailr}}
\newcommand{\tipaz}{\text{\textctyogh}}
\newcommand{\tipaomega}{\text{\textcloseomega}}
\newcommand{\tipae}{\text{\textrhookschwa}}
\newcommand{\tipaee}{\text{\textreve}}
\newcommand{\tipak}{\text{\texthtk}}
\newcommand{\mol}{\upmu}
\newcommand{\dmol}{d\upmu}




\usepackage{tipx}
\newcommand{\tipxgamma}{\text{\textfrtailgamma}}
\newcommand{\tipxcc}{\text{\textctstretchc}}
\newcommand{\tipxphi}{\text{\textqplig}}















\numberwithin{equation}{section}




\title{Qiuzhen Lectures on Functional Analysis}
\author{{\sc Bin Gui}
	\\
	{\small \sc Yau Mathematical Sciences Center, Tsinghua University.}\\
	{\small binguimath@gmail.com\qquad bingui@tsinghua.edu.cn}
}
%\date{}

%\definecolor{mycolor}{RGB}{227,237,205} \pagecolor{mycolor}

\begin{document}\sloppy % avoid stretch into margins
	\pagenumbering{arabic}
	%\pagenumbering{gobble}
	\setcounter{page}{1}
	%\setcounter{section}{-1}
	%\setcounter{equation}{6}



	






	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



	
	\maketitle
\small   
%\hyperlink{page.7}{Last page of TOC}\qquad 

\hyperlink{current}{Current writing}


%\hyperlink{beforeindex}{Last page before index}~~~~~~  
%\hypertarget{beforeindex}{}



%\noindent Sections on history include but are not limited to: 
%\ref{lb55} (point-set topology),  \ref{lb550} (integral theory, Fourier series), \ref{lb543} (Banach-Alaoglu, Hahn-Banach),  \ref{lb548} (quotient Banach spaces, Hahn-Banach), \ref{lb671} and most part of Ch. \ref{lb672} (Hilbert spaces, integral equations), \ref{lb733} (measurable sets), \ref{mc89} (Riesz-Fischer theorem, $L^p$-$L^q$ duality), \ref{lb896} (functional calculus, spectral theory)
%\normalsize
%\thispagestyle{empty}	 %remove page number of this page


%Contents hyperlinks: \hyperlink{page.2}{Page 2}, \hyperlink{page.3}{Page 3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-0.5cm}

%\makeatletter
%\newcommand*{\toccontents}{\@starttoc{toc}}
%\makeatother
%\toccontents



	
% title and table of contents same page, no content title

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\normalsize
\tableofcontents






\newpage



\section{Preliminaries}

\subsection{Notation}

In this monograph, unless otherwise stated, we understand the field $\Fbb$ as either $\Rbb$ or $\Cbb$.

We use frequently the abbreviations:
\begin{gather*}
\text{iff=if and only if}\\
\text{LHS=left hand side}\qquad
\text{RHS=right hand side}\\
\text{$\exists$=there exists}\qquad \text{$\forall$=for all}\\
\text{i.e.=id est=that is=namely}\qquad\text{e.g.=for example}\\
\text{cf.=compare/check/see/you are referred to}\\
\text{resp.=respectively}\qquad 
\text{WLOG=without loss of generality}\\
\text{LCH=locally compact Hausdorff\index{00@LCH=locally compact Hausdorff}}\\
\text{MCT=monotone convergence theorem}\index{00@MCT=monotone convergence theorem}\\
\text{DCT=dominated convergence theorem}\index{00@DCT=dominated convergence theorem}
\end{gather*}

%If $P,Q$ are properties, then
%\begin{align*}
%P\land Q=P\text{ and }Q\qquad P\lor Q=P\text{ or }Q\qquad \neg P=\text{ Not }P
%\end{align*}
When we write $A:=B$ or $A\xlongequal{\mathrm{def}}B$, we mean that $A$ is defined by the expression $B$. When we write $A\equiv B$, we mean that $A$ are $B$ are different symbols of the same object.





Unless otherwise stated, an inner product space $V$ denotes a complex inner product space, and its sesquilinear form $\bk{\cdot|\cdot}$ is \uwave{linear on the right argument $|\cdot\rangle$ and antilinear on the left argument $\langle\cdot|$}. Note that this convention is different from that of \cite{Gui-A}, where the right variable is antilinear.


If $V$ is an $\Fbb$-vector space, then for each $v\in V$ and each linear map $\varphi:V\rightarrow\Fbb$, we write
\begin{align*}
\bk{v,\varphi}=\bk{\varphi,v}:=\varphi(v)
\end{align*}

We assume $a\cdot(+\infty)=(+\infty)\cdot a=+\infty$ if $a\in(0,+\infty]$, and $0\cdot(+\infty)=(+\infty)\cdot 0=0$.

An increasing function/sequence/net means a non-decreasing one.






\begin{itemize}
\item Unless otherwise specified, completeness of a metric space or normed vector space refers to Cauchy completeness.
\item $\Nbb=\{0,1,2,\dots\}$, $\Zbb_+=\{1,2,\dots\}$.
\item $\Rbb_{\geq0}=[0,+\infty)$, $\ovl\Rbb_{\geq0}=[0,+\infty]$, $\ovl\Rbb=[-\infty,+\infty]$.
\item An \textbf{interval} \index{00@Interval} denotes a connected subset of $\ovl\Rbb$. A \textbf{proper interval} \index{00@Proper interval} denotes an interval with non-zero Lebesgue measure.
\item $Y^X$ is the set of functions with domain $X$ and codomain $Y$.
\item $2^X$ is the set of subsets of $X$.
\item $\fin(2^X)$ is the set of finite subsets of $X$.
\item If $f:X\rightarrow Y$ is a map, then \index{Rng@$\Rng(f)$, the range of $f$}
\begin{align*}
\Rng(f)=f(X)
\end{align*}
\item If $V$ is a vector space and $X$ is a set, then $V^X$ is viewed as a vector space whose linear structure is defined by
\begin{gather*}
(af+bg)(x)=af(x)+bg(x)\qquad\text{for all }f,g\in V^X\text{ and }a,b\in\Fbb
\end{gather*}
\item If $X$ is a set and $A\subset X$, the \textbf{characteristic function} \index{zz@$\chi_A$} is
\begin{align*}
\chi_A:X\rightarrow\{0,1\}\qquad x\mapsto\left\{
\begin{array}{ll}
1&\text{ if }x\in A\\[0.5ex]
0&\text{ if }x\in X\setminus A
\end{array}
\right.
\end{align*} 
\item $\Cl_X(A)$, also denoted by $\Cl(A)$ or $\ovl A$, is the closure of $A\subset X$ with respect to the topological space $X$.
\item If $X$ is a metric space and $p\in X,r\in[0,+\infty]$, we let \index{B@$B_X(p,r),\ovl B_X(p,r)$}
\begin{gather*}
B_X(p,r)=\{x\in X:d(x,p)<r\}\qquad \ovl B_X(p,r)=\{x\in X:d(x,p)\leq r\}
\end{gather*}
For each $E\subset X$, we define the \textbf{diameter} \index{diam@$\diam(E)$} \index{00@Diameter $\diam(E)$}
\begin{align*}
\diam(E)=\sup\{d(x,y):x,y\in E\}
\end{align*}
\item If $X$ is a topological space, then $\mc T_X$ \index{TX@$\mc T_X$, the topology of $X$} denotes the topology of $X$, i.e.,
\begin{align*}
\mc T_X=\{\text{open subsets of }X\}
\end{align*}
If $x\in X$, a \textbf{neighborhood} \index{00@Neighborhood} of $x$ denotes an \textit{open} subset of $X$ containing $x$. We let \index{Nbh@$\Nbh_X(x)=\Nbh(x)$}
\begin{align*}
\Nbh_X(x)\equiv \Nbh(x):=\{\text{neighborhoods of $x$ in $X$}\}
\end{align*}
\item If $X,Y$ are topological spaces, then \index{Bor@$\Bor(X,Y)$, the Borel maps $X\rightarrow Y$}
\begin{gather*}
C(X,Y)=\{f\in Y^X:f\text{ is continuous}\}\\
\fk B_X=\text{the Borel $\sigma$-algebra of }X\\
\Bor(X,Y)=\{f\in Y^X:f\text{ is Borel}\}
\end{gather*}
\item $m^n$, as a measure, denotes the Lebesgue measure on $\Rbb^n$, and is abbreviated to $m$ when no confusion arises.
\item $\Sbb^1=\{z\in\Cbb:|z|=1\}\simeq\Rbb/2\pi\Zbb$. If $f$ is a function on $\Sbb^1$, equivalently, a $2\pi$-periodic function on $\Rbb$, then
\begin{align*}
\wht f(n)=\frac 1{2\pi}\int_{-\pi}^\pi f(x)e^{-\im nx}dm(x)
\end{align*}
is its $n$-th Fourier coefficient (whenever the integral can be defined).
\item $(X,\fk M,\mu)$, often abbreviated to $(X,\mu)$, denotes a measure space where $\fk M$ is the $\sigma$-algebra and $\mu:\fk M\rightarrow\ovl\Rbb_{\geq0}$ is the measure.
\item Let $V$ be a normed vector space. Let $X$ is either a set or a topological space, depending on the context. Let $1\leq p<+\infty$. For each $f\in V^X$, 
\begin{gather*}
\Supp_X(f)\equiv\Supp(f)=\Cl_X(\{x\in X:f(x)\neq0\})\\
\Vert f\Vert_{l^\infty(X,V)}=\Vert f\Vert_{l^\infty}=\sup_{x\in X}\Vert f(x)\Vert\\
\Vert f\Vert_{l^p(X,V)}=\Vert f\Vert_{l^p}=\Big(\sum_{x\in X}\Vert f(x)\Vert^p\Big)^{\frac 1p}\\
|f|\text{ is the function }X\rightarrow \Rbb_{\geq0}\text{ such that }|f|(x)=\Vert f(x)\Vert
\end{gather*}
We call $|f|$ the \textbf{absolute value function} of $f$. For each $E\subset V$, we let
\begin{gather*}
C_c(X,E)=\{f\in C(X,E):\Supp(f)\text{ is compact in $X$}\}\\
l^\infty(X,V)=\{f\in V^X:\Vert f\Vert_\infty<+\infty\}\\
l^p(X,V)=\{f\in V^X:\Vert f\Vert_p<+\infty\}
\end{gather*}
We are particularly interested in the case that $E=V$, $E=[0,1]$, and $E=\Rbb_{\geq0}$.
\item Let $V$ be a normed vector space. Let $X$ be a set. We say that a family $(f_\alpha)_{\alpha\in\scr A}$ in $V^X$ is \textbf{uniformly bounded} \index{00@Uniformly bounded families of functions} if $\sup_{\alpha\in\scr A}\Vert f_\alpha\Vert_{l^\infty(X,V)}<+\infty$.
\item If $X$ is LCH and $V$ is a normed $\Fbb$-vector space, we understand $C_c(X,V)$ as a normed $\Fbb$-vector space whose linear structure inherits from that of $V^X$, and \uwave{whose norm is chosen to be the $l^\infty$-norm}.
\item If $(X,\fk M)$ and $(Y,\fk N)$ are measurable spaces, then
\begin{gather*}
\mc L(X,Y)=\text{\{measurable functions $X\rightarrow Y$\}}
\end{gather*}
If $V$ is a normed vector space, for each $f\in\mc L(X,V)$ and $1\leq p<+\infty$, we let
\begin{gather*}
\Vert f\Vert_{L^p(X,\mu)}=\Vert f\Vert_{L^p}=\Big(\int_X|f|^pd\mu\Big)^{\frac 1p}\\
\Vert f\Vert_{L^\infty(X,\mu)}=\Vert f\Vert_{L^\infty}=\inf\{\lambda\in\ovl\Rbb_{\geq0}:\mu\{x\in X:\Vert f(x)\Vert>a\}=0\}
\end{gather*}
which are potentially infinite.
\item In the notation of function spaces, the codomain is understood to be $\Cbb$ when it is suppressed. For example,
\begin{gather*}
C_c(X)=C_c(X,\Cbb)\qquad \Bor(X)=\Bor(X,\Cbb)\qquad L^p(X,\mu)=L^p(X,\mu,\Cbb)
\end{gather*}
However, this convention does not apply to $\fk L(V)$: If $V$ is a normed vector space, then $\fk L(V)$ denotes $\fk L(V,V)$, the space of bounded linear operators on $V$.
\end{itemize}



\subsection{Review of important facts in point-set topology}

Fix a normed vector space $\mc V$.

\subsubsection{Miscellaneous definitions and properties}


\begin{df}
If $X,Y$ are metric spaces and $f:X\rightarrow Y$ is map, we say that $C\in\Rbb_{\geq0}$ is a \textbf{Lipschitz constant} \index{Lipschitz constant} of $f$ if
\begin{align*}
d(f(x_1),f(x_2))\leq Cd(x_1,x_2)\qquad\text{for all }x_1,x_2\in X
\end{align*}
If $f$ has a Lipschitz constant, we say that $f$ is \textbf{Lipschitz continuous}. \index{00@Lipschitz continuous}
\end{df}


\begin{df}
If $d$ and $d'$ are two metrics on a set $X$, we say that $d$ and $d'$ are \textbf{equivalent} \index{00@Equivalent metrics} if there exists $\alpha,\beta\in\Rbb_{>0}$ such that
\begin{align*}
d(x,y)\leq \alpha d'(x,y)\qquad d'(x,y)\leq\beta d(x,y)\qquad\text{for all }x,y\in X
\end{align*}
\end{df}

\begin{df}\label{lb33}
Let $X_1,\dots,X_N$ be metric spaces. For each $1\leq p<+\infty$, the \textbf{\pmb{$l^\infty$}-product metric} $d_\infty$ \index{00@$l^\infty$-product metric} and the \textbf{\pmb{$l^p$}-product metric} \index{00@$l^p$-product metric} $d_p$ are the metrics on $X_1\times\cdots\times X_N$ defined by
\begin{gather*}
d_\infty((x_1,\dots,x_N),(y_1,\dots,y_N)):=\max\{d(x_1,y_1),\dots,d(x_N,y_N)\}\\
d_p((x_1,\dots,x_N),(y_1,\dots,y_N)):=\sqrt[p]{d(x_1,y_1)^p+\cdots+d(x_N,y_N)}
\end{gather*}
for all $x_i,y_i\in X_i$. These metrics are equivalent. We equip $X_1\times\cdots\times X_N$ with any metric equivalent to $l^\infty$ and $l^p$.
\end{df}

\begin{rem}\label{lb34}
Recall that if $f:X\rightarrow Y$ is a map of topological spaces, and $X=\bigcup_{i\in I} U_i$ is an open cover of $X$, then $f$ is continuous iff $f|_{U_i}:U_i\rightarrow Y$ is continuous for any $i\in I$.
\end{rem}


\begin{df}
Let $f:X\rightarrow Y$ be a map where $(Y,\mc T_Y)$ is a topological space. The \textbf{pullback topology} \index{00@Pullback topology} on $X$ is defined to be
\begin{align*}
f^*\mc T_Y:=f^{-1}(\mc T_Y)=\{f^{-1}(V):V\in\mc T_Y\}
\end{align*}
Then, a net $(x_\alpha)$ in $X$ converges under $f^*\mc T_Y$ to $x$ iff
\begin{align*}
\lim_\alpha f(x_\alpha)=f(x)
\end{align*}
\end{df}


\subsubsection{Product topology and pointwise convergence}

Let $(X_\alpha)_{\alpha\in\scr A}$ be a family of topological spaces. Elements of the product space
\begin{align*}
S=\prod_{\alpha\in\scr A}X_\alpha
\end{align*}
are denoted by $x=(x_\alpha)_{\alpha\in\scr A}$. Let
\begin{align*}
\pi_\alpha:S\rightarrow X_\alpha\qquad x\mapsto x(\alpha)
\end{align*}
It is easy to check that
\begin{align*}
\mc B=\Big\{&\prod_{\alpha\in\scr A} U_\alpha: \text{each $U_\alpha$ is open in $X_\alpha$},\\
& \text{$U_\alpha=X_\alpha$ for all but finitely many $\alpha$}\Big\}\\
=&\Big\{\bigcap_{\alpha\in E} \pi_\alpha^{-1}(U_\alpha):E\in\fin(2^{\scr A}), \text{ $U_\alpha$ is open in $X_\alpha$ for each $\alpha\in E$}    \Big\}
\end{align*}
is a base for a topology, namely, for each $W_1,W_2\in\mc B$ and $x\in W_1\cap W_2$, there exists $W_3\in\mc B$ such that $W_3\subset W_1\cap W_2$. Therefore, $\mc B$ generates a topology.
\begin{df}
The topology of $S$ generated by $\mc B$ is called the \textbf{product topology} \index{00@Product topology} or \textbf{pointwise convergence topology} \index{00@Pointwise convergence topology} of $S$. Unless otherwise stated, the product of a family of topological spaces is equipped with the product topology.
\end{df}

\begin{rem}
If each $X_\alpha$ is Hausdorff, then $S$ is clearly Hausdorff.
\end{rem}


\begin{thm}\label{lb50}
Let $(x_\mu)_{\mu\in I}$ be a net in $S$, and let $x\in S$. Then the following conditions are equivalent:
\begin{enumerate}[label=(\alph*)]
\item $\dps\lim_{\mu\in I}x_\mu=x$ under the product topology.
\item $(x_\mu)_{\mu\in I}$ converges pointwise to $x$, namely, for each $\alpha\in\scr A$ we have $\dps\lim_{\mu\in I}x_\mu(\alpha)=x(\alpha)$ in $X_\alpha$.
\end{enumerate}
\end{thm}


\begin{proof}
(a)$\Rightarrow$(b): Fix $\alpha\in\scr A$. For each open $U_\alpha\subset X_\alpha$, we have $\pi^{-1}(U_\alpha)\in\mc B$. Therefore,
\begin{align}
\pi_\alpha:S\rightarrow X_\alpha\qquad\text{is continuous}
\end{align}
Thus, if $\lim_\mu x_\mu=x$, then $\lim_\mu \pi_\alpha(x_\mu)=\pi_\alpha(x)$. This proves (b).

(b)$\Rightarrow$(a): Assume (b). Choose any $W\in\MB$ containing $x$. Then there exists $E\in\fin(2^{\scr A})$ such that $W=\bigcap_{\alpha\in E}\pi_\alpha^{-1}(U_\alpha)$, where each $U_\alpha\subset X_\alpha$ is open and containing $x_\alpha$. For such $\alpha\in E$, since $\lim_\mu x_\mu(\alpha)=x(\alpha)$, we know that $(x_\mu(\alpha))$ is $\mu$-eventually in $U_\alpha$. Therefore, since $E$ is finite, we conclude that $(x_\mu)$ is eventually in $W$. This proves (a).
\end{proof}

\begin{co}\label{lb55}
Let $Z$ be a topological space. Suppose that for each $\alpha\in\scr A$, a map $f_\alpha:Z\rightarrow X_\alpha$  is chosen. Then \index{zz@$\bigvee_{\alpha\in\scr A}f_\alpha$}
\begin{gather}
\bigvee_{\alpha\in\scr A}f_\alpha:Z\rightarrow\prod_{\alpha\in\scr A}X_\alpha\qquad z\mapsto (f_\alpha(z))_{\alpha\in\scr A}
\end{gather}
is continuous iff $f_\alpha$ is continuous for each $\alpha\in\scr A$.
\end{co}

\begin{proof}
If $F:=\bigvee_{\alpha\in\scr A}f_\alpha$ is continuous, then since $\pi_\alpha$ is continuous, $f_\alpha=\pi_\alpha\circ f_\alpha$ is also continuous. Conversely, suppose that each $f_\alpha$ is continuous. Let $(z_i)$ be a net in $Z$ converging to $z\in Z$. For each $\alpha$, since $f_\alpha$ is continuous, we see that $\lim_if_\alpha(z_i)=f_\alpha(z)$. By Thm. \ref{lb50}, $F(z_i)$ converges to $F(z)$. This proves that $F$ is continuous.
\end{proof}




\begin{pp}\label{lb51}
Suppose that $\scr A$ is countable. If each $X_\alpha$ is second countable, then $S$ is second countable. If each $X_\alpha$ is metrizable, then $S$ is metrizable.
\end{pp}

\begin{proof}
If $\mc U_\alpha$ is a base of the topology of $X_\alpha$, then
\begin{align*}
\mc U:=\Big\{\bigcap_{\alpha\in E} \pi_\alpha^{-1}(U_\alpha):E\in\fin(2^{\scr A}), U_\alpha\in \MU_\alpha    \Big\}
\end{align*}
is a base of the the product topology, which is countable if each $\MU_\alpha$ is countable.

Now assume that each $X_\alpha$ is equipped with a metric $d_\alpha$. Fix any $R\in\Rbb_{>0}$, and let $\wtd d_\alpha$ be metric on $X_\alpha$ inducing the same topology as $d_\alpha$, and satisfies $d_\alpha\leq R$. For example,
\begin{subequations}\label{eq32}
\begin{align}
\wtd d_\alpha(x_\alpha,y_\alpha)=\min\{d_\alpha(x_\alpha,y_\alpha),R\}\qquad\text{for each }x_\alpha,y_\alpha\in X_\alpha
\end{align}
Let $\nu:\scr A\rightarrow\Zbb_+$ be an injective map, and define a metric $d$ on $S$ by
\begin{align}
d(x,y)=\sum_{\alpha\in\scr A}2^{-\nu(\alpha)}\wtd d_\alpha(x(\alpha),y(\alpha))\qquad\text{for each }x,y\in S
\end{align}
\end{subequations}
One shows easily that a net $(x_\mu)$ in $S$ converging to $x\in S$ iff $\lim_\mu \wtd d_\alpha(x_\mu(\alpha),x(\alpha))=0$ for all $\alpha\in\scr A$. Therefore, by Thm. \ref{lb50}, $d$ induces the product topology.
\end{proof}








\begin{thm}[\textbf{Tychonoff theorem}]\index{00@Tychonoff theorem}\label{lb61}
Assume that $X_\alpha$ is compact for each $\alpha\in\scr A$. Then $S$ is compact.
\end{thm}


\begin{proof}[$\star$ Proof]
Assume WLOG that $\scr A$ is non-empty, that each $X_\alpha$ is non-empty. Let $(x_\mu)_{\mu\in I}$ be a net in $S$. We want to show that $(x_\mu)_{\mu\in I}$ has a cluster point.

For each $\scr E\subset\scr A$, let $S_{\scr E}=\prod_{\alpha\in\scr E}X_\alpha$. For each $x\in S_{\scr E}$, we write $\Domain(x)=\scr E$.  For each $\scr E\subset\scr F\subset\scr A$ and $y\in S_{\scr F}$, let $y|_{\scr E}=(y(\alpha))_{\alpha\in\scr E}$. Let
\begin{align*}
P=\bigcup_{\scr E\subset\scr A}\big\{x\in S_{\scr E}:x\text{ is a cluster point of $(x_\mu|_{\scr E})_{\mu\in I}$ in $S_{\scr E}$} \big\}
\end{align*} 
equipped with the partial order ``$\subset$". In other words, if $x,y\in P$, then $x\leq y$ means that $\Domain(x)\subset\Domain(y)$ and $x=y|_{\scr E}$.

Since each $X_\alpha$ is compact, $P$ is clearly non-empty. Let us show that every totally ordered non-empty subset $Q\subset P$ has an upper bound in $P$, so that Zorn's lemma can be applied. Let $x$ be the union of all elements of $Q$. Thus $x\in S_{\scr E}$ where $\scr E=\bigcup_{y\in Q}\Domain(y)$, and we have $x|_{\Domain(y)}=y$ for each $y\in Q$. 

To show that $x$ is a cluster point of $(x_\mu|_{\scr E})_{\mu\in I}$ in $S_{\scr E}$, we pick any neighborhood of $x$ in $S_{\scr E}$, which, after shrinking if necessary, is of the form $W=\prod_{\alpha\in\scr E}U_\alpha$ where each $U_\alpha\subset X_\alpha$ is open, and there exists $K\in\fin(2^{\scr E})$ such that $U_\alpha=X_\alpha$ whenever $\alpha\notin K$. Since $\scr E=\bigcup_{y\in Q}\Domain(y)$, there exists $y\in Q$ such that $K\subset\Domain(y)$. Namely,   $(x_\mu|_{\Domain(y)})_{\mu\in I}$ has cluster point $y$, and $K\subset\Domain(y)$. Therefore $(x_\mu|_K)_{\mu\in I}$ has cluster point $y|_K$ (which equals $x|_K$ because $x|_{\Domain(y)}=y$), and hence is frequently in $\prod_{\alpha\in K}U_\alpha$. Thus $(x_\mu|_{\scr E})_{\mu\in I}$ is frequently in $W$. This finishes the proof that $x\in P$. Clearly $x$ is an upper bound of $Q$.

Now we can apply Zorn's lemma, which claims that $P$ has a maximal element $x\in P$. The proof of the Tychonoff theorem will be finished by showing that $\scr E:=\Domain(x)$ equals $\scr A$. Suppose not. Choose $\beta\in\scr A\setminus\scr E$. Since $x\in P$, there is a subnet $(x_{\mu_\nu}|_{\scr E})_{\nu\in J}$ of $(x_\mu|_{\scr E})_{\mu\in I}$ converging pointwise to $x$. Since $X_\beta$ is compact, $(x_{\mu_\nu}(\beta))_{\nu\in J}$ has a converging subnet $(x_{\mu_{\nu_\upsilon}}(\beta))_{\upsilon\in L}$. Define $\wtd x\in S_{\scr E\cup\{\beta\}}$ to be $x$ when restricted to $\scr E$, and $\wtd x(\beta):=\lim_\upsilon x_{\mu_{\nu_\upsilon}}(\beta)$. Then $\wtd x\in P$, and $\wtd x$ is strictly larger than $x$, contradicting the maximality of $x$.
\end{proof}



\begin{rem}\label{lb52}
If $\scr A$ is a countable set, and if each $X_\alpha$ is compact and metrizable, the \textbf{diagonal method} \index{00@Diagonal method} can be used in place of Zorn's lemma to prove that $S$ (which is metrizable by Prop. \ref{lb51}) is compact:

We consider the case that $\scr A=\Zbb_+$. (The case that $\scr A$ is finite is even simpler.) Let $(x_n)_{n\in\Zbb_+}$ be a sequence in $S$. We construct inductively a double sequence $(x_{m,n})_{m,n\in\Zbb_+}$ in $S$ as follows. Since $X_1$ is sequentially compact, $(x_n)$ has subseqeunce $(x_{1,n})_{n\in\Zbb_+}$ whose first component $(x_{1,n}(1))_{n\in\Zbb_+}$ converges to some $x(1)\in X_1$. Suppose that $(x_{m-1,n})_{n\in\Zbb_+}$ has been constructed (where $m-1\geq 1$). Since $X_m$ is sequentially compact, $(x_{m-1,n})_{n\in\Zbb_+}$ has a subsequence $(x_{m,n})_{n\in\Zbb_+}$ whose $m$-th component $(x_{m,n}(m))_{n\in\Zbb_+}$ to some $x(m)\in S$. In this way, the double sequence $(x_{m,n})$ in $S$ and the element $x\in S$ are constructed. One checks easily that $(x_{n,n})_{n\in\Zbb_+}$ is a subsequence of $(x_n)$ converging to $x$.  \hqed 
\end{rem}

















\subsubsection{Precompact sets}


Let $X$ be a Hausdorff space. 

\begin{df}
Let $A\subset X$. We say that $A$ is \textbf{precompact} relative to $X$ and write \index{zz@$\Subset$}
\begin{align*}
A\Subset X
\end{align*}
if $\Cl_X(A)$ is compact, equivalently, if $A$ is contained in a compact subset of $X$.
\end{df}

Recall that a subset of a compact Hausdorff space is closed iff it is compact.

\begin{proof}[Proof of equivalence]
``$\Rightarrow$": Obvious. ``$\Leftarrow$": Let $B\subset X$ be compact and containing $A$. Then $B$ is closed in $X$. So $\Cl_X(A)\subset B$. Since $\Cl_X(A)$ is closed in $X$ and hence closed in $B$, it is compact.
\end{proof}

\begin{rem}\label{lb1}
Let $W\subset X$. Then for each $A\subset W$, we have 
\begin{align*}
A\Subset W\qquad\Longleftrightarrow\qquad A\Subset X\text{ and }\Cl_X(A)\subset W
\end{align*}
When either side is true, we have $\Cl_W(A)=\Cl_X(A)$. Thus, both $\Cl_W(A)$ and $\Cl_X(A)$ can be denoted unambiguously by $\ovl A$.
\end{rem}

In practice, we often choose $W$ to be an open subset of $X$.

\begin{proof}
``$\Leftarrow$": $\Cl_X(A)$ is a compact set inside $W$ and contains $A$. So $A\Subset W$.

``$\Rightarrow$": We have a compact set $B$ such that $A\subset B\subset W$. So $A\Subset X$. Since $B$ is closed in any larger set, we have $\Cl_X(A)\subset B$ and hence $\Cl_X(A)\subset W$.

It is obvious that $\Cl_W(A)\subset\Cl_X(A)$. Assume $A\Subset W$. Then $\Cl_W(A)$ is compact. In the above paragraph, if we choose $B=\Cl_W(A)$. then we have $\Cl_X(A)\subset B=\Cl_X(A)$. This proves $\Cl_W(A)=\Cl_X(A)$.
\end{proof}

\begin{rem}\label{lb2}
Let $U$ be an open subset of $X$. Let $f\in C_c(U,\mc V)$. Then by zero-extension, $f$ can be viewed as an element of $C_c(X,\mc V)$ supported in $U$. Briefly speaking, we have
\begin{align*}
C_c(U,\mc V)\subset C_c(X,\mc V)
\end{align*}
Moreover, for each $f\in C_c(U,\mc V)$, we have
\begin{align*}
\Supp_U(f)=\Supp_X(f)
\end{align*}
\end{rem}

\begin{proof}
Let $f$ take value $0$ outside $U$. Let $K=\Supp_U(f)$, which is compact by assumption. Since $f|_U$ is continuous and $f|_{K^c}=0$ are continuous, and since $X=U\cup K^c$ is an open cover on $X$, $f$ is continuous. By the Rem. \ref{lb1}, we have $\Supp_U(f)=\Supp_X(f)$. Therefore $f\in C_c(X,\mc V)$.
\end{proof}


Under the setting of Rem. \ref{lb2}, it is clear that
\begin{align}
C_c(U,\mc V)=\{f\in C_c(X,\mc V):\Supp_X(f)\subset U\}
\end{align}




\subsubsection{LCH spaces}

Let $X$ be LCH.

\begin{pp}\label{lb3}
Any closed or open subset of $X$ is LCH.
\end{pp}

\begin{proof}
See \cite[Subsec. 8.6.2]{Gui-A}.
\end{proof}

\begin{co}\label{lb54}
Let $W\subset X$ be an open subset. Let $K\subset W$ be compact. Then there exists an open subset $U$ of $X$ such that $K\subset U\Subset W$. 
\end{co}
\begin{proof}
The case that $K$ is a single point follows from the fact that $W$ is LCH, cf. Prop. \ref{lb3}. The general case follows from the compactness of $K$.
\end{proof}

\begin{co}\label{lb102}
Let $K_1,K_2$ be mutually disjoint compact subsets of $X$. Then there exist open subsets $U_1,U_2$ of $X$ such that $K_1\subset U_1$ and $K_2\subset U_2$.
\end{co}

\begin{proof}
This corollary in fact holds even without the assumption that $X$ is locally compact, and its proof is a straightforward exercise in point-set topology. However, it also follows directly from the results established above. Indeed, by Prop. \ref{lb3}, $X\setminus K_2$ is LCH. Therefore, by Cor. \ref{lb54}, there exists an open set $U_1$ such that $K_1\subset U_1\Subset X\setminus K_2$. Let $U_2=X\setminus\ovl U_1$.
\end{proof}





\begin{thm}[\textbf{Urysohn's lemma}]\label{lb56}\index{00@Urysohn's lemma}
Let $K\subset X$ be compact. Then there exists a (continuous) \textbf{Urysohn function} \index{00@Urysohn function} $f$ with respect to $K$ and $X$, i.e., $f\in C_c(X,[0,1])$ and $f|_K=1$.
\end{thm}

\begin{proof}
See \cite[Sec. 15.4]{Gui-A}.
\end{proof}


\begin{rem}\label{lb57}
Urysohn's lemma can be used in the following way. Suppose that $K\subset U\subset X$ where $K$ is compact and $U$ is open in $X$. By Prop. \ref{lb3}, $U$ is LCH. Therefore, by Thm. \ref{lb56}, there exists $f\in C_c(U,[0,1])$ such that $f|_K=1$. By Rem. \ref{lb2}, $f$ can be viewed as an element of $C_c(X,[0,1])$ satisfying $f|_K=1$ and $\Supp(f)\subset U$.
\end{rem}


\begin{thm}\label{lb100}
Let $K$ be a compact subset of $X$. Let $\fk U=(U_1,\dots,U_n)$ be a finite collection of open subsets of $X$ covering $K$ (i.e. $K\subset U_1\cup\cdots\cup U_n$). Then there exist $h_i\in C_c(U_i,\Rbb_{\geq0})$ (for all $1\leq i\leq n$) satisfying the following conditions:
\begin{enumerate}[label=(\arabic*)]
\item $0\leq \dps \sum_{i=1}^nh_i\leq 1$ on $X$. 
\item  $\dps\sum_{i=1}^nh_i\big|_K=1$.
\end{enumerate}
Such $h_1,\dots,h_n$ are called a \textbf{partition of unity of \pmb{$K$} subordinate to \pmb{$\fk U$}}. \index{00@Partition of unity in LCH spaces}
\end{thm}

In fact, $h_1,\dots,h_n$ should be viewed as a partition of the Urysohn function $h:=h_1+\cdots+h_n$.


\begin{proof}
See \cite[Sec. 15.4]{Gui-A}. Note that condition (1) is not stated in some textbooks on partitions of unity.  However, even if (1) is not initially satisfied, one can enforce it by setting $g(x)=\max\{\sum_i h_i(x),1\}$ and replacing each $h_i$ with $h_i/g$.
\end{proof}



\begin{thm}[\textbf{Tietze extension theorem}]\index{00@Tietze extension theorem}\label{lb83}
Let $K$ be a compact subset of $X$. Let $f\in C(K,\Fbb)$. Then there exists $\wtd f\in C_c(X,\Fbb)$ such that $\wtd f|_K=f$, and that $\Vert\wtd f\Vert_{l^\infty(X)}=\Vert f\Vert_{l^\infty(K)}$.
\end{thm}

\begin{proof}
See \cite[Sec. 15.4]{Gui-A}.
\end{proof}



\begin{df}
We let \index{C0@$C_0(X,\mc V),C_0(X,E)$}
\begin{align*}
C_0(X,\mc V)=\left\{
\begin{array}{ll}
\{f\in C(X,\mc V):\lim_{x\rightarrow\infty}\Vert f(x)\Vert=0\}&\text{if $X$ is not compact}\\[0.5ex]
C(X,\mc V)=C_c(X,\mc V)&\text{if $X$ is compact}
\end{array}
\right.
\end{align*}
where $\wht X=X\cup\{\infty\}$ is the one-point compactification of $X$. Equivalently, $C_0(X,\mc V)$ is the set of all $f\in C(X,\mc V)$ such that for any $\eps>0$ there exists a compact $K\subset X$ such that $\Vert f\Vert_{l^\infty(X\setminus K)}<\eps$. See \cite[Subsec. 15.8.1]{Gui-A} for more discussions. For each $E\subset\mc V$, we let
\begin{align*}
C_0(X,E)=C_0(X,V)\cap E^X
\end{align*}
\end{df}


\begin{rem}
$C_0(X,\mc V)$ is the $l^\infty$-closure of $C_c(X,\mc V)$ in $C(X,\mc V)$. 
\end{rem}

\begin{proof}
One easily shows that $C_0(X,\mc V)$ is closed in $C(X,\mc V)$. To show that $C_c(X,\mc V)$ is dense in $C_0(X,\mc V)$, we choose any $f\in C_0(X,\mc V)$. Then for each $\eps>0$ there exists a compact $K\subset X$ such that $\Vert f\Vert_{l^\infty(K^c)}<\eps$. By Urysohn's lemma, there exists $h\in C_c(X,[0,1])$ such that $h|_K=1$. Then $\Vert hf\Vert_{l^\infty(K^c)}<\eps$, and hence $\Vert f-hf\Vert_{l^\infty(X)}<2\eps$. This finishes the proof, since $hf\in C_c(X,\mc V)$.
\end{proof}

\begin{rem}\label{lb84}
Suppose that $X$ is second countable. Then $X$ is Lindel\"of. Therefore, $X$ has a countable open cover $\fk U=(U_n)_{n\in\Zbb_+}$ whose members $U_n$ are precompact open subsets of $X$. In particular, $X$ is $\sigma$-compact, since $X=\bigcup_{n\in\Zbb_+}\ovl{U_n}$ where each $\ovl{U_n}$ is compact.
\end{rem}




\subsection{$*$-algebras and the Stone-Weierstrass theorem}


Recall that $\Fbb\in\{\Rbb,\Cbb\}$. In this section, we let $\Kbb$ be any subfield of $\Cbb$ closed under complex conjugation, such as $\Rbb,\Cbb,\Qbb,\Qbb+\im\Qbb$.


\begin{df}
A \textbf{$\Kbb$-algebra} \index{00@Algebra}  is defined to be a ring $\scr A$ (not necessarily having $1$) that is also a $\Kbb$-vector space, such that the vector addition agrees with the ring addition, and the scalar multiplication is compatible with the ring multiplication in the following sense: for all $\lambda\in\Kbb$ and $x,y\in\scr A$, we have
\begin{align}
\lambda(xy)=(\lambda x)y=x(\lambda y)
\end{align}

A $\Kbb$-algebra is called \textbf{unital} \index{00@Unital algebra} if $\scr A$, as a ring, has a multiplicative identity $1$. In this case, we write $\lambda\cdot 1$ as $\lambda$ if $\lambda\in\Kbb$. 

A $\Kbb$-algebra is called \textbf{commutative} or \textbf{abelian} \index{00@Commutative algebra} \index{00@Abelian algebra} if $xy=yx$ for all $x,y\in\scr A$.

If $\scr A$ is a $\Kbb$-algebra, then a \textbf{($\Kbb$-)subalgebra} \index{00@Subalgebra} is a subset $\scr B$ which is invariant under the ring addition, ring multiplication, and scalar multiplication. (Namely, $\scr B$ is a subring and also a subspace of $\scr A$.) If $\scr A$ is unital, then a \textbf{unital ($\Kbb$-)subalgebra} of $\scr A$ is a $\Kbb$-subalgebra containing the identity of $\scr A$.  \hfill\qedsymbol
\end{df}


\begin{rem}
A unital $\Kbb$-algebra $\scr A$ can equivalently be described as a ring with identity, together with a ring homomorphism $\Cbb\rightarrow Z(\scr A)$ where $Z(\scr A)$ is the \textbf{center} of $\scr A$, i.e.
\begin{align*}
Z(\scr A)=\{x\in\scr A:xy=yx\text{ for every }y\in\scr A\}
\end{align*}
We leave the verification of this equivalence to the reader.
\end{rem}



\begin{eg}
If $V$ is a $\Fbb$-vector space, then $\End(V)$, the set of $\Fbb$ linear maps $V\rightarrow V$, is naturally an $\Fbb$-algebra. If $V$ is a normed vector space, then $\fk L(V)$ is an $\Fbb$-algebra.
\end{eg}

\begin{df}\label{lb53}
A \textbf{*-$\Kbb$-algebra} \index{00@*-$\Kbb$-algebra} is defined to be a $\Kbb$-algebra together with an \textbf{antilinear map} \index{00@Antilinear map} $*:\scr A\rightarrow\scr A$ sending $x$ to $x^*$ (where ``antilinear" means that for every $a,b\in\Cbb$ and $x,y\in\scr A$ we have $(ax+by)^*=\ovl ax^*+\ovl by^*$) such that for every $x,y\in\scr A$, we have
\begin{align*}
(x^*)^*=x\qquad (xy)^*=y^*x^*
\end{align*}
Note that $*$ must be bijective. We call $*$ an \textbf{involution}. 
\index{00@Involution} A \textbf{*-$\Kbb$-subalgebra} \index{00@*-$\Kbb$-subalgebra} $\scr B$ is defined to be a subalgebra satisfying $x\in\scr B$ iff $x^*\in\scr B$. If $\scr A$ is a unital algebra with unit $\idt$, we say that $\scr A$ is a \textbf{unital *-$\Kbb$-algebra} if $\scr A$ is equipped with an involution $*:\scr A\rightarrow\scr A$ such that $\scr A$ is a *-algebra, and that
\begin{align*}
\idt^*=\idt
\end{align*}
A unital *-subalgebra is a unital subalegbra and also a *-subalgebra.
\end{df}

\begin{cv}
We omit ``$\Kbb$-" when $\Kbb$ is $\Cbb$. For example, a \textbf{unital *-algebra} means a unital $*$-$\Cbb$-algebra.
\end{cv}



\begin{eg}
The set of complex $n\times n$ matrices $\Cbb^{n\times n}$ is naturally a unital $*$-algebra if for every $A\in\Cbb^{n\times n}$ we define $A^*=\ovl A^\tr$, the complex conjugate of the transpose of $A$.
\end{eg}



\begin{eg}
Let $X$ be a set. Then $\Kbb^X$ is naturally a unital $\Kbb$-algebra, and $l^\infty(X,\Kbb)$ is its unital $\Kbb$-subalgebra. If $X$ is a topological space, then $C(X,\Kbb)$ is a unital $\Kbb$-subalgebra of $\Kbb^X$. If $X$ is compact, then $C(X,\Kbb)$ is a unital $\Kbb$-subalgebra of $l^\infty(X,\Kbb)$.
\end{eg}



\begin{eg}
Let $X$ be a set. Then $\Cbb^X$ is a unital *-algebra if for every $f\in\Cbb^X$ we define \index{f@$f^*(x)=\ovl{f(x)}$}
\begin{align}\label{eq33}
f^*:X\rightarrow\Cbb\qquad \pmb{f^*(x)}=\ovl{f(x)}
\end{align}
Then $\Kbb^X$ and $l^\infty(X,\Kbb)$ are unital *-$\Kbb$-subalgebras of $\Cbb^X$.

Assume that $X$ is a compact topological space. Then $C(X,\Fbb)$ is a unital *-$\Fbb$-subalgebra of $l^\infty(X,\Fbb)$. If $f_1,\dots,f_n\in C(X,\Fbb)$, then $\Fbb[f_1,\dots,f_n]$, the set of polynomials of $f_1,\dots,f_n$ with coefficients in $\Fbb$, is a unital $\Fbb$-subalgebra of $C(X,\Fbb)$. And $\Fbb[f_1,f_1^*,\dots,f_n,f_n^*]$ is a unital *-$\Fbb$-subalgebra of $C(X,\Fbb)$.  \hqed
\end{eg}


More generally, we have:

\begin{eg}
Let $\scr A$ be an abelian unital $\Kbb$-algebra. Let $\fk S\subset\scr A$. Then \index{FS@$\Kbb\bk{\fk S}$}
\begin{align}
\Kbb\bk{\fk S}=\Span_\Kbb\{x_1^{n_1}\cdots x_k^{n_k}:k\in\Zbb_+,x_i\in\fk S,n_i\in\Nbb\}
\end{align}
the set of (possibly non-commutative) polynomials of elements in $\fk S$, is the smallest unital $\Kbb$-subalgebra containing $\fk S$, called the \textbf{unital $\Kbb$-subalgebra generated by $\fk S$}. \index{00@Subalgebra generated by...} (Here, we understand $x^0=1$ if $x\in\scr A$.) Thus, if $\scr A$ is an abelian unital *-algebra, then $\Cbb\bk{\fk S\cup\fk S^*}$ (where $\fk S^*=\{x^*:x\in\fk S\}$) is the smallest unital *-algebra containing $\fk S$, called the \textbf{unital *-$\Kbb$-subalgebra generated by $\fk S$}.
\end{eg}



\begin{df}
Let $X$ be sets. Let $(f_\alpha)_{\alpha\in\fk A}$ be a family of maps where $f_\alpha:X\rightarrow Y_\alpha$ and $Y_\alpha$ is a set.  We say that $(f_\alpha)_{\alpha\in\fk A}$ \textbf{separates the points of $\pmb X$} \index{00@Seperate points} if for any distinct $x_1,x_2\in X$ there exists $\alpha\in\fk A$ such that $f_\alpha(x_1)\neq f_\alpha(x_2)$. Equivalently, the map
\begin{gather}
\bigvee_{\alpha\in\fk A}f_\alpha:X\rightarrow \prod_{\alpha\in\fk A}Y_\alpha\qquad x\mapsto (f_\alpha(x))_{\alpha\in\fk A}
\end{gather}
is injective.
\end{df}


\begin{eg}\label{lb58}
Let $X$ be an LCH space. Then $C_c(X,[0,1])$ separates the points of $X$.
\end{eg}

\begin{proof}
Choose any distinct points $x,y\in X$. By Urysohn's lemma (Rem. \ref{lb57}), there exists $f\in C_c(X,[0,1])$ such that $f(x)=1$ and $\Supp(f)\subset X\setminus\{y\}$. So $f$ separates $x,y$.
\end{proof}

\begin{thm}[\textbf{Stone-Weierstrass theorem}]\index{00@Stone-Weierstrass}\label{lb87}
Let $X$ be a compact Hausdorff space. Let $\fk S\subset C(X,\Fbb)$. Suppose that $\fk S$ separates the points of $X$. Then the $*$-$\Fbb$-subalgebra $\Fbb\bk{\fk S\cup\fk S^*}$ generated by $\fk S$ is dense in $C(X,\Fbb)$ under the $l^\infty$-norm.
\end{thm}

Note that if $\Fbb=\Rbb$, then $\fk S^*=\fk S$ by \eqref{eq33}.

If $\Fbb=\Cbb$, then since $(\Qbb+\im\Qbb)\bk{\fk S\cup\fk S^*}$ is $l^\infty$-dense in $\Cbb\bk{\fk S\cup\fk S^*}$, it is clear that $(\Qbb+\im\Qbb)\bk{\fk S\cup\fk S^*}$ is $l^\infty$-dense in $C(X)$. Similarly, if $\Fbb=\Rbb$, then $\Qbb\bk{\fk S}$ is $l^\infty$-dense in $C(X,\Rbb)$.

\begin{proof}
See \cite[Ch. 15]{Gui-A}.
\end{proof}




The following application of the Stone-Weierstrass theorem will be used in the study of weak-* topology, particularly in the proof of Thm. \ref{lb76}. Recall that $C(X,\Fbb)$ is equipped with the $l^\infty$-norm.

\begin{thm}\label{lb75}
Let $X$ be a compact Hausdorff space. Then the following are equivalent:
\begin{enumerate}[label=(\alph*)]
\item $X$ is metrizable.
\item $X$ is second countable.
\item There is a sequence $(f_n)_{n\in\Zbb_+}$ in $C(X,\Fbb)$ separating the points of $X$.
\item $C(X,\Fbb)$ is separable.
\end{enumerate}
Moreover, if (c) is satisfied, then for each $R\in\Rbb_{>0}$, a compatible metric $d$ on $X$ can be chosen to be
\begin{gather}\label{eq34}
d(x,y)=\sum_{n\in\Zbb_+}2^{-n}\min\{|f_n(x)-f_n(y)|,R\}\qquad\text{for each }x,y\in X
\end{gather}
\end{thm}


In particular, if (c) is satisfied and $\sup_{n\in\Zbb_+}\Vert f_n\Vert_{l^\infty}<+\infty$, we can choose $R=2\sup_{n\in\Zbb_+}\Vert f_n\Vert_{l^\infty}$. Then \eqref{eq34} becomes
\begin{gather}\label{eq35}
d(x,y)=\sum_{n\in\Zbb_+}2^{-n}|f_n(x)-f_n(y)|\qquad\text{for each }x,y\in X
\end{gather}



The Stone-Weierstrass theorem will be used in the direction (c)$\Rightarrow$(d). The equivalence of (a,b,c) does not rely on the Stone-Weierstrass theorem.

\begin{proof}
(a)$\Rightarrow$(b): By .\\[-1ex]

(b)$\Rightarrow$(c): Since $X$ is second countable, we can choose an infinite countable base $(U_n)_{n\in\Zbb}$ of the topology. For each $m,n\in\Zbb_+$, if $U_n\Subset U_m$, we choose $f_{m,n}\in C_c(U_m,[0,1])\subset C_c(X,[0,1])$ such that $f|_{\ovl U_n}=1$ (which exists by Urysohn's lemma); otherwise, we let $f_{m,n}=0$. 

Let us prove that $\{f_{m,n}:m,n\in\Zbb_+\}$ separates the points of $X$: Choose distinct $x,y\in X$. Since $X\setminus\{y\}\in\Nbh_X(x)$, there exists $U_m$ containing $x$ and is contained in $X\setminus\{y\}$. By Cor. \ref{lb54}, there exists $n$ such that $\{x\}\subset U_n\Subset U_m$. Then $f_{m,n}(x)=1$ and $f_{m,n}(y)=0$.\\[-1ex]

(c)$\Rightarrow$(a,b): Since $(f_n)$ separates points, the map
\begin{gather*}
\Phi=\bigvee_n f_n:X\rightarrow\Fbb^{\Zbb_+}\qquad x\mapsto (f_n(x))_{n\in\Zbb_+}
\end{gather*}
is injective. By Cor. \ref{lb55}, $\Phi$ is continuous. Since $X$ is compact, the map $\Phi$ restricts to a homeomorphism $\Phi:X\rightarrow\Phi(X)$, where $\Phi(X)$ is equipped with the subspace topology of the product topology of $\Fbb^{\Zbb_+}$. By Prop. \ref{lb51}, $\Fbb^{\Zbb_+}$ is metrizable and second countable, so $\Phi(X)$, and hence $X$, is metrizable and second countable. This proves (a) and (b).

By \eqref{eq32}, the product topology of $\Fbb^{\Zbb_+}$ is induced by the metric
\begin{align*}
\delta(u,v)=\sum_{n\in\Zbb_+}2^{-n}\min\{|u(n)-v(n)|,R\}\qquad\text{for each }u,v\in\Fbb^{\Zbb_+}
\end{align*}
Therefore, the pullback metric $\Phi^*\delta$ on $X$ (defined by $\Phi^*\delta(x,y)=\delta(\Phi(x),\Phi(y))$) induces the topology of $X$. Clearly $\Phi^*\delta(x,y)$ equals \eqref{eq34}. \\[-1ex]

(c)$\Rightarrow$(d): Let $\Kbb=\Fbb\cap(\Qbb+\im\Qbb)$. By Stone-Weierstrass, the countable set $\Kbb[\{f_n:n\in\Zbb_+\}]$ is dense in $C(X,\Fbb)$. Thus $C(X,\Fbb)$ is separable.\\[-1ex]

(d)$\Rightarrow$(c): By Exp. \ref{lb58}, $C(X,\Fbb)$ separates the points of $X$. Therefore, any dense subset of $C(X,\Fbb)$ separates the points of $X$. Since $C(X,\Fbb)$ is separable, it has a countable dense subset separating the points of $X$.
\end{proof}







\subsection{Review of measure theory: general facts}

\subsubsection{Some useful definitions and their basic properties}

\begin{df}
Let $X$ be a set. Suppose that $\scr C$ is an $\Fbb$-linear subspace of $\Fbb^X$. A \textbf{positive linear functional} \index{00@Positive linear functional} on $\scr C$ denotes an $\Fbb$-linear map $\Lambda:\scr C\rightarrow\Fbb$ such that $\Lambda(f)\geq0$ for all $f\in\scr C\cap \Rbb_{\geq0}^X$. 
\end{df}

Recall that if $(X,\fk M)$ is a measurable space, an \textbf{\pmb{$\Fbb$}-valued simple function} on $X$ \index{00@Simple function} is an $\Fbb$-linear combination of characteristic functions over measurable sets; that is, an element of $\Span_\Fbb\{\chi_E:E\in\fk M\}$.


\begin{df}\label{lb98}
Let $X$ be a set. Let $x\in X$. The \textbf{Dirac measure \pmb{$\delta_x$}} \index{00@Diract measure} \index{zz@$\delta_x$, the Dirac measure at $x$} of $x$ is defined to be the measure $\delta_x:2^X\rightarrow\ovl\Rbb_{\geq0}$ satisfying $\delta_x(A)=1$ if $x\in A$, and $\delta_x(A)=0$ if $x\notin A$.
\end{df}


\begin{df}
Let $(X,\mc T_X)$ be a topological space. Let $\fk M\subset 2^X$ be a $\sigma$-algebra containing the Borel $\sigma$-algebra $\fk B_X$. Let $\mu:\fk M\rightarrow\ovl\Rbb_{\geq0}$ be a measure. Assume that one of the following conditions holds:
\begin{enumerate}[label=(\arabic*)]
\item $X$ is second countable.
\item $X$ is LCH, and $\mu|_{\fk B_X}$ is a Radon measure.
\end{enumerate}
The \textbf{support \pmb{$\Supp(\mu)$}} \index{00@Support of a measure} \index{Supp@$\Supp(\mu)$} is defined to be
\begin{align*}
\Supp(\mu)=\{x\in X:\mu(U)>0\text{ for each }U\in\Nbh_X(x)\}
\end{align*}
Then $\Supp(\mu)$ is a closed subset of $X$, because we clearly have
\begin{align*}
X\setminus\Supp(\mu)=\bigcup_{U\in\mc T_X,\mu(U)=0}U
\end{align*}
Moreover, we have $\mu(X\setminus\Supp(\mu))=0$. Thus, $\Supp(\mu)$ is the largest closed subset whose complement is $\mu$-null.
\end{df}

\begin{proof}[Proof that $X\setminus\Supp(\mu)$ is null]
It suffices to show that if a family of open subsets $(U_\alpha)_{\alpha\in\scr A}$ is null, then the union $U:=\bigcup_\alpha U_\alpha$ is null. 

Assume that condition (1) holds. Since any subset of a second countable space is second countable and hence Lindel\"of, the set $U$ is Lindel\"of. So $(U_\alpha)$ has a countable subfamily covering $U$. Therefore, by the countable additivity, $U$ is null. 

Assume that condition (2) holds. Since Radon measures are inner regular on open sets (cf. Def. \ref{lb97}), $\mu(U)$ is the supremum of $\mu(K)$ where $K$ runs through all compact subsets of $U$. Since $K$ is compact,  $(U_\alpha)$ has a finite subfamily covering $K$. Therefore $K$ is null, and hence $U$ is null.
\end{proof}


\begin{lm}
Let $\mu:\fk M\rightarrow\ovl\Rbb_{\geq0}$ be as in Def. \ref{lb98}, and assume that Condition (1) or (2) of Def. \ref{lb98} holds. The following are equivalent:
\begin{enumerate}[label=(\alph*)]
\item $\Supp(\mu)$ is a finite set.
\item $\mu$ is a linear combination of Dirac measures (restricted to $\fk M$).
\end{enumerate}
\end{lm}

\begin{proof}
(b)$\Rightarrow$(a): This is obvious.

(a)$\Rightarrow$(b): Write $E=\Supp(\mu)$. Choose any measurable $f:X\rightarrow\ovl\Rbb_{\geq0}$. Then, since $\mu|_{X\setminus E}=0$, the integral of any measurable function $g:X\rightarrow\ovl\Rbb_{\geq0}$ vanishing ourside $E$ is zero. In particular, we can choose $g$ to be the unique one such that $g+\sum_{x\in E}f(x)\chi_{\{x\}}=f$. Therefore
\begin{align*}
\int_Xfd\mu=\int_E \sum_{x\in E}f(x)\chi_{\{x\}}d\mu=\sum_{x\in E}f(x)\cdot \mu(\{x\})
\end{align*}
This shows that $\mu=\sum_{x\in E}\mu(\{x\})\delta_x$.
\end{proof}






\subsubsection{Radon-Nikodym derivatives}

Fix a measurable space $(X,\fk M)$. 

\begin{df}
Let $\mu,\nu:\fk M\rightarrow[0,+\infty]$ are measures. We say that $\nu$ is \textbf{absolutely continuous} with respect to $\mu$ \index{00@Absolute continuity of measures} and write $\pmb{\nu\ll\mu}$ \index{zz@$\nu\ll\mu$} if any $\mu$-null set is $\nu$-null. We say that $h\in\mc L(X,\ovl\Rbb_{\geq0})$ is a \textbf{Radon-Nikodym derivative} of $\nu$ with respect to $\mu$ if 
\begin{align*}
\int_X fd\nu=\int_X fhd\mu\quad \text{ for all }f\in\mc L(X,\ovl\Rbb_{\geq0})
\end{align*}
By MCT, the above condition is equivalent to
\begin{align*}
\nu(E)=\int_E hd\mu\qquad\text{ for all }E\in\fk M
\end{align*}
We write $\pmb{d\nu=hd\mu}$.
\end{df}

\begin{rem}
If $\mu$ is $\sigma$-finite, and if $h_1,h_2$ are both Radon-Nikodym derivatives of $\nu$ with respect to $\mu$, then $h_1(x)=h_2(x)$ for $\mu$-a.e. $x\in X$.
\end{rem}


\begin{proof}
It suffices to assume that $\mu(X)<+\infty$. For each $k\in\Nbb$, let
\begin{align*}
A_k=\{x\in X:h_1(x)<h_2(x)\text{ and }h_1(x)\leq k\}
\end{align*}
Then $\int_{A_k} h_1d\mu\leq k\mu(X)<+\infty$, and
\begin{align*}
\int_{A_k} h_1d\mu=\int_{A_k} d\nu=\int_{A_k}h_2d\mu
\end{align*}
Taking subtraction, we get $\int_{A_k}(h_2-h_1)d\mu=0$. Let $A=\bigcup_k A_k=\{x\in X:h_1(x)<h_2(x)\}$. By MCT,  $\int_A(h_2-h_1)d\mu=0$. Since $h_2-h_1\geq0$ on $A$, we conclude $h_2-h_1=0$ $\mu$-a.e. on $A$, and hence $\mu(A)=0$. Similarly, $\mu(B)=0$ where $B=\{x\in X:h_1(x)>h_2(x)\}$.
\end{proof}

\begin{rem}
If $\nu$ is $\sigma$-finite, and if $d\nu=hd\mu$, then $h(x)<+\infty$ for $\mu$-a.e. $x\in X$. 
\end{rem}

\begin{proof}
Let $A=\{x\in A:h(x)=+\infty\}$. Since $\nu$ is $\sigma$-finite, we can write $A=\bigcup_{k\in\Nbb}A_k$ where $A_k\in\fk M$ and $\nu(A_k)<+\infty$. Since $\nu(A_k)=\int_{A_k}hd\mu=+\infty \mu(A_k)$, we have $\mu(A_k)=0$, and hence $\mu(A)=0$.
\end{proof}





\begin{thm}[\textbf{Radon-Nikodym theorem}]\label{lb27} \index{00@Radon-Nikodym theorem}
Assume that $\mu,\nu:\fk M\rightarrow[0,+\infty]$ are $\sigma$-finite measures. Then $\nu\ll\mu$ iff $\nu$ has a Radon-Nikodym derivative with respect to $\mu$.
\end{thm}


\begin{proof}[Proof]
``$\Leftarrow$" is obvious. Let us prove ``$\Rightarrow$". It is easy to reduce to the case that $\mu(X),\nu(X)<+\infty$. Let $d\psi=d\mu+d\nu$. So $\mu,\nu\leq\psi$. Therefore, the linear functional
\begin{gather*}
\Lambda: L^2(X,\psi)\rightarrow\Cbb\qquad \xi\mapsto \int_X \xi d\mu
\end{gather*}
is bounded. Since $L^2(X,\psi)$ is a Hilbert space (Thm. \ref{lb26}), by the Riesz-Fr\'echet theorem, there exists $f\in L^2(X,\psi)$ such that $\int_X\xi d\nu=\int_X \xi fd\psi$ for all $\xi\in L^2(X,\psi)$. Since $\Lambda$ sends positive functions to $\Rbb_{\geq0}$, after adding an $\psi$-a.e. function to $\xi$, we have $\psi\geq0$ everywhere.


We have found $f\in\mc L(X,\Rbb_{\geq0})$ such that $d\mu=fd\psi$. Similarly, we have $g\in\mc L(X,\Rbb_{\geq0})$ such that $d\nu=gd\psi$.  Since $\mu\leq\psi \ll \mu$, we have $f>0$ outside a $\psi$-null set $\Delta$. Let $h=g/f$ outside $\Delta$, and $h=0$ on $\Delta$. Then $d\nu=hd\mu$. 
\end{proof}












\subsubsection{$L^p$-spaces}


Let $(X,\fk M,\mu)$ be a measure space. Let $1\leq p,q\leq +\infty$ such that $p^{-1}+q^{-1}=1$.

\begin{thm}\label{lb79}
Let $1\leq p<+\infty$. Then the set of integrable $\Fbb$-valued simple functions is dense in $L^p(X,\mu,\Fbb)$. In other words,
\begin{align*}
\{\chi_E:E\subset\fk M,\mu(E)<+\infty\}
\end{align*}
spans a dense subspace of $L^p(X,\mu,\Fbb)$.
\end{thm}

\begin{proof}
See \cite[Sec. 27.2]{Gui-A}.
\end{proof}


\begin{thm}[\textbf{Riesz-Fischer theorem}, the modern form]\index{00@Riesz-Fischer theorem, the modern form}\label{lb26}
The normed vector space $L^p(X,\mu,\Fbb)$ is (Cauchy) complete. Moreover, any Cauchy sequence in $L^p(X,\mu,\Fbb)$ has a subseqence converging $\mu$-a.e..
\end{thm}


\begin{proof}
See \cite[Sec. 27.3]{Gui-A}.
\end{proof}


\begin{lm}\label{lb28}
Assume that $(X,\mu)$ is $\sigma$-finite. Let $\mc S_+$ be the set of simple functions $X\rightarrow\Rbb_{\geq0}$. Then for each $f\in\mc L(X,\ovl\Rbb_{\geq0})$ we have
\begin{align}\label{eq15}
\Vert f\Vert_{L^p(X,\mu)}=\sup\Big\{\int_X fgd\mu:g\in\mc S_+, \Vert g\Vert_{L^q(X,\mu)}\leq 1 \Big\}
\end{align}
Consequently, for each $f\in\mc L(X,\Cbb)$ we have
\begin{align}\label{eq16}
\Vert f\Vert_{L^p(X,\mu)}=\sup\Big\{\int_X |fg|:g\in L^q(X,\mu), \Vert g\Vert_q\leq 1 \Big\}
\end{align}
\end{lm}



\begin{proof}
By H\"older's inequality, we have ``$\geq$".  To prove ``$\leq$", we note that \eqref{eq16} follows immediately from \eqref{eq15} by writing $f=u|f|$ where $u\in\mc L(X,\Sbb^1)$ and applying \eqref{eq15} to $|f|$. Thus, in the following, we assume $f\in\mc L(X,\ovl\Rbb_{\geq0})$. 

Case $1<p<+\infty$: Choose an increasing sequence $(f_n)$ (i.e. $f_1\leq f_2\leq\cdots$) in $\mc S_+$ converging pointwise to $f$ such that each $f_n$ vanishes outside a measurable $\mu$-finite set. Let $g_n=(f_n)^{p-1}$. After removing the first several terms, we assume $\Vert g_n\Vert_{L^q}>0$ for all $n$. Then
\begin{align*}
0<\Vert g_n\Vert_q=\Vert f_n\Vert_p^{p/q}<+\infty
\end{align*}
By MCT, we have $\lim_n \Vert g_n\Vert_p=\Vert f\Vert_p^{p/q}$ and $\lim_n \int_X fg_n=\Vert f\Vert_p^p$. Thus, if $\Vert f\Vert_p<+\infty$, then
\begin{align*}
\lim_n\Vert g_n\Vert_q^{-1}\int_X fg_n=\Vert f\Vert_p^{-p/q}\cdot \Vert f\Vert_p^p=\Vert f\Vert_p
\end{align*}
This proves \eqref{eq15} when $\Vert f\Vert_p<+\infty$. If $\Vert f\Vert_p=+\infty$, then, by MCT, $\Vert f_n\Vert_p<+\infty$ can be sufficiently large. Applying \eqref{eq15} to $f_n$, we obtain $g\in\mc S_+$ such that $\Vert g\Vert_q\leq 1$ and $\int f_ng$ is sufficiently large, and hence $\int fg$ is sufficiently large. Thus \eqref{eq15} holds again.

Case $p=1$: Let $g=1$.

Case $p=+\infty$: Write $X=\bigcup_{n\in\Nbb} \Omega_n$ where $\Omega_n\in\fk M$ and $\mu(\Omega_n)<+\infty$. Choose any $0\leq\lambda<\Vert f\Vert_\infty$. Then $A:=\{|f|>\lambda\}$ satisfies $\mu(A)>0$. Thus, there exists $n$ such that $0<\mu(A\cap\Omega_n)<+\infty$. Let $g=\chi_{A\cap\Omega_n}/\mu(A\cap\Omega_n)$. Then $g\in\mc S_+$, $\Vert g\Vert_1=1$, and $\int fg\geq\lambda$. This proves \eqref{eq15}.
\end{proof}















\begin{thm}\label{lb13}
Assume that $(X,\mu)$ is $\sigma$-finite. Assume $1<p\leq+\infty$. Then we have an isomorphism of normed vector spaces
\begin{gather}\label{eq31}
\Psi: L^p(X,\mu,\Fbb)\rightarrow L^q(X,\mu,\Fbb)^*\qquad f\mapsto \Big(g\in L^q(X,\mu,\Fbb)\mapsto \int_Xfgd\mu \Big)
\end{gather}
\end{thm}


When $p<+\infty$, the assumption on $\sigma$-finiteness can be removed. See \cite[Sec. 6.2]{Fol-R}. When $p=2$, this is simply due to the completeness of $L^2(X,\mu,\Fbb)$ and the Riesz-Fr\'echet theorem.

\begin{proof}[Proof]
By H\"older's inequality and Lem. \ref{lb28}, $\Psi$ is an isometry. Let us show that any $\Lambda\in L^q(X,\mu,\Fbb)^*$ belongs to the range of $\Psi$. \\[-1ex]


Step 1. By considering the real and imaginary parts, we can first assume that $\Lambda$ is real, i.e., $\Lambda(f)\in\Rbb$ for any $f\in L^q(X,\mu,\Rbb_{\geq0})$. 

Let us define $\Rbb_{\geq0}$-linear maps $\Lambda^+,\Lambda^-:L^q(X,\mu,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ with operator norms $\leq \Vert\Lambda\Vert$, i.e.,
\begin{align}\label{eq18}
\Vert\Lambda^\pm(g)\Vert\leq\Vert\Lambda\Vert\cdot\Vert g\Vert_q\qquad\text{for all }g\in L^q(X,\mu,\Rbb_{\geq0})
\end{align}
and let us check that 
\begin{align}\label{eq19}
\Lambda(g)=\Lambda^+(g)-\Lambda^-(g)\qquad\text{for all }g\in L^q(X,\mu,\Rbb_{\geq0})
\end{align}
Eq. \eqref{eq19} is called the \textbf{Jordan decomposition} of $\Lambda$.

Define the  $\Lambda^\pm:L^q(X,\mu,\Rbb_{\geq0})\rightarrow \ovl\Rbb$ by sending each $g\in L^q(X,\mu,\Rbb_{\geq0})$ to
\begin{gather}\label{eq17}
\Lambda^\pm(g)=\sup\{\pm\Lambda (h):h\in L^q(X,\mu,\Rbb_{\geq0}),h\leq g\}
\end{gather}
Since $0\leq g$, we clearly have $\Lambda^+(g)\geq0$. Since $\Lambda$ is bounded and $\Vert h\Vert_q\leq\Vert g\Vert_q$, we clearly have $\Vert\Lambda^+(g)\Vert\leq \Vert\Lambda\Vert\cdot\Vert g\Vert_q$. In particular, $\Lambda^+$ has range in $\Rbb_{\geq0}$. Since $\Lambda^\pm=(-\Lambda)^\mp$, a similar property holds for $\Lambda^-$. Thus, we have checked \eqref{eq18}.

Clearly, for each $f,g\in L^1(X,\mu,\Rbb_{\geq0})$, we have $\Lambda^+(f+g)\geq\Lambda^+(f)+\Lambda^+(g)$. To prove the other direction, choose any $h\in L^q(X,\mu,\Rbb_{\geq0})$ such that $h\leq f+g$. Let $h_1=fh/(f+g)$ and $h_2=gh/(f+g)$, understood to be zero where the denominator vanishes. Then $h_1,h_2\in L^1(X,\mu,\Rbb_{\geq0})$ and $h_1\leq f$ and $h_2\leq g$. This proves $\Lambda^+(f+g)\leq\Lambda^+(f)+\Lambda^+(g)$. Thus $\Lambda^+$ (and similarly $\Lambda^-$) is $\Rbb_{\geq0}$-linear.

From \eqref{eq17}, one easily checks $\Lambda(g)+\Lambda^-(g)\leq\Lambda^+(g)$ for each $f\in L^q(X,\mu,\Rbb_{\geq0})$. Replacing $\Lambda$ with $-\Lambda$, we get $-\Lambda(g)+\Lambda^+(g)\leq \Lambda^-(g)$. Thus \eqref{eq19} holds.\\[-1ex]




Step 2. Let us prove that $\Lambda^+$ is represented by some $f^+\in L^p(X,\mu,\Rbb_{\geq0})$, namely,
\begin{align}\label{eq21}
\Lambda^+(g)=\int_X f^+gd\mu\qquad\text{for all }g\in L^q(X,\mu,\Rbb_{\geq0})
\end{align}
Then, similarly, $\Lambda^-$ is represented by some $f^-\in L^p(X,\mu,\Rbb_{\geq0})$. Thus $\Lambda$ is represented by $f^+-f^-$, finishing the proof.

Write $X=\bigsqcup_n X_n$ where $\mu(X_n)<+\infty$. Suppose that we can find $f_n^+\in L^p(X_n,\mu)$ representing $\Lambda^+|_{L^q(X_n,\mu)}$, then we can define $f^+:X\rightarrow\Rbb_{\geq0}$ such that $f^+|_{X_n}=f_n$ for all $n$. Clearly $f^+$ represents $\Lambda^+$. In particular, by Lem. \ref{lb28} and \eqref{eq18}, $\Vert f^+\Vert_p\leq\Vert\Lambda\Vert<+\infty$. Thus $f\in L^p(X,\mu)$.


Therefore, according to the previous paragraph, we may assume at the beginning that $\mu(X)<+\infty$. Define
\begin{align*}
\nu:\fk M\rightarrow[0,+\infty]\qquad E\mapsto \Lambda(\chi_E)
\end{align*}
Then one checks easily that $\nu$ is a measure,\footnote{To check the countable additivity, we let $E_1\subset E_2\subset\cdots$ be measurable and $E=\bigcup_n E_n$. Let $F_n=E\setminus E_n$. By \eqref{eq18}, $\nu(F_n)\leq\Vert\Lambda\Vert\mu(F_n)^{\frac 1q}\rightarrow0$. Thus $\nu(E_n)\rightarrow\nu(E)$.} and that $\nu\ll\mu$. Therefore, by the Radon-Nikodym Thm. \ref{lb27}, there exists $f^+\in\mc L(X,\Rbb_{\geq0})$ such that $d\nu=f^+d\mu$. Thus
\begin{align}\label{eq20}
\Lambda^+(g)=\int_X gd\nu=\int_X f^+gd\mu\quad\text{for each simple function $g\in L^q(X,\mu,\Rbb_{\geq0})$}
\end{align}
Lem. \ref{lb28} and \eqref{eq18} then imply $\Vert f^+\Vert_p\leq \Vert\Lambda\Vert<+\infty$, and hence $f\in L^p(X,\mu,\Rbb_{\geq0})$. 

Finally, for $g\in L^q(X,\mu,\Rbb_{\geq0})$, find an increasing sequence of simple functions $g_n\in L^q(X,\mu,\Rbb_{\geq0})$ converging pointwise to $g$. By \eqref{eq18}, $\Lambda^+(g-g_n)\leq \Vert\Lambda\Vert\cdot\Vert g-g_n\Vert_q$ where the RHS converges to zero by DCT. By MCT, $\int_Xf^+g_nd\mu\rightarrow\int_X f^+gd\mu$. Thus, by \eqref{eq20}, we conclude \eqref{eq21}.
\end{proof}






\subsection{Review of measure theory: Radon measures}



\subsubsection{Radon measures and the Riesz-Markov representation theorem}

Let $X$ be LCH. The reference for this subsection is \cite[Ch. 25]{Gui-A}.

\begin{df}
Let $\fk M\subset 2^X$ be a $\sigma$ algebra containing $\fk B_X$, and let $\mu:\fk M\rightarrow\ovl\Rbb_{\geq0}$ be a measure. Let $E\in\fk M$. We say that $\mu$ is \textbf{outer regular}\index{00@Outer and inner regularity of measures} on $E$ if
\begin{align*}
\mu(E)=\inf\{\mu(U):U\supset E,U\text{ is open}\}
\end{align*}
We say that $\mu$ is \textbf{inner regular} on $E$ if
\begin{align*}
\mu(E)=\sup\{\mu(K):K\subset E,K\text{ is compact}\}
\end{align*}
We say that $\mu$ is \textbf{regular} on $E$ if $\mu$ is both outer and inner regular on $E$.
\end{df}




\begin{lm}\label{lb4}
Let $\mu:\fk B_X\rightarrow\ovl\Rbb_{\geq0}$ be a Borel measure. Let $U\subset X$ be open. Then
\begin{align*}
\sup\big\{\mu(K):K\subset U,K\text{ is compact}\big\}=\sup\Big\{\int_Xfd\mu:f\in C_c(U,[0,1])  \Big\}
\end{align*}
Therefore, $\mu$ is inner regular on $U$ iff
\begin{align*}
\mu(U)=\sup\Big\{\int_Xfd\mu:f\in C_c(U,[0,1])  \Big\}
\end{align*}
\end{lm}


\begin{proof}
Let $A,B$ denote the LHS and the RHS. If $f\in C_c(U,[0,1])$, then setting $K=\Supp(f)$, we have $\mu(K)=\int_X\chi_Kd\mu\geq\int_X fd\mu$. This proves $A\geq B$.

Conversely, let $K\subset U$. By Urysohn's lemma, there exists $f\in C_c(U,[0,1])$ such that $f|_K=1$. So $\mu(K)=\int_X\chi_Kd\mu\leq\int_X fd\mu$. This proves $A\leq B$.
\end{proof}


\begin{df}\label{lb97}
A Borel measure $\mu:\fk B_X\rightarrow\ovl\Rbb_{\geq0}$ is called a \textbf{Radon measure} \index{00@Radon measure} if the following conditions are satisfied:
\begin{enumerate}[label=(\alph*)]
\item $\mu$ is outer regular on Borel sets. 
\item $\mu$ is inner regular on open sets. Equivalently, for each open $U\subset X$, we have
\begin{align}\label{eq47}
\mu(U)=\sup\Big\{\int_Xfd\mu:f\in C_c(U,[0,1])  \Big\}
\end{align}
\item $\mu(K)<+\infty$ if $K$ is a compact subset of $X$. Equivalently, for each $f\in C_c(X,\Rbb_{\geq0})$ we have
\begin{align}
\dps\int_Xfd\mu<+\infty
\end{align}
\end{enumerate}
\end{df}

\begin{proof}[Proof of equivalence]
The equivalence in (b) is due to Lem. \ref{lb4}. The equivalence in (c) can be proved in a similar way to Lem. \ref{lb4}.
\end{proof}













\begin{rem}\label{lb12}
There exist canonical bijections among:
\begin{itemize}
\item $\Rbb_{\geq0}$-linear maps $C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$
\item Positive linear functionals on $C_c(X,\Rbb)$.
\item Positive linear functionals on $C_c(X)=C_c(X,\Cbb)$.
\end{itemize}
\end{rem}
\begin{proof}
An $\Rbb_{\geq0}$-linear map $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ can be extended uniquely to a linear map $\Lambda:C_c(X,\Rbb)\rightarrow\Rbb$ due to the following Lem. \ref{lb5}. The latter can be extended to a linear functional on $C_c(X)$ by setting $\Lambda(f)=\Lambda(\Real f)+\im\Lambda(\Imag f)$ for all $C_c(X)$. 
\end{proof}

\begin{lm}\label{lb5}
Let $K$ be an $\Rbb_{\geq0}$-linear subspace of an $\Rbb$-vector space $V$. Let $W$ be an $\Rbb$-linear space. Let $\Gamma:K\rightarrow W$ be an $\Rbb_{\geq0}$-linear map. Suppose that $V=\Span_\Rbb K$. Then $\Gamma$ can be extended uniquely to an $\Rbb$-linear map $\Lambda:V\rightarrow W$. 
\end{lm}


\begin{proof}
The uniqueness is obvious. To prove the existence, note that any $v\in V$ can be written as
\begin{align*}
v=v^+-v^-
\end{align*}
where $v^+,v^-\in K$. (Proof: Since $V=\Span_\Rbb K$, we have $v=a_1u_1+\cdots+a_mu_m-b_1w_1-\cdots-b_nw_n$ where each $u_i,w_j$ are in $K$, and each $a_i,b_j$ are in $\Rbb_{\geq0}$. One sets $v^+=\sum_i a_iu_i$ and $v^-=\sum_j b_jw_j$.) We then define $\Lambda(v)=\Gamma(v^+)-\Gamma(v^-)$. 

Let us show that this gives a well-defined map $\Lambda:V\rightarrow W$. Assume that $v=w^+-w^-$ where $w^+,w^-\in K$. Then $\Gamma(v^+)-\Gamma(v^-)=\Gamma(w^+)-\Gamma(w^-)$ iff $\Gamma(v^+)+\Gamma(w^-)=\Gamma(v^-)+\Gamma(w^+)$, iff (by the additivity of $\Gamma$) $\Gamma(v^++w^-)=\Gamma(v^-+w^+)$. The last statement is true because $v^+-v^-=w^+-w^-$ implies $v^++w^-=v^-+w^+$.

It is easy to see that $\Lambda$ is additive. If $c\geq0$, then $cv=cv^+-cv^-$ where $cv^+,cv^-\in K$. So $\Lambda(cv)=\Gamma(cv^+)-\Gamma(cv^-)$, which (by the $\Rbb_{\geq0}$-linearity of $\Gamma$) equals $c\Gamma(v^+)-c\Gamma(v^-)=c\Lambda(v)$. Since $-v=v^--v^+$, we have $\Lambda(-v)=\Gamma(v^-)-\Gamma(v^+)=-\Lambda(v)$. Hence $\Lambda(-cv)=c\Lambda(-v)=-c\Lambda(v)$. This proves that $\Lambda$ commutes with the $\Rbb$-multiplication.
\end{proof}


\begin{thm}[\textbf{Riesz-Markov representation theorem}]\label{lb7} \index{00@Riesz-Markov representation theorem}
For every positive linear $\Lambda:C_c(X,\Fbb)\rightarrow\Fbb$ there exists a unique Radon measure $\mu:\fk B_X\rightarrow\ovl\Rbb_{\geq0}$ such that
\begin{align}
\Lambda(f)=\int_Xfd\mu
\end{align}
for all $f\in C_c(X,\Fbb)$. Moreover, every Radon measure on $X$ arises from some $\Lambda$ in this way.

In addition, the operator norm $\Vert\Lambda\Vert$ equals $\mu(X)$. Therefore, $\Lambda$ is bounded iff $\mu$ is a finite measure. 
\end{thm}

\begin{proof}
See \cite[Sec. 25.3]{Gui-A} for the first paragraph. The second paragraph asserts that
\begin{align*}
\sup_{f\in\ovl B_{C_c(X)}(0,1)}|\Lambda(f)|= \mu(X)
\end{align*}
The inequality ``$\leq$" is obvious. The reverse inequality ``$\geq$" follows from \eqref{eq47}.
\end{proof}



\subsubsection{Basic properties of Radon measures}

\begin{thm}\label{lb101}
Let $\mu$ be a Radon measure (or its completion) on $X$. Then $\mu$ is regular on any measurable set $E$ satisfying $\mu(E)<+\infty$.
\end{thm}

\begin{proof}
See \cite[Sec. 25.4]{Gui-A}. A sketch of the proof (different from that in \cite{Gui-A}) is as follows. 

Assume WLOG that $E$ is Borel. Since Radon measures are outer regular on Borel sets, it remains to prove that $\mu$ is inner regular on $E$. Pick an open set $\mu(U)$ such that $\mu(U\setminus E)$ is small. Since $\mu$ is inner regular on $U$, there is a compact $K\subset U$ such that $\mu(U\setminus K)$ is small. However, $K$ is not necessarily contained in $E$. 

To fix this issue, we note that since $\mu$ is outer regular on $U\setminus E$, we can find an open set $V\subset U$ containing $U\setminus E$ whose measure is close to $\mu(U\setminus E)$. In particular, $\mu(V)$ is small. Then $K\setminus V$ is a compact subset of $E$ whose measure is close to $\mu(E)$.
\end{proof}



\begin{thm}\label{lb64}
Assume that $X$ is second countable. Let $\mu$ be a Borel measure on $X$. Then $\mu$ is Radon iff $\mu(K)<+\infty$ for any compact $K\subset X$.
\end{thm}

In particular, a finite Borel measure on $\Rbb^n$ (where $n\in\Nbb$) is Radon.

\begin{proof}
See \cite[Sec. 25.5]{Gui-A}.
\end{proof}





\subsubsection{Approximation and density}

The main reference for this subsection is \cite[Sec. 27.2]{Gui-A}.








\begin{thm}[\textbf{Lusin's theorem}]\label{lb82}\index{00@Lusin's theorem}
Let $X$ be LCH. Let $\mu$ be a Radon measure (or its completion) on $X$ with $\sigma$-algebra $\fk M$. Let $f:X\rightarrow\Fbb$ be measurable. Let $A\in\fk M$ such that $\mu(A)<+\infty$. Then for each $\eps>0$ there exists a compact $K\subset A$ such that $\mu(A\setminus K)<\eps$ and that $f|_K:K\rightarrow\Fbb$ is continuous.
\end{thm}

With the help of the Tietze extension Thm. \ref{lb83}, Lusin's theorem implies that for each $\eps>0$ there exist a compact $K\subset A$ and some $\wtd f\in C_c(X,\Fbb)$ such that $\wtd f|_K=f|_K$ and $\mu(A\setminus K)<\eps$.

\begin{proof}
See \cite[Sec. 25.4]{Gui-A}.
\end{proof}


\begin{thm}\label{lb14}
Let $1\leq p<+\infty$. Let $\mu$ be a Radon measure (or its completion) on an LCH space $X$. Then, under the $L^p$-norm, the space $C_c(X,\Fbb)$ is dense in $L^p(X,\mu,\Fbb)$. More precisely, the map $f\in C_c(X,\Fbb)\mapsto f\in L^p(X,\mu,\Fbb)$ has dense range.
\end{thm}


\begin{proof}
See \cite[Sec. 27.2]{Gui-A}.
\end{proof}










\begin{rem}
One easily checks that
\begin{align*}
&\Span_\Fbb\{\chi_I:I\subset\Rbb\text{ is a bounded interval}\}\\
=&\Span_\Fbb\{\chi_I:I\subset\Rbb\text{ is a compact interval}\}\\
=&\Span_\Fbb\{\chi_I:I\subset\Rbb\text{ is a bounded open interval}\}
\end{align*}
An element in these sets is called an $\Fbb$-valued \textbf{step function}. \index{00@Step functions} Moreover, one checks that
\begin{gather*}
\{\text{right-continuous $\Fbb$-valued step functions}\}=\Span_\Fbb\{\chi_{[a,b)}:a,b\in\Rbb\}\\
\{\text{left-continuous $\Fbb$-valued step functions}\}=\Span_\Fbb\{\chi_{(a,b]}:a,b\in\Rbb\}
\end{gather*}
\end{rem}


\begin{thm}\label{lb77}
Let $1\leq p<+\infty$. Let $\mu$ be a Radon measure (or its completion) on $\Rbb$. Then each of the following classes of functions form a dense subset of $L^p(\Rbb,\mu,\Fbb)$:
\begin{enumerate}[label=(\alph*)]
\item Right-continuous $\Fbb$-valued step functions.
\item Left-continuous $\Fbb$-valued step functions.
\item Elements of $\Span_\Fbb\{\chi_{(-\infty,b]}:b\in\Rbb\}$.
\item Elements of $\Span_\Fbb\{\chi_{(-\infty,b)}:b\in\Rbb\}$.
\end{enumerate}
\end{thm}

\begin{proof}
With the help of Thm. \ref{lb14}, the density of (a) and (b) can be proved by approximating a function $f\in C_c(X,\Fbb)$ with left/right-continuous step functions. See \cite[Sec. 27.2]{Gui-A} for details.

Since (a)$\subset$(c) and (b)$\subset$(d), the density of (c) and (d) follows.
\end{proof}




\begin{thm}\label{lb85}
Let $1\leq p<+\infty$. Let $\mu$ be a Radon measure (or its completion) on a second countable LCH space $X$. Then $L^p(X,\mu,\Fbb)$ is separable.
\end{thm}


\begin{proof}
See \cite[Sec. 27.2]{Gui-A}.
\end{proof}






\subsubsection{Complex Radon measures}


\begin{df}
If $X$ is a set and $\fk M\subset 2^X$ is a $\sigma$-algebra, a \textbf{complex measure} \index{00@Complex measure} (resp. \textbf{signed measure}) \index{00@Signed measure} is a function $\fk M\rightarrow \Cbb$ (resp. $\fk M\rightarrow\Rbb$) that can be written as a $\Cbb$-linear (resp. $\Rbb$-linear) combination of finite measures on $\fk M$.
\end{df}



We now assume that $X$ is LCH. 

\begin{df}
A complex (resp. signed) measure on $\fk B_X$ is called \textbf{Radon} if it is a $\Cbb$-linear (resp. $\Rbb$-linear) combination of finite Radon measures. 
\end{df}

Suppose that $\mu$ is a complex Radon measure on $X$. Then similar to the proof of Rem. \ref{lb12}, for each $f\in C_0(X)$, we can extend the $\Rbb_{\geq0}$-linear functional $f\mapsto\int_X fd\mu$, where $\mu$ are finite Radon measures, to $\mu\mapsto \int_X fd\mu$ for all complex Radon measures $\mu$. This gives a $\Cbb$-bilinear map
\begin{align*}
(f,\mu)\mapsto\int_X fd\mu\qquad\in\Cbb
\end{align*}
for $f\in C_0(X)$ and complex Radon measures $\mu$.



\begin{thm}[\textbf{Riesz-Markov representation theorem}] \index{00@Riesz-Markov representation theorem}\label{lb8}
Let $\Fbb=\Cbb$ (resp. $\Fbb=\Rbb$.) Then the elements of $C_c(X,\Fbb)^*$ are precisely linear functionals
\begin{align*}
\Lambda:C_c(X,\Fbb)\rightarrow\Fbb \qquad f\mapsto \int_X fd\mu
\end{align*}
where $\mu$ is complex (resp. signed) Radon measure on $X$.
\end{thm}




\begin{proof}
It suffices to assume that $\Lambda$ is real, i.e., sending $C_c(X,\Rbb)$ into $\Rbb$. Similar to the proof of Thm. \ref{lb13}, one writes $\Lambda=\Lambda^+-\Lambda^-$ where $\Lambda^\pm$ are positive. Then apply Thm. \ref{lb7} to $\Lambda^\pm$. See \cite[Subsec. 25.10.2]{Gui-A} for details.
\end{proof}




\begin{rem}
Since $C_c(X,\Fbb)$ is $l^\infty$-dense in $C_0(X,\Fbb)$, by Cor. \ref{lb44}, the dual spaces $C_c(X,\Fbb)^*$ and $C_0(X,\Fbb)^*$ are canonically identified. Therefore, Thm. \ref{lb8} holds verbatim if $C_c(X,\Fbb)$ is replaced by $C_0(X,\Fbb)$.  
\end{rem}


\begin{comment}
\begin{df}
Let $\mu$ be a complex Radon measure on $X$. Let $\Lambda\in C_c(X,\Fbb)^*=C_0(X,\Fbb)^*$ be the linear functional corresponding to $\mu$ as in Thm. \ref{lb8}. The \textbf{total variation} \pmb{$\Vert\mu\Vert$} \index{00@Total variation $\Vert\mu\Vert$} \index{zz@$\Vert\mu\Vert$, the total variation} is defined to be the operator norm of $\Lambda$, i.e.,
\begin{align*}
\Vert\mu\Vert=\Vert\Lambda\Vert=\sup_{f\in \ovl B_{C_c(X)}(0,1)}|\Lambda(f)|=\sup_{f\in \ovl B_{C_0(X)}(0,1)}|\Lambda(f)|
\end{align*}
\end{df}
\end{comment}



\subsection{Basic facts about increasing functions}\label{lb88}

\subsubsection{Notation}\label{lb89}

If $I\subset\Rbb$ is a proper interval, a function $\rho:I\rightarrow\Rbb$ is called \textbf{increasing} if it is non-decreasing, i.e., $\rho(x)\leq \rho(y)$ whenever $x,y\in I$ and $x\leq y$. For each $t\in\Rbb$, let
\begin{align*}
I_{\leq t}=I\cap (-\infty,t]\quad I_{<t}=I\cap (-\infty,t)\quad I_{\geq t}=I\cap [t,+\infty)\quad I_{>t}=I\cap (t,+\infty)
\end{align*}

Suppose that $a=\inf I$ and $b=\sup I$. Let $\rho:I\rightarrow \Rbb$ be increasing. If $x\in(a,b)$, then the left and right limits\footnote{When taking the limit $\lim_{y\rightarrow x^\pm}$, we do not allow $y$ to be equal to $x$.}
\begin{align}
\rho(x^-)=\lim_{y\rightarrow x^-}\rho(y)\qquad \rho(x^+)=\lim_{y\rightarrow x^+}\rho(y)
\end{align}
exist, and
\begin{align*}
\rho(x^-)\leq \rho(x)\leq \rho(x^+)
\end{align*}
If $a\in I$, then $\rho(a^+)$ exists, and $\rho(a)\leq \rho(a^+)$. If $b\in I$, then $\rho(b^-)$ exists, and $\rho(b^-)\leq \rho(b)$. Let
\begin{align*}
\Omega_\rho=\{x\in (a,b):\rho|_{(a,b)}\text{ is continuous at }x\}
\end{align*}
Then for each $x\in (a,b)$, we have
\begin{gather}\label{eq38}
\begin{gathered}
x\in\Omega_\rho\quad\Leftrightarrow\quad \rho(x^-)=\rho(x^+) \quad\Leftrightarrow\quad \rho(x^-)=\rho(x)=\rho(x^+)
\end{gathered}
\end{gather}


\subsubsection{Basic properties of increasing functions}

Let $I\subset\Rbb$ be a proper interval with $a=\inf I,b=\sup I$.

\begin{pp}\label{lb62}
If $\rho:I\rightarrow\Rbb$ is increasing, then $I\setminus\Omega_\rho$ is countable.
\end{pp}

\begin{proof}
Replacing $\rho$ with $\arctan\circ\rho$, we may assume that $\rho$ is bounded. Let $C=\diam(\rho(I))=\sup_{x,y\in I}|\rho(x)-\rho(y)|$. Let $A=(a,b)\setminus\Omega_\rho$. Then for each $B\in\fin(2^A)$, we have
\begin{align*}
\sum_{x\in B}(\rho(x^+)-\rho(x^-))\leq C
\end{align*}
Applying $\lim_B$, we get $\sum_{x\in A}(\rho(x^+)-\rho(x^-))\leq C<+\infty$. Therefore $A$ is countable.
\end{proof}


\begin{df}
Let $\rho:I\rightarrow\Rbb$. The \textbf{right-continuous normalization} \index{00@Right-continuous normalization} of $\rho$ is the function $\wtd\rho:I\rightarrow \Rbb$ defined by
\begin{gather*}
\wtd\rho(x)=\left\{
\begin{array}{ll}
\rho(x^+)&\text{if }x<b\\[0.5ex]
\rho(b)&\text{if }x=b
\end{array}
\right.
\end{gather*}
The function $\wtd\rho$ is clearly increasing and right-continuous. Moreover, $\wtd\rho$ clearly agrees with $\rho$ on $\Omega_\rho$. Therefore, $\wtd\rho$ and $\rho$ are almost equal, as defined by the following proposition.
\end{df}



\begin{pp}\label{lb70}
Let $\rho_1,\rho_2:I\rightarrow\Rbb$ be increasing. Then the following are equivalent:
\begin{enumerate}[label=(\alph*)]
\item There exists a dense subset $E\subset I$ such that $\rho_1|_E=\rho_2|_E$.
\item $\Omega_{\rho_1}=\Omega_{\rho_2}$, and $\rho_1|_{\Omega_{\rho_1}}=\rho_2|_{\Omega_{\rho_2}}$.
\item The right-continuous normalizations of $\rho_1$ and $\rho_2$ agree on $I_{<b}$.
\end{enumerate}
If any of these statements are true, we say that $\rho_1,\rho_2$ are \textbf{almost equal}. \index{00@Almost equal increasing functions}
\end{pp}


\begin{proof}
(a)$\Rightarrow$(b): Assume (a). Choose any $x\in I$. If $x>a$ then
\begin{subequations}\label{eq40}
\begin{align}\label{eq40a}
\rho_1(x^-)=\lim_{E\ni y\rightarrow x^-}\rho_1(y)=\lim_{E\ni y\rightarrow x^-}\rho_2(y)=\rho_2(x^-)
\end{align}
Similarly, if $x<b$ then
\begin{align}\label{eq40b}
\rho_1(x^+)=\rho_2(x^+)
\end{align}
\end{subequations}
Thus (b) follows from \eqref{eq38}.\\[-1ex]

(b)$\Rightarrow$(a): By Prop. \ref{lb62}, $E:=(a,b)\cap\Omega_{\rho_1}$ is a dense subset of $(a,b)$.\\[-1ex]

(b)$\Leftrightarrow$(c): Let $\wtd\rho_i$ be the right continuous normalization of $\rho_i$. Then by (a)$\Rightarrow$(b), we have $\Omega_{\rho_i}=\Omega_{\wtd\rho_i}$ and $\rho_i|_{\Omega_{\rho_i}}=\wtd\rho_i|_{\Omega_{\wtd\rho_i}}$. Therefore, (b) holds iff
\begin{align}\label{eq39}
\Omega_{\wtd\rho_1}=\Omega_{\wtd\rho_2}\qquad \text{and}\qquad \wtd\rho_1|_{\Omega_{\wtd\rho_1} }=\wtd\rho_2|_{\Omega_{\wtd\rho_2} }
\end{align}
Clearly (c) implies \eqref{eq39}. Suppose that \eqref{eq39} is true. Then for each $x\in I_{<b}$ we have
\begin{align*}
\wtd\rho_1(x)=\wtd\rho_1(x^+)\xlongequal{\eqref{eq40b}}\wtd\rho_2(x^+)=\wtd\rho_2(x)
\end{align*}
Thus \eqref{eq39} implies (c). Therefore (b) and (c) are equivalent.
\end{proof}






\subsection{The Stieltjes integral}


\subsubsection{Definitions and basic properties}

In this subsection, we fix a proper interval $I\subset\Rbb$, and let $\rho:I\rightarrow\Rbb_{\geq0}$ be an increasing function.



\begin{df}
Let $J$ be any proper bounded interval. Let $a=\inf J,b=\sup J$. A \textbf{partition} \index{00@Partition of an interval} of the interval $J$ is defined to be an element of the form
\begin{align}
\sigma=\{a_0,a_1,\dots,a_n\in [a,b]:a_0=a<a_1<a_2<\cdots<a_n=b,n\in\Zbb_+\}
\end{align}
The \textbf{mesh} \index{00@Mesh} of $\sigma$ is defined to be
\begin{align*}
\max\{a_i-a_{i=1}:i=1,\dots,n\}
\end{align*}
If $\sigma,\sigma'\in \fin(2^J)$ are partitions of $J$, we say that $\sigma'$ is a \textbf{refinement} \index{00@Refinement of a partition} \index{00@Finer partition} of $\sigma$ (or that $\sigma'$ is \textbf{finer than} $\sigma$), if $\sigma\subset\sigma'$. In this case, we also write  \index{zz@$\sigma\prec\sigma'$} 
\begin{align*}
\sigma\prec\sigma'
\end{align*}
We define $\mc P(J)$ to be\index{PI@$\mc P(I)$, the set of partitions of the bounded interval $I$}
\begin{align*}
\mc P(J)=\{\text{partitions of $J$}\}
\end{align*}
\end{df}


\begin{rem}
If $\sigma,\sigma'\in\mc P(J)$, then clearly $\sigma\cup\sigma'\in\mc P(J)$ and $\sigma,\sigma'\prec \sigma\cup\sigma$. Therefore, $\prec$ is a partial order on $\mc P(J)$. We call $\sigma\cup\sigma'$ the \textbf{common refinement} \index{00@Common refinement} of $\sigma$ and $\sigma'$.
\end{rem}


\begin{df}
A \textbf{tagged partition} \index{00@Tagged partition} of $I$ is an ordered pair
\begin{align}\label{eq41}
(\sigma,\xi_\blt)=\big(\{a_0=a<a_1<\cdots<a_n=b\},(\xi_1,\dots,\xi_n) \big)
\end{align}
where $\sigma\in\mc P(J)$ and 
\begin{align*}
\xi_i\in(a_{j-1},a_j]
\end{align*}
for all $1\leq j\leq n$. The set\index{QI@$\mc Q(I)$, the directed set of tagged partitions}
\begin{align*}
\mc Q(J)=\{\text{tagged partitions of $J$}\}
\end{align*}
equipped with the preorder $\prec$ defined by
\begin{align}
(\sigma,\xi_\blt)\prec(\sigma',\xi_\blt')\qquad\Longleftrightarrow\qquad \sigma\subset\sigma'
\end{align}
is a directed set.
\end{df}



\begin{df}\label{lb66}
Let $V$ be a Banach space. Assume $[a,b]\subset I$ and $a<b$. Let $f\in C([a,b],V)$. For each $(\sigma,\xi_\blt)\in\mc Q(I)$, define the \textbf{Stieltjes sum}\index{00@Stieltjes sum} \index{Sf@$S_\rho(f,\sigma,\xi_\blt)$}
\begin{align*}
S_\rho(f,\sigma,\xi_\blt)=\sum_{j\geq 1}f(\xi_j)\big(\rho(a_j)-\rho(a_{j-1})\big)
\end{align*}
abbreviated to $S(f,\sigma,\xi_\blt)$ when no confusion arises. The \textbf{Stieltjes integral} \index{00@Stieltjes integral} on $(a,b]$ is defined to be the limit of the net $(S_\rho(f,\sigma,\xi_\blt))_{(\sigma,\xi_\blt)\in\mc Q([a,b])}$:
\begin{align}\label{eq1}
\int_{(a,b]} fd\rho=\lim_{(\sigma,\xi_\blt)\in\mc Q(I)}S_\rho(f,\sigma,\xi_\blt)
\end{align}
The \textbf{Stieltjes integral} on $[a,b]$ is defined to be
\begin{align}
\int_{[a,b]}fd\rho=f(a)\rho(a)+\int_{(a,b]}fd\rho
\end{align}
\end{df}


Note that when $f(a)\neq0$, the integral $\int_{(a,b]}fd\rho$ depends not only on $\rho|_{(a,b]}$ but also on the value $\rho(a)$. On the other hand, it is clear that
\begin{gather}
\int_{(a,b]}fd\rho=\int_{(a,b]}fd\rho|_{[a,b]}\qquad \int_{[a,b]}fd\rho=\int_{[a,b]}fd\rho|_{[a,b]}
\end{gather}


\begin{proof}[Proof of the convergence of \eqref{eq1}]
Since $f$ is uniformly continuous, for each $\eps>0$, there exists $\delta>0$ such that $\Vert f(x)-f(y)\Vert\leq\eps$ for all $x,y\in[a,b]$ and $|x-y|\leq\delta$. Choose any tagged partition $(\sigma,\xi_\blt)$ of $[a,b]$ with mesh $\leq\delta$. Then one easily sees that for any $(\sigma',\xi_\blt')\succ(\sigma,\xi)$ we have
\begin{align*}
\Vert S(f,\sigma',\xi_\blt')-S(f,\sigma,\xi_\blt)\Vert\leq \eps(\rho(b)-\rho(a))
\end{align*}
Therefore, the net $(S(f,\sigma,\xi_\blt))_{(\sigma,\xi_\blt)\in\mc Q(I)}$ is Cauchy. So it must converge because $V$ is complete.
\end{proof}

\begin{rem}\label{lb63}
The above proof implies the following useful fact: Let $f\in[a,b]$. Let $\eps,\delta>0$ such that $\Vert f(x)-f(y)\Vert\leq\eps$ for all $x,y\in[a,b]$ satisfying $|x-y|\leq\delta$. Then for each tagged partition $(\sigma,\xi_\blt)$ of $[a,b]$ with mesh $\leq\delta$, we have
\begin{align}
\Big\Vert \int_{(a,b]}fd\rho-S_\rho(f,\sigma,\xi_\blt)\Big\Vert\leq \eps(\rho(b)-\rho(a))
\end{align}
and hence
\begin{align}
\Big\Vert \int_{[a,b]}fd\rho-f(a)\rho(a)-S_\rho(f,\sigma,\xi_\blt)\Big\Vert\leq \eps(\rho(b)-\rho(a))
\end{align}
\end{rem}


\begin{eg}\label{lb71}
The integrals of the constant function $1$ are
\begin{align*}
\int_{(a,b]}d\rho=\rho(b)-\rho(a)\qquad \int_{[a,b]}d\rho=\rho(b)
\end{align*}
\end{eg}

\begin{eg}\label{lb68}
Suppose that $\rho|_{(a,b]}=1$. Then
\begin{align*}
\int_{(a,b]}fd\rho=f(a)(1-\rho(a))\qquad \int_{[a,b]}fd\rho=f(a)
\end{align*}
In particular, if $\rho|_{[a,b]}=1$, then $\dps\int_{(a,b]}fd\rho=0$ and $\dps\int_{[a,b]}fd\rho=f(a)$.
\end{eg}





\begin{rem}\label{lb65}
It is easy to see that 
\begin{align*}
\Lambda:C([a,b],V)\rightarrow V\qquad f\mapsto \int_{[a,b]}fd\rho
\end{align*}
is linear. Moreover, since $\Vert S(f,\sigma,\xi_\blt)\Vert\leq (\rho(b)-\rho(a))\Vert f\Vert_{l^\infty}$ and hence $\Vert f(a)\rho(a)+ S(f,\sigma,\xi_\blt)\Vert\leq \rho(b)\Vert f\Vert_{l^\infty}$, the operator norm $\Vert\Lambda\Vert$ satisfies $\Vert\Lambda\Vert\leq \rho(b)$, that is
\begin{align*}
\Big\Vert\int_{[a,b]}fd\rho\Big\Vert\leq \rho(b)\Vert f\Vert_{l^\infty}\qquad\text{for all }f\in C([a,b],V)
\end{align*}
In particular, $\Lambda$ is bounded.
\end{rem}

\begin{rem}\label{lb6}
It is easy to check that $\rho\mapsto\int_{(a,b]} fd\rho$ and $\rho\mapsto\int_{[a,b]} fd\rho$ are $\Rbb_{\geq0}$-linear over increasing functions $\rho:[a,b]\rightarrow\Rbb_{\geq0}$. Moreover, if $c\in(a,b)$, one easily shows
\begin{align}
\int_{(a,b]}fd\rho=\int_{(a,c]}fd\rho+\int_{(c,b]}fd\rho
\end{align}
by considering tagged partitions finer than $\{a,c,b\}$.
\end{rem}


Exp. \ref{lb68} suggests that the value of $\int_{[a,b]}fd\rho$ is independent of $\rho(a)$:

\begin{lm}\label{lb69}
Suppose that $\rho_1,\rho_2:[a,b]\rightarrow\Rbb_{\geq0}$ are increasing and satisfies $\rho_1|_{(a,b]}=\rho_2|_{(a,b]}$. Then for each $f\in C([a,b],V)$ we have $\dps\int_{[a,b]}fd\rho_1=\int_{[a,b]}fd\rho_2$.
\end{lm}

See Thm. \ref{lb67} for a generalization of this lemma.

\begin{proof}
Assume WLOG that $\rho_1(a)\leq\rho_2(a)$. Let $\lambda=\rho_2(a)-\rho_1(a)$. Then $\rho_2-\rho_1=\lambda\cdot\chi_{\{a\}}=\lambda\cdot (1-\chi_{(a,b]})$, and hence $\rho_1+\lambda=\rho_2+\lambda\cdot\chi_{(a,b]}$. By Rem. \ref{lb6},
\begin{align*}
\int_{[a,b]}fd\rho_1+\lambda\int_{[a,b]} fd1=\int_{[a,b]}fd\rho_2+\lambda\int_{[a,b]} fd\chi_{(a,b]}
\end{align*}
By Exp. \ref{lb6}, we obtain $\int_{[a,b]}fd\rho_1=\int_{[a,b]}fd\rho_2$.
\end{proof}



\begin{comment}
\begin{rem}
The Stieltjes integral can be defined on unbounded intervals. For example, if $\rho:[a,+\infty)\rightarrow\Rbb$ is \textit{bounded} and increasing, for $f\in C_0([a,+\infty),V)$, we define
\begin{align*}
\int_{[a,+\infty)} fd\rho=\lim_{\lambda\rightarrow+\infty}\int_{[a,\lambda]} fd\rho
\end{align*}
where the RHS converges. Similarly, we can define $\int_{-\infty}^{+\infty}fd\rho$ for bounded increasing $\rho:\Rbb\rightarrow\Rbb$ and $f\in C_0(\Rbb,V)$.
\end{rem}
\end{comment}





\subsubsection{Dependence of the Stieltjes integral on $\rho$}


Let $I\subset\Rbb$ be a proper interval, and let $a=\inf I$ and $b=\sup I$. Note that $I$ is not assumed to be bounded. 

\begin{df}
For each $f\in C_c(I,V)$ and each increasing $\rho:I\rightarrow\Rbb$, we can still define the \textbf{Stieltjes integral} \index{00@Stieltjes integral}
\begin{align*}
\int_I fd\rho:=\int_Jfd\rho
\end{align*}
where $J$ is any compact sub-interval of $I$ containing $\Supp_I(f)$. The value of the integral is clearly independent of the choice of such $J$. Moreover, this definition is compatible with the definitions of $\int_{[a,b]}fd\rho$ and $\int_{(a,b]}fd\rho$ in Def. \ref{lb66}.
\end{df}


\begin{thm}\label{lb67}
Let $\rho_1,\rho_2:I\rightarrow\Rbb_{\geq0}$ be increasing functions satisfying the following condition:
\begin{itemize}
\item $\rho_1$ and $\rho_2$ are almost equal, and $\rho_1(b)=\rho_2(b)$ if $b\in I$. (By Prop. \ref{lb70}, this is equivalent to that $\rho_1,\rho_2$ have the same right-continuous normalization.)
\end{itemize}
Then for each $f\in C_c(I,V)$, we have
\begin{align*}
\int_I fd\rho_1=\int_I fd\rho_2
\end{align*}
\end{thm}



\begin{proof}
By Lem. \ref{lb69}, we may assume that $\rho_1(a)=\rho_2(a)$ if $a\in I$. 

Fix $f\in C_c(I,V)$. Choose $\alpha,\beta\in\Rbb$ satisfying $\Supp_I(f)\subset[\alpha,\beta]\subset I$. Due to the assumption on $\rho_1,\rho_2$, we may slightly enlarge the compact interval $J:=[\alpha,\beta]$ so that
\begin{align*}
\rho_1(\alpha)=\rho_2(\alpha)\qquad \rho_1(\beta)=\rho_2(\beta)
\end{align*}
(When $a\in I$ resp. $b\in I$, one can even set $\alpha=a$ resp. $\beta=b$.) Then $\int_I fd\rho_i=\int_J fd\rho_i$.


Let $C=\max\{\rho_i(\beta)-\rho_i(\alpha):i=1,2\}$. Choose any $\eps>0$. Since $f$ is uniformly continuous, there exists $\delta>0$ such that $|f(x)-f(y)|\leq\eps$ whenever $x,y\in I$ and $|x-y|\leq\delta$. Choose a tagged partition
\begin{align*}
(\sigma,\xi_\blt)=\big(\{a_0=\alpha<a_1<\cdots<a_n=\beta\},(\xi_1,\dots,\xi_n) \big)
\end{align*}
of $J$ with mesh $<\delta$. Moreover, due to the assumption on $\rho_1,\rho_2$, by a slight adjustment, we may assume that $\rho_1(a_j)=\rho_2(a_j)$ for each $0\leq j\leq n$. This implies
\begin{align*}
S_{\rho_1}(f,\sigma,\xi_\blt)=S_{\rho_2}(f,\sigma,\xi_\blt)
\end{align*}
Therefore, by Rem. \ref{lb63}, we obtain
\begin{align*}
\Big\Vert \int_J fd\rho_1-\int_J fd\rho_2\big\Vert\leq 2\eps\cdot C
\end{align*}
This completes the proof by choosing arbitrary $\eps$.
\end{proof}


\begin{thm}\label{lb72}
Let $\rho_1,\rho_2:I\rightarrow\Rbb_{\geq0}$ be \uwave{bounded} increasing functions satisfying
\begin{gather}\label{eq48}
\begin{gathered}
%\lim_{x\rightarrow a^+}\rho_1(x)=\lim_{x\rightarrow a^+}\rho_2(x)\qquad\text{if}\qquad a\in I\\
\lim_{x\rightarrow a^+}\rho_1(x)=\lim_{x\rightarrow a^+}\rho_2(x)=0\qquad\text{if }a\notin I
\end{gathered}
\end{gather}
Then the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $\rho_1$ and $\rho_2$ are almost equal, and $\rho_1(b)=\rho_2(b)$ if $b\in I$. (By Prop. \ref{lb70}, this is equivalent to that $\rho_1,\rho_2$ have the same right-continuous normalization.)
\item For each $f\in C_c(I,\Fbb)$ we have
\begin{align*}
\int_I fd\rho_1=\int_I fd\rho_2
\end{align*}
\end{enumerate}
\end{thm}


\begin{proof}
By Thm. \ref{lb67}, we have ``(1)$\Rightarrow$(2)". Assume (2). Let us prove (1). Let $\wtd\rho_i$ be the right-normalization of $\rho_i$. By ``(1)$\Rightarrow$(2)", we have $\int_I fd\rho_i=\int_I fd\wtd\rho_i$. Therefore, to prove (1), it suffices to assume that $\rho_1$ and $\rho_2$ are right-continuous on $I$.

We shall prove (1) by choosing an arbitrary bounded increasing right-continuous $\rho:I\rightarrow\Rbb_{\geq0}$, and show that for each $x\in I$, the value $\rho(x)$ can be recovered from the integrals $\int_Ifd\rho$ where $f\in C_c(I,\Rbb)$.

Case 1: Assume $a\notin I$ and $a<x<b$. For each real numbers $v,y$ satisfying
\begin{align*}
a<v<x<y<b
\end{align*}
choose $\varphi_{v,y}\in C_c(I,[0,1])$ satisfying
\begin{align*}
\chi_{[v,x]}\leq\varphi_{v,y}\leq \chi_{(a,y]}
\end{align*}
Choose $u\in(a,v)$ such that $\varphi_{v,y}$ vanishes outside $[u,y]$. Then by Rem. \ref{lb6},
\begin{align*}
&\int_I\varphi_{v,y}d\rho=\int_{[u,y]}\varphi_{v,y}d\rho=\varphi_{v,y}(u)+\int_{(u,v]}\varphi_{v,y}d\rho+\int_{(v,x]}\varphi_{v,y}d\rho+\int_{(x,y]}\varphi_{v,y}d\rho\\
=&\int_{(u,v]}\varphi_{v,y}d\rho+\rho(x)-\rho(v)+\int_{(x,y]}\varphi_{v,y}d\rho
\end{align*}
where Exp. \ref{lb71} is used in the last equality. By Rem. \ref{lb63}, we have $\int_{(u,v]}\varphi_{v,y}d\rho\leq \rho(v)-\rho(u)\leq\rho(v)$ and $\int_{(x,y]}\varphi_{v,y}d\rho\leq (\rho(y)-\rho(x))$. Since $\rho$ is right-continuous and satisfies \eqref{eq48}, we have
\begin{align*}
\lim_{v\searrow a^+}\rho(v)=\lim_{y\searrow x^+}(\rho(y)-\rho(x))=0
\end{align*}
Therefore, the above calculation of $\int_I\varphi_{v,y}d\rho$ shows
\begin{align*}
\lim_{
\begin{subarray}{c}
v\searrow a^+\\
y\searrow x^+
\end{subarray}}
\int_I \varphi_{v,y}d\rho=\lim_{v\searrow a^+}(\rho(x)-\rho(v))=\rho(x)
\end{align*}



Case 2: Assume $a\in I$ and $a\leq x<b$. For each $y\in(x,b)$, choose $\varphi_y\in C_c(I,[0,1])$ such that $\chi_{[a,x]}\leq\varphi_y\leq\chi_{[a,y]}$. Similar to the argument in Case 1, one shows
\begin{align*}
\int_I\varphi_yd\rho=\int_{[a,x]}\varphi_yd\rho+\int_{(x,y]}\varphi_yd\rho=\rho(x)+\int_{(x,y]}\varphi_yd\rho
\end{align*}
where Exp. \ref{lb71} is used. By Rem. \ref{lb63}, $\int_{(x,y]}\varphi_yd\rho\leq \rho(y)-\rho(x)$. Therefore, the right-continuity of $\rho$ implies
\begin{align*}
\lim_{y\searrow x^+}\int_I \varphi_yd\rho=\rho(x)
\end{align*}


Case 3: Assume $I=(a,b]$ and $x=b$.  For each $v\in(a,x)$, choose $\varphi_v\in C_c(I,[0,1])$ such that $\chi_{[v,b]}\leq \varphi_v\leq \chi_I$. Similar to the argument above,
\begin{align*}
\lim_{v\searrow a^+}\int_I\varphi_vd\rho=\rho(b)
\end{align*}

Case 4: Assume $I=[a,b]$ and $x=b$. Then $\dps\int_I d\rho=\rho(b)$.
\end{proof}


\begin{rem}\label{lb93}
The assumption \eqref{eq48} imposes little restriction. Indeed, suppose $a\notin I$. Then for each $f\in C_c(I)$, since there exists $v\in\Rbb_{>a}$ such that $f$ vanishes on $(a,v]$, for any constant $\varkappa\in\Rbb$ with $\rho+\varkappa\geq0$, we clearly have
\begin{align}
\int_I fd\rho=\int_I fd(\rho+\varkappa)
\end{align}
Therefore, when $a\notin I$, given any two increasing functions $\rho_1,\rho_2:I\rightarrow\Rbb_{\geq0}$, we can freely add constants to $\rho_1$ and $\rho_2$ to ensure that \eqref{eq48} holds.
\end{rem}



\subsection{The Riesz representation theorem via the Stieltjes integral}

In this section, we fix a proper interval $I\subset\Rbb$, and let $a=\inf I$ and $b=\sup I$.

\subsubsection{The positive case}




\begin{thm}[\textbf{Riesz representation theorem}]\label{lb9}
We have a bijection between:
\begin{enumerate}[label=(\alph*)]
\item A bounded increasing right-continuous function $\rho:I\rightarrow\Rbb_{\geq0}$ satisfying $\lim_{x\rightarrow a^+}\rho(a)=0$ if $a\notin I$.
\item A bounded positive linear functional $\Lambda:C_c(I,\Fbb)\rightarrow\Fbb$.
\end{enumerate}
$\Lambda$ is determined by $\rho$ by
\begin{align}\label{eq43}
\Lambda:C(I,\Fbb)\rightarrow\Fbb\qquad f\mapsto\int_I fd\rho
\end{align}
$\rho$ is determined by $\Lambda$ by 
\begin{align}\label{eq42}
\rho(x)=\mu(I_{\leq x})\qquad\text{for all }x\in I
\end{align}
where $\mu$ is the finite Borel measure on $I$ associated to $\Lambda$ as in the Riesz-Markov representation Thm. \ref{lb7}. 
\end{thm}

Note that by Thm. \ref{lb64}, finite Borel measures on $I$ and finite Radon measures on $I$ coincide.


\begin{proof}
Step 1. Thm. \ref{lb7} establishes the equivalence between a bounded positive linear $\Lambda$ and a finite Borel measure $\mu$. We let prove the equivalence between the radon measures $\mu$ and the functions $\rho$ satisfying (a).

More precisely, given a Radon measure $\mu$ on $I$, let $\rho_\mu:I\rightarrow\Rbb_{\geq0}$ be defined by \eqref{eq42}, that is, for each $x\in I$ we have 
\begin{align}
\rho_\mu(x)=\mu(I_{\leq x})
\end{align}
Then $\rho_\mu$ is clearly bounded and increasing. By DCT,  $\rho_\mu$ is right-continuous, and we have $\lim_{x\rightarrow a^-}\rho(x)=0$ when $a\notin I$. Therefore, $\rho_\mu$ satisfies (a). 

Conversely, given any $\rho$ satisfying (a), let $\mu_\rho$ be the unique Radon measure corresponding to $\rho$ via \eqref{eq43}, i.e., for each $f\in C_c(I,\Fbb)$ we have
\begin{align}\label{eq46}
\int_I f d\mu_\rho=\int_I fd\rho
\end{align}
By Rem. \ref{lb65}, the linear functional $f\in C_c(I,\Fbb)\mapsto \int_Ifd\rho$ is bounded with operator norm $\leq\sup_{x\in I}\rho(x)$. Thus, $\mu_\rho$ is a finite measure.

We want to show that $\Phi:\rho\mapsto\mu_\rho$ and $\Psi:\mu\mapsto\rho_\mu$ are inverses of each other. By Thm. \ref{lb72}, the map $\Phi$ is injective. Therefore, it suffices to prove that $\Phi\circ\Psi=\id$, i.e., that $\mu_{\rho_\mu}=\mu$. This means proving
\begin{align}\label{eq45}
\int_I fd\mu=\int_Ifd\rho_\mu
\end{align}
for each $f\in C_c(I,\Fbb)$. \\[-1ex]

Step 2.  Let us fix $f\in C_c(I,\Fbb)$ and prove \eqref{eq45}. Choose $\alpha,\beta\in\Rbb$ such that $J:=[\alpha,\beta]$ is a sub-interval of $I$ containing $\Supp_I(f)$. Choose any $\eps>0$. Since $f$ is uniformly continuous, there exists $\delta>0$ such that $|f(x)-f(y)|\leq\eps$ whenever $x,y\in I$ and $|x-y|\leq\delta$. Choose a tagged partition
\begin{align*}
(\sigma,\xi_\blt)=\big(\{a_0=\alpha<a_1<\cdots<a_n=\beta\},(\xi_1,\dots,\xi_n) \big)
\end{align*}
of $J$ with mesh $\leq\delta$. By Rem. \ref{lb63}, we have
\begin{align}\label{eq44}
\Big| \int_Jfd\rho_\mu-f(\alpha)\rho_\mu(\alpha)-S_{\rho_\mu}(f,\sigma,\xi_\blt)\Big|\leq \eps(\rho_\mu(\beta)-\rho_\mu(\alpha))=\eps\cdot\mu((\alpha,\beta])
\end{align}


Also, we have $\Vert f-g\Vert_{l^\infty(I)}\leq\eps$ where
\begin{align*}
g=f(\alpha)\chi_{\{a\}}+\sum_{i=1}^n f(\xi_i)\chi_{(a_{i-1},a_i]}
\end{align*}
By \eqref{eq42}, we have
\begin{align*}
\mu(\{\alpha\})=\rho_\mu(\alpha)-\mu(I_{<\alpha})\qquad \mu((a_{i-1},a_i])=\rho_\mu(a_i)-\rho_\mu(a_{i-1})
\end{align*}
Note that if $f(\alpha)\neq 0$, then by $\Supp_I(f)\subset[\alpha,\beta]$, we must have $\alpha=a\in I$ and hence $I_{<\alpha}=\emptyset$. Therefore, we must have
\begin{align*}
\int_I gd\mu=f(\alpha)\rho_\mu(\alpha)+ S_{\rho_\mu}(f,\sigma,\xi_\blt)
\end{align*}
Combining this fact with $\Vert f-g\Vert_{l^\infty(I)}\leq\eps$, we get
\begin{align*}
\Big| \int_I fd\mu-f(\alpha)\rho_\mu(\alpha)-S_{\rho_\mu}(f,\mu,\xi_\blt)\Big|\leq \eps\cdot\mu(J)
\end{align*}
This inequality, together with \eqref{eq44}, implies
\begin{align*}
\Big| \int_I fd\mu-\int_I fd\rho_\mu\Big|\leq 2\eps\cdot\mu(J)
\end{align*}
Since $\eps$ is arbitrary, we conclude \eqref{eq45}.
\end{proof}







\begin{comment}
\begin{rem}
There is a bijection between:
\begin{itemize}
\item An increasing right-continuous function $\rho:(a,b]\rightarrow\Rbb_{\geq0}$.
\item An increasing right-continuous function $\varrho:[a,b]\rightarrow\Rbb_{\geq0}$.
\end{itemize}
They are related by
\begin{align}
\rho=\varrho|_{(a,b]}
\end{align}
Equivalently, viewing $\rho$ as a function on $[a,b]$ (cf. Conv. \ref{lb10}),
\begin{align}
\rho=\varrho-\varrho(a)\cdot\chi_{\{a\}}\qquad 
\end{align}
Since $\rho=\varrho-\varrho(a)+\varrho(a)\chi_{(a,b]}$ and $\int_a^b fd\chi_{(a,b]}=f(a)$, by Rem. \ref{lb6}, we have
\begin{align}
\int_a^b fd\rho=f(a)\varrho(a)+\int_a^bfd\varrho
\end{align}
These relations allow us to convert the setting of \cite[Sec. 25.7]{Gui-A}, which uses $\varrho$ to present the Riesz representation theorem, to the current setting.
\end{rem}
\end{comment}


\subsubsection{The general case}


\begin{df}
 A real-valued function $I\rightarrow\Fbb$ is called of \textbf{bounded variation} (or simply \textbf{BV}) \index{BV@BV=bounded variation} if it is an $\Fbb$-linear combination of bounded increasing functions $I\rightarrow\Rbb_{\geq0}$. The space of BV functions from $I$ to $\Fbb$ is denoted by $BV(I,\Fbb)$. \index{BV@$BV(I,\Fbb)$}
\end{df}

\begin{rem}
By Rem. \ref{lb65} and \ref{lb6}, we have an $\Rbb_{\geq0}$-bilinear functional
\begin{align*}
(f,\rho)\mapsto \int_I fd\rho\qquad\in\Rbb_{\geq0}
\end{align*}
for $f\in C_c(I,\Rbb_{\geq0})$ and bounded increasing $\rho:I\rightarrow\Rbb_{\geq0}$. Similar to the proof of Rem. \ref{lb12}, it can be extended to a positive bililinear functional 
\begin{align*}
C_c(I,\Cbb)\times BV(I,\Cbb)\rightarrow\Cbb\qquad (f,\rho)\mapsto \int_I fd\rho
\end{align*}
\end{rem}


\begin{thm}[\textbf{Riesz representation theorem}]\label{lb10}
The elements of the dual space $C_c(I,\Fbb)^*$ are precisely linear functionals of the form
\begin{gather*}
\Lambda:C(I,\Fbb)\rightarrow\Fbb\qquad f\mapsto\int_I fd\rho
\end{gather*}
where $\rho\in BV(I,\Fbb)$. Moreover, the BV function $\rho$ can be chosen such that it is right-continuous on $I$, and that $\lim_{x\rightarrow a^+}\rho(x)=0$ if $a\notin I$.
\end{thm}

\begin{proof}
This is immediate from Thm. \ref{lb8} and \ref{lb9}.
\end{proof}







\newpage


\section{Normed vector spaces and their dual spaces}


\subsection{The origin of dual spaces in the calculus of variations}\label{lb24}



Linear functional analysis treats function spaces as linear spaces with appropriate geometric/topological structures and analytic properties. In the foundational theory of functional analysis, two analytic properties are especially important: (Cauchy) completeness and duality. In this course, our focus is primarily on normed vector spaces $V$. For such spaces, Cauchy completeness is interpreted in the same way as in any metric space. Duality, on the other hand, refers to the natural identification of $V$ as the dual space $V^*$ of another normed vector space $U$.



Many early results in functional analysis were related to duality, while the significance of completeness was not immediately recognized. In fact, the history of functional analysis experienced a paradigm shift from the study of (scalar-valued) functionals to linear maps between vector spaces. Specifically, attention moved from continuous bilinear maps of the form $U \times V \rightarrow \mathbb{F}$ to the analysis of continuous linear maps $V \rightarrow W$, where $U,V,W$ are normed vector spaces. With this shift, completeness became increasingly central to modern analysis. See Sec. \ref{lb43} for further illustrations.




The early part of this course will also focus more on dual spaces. If $V$ is a normed $\Fbb$-vector space, then the \textbf{dual space} $V^*=\fk L(V,\Fbb)$ is defined to be the space of bounded (i.e. continuous) linear maps $V\rightarrow\Fbb$. One of the major themes in early functional analysis was the characterization of dual spaces of various function spaces under appropriate norms. Among the most notable results are F. Riesz's characterization of $C([a,b], \Rbb)^*$ (cf. Thm. \ref{lb10}) in \cite{Rie09, Rie11}, and his proof that $L^q([a,b],m, \Rbb)^* \simeq L^p([a,b],m, \Rbb)$ (cf. Thm. \ref{lb13}) in \cite{Rie10}. These results highlight a profound connection between dual spaces and measure/integration theory. Nevertheless, the study of dual spaces originally arose from a somewhat different field: the calculus of variations in the 19th century.


Consider a nonlinear functional $S:f\mapsto S(f)\in\Rbb$, for example, of the form
\begin{gather*}
S(f)=\int_a^b L(f(t),f'(t),\dots,f^{(r)}(t))dt
\end{gather*}
where $L$ is a ``nice" real valued function with $r$-variables, and $f$ is defined on $[a,b]$. If we perturb $f$ slightly by a variation $\eta$, then the corresponding change in $S$ can be approximated by
\begin{align}\label{eq2}
\delta S[f,\eta]:=S(f+\eta)-S(f)\approx \int_a^b  \beta_f(t)\cdot \eta(t)dt
\end{align}
where $\beta_f:[a,b]\rightarrow\Rbb$ is a function depending on $f$. This function should be interpreted loosely. In some cases, it may involve delta functions or similar objects that are not functions in the classical sense, but rather distributions:


\begin{eg}
Consider the case where $L$ is smooth and $r=1$, i.e.
\begin{align*}
S(f)=\int_a^b L(f(t),f'(t))dt
\end{align*}
(For example, $L(x,y)=T(y)-V(x)$ where $T(y)=\frac 12 my^2$ the kinetic energy for the mass $m\in\Rbb_{>0}$, and $V(x)$ is the potential energy at $x$.) Then
\begin{align*}
&\delta S[f,\eta]=\int_a^b L(f+\eta,f'+\eta')\approx \int_a^b (\partial_x L(f,f')\eta+\partial_y L(f,\eta)\eta')\\
=&\partial_yL(f,f')\eta\big|_a^b+\int_a^b (\partial_xL(f,f')-\partial_t\partial_yL(f,f'))\eta
\end{align*}
If we assume that the function $f$ and its variation $\eta$ always vanish at the endpoints $a,b$, then we obtain \eqref{eq2} with
\begin{align*}
\beta_f(t)=\partial_xL(f(t),f'(t))-\partial_t\partial_yL(f(t),f'(t))
\end{align*}
The equation $\beta_f=0$ is called the \textbf{Euler-Lagrange equation}. 

However, if no boundary conditions are imposed on the endpoints, then the term $\partial_yL(f,f')\eta\big|_a^b$ is not necessarily zero. As a result, we have
\begin{align*}
\beta_f=L(f(b),f'(b))\delta_b-L(f(a),f'(a))\delta_a+\partial_xL(f,f')-\partial_t\partial_y(f,f')
\end{align*}
where, for each $c\in\Rbb$, $\delta_c$ is the ``\textbf{delta function}" \index{00@Delta function $\delta_c$} at $c$, namely, the imaginary function $\Rbb\rightarrow\Rbb_{\geq0}$ vanishing outside $c$ and satisfying $\int_\Rbb\delta_c=1$. The situation becomes even more singular if we define $S$ by
\begin{align*}
S(f)=\sum_{i=1}^n \lambda_i f(c_i)+\int_a^b L(f(t),f'(t))dt
\end{align*} 
where $\lambda_i\in\Rbb$ and $a<c_i<b$, then
\begin{align*}
\beta_f=\sum_{i=1}^n \lambda_i\delta_{c_i}+L(f(b),f'(b))\delta_b-L(f(a),f'(a))\delta_a+\partial_xL(f,f')-\partial_t\partial_y(f,f')
\end{align*}
This raises the question: what should the function $\beta_f$, alternatively the integral operator $\dps\eta\mapsto \int_a^b\beta_f\eta$, actually look like in the general case?  \hfill\qedsymbol
\end{eg}



It is in this context that the problem of classifying bounded linear functionals on $C([a,b],\Rbb)$, originally posed by Hadamard in 1903, should be understood. Recall that if $V,W$ are normed vector spaces, $\Omega\subset V$ is open, and $S:\Omega\rightarrow W$ is a map, one says that $S$ is differentiable at $f\in\Omega$ if 
\begin{align*}
S(f+\eta)-S(f)=\Lambda(\eta)+o(\eta)
\end{align*}
where $\Lambda:V\rightarrow W$ is a bounded linear operator (called the \textbf{differential} of $S$ at $f$), and $\lim_{\Vert\eta\Vert\rightarrow0}o(\eta)/\Vert\eta\Vert=0$. In the calculus of variations, one sets $W=\Fbb$. Then $\Lambda\in V^*$. One can thus understand $\eta\mapsto\delta S[f,\eta]$ as a bounded linear functional on a function space $V$ equipped with a suitable norm.



The problem of expressing $\delta S[f,\eta]$ as an integral involving $\eta$ is therefore transformed to the problem of characterizing the dual space $V^*$. More precisely, the space $V$---and in particular its norm---is not fixed in advance. The situation is not that one starts with a given normed space and is then asked to characterize its dual. Rather, the task is to find an appropriate norm on a suitable function space $V$ such that the bounded linear functionals on $V$, once studied and classified as integrals, are well-suited to capturing the variation of $S$.\footnote{The same function space $V$, when equipped with different norms, leads to different classifications of bounded linear functionals. For example, let $V=C([a,b])$. If the norm is $l^\infty$, then by Thm. \ref{lb10}, the bounded linear functionals are the Stieltjes integrals with respect to BV functions. If the norm is $L^2$, then by Exp. \ref{lb49}, the bounded linear functionals are those of the form $f\mapsto\int fgdm$ where $g\in L^2([a,b],m)$.} \uwave{The two perspectives on $\delta S[f,\eta]$---as a bounded linear functional on $V$, and as an integral involving $\eta$---together offer a deeper and more complete understanding of the variation of $S$.}

More discussion of the relationship between dual spaces and the calculus of variations can be found in \cite{Gray84}.


\subsection{Moment problems: a bridge between integral theory and dual spaces}\label{lb41}




The theory of dual spaces would not have reached its current depth and sophistication if it were developed solely within the framework of the calculus of variations. For instance, Riesz’s classification of the duals of $C([a,b])$ and $L^p([a,b],m)$ would have been impossible without the Lebesgue and Stieltjes integrals. In fact, the very form of Riesz’s theorems presents a striking connection between integration theory and  dual spaces.

But why should such a connection exist in the first place? The way this relationship appears in Riesz’s theorems calls for a deeper explanation.  My short answer is this: \uwave{it is the moment problems that form the bridge between integration theory and the theory of dual spaces}. (Readers may jump ahead to Subsection \ref{lb25} for the detailed final conclusion.)

To clarify my point, consider the first major example of a duality theorem: the identification $(L^2)^*\simeq L^2$ proved by Riesz and Fr\'echet in 1907:

\begin{thm}[\textbf{Riesz-Fr\'echet theorem}, the classical form]\label{lb15}  \index{00@Riesz-Fr\'echet theorem, the classical form}
We have a linear isomorphism
\begin{gather*}
\Lambda:L^2\big([-\pi,\pi],\frac m{2\pi}\big)\rightarrow L^2\big([-\pi,\pi],\frac m{2\pi}\big)^*\\
\bk{\Lambda(f),g}=\frac 1{2\pi}\int_{-\pi}^\pi fgdm
\end{gather*}
\end{thm}
In fact, Riesz studied $L^2$ spaces several years before introducing the more general $L^p$ spaces. His interest in $L^2$ spaces was clearly influenced by Hilbert’s earlier work on the Hilbert space $l^2(\Zbb)$ and its applications to the theory of integral equations. It was Hilbert’s insights that served as the crucial bridge leading to the Riesz-Fr\'echet Thm. \ref{lb15}---the first major result linking Lebesgue integration with dual spaces. 

As I will explain in the following, Hilbert’s role in this development is best understood through the lens of moment problems.


\subsubsection{Moment problems and dual spaces}


Let me begin by introducing moment problems and explaining how they relate to dual spaces---particularly to the characterization of dual spaces in terms of integral representations.


\begin{problem}[\textbf{Moment problem}, original version]\index{00@Moment problem}\label{lb16}
Let $(\xi_n)$ be a sequence of scalar-valued functions defined on a space, e.g., an interval $I\subset\Rbb$. Choose a sequence of scalars $(c_n)$ satisfying certain conditions. Find a scalar valued function $f$ on $I$ such that for all $n$, we have
\begin{align}\label{eq10}
\int \xi_n f=c_n\qquad\text{resp.}\qquad \int \xi_ndf=c_n
\end{align} 
The numbers $c_1,c_2,\dots$ are called the \textbf{moments}\index{00@Moment} of $f$ resp. $df$. 
\end{problem}



There are two typical types of moment problems:
\begin{itemize}
\item \textbf{Trigonometric moment problem}:\index{00@Trigonometric moment problem} Here $I=\Sbb^1\simeq\Rbb/2\pi\Zbb$, and $\xi_n(x)=e^{-\im nx}$ for $n\in\Zbb$. The problem then amounts to finding a function $f$ with prescribed Fourier coefficients $c_1,c_2,\dots$.
\item \textbf{Polynomial moment problem}:\index{00@Polynomial moment problem} Here $I\subset\Rbb$ is an interval, not necessarily bounded, and $\xi_n(x)=x^n$ for $n\in\Nbb$. One is asked to find an increasing or BV function $f$ such that $df$ has moments $c_1,c_2,\dots$.
\end{itemize}


Many (but not all) moment problems can be reformulated in the language of bounded linear functionals and dual spaces as follows:

\begin{problem}[\textbf{Moment problem}, dual space version]\label{lb17}
Let $(\xi_n)$ be a sequence in a normed vector space $V$, and let  $(c_n)$ be a sequence of scalars. Suppose that there exists $M\in\Rbb_{\geq0}$ such that
\begin{align}\label{eq3}
\Big|\sum_n a_nc_n\Big|\leq M\Big \Vert\sum_n a_n\xi_n\Big\Vert 
\end{align}
for each sequence of scalars $(a_n)$ with finitely many nonzero terms. Find $\varphi\in V^*$ such that
\begin{align}\label{eq4}
\bk{\xi_n,\varphi}=c_n\qquad\text{for all }n
\end{align}
\end{problem}

\begin{rem}
Note that \eqref{eq3} is necessary for the existence of $\varphi$ satisfying \eqref{eq4}, because
\begin{align*}
\Big|\sum_n a_nc_n\Big|=\Big|\bigbk{\sum_n a_n\xi_n,\varphi} \Big|\leq \Vert\varphi\Vert\cdot \Big\Vert\sum_n a_n\xi_n\Big\Vert 
\end{align*}
where $\Vert\varphi\Vert$ is the operator norm. Hence \eqref{eq3} holds for any $M$ satisfying $\Vert\varphi\Vert\leq M$. 

Conversely, if we know that $V_0=\Span\{\xi_n\}$ is dense in $V$, then \eqref{eq3} guarantees that the linear functional
\begin{align*}
\varphi:V_0\rightarrow\Fbb\qquad \sum_n a_n\xi_n\mapsto \sum_n a_n c_n
\end{align*}
is well-defined and bounded, with operator norm $\Vert\varphi\Vert\leq M$. By boundedness, $\varphi$ extends uniquely to a bounded linear functional on all of $V$. Therefore, Problem \ref{lb17} can always be solved.

The case where $V_0$ is not dense in $V$ is more subtle and will be treated in detail in a later chapter.   \hqed
\end{rem}


Once Problem \ref{lb17} is resolved---for example, when $\Span\{\xi_n\}$ is dense in $V$---Problem \ref{lb16} can be solved by answering the following:

\begin{problem}[\textbf{Characterization of the dual space}]\label{lb22}
Characterize the elements of $V^*$ as precisely those linear functionals $\varphi:V\rightarrow\Fbb$ of the form
\begin{align*}
\bk{\xi,\varphi}=\int\xi f{\text{~ resp.~ }} \int\xi df
\end{align*}
(for all $\xi\in V$), where $f$ is a function satisfying suitable regularity or integrability conditions.
\end{problem}


Conversely, Problem \ref{lb22} can be reduced to the moment Problem \ref{lb16} by choosing a densely-spanning $(\xi_n)$ and taking $c_n=\bk{\xi_n,\varphi}$. The solution to Problem \ref{lb16} then yields a function $f$ such that $\bk{\xi_n,f}=\bk{\xi_n,\varphi}$. By the density of $\Span\{\xi_n\}$ in $V$, it follows that $\varphi$ is represented by $f$. 

Thus, we conclude that when $(\xi_n)$ spans a dense subspace of $V$, \uwave{the moment problem (Problem \ref{lb16}) and the characterization of dual spaces (Problem \ref{lb22}) are equivalent}.



\subsubsection{Moment problems and integral theory/function theory}\label{lb19}


In the remainder of this section, we focus on the case where the sequence of functions $(\xi_n)$ is ``sufficiently rich", for example, when it spans a dense subspace of $V$ in Problem \ref{lb17}. Under this assumption, the function $f$ (resp. $df$) in Problem \ref{lb16} or the functional $\varphi$ in Problem \ref{lb17} is uniquely determined by the moments $(c_n)$. Therefore, $(c_n)$ can be understood as the \textbf{coordinates} of $f$ (resp. $df$) and $\varphi$ under the \textbf{coordinate system} $(\xi_n)$.


We now explain how the moment problems connect to integral theory---in other words, to \textbf{function theory}. A central theme in function theory is the approximation of abstract or complicated functions by simpler, more elementary ones. This motivation often arises from practical mathematical problems, particularly those originating in physics, where one seeks to express the solution as a series of elementary functions, such as a power series or a Fourier series. The question of how such series should converge---uniformly, pointwise, or in some other sense---and what kinds of functions they can approximate was a central focus of function theory in the 18th and 19th centuries.


The first step in understanding and solving the approximation problem is to analyze the corresponding moment problem. A typical scenario unfolds as follows. In the setting of Problem \ref{lb16}, suppose there exists a sequence of elementary functions $(f_n)$ such that
\begin{align}\label{eq5}
\int \xi_k f_n\quad\text{resp.}\quad \int \xi_kdf_n\quad=c_k\qquad \text{when $|k|\leq |n|$}
\end{align}
This situation arises, for instance, in the study of continued fractions and polynomial moments, where $\xi_k(x)=x^k$. In the case of Fourier series, an even stronger condition holds:
\begin{align}\label{eq6}
\int \xi_k f_n\quad\text{resp.}\quad\int \xi_k df_n\quad=\left\{
\begin{array}{ll}
c_k&\text{if }|k|\leq |n|\\[0.5ex]
0&\text{if }|k|>|n|
\end{array}
\right.
\end{align}
where $\xi_k(x)=e^{-\im kx}$ and $f_n(x)=\sum_{|k|\leq n}c_k e^{\im kx}$. The approximation problem asks:

\begin{problem}\label{lb18}
Does the sequence $(f_n)$ converge to some function $f$? If so, in what sense does it converge? 
\end{problem}

To approach this problem, observe that if such a function $f$ exists, and if the integral commutes with the convergence of sequence of functions, then
\begin{subequations}\label{eq7}
\begin{align}
\int \xi_k f=\int\lim_{|n|\rightarrow\infty}\xi_kf_n=\lim_{|n|\rightarrow\infty}\int \xi_kf_n\xlongequal{\eqref{eq5}}c_k
\end{align}
resp.
\begin{align}\label{eq7b}
\int \xi_k df=\int\lim_{|n|\rightarrow\infty}\xi_kdf_n=\lim_{|n|\rightarrow\infty}\int \xi_kdf_n\xlongequal{\eqref{eq5}}c_k
\end{align}
\end{subequations}
Therefore, \uwave{the first step in solving Problem \ref{lb18} is to find a function $f$ solving the moment Problem \ref{lb16}}. Once such an $f$ is found, the next step is to prove that the sequence $(f_n)$ converges to $f$, and investigate the mode of convergence.


Historically, the understanding of convergence, the properties of the limiting function $f$, and the integrals appearing in \eqref{eq7} was often insufficient to resolve the approximation problem at the outset. In many cases, addressing the approximation problem required the development of new theories of integration or the extension of the class of integrable functions. Both the Lebesgue and Stieltjes integrals emerged from such needs. For instance, the challenges posed by Fourier series played a central role in motivating the development of the Riemann and later the Lebesgue integral. See \cite[Ch. 6, 9]{Jah} and \cite{Haw-L} for a detailed discussion of how Fourier series drove this evolution. The connection between continued fractions and the Stieltjes integral will be explored in Ch. \ref{lb114}. 

\begin{table}[h]
\centering
 \begin{tabular}{|c|c|c|}
    \hline 
Function theory& \rule{0pt}{0.45cm} Moment Problems & Dual spaces\\
\hline
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Lebesgue integral} \\
\&\\
\text{Fourier series}
\end{array}$& Fourier coefficients&$L^2([a,b],m)^*$\\
\hline 
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Stieltjes integral} \\
\&\\
\text{Continued fractions}
\end{array}$
&Polynomial moments&$C([a,b])^*$\\
\hline
  \end{tabular}
\caption{The origin of moment problems in function theory}\label{tb2}
\end{table}



\subsubsection{Convergence of functions, moments, and linear functionals}





In the previous subsection, we noted that solving moment problems determines the function $f$ that appears in Problem \ref{lb18}. But can the moment problem perspective also help us understand the convergence of $f_n$ to $f$? Or conversely, can the convergence behavior of $f_n$ toward $f$ offer deeper insight into the structure of moment problems themselves? Thanks to Hilbert's foundational work on the Hilbert space $l^2(\Zbb)$---especially his groundbreaking 1906 paper \cite{Hil06}---the answer is yes.\footnote{Indeed, Hilbert originally worked with the real Hilbert space $l^2(\Zbb,\Rbb)$, rather than the complex one $l^2(\Zbb)=l^2(\Zbb,\Cbb)$. For clarity and simplicity, however, we will work with $l^2(\Zbb)$ in what follows.} 


A key concept introduced by Hilbert in \cite{Hil06} is \textbf{weak convergence}: If $(\psi_n)$ is a sequence in $l^2(\Zbb)$ with uniformly bounded norm, i.e.,
\begin{align}\label{eq11}
\sup_n\Vert\psi_n\Vert_2<+\infty
\end{align}
we say that $(\psi_n)$ converges weakly to $\psi\in l^2(\Zbb)$ if it converges pointwise $\Zbb$, i.e.,
\begin{align}\label{eq8}
\lim_n\psi_n(k)=\psi(k)\qquad\text{for all }k\in\Zbb
\end{align}
Since $l^2(\Zbb)$ is typically interpreted as the space of Fourier series of $L^2$-integrable functions, Hilbert's notion of weak convergence corresponds to the (pointwise) convergence of Fourier coefficients. That is,
\begin{align*}
\lim_n \wht f_n(k)=\wht f(k)\qquad\text{for all }k\in\Zbb
\end{align*}
where $f_n$ and $f$ are $L^2$-integrable functions on $[-\pi,\pi]$.\footnote{Hilbert himself did not initially connect $l^2(\Zbb)$ with the Lebesgue integral. The precise relationship between $l^2(\Zbb)$ and $L^2([-\pi,\pi],\frac m{2\pi})$ was later clarified by Riesz and Fischer in 1907.}


The notion of weak convergence---later extended to weak-* convergence---provided a fundamentally new insight into the study of moment problems and their connection to dual spaces and function theory/integral theory. Since Fourier coefficients are simply trigonometric moments, the weak convergence described by \eqref{eq8} can be understood as the (pointwise) \textbf{convergence of moments}, which means, in the setting of the moment Problem \ref{lb16}, that
\begin{align}\label{eq9}
\lim_n\int \xi_kf_n\quad\text{resp.}\quad\lim_n\int\xi_k df_n\quad=c_n\qquad\text{for all }k
\end{align}


The translation of \eqref{eq9} into the setting of the dual space version of the moment Problem \ref{lb17} is straightforward: One considers a sequence $(\varphi_k)$ in $V^*$ such that $\lim_n\bk{\xi_k,\varphi_n}=\bk{\xi_k,\varphi}$ holds for all $k$. Since we have assumed at the beginning of Subsec. \ref{lb19} that $(\xi_n)$ spans a dense subspace of $V$, it follows from \eqref{eq11} that \uwave{this convergence of moments is equivalent to the \textbf{weak-* convergence}} of $(\varphi_n)$ to $\varphi$. That is, we say that $(\varphi_n)$ converges weak-* to $\varphi$ if
\begin{align}\label{eq13}
\lim_n\bk{\xi,\varphi_n}=\bk{\xi,\varphi}\qquad\text{for all }\xi\in V
\end{align}
Thus, the second and third columns of Table \ref{tb1} are equivalent. See Thm. \ref{lb80} for the formal statement of this equivalence.



On the other hand, \eqref{eq9} generalizes the condition \eqref{eq5}, which, as previously mentioned, arises naturally in the study of Fourier series and continued fractions. As such, its function-theoretic interpretation---highlighted by the following theorems---provides a general framework for understanding the convergence of the sequence $(f_n)$ to $f$ in Problem \ref{lb18}. 


\begin{thm}
Let $1<p\leq+\infty$ and $p^{-1}+q^{-1}=1$. Let $(f_n)$ be a uniformly $L^p$-norm bounded sequence in $L^p([a,b],m)$. Suppose that $(f_n)$ converges pointwise to $f$. Then we have $f\in L^p([a,b],m)$. Moreover,  $(f_n)$ converges weak-* to $f$, which means that $\lim_n\int f_ngdm=\int fgdm$ for all $g\in L^q([a,b],m)$.
\end{thm}

\begin{proof}
See Thm. \ref{lb81}.
\end{proof}


\begin{thm}\label{lb20}
Let $1<p\leq+\infty$ and $p^{-1}+q^{-1}=1$. Let $(f_n)$ be a uniformly $L^p$-norm bounded sequence in $L^p([a,b],m)$. Then $(f_n)$ converges weak-* to some element $f\in L^p([a,b],m)$  iff the limit
\begin{align}\label{eq14}
F(x):=\lim_n \int_a^x f_ndm
\end{align}
exists for every $x\in[a,b]$. When $(f_n)$ converges weak-* to $f\in L^p([a,b],m)$, for each $x\in[a,b]$ we have
\begin{align}\label{eq12}
F(x)=\int_a^x fdm
\end{align}
\end{thm}

\begin{proof}
If $(f_n)$ converges weak-* to $f$, then $\lim_n \int f_n\chi_{[a,x]}=\int f_n\chi_{[a,x]}$, which implies that $F(x)$ exists and equals $\int_a^x fdm$. 

The other direction is more difficult. Indeed, it is almost equivalent to the duality $L^p([a,b],m)\simeq L^q([a,b],m)^*$. See Thm. \ref{lb78}.
\end{proof}

\begin{comment}

Conversely, assume that $F(x)$ exists for all $x$. Let $M=\sup_n\Vert f_n\Vert_p$, which by assumption is finite. For each $\eps>0$ and for each mutually disjoint intervals $I_1=(a_1,b_1),\dots,I_k=(a_k,b_k)$ in $[a,b]$ with total length $\leq M^{-q}\eps^q$, setting $I=I_1\cup\cdots\cup I_k$, we have
\begin{align*}
\sum_{i=1}^k |F(b_i)-F(a_i)|\leq\sum_{i=1}^k \limsup_n\int_{I_i} |f_n|dm\leq M\Vert\chi_I\Vert_q=M\cdot m(I)^{\frac 1q}\leq \eps
\end{align*}
Therefore $F$ is absolutely continuous. Thus, $f:=F'$ exists a.e. and is $L^1$, and \eqref{eq12} holds for all $f$.
\end{comment}



\begin{thm}\label{lb21}
Let $(\rho_n)$ be a uniformly $l^\infty$-bounded sequence of increasing functions $[a,b]\rightarrow\Rbb_{\geq0}$.  The following are true.
\begin{enumerate}
\item Let $\rho:[a,b]\rightarrow\Rbb_{\geq0}$ be bounded and increasing. Then $(d\rho_n)$ converges weak-* to $d\rho$ iff $(\rho_n)$ converges pointwise to $\rho$ at $b$ and at any point where $\rho|_{(a,b)}$ is continuous.
\item $(d\rho_n)$ converges weak-* to $d\rho$ for some bounded increasing $\rho:[a,b]\rightarrow\Rbb_{\geq0}$ iff $(\rho_n)$ converges pointwise at $b$ and on a dense subset of $I$.
\end{enumerate}
\end{thm}

By saying that $(d\rho_n)$ converges weak-* to $d\rho$, we mean $\lim_n \int gd\rho_n=\int gd\rho$ for all $g\in C([a,b],m)$.

\begin{proof}
See Thm. \ref{lb92} and Cor. \ref{lb95}.
\end{proof}

The above theorems establish an intimate connection between the (pointwise) convergence of moments and the pointwise convergence of the antiderivatives of a sequence of functions.\footnote{We are viewing $\rho_n$ and $\rho$ as the antiderivatives of $d\rho_n$ and $d\rho$.} Our understanding of convergence from various perspectives can thus be summarized in Table \ref{tb1}.

\begin{table}[H]
\centering
 \begin{tabular}{|c|c|c|}
    \hline \rule{0pt}{0.45cm}
Function theory & Moment Problems & Dual spaces\\
\hline 
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Pointwise convergence} \\
\text{of (antiderivatives of)}\\
\text{a sequence of functions}
\end{array}$
& 
$\begin{array}{c}
\text{Pointwise convergence} \\
\text{of moments}\\
\end{array}$
 & Weak-* convergence\\
\hline
  \end{tabular}
\caption{Equivalence of convergence notions}\label{tb1}
\end{table}


\subsubsection{Equivalence of the first and second columns of Table \ref{tb1}}\label{lb107}



Thm. \ref{lb20} and \ref{lb21}, which establish the equivalence of the first and second columns of Table \ref{tb1}, are not easy to prove. In fact, proving Thm. \ref{lb20} typically requires the duality $L^p([a,b])\simeq L^q([a,b])^*$, or at least techniques closely related to those used in establishing this duality. 


Therefore, the solvability of the moment problems (Problems \ref{lb16} and \ref{lb17})---in other words, the solvability of Problem \ref{lb22} concerning the characterization of dual spaces---is closely related to the equivalence between the first and second columns of Table \ref{tb1}. This close connection rests on the following principle:

\begin{principle}\label{lb23}
Usually, if $V$ is a normed vector space consisting of functions,  any element $\varphi$ of $V^*$ can be weak-* approximated by elementary functions with uniformly bounded norms. More precisely, there exists a sequence (or a net) of elementary functions $(f_n)$ such that the operator norms of the linear functionals $\xi\in V\mapsto\int \xi f_n$ are uniformly bounded, and
\begin{align*}
\lim_n \int\xi f_n=\bk{\xi,\varphi}\qquad\text{for all }\xi\in V
\end{align*}
\end{principle}


\begin{rem}\label{lb110}
Here is how, with the help of Principle \ref{lb23}, the characterization of $V^*$ can be derived from the equivalence of the first and second columns of Table \ref{tb1}: 

By this principle, for each $\varphi\in V^*$, we can select a sequence $(f_n)$  approximating weak-* to $\varphi$. Since the second column of Table \ref{tb1} implies the first column, the sequence $(f_n)$ converges to some function $f$ in the sense described in the first column of Table \ref{tb1}. Then, by the equivalence of the three modes of convergence in that table, it follows that $(f_n)$ converges weak-* to $f$. Consequently, $\varphi$ is represented by integration against $f$, thereby solving the problem of characterizing the dual space $V^*$. \hqed
\end{rem}

The idea outlined in Rem. \ref{lb110} is roughly the approach Riesz employed in 1907 to solve the following trigonometric moment problem.

\index{00@Riesz-Fischer theorem, Riesz's original version}
\begin{thm}[\textbf{Riesz-Fischer theorem}, Riesz's original version]\footnote{The modern interpretation of the Riesz-Fischer theorem as stating that $L^2(X,\mu)$ (or more generally $L^p(X,\mu)$) is Cauchy-complete for any measure space $(X,\mu)$ has led to a significant misunderstanding. In fact, while Fischer formulated the theorem for $L^2([-\pi,\pi],\frac m{2\pi})$ in terms of Cauchy sequences, Riesz understood it quite differently---through the lens of moment problems.

Therefore, once Riesz realized that solving moment problems is equivalent to the characterization of dual spaces, he immediately obtained the Riesz-Fr\'echet Thm. \ref{lb15}. As we have emphasized at the beginning of Sec. \ref{lb24}, completeness and duality are fundamentally distinct properties, each serving distinct purposes and arising from different considerations. The fact that they coincide in the case of inner product spaces is purely a coincidence.}
For each $(c_k)_{k\in\Zbb}$ in $l^2(\Zbb)$, there is an (automatically unique) $f\in L^2([-\pi,\pi],\frac m{2\pi})$ whose Fourier series is equal to $(c_k)$.
\end{thm}


\begin{proof}[\textbf{Riesz's idea of the proof}]\footnote{See \cite[Ch. 6]{Haw-L}.}
Choose $(c_k)_{k\in\Zbb}$ in $l^2(\Zbb)$. One aims to solve the moment problem that there exists $f\in L^2$ such that $\frac{1}{2\pi}\int fe_{-k}=c_k$ for all $k\in\Zbb$, where $e_k(x)=e^{\im kx}$. For each $n\in\Nbb$, let
\begin{align*}
f_n=\sum_{-n\leq k\leq n}c_ke_k
\end{align*}
Then $(f_n)$ converges weak-* to the bounded linear functional $\varphi\in (L^2)^*$ satisfying $\bk{e_{-k},\varphi}=c_k$ for all $k$. (This is an instance of Principle \ref{lb23}.) \footnote{Riesz's original proof does not use the language of linear functionals.} 

On the other hand, the property $\sum_k|c_k|^2<+\infty$ implies that the antiderivatives of $(f_n)$ converge pointwise to some function $F$ in the sense of \eqref{eq14}. This establishes the convergence described in the first column of Table \ref{tb1}. 

Then, applying the fundamental theorem of calculus for the Lebesgue integral, Riesz deduced the convergence in the second column of Table \ref{tb1} for the derivative function $f:=F'$ (which exists a.e. and is $L^2$) and for another densely spanning set of functions---the set $\{\chi_{[a,x]}:x\in[a,b]\}$.\footnote{The fact that the fundamental theorem of calculus for the Lebesgue integral---one of the deepest results in measure theory---is used here highlights how non-trivial the equivalence between the first and second columns of Table \ref{tb1} really is.} Namely, he obtained
\begin{align*}
\bk{\chi_{[a,x]},f}=\lim_n\bk{\chi_{[a,x]},f_n}\qquad\text{for all }x\in[a,b]
\end{align*}
Therefore, since the second column of Table \ref{tb1} is equivalent to the third, $(f_n)$ converges weak-* to $f$. Thus $\varphi$ is represented by $f$, which implies that $f$ solves the desired moment problem---since $\varphi$ does.
\end{proof}

Note that the fundamental theorem of calculus for the Lebesgue integral is crucial to the above proof. Likewise, the Radon-Nikodym Thm. \ref{lb27}---a modern form of the fundamental theorem of calculus---also plays a central role in the proof of Theorem \ref{lb13}, which establishes the duality \ref{lb13} on $L^p(X,\mu)\simeq L^q(X,\mu)^*$. This reinforces the point that the characterization of dual spaces is deeply connected to the equivalence between the first and second columns of Table \ref{tb1}. 

See \cite[Sec. 27.3]{Gui-A} for further discussion on the relationship between the classical and modern proofs of the duality $L^p\simeq(L^q)^*$, the connection between this duality and the completeness of $L^p$-spaces, and the role of derivatives---both in the classical sense and in the form of Radon-Nikodym derivatives---in this context.



\subsubsection{Conclusion}\label{lb25}


We now summarize the discussion so far by addressing the question posed at the beginning of this section: Why are dual spaces related to integral theory? More specifically, from the mathematical-historical perspective, why is it possible to characterize the dual spaces of $L^p(X,\mu)$ and $C(X)$?

\begin{table}[h]
\centering
 \begin{tabular}{|c|c|c|}
    \hline \rule{0pt}{0.45cm}
Function theory & Moment Problems & Dual spaces\\
\hline & \rule{0pt}{0.5cm} Solving moment problems &Characterizing $V^*$\\
\hline\multicolumn{3}{|c|}{\rule{0pt}{0.5cm}  Related by \scalebox{1.3}{$\Updownarrow$} Principle \ref{lb23} } \\
\hline 
\cellcolor{gray!20}$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Pointwise convergence} \\
\text{of (antiderivatives of)}\\
\text{a sequence of functions}
\end{array}$
& 
\cellcolor{gray!20}$\begin{array}{c}
\text{Pointwise convergence} \\
\text{of moments}\\
\end{array}$
 & Weak-* convergence\\
\hline
  \end{tabular}
\caption{The cells in each row are equivalent}\label{tb4}
\end{table}



The answer, in my view, is captured in Table \ref{tb4}: The power of the Lebesgue and Stieltjes integrals lies in their ability to establish the equivalence between the two gray cells in that table. Once this equivalence is established, with the help of Principle \ref{lb23}, the characterization of dual spaces in terms of integrals becomes straightforward.

But why are these two integrals powerful enough to establish the equivalence between the two gray cells in Table \ref{tb4}?—Because both the Lebesgue and Stieltjes integrals arise from the study of moment problems, which in turn are rooted in the corresponding approximation problems, as illustrated in Table \ref{tb2}. The emphasis of these integral theories on the commutativity of limits and integration anticipates the equivalence of the two gray cells.

In light of the equivalences in Table \ref{tb4}, the Lebesgue integral, as the completion of the Riemann integral, can be interpreted as the weak-* completion of trigonometric functions and continuous functions. Similarly, the Stieltjes integral, as the completion of finite sums, can be viewed as the weak-* completion of discrete spectra---a perspective that will be one of the main themes of Ch. \ref{lb114}. See Table \ref{tb3}.







\begin{table}[H]
\centering
 \begin{tabular}{|c|c|c|}
    \hline 
Completion of Integrals &$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Extension of} \\
\text{classes of functions}
\end{array}$  & \textbf{Weak-* completion}\\
\hline 
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Riemann integral} \\
\cap\\
\text{Lebesgue integral}
\end{array}$
& 
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Continuous functions} \\
\cap\\
\text{Measurable functions}
\end{array}$
 & of continuous functions\\
\hline 
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Finite sum} \\
\cap\\
\text{Stieltjes integral}
\end{array}$
& 
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Discrete spectra} \\
\cap\\
\text{Continuous spectra}
\end{array}$
 & of discrete spectra\\
\hline
  \end{tabular}
\caption{}\label{tb3}
\end{table}







\begin{comment}
Let us return to Hilbert’s contribution in \cite{Hil06} from the perspective of moment problems. 
\begin{itemize}
\item In his study of integral equations, Hilbert introduced the general notion of weak convergence in $l^2(\Zbb)$, which takes the form of pointwise convergence of moments and anticipates the future notion of  weak-* convergence. 

More specifically, Hilbert considered a completely continuous, self-adjoint, bounded linear operator\footnote{More precisely, Hilbert worked with a bilinear form.} $T$ on $l^2(\Zbb)$, and his goal was to find the eigenvectors of $T$. To identify an eigenvector $\xi\in l^2(\Zbb)$ of unit norm corresponding to the largest (real) eigenvalue $\lambda$, he constructed a sequence $(\xi_n)$ in the closed unit ball $\ovl B_{l^2(\Zbb)}(0,1)$ such that $\bk{T\xi_n|\xi_n}\rightarrow\lambda$, and that $(\xi_n)$ converges weakly to some $\xi\in \ovl B_{l^2(\Zbb)}(0,1)$. 
\item In his proof of the spectral theorem for bounded self-adjoint operators on $l^2(\Zbb)$---not necessarily completely continuous---Hilbert approximated the continuous spectrum using discrete spectra. This approximation takes the form of the convergence of a sequence of increasing functions $\rho_n\rightarrow\rho$. This mode of convergence is more general than that used earlier by Stieltjes in his study of continued fractions---just as the convergence of moments described in \eqref{eq9} is a generalization of the more specific form given in \eqref{eq5}.\footnote{Hilbert did not express his approximation in terms of the pointwise convergence of moments. This reformulation, connecting Hilbert's approach to the framework of moment problems and dual spaces, was later introduced by Riesz in \cite{Rie13}.}
\end{itemize}


For a detailed discussion of the first part, see \cite[Sec. 22.5]{Gui-A}; we will also revisit this topic in Ch. 6. The second part will be addressed in the following chapter.
\end{comment}



\noindent \small\textit{Side note.}  A common viewpoint---motivated by the completeness of $L^1$-spaces---regards the Lebesgue integral and the Lebesgue measurable/integrable functions as the Cauchy completion of Riemann integrals and continuous functions. In my view, this perspective is not only historically inaccurate, but also mathematically misleading.

Historically, the first $L^p$-space considered is $L^2([a,b],m)$, due to its close relation with $l^2(\Zbb)$, the space of trigonometric moments of $L^2$-integrable functions. The space $l^2(\Zbb)$ was introduced by Hilbert in \cite{Hil06}, where weak convergence (equivalently, pointwise convergence of moments) plays a central role in his proof of the Hilbert-Schmidt theorem. In \cite{Rie10}, Riesz studied the space $L^p([a,b],m)$ for $1<p<+\infty$, and in particular proved the duality $L^p([a,b],m)\simeq L^q([a,b],m)^*$. The completeness of $L^p([a,b],m)$ follows as a corollary. However, $L^1([a,b],m)$ was not considered, likely due to its lack of a satisfactory duality theory. This clearly shows that duality was originally viewed as more fundamental than Cauchy completeness.


Mathematically, to perform a Cauchy completion, one needs a norm, which in this context is defined via an integral. Yet, while integrals are linear functionals, norms only satisfy the subadditivity. As a result, norms and Cauchy completions do not provide the right conceptual framework for understanding the nature of the Lebesgue integral from a functional-analytic perspective.


The more appropriate viewpoint is to regard the Lebesgue integral as arising from weak-* completion, not Cauchy completion.

\normalsize


\subsection{Bounded multilinear maps}


\subsubsection{Seminorms, norms, and normed vector spaces}

\begin{df}\label{lb45}
If $V$ is an $\Fbb$-vector space, a function $\Vert\cdot\Vert:V\rightarrow\Rbb_{\geq0}$ is called a \textbf{seminorm} \index{00@Seminorm} if
\begin{align}\label{eq28}
\Vert av\Vert=|a|\cdot\Vert v\Vert\qquad \Vert u+v\Vert\leq\Vert u\Vert+\Vert v\Vert\qquad\text{for any $u,v\in V$ and $a\in\Fbb$}
\end{align}
A seminorm is called a \textbf{norm} if any $v\in V$ satisfying $\Vert v\Vert=0$ is the zero vector $0$. A vector space $V$, equipped with a norm, is called a \textbf{normed vector space}.

If $V$ is a normed vector space, then a \textbf{normed vector subspace} \index{00@Normed vector subspace} of $V$ denotes a linear subspace $U\subset V$ equipped with the norm inherited from $V$, i.e., the restriction of $V$'s norm to $U$.  

We say that $V$ is \textbf{separable} \index{00@Separable normed vector spaces} if it is so under the \textbf{norm topology}, \index{00@Norm topology} namely, the topology induced by the metric $d(u,v)=\Vert u-v\Vert$. \hqed
\end{df}

\begin{rem}\label{lb46}
In Def. \ref{lb45}, the condition $\Vert av\Vert=|a|\cdot\Vert v\Vert$ can be weakened to
\begin{align}\label{eq29}
\Vert av\Vert\leq|a|\cdot\Vert v\Vert\qquad\text{for any $v\in V$ and $a\in\Fbb$}
\end{align}
Therefore, \eqref{eq28} can be weakened to
\begin{align}
\Vert au+bv\Vert\leq |a|\cdot\Vert u\Vert+|b|\cdot\Vert v\Vert\qquad\text{for any $u,v\in V$ and $a,b\in\Fbb$}
\end{align}
\end{rem}

\begin{proof}
Suppose that \eqref{eq29} is true. Then we clearly have $\Vert av\Vert=|a|\cdot\Vert v\Vert$ when $a=0$. Suppose that $a\neq 0$. Then $\Vert v\Vert=\Vert a^{-1}av\Vert\leq |a|^{-1}\Vert a v\Vert$, and hence $\Vert av\Vert\geq |a|\cdot\Vert v\Vert$. Therefore $\Vert av\Vert=|a|\cdot\Vert v\Vert$.
\end{proof}



\begin{rem}\label{lb59}
The norm function $\Vert\cdot\Vert:V\rightarrow\Rbb_{\geq0}$ is continuous. This is because
\begin{align}
\Vert u\Vert-\Vert v\Vert\leq \Vert u-v\Vert
\end{align}
Therefore, if $(v_\alpha)$ is a net in $V$ converging (in norm) to $v$, then
\begin{align*}
\Vert v\Vert=\lim_\alpha\Vert v_\alpha\Vert
\end{align*}
\end{rem}

\begin{pp}\label{lb47}
Let $\Vert\cdot\Vert_V$ be a seminorm on an $\Fbb$-vector space $V$. Let $V_0=\{v\in V:\Vert v\Vert_V=0\}$. Then $V_0$ is a linear subspace on $V$, and there is a (clearly unique) norm $\Vert\cdot\Vert_{V/V_0}$ on the quotient space $V/V_0$ such that
\begin{align}\label{eq27}
\Vert v+V_0\Vert_{V/V_0}=\Vert v\Vert_V\qquad\text{for all }v\in V
\end{align}
\end{pp}

In the future, unless otherwise stated, we will always equip $V/V_0$ with this norm $\Vert\cdot\Vert_{V/V_0}$.

\begin{proof}
We abbreviate $\Vert\cdot\Vert_V$ to $\Vert\cdot\Vert$. If $u,v\in V_0$ and $a,b\in\Fbb$, then
\begin{align*}
\Vert au+bv\Vert\leq |a|\Vert u\Vert+|b|\Vert v\Vert=0
\end{align*}
This shows that $V_0$ is a linear subspace of $V$. On the other hand, if $u,v\in V$ satisfy $u+V_0=v+V_0$, then $u-v\in V_0$, and hence
\begin{align*}
\Vert v\Vert=\Vert u+v-u\Vert\leq\Vert u\Vert+\Vert v-u\Vert=\Vert u\Vert
\end{align*}
Similarly, $\Vert u\Vert\leq\Vert v\Vert$. Therefore $\Vert u\Vert=\Vert v\Vert$. This implies that we have a well-defined function $\Vert\cdot\Vert_{V/V_0}:V/V_0\rightarrow\Rbb_{\geq0}$ satisfying \eqref{eq27}.

If $u,v\in V$ and $a,b\in\Fbb$, then
\begin{align*}
\Vert a(u+V_0)+b(v+V_0)\Vert_{V/V_0}=\Vert au+bv+V_0\Vert_{V/V_0}=\Vert au+bv\Vert\leq |a|\Vert u\Vert+|b|\Vert v\Vert
\end{align*}
\end{proof}








\subsubsection{Bounded multilinear maps}

In the rest of this section,  $V_1,V_2,\dots$ and $U,V,W$ all denote normed $\Fbb$-vector spaces.

\begin{df}
Let $N\in\Zbb_+$. A map $T:V_1\times\cdots\times V_N\rightarrow W$ is called a \textbf{multilinear map} \index{00@Multilinear map} if for each $1\leq i\leq N$ and each fixed $v_j\in V_j$ (for all $j\neq i$), the map
\begin{align*}
v_i\in V_i\mapsto T(v_1,\dots,v_N)\in W
\end{align*}
is $\Fbb$-linear. We let \index{Lin@$\Lin(V_1\times\cdots\times V_N,W)$}
\begin{align*}
\Lin(V_1\times\cdots\times V_N,W)=\{\text{multilinear maps }V_1\times\cdots\times V_N\rightarrow W\}
\end{align*}
For each $T\in \Lin(V_1\times\cdots\times V_N,W)$, we define the \textbf{operator norm}\index{00@Operator norm $\Vert T\Vert$}\index{T@$\Vert T\Vert$, the operator norm of $T$}
\begin{align*}
\Vert T\Vert:=\Vert T\Vert_{l^\infty(\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1),W)}=\sup_{v_1\in\ovl B_{V_1}(0,1),\dots,v_N\in\ovl B_{V_N}(0,1)}\Vert T(v_1,\dots,v_N)\Vert
\end{align*}
We say that $T$ is \textbf{bounded} \index{00@Bounded multilinear map} if $\Vert T\Vert<+\infty$. 
\end{df}


\begin{df}\label{lb116}
We let \index{LV@$\fk L(V_1\times\cdots\times V_N,W)$}
\begin{gather}\label{eq26}
\fk L(V_1\times\cdots\times V_N,W):=\{\text{bounded multilinear maps }V_1\times\cdots\times V_N \rightarrow W\}
\end{gather}
viewed as an $\Fbb$-linear subspace of $W^{V_1\times\cdots\times V_N}$. We let \index{LV@$\fk L(V)$} \index{V@$V^*=\fk L(V,\Fbb)$}
\begin{align*}
\fk L(V):=\fk L(V,V)\qquad V^*:=\fk L(V,\Fbb)
\end{align*}
Element of $\fk L(V)$ are called \textbf{bounded linear operators on} $V$. The space $V^*$ is called the \textbf{dual space} of $V$.
\end{df}

\begin{rem}
In this course, the most frequently encountered cases of \eqref{eq26} are $\fk L(V)$, $V^*$, and $\fk L(U\times V,\Fbb)$. In Ch. \ref{lb114}, we also consider spaces such as $\fk L(U\times V\times V_*,\Fbb)$, where $V_*$ is a normed vector space with dual space $V$. In such cases, Prop. \ref{lb40} gives isomorphisms
\begin{align*}
\fk L(U\times V\times V_*,\Fbb)\simeq\fk L(U,\fk L(V\times V_*,\Fbb))\simeq \fk L(U,\fk L(V))
\end{align*}
\end{rem}





\begin{rem}\label{lb30}
$\Vert T\Vert$ is the smallest element in $\ovl\Rbb_{\geq0}$ satisfying
\begin{align}\label{eq22}
\Vert T(v_1,\dots,v_N)\Vert\leq \Vert T\Vert\cdot \Vert v_1\Vert\cdots\Vert v_N\Vert
\end{align}
\end{rem}

\begin{proof}
If one of $v_1,\dots,v_N$ is zero, then $T(v_1,\dots,v_N)=0$ by the multilinearity, and hence \eqref{eq22} holds. So we assume that $v_1,\dots,v_N$ are all non-zero. So their norms are all nonzero. Since $v_i/\Vert v_i\Vert\in B_{V_i}(0,1)$, we have
\begin{align*}
\Big\Vert T\Big(\frac{v_1}{\Vert v_1\Vert},\cdots,\frac{v_N}{\Vert v_N\Vert}\Big)\Big\Vert\leq\Vert T\Vert
\end{align*}
which implies \eqref{eq22} by the multilinearity. 

We have proved that $\Vert T\Vert$ satisfies \eqref{eq22}. Now, suppose that $C\in\ovl\Rbb_{\geq0}$ and
\begin{align*}
\Vert T(v_1,\dots,v_N)\Vert\leq C\cdot \Vert v_1\Vert\cdots\Vert v_N\Vert
\end{align*}
for all $v_i\in V_i$. Taking $v_i\in\ovl B_V(0,1)$, we see that $\Vert T\Vert\leq C$.
\end{proof}

Recall Def. \ref{lb33}.

\begin{pp}\label{lb35}
Let $T:V_1\times\cdots\times V_N\rightarrow W$ be multilinear. The following are equivalent.
\begin{enumerate}[label=(\alph*)]
\item $T$ is continuous.
\item $T$ is continuous at $0\times\cdots\times 0$.
\item $T$ is bounded.
\item $T$ is Lipschitz continuous on $\ovl B_{V_1}(0,R)\times\cdots\times\ovl B_{V_N}(0,R)$ for every $R\in\Rbb_{>0}$.
\item $T$ is Lipschitz continuous on $\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1)$.
\end{enumerate}
Moreover, if $T$ is bounded, and if $V_1\times\cdots\times V_N$ is equipped with the $l^\infty$-product metric, then the Lipschitz constant in (d) can be chosen to be $NR^{N-1}\Vert T\Vert$.
\end{pp}

What matters about the Lipschitz constant above is not its exact formula, but the implication it carries: namely, that any family $(T_\alpha)$ in $\fk L(V_1\times\cdots\times V_N,W)$ satisfying $\sup_\alpha\Vert T_\alpha\Vert<+\infty$, when restricted to a bounded subset of $V_1\times\cdots\times V_N$, admits a uniform Lipschitz constant.


\begin{proof}
Clearly (a)$\Rightarrow$(b).

(b)$\Rightarrow$(c): Assume (b). Then $0\times\cdots\times 0$ is an interior point of $T^{-1}(B_W(0,1))$, and hence contains $B_{V_1}(0,2\delta_1)\times\cdots\times B_{V_N}(0,2\delta_N)$ for some $\delta_1,\dots,\delta_N>0$. So $T$ sends $\ovl B_{V_1}(0,\delta_1)\times\cdots\times\ovl B_{V_N}(0,\delta_N)$ (which equals $\delta_1\ovl B_{V_1}(0,1)\times\cdots\times\delta_N\ovl B_{V_N}(0,1)$) into $B_W(0,1)$. By multilinearity, $T$ sends $\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1)$ into $B_W(0,\delta_1^{-1}\cdots\delta_N^{-1})$. This proves (c). 

(c)$\Rightarrow$(d): Assume (c). Choose $v_i\in \ovl B_{V_i}(0,R_i)$. Then, for each $\xi_i\in \ovl B_{V_i}(0,R_i)$,
\begin{align*}
&\Vert T(\xi_1,\dots,\xi_N)-T(v_1,\dots,v_N)\Vert\\
\leq&\Vert T(\xi_1-v_1,\xi_2,\xi_3,\dots,\xi_N)\Vert+\Vert T(v_1,\xi_2-v_2,\xi_3,\dots,\xi_N)\Vert\\
&+\Vert T(v_1,v_2,\xi_3-v_3,\dots,\xi_N)\Vert+\cdots+\Vert T(v_1,v_2,v_3,\dots,\xi_N-v_N)\Vert\\
\leq&NR^{N-1}\Vert T\Vert\cdot \max\{\Vert \xi_1-v_1\Vert,\dots,\Vert \xi_N-v_N\Vert\}
\end{align*}
where \eqref{eq22} is used in the last inequality. Thus $T$ has Lipschitz constant $NR^{N-1}\Vert T\Vert$.

(e)$\Leftrightarrow$(d): This is clear by scaling the vectors.

(d)$\Rightarrow$(f): This is clear from Rem. \ref{lb34}.
\end{proof}



\begin{eg}
A linear map $T:V\rightarrow W$ is called a \textbf{linear isometry} if it is an isometry of metric spaces, i.e., $\Vert Tv_1-Tv_2\Vert=\Vert v_1-v_2\Vert$ for all $v_1,v_2\in V$. This is clearly equivalent to
\begin{align*}
\Vert Tv\Vert=\Vert v\Vert\qquad\text{for all }v\in V
\end{align*}
A linear isometry is clearly bounded with operator norm $\Vert T\Vert=1$ (unless when $V=\{0\}$). Moreover, a linear isometry is clearly injective. A linear isometry $T:V\rightarrow W$ which is also surjective (and hence bijective) is called an \textbf{isomorphism of normed vector spaces}.\index{00@Isomorphism of normed vector spaces} In that case, we say that the normed vector spaces $V,W$ are \textbf{isomorphic}. \index{00@Isomorphic normed vector spaces}
\end{eg}


\begin{rem}
Suppose that $\Phi:V\rightarrow W$ is a linear map of vector spaces, and $W$ is a normed vector space. Then $V$ has a seminorm defined by
\begin{align*}
\Vert v\Vert_V:=\Vert \Phi(v)\Vert_V
\end{align*}
Equip $V/\Ker\Phi$ with the norm defined by Prop. \ref{lb47}. Then $\Phi$ descends to a linear map $\wtd\Phi:V/\Ker\Phi\rightarrow W$, which is clearly a linear isometry. 
\end{rem}

\begin{eg}\label{lb48}
Let $1\leq p\leq+\infty$, let $X$ be an LCH space, let $\mu$ be a Radon measure (or its completion) on $X$. Let $\Phi:C_c(X,\Fbb)\rightarrow L^p(X,\mu,\Fbb)$ be the obvious map. Then $\Phi$ descends to a linear isometry of normed vector spaces
\begin{gather}\label{eq30}
C_c(X,\Fbb)\big/\big\{f\in C_c(X,\Fbb):f=0\text{ $\mu$-a.e.}\big\}\longrightarrow L^p(X,\mu,\Fbb)
\end{gather}
Now assume $p<+\infty$. Then by Thm. \ref{lb14}, the map \eqref{eq30} has dense range. This is often expressed by saying that $C_c(X,\Fbb)\big/\big\{f\in C_c(X,\Fbb):f=0\text{ $\mu$-a.e.}\big\}$ is dense in $L^p(X,\mu,\Fbb)$, or simply that $C_c(X,\Fbb)$ is dense in $L^p(X,\mu,\Fbb)$.
\end{eg}





\subsection{Fundamental properties of bounded multilinear maps}

Let $V_1,V_2,\dots,U,V,W$ be normed vector spaces. In this section, we establish several fundamental properties of bounded multilinear maps that will be used frequently throughout the course. We first note the elementary fact:

\begin{rem}\label{lb29}
Let $U$ be a linear subspace of $V$. Let $R\in\Rbb_{>0}$. Then $U$ is dense in $V$ iff $\ovl B_U(0,R)$ is dense in $\ovl B_V(0,R)$. 
\end{rem}

\begin{proof}
The direction ``$\Leftarrow$" is obvious. Let us prove ``$\Rightarrow$". Let $\xi\in\ovl B_V(0,R)$, choose a sequence $(\xi_n)$ in $U$ converging to $\xi$. Assume WLOG that $\xi\neq0$ and $R\in\Rbb_{>0}$; otherwise, the approximation is obvious. Since the norm function is continuous, $\Vert\xi_n\Vert\rightarrow\Vert\xi\Vert$. In particular, $\Vert\xi_n\Vert$ is eventually nonzero. Thus $\frac{\Vert\xi\Vert}{\Vert\xi_n\Vert}\xi_n\rightarrow \xi$.
\end{proof}

Recall that two sequences $(x_n),(y_n)$ in a metric space $X$ is called \textbf{Cauchy equivalent} \index{00@Cauchy equivalence of two sequences} if $\lim_n d(x_n,y_n)=0$.


\begin{thm}\label{lb31}
Suppose that $W$ is complete. For each $i$, let $U_i$ be a dense linear subspace of $V_i$. Then we have an isomorphism of normed vector spaces
\begin{gather}\label{eq23}
\begin{gathered}
\fk L(V_1\times\cdots\times V_N,W)\xlongrightarrow{\simeq} \fk L(U_1\times\cdots\times U_N,W)\\
T\mapsto T\big|_{U_1\times\cdots\times U_N}
\end{gathered}
\end{gather}
\end{thm}


\begin{proof}
Denote the map \eqref{eq23} by $\Phi$ which is clearly linear. By Rem. \ref{lb29}, $\ovl B_{U_1}(0,1)\times\cdots\times\ovl B_{U_N}(0,1)$ is dense in $\ovl B_{U_1}(0,1)\times\cdots\times\ovl B_{U_N}(0,1)$. This shows that $\Psi$ is a linear isometry, i.e., $T$ and $T\big|_{U_1\times\cdots\times U_N}$ have the same operator norm.

We now show that $\Phi$ is surjective. Here, the completeness of $W$ is need. Let $T\in \fk L(U_1\times\cdots\times U_N,W)$. We want to extend $T$ to a bounded multilinear map $V_1\times\cdots\times V_N\rightarrow W$. We only need to extend $T$ on the first component, i.e., extend $T$ to a bounded multilinear $V_1\times U_2\times U_3\times\cdots\times U_N\rightarrow W$. Then, a similar argument applies to the second component extend $T$ to a bounded multilinear $V_1\times V_2\times U_3\times\cdots\times U_N\rightarrow W$. By repeating this procedure, we obtain bounded multilinear $V_1\times\cdots\times V_N\rightarrow W$ extending $T$.

Let $\xi\in V_1,u_2\in U_2,\dots,u_N\in U_N$. Let $(\xi_n)$ be a sequence in $U_1$ converging to $\xi$. In particular, $(x_n)$ is a Cauchy sequence. By Rem. \ref{lb30}, $T(\xi_n,v_2,\dots,v_N)$ is a Cauchy sequence in $W$. Therefore, by the completeness of $W$, $T(\xi_n,v_2,\dots,v_N)$ converges to some element, which we denote by $T(\xi,v_2,\dots,v_N)$.

Let us show that the definition of $T(\xi,v_2,\dots,v_N)$ is independent of the choice of sequence converging to $\xi$. Suppose that $(\xi_n')$ is another sequence converging to $\xi$. Then $(\xi_n)$ and $(\xi_n')$ are Cauchy equivalent. By Rem. \ref{lb30}, $T(\xi_n,v_2,\dots,v_N)$ and $T(\xi_n',v_2,\dots,v_N)$ are Cauchy equivalent. So they converge to the same element.

Thus, we have defined a map $T:V_1\times U_2\times\cdots\times U_N\rightarrow W$. We leave it to the reader to check that $T$ is bounded multi-linear map.
\end{proof}


\begin{co}\label{lb44}
Let $U$ be a dense linear subspace of $V$. Then we have an isomorphism of normed vector spaces
\begin{gather}
V^*\xlongrightarrow{\simeq} U^*\qquad \varphi\mapsto\varphi|_U
\end{gather}
\end{co}

\begin{proof}
This follows immediate from Thm. \ref{lb31}.
\end{proof}

\begin{eg}\label{lb49}
Let $1\leq q<+\infty$ and $p^{-1}+q^{-1}=1$. Let $X$ be an LCH space. Let $\mu$ be a Radon measure (or its completion) on $X$. By Exp. \ref{lb48}, the $L^q$-seminorm on $C_c(X,\Fbb)$ descends to the $L^q$-norm on $V=C_c(X,\Fbb)/\{f\in C_c(X,\Fbb):f=0\text{ $\mu$-a.e.}\}$, and $V$ is dense in $L^p(X,\mu)$. Therefore, by Thm. \ref{lb13} and Cor. \ref{lb44}, the map \eqref{eq31} gives an isomorphism of normed vector spaces $V^*\simeq L^p(X,\mu)$.
\end{eg}

The following Prop. \ref{lb73} and Thm. \ref{lb72} will imply Thm. \ref{lb80}, which establishes the equivalence of the second and third columns of Table \ref{tb1}.

\begin{pp}\label{lb73}
For each $i$, let $E_i$ be a densely spanning subset of $V_i$. Let $(T_\alpha)$ be a net in $\fk L(V_1\times\cdots\times V_N,W)$ with \textbf{uniformly bounded operator norms}, \index{00@Uniformly bounded operator norms} i.e., $\sup_\alpha\Vert T_\alpha\Vert<+\infty$. Suppose that $T\in\fk L(V_1\times\cdots\times V_N,W)$ and $(T_\alpha)$ converges pointwise on $E_1\times\cdots\times E_N$ to $T$. Then $(T_\alpha)$ converges pointwise on $V_1\times\cdots\times V_N$ to $T$.
\end{pp}

\begin{proof}
Let $U_i=\Span(E_i)$, which is dense in $V_i$. Then $(T_\alpha)$ converges pointwise on $U_1\times\cdots\times U_N$ to $T$.

Choose any $\xi_i\in V_i$. Choose $R\in\Rbb_{>0}$ such that $\Vert\xi_i\Vert\leq R$ for each $i$. Since $\sup_\alpha\Vert T_\alpha\Vert<+\infty$, by Prop. \ref{lb35}, $\{T_\alpha,T:\alpha\in I\}$ has a uniform Lipschitz constant $C\in \Rbb_{\geq0}$ (with respect to the $l^\infty$-product metric) when restricted to $\ovl B_{V_1}(0,R)\times\cdots\times \ovl B_{V_N}(0,R)$. By Rem. \ref{lb29}, for each $\eps>0$, there exists $v_i\in\ovl B_{U_i}(0,R)$ such that $\Vert \xi_i-v_i\Vert\leq\eps$. Then
\begin{align*}
&\limsup_\alpha \Vert T(\xi_1,\dots,\xi_N)-T_\alpha(\xi_1,\dots,\xi_N)\Vert\\
\leq&\limsup_\alpha \Vert T(v_1,\dots,v_N)-T_\alpha(v_1,\dots,v_N)\Vert+2C\eps=2C\eps
\end{align*}
Since $\eps$ is arbitrary, we conclude that $T_\alpha(\xi_1,\dots,\xi_N)\rightarrow T(\xi_1,\dots,\xi_N)$.
\end{proof}



\begin{thm}\label{lb32}
Suppose that $W$ is complete. For each $i$, let $E_i$ be a densely spanning subset of $V_i$. Let $(T_\alpha)$ be a net in $\fk L(V_1\times\cdots\times V_N,W)$ satisfying $\sup_\alpha\Vert T_\alpha\Vert<+\infty$. Suppose that $(T_\alpha)$ converges pointwise on $E_1\times\cdots\times E_N$. Then $(T_\alpha)$ converges pointwise on $V_1\times\cdots\times V_N$ to some $T\in\fk L(V_1\times\cdots\times V_N,W)$, and 
\begin{align}\label{eq37}
\Vert T\Vert\leq\liminf_\alpha\Vert T_\alpha\Vert
\end{align}
\end{thm}

Inequality \eqref{eq37} is sometimes referred to as \textbf{Fatou's lemma}.


\begin{proof}
Let $U_i=\Span(E_i)$, which is dense in $V_i$. Let $T:U_1\times\cdots\times U_N\rightarrow W$ be the pointwise limit of $(T_\alpha)_{\alpha\in I}$ restricted to $U_1\times\cdots\times U_N$, which is clearly linear. Moreover, for each $v_i\in\ovl B_{U_i}(0,1)$ we have
\begin{align*}
\Vert T(v_1,\dots,v_N)\Vert=\liminf_\alpha \Vert T_\alpha(v_1,\dots,v_N)\Vert\leq \liminf_\alpha \Vert T_\alpha\Vert
\end{align*}
Taking $\sup$ over all $v_i\in\ovl B_{U_i}(0,1)$, we see that $\Vert T\Vert\leq\sup_\alpha\Vert T_\alpha\Vert<+\infty$. In particular, $T\in\fk L(U_1\times\cdots\times U_N,W)$. By Thm. \ref{lb31}, $T$ can be extended to a bounded multilinear map $T:V_1\times\cdots\times V_N\rightarrow W$ with $\Vert T\Vert$ unchanged. By Prop. \ref{lb73}, this extended $T$ is the pointwise limit of $(T_\alpha)$ on the whole domain $V_1\times\cdots\times V_N$. 
\end{proof}


\begin{rem}\label{lb36}
Recall that if $X$ is a set, then $l^\infty(X,W)$, equipped with the $l^\infty$-norm, is a normed vector space.

By the definition of operator norms, we have a linear isometry of normed vector spaces
\begin{gather}\label{eq24}
\begin{gathered}
\fk L(V_1\times\cdots\times V_N,W)\rightarrow l^\infty(\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1),W)\\
T\mapsto T|_{\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1)}
\end{gathered}
\end{gather}
Therefore, by identifying $\fk L(V_1\times\cdots\times V_N,W)$ with its image under \eqref{eq24}, we view $\fk L(V_1\times\cdots\times V_N,W)$ as a normed vector subspace of $l^\infty(\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N},W)$. 

Consequently, if $(T_\alpha)$ is a net in $\fk L(V_1\times\cdots\times V_N,W)$, and if $T\in\fk L(V_1\times\cdots\times V_N,W)$, then $\lim_\alpha\Vert T-T_\alpha\Vert=0$ is equivalent to that $(T_\alpha)$ converges uniformly to $T$ on $\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1)$.  \hqed
\end{rem}




\begin{thm}\label{lb37}
$\fk L(V_1\times\cdots\times V_N,W)$ is a closed linear subspace of $l^\infty(\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1),W)$. 
\end{thm}

\begin{proof}
Let $T\in l^\infty(\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1),W)$ be the limit of a sequence $(T_n)$ in $\fk L(V_1\times\cdots\times V_N,W)$. Then $(T_n)$ converges uniformly on $\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1)$ to $T$. By scaling the vectors, we see that $(T_n)$ converges uniformly on $\ovl B_{V_1}(0,R)\times\cdots\times\ovl B_{V_N}(0,R)$ for any $R>0$. Let $T:V_1\times\cdots\times V_N\rightarrow W$ be the pointwise limit of $(T_n)$, which automatically extends the original $T$ defined on $\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1)$.

Since each $T_n$ is multilinear, clearly $T$ is multilinear. Thus $T\in\fk L(V_1\times\cdots\times V_N,W)$. This proves that $\fk L(V_1\times\cdots\times V_N,W)$ is a closed.
\end{proof}


\begin{co}\label{lb39}
Suppose that $W$ is complete. Then $\fk L(V_1\times\cdots\times V_N,W)$ is complete.
\end{co}

\begin{proof}
Since $W$ is complete, by the following Prop. \ref{lb38}, $l^\infty(\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N},W)$ is complete. Since any closed subset of a complete space is complete, by Thm. \ref{lb37}, $\fk L(V_1\times\cdots\times V_N,W)$ is complete.
\end{proof}



\begin{pp}\label{lb38}
Suppose that $W$ is complete. Then for each $1\leq p\leq+\infty$, the normed vector space $l^p(X,W)$ is complete.
\end{pp}

\begin{proof}
Let $(f_n)$ be a Cauchy sequence in $l^p(X,W)$. Then for each $x\in X$, $(f_n(x))$ is a Cauchy sequence in $W$, and hence converges to some $f(x)\in W$. This defines $f:X\rightarrow W$. 

Case $p=+\infty$: For each $\eps>0$, choose $N\in\Zbb_+$ such that for all $m,n\geq N$ we have $\Vert f_n-f_m\Vert_{l^\infty}\leq\eps$, i.e.,  $\Vert f_n(x)-f_m(x)\Vert\leq\eps$ for every $x\in X$.  Applying $\lim_{m\rightarrow\infty}$, we get $\Vert f_n(x)-f(x)\Vert\leq\eps$ for all $x\in X$ and $n\geq N$. Thus, for all $n\geq N$ we have $\Vert f_n-f\Vert_{l^\infty}\leq \eps$; in particular, we have $f\in l^\infty(X,W)$. Thus $\Vert f_n-f\Vert_{l^\infty}\rightarrow0$.

Case $p<+\infty$: For each $\eps>0$, choose $N\in\Zbb_+$ such that for all $m,n\geq N$ we have $\Vert f_n-f_m\Vert_{l^p(X)}\leq\eps$, equivalently, $\Vert f_n-f_m\Vert_{l^p(A)}\leq\eps$ for each $A\in\fin(2^X)$. Applying $\lim_{m\rightarrow\infty}$, we get $\Vert f_n-f\Vert_{l^p(A)}\leq\eps$ for all $n\geq N$ and $A\in\fin(2^X)$. Thus $\Vert f_n-f\Vert_{l^p(X)}\leq\eps$ for all $n\geq N$; in particular, we have $f\in l^p(X,W)$. This proves $\Vert f_n-f\Vert_p\rightarrow0$.
\end{proof}


\begin{co}\label{lb128}
The dual space $V^*$, equipped with the operator norm, is complete.
\end{co}


\begin{proof}
This follows immediately from Cor. \ref{lb39}.
\end{proof}




\subsection{The roles of completeness and duality}\label{lb43}

Let $V_1,\dots,V_N$ and $V,W$ be normed vector spaces.


\subsubsection{The role of Cauchy completeness}\label{lb141}



In functional analysis, Cauchy completeness plays two primary roles:
\begin{enumerate}
\item Completeness as a domain property, where it is often used in conjunction with the Baire category theorem.
\item Completeness as a codomain property, which ensures that linear operators can be restricted from the whole space to a dense subspace without loss. Thm. \ref{lb31} and \ref{lb32} are typical examples illustrating this usage.
\end{enumerate}



Among these two, completeness as a codomain is the more widely encountered in practice. This suggests that \uwave{the recognition and widespread appreciation of \textbf{Cauchy completeness} in function spaces developed alongside the study of linear operators}---that is, linear maps from $V$ to $W$---rather than with linear, bilinear, or multilinear functionals, such as $V\times W\rightarrow\Fbb$. In the early days of functional analysis, particularly in Hilbert’s foundational work \cite{Hil06}, the dominant perspective was centered not on linear operators, but on bilinear forms and linear functionals. Within this (bi)linear framework, completeness is not required---indeed, in Thm \ref{lb31}, \ref{lb32}, and Corollary \ref{lb39}, when $W=\Fbb$, none of the remaining vector spaces involved (namely $V_1,\dots,V_N$) are assumed to be complete.


Historically, the focus on bilinear forms gradually gave way to the linear operator viewpoint. As this shift took place, Cauchy completeness came to occupy a central role in functional analysis. The fact that the bilinear form or multilinear functional viewpoint can be reformulated in terms of linear operators is a consequence of the following elementary observation:



\begin{pp}\label{lb40}
Let $U_1,\dots,U_M$ be normed vector spaces. Then we have an isomorphism of normed vector spaces
\begin{gather}\label{eq25}
\begin{gathered}
\fk L(U_1\times\cdots\times U_M\times V_1\times\cdots\times V_N,W)\xlongrightarrow{\simeq}\fk L(U_1\times\cdots\times U_M,\fk L(V_1\times\cdots\times V_N,W))\\
T\mapsto \Big((u_1,\dots,u_M)\mapsto T(u_1,\dots,u_M,-,\dots,-)\Big)
\end{gathered}
\end{gather}
where $T(u_1,\dots,u_M,-,\dots,-)$ denotes the multilinear map $V_1\times\cdots\times V_N\rightarrow W$ sending $(v_1,\dots,v_N)$ to $T(u_1,\dots,u_M,v_1,\dots,v_N)$.
\end{pp}

\begin{proof}
It is easy to verify that the second line of \eqref{eq25} defines a linear isomorphism
\begin{align*}
\Psi:&\Lin(U_1\times\cdots\times U_M\times V_1\times\cdots\times V_N,W)\\
&\xlongrightarrow{\simeq}\Lin(U_1\times\cdots\times U_M,\Lin(V_1\times\cdots\times V_N,W))
\end{align*}
To explain the idea of comparing the operator norms, we assume for simplicity that $M=N=1$, and write $U_1=U$ and $V_1=V$. 

Choose any $T\in\Lin(U\times V,W)$. Then $\Psi(T):U\rightarrow\Lin(V,W)$ sends each $u\in V$ to the linear map
\begin{align*}
\Psi(T)(u):v\in\Lin(V,W)\mapsto T(u,v)
\end{align*}
Thus, for each $u\in U$ and $v\in V$, we have
\begin{align*}
\Vert T(u,v)\Vert=\Vert \Psi(T)(u)(v)\Vert\leq \Vert \Psi(T)(u)\Vert\cdot \Vert v\Vert\leq\Vert\Psi(T)\Vert\cdot\Vert u\Vert\cdot\Vert v\Vert
\end{align*}
This proves $\Vert T\Vert\leq\Vert\Psi(T)\Vert$. Conversely, for each $u\in U$,
\begin{align*}
&\Vert \Psi(T)(u)\Vert=\sup_{v\in\ovl B_V(0,1)}\Vert\Psi(T)(u)(v)\Vert=\sup_{v\in\ovl B_V(0,1)}\Vert T(u,v)\Vert\\
\leq&\sup_{v\in\ovl B_V(0,1)}\Vert T\Vert\cdot\Vert u\Vert\cdot\Vert v\Vert=\Vert T\Vert\cdot\Vert u\Vert
\end{align*}
This proves $\Vert\Psi(T)\Vert\leq\Vert T\Vert$. 

We have proved that $\Vert\Psi(T)\Vert=\Vert T\Vert$. In particular, if $T$ is bounded, then $\Psi(T)(u)$ is bounded for each $u\in U$, and $\Psi(T)$ is bounded. Conversely, if $\Psi(T)(u)$ is bounded for each $u$, and if $\Psi(T)$ is bounded, then $T$ is bounded. This proves that $\Psi$ restricts to the linear isomorphism \eqref{eq25}, which is an isometry because $\Vert\Psi(T)\Vert=\Vert T\Vert$.
\end{proof}


\subsubsection{The role of duality}\label{lb132}


The following two corollaries follow immediate from Prop. \ref{lb40}.

\begin{co}\label{lb134}
We have an isomorphism of normed vector spaces
\begin{gather}
\fk L(U\times V,\Fbb)\xlongrightarrow{\simeq}\fk L(U,V^*)\qquad T\mapsto\big(u\mapsto T(u,-)\big)
\end{gather}
\end{co}


\begin{co}\label{lb42}
Suppose that $V$ is the dual space of another normed vector space $V_*$. Then we have an isomorphism of normed vector spaces
\begin{gather}
\fk L(V\times V_*,\Fbb)\xlongrightarrow{\simeq}\fk L(V)\qquad T\mapsto\big(v\mapsto T(v,-)\big)
\end{gather}
\end{co}


In Sec. \ref{lb24} and \ref{lb41}, we explored the motivation for introducing dual spaces from the perspectives of the calculus of variations and moment problems. Cor. \ref{lb42} now offers yet another compelling reason for the study of duality: when a space $V$ possesses a \textbf{dual structure}---specifically, \uwave{when $V$ is the dual of some normed space $V_*$---it allows us to approach problems from both the bilinear form and linear operator perspectives}. 

What are the respective advantages of these two viewpoints? To address this, I would like to revisit the arguments presented in \cite{Gui-A}, particularly in the Introduction and in Ch. 21 and 25 of \cite{Gui-A}:


\begin{enumerate}
\item The bilinear form framework allows us to draw upon the full strength of measure theory. In fact, measure theory can be understood as a method of \textbf{monotone convergence extension}---a procedure for extending linear functionals in such a way that the monotone convergence theorem (or its variants) holds. \index{00@Monotone convergence extension} This type of extension aligns naturally with the structure of bilinear forms.
\item The space $\fk L(V)$ of bounded linear operators on $V$ is not just a vector space but also an algebra, with multiplication given by composition. This algebraic structure enables the use of \textbf{symbolic calculus}, a technique developed in the mid-19th century in the study of linear algebras, and it connects directly to the representation-theoretic perspectives that flourished in the 20th century.
\end{enumerate}

As discussed in \cite[Sec. 25.8, 25.9]{Gui-A}, and as we will also explore in Ch. \ref{lb114}, Riesz’s spectral theorem provides a striking example of how these two advantages can be fruitfully combined.



\subsection{Dual spaces and the weak-* topology}


Let $V_1,V_2,\dots,U,V,W$ be normed $\Fbb$-vector spaces.


\begin{df}
By viewing $V^*$ as a subset of $\Cbb^V$, the subspace topology on $V^*$ inherited from the product topology of $\Cbb^V$ is called the \textbf{weak-* topology} \index{00@Weak-* topology} on $V^*$. By Thm. \ref{lb50}, this is the unique topology such that for any net $(\varphi_\alpha)$ in $V^*$ and any $\varphi\in V$, the net $(\varphi_\alpha)$ \textbf{converges weak-*} \index{00@Weak-* convergence} to $\varphi$---that is, converges to $\varphi$ in the weak-* topology---iff 
\begin{align}\label{eq49}
\lim_\alpha\bk{\varphi_\alpha,v}=\bk{\varphi,v}\qquad\text{for any }v\in V
\end{align}
Since $\Cbb^V$ is Hausdorff, the weak-* topology is also Hausdorff.
\end{df}



Weak-* topology is mainly considered for closed balls of $V^*$, rather than the whole dual space $V^*$, because for such subsets, pointwise convergence of moments is equivalent to weak-* convergence---that is, the second and third columns of Table \ref{tb1} are equivalent. This equivalence is formally stated in the following theorem.

\begin{thm}\label{lb80}
Suppose that $E$ is a densely spanning subset of $V$. Let $(\varphi_\alpha)$ be a net in $V^*$ satisfying $\sup_\alpha\Vert\varphi_\alpha\Vert<+\infty$. Then $(\varphi_\alpha)$ converges weak-* in $V^*$ iff the limit $\lim_\alpha\bk{\varphi_\alpha,v}$ exists for any $v\in E$. 

Moreover, if  $\varphi\in V^*$ satisfies that
\begin{align*}
\lim_\alpha\bk{\varphi_\alpha,v}=\bk{\varphi,v}\qquad\text{for any }v\in E
\end{align*}
then $(\varphi_\alpha)$ converges weak-* to $\varphi$.
\end{thm}

\begin{proof}
This is clear from Prop. \ref{lb73} and  Thm. \ref{lb32}.
\end{proof}


\begin{rem}\label{lb96}
Let $U$ be a dense linear subspace of $V$. (For example, take $V=C_0(X,\Fbb)$ and $U=C_c(X,\Fbb)$.) Recall the canonical isomorphism $V^*\simeq U^*$ given in Cor. \ref{lb44}. Then by Prop. \ref{lb80}, for each $R\in\Rbb_{\geq0}$, the weak-* topology on $\ovl B_{V^*}(0,R)$ agrees with the weak-* topology on $\ovl B_{U^*}(0,R)$. However, the weak-* topology on $V^*$ is in general not equal to the weak-* topology on $U^*$. 
\end{rem}



In Prop. \ref{lb80}, one might further ask whether a net $(\varphi_\alpha)$ in $\ovl B_{V^*}(0,R)$ that converges weak-* has its limit also in $\ovl B_{V^*}(0,R)$. The answer is yes:

\begin{pp}[\textbf{Fatou's lemma for weak-* convergence}]\index{00@Fatou's lemma for weak-* convergence}\label{lb106}
Let $(\varphi_\alpha)$ be a net in $V^*$ converging weak-* to some $\varphi\in V^*$. Then
\begin{align}\label{eq36}
\Vert\varphi\Vert\leq\liminf_\alpha\Vert\varphi_\alpha\Vert
\end{align}
In other words, the norm function $\Vert\cdot\Vert:V^*\rightarrow\Rbb_{\geq0}$ is lower semicontinuous with respect to the weak-* topology on $V^*$.
\end{pp}


In contrast, if $(\varphi_\alpha)$ converges in the operator norm to $\varphi$, then $\Vert\varphi\Vert=\lim_\alpha\Vert\varphi_\alpha\Vert$. Cf. Rem. \ref{lb59}.


\begin{proof}
For each $v\in\ovl B_V(0,1)$, we have
\begin{align*}
|\bk{\varphi,v}|=\lim_\alpha |\bk{\varphi_\alpha,v}|=\liminf_\alpha |\bk{\varphi_\alpha,v}|\leq\liminf_\alpha\Vert\varphi_\alpha\Vert\cdot\Vert v\Vert=\Vert\varphi_\alpha\Vert
\end{align*}
Applying $\sup_{v\in\ovl B_V(0,1)}$ to the LHS above yields \eqref{eq36}. (See also Thm. \ref{lb32}.)
\end{proof}



\begin{thm}[\textbf{Banach-Alaoglu theorem}]\index{00@Banach-Alaoglu theorem}\label{lb60}
$\ovl B_{V^*}(0,1)$ is \textbf{weak-* compact}---that is, it is compact in the weak-* topology. \index{00@Weak-* compact}
\end{thm}

Thus, $\ovl B_{V^*}(0,1)$ is a compact Hausdorff space.


\begin{proof}[\textbf{First proof}]
Let $(\varphi_\alpha)$ be a net $\ovl B_{V^*}(0,1)$. Since $|\bk{\varphi_\alpha,v}|\leq\Vert v\Vert$ for each $v\in V$, we can view $(\varphi_\alpha)$ as a net in
\begin{align*}
S=\prod_{v\in V} \ovl B_\Fbb(0,\Vert v\Vert)
\end{align*}
By Tychonoff's Thm. \ref{lb61}, $S$ is compact. Therefore, $(\varphi_\alpha)$ has a subnet $(\varphi_{\alpha_\mu})$ converging pointwise on $V$ to some function $\varphi:V\rightarrow\Fbb$. The function $\varphi$ is clearly linear and satisfies $\Vert\varphi\Vert\leq\sup_\mu\Vert\varphi_{\alpha_\mu}\Vert\leq 1$, cf. Thm. \ref{lb32}.  Thus $(\varphi_{\alpha_\mu})$ converges weak-* to $\varphi\in\ovl B_{V^*}(0,1)$. This finishes the proof that $\ovl B_{V^*}(0,1)$ is compact.
\end{proof}

The above proof relies on Tychonoff's theorem, which in turn relies on Zorn's lemma. When $V$ is separable, one can prove the Banach-Alaoglu theorem without using Zorn's lemma:

\begin{proof}[\textbf{Second proof assuming that $V$ is separable}]
Let $E$ be a countable dense subset of $V$. Then
\begin{align*}
\Phi:\ovl B_{V^*}(0,1)\rightarrow\Fbb^E\qquad\varphi\mapsto\varphi|_E
\end{align*}
is injective. Moreover, if $(\varphi_\alpha)$ is a net in $\ovl B_{V^*}(0,1)$ and $\varphi\in\ovl B_{V^*}(0,1)$, then Prop. \ref{lb73} indicates that $(\varphi_\alpha)$ converges weak-* to $\varphi$ iff $(\varphi_\alpha)$ converges pointwise on $E$ to $\varphi$. Therefore, $\Phi$ restricts to a homeomorphism from $\ovl B_{V^*(0,1)}$ to its image. Thus, since $\Fbb^E$ is metrizable (cf. Prop. \ref{lb51}), so is any subset---in particular, $\ovl B_{V^*}(0,1)$. 

Therefore, showing that $\ovl B_{V^*}(0,1)$ is compact is equivalent to showing that it is sequentially compact. Let $(\varphi_n)$ be a sequence in $\ovl B_{V^*}(0,1)$. By the diagonal method (cf. Rem. \ref{lb52}), $(\varphi_n)$ has a subsequence $(\varphi_{n_k})$ converging pointwise on $E$. Thm. \ref{lb32} now implies that $(\varphi_{n_k})$ converges weak-* to some $\varphi\in\ovl B_{V^*}(0,1)$.
\end{proof}


The above proof shows that if $V$ is separable, then $\ovl B_{V^*}(0,1)$ is metrizable and therefore sequentially compact under the weak-* topology. The converse is also true:

\begin{thm}\label{lb76}
The following statements are equivalent.
\begin{enumerate}[label=(\alph*)]
\item The normed vector space $V$ is separable.
\item When equipped with the weak-* topology, the compact Hausdorff space $\ovl B_{V^*}(0,1)$ is metrizable. 
\end{enumerate}
\end{thm}


\begin{proof}
(a)$\Rightarrow$(b) has been proved above. Here, we give a more direct argument of the equivalence (a)$\Rightarrow$(b). By the following Lem. \ref{lb74}, $V$ can be viewed as a subset of $C(X,\Fbb)$ where $X=\ovl B_{V^*}(0,1)$ is compact by Banach-Alaoglu. Clearly $V$ separates the points of $X$. Therefore, if $V$ is separable, then $X$ is metrizable by (c)$\Rightarrow$(a) of Thm. \ref{lb75}. Conversely, if $X$ is metrizable, then $C(X,\Fbb)$ is separable the (a)$\Rightarrow$(d) of Thm. \ref{lb75}. Therefore, the subset $V$ of $C(X,\Fbb)$ is also separable.
\end{proof}

\begin{lm}\label{lb74}
For each $\varphi\in V$, the function
\begin{align*}
\ovl B_{V^*}(0,1)\rightarrow\Fbb\qquad \varphi\mapsto \bk{\varphi,v}
\end{align*}
is continuous with respect to the weak-* topology.
\end{lm}


\begin{proof}
This is clear by \eqref{eq49}.
\end{proof}


\begin{rem}
When $V$ is separable, a metric $d$ generating the weak-* topology of $\ovl B_{V^*}(0,1)$ can be explicitly given: Let $(v_n)_{n\in\Zbb_+}$ be a dense sequence in $V$. Replacing $v_n$ with $v_n/\Vert v_n\Vert$ if $v_n\neq 0$, we assume that $\Vert v_n\Vert\leq 1$. Then, by \eqref{eq35}, the metric $d$ can be chosen to be
\begin{align}
d(\varphi_1,\varphi_2)=\sum_{n\in\Zbb_+}2^{-n}|\varphi_1(v_n)-\varphi_2(v_n)|\qquad\text{for each }\varphi_1,\varphi_2\in \ovl B_{V^*}(0,1)
\end{align}
\end{rem}





\subsection{Weak-* convergence in $L^p$-spaces}

Let $(X,\fk M,\mu)$ be a $\sigma$-finite measure space.\footnote{The condition on $\sigma$-finiteness can be removed at least when $p=2$. See the paragraph after Thm. \ref{lb13}.} Let $I\subset\Rbb$ be a closed proper interval. Let $1<p\leq+\infty$ and $p^{-1}+q^{-1}=1$. 

We identify $L^p(X,\mu,\Fbb)$ with the dual space $L^q(X,\mu,\Fbb)^*$ via the isomorphism described in Thm. \ref{lb13}. This defines the \textbf{weak-* topology on \pmb{$L^p(X,\mu,\Fbb)$}} \index{00@Weak-* topology on $L^p(X,\mu,\Fbb)$}. In particular, a net $(f_\alpha)$ in $L^p(X,\mu,\Fbb)$ converges weak-* to $f\in L^p(X,\mu,\Fbb)$ iff
\begin{align*}
\lim_\alpha\int_X f_\alpha gd\mu=\int_Xfgd\mu\qquad\text{for all }g\in L^q(X,\mu,\Fbb)
\end{align*}


\subsubsection{Pointwise convergence and weak-* convergence}


Let us prove Thm. \ref{lb12} in a slightly more general setting. Note that a finite Borel measure $\mu$ on an interval $I\subset\Rbb$ can be extended by zero to a finite Borel measure on $\Rbb$, which is Radon by Thm. \ref{lb64}. Therefore, to generalize Thm. \ref{lb12}, it suffices to consider finite Borel (equivalently, finite Radon) measures on $\Rbb$.

\begin{thm}\label{lb78}
Let $\mu$ be a finite Borel measure on $\Rbb$. Let $(f_\alpha)$ be a net in $L^p(\Rbb,\mu,\Fbb)$ satisfying $\sup_\alpha\Vert f_\alpha\Vert_{L^p}<+\infty$. Then $(f_\alpha)$ converges weak-* to some element $f\in L^p(\Rbb,\mu,\Fbb)$  iff the following limit exists for every $x\in \Rbb$:
\begin{align}\label{eq50}
F(x):=\lim_\alpha \int_{(-\infty,x]} f_\alpha d\mu
\end{align}
When $(f_\alpha)$ converges weak-* to $f\in L^p(\Rbb,\mu,\Fbb)$, for each $x\in\Rbb$ we have
\begin{align}\label{eq51}
F(x)=\int_{(-\infty,x]} fd\mu
\end{align}
\end{thm}

Note that since $\mu$ is finite, the constant function $1$ belongs to $L^q$. Therefore, by H\"older's inequality, any function in $L^p(\Rbb,\mu,\Fbb)$ is integrable.

\begin{proof}
First, assume that $(f_\alpha)$ converges weak-* to $f$ in $L^p(\Rbb,\mu,\Fbb)$. Then for each $x\in\Rbb$, we have $\lim_\alpha \int f_\alpha\chi_{(-\infty,x]}d\mu=\int f\chi_{(-\infty,x]}d\mu$. This proves that \eqref{eq50} exists and \eqref{eq51} holds.

Next, we assume that \eqref{eq50} exists for every $x$. In the following, we give two proofs of the weak-* convergence of $(f_\alpha)$.\\[-1ex]

First proof. Let $\varphi_\alpha\in L^q(\Rbb,\mu,\Fbb)^*$ be the linear functional associated to $f_\alpha$, i.e., $\bk{\varphi_\alpha,g}=\int f_\alpha gd\mu$ for each $g\in L^q$. By assumption, $\varphi_\alpha$ converges when evaluated with any member of
\begin{align*}
\mc E=\Span_\Fbb\{\chi_{(-\infty,x]}:x\in\Rbb\}
\end{align*}
By Thm. \ref{lb77}, $\mc E$ is dense in $L^q$. Therefore, since
\begin{align*}
\sup_\alpha\Vert\varphi_\alpha\Vert=\sup_\alpha \Vert f_\alpha\Vert_p<+\infty
\end{align*}
by Thm. \ref{lb80}, $(\varphi_\alpha)$ converges weak-* to some $\varphi\in (L^q)^*$. By Thm. \ref{lb13}, $\varphi$ is represented by some $f\in L^p(\Rbb,\mu,\Fbb)$. Thus $(f_\alpha)$ converges weak-* to $f$.\\[-1ex]

Second proof. In this proof, we use the fact that any bounded closed ball of $L^p(\Rbb,\mu,\Fbb)$ is weak-* compact, which is due to Thm. \ref{lb13} and the Banach-Alaoglu theorem.  

Since $\sup_\alpha \Vert f_\alpha\Vert_p<+\infty$, the net $(f_\alpha)$ has a subnet $(f_{\alpha_\nu})$ converging weak-* to some $f\in L^p$. By the first paragraph, for each $x\in\Rbb$ we have
\begin{align*}
\lim_\nu\int_{(-\infty,x]}f_{\alpha_\nu} d\mu=\int_{(-\infty,x]}fd\mu
\end{align*} 
Since \eqref{eq50} converges, we conclude
\begin{align*}
\lim_\alpha\int_{(-\infty,x]}f_\alpha d\mu=\int_{(-\infty,x]}fd\mu
\end{align*} 
That is, if we let $\varphi_\alpha\in(L^q)^*$ represent $f_\alpha$ and let $\varphi\in(L^q)^*$ represent $f$, then $(\varphi_\alpha)$ converges to $\varphi$ when evaluated on $\mc E$. By Thm. \ref{lb77}, $\mc E$ is dense in $L^q$. Therefore, by Thm. \ref{lb80}, $(\varphi_\alpha)$ converges weak-* to $\varphi$. That is, $(f_\alpha)$ converges weak-* to $f$. 
\end{proof}


We now present another connection between pointwise convergence and weak-* convergence.


\begin{thm}\label{lb81}
Let $(f_n)$ be a sequence in $L^p(X,\mu,\Fbb)$ satisfying $\sup_n\Vert f_n\Vert_p<+\infty$. Suppose that $(f_n)$ converges pointwise to $f$. Then $f\in L^p(X,\mu,\Fbb)$, and $(f_n)$ converges weak-* to $f$.
\end{thm}


\begin{proof}
By Fatou's lemma, we have $f\in L^p$, since
\begin{align*}
\int |f|^p\leq\liminf_n\int |f_n|^p<+\infty
\end{align*}
Thm. \ref{lb78} suggests that when $X=\Rbb$ and $\mu$ is a finite Borel measure, to prove that $(f_n)$ converges weak-* to $f$, it suffices to verify that $\lim_n \int_{(-\infty,x]}f_n=\int_{(-\infty,x]}f$ for each $x\in\Rbb$. Motivated by this, we claim that in the general case, it suffices to prove
\begin{align}\label{eq52}
\lim_n \int_E f_nd\mu=\int_E fd\mu
\end{align}
for each $E\in\fk M$ satisfying $\mu(E)<+\infty$. (Note that any $L^p$ function is integrable in $E$ by H\"older's inequality.) Indeed, suppose \eqref{eq52} is true. Then, by the density of integrable simple functions in $L^p$ (Thm. \ref{lb79}), and by Thm. \ref{lb80}, the sequence $(f_n)$ converges weak-* to $f$.

Let us prove \eqref{eq52}. For each $\lambda\geq0$, let $\alpha_\lambda:\Rbb_{\geq0}\rightarrow[0,1]$ be the (continuous) piecewise linear increasing function such that $\alpha_\lambda|_{[0,\lambda]}=0$ and $\alpha_\lambda|_{[\lambda+1,+\infty)}=1$. Let $\beta_\lambda=1-\alpha_\lambda$. Since $0\leq\alpha_\lambda\leq\chi_{[\lambda,+\infty)}$, we have
\begin{align*}
\lambda^{p-1}\alpha_\lambda\leq\lambda^{p-1}\chi_{[\lambda,+\infty)}\leq x^{p-1}
\end{align*}
where $x$ denotes the identity function $\id:\Rbb_{\geq0}\rightarrow\Rbb_{\geq0}$. Hence $\lambda^{p-1}x\alpha_\lambda\leq x^p$, which implies $\lambda^{p-1}|f_n|(\alpha_\lambda\circ|f_n|)\leq|f_n|^p$. Let $C:=\sup_n\int_E|f_n|^p$. Then
\begin{align*}
\lambda^{p-1}\sup_n\int_E |f_n|\cdot(\alpha_\lambda\circ|f_n|)\leq \sup_n\int_E|f_n|^p=C<+\infty
\end{align*}
Therefore, $(f_n)$ is \textbf{uniformly integrable} on $E$, which means that for each $\eps>0$ we have
\begin{align*}
\sup_n\int_E |f_n|\cdot(\alpha_\lambda\circ|f_n|)\leq\eps\qquad\text{for sufficiently large }\lambda
\end{align*}
Since $|f|\cdot(\alpha_\lambda\circ|f|)$ decreases to $0$ as $\lambda\rightarrow+\infty$, and since $\int_E|f|<+\infty$ (due to H\"older's inequality), by DCT or MCT, 
\begin{align*}
\int_E |f|\cdot(\alpha_\lambda\circ|f|)\leq\eps\qquad\text{for sufficiently large }\lambda
\end{align*}

On the other hand, since $0\leq x\beta_\lambda\leq \lambda+1$, and since $\lim_n \beta_\lambda\circ|f_n|$ converges pointwise to $\beta_\lambda\circ|f|$ (due to the continuity of $\beta_\lambda$), by DCT we have
\begin{align*}
\lim_n \int_E f_n\cdot(\beta_\lambda\circ|f_n|)=\int_E f\cdot(\beta_\lambda\circ|f|)
\end{align*}
Therefore, since $\alpha_\lambda+\beta_\lambda=1$,
\begin{align*}
\limsup_n \Big|\int_Ef_n-\int_E f\Big|\leq& \limsup_n \Big|\int_E f_n\cdot(\beta_\lambda\circ|f_n|)-\int_E f\cdot(\beta_\lambda\circ|f|)  \Big|\\
&+\limsup_n\int_E |f_n|\cdot(\alpha_\lambda\circ|f_n|)+\int_E |f|\cdot(\alpha_\lambda\circ|f|)
\end{align*}
where the RHS is $\leq 2\eps$ for sufficiently large $\lambda$.
\end{proof}



\subsubsection{Weak-* approximation by elementary functions}

Let $X$ be an LCH space, and let $\mu$ be a Radon measure (or its completion) on $X$ with $\sigma$-algebra $\fk M$. We assume that $\mu$ is $\sigma$-finite. This condition holds, for example, when $X$ is $\sigma$-compact (in particular, when $X$ is second countable; cf. Rem. \ref{lb84}.)


In this subsection, we examine Principle \ref{lb23} in the context of $L^p$-spaces. We begin with the following observation:

\begin{rem}
Let $V$ be a normed vector space, and let $U$ be a linear subspace of $V^*$. Let $R\in\Rbb_{>0}$. By Rem. \ref{lb29}, $U$ is norm-dense in $V^*$ iff $\ovl B_U(0,R)$ is norm-dense in $\ovl B_{V^*}(0,R)$. 

It is clear from linearity that if $\ovl B_U(0,R)$ is weak-* dense in $\ovl B_{V^*}(0,R)$, then $U$ is weak-* dense in $V^*$. However, the weak-* density of $U$ in $V^*$ does not imply the weak-* density of $\ovl B_U(0,R)$ in $\ovl B_{V^*}(0,R)$. Therefore, when studying weak-* approximation in $V^*$, we aim---when possible---to approximate any $\varphi\in V^*$ by a net $(\varphi_\alpha)$ in $U$ such that $\Vert \varphi_\alpha\Vert\leq\Vert\varphi\Vert$. This ensures not only convergence but also control of norms.  \hqed
\end{rem}


\begin{thm}\label{lb86}
The closed unit ball of $C_c(X,\Fbb)$ is weak-* dense in the closed unit ball of $L^p(X,\mu,\Fbb)$. More precisely, the obvious map $C_c(X,\Fbb)\rightarrow L^p(X,\mu,\Fbb)$ sends $\ovl B_{C_c(X,\Fbb)}(0,1)$ to a weak-* dense subset of $\ovl B_{L^p(X,\mu,\Fbb)}(0,1)$.
\end{thm}


\begin{proof}
By Thm. \ref{lb14}, if $p<+\infty$, then $\ovl B_{C_c(X,\Fbb)}(0,1)$ is norm-dense in $\ovl B_{L^p(X,\mu,\Fbb)}(0,1)$, and hence also weak-* dense.

Now, we assume $p=+\infty$. let $\scr I$ be the directed set
\begin{gather*}
\scr I=\{(\MG,\eps):\MG\in\fin(2^{C_c(X,\Fbb)}),\eps\in\Rbb_{\geq0}\}\\
(\MG_1,\eps_1)\leq(\MG_2,\eps_2)\qquad\text{means}\qquad \MG_1\subset\MG_2,\eps_1\geq\eps_2
\end{gather*}
Fix any $f\in \ovl B_{L^\infty(X,\mu,\Fbb)}(0,1)$. By adding a $\mu$-a.e. zero function to $f$, we assume that $\Vert f\Vert_{l^\infty(X)}=\Vert f\Vert_{L^\infty(X,\mu,\Fbb)}\leq 1$. We claim that for any $(\MG,\eps)\in\scr I$, there exists $f_{\MG,\eps}\in \ovl B_{C_c(X,\Fbb)}(0,1)$ such that
\begin{align*}
\Big| \int_X (f-f_{\MG,\eps})gd\mu\Big|\leq\eps\qquad\text{for all }g\in\MG
\end{align*}
If this is true, then $(f_{\MG,\eps})_{(\MG,\eps)\in\scr I}$ converges to $f$ when integrated against any element of $C_c(X,\Fbb)$. Since $C_c(X,\Fbb)$ is dense in $L^1(X,\mu,\Fbb)$ (Thm. \ref{lb14}), it follows from Thm. \ref{lb80} that $(f_{\MG,\eps})_{(\MG,\eps)\in\scr I}$ converges weak-* to $f$, finishing the proof.

Let us prove the claim. We write $\MG=\{g_1,\dots,g_n\}$. Let $A_i=\Supp(g_i)$ and $A=A_1\cup\cdots\cup A_n$. Since $A$ is compact, we have $\mu(A)<+\infty$. Let $M=\Vert g_1\Vert_\infty+\cdots+\Vert g_n\Vert_\infty$. By Lusin's Thm. \ref{lb82} and the Tietze extension Thm. \ref{lb83}, there exist a compact set $K\subset A$ and a function $f_{\MG,\eps}\in C_c(X,\Fbb)$ satisfying
\begin{align*}
f_{\MG,\eps}|_K=f|_K\qquad\Vert f_{\MG,\eps}\Vert_{l^\infty}=\Vert f\Vert_{l^\infty}\qquad \mu(A\setminus K)\leq\eps/2M
\end{align*}
Recall that $\Vert f\Vert_{l^\infty}\leq 1$. Thus, for each $1\leq i\leq n$, we have
\begin{align*}
&\Big| \int_X (f-f_{\MG,\eps})g_i\Big|=\Big| \int_{A\setminus K} (f-f_{\MG,\eps})g_i\Big|\leq M\int_{A\setminus K}(|f|+|f_{\MG,\eps}|)\\
\leq&2M\cdot \mu(A\setminus K)\leq \eps
\end{align*}
\end{proof}


\begin{co}
Let $\mu$ be a finite Borel measure on $\Sbb^1$. Let $U=\Span_\Cbb\{e_n:n\in\Zbb\}$ where $e_n:z\in\Sbb^1\mapsto z^n\in\Cbb$. Then for each $f\in L^p(\Sbb^1,\mu)$, there exists a sequence $(f_n)$ in $U$ converging weak-* to $f$ and satisfying $\sup_n\Vert f\Vert_{L^p}\leq\Vert f\Vert_{L^p}$.
\end{co}

\begin{proof}
By Thm. \ref{lb85}, the normed vector space $V=L^q(\Sbb^1,\mu)$ is separable. Therefore, by Thm. \ref{lb76}, the weak-* topology of $\ovl B_{L^q(\Sbb^1,\mu)}(0,1)$ is metrizable. Therefore, to prove the corollary, it suffices to show that $\ovl B_U(0,1)$ is weak-* dense in $\ovl B_{L^q(\Sbb^1,\mu)}(0,1)$. 

By Thm. \ref{lb86}, $\ovl B_{C(\Sbb^1)}(0,1)$ is weak-* dense in $\ovl B_{L^q(\Sbb^1,\mu)}(0,1)$. By the Stone-Weierstrass Thm. \ref{lb87}, $U$ is $l^\infty$-dense (and hence $L^p$-dense) in $C(\Sbb^1)$. Thus, $\ovl B_U(0,1)$ is $L^p$-norm-dense (and hence weak-* dense) in $\ovl B_{C(\Sbb^1)}(0,1)$. This finishes the proof.
\end{proof}



\subsection{Weak-* convergence in $l^p$-spaces}



Let $X$ be a set, and let $1\leq p\leq+\infty$ and $p^{-1}+q^{-1}=1$. In this section, we prove the equivalence of the first two columns of Table \ref{tb1} for $V=L^q(X,\Fbb)$, cf. Thm. \ref{lb111}. The most important case is when $X$ is countable and $p=q=2$. For example, $l^2(\Zbb^n)$ corresponds to the space of Fourier coefficients of $L^2$-functions on $\mathbb T^n:=(\Sbb^1)^n$.

%The key reason that the duality $(l^q)^*\simeq l^p$ does not how for $p=+\infty$ is due to the fact that the following lemma does not hold when $p=+\infty$.







\subsubsection{The linear isometry $l^p(X,\Fbb)\rightarrow l^q(X,\Fbb)^*$}

\begin{pp}\label{lb109}
Assume that $1\leq p<+\infty$. Then $C_c(X,\Fbb)$ is dense in $l^p(X,\Fbb)$, where
\begin{align}\label{eq60}
C_c(X,\Fbb):=\{f\in\Fbb^X:\Supp(f)\text{ is a finite set}\}
\end{align}
\end{pp}

The notation of $C_c(X,\Fbb)$ in \eqref{eq60} is compatible with our usual notation for LCH spaces if $X$ is equipped with the discrete topology $\mc T_X=2^X$.

\begin{proof}
Choose $f\in l^p(X,\Fbb)$. Then, since
\begin{align*}
\lim_{A\in\fin(2^X)}\sum_A|f|^p=\sum_X|f|^p
\end{align*}
we have
\begin{align*}
\lim_{A\in\fin(2^X)} \Vert f-f\chi_A\Vert_{l^p}^p=\lim_{A\in\fin(2^X)}\sum_{X\setminus A}|f|=\sum_X|f|^p-\lim_{A\in\fin(2^X)}\sum_A|f|^p=0
\end{align*}
Thus, $(f\chi_A)_{A\in\fin(2^X)}$ is a net in $C_c(X,\Fbb)$ converging to $f$.
\end{proof}




\begin{rem}\label{lb108}
We have a linear map
\begin{gather}\label{eq58}
\begin{gathered}
\Psi:l^p(X,\Fbb)\rightarrow l^q(X,\Fbb)^*\\
f\mapsto\Big(g\in l^q(X,\Fbb)\mapsto \sum_{x\in X}f(x)g(x)\Big)
\end{gathered}
\end{gather}
Indeed, by H\"older's inequality, for each $A\in\fin(2^X)$,
\begin{align*}
\Big|\sum_A fg\Big|\leq\sum_A|fg|\leq \Vert f\Vert_{l^p(A)}\cdot\Vert g\Vert_{l^q(X)}\leq \Vert f\Vert_{l^p(X)}\cdot\Vert g\Vert_{l^q(X)}
\end{align*}
Applying $\lim_A$, we see that $\sum_Xfg$ is absolutely convergence (i.e. $\sum_X|fg|<+\infty$), and 
\begin{align*}
\Big|\sum_X fg\Big|\leq\sum_X|fg|\leq\Vert f\Vert_{l^p(X)}\cdot\Vert g\Vert_{l^q(X)}
\end{align*}
This justifies the claim that $\Psi$ has range in $l^q(X,\Fbb)^*$ (rather than just in $\Lin(l^q(X,\Fbb),\Fbb)$), and that $\Vert\Psi\Vert\leq 1$.
\end{rem}

\begin{pp}\label{lb112}
The map $\Psi$ in \eqref{eq58} is a linear isometry.
\end{pp}

\begin{proof}
We already know $\Vert\Psi\Vert\leq 1$, and we want to show $\Vert\Psi\Vert=1$. 

Case $p<+\infty$: By Prop. \ref{lb109} and Thm. \ref{lb31}, we have $\Vert\Psi\Vert=\Vert\Psi|_{C_c(X,\Fbb)}\Vert$. Therefore, it suffices to show that $\Vert\Psi(f)\Vert=\Vert f\Vert$ for each $f\in C_c(X,\Fbb)$. We assume WLOG that $f\neq0$. Then
\begin{align*}
\bk{\Psi(f),g}=\Vert f\Vert_{l^p}\cdot\Vert g\Vert_{l^q}
\end{align*}
if we write $f=u|f|$ (where $u:X\rightarrow\Sbb^1$) and let $g=\ovl u\cdot |f|^{p-1}$. Since $\Vert\Psi(f)\Vert\cdot\Vert g\Vert_{l^q}\geq|\bk{\Psi(f),g}|$ and $\Vert g\Vert_{l^q}>0$, we conclude that $\Vert\Psi(f)\Vert\geq\Vert f\Vert_{l^p}$, and hence $\Vert\Psi(f)\Vert=\Vert f\Vert_{l^p}$.

Case $p=+\infty$: For each $0\leq\lambda<1$, let $x\in X$ such that $|f(x)|\geq \lambda\Vert f\Vert_{l^\infty}$. Take $g=\chi_{\{x\}}$. Then
\begin{align*}
\bk{\Psi(f),g}=\lambda\Vert f\Vert_{l^p}\cdot\Vert g\Vert_{l^q}
\end{align*}
and hence $\Vert\Psi(f)\Vert\geq\lambda\Vert f\Vert_{l^p}$. Since $\lambda$ is arbitrary, we conclude $\Vert\Psi(f)\Vert=\Vert f\Vert_{l^p}$.
\end{proof}


\subsubsection{Weak-* convergence in $l^p(X,\Fbb)$}

\begin{df}
Assume that $1<p\leq+\infty$. The \textbf{weak-* topology on $\pmb{l^p(X,\Fbb)}$} \index{00@Weak-* topology on $l^p(X,\Fbb)$} is defined to be the pullback topology via the (injective) map $\Phi:l^p(X,\Fbb)\rightarrow l^q(X,\Fbb)^*$ of the weak-* topology of $l^q(X,\Fbb)^*$. In other words, a net $(f_\alpha)$ in $l^p(X,\Fbb)$ converges weak-* to $f\in l^p(X,\Fbb)$ iff for each $g\in l^q(X,\Fbb)$ we have
\begin{align}\label{eq59}
\lim_\alpha\sum_X f_\alpha g=\sum_X fg
\end{align}
\end{df}


\begin{thm}\label{lb111}
Assume $1<p\leq+\infty$. Let $(f_\alpha)$ be a net in $L^p(X,\Fbb)$ satisfying $\sup_\alpha\Vert f_\alpha\Vert_{l^p}<+\infty$. Then $(f_\alpha)$ converges weak-* to some $f\in l^p(X,\Fbb)$ iff $\lim_\alpha f_\alpha(x)$ converges for each $x\in X$. 

Moreover, if $(f_\alpha)$ converges weak-* to $f$, then $f(x)=\lim_\alpha f_\alpha(x)$ for each $x\in X$.
\end{thm}

Consequently, if $p>1$ and $(f_\alpha)$ is a uniformly $l^p$-bounded net in $L^p(X,\Fbb)$ converging pointwise to $f:X\rightarrow\Fbb$, then $f\in l^p(X,\Fbb)$. (Indeed, by Thm. \ref{lb111}, $(f_\alpha)$ converges weak-* to some $\wtd f\in l^p(X,\Fbb)$, and $\wtd f$ is the pointwise limit of $(f_\alpha)$. Therefore $f=\wtd f$ belongs to $l^p(X,\Fbb)$.) 

However, as we will see below, this conclusion must in fact be established first in order to complete the proof of  Thm. \ref{lb111}


\begin{proof}
First, assume that $(f_\alpha)$ converges weak-* to $f\in l^p(X,\Fbb)$. Applying \eqref{eq59} to $g=\chi_{\{x\}}$ (for each $x\in X$), we see that $(f_\alpha)$ converges pointwise to $f$.

Conversely, assume that $(f_\alpha)$ converges pointwise on $X$. Let $f\in\Fbb^X$ be the pointwise limit of $(f_\alpha)$. Recall that $C=\sup_\alpha\Vert f_\alpha\Vert_{l^p}$ is finite. We claim that $f\in l^p(X,\Fbb)$. Indeed, if $p=+\infty$, then for each $x\in X$, we have
\begin{align*}
|f(x)|=\lim_\alpha|f_\alpha(x)|\leq\sup_\alpha \Vert f_\alpha\Vert_{l^\infty}<+\infty
\end{align*}
If $p<+\infty$, then for each $A\in\fin(2^X)$, 
\begin{align*}
\sum_A |f|^p=\lim_\alpha\sum_A |f_\alpha|^p\leq\sup_\alpha \Vert f_\alpha\Vert^p_{l^p}\leq C^p 
\end{align*}
Applying $\lim_A$, we see that $\sum_X|f|^p\leq C^p$, and hence $f\in l^p(X,\Fbb)$.

Let $\Psi$ be as in \eqref{eq58}. By Prop. \ref{lb109}, $C_c(X,\Fbb)$ is dense in $L^q(X,\Fbb)$. Therefore, to show that $(f_\alpha)$ converges weak-* to $f$, by Thm. \ref{lb80} and the observation that
\begin{align*}
\sup_\alpha\Vert\Psi(f_\alpha)\Vert=\sup_\alpha\Vert f_\alpha\Vert_{l^p}<+\infty
\end{align*}
it suffices to show that $\bk{\Psi(f_\alpha),g}$ converges to $\bk{\Psi(f),g}$ (that is, $\sum f_\alpha g$ converges to $\sum fg$) for each $g\in C_c(X,\Fbb)$. But this follows from the fact that $(f_\alpha)$ converges pointwise to $f$.
\end{proof}


As an application of Thm. \ref{lb111}, we prove a variant of Prop. \ref{lb109}.

\begin{pp}
Let $1<p\leq+\infty$. Then $\ovl B_{C_c(X,\Fbb)}(0,1)$ is weak-* dense in $\ovl B_{l^\infty(X,\Fbb)}$.
\end{pp}


\begin{proof}
Let $f\in \ovl B_{l^\infty(X,\Fbb)}$. Then $(f\chi_A)_{A\in\fin(2^X)}$ is a net in $\ovl B_{C_c(X,\Fbb)}(0,1)$ converging pointwise to $f$. By Thm. \ref{lb111}, this net converges weak-* to $f$. 
\end{proof}


\subsubsection{The isomorphism $l^p(X,\Fbb)\simeq l^q(X,\Fbb)^*$}


Now that the equivalence of the first two columns of Table \ref{tb1} for $V=L^q(X,\Fbb)$ has been established in Thm. \ref{lb111} for $p>1$, we can prove the isomorphism $l^p(X,\Fbb)\simeq l^q(X,\Fbb)^*$ by following the strategy outlined in Rem. \ref{lb110}. 

Of course, at least when $X$ is countable, this isomorphism is a special case of the duality $L^p(X,\mu,\Fbb)\simeq L^q(X,\mu,\Fbb)^*$ from Thm. \ref{lb13}, by taking $\mu:2^X\rightarrow[0,+\infty]$ to be the counting measure. However, there are good reasons to study the proof of $l^q(X,\Fbb)^*\simeq l^p(X,\Fbb)$ independently. 

First, the proof of Thm. \ref{lb13} is significantly more involved than the direct proof in the $l^p$ setting. Whenever a result admits a simpler proof in a special case, it is worthwhile to examine that proof directly. Second, Thm. \ref{lb13} depends crucially on the Radon–Nikodym Thm. \ref{lb27}, which in turn can be derived from the Riesz-Fr\'echet Theorem. The latter can be proved with the help of the isomorphism $l^2(X,\Fbb)\simeq l^2(X,\Fbb)^*$. Third, since the proof below follows the idea in Rem. \ref{lb110}, it also serves as another concrete illustration of Table \ref{tb4}.


%We note that the reason that $(l^q)^*\simeq l^p$ does not hold for $p=1$ is that Principle \ref{lb23} does not hold for $V=l^\infty(X,\Fbb)$ (when $X$ is infinite), that is, not all elements of $l^\infty(X,\Fbb)^*$ can be weak-* approximated 



\begin{thm}\label{lb127}
Assume that $1<p\leq+\infty$. Then the map $\Psi:l^p(X,\Fbb)\rightarrow l^q(X,\Fbb)^*$ is an isomorphism of normed vector spaces.
\end{thm}



\begin{proof}
By Prop. \ref{lb112}, it remains to show that $\Psi$ is surjective. Choose $\varphi\in l^q(X,\Fbb)^*$. We want to find $f\in l^p(X,\Fbb)$ such that $\Psi(f)=\varphi$. \\[-1ex]

Step 1. In this step, we verify Principle \ref{lb23}, which says in the current setting that $\varphi$ can be weak-* approximated by a uniformly bounded net in $C_c(X,\Fbb)$. 

For each $A\in\fin(2^X)$, let $\Psi_A:l^p(A,\Fbb)\rightarrow l^q(A,\Fbb)^*$ be defined as in \eqref{eq58}, which is a linear isometry by Prop. \ref{lb112}. Moreover, since $l^p(A,\Fbb)$ and $l^q(A,\Fbb)^*$ both have dimension $|A|$, $\Psi_A$ is an isomorphism. Therefore, there exists $f_A\in C_c(X,\Fbb)$, supported in $A$, such that
\begin{align*}
\Psi_A(f_A)=\varphi|_{l^q(A,\Fbb)}
\end{align*}
This relation clearly shows that
\begin{align*}
\lim_{A\in\fin(2^X)}\bk{\Psi(f_A),g}=\bk{\varphi,g}
\end{align*}
for each $g$ of the form $\chi_{\{x\}}$ where $x\in X$, and hence for each $g\in C_c(X,\Fbb)$. Moreover, the net $(\Psi(f_A))_{A\in\fin(2^X)}$ is uniformly bounded, since
\begin{align*}
\Vert\Psi(f_A)\Vert_{l^p}=\Vert\varphi|_{l^q(A,\Fbb)}\Vert\leq\Vert\varphi\Vert
\end{align*}
Therefore, since $C_c(X,\Fbb)$ is dense in $l^q(X,\Fbb)$ (cf. Prop. \ref{lb109}), by Thm. \ref{lb80}, the net $(\Psi(f_A))_{A\in\fin(2^X)}$ converges weak-* to $\varphi$. In other words, $(f_A)_{A\in\fin(2^X)}$ is a uniformly $l^p$-bounded net in $C_c(X,\Fbb)$ converging weak-* to $\varphi$.\\[-1ex]

Step 2. For each $x\in X$, the limit
\begin{align*}
\lim_{A\in\fin(2^X)}f_A(x)=\lim_{A\in\fin(2^X)}\sum_X f_A\chi_{\{x\}}
\end{align*}
converges by the weak-* convergence of $(f_A)_{A\in\fin(2^X)}$. Therefore, since $(f_A)_{A\in\fin(2^X)}$ is a uniformly bounded, by Thm. \ref{lb111}, the net $(f_A)_{A\in\fin(2^X)}$ converge weak-* to some $f\in l^p(X,\Fbb)$. Thus $\varphi=\Psi(f)$.
\end{proof}







\subsection{Weak-* convergence of distribution functions}


In this section, we fix a proper interval $I\subset\Rbb$, and let $a=\inf I, b=\sup I$. We use freely the notation in Subsec. \ref{lb89}. In particular, for each function $\rho$ on $I$, we let
\begin{align*}
\Omega_\rho=\{x\in(a,b):\rho|_{(a,b)}\text{ is continuous at }x\}
\end{align*}
A family of functions $(\rho_\alpha)$ from $I$ to $\Rbb$ is called \textbf{uniformly bounded} if $\sup_\alpha \Vert\rho_\alpha\Vert_{l^\infty(I,\Rbb)}<+\infty$.

The goal of this section is to prove Thm. \ref{lb21}, which characterizes the relationship between pointwise convergence and weak-* convergence for increasing functions. To this end, we begin with several preparatory results concerning the pointwise convergence of such functions.


\subsubsection{Almost convergence of increasing functions}



\begin{lm}\label{lb90}
Let $(\rho_\alpha)$ be a uniformly bounded net of increasing functions $I\rightarrow\Rbb_{\geq0}$. Suppose that $(\rho_\alpha)$ converges pointwise on a dense subset $E\subset I$. Then there exists a bounded increasing function $\rho:I\rightarrow\Rbb_{\geq0}$ such that $(\rho_\alpha)$ converges pointwise on $E$ to $\rho$.
\end{lm}

\begin{proof}
Let $\rho:E\rightarrow\Rbb_{\geq0}$ be the pointwise limit of $(\rho_\alpha)$, which is clearly bounded and increasing. Extend $\rho$ to a function $\rho:I_{<b}\cup(E\cap\{b\})\rightarrow\Rbb_{\geq0}$ by setting
\begin{align*}
\rho(x)=\lim_{E\ni y\rightarrow x^+}\rho(y)
\end{align*} 
if $x\in I\setminus E$. Extend $\rho$ further to $\rho:I\rightarrow\Rbb_{\geq0}$ by setting $\rho(b)=\lim_{x\rightarrow b^-}\rho(x)$ if $b\in I\setminus E$. Then $\rho$ is bounded and increasing, and $(\rho_\alpha)$ converges pointwise to $\rho$ on $E$.
\end{proof}



\begin{pp}\label{lb91}
Let $(\rho_\alpha)$ be a uniformly bounded net of increasing functions $I\rightarrow\Rbb_{\geq0}$. Let $\rho:I\rightarrow\Rbb_{\geq0}$ be increasing. Then the following are equivalent:
\begin{enumerate}[label=(\alph*)]
\item There exists a dense subset $E\subset I$ such that $(\rho_\alpha)$ converges pointwise on $E$ to $\rho$.
\item The net $(\rho_\alpha)$ converges pointwise on $\Omega_\rho$ to $\rho$.
\end{enumerate}
If either of these two statements are true, we say that $(\rho_\alpha)$ \textbf{almost converges} to $\rho$. \index{00@Almost convergence of a net of increasing functions}
\end{pp}


\begin{proof}
Since $\Omega_\rho$ is dense (Prop. \ref{lb62}), clearly (b) implies (a).

Now assume (a). Choose any $x\in\Omega_\rho$. We will show that every convergent subnet $(\rho_{\alpha_\nu}(x))$ of $(\rho_\alpha(x))$ converges to $\rho(x)$. This will immediately imply (b).

By Lem. \ref{lb90},  there exists an increasing function $\wtd\rho:I\rightarrow\Rbb_{\geq0}$ such that $(\rho_{\alpha_\nu})$ converges on $E\cup\{x\}$ to $\wtd\rho$. Since $(\rho_{\alpha_\nu})$ converges pointwise on $E$ to $\rho$, the functions $\rho$ and $\wtd\rho$ agree on $E$. Namely, $\rho$ and $\wtd\rho$ are almost equal. Therefore, by Prop. \ref{lb70}, $\rho$ and $\wtd\rho$ agree on $\Omega_\rho$, and in particular at $x$. This proves $\lim_\nu\rho_{\alpha_\nu}(x)=\rho(x)$.
\end{proof}


The following theorem can be viewed as a concrete manifestation of the Banach-Alaoglu Thm. \ref{lb60} in the setting of $C_c(I)^*$. It will be used in the proof of Thm. \ref{lb92}.


\begin{thm}[\textbf{Helly selection theorem}]\index{00@Helly selection theorem}\label{lb94}
Let $(\rho_\alpha)$ be a uniformly bounded net (resp. sequence) of increasing functions $I\rightarrow\Rbb_{\geq0}$. Then $(\rho_\alpha)$ admits a pointwise convergent subnet (resp. subsequence).
\end{thm}

\begin{proof}
The existence of a pointwise convergent subnet follows directly from the Tychonoff Thm. \ref{lb61}. Therefore, let us assume that $(\rho_\alpha)$ is a sequence $(\rho_n)$. Let $E=I\cap\Qbb$. Then, by the diagonal method (cf. Rem. \ref{lb52}), $(\rho_n)$ has a subsequence $(\rho_{n_k})$ converging pointwise on $E$. By Lem. \ref{lb90}, there exists a bounded increasing $\rho:I\rightarrow\Rbb_{\geq0}$ such that $(\rho_{n_k})$ converges pointwise on $E$ to $\rho$. Therefore, by Prop. \ref{lb91}, $(\rho_{n_k})$ converges pointwise on $\Omega_\rho$ to $\rho$. Since $I\setminus\Omega_\rho$ is countable, by the diagonal method again, $(\rho_{n_k})$ has a subsequence converging pointwise on $I\setminus\Omega_\rho$, and hence on $I$. 
\end{proof}



\subsubsection{Almost convergence and weak-* convergence}

\begin{df}
Let $(\rho_\alpha)$ be a net in $BV(I,\Fbb)$. Let $\rho\in BV(I,\Fbb)$. Let $\Lambda_\alpha$ and $\Lambda$ be the elements of $C_c(I,\Fbb)^*$ corresponding to $\rho_\alpha$ and $\rho$, respectively, via the Riesz representation Thm. \ref{lb10}.  We say that the net $(d\rho_\alpha)$ \textbf{converges weak-*} \index{00@Weak-* convergence of $(d\rho_\alpha)$ where $(\rho_\alpha)$ is a net of BV functions} to $d\rho$ if $(\Lambda_\alpha)$ converges weak-* to $\Lambda$. Namely, for each $f\in C_c(I,\Fbb)$, we have
\begin{align}\label{eq53}
\lim_\alpha \int_I f d\rho_\alpha=\int_I fd\rho
\end{align}
\end{df}


The following Thm. \ref{lb92} is parallel to Thm. \ref{lb78}. However, unlike Thm. \ref{lb78} whose proof relies on the isomorphism $L^p\simeq(L^q)^*$, Thm. \ref{lb92} does not rely on the Riesz representation theorem.

\begin{thm}\label{lb92}
Let $(\rho_\alpha)_{\alpha\in\scr A}$ be a uniformly bounded net of bounded increasing functions $I\rightarrow\Rbb_{\geq0}$. Let $\rho:I\rightarrow\Rbb_{\geq0}$ be bounded and increasing. Then the following are equivalent:
\begin{enumerate}[label=(\alph*)]
\item There exists a bounded family $(\varkappa_\alpha)_{\alpha\in\scr A}$ in $\Rbb$ (assumed to be zero if $a\in I$) satisfying the following conditions:
\begin{itemize}
\item $(\rho_\alpha+\varkappa_\alpha)$ almost converges to $\rho$.
\item $\lim_\alpha(\rho_\alpha(b)+\varkappa_\alpha)=\rho(b)$ if $b\in I$.
\end{itemize}
\item The net $(d\rho_\alpha)$ converges weak-* to  $d\rho$.
\end{enumerate}
\end{thm}

The boundedness of $(\varkappa_\alpha)_{\alpha\in\scr A}$ means that $\sup_\alpha|\vkp_\alpha|<+\infty$.

\begin{proof}
(a)$\Rightarrow$(b): Assume (a). We verify \eqref{eq53} for each $f\in C_c(I,\Fbb)$, which established (b). Recall from Rem. \ref{lb93} that if $a\notin I$, adding constants to $\rho_\alpha$ and $\rho$ does not affect the values of $\int_I fd\rho_\alpha$ and $\int_I fd\rho$. 

Since $(\rho_\alpha)$ is uniformly bounded $(\vkp_\alpha)$ is bounded, there exists $c\geq0$ such that $\rho_\alpha+\vkp_\alpha+c\geq0$ for all $\alpha$. Therefore, replacing $\rho_\alpha$ with $\rho_\alpha+\vkp_\alpha+c$ and $\rho$ with $\rho+c$, we assume that there exists a dense subset $E\subset I$ such that $(\rho_\alpha)$ converges pointwise on $E$ to $\rho$, and that $b\in E$ if $b\in I$.

Choose any $f\in C_c(I,\Fbb)$. Choose $u,v\in\Rbb$ satisfying $\Supp_I(f)\subset[u,v]\subset I$, and let $J=[u,v]$. By increasing $v$ if possible, we may assume that $v\in E$. (When $b\in I$, one simply choose $v=b$.) 

In the case where $a\in I$, by Lem. \ref{lb69}, the values of $\int_J fd\rho_\alpha$ and $\int_J fd\rho$ remain unchanged if we change the values of $\rho_\alpha(a)$ and $\rho(a)$ to $0$. Therefore,  we may assume that $\rho_\alpha(a)=\rho(a)=0$ (so that $a$ can be included to $E$), and we may also choose $u=a$. In the case where $a\notin I$, by the density of $E$, we can slightly decrease $u$ so that $u\in E$. To summarize, whether $a$ or $b$ belongs to $I$ or not, we can assume 
\begin{align*}
u,v\in E
\end{align*}

Since $f$ is uniformly continuous, for each $\eps>0$ there exists $\delta>0$ such that $|f(x)-f(y)|\leq\eps$ for each $x,y\in I$ satisfying $|x-y|\leq\delta$. Choose a tagged partition
\begin{align*}
(\sigma,\xi_\blt)=\big(\{a_0=u<a_1<\cdots<a_n=v\},(\xi_1,\dots,\xi_n) \big)
\end{align*}
of $J$ with mesh $<\delta$. Since $E$ is dense, by a slight adjustment, we may assume that $a_0,a_1,\dots,a_n\in E$. This implies
\begin{align*}
\lim_\alpha f(u)\rho_\alpha(u)=f(u)\rho(u)\qquad\lim_\alpha S_{\rho_\alpha}(f,\sigma,\xi_\blt)=S_\rho(f,\sigma,\xi_\blt)
\end{align*}
Therefore, if we let $C=\sup\{\rho_\alpha(v)-\rho_\alpha(u),\rho(v)-\rho(u):\alpha\in\scr A\}$, then Rem. \ref{lb63} implies
\begin{align*}
\limsup_\alpha \Big|\int_J fd\rho_\alpha-\int_J fd\rho\Big|\leq 2\eps\cdot C
\end{align*}
This finishes the proof of \eqref{eq53}.\\[-1ex]

(b)$\Rightarrow$(a): Assume (b). We first consider the case where $a\notin I$. Fix $t\in\Omega_\rho$, and let
\begin{align*}
\varkappa_\alpha=\rho(t)-\rho_\alpha(t)
\end{align*}
Then $(\vkp_\alpha)$ is bounded. Therefore, $(\rho_\alpha+\vkp_\alpha)$ is uniformly bounded, and hence there exists $c\geq0$ such that $\rho_\alpha+\vkp_\alpha+c\geq0$ for all $\alpha$. Replacing $\rho_\alpha$ with $\rho_\alpha+c$ and $\rho$ with $\rho+c$, we assume that $\rho_\alpha+\vkp_\alpha\geq0$ for all $\alpha$. (Of course, we still have $\rho\geq0$.) 

Choose any $x\in\Omega_\rho$. To show that $(\rho_\alpha(x)+\vkp_\alpha)_\alpha$ converges to $\rho(x)$, it suffices to show that every convergent subnet $(\rho_\beta(x)+\vkp_\beta)_\beta$ converges to $\rho(x)$.

By the Helly selection Thm. \ref{lb94}, the net of functions $(\rho_\beta+\vkp_\beta)_\beta$ has a pointwise convergent subnet $(\rho_\gamma+\vkp_\gamma)_\gamma$. Let $\wtd\rho:I\rightarrow\ovl\Rbb_{\geq0}$ be the pointwise limit of this subnet, which is clear bounded and increasing. By (a)$\Rightarrow$(b), the net $(d(\rho_\upgamma+\vkp_\gamma))_\gamma$ converges weak-* to $d\wtd\rho$. By assumption, it also converges weak-* to $d\rho$. Therefore, we have $\int_I fd\wtd\rho=\int_I fd\rho$ for each $f\in C_c(I)$. 

By Thm. \ref{lb72} (and noting Rem. \ref{lb93}), we have
\begin{align*}
\wtd\rho-\lim_{y\rightarrow a^+}\wtd\rho(y)=\rho-\lim_{y\rightarrow a^+}\rho(y)\qquad\text{on }\Omega_\rho
\end{align*}
In other words, there exists a constant $c\in\Rbb$ such that
\begin{align}\label{eq54}
\wtd\rho+c=\rho\qquad\text{on }\Omega_\rho
\end{align}

Since $\rho_\alpha(t)+\vkp_\alpha=\rho(t)$ is constant over $\alpha$, and since its subnet $(\rho_\gamma(t)+\vkp_\gamma)_\gamma$ converges to $\wtd\rho(t)$, we conclude $\wtd\rho(t)=\rho(t)$. Therefore, since $t\in\Omega_\rho$, by \eqref{eq54}, we have $c=0$. Since $x\in\Omega_\rho$, by \eqref{eq54}, we obtain $\wtd\rho(x)=\rho(x)$. This proves that $(\rho_\gamma(x)+\vkp_\gamma)_\gamma$ converges to $\rho(x)$, and hence $(\rho_\beta(x)+\vkp_\beta)_\beta$ converges to $\rho(x)$.

Now consider the case where $a\in I$. We set $\vkp_\alpha=0$.  Similar to the above argument, we choose any $x\in\Omega_\rho$, choose a subnet $\rho_\beta$ converging at $x$, and further choose a subnet $\rho_\gamma$ converging pointwise on $I$ to $\wtd\rho:I\rightarrow\ovl\Rbb_{\geq0}$. By (a)$\Rightarrow$(b), we have $\int_I fd\wtd\rho=\int_I fd\rho$ for each $f\in C_c(I)$. Consequently, Thm. \ref{lb72} implies that $\wtd\rho=\rho$ on $\Omega_\rho$. Since $x\in\Omega_\rho$, we obtain again $\lim_\beta \rho_\beta(x)=\lim_\gamma \rho_\gamma(x)=\wtd\rho(x)=\rho(x)$. Therefore $(\rho_\alpha(x))_\alpha$ converges to $\rho(x)$ for each $x\in\Omega_\rho$.
\end{proof}



\begin{co}\label{lb95}
Let $(\rho_\alpha)_{\alpha\in\scr A}$ be a uniformly bounded net of increasing functions $I\rightarrow\Rbb_{\geq0}$. Then the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item There exists a bounded family $(\varkappa_\alpha)_{\alpha\in\scr A}$ in $\Rbb$ (assumed to be zero if $a\in I$) such that $(\rho_\alpha+\varkappa_\alpha)$ converges pointwise on a dense subset $E\subset I$, and also at $b$ if $b\in I$.
\item There exists a bounded increasing $\rho:I\rightarrow\Rbb_{\geq0}$ such that $(d\rho_\alpha)_{\alpha\in\scr A}$ converges weak-* to $d\rho$.
\end{enumerate}
\end{co}


\begin{proof}
``(2)$\Rightarrow$(1)" follows immediately from Thm. \ref{lb92}. Conversely, assume (1). By Lem. \ref{lb90}, there exists a bounded increasing $\rho:I\rightarrow\Rbb_{\geq0}$ such that $(\rho_\alpha+\varkappa_\alpha)$ converges pointwise on $E\cup\{I\cap\{b\}\}$ to $\rho$. Then Thm. \ref{lb92} implies (2).
\end{proof}




\subsection{Weak-* approximation of Radon measures by Dirac measures}


Fix an LCH space $X$. Recall that we have assumed throughout the notes that $\Fbb\in\{\Rbb,\Cbb\}$. Let \index{RM@$\RM(X,\Kbb)$ where $\Kbb$ is $\ovl\Rbb_{\geq0},\Rbb_{\geq0},\Rbb,\Cbb$}
\begin{gather}
\begin{gathered}
\RM(X,\ovl\Rbb_{\geq0})=\{\text{Radon measures on $X$}\}\\
\RM(X,\Rbb_{\geq0})=\{\text{finite Radon measures on $X$}\}\\
\RM(X,\Rbb)=\{\text{signed Radon measures on $X$}\}\\
\RM(X,\Cbb)=\{\text{complex Radon measures on $X$}\}
\end{gathered}
\end{gather}
which are vectors spaces over $\ovl\Rbb_{\geq0},\Rbb_{\geq0},\Rbb,\Cbb$ respectively. Note the inclusion relation
\begin{align*}
\RM(X,\Rbb_{\geq0})\subset\RM(X,\ovl\Rbb_{\geq0})\qquad \RM(X,\Rbb_{\geq0})\subset \RM(X,\Rbb)\subset\RM(X,\Cbb)
\end{align*}
Recall that for each $x\in X$, the Dirac measure at $x$ is denoted by $\delta_x$.

The goal of this section is to prove Principle \ref{lb23} for $V=C_c(X,\Fbb)$. In this context, elementary functions are understood as linear combinations of Dirac measures. When $X$ is an interval $I\subset\Rbb$, these elementary functions correspond to bounded increasing functions $I\rightarrow\Rbb_{\geq0}$ whose ranges are finite sets.

\subsubsection{Definitions and basic properties}


\begin{df}
Recall the $\Fbb$-linear isomorphism
\begin{align*}
\RM(X,\Fbb)\simeq C_c(X,\Fbb)^*
\end{align*}
defined by the Riesz-Markov representation Thm. \ref{lb8}. The pullback of the operator norm on $C_c(X,\Fbb)^*$ to $\mu\in\RM(X,\Fbb)$ is called the \textbf{total variation} of $\mu$, and is denoted by \pmb{$\Vert\mu\Vert$}. \index{00@Total variation of a complex measure} \index{zz@$\Vert\mu\Vert$, the total variation of $\mu$} In other words,
\begin{align*}
\Vert\mu\Vert=\sup\Big\{\Big|\int fd\mu\Big|:f\in C_c(X,\Fbb),|f|\leq1 \Big\}
\end{align*}
A family of complex Radon measures $(\mu_\alpha)_{\alpha\in\scr A}$ is called \textbf{uniformly bounded} \index{00@Uniformly bounded family of complex measures} if
\begin{align*}
\sup_{\alpha\in\scr A}\Vert\mu_\alpha\Vert<+\infty
\end{align*}
The weak-* topology on $C_c(X,\Fbb)^*$ defines the \textbf{weak-* topology on \pmb{$\RM(X,\Fbb)$}}. Thus, if $(\mu_\alpha)$ is a uniformly bounded net in $\RM(X,\Fbb)$, and if $\mu\in\RM(X,\Fbb)$, then $(\mu_\alpha)$ converges weak-* to $\mu$ \footnote{We also say that $(d\mu_\alpha)$ converges weak-* to $d\mu$.} iff for each $f\in C_c(X,\Fbb)$ we have\footnote{By Rem. \ref{lb96}, this is equivalent to that \eqref{eq55} holds for each $f\in C_0(X,\Fbb)$.}
\begin{align}\label{eq55}
\lim_\alpha\int_Xfd\mu_\alpha=\int_X fd\mu
\end{align}
\end{df}



\begin{eg}\label{lb99}
By Thm. \ref{lb7}, if $\mu\in\RM(X,\Rbb_{\geq0})$, then
\begin{align*}
\Vert\mu\Vert=\mu(X)
\end{align*}
\end{eg}


\begin{eg}\label{lb103}
Let $E\subset X$ be a finite set, and let $c:E\rightarrow\Fbb$ be a function. Then
\begin{align}
\Big\Vert  \sum_{x\in E}c(x)\delta_x\Big\Vert=\sum_{x\in E}|c(x)|
\end{align}
\end{eg}

\begin{proof}
Let $\mu=\sum_{x\in E}c(x)\delta_x$. By Exp. \ref{lb99}, we have $\Vert\delta_x\Vert=1$. Since norms satisfy the sub-additivity, we have
\begin{align*}
\Vert\mu\Vert\leq\sum_{x\in E}|c(x)|\cdot\Vert\delta_x\Vert=\sum_{x\in E}|c(x)|
\end{align*}
By Urysohn's lemma, there exists $f\in C_c(X,\Fbb)$ such that $\Vert f\Vert_{l^\infty}\leq 1$, and that for each $x\in E$, we have $|f(x)|=1$ and $f(x)c(x)=|c(x)|$. Then $\int_X fd\mu=\sum_{x\in E}|c(x)|$. This proves $\Vert\mu\Vert\geq\sum_{x\in E}|c(x)|$.
\end{proof}


\begin{lm}\label{lb104}
Let $\mu\in\RM(X,\Fbb)$. Let $A_1,\dots,A_k$ be mutually disjoint Borel subsets of $X$. Then
\begin{align*}
\Vert\mu\Vert\geq\sum_{j=1}^k |\mu(A_j)|
\end{align*}
\end{lm}

\begin{proof}
Since $\mu$ is a linear combination of finite Radon measures, there exists $\wht\mu\in\RM(X,\Rbb_{\geq0})$ such that $|\mu(A)|\leq \wht\mu(A)$ for each Borel $A\subset X$. Since Radon measures are regular on Borel sets with finite measures (Thm. \ref{lb101}), for each $\eps>0$ there exists compact $K_j\subset A_j$ such that $\wht\mu(A_j\setminus K_j)\leq \eps$. 

By Cor. \ref{lb102}, there exist mutually disjoint open subsets $U_1,\dots,U_n\subset X$ such that $U_j\supset K_j$. Since $\wht\mu$ is regular on $K_j$, we may assume that $\wht\mu(U_j\setminus K_j)<\eps$. By Urysohn's lemma, there exists $f_j\in C_c(U_j,\Fbb)$ such that $|f_j|\leq 1$, that $f_j|_{K_j}$ equals a constant $c_j\in\Fbb$, and that $c_j\mu(K_j)=|\mu(K_j)|$. Let $f=f_1+\cdots f_k$, which is an element of $C_c(X,\Fbb)$ satisfying $|f|\leq 1$. Then 
\begin{align*}
\int_{\bigcup_j K_j}fd\mu=\sum_j|\mu(K_j)|\qquad \Big|\int_{X\setminus\bigcup_j K_j} fd\mu\Big|\leq k\eps
\end{align*}
Since $|\mu(A_j)-\mu(K_j)|=|\mu(A_j\setminus K_j)|\leq\wht\mu(A_j\setminus K_j)\leq\eps$, we obtain $|\mu(K_j)|\geq |\mu(A_j)|-\eps$, and hence
\begin{align*}
\Vert\mu\Vert\geq\Big|\int_X fd\mu\Big|\geq\Big|\int_{\bigcup_j K_j}fd\mu\Big|-\Big|\int_{X\setminus\bigcup_j K_j} fd\mu \Big|\geq \sum_j |\mu(A_j)|-2k\eps
\end{align*}
Since $\eps$ is arbitrary, we obtain the desired inequality.
\end{proof}



\subsubsection{Approximation of Radon measures by Dirac measures}

In this section, we let $\Kbb\in\{\Rbb_{\geq0},\Rbb,\Cbb\}$. 

\begin{thm}\label{lb105}
Define
\begin{align*}
\MD(X,\Kbb)=\Span_\Kbb\{\delta_x:x\in X\}
\end{align*}
Then the closed unit ball of $\MD(X,\Kbb)$ is weak-* dense in the closed unit ball of $\RM(X,\Kbb)$. In other words, $\ovl B_{\MD(X,\Kbb)}(0,1)$ is weak-* dense in $\ovl B_{\RM(X,\Kbb)}(0,1)$.
\end{thm}


\begin{proof}
Fix $\mu\in\RM(X,\Kbb)$ satisfying $\Vert\mu\Vert\leq 1$. Similar to the proof of Thm. \ref{lb86}, we let $\scr I$ be the directed set
\begin{gather*}
\scr I=\{(\MG,\eps):\MG\in\fin(2^{C_c(X,\Kbb)}),\eps\in\Rbb_{\geq0}\}\\
(\MG_1,\eps_1)\leq(\MG_2,\eps_2)\qquad\text{means}\qquad \MG_1\subset\MG_2,\eps_1\geq\eps_2
\end{gather*}
We claim that for any $(\MG,\eps)\in\scr I$, there exists $\mu_{\MG,\eps}\in\ovl B_{\MD(X,\Kbb)}(0,1)$ such that
\begin{align*}
\Big|\int_X fd\mu-\int_X fd\mu_{\MG,\eps}\Big |\leq\eps\qquad\text{for all }f\in\MG
\end{align*}
If this is true, then $(\mu_{\MG,\eps})_{(\MG,\eps)\in\scr I}$ is a net in $\ovl B_{\MD(X,\Kbb)}(0,1)$ converging weak-* to $\mu$. This will finish the proof.

Let us prove the claim. Since $\mu$ is a linear combination of finite Radon measures, there exists $\wht\mu\in\RM(X,\Rbb_{\geq0})$ such that
\begin{align*}
\Big|\int_X gd\mu\Big|\leq\int_X |g|d\wht\mu
\end{align*}
for each bounded Borel function $g:X\rightarrow\Cbb$.

Let $K\subset X$ be compact and containing $\Supp(f)$ for all $f\in\MG$. By the compactness of $K$, there exist open sets $U_1,\dots,U_k\subset X$ whose union contains $K$, such that $\diam(f(U_j))\leq \eps/\wht\mu(K)$ for each $j$ and $f\in\MG$. Choose a Borel set $A_j\subset U_j$ such that  $K=A_1\sqcup\cdots\sqcup A_k$.\footnote{For example, take $A_1=K\cap U_1$ and $A_j=K\cap U_j\setminus (U_1\cup\cdots\cup U_{j-1})$ if $j>1$.} Choose any $x_j\in A_j$, and let
\begin{align}\label{eq56}
\mu_{\MG,\eps}=\sum_{j=1}^k\mu_j(A_j)\delta_{x_j}
\end{align}
Then, for each $f\in\MG$,
\begin{align*}
&\Big| \int_X fd(\mu-\mu_{\MG,\eps})\Big|\leq\sum_{j=1}^k\Big|\int_{A_i}fd(\mu-\mu_{\MG,\eps})\Big|=\sum_{j=1}^k\Big|\int_{A_i}fd\mu -\mu_j(A_j)f(x_i)\Big|\\
=&\sum_{j=1}^k\Big|\int_{A_i}(f-f(x_j))d\mu\Big|\leq\sum_{j=1}^k\int_{A_j}|f-f(x_j)|d\wht\mu\leq \frac{\eps}{\wht\mu(K)}\sum_{j=1}^k\wht\mu(A_j)=\eps
\end{align*}
This proves the desired inequality. Moreover, by Exp. \ref{lb103} and Lem. \ref{lb104},
\begin{align*}
\Vert\mu_{\MG,\eps}\Vert=\sum_{j=1}^k|\mu_j(A_j)|\leq\Vert\mu\Vert\leq1
\end{align*}
This proves that $\mu_{\MG,\eps}\in\ovl B_{\MD(X,\Kbb)}(0,1)$.
\end{proof}



The proof of Thm. \ref{lb105} immediately implies:


\begin{thm}
For each $\mu\in\RM(X,\Cbb)$, we have
\begin{align}\label{eq57}
\Vert\mu\Vert=\sup\Big\{\sum_{j=1}^k|\mu(A_j)|:k\in\Zbb_+\text{, and $A_1,\dots,A_k\in\fk B_X$ are mutually disjoint}\Big\}
\end{align}
\end{thm}

\begin{proof}
Lem. \ref{lb104} implies ``$\geq$". Let us prove ``$\leq$". Let $(\mu_{\MG,\eps})_{(\MG,\eps)\in\fk I}$ be the net in $\MD(X,\Cbb)$ converging weak-* to $\mu$ and satisfying $\Vert\mu_{\MG,\eps}\Vert\leq\Vert\mu\Vert$. Each $\mu_{\MG,\eps}$ is of the form \eqref{eq56}, by Lem. \ref{lb103}, the RHS of \eqref{eq57} is $\geq\Vert\mu_{\MG,\eps}\Vert$. By Fatou's lemma for weak-* convergence (Prop. \ref{lb106}), the RHS of \eqref{eq57} is $\geq\Vert\mu\Vert$.
\end{proof}


\begin{comment}
In Subsec. \ref{lb107}, we noted that characterizing the dual space $V^*$ is equivalent to establishing the equivalence between the first and second columns of Table \ref{tb1}---that is, between pointwise convergence of functions and convergence of moments---once Principle \ref{lb23} is in place.

Now, let $I\subset\Rbb$ be a proper interval, and suppose our goal is to classify the positive linear functionals on $C(I)$, i.e., to prove the Riesz Representation Thm. \ref{lb9}. The equivalence of the first and second columns of Table \ref{tb1} is established in Thm. \ref{lb92} and Cor. \ref{lb95}. If we can prove Principle \ref{lb23}, which asserts in the current setting that any positive linear functional on $C(I)$ can be weak-* approximated by elementary functions (i.e., linear combinations of Dirac measures; see Table \ref{lb3}), then Thm. \ref{lb9} follows as a consequence.

Of course, Thm. \ref{lb105} shows that Principle \ref{lb23} can be deduced if the Riesz Representation Thm. \ref{lb9} is already known. However, by slightly modifying the argument in the proof of Thm. \ref{lb105}, one can prove Principle \ref{lb23} without assuming Thm. \ref{lb9} in advance:
\end{comment}


\newpage








\section{Basics of inner product spaces}




\subsection{Sesquilinear forms}



Let $V$ be $\Cbb$-vector spaces.



\subsubsection{Sesquilinear forms}



\begin{df}
A map of $\Cbb$-vector spaces $T:V\rightarrow W$ is called \textbf{antilinear} or \textbf{conjugate linear} \index{00@Antilinear map} if for every $a,b\in\Fbb$ and $u,v\in V$ we have
\begin{align*}
T(au+bv)=\ovl au+\ovl bv
\end{align*}
where $\ovl a,\ovl b$ are the complex conjugates of $a,b$.
\end{df}


\begin{df}
A function $\bk{\cdot|\cdot}:V\times V\rightarrow\Cbb$ (sending $u\times v\in V^2$ to $\bk{u|v}$) is called a \textbf{sesquilinear form} \index{00@Sesquilinear form} if it is antilinear on the first variable, and linear on the second one.\footnote{This is different from \cite{Gui-A}, where the second variable is assumed to be antilinear} Namely, for each $a,b\in\Cbb$ and $u,v,w\in V$ we have
\begin{gather*}
\bk{au+bv|w}=\ovl a\bk{u|w}+\ovl b\bk{v|w}\qquad \bk{w|au+bv}=a\bk{w|u}+b\bk{w|v}
\end{gather*}
More generally, if $V,W$ are complex vector spaces, a map $V\times W\rightarrow\Cbb$ is also called \textbf{sesquilinear} if it is antilinear on the $V$-component and linear on the $W$-component. The function
\begin{align*}
V\rightarrow\Cbb\qquad v\mapsto\bk{v|v}
\end{align*}
is called the \textbf{quadratic form} \index{00@Quadratic form associated to a sesquilinear form} associated to the sesquilinear form $\bk{\cdot|\cdot}$.
\end{df}

Notice the difference between the notations $\bk{u|v}$ and $\bk{u,v}$: the latter always means a bilinear form, i.e., a function which is linear on both variables.


\begin{rem}
For each sesquilinear form $\bk{\cdot|\cdot}$ on $V$, we have the \textbf{polarization identity} \index{00@Polarization identity}
\begin{align}
\begin{aligned}
&\bk{u|v}=\frac 14\sum_{t=0,\frac \pi 2,\pi,\frac{3\pi}2}~ \bk{u+e^{\im t}v|u+e^{\im t}v}e^{\im t}\\
=&\frac 14\Big(\bk{u+v|u+v}-\bk{u-v|u-v}+\im\bk{u+\im v|u+\im v}-\im\bk{u-\im v|u-\im v}\Big)
\end{aligned}
\end{align}
Therefore, sesquilinear forms are determined by their associated quadratic forms.
\end{rem}



\begin{df}
Let $\omega(\cdot|\cdot):V\times W\rightarrow\Cbb$ be a sesquilinear form. The \textbf{adjoint sesequilinear form $\pmb{\omega^*}$} \index{00@Adjoint sesquilinear form} \index{zz@$\omega^*$, the adjoint sesquilinear form of $\omega$} is defined to be
\begin{align*}
\omega^*:W\times V\rightarrow\Cbb\qquad \omega^*(w|v)=\ovl{\omega(v|w)}
\end{align*}
\end{df}


\begin{df}
A sesquilinear form $\bk{\cdot|\cdot}:V\times V\rightarrow\Cbb$ is called a \textbf{Hermitian form} \index{00@Hermitian form} if is equal to it adjoint, namely, 
\begin{align*}
\bk{v|u}=\ovl{\bk{u|v}}\qquad\text{for each }u,v\in V
\end{align*}
\end{df}



\begin{pp}\label{lb113}
Let $\bk{\cdot|\cdot}$ be a sesquilinear form on $V$. The following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $\bk{\cdot|\cdot}$ is a Hermitian form.
\item The quadratic form associated to $\bk{\cdot|\cdot}$ is real-valued, that is, for each $v\in V$ we have $\bk{v|v}\in\Rbb$.
\end{enumerate}
\end{pp}


\begin{proof}
Let $\omega=\bk{\cdot|\cdot}$. By the polarization identity, we have $\omega^*=\omega$ iff $\omega^*(v|v)=\omega(v|v)$ (i.e. $\ovl{\omega(v|v)}=\omega(v|v)$) for each $v\in V$. 
\end{proof}


\subsubsection{Positive sesquilinear forms}


\begin{df}\label{lb139}
A sesquilinear form $\bk{\cdot|\cdot}$ on $V$ is called \textbf{positive semi-definite} (or simply \textbf{positive}) and written as $\bk{\cdot|\cdot}\geq0$, \index{00@Positive sesquilinear form} if $\bk{v|v}\geq0$ for all $v\in V$. If a positive sesquilinear form $\bk{\cdot|\cdot}$ on $V$ is fixed, we define
\begin{align}
\Vert v\Vert=\sqrt{\bk{v|v}}\qquad\text{ for all }v\in V
\end{align} 
Then it is clear that $\Vert\lambda v\Vert=|\lambda|\cdot\Vert v\Vert$ for each $v\in V$ and $\lambda\in\Cbb$. A vector $v\in V$ satisfying $\Vert v\Vert=1$ is called a \textbf{unit vector}. \index{00@Unit vector} 
\end{df}

By Prop. \ref{lb113}, a positive sesquilinear form is Hermitian. More generally, we have the following definition:

\begin{df}\label{lb140}
Let $\omega_1,\omega_2$ be Hermitian forms on $V$. We write\index{zz@$\omega_1\leq\omega_2$ where $\omega_1,\omega_2$ are Hermitian forms}
\begin{align*}
\pmb{\omega_1\leq\omega_2}
\end{align*}
(equivalently, $\omega_2\geq\omega_1$) if the (real-valued) quadratic forms associated to $\omega_1$ and $\omega_2$ satisfy the corresponding inequality, that is,
\begin{align*}
\omega_1(\xi|\xi)\leq\omega_2(\xi|\xi)\qquad\text{for each }\xi\in V
\end{align*}
Thus, ``$\leq$" defines a partial order on the set of sesquilinear forms on $V$. Moreover, the meaning of $0\leq\omega$ agrees that in Def. \ref{lb139}
\end{df}




\begin{thm}[\textbf{Cauchy-Schwarz inequality}] \index{00@Cauchy-Schwarz inequality}
Let $\bk{\cdot|\cdot}$ be a positive sesquilinear form on $V$. Then for each $u,v\in V$ we have
\begin{align*}
|\bk{u|v}|\leq\Vert u\Vert\cdot\Vert v\Vert
\end{align*}
\end{thm}

\begin{proof}
By linear algebra, if $f:\Rbb^2\rightarrow\Rbb$ is a quadratic form
\begin{align*}
f(x,y)=\begin{pmatrix}
x&y
\end{pmatrix}\begin{pmatrix}
a&b\\
b&c
\end{pmatrix}
\begin{pmatrix}
x\\
y
\end{pmatrix}
=ax^2+2bxy+cy^2
\end{align*}
where $a,b,c\in\Rbb$, then $f\geq0$ iff $a\geq0,b\geq0$ and
\begin{align*}
ac-b^2\equiv\det\begin{pmatrix}
a&b\\
b&c
\end{pmatrix}\geq0
\end{align*}
In fact, we only need the fact that if $f\geq0$ then $ac-b^2\geq0$. To see this, note that if $f$ is not always $0$, then one of $a,c$ must be nonzero; otherwise, $f(x,y)=2bxy$ cannot be always $\geq0$. Thus, assume WLOG that $a\neq0$. Then $f(x,1)=ax^2+2bx+c=a(x+b/a)^2+c-b^2/a$, which implies $a>0$ and $c-b^2/a\geq0$, and hence $ac-b^2\geq0$.

Now, we let $f:\Rbb^2\rightarrow\Rbb_{\geq0}$ be the quadratic form defined by pulling back the form $\xi\in V\mapsto\bk{\xi|\xi}$ via the map $(x,y)\in\Rbb^2\mapsto xu+yv\in V$, that is,
\begin{align*}
f(x,y)=\bk{xu+yv|xu+yv}=\Vert u\Vert^2\cdot x^2+2\Real\bk{u|v}\cdot xy+\Vert v\Vert^2\cdot y^2
\end{align*}
Then, the above paragraph shows that $\Vert u\Vert^2\cdot\Vert v\Vert^2-(\Real\bk{u|v})^2\geq0$, equivalently,
\begin{align*}
|\Real\bk{u|v}|\leq \Vert u\Vert\cdot\Vert v\Vert
\end{align*}
Choose $\lambda\in\Sbb^1$ such that $\lambda\bk{u|v}\in\Rbb$. Since the above inequality holds when $v$ is replaced by $\lambda v$, we get
\begin{align*}
|\bk{u|v}|=|\Real\bk{u|\lambda v}|\leq\Vert u\Vert\cdot\Vert \lambda v\Vert=\Vert u\Vert\cdot\Vert v\Vert
\end{align*}
\end{proof}

\begin{co}
Let $\bk{\cdot|\cdot}$ be a positive sesquilinear form on $V$. Then we have
\begin{align*}
\{v\in V:\Vert v\Vert=0\}=\{v\in V:\bk{v|\xi}=0\text{ for all }\xi\in V\}
\end{align*}
where the RHS is clearly a linear subspace of $V$. We call this space the \textbf{null space} of $\bk{\cdot|\cdot}$. \index{00@Null space of a positive sesquilinear form}
\end{co}

\begin{proof}
Let $v\in V$. If $\bk{v|V}=0$, then $\Vert v\Vert^2=\bk{v|v}=0$. Conversely, if $\Vert v\Vert=0$, then by the Cauchy-Schwarz inequality, for each $\xi\in V$ we have $|\bk{u|\xi}|\leq \Vert u\Vert\cdot\Vert\xi\Vert=0$.
\end{proof}





\begin{co}\label{lb115}
Let $\bk{\cdot|\cdot}$ be a positive sesquilinear form on $V$. Then $v\in V\mapsto\Vert v\Vert\in\Rbb_{\geq0}$ is a seminorm on $V$. 
\end{co}

\begin{proof}
It remains to check the subadditivity: for each $u,v\in V$, the Cauchy-Schwarz inequality imlies
\begin{align*}
&\Vert u+v\Vert^2=\bk{u+v|u+v}=\Vert u\Vert^2+2\Real\bk{u|v}+\Vert u\Vert^2\\
\leq& \Vert u\Vert^2+2\Vert u\Vert\cdot\Vert v\Vert+\Vert v\Vert^2=(\Vert u\Vert+\Vert v\Vert)^2
\end{align*}
\end{proof}






\subsection{Inner product spaces and bounded sesquilinear forms}




\subsubsection{Inner product spaces}




\begin{df}
Let $\bk{\cdot|\cdot}$ be a positive sesquilinear form on a $\Cbb$-vector space $V$. We call $\bk{\cdot|\cdot}$ an \textbf{inner product} \index{00@Inner product} if it is  \textbf{non-degenerate}, i.e., the null space is $0$.  We call the pair $(V,\bk{\cdot|\cdot})$ (or simply call $V$) an \textbf{inner product space} or a \textbf{pre-Hilbert space} \index{00@Inner product space, also called pre-Hilbert space}.
\end{df}



\begin{exe}
Let $\bk{\cdot|\cdot}$ be a positive sesquilinear form on $V$ with null space $\scr N$. Prove that there is a (necessarily unique) inner product $\bk{\cdot|\cdot}_{V/\scr N}$ on the quotient space $V/\scr N$ such that for any $u,v\in V$, the cosets $u+\scr N$ and $v+\scr N$ satisfy
\begin{align*}
\bk{u+\scr N|v+\scr N }_{V/\scr N}=\bk{u|v}
\end{align*}
\end{exe}


\begin{eg}
Let $X$ be a set. Then $l^2(X)=l^2(X,\Cbb)$ is an inner product space, where
\begin{align*}
\bk{f|g}=\sum_{x\in X} \ovl{f(x)}g(x)\qquad\text{for any }f,g\in l^2(X)
\end{align*} 
\end{eg}


\begin{eg}
Let $(X,\mu)$ be a measure space. Then $L^2(X,\mu)$ is an inner product space, where
\begin{align*}
\bk{f|g}=\int_X \ovl fgd\mu\qquad\text{for any }f,g\in L^2(X,\mu)
\end{align*}
\end{eg}


\begin{rem}
By Rem. \ref{lb115}, an inner product space $V$ is equipped with the norm defined by $\vert v\Vert=\sqrt{\bk{v|v}}$. In particular, $V$ is a metric space with metric $d(u,v)=\Vert u-v\Vert$. The topology on $V$ induced by this metric is called the \textbf{norm topology} \index{00@Norm topology} of $V$. 
\end{rem}

\begin{rem}
Let $V,W$ be inner product spaces. If $T:V\rightarrow V$ is a linear map, then $T$ is an isometry of metric spaces iff $T$ is an isometry of normed vector spaces, i.e., 
\begin{align*}
\bk{Tv|Tv}=\bk{v|v}\qquad \text{for all }v\in V
\end{align*}
By the polarization identity, this is equivalent to
\begin{align*}
\bk{Tu|Tv}=\bk{u|v}\qquad \text{for all }u,v\in V
\end{align*} 
A surjective linear isometry $T:V\rightarrow W$ is called a \textbf{unitary map}. \index{00@Unitary maps} If $T:V\rightarrow W$ is unitary, we say that $V,W$ are \textbf{isomorphic inner product spaces} (or that $V,W$ are \textbf{unitarily equivalent}). \index{00@Unitarily equivalent} 


Similarly, if $T:V\rightarrow V$ is antilinear map between inner product spaces, then $T$ is an isometry of metric spaces iff
\begin{align*}
\bk{Tv|Tv}=\bk{v|v}\qquad \text{for all }v\in V
\end{align*}
By the polarization identity, this is equivalent to
\begin{align*}
\bk{Tu|Tv}=\bk{v|u}\qquad \text{for all }u,v\in V
\end{align*}
A surjective antilinear isometry $T:V\rightarrow W$ is called an \textbf{antiunitary map}. \index{00@Antiunitary map} If $T:V\rightarrow W$ is antiunitary, we say that $V$ and $W$ are \textbf{antiunitarily equivalent}. \hqed
\end{rem}



\subsubsection{Bounded sesquilinear forms}




Let $V,W$ be inner product spaces.



\begin{df}
The \textbf{(complex) conjugate} \index{00@Conjugate inner product space $V^\Co$} of $V$ is the inner product space $V^\Co$ \index{VCo@$V^\Co$} defined as follows. The elements of $V^\Co$ correspond bijectively to those of $V$ by the map \index{vc@$v^\Co=\ovl v$}
\begin{align*}
\Co:V\rightarrow V^\Co\qquad v\mapsto v^\Co\equiv\ovl v
\end{align*}
where $v^\Co\equiv\ovl v$ is an abstract element, called the \textbf{conjugate} of $v$. Moreover, the structure of an inner product space on $V^\Co$ is defined in such a way that $\Co$ is antiunitary. In other words, for each $u,v\in V$ and $a,b\in\Cbb$, we have
\begin{gather*}
\ovl a\cdot\ovl u+\ovl b\cdot\ovl v:=\ovl{au+bv}\\
\bk{\ovl u|\ovl v}_{V^\Co}:=\ovl{\bk{u|v}_V}=\bk{v|u}_V
\end{gather*}

The conjugate of $V^\Co$ is defined to be $V$, that is,
\begin{align*}
(V^\Co)^\Co=V
\end{align*}
Moreover, the conjugate map $\Co:V^\Co\rightarrow V$ is defined by
\begin{align*}
\Co:V^\Co\rightarrow V\qquad \ovl v\mapsto v
\end{align*}
Thus $\ovl{\ovl v}=v$ for each $v\in V$. \hqed
\end{df}


\begin{rem}
An antilinear map $T:V\rightarrow W$ is equivalent to the linear map
\begin{subequations}\label{eq61}
\begin{gather}\label{eq61a}
V\rightarrow W^\Co\qquad v\mapsto \ovl{Tv}
\end{gather}
and is also equivalent to the linear map
\begin{align}\label{eq61b}
V^\Co\rightarrow W\qquad \ovl v\mapsto Tv
\end{align}
\end{subequations}
It is clear that $T$ is an antilinear isometry (resp. antiunitary) iff \eqref{eq61a} is a linear isometry (resp. unitary) iff \eqref{eq61b} is a linear isometry (resp. unitary).
\end{rem}


\begin{rem}
A sesquilinear form $\omega:V\times W\rightarrow \Cbb$ is equivalent to a bilinear form
\begin{align*}
\wtd\omega:V^\Co\times W\rightarrow\Cbb\qquad (\ovl v,w)\mapsto \bk{v|w}
\end{align*}
Unless otherwise stated, we always view $\omega$ and $\wtd\omega$ as the same.
\end{rem}

\begin{df}
Let $\omega:V\times W\rightarrow\Cbb$ be a sesquilinear form. The \textbf{norm} \index{00@Norm of sesquilinear forms} $\Vert\omega\Vert$ is defined to be the norm of the associated bilinear form $V^\Co\times W\rightarrow\Cbb$. Therefore, 
\begin{align*}
\Vert\omega\Vert=\sup_{v\in\ovl B_V(0,1),w\in\ovl B_W(0,1)}|\omega(u|v)|
\end{align*}
Recalling the notation \eqref{eq26}, we let \index{Sesq@$\Ses(V\vert W)$ and $\Ses(V)$}
\begin{align*}
\Ses(V|W):=\fk L(V^\Co\times W,\Cbb)
\end{align*}
which is the space of bounded sesquilinear forms $V\times W\rightarrow\Cbb$. We write
\begin{align*}
\Ses(V):=\Ses(V|V)
\end{align*}
The elements of $\Ses(V|W)$ (resp. $\Ses(V)$) are called \textbf{bounded sesquilinear forms} \index{00@Bounded sesquilinear forms} on $V\times W$ (resp. on $V$).
\end{df}


\begin{eg}\label{lb125}
The inner product
\begin{align*}
\bk{\cdot|\cdot}:V\times V\rightarrow\Cbb\qquad (u,v)\mapsto\bk{u|v}
\end{align*}
has norm $1$, and hence belongs to $\Ses(V)$. Therefore, by Prop. \ref{lb35}, this map is continuous.
\end{eg}



\subsection{Orthogonality}



Let $V$ be an inner product spaces.



\subsubsection{Orthogonal and orthonormal vectors}

\begin{df}
A set $\fk S$ of vectors of $V$ are called \textbf{orthogonal} \index{00@Orthogonal} if $\bk{u|v}=0$ for any distinct $u,v\in V$. An orthogonal set $\fk S$ is called \textbf{orthonormal} \index{00@Orthonormal} if $\Vert v\Vert=1$ for all $v\in V$. 
\end{df}

\begin{rem}
We will also talk about an \textbf{orthogonal} resp.  \textbf{orthonormal family of vectors} $(e_i)_{i\in I}$. This means that $\bk{e_i|e_j}=0$ for any distinct $i,j\in I$ (resp. $\bk{e_i|e_j}=\delta_{i,j}$ for any $i,j\in I$). 
\end{rem}

In particular, two vectors $u,v\in V$ are called orthogonal and written as \index{uv@$u\perp v$}
\begin{align*}
u\perp v
\end{align*}
when $\bk{u|v}=0$. A fundamental fact about orthogonal vectors is
\begin{pp}[\textbf{Pythagorean identity}]\index{00@Pythagorean identity}
Suppose that $u,v\in V$ are orthogonal. Then
\begin{align}\label{eq62}
\Vert u+v\Vert^2=\Vert u\Vert^2+\Vert v\Vert^2
\end{align}
In particular,
\begin{align}\label{eq63}
\Vert v\Vert\leq\Vert u+v\Vert
\end{align}
\end{pp}


\begin{proof}
$\Vert u+v\Vert^2=\bk{u+v|u+v}=\bk{u|u}+\bk{v|v}+2\Real \bk{u|v}=\bk{u|u}+\bk{v|v}$.
\end{proof}


Note that by applying \eqref{eq62} repeatedly, we see that if $v_1,\dots,v_n\in V$ are orthogonal, then
\begin{align}\label{eq64}
\Vert v_1+\cdots+v_n\Vert^2=\Vert v_1\Vert^2+\cdots+\Vert v_n\Vert^2
\end{align}



\begin{rem}
Suppose that $\fk S$ is an orthonormal set of vectors of $V$. Then $\fk S$ is clearly linearly independent. (If $e_1,\dots,e_n\in\fk S$ and $\sum_i a_ie_i=0$, then $a_j=\sum_i\bk{e_j|a_ie_i}=\bk{e_j|0}=0$.) Thus, by linear algebra, if $\fk S=\{e_1,\dots,e_n\}$ is finite, then one can find uniquely $a_1,\dots,a_n\in\Cbb$ and $u\in V$ such that $v=a_1e_1+\cdots+a_ne_n+u$ and that $u$ is orthogonal to $e_1,\dots,e_n$. The expressions of $a_1,\dots,a_n,u$ can be expressed explicitly:
\end{rem}


\begin{pp}[\textbf{Gram-Schmidt}]\index{00@Gram-Schmidt}
Let $e_1,\dots,e_n$ be orthonormal vectors in $V$. Let $v\in V$. Then
\begin{align}
v-\sum_{i=1}^n e_i\cdot \bk{e_i|v}
\end{align}
is orthogonal to $e_1,\dots,e_n$.
\end{pp}

\begin{proof}
This is a direct calculation and is left to the readers.
\end{proof}


\begin{rem}\label{lb117}
``Gram-Schmidt" usually refers to the following process. Let $v_1,\dots,v_n$ be a set of linearly independent vectors of $V$. Then there is an algorithm of finding an orthonormal basis of $U=\Span\{v_1,\dots,v_n\}$: Let $e_1=v_1/\Vert v_1\Vert$. Suppose that a set of orthonormal vectors $e_1,\dots,e_k$ in $U$ have been found. Then $e_{k+1}$ is defined by $\wtd v_{k+1}/\Vert\wtd v_{k+1}\Vert$ where $\wtd v_{k+1}=v_{k+1}-\sum_{i=1}^k e_i\cdot\bk{e_i|v_{k+1}}$.
\end{rem}



Combining Pythagorean with Gram-Schmidt, we have:
\begin{co}[\textbf{Bessel's inequality}]\label{lb118}
Let $(e_i)_{i\in I}$ be a family of orthonormal vectors of $V$. Then for each $v\in V$ we have
\begin{align}\label{eq65}
\sum_{i\in I}|\bk{e_i|v}|^2\leq \Vert v\Vert^2
\end{align}
In particular, the set $\{i\in I:\bk{e_i|v}\neq0\}$ is countable.
\end{co}




\begin{proof}
The LHS of \eqref{eq65} is $\lim_{J\in\fin(2^I)}\sum_{j\in J}|\bk{e_j|v}|^2$. Thus, it suffices to show that for each $J\in\fin(2^I)$ we have $\sum_{j\in J}|\bk{e_j|v}|^2\leq \Vert v\Vert^2$. Let 
\begin{align*}
u_1=\sum_{j\in J}e_j\cdot\bk{e_j|v} \qquad u_2=v-u_1
\end{align*}
(Namely, $v=u_1+u_2$ is the orthogonal decomposition of $v$ with respect to $\Span\{e_j:j\in J\}$.) By Gram-Schmidt, we have $\bk{u_1|u_2}=0$. By Pythagorean, we have $\Vert u_1\Vert^2\leq\Vert v\Vert^2$. But Pythagorean \eqref{eq64} also implies
\begin{align*}
\Vert u_1\Vert^2=\sum_{j\in J}|\bk{e_j|v}|^2
\end{align*}
The last statement about countability follows from .
\end{proof}



\subsubsection{Orthogonal decomposition}


\begin{df}\label{lb119}
Let $U$ be a linear subspace of $V$. Let $v\in V$. An \textbf{orthogonal decomposition} \index{00@Orthogonal decomposition and orthonal projection} of $v$ with respect to $U$ is an expression of the form
\begin{align*}
v=u+w\qquad \text{where $u\in U$ and $w\perp U$}
\end{align*}
Orthogonal decompositions of $v$ are unique if exist. We call $u$ the \textbf{orthogonal projection} of $v$ onto $U$.
\end{df}

\begin{proof}[Proof of uniqueness]
Suppose that $v=u'+w'$ is another orthogonal decomposition. Then $u-u'$ equals $w'-w$. Let $\xi=u-u'$. Then $\xi\in U$ and $\xi\perp U$. So $\bk{\xi|\xi}=0$, and hence $\xi=0$. So $u=u'$ and $w=w'$.
\end{proof}


\begin{eg}\label{lb124}
Let $e_1,\dots,e_n$ be orthonormal vectors of $V$. Let $U=\Span\{e_1,\dots,e_n\}$. Choose any $v\in V$. Then by Gram-Schmidt,
\begin{align}
v=u+w\qquad\text{where }u=\sum_{i=1}^ne_i\cdot\bk{e_i|v}\text{ and }w=v-u
\end{align}
is the orthogonal decomposition of $v$ with respect to $U$.
\end{eg}

\begin{pp}\label{lb120}
Let $U$ be a linear subspace of $V$. Suppose that $v\in V$ has orthogonal decomposition $v=u+w$ with respect to $U$. Then
\begin{align}
\Vert v-u\Vert=\inf_{\xi\in U}\Vert v-\xi\Vert
\end{align}
\end{pp}


\begin{proof}
Clearly ``$\geq$" holds. Choose any $\xi\in U$. Then $v-\xi=v-u+u-\xi=w+(u-\xi)$. Since $u-\xi\in U$, we have $w\perp u-\xi$. Thus, by Pythagorean, we have $\Vert w\Vert\leq\Vert v-\xi\Vert$.
\end{proof}



\subsubsection{Orthonormal basis}



\begin{df}\label{lb121}
A set $\fk S$ (or a family $(e_i)_{i\in I}$) of orthonormal vectors of $V$ is called an \textbf{orthonormal basis} \index{00@Orthonormal basis} of $V$ if it spans a dense subspace of $V$.  
\end{df}

\begin{eg}
If $X$ is a set, by Prop. \ref{lb109}, $l^2(X)$ has an orthonormal basis $(\chi_{\{x\}})_{x\in X}$.
\end{eg}


\begin{eg}\label{lb122}
If $V$ is separable, then $V$ has a countable orthonormal basis.
\end{eg}

\begin{proof}
Let $\{v_1,v_2,\dots\}$ be a dense subset of $V$ where $v_1\neq 0$. Then by Gram-Schmidt (Rem. \ref{lb117}), we can find $e_1,e_2,\dots\in V$ such that the set $\{e_1,e_2,\dots\}$ is orthnormal (after removing the duplicated terms), and that $\Span\{v_1,\dots,v_n\}=\Span\{e_1,\dots,e_n\}$ for each $n$. Then $\{e_1,e_2,\dots\}$ clearly spans a dense subspace of $V$.
\end{proof}

We remark that there are non-separable and non-complete inner product spaces that do not have orthonormal bases. See \cite{Gud74}.


\begin{thm}\label{lb123}
Suppose that $(e_i)_{i\in I}$ is an orthonormal basis of $V$. Then for each $v\in V$, the RHS of the following converges (under the norm of $V$) to the LHS:
\begin{align}
v=\sum_{i\in I}e_i\cdot\bk{e_i|v}
\end{align}
\end{thm}

\begin{proof}
Note that for $J\in\fin(2^I)$, the expression
\begin{align*}
\Big\Vert v-\sum_{j\in J}e_j\cdot\bk{e_j|v}\Big\Vert^2=\Vert v\Vert^2-\sum_{j\in J}|\bk{e_j|v}|^2
\end{align*}
decreases when $J$ increases. Thus, it suffices to prove that the $\inf_{J\in \fin(2^I)}$ of this expression is $0$. 

By assumption,  we can find $J\in\fin(2^I)$ and $(\lambda_j)_{j\in J}$ in $\Cbb$ such that $\Vert v-\sum_{j\in J}\lambda_je_j\Vert$ is small enough. On the other hand, applying Prop. \ref{lb120} to the orthogonal projection $v=u+w$ where $w=\sum_{j\in J}e_j\cdot\bk{e_j|v}$ (cf. Exp. \ref{lb124}), we have
\begin{align}
\Big\Vert v-\sum_{j\in J}e_j\cdot\bk{e_j|v}\Big\Vert\leq \Big\Vert v-\sum_{j\in J}\lambda_je_j\Big\Vert
\end{align}
Thus, the infimum of the LHS over $J\in\fin(2^I)$ is zero.
\end{proof}



\begin{co}[\textbf{Parseval's identity}]\index{00@Parseval's identity}\label{lb601}
Suppose that $(e_i)_{i\in I}$ is an orthonormal basis of $V$. Then for each $u,v\in V$ we have
\begin{align}\label{eq246}
\bk{u|v}=\sum_{i\in I}\bk{u|e_i}\cdot\bk{e_i|v}
\end{align}
In particular,
\begin{align}
\Vert v\Vert^2=\sum_{i\in I}|\bk{e_i|v}|^2
\end{align}
\end{co}

\begin{proof}
By Thm. \ref{lb123}, $v=\lim_{J\in\fin(2^I)}v_J$ where $v_J=\sum_{j\in J}e_j\cdot\bk{v|e_j}$. By the continuity of $\bk{\cdot|\cdot}:V\times V\rightarrow\Cbb$ (Exp. \ref{lb125}), we have
\begin{align*}
\bk{u|v}=\lim_{J\in\fin(2^I)}\bk{u|v_J}=\lim_{J\in\fin(2^I)}\sum_{j\in J}\bk{u|e_j}\cdot\bk{e_j|v}=\sum_{i\in I}\bk{u|e_i}\cdot\bk{e_i|v}
\end{align*}
\end{proof}



\begin{co}\label{lb126}
Suppose that $(e_x)_{x\in X}$ is an orthonormal basis of $V$. Then there is a linear isometry
\begin{gather}\label{eq66}
\Phi:V\rightarrow l^2(X)\qquad v\mapsto \big(\bk{e_x|v})_{x\in X}
\end{gather} 
whose range is dense in $l^2(X)$.
\end{co}




\begin{proof}
Parseval's identity shows that $(\bk{e_x|v})_{x\in X}$ has finite $l^2$-norm $\Vert v\Vert$. So the map $\Phi$ defined by \eqref{eq66} is clearly a linear isometry. The density of the range of $\Phi$ follows from the fact that $l^2(X)$ contains all $\chi_{\{x\}}=\Phi(e_x)$, and that $\Span\{\chi_{\{x\}}:x\in X\}$ is dense in $l^2(X)$ (cf. Prop. \ref{lb109}).
\end{proof}




\subsection{Hilbert spaces}


\begin{thm}\label{lb129}
Let $\MH$ be an inner product space. Then the following three conditions are equivalent:
\begin{enumerate}[label=(\alph*)]
\item $\MH$ is (Cauchy) complete.
\item For each orthonormal family $(e_i)_{i\in I}$ in $\MH$, and for each family $(a_i)_{i\in I}$ in $\Cbb$ satisfying $\sum_{i\in I}|a_i|^2<+\infty$, the unordered sum $\sum_{i\in I}a_ie_i$ converges (under the norm of $\MH$).
\item $\MH$ is unitarily equivalent to $l^2(X)$ for some set $X$.
\end{enumerate} 
If $\MH$ satisfies any of these conditions, we say that $\MH$ is a \textbf{Hilbert space}.
\end{thm}



\begin{proof}
(c)$\Rightarrow$(a): By Thm. \ref{lb127}, $l^2(X)$ is the dual space of $l^2(X)$. Since any dual space is complete (Cor. \ref{lb128}), $l^2(X)$ is complete.

(a)$\Rightarrow$(b): Since $\sum_i |a_i|^2<+\infty$, for each $\eps>0$ there exists $J\in\fin(2^I)$ such that for all finite $K\subset I\setminus J$ we have $\sum_{k\in K}|a_k|^2<\eps$, and hence, by the Pythagorean identity,
\begin{align*}
\Big\Vert \sum_{k\in K}a_ke_k\Big\Vert^2=\sum_{k\in K}|a_ke_k|^2<\eps
\end{align*}
Thus $(\sum_{j\in J}a_je_j)_{J\in\fin(2^I)}$ is a Cauchy net. By the completeness of $\MH$, we see that $\sum_{i\in I}a_ie_i$ converges.

(b)$\Rightarrow$(c): Assume (b). We first show that $\MH$ has an orthonormal basis. By Zorn's lemma, we can find a maximal (with respect to the partial order $\subset$) set of orthonormal vectors, written as a family $(e_i)_{i\in I}$. The maximality implies that every nonzero vector $\xi\in \MH$ is not orthogonal to some $e_i$. (Otherwise, $\{e_i:i\in I\}$ can be extended to $\{e_i:i\in I\}\cup\{\xi/\Vert\xi\Vert\}$.)

Let us prove that $(e_i)_{i\in I}$ is an orthonormal basis. Suppose not. Then $U=\Span\{e_i:i\in I\}$ is not dense in $\MH$. Let $\xi\in \MH\setminus \ovl{U}$. By Bessel's inequality, we have
\begin{align*}
\sum_{i\in I}|\bk{e_i|\xi}|^2<+\infty
\end{align*}
Therefore, by (b),
\begin{align}
\sum_{i\in I}e_i\cdot\bk{e_i|\xi}
\end{align}
converges to some vector $\eta\in \MH$. By the continuity of $\bk{\cdot|\cdot}$ (Exp. \ref{lb125}), we see that $\bk{e_i|\eta}=\bk{e_i|\xi}$ for all $i$, and hence
\begin{align}
\bk{e_i|\xi-\eta}=0\qquad\text{ for all }i\in I
\end{align}
Since $\eta\in\ovl U$ and $\xi\notin\ovl U$, we conclude that $\xi-\eta$ is a nonzero vector orthogonal to all $e_i$. This contradicts the maximality of $(e_i)_{i\in I}$.

Now we have an orthonormal basis $(e_i)_{i\in I}$. By Cor. \ref{lb126}, we have a linear isometry
\begin{align*}
\Phi:\MH\rightarrow l^2(I)\qquad \xi\mapsto \big(\bk{e_i|\xi}\big)_{i\in I}
\end{align*}
with dense range. If $(a_i)_{i\in I}$ belongs to $l^2(I)$, by (b), the unordered sum $\sum_{i\in I}a_ie_i$ converges to some $\xi\in \MH$. Clearly $\Phi(\xi)=(a_i)_{i\in I}$. This proves that $\Phi$ is surjective, and hence is a unitary map. So $\MH\simeq l^2(I)$.
\end{proof}


In the proof of Thm. \ref{lb129}, we use Zorn's lemma to show that every Hilbert space $\MH$ admits an orthonormal basis. The same argument yields a stronger result:

\begin{pp}\label{lb137}
Let $\MH$ be a Hilbert space. Then any orthonormal family of vectors in $\MH$ can be extended to an orthonormal basis.
\end{pp}

When $\MH$ is separable, this proposition can be proved without invoking Zorn's lemma, by applying mathematical induction together with the Gram-Schmidt process (Rem. \ref{lb117}). We leave the details of the proof of Prop. \ref{lb137} to the reader.



\begin{eg}
By Thm. \ref{lb129}, if $X$ is a set, then $l^2(X)$ is a Hilbert space.
\end{eg}


\begin{eg}
Let $(X,\mu)$ be a measure space. By the Riesz-Fischer Thm. \ref{lb26}, the inner product space $L^2(X,\mu)$ is a Hilbert space.
\end{eg}

\begin{eg}
If $V$ is a closed linear subspace of $\MH$ whose inner product is inherited from that of $\MH$, then $V$ is a Hilbert space. This is either due to Thm. \ref{lb129}-(b), or due to the fact that a closed subset of a complete metric space is complete.
\end{eg}


\begin{co}\label{lb130}
Every Hilbert space $\mc H$ has an orthonormal basis. Moreover, $\mc H$ is separable iff the orthonormal basis can be chosen to be countable.
\end{co}

\begin{proof}
That $\mc H$ has an orthonormal basis follows from the proof of Thm. \ref{lb129} or from the fact that $l^2(X)$ has an orthonormal basis $(\chi_{\{x\}})_{x\in X}$. If $X$ is countable, then $l^2(X)$ has dense subset $\Span_{\Qbb+\im\Qbb}\{\chi_{\{x\}}:x\in X\}$ and hence is separable. Conversely, we have proved in Exp. \ref{lb122} that every separable inner product space has a countable orthonormal basis.
\end{proof}


\begin{thm}\label{lb131}
Let $(e_x)_{x\in X}$ be an orthonormal basis of a Hilbert space $\mc H$. Then we have a unitary map
\begin{gather}
\mc H\xlongrightarrow{\simeq} l^2(X)\qquad \xi\mapsto\big(\bk{e_x|\xi}\big)_{x\in X}
\end{gather}
\end{thm}



\begin{proof}
This is clear from the proof of Thm. \ref{lb129}.
\end{proof}



\subsection{Bounded linear maps, sesquilinear forms, and matrices}



In this section, we let $U,V,W$ be inner product spaces.



In Subsec. \ref{lb132}, we discussed the close relationship between bounded linear maps and bounded bilinear forms in the general setting of normed vector spaces. This connection allows us to combine the strengths of both perspectives. One key advantage of the perspective of linear operators is that the space $\fk L(V)$ is particularly well-suited for symbolic calculus.


In this section, we explore this relationship in the context of inner product spaces and Hilbert spaces. We will see that the passage from $\fk L(V)$ to bounded sesquilinear forms fundamentally relies on the Riesz–Fréchet theorem, a pivotal result that enables this correspondence.


\subsubsection{The Riesz-Fr\'echet representation theorem}


\begin{df}
If $T\in\Lin(V,W)$, we let $\omega_T$ be the sesquilinear form \index{zz@$\omega_T$}
\begin{gather*}
\omega_T:W\times V\rightarrow\Cbb \qquad (w,v)\mapsto \bk{w|Tv}
\end{gather*}
\end{df}

\begin{pp}\label{lb133}
For each $T\in\Lin(V,W)$, we have
\begin{align*}
\Vert T\Vert=\Vert\omega_T\Vert
\end{align*}
Consequently, $T$ is bounded iff $\omega_T$ is so, and the map $T\in\Lin(V,W)\mapsto \omega_T$ is injective.
\end{pp}



\begin{proof}
For each $v\in V,w\in W$, we have
\begin{align*}
|\omega_T(w|v)|=|\bk{w|Tv}|\leq\Vert Tv\Vert\cdot\Vert w\Vert\leq \Vert T\Vert\cdot\Vert v\Vert\cdot\Vert w\Vert
\end{align*}
Applying $\sup$ over all $v,w$ in the closed unit balls, we get $\Vert\omega_T\Vert\leq\Vert T\Vert$. Moreover,
\begin{align*}
\Vert Tv\Vert^2=\omega_T(Tv|v)\leq\Vert \omega_T\Vert\cdot \Vert Tv\Vert\cdot\Vert v\Vert
\end{align*}
and hence $\Vert Tv\Vert\leq \Vert\omega_T\Vert\cdot\Vert v\Vert$. Applying $\sup$ over all $v$ in the closed unit ball, we get $\Vert T\Vert\leq\Vert\omega_T\Vert$.
\end{proof}





By Prop. \ref{lb133}, the map $T\in\Lin(V,W)$ restricts to a linear isometry of normed vector spaces
\begin{gather}
\fk L(V,W)\rightarrow \Ses(W|V)\qquad T\mapsto\omega_T
\end{gather}
On the other hand, Cor. \ref{lb134} implies
\begin{align*}
\Ses(W|V)=\fk L(W^\Co\times V,\Cbb)\simeq\fk L(V,(W^\Co)^*)
\end{align*}
and hence a linear isometry
\begin{align}\label{eq67}
\fk L(V,W)\rightarrow \fk L(V,(W^\Co)^*)
\end{align}

\begin{exe}
Show that the map \eqref{eq67} sends each $T\in\fk L(V,W)$ to $\Phi\circ T$, where $\Phi:W\rightarrow (W^\Co)^*$ is defined below.
\end{exe}



\begin{thm}[\textbf{Riesz-Fr\'echet representation theorem}] \index{00@Riesz-Fr\'echet representation theorem}\label{lb135}
The following map is a linear isometry:
\begin{subequations}\label{eq68}
\begin{align}
\Phi:W\rightarrow (W^\Co)^*\qquad \xi\mapsto \bk{\ovl\xi|-}
\end{align}
where $\bk{\ovl\xi|-}$ denotes the bounded linear functional
\begin{align}
\bk{\ovl\xi|-}:W^\Co\rightarrow\Cbb\qquad \ovl w\mapsto\bk{\ovl\xi|\ovl w}_{W^\Co}=\bk{w|\xi}_W
\end{align}
\end{subequations}
Moreover, $W$ is a Hilbert space iff $\Phi$ is surjective (and hence an isomorphism of normed vector spaces).
\end{thm}

In other words, $\Phi$ is determined by the fact that for each $w,\xi\in W$, 
\begin{align}
\bk{\ovl w,\Phi\xi}=\bk{w|\xi}
\end{align}


\begin{proof}
First, note that for each $\xi\in W$,
\begin{align}
\Vert\xi\Vert=\sup_{w\in\ovl B_W(0,1)}|\bk{w|\xi}|
\end{align}
Indeed, the Cauchy-Schwarz inequality implies ``$\geq0$". The equality can be achieved by choosing $w=\xi/\Vert\xi\Vert$ if $\xi\neq0$. Therefore,
\begin{align*}
\Vert\Phi(\xi)\Vert=\sup_{\ovl w\in\ovl B_{W^\Co}(0,1)}|\bk{\ovl w,\Phi(\xi)}|=\sup_{w\in\ovl B_W(0,1)}|\bk{w|\xi}|=\Vert\xi\Vert
\end{align*}
This proves that $\Phi$ is a linear isometry.

If $\Phi$ is surjective, then the normed vector space $W$ is isomorphic to the dual space $(W^\Co)^*$ where the latter is complete by Cor. \ref{lb128}. Therefore, $W$ is a Hilbert space.

Conversely, assume that $W$ is a Hilbert space. Then we can assume that $W=l^2(X)$ for some set $X$. The surjectivity of $\Phi$ then follows from the surjectivity of the map
\begin{align*}
l^2(X)\rightarrow l^2(X)^*\qquad \xi\mapsto \bk{-,\xi}
\end{align*}
due to Thm. \ref{lb127}.
\end{proof}


\begin{df}
The map $\Phi$ in Thm. \ref{lb135} is called the \textbf{Riesz isometry} of $W$. If $W$ is a Hilbert space, then $\Phi$ is called the \textbf{Riesz isomorphism} of $W$. \index{00@Riesz isometry/isomorphism} An equivalent description of $\Phi$ is as follows: In view of the isomorphism
\begin{align*}
\Ses(W)=\fk L(W^\Co\times W,\Cbb)\simeq\fk L(W,(W^\Co)^*)
\end{align*}
due to Cor. \ref{lb134}, the Riesz isometry $\Phi$ is the element of $\fk L(W,(W^\Co)^*)$ corresponding the the inner product $\bk{\cdot|\cdot}_W$ as an elemet of $\Ses(W)$.
\end{df}


\subsubsection{Equivalence between bounded linear maps and bounded sesquilinear forms}






With the help of the Riesz-Fr\'echet theorem, we can establish the equivalence between bounded linear maps and bounded sesquilinear forms.

\begin{thm}\label{lb136}
Let $\MH,\MK$ be Hilbert spaces. Then we have an isomorphism of normed vector spaces
\begin{gather}
\fk L(\MH,\MK)\xlongrightarrow{\simeq}\Ses(\MK|\MH)\qquad T\mapsto\omega_T
\end{gather}
In particular, when $\MH=\MK$, the above isomorphism becomes
\begin{gather}
\fk L(\MH)\xlongrightarrow{\simeq}\Ses(\MH)\qquad T\mapsto\omega_T
\end{gather}
\end{thm}


\begin{proof}
By Cor. \ref{lb134}, we have
\begin{align*}
\fk L(\MH,(\MK^\Co)^*)\simeq\fk L(\MK^\Co\times\MH,\Cbb)=\Ses(\MK|\MH)
\end{align*}
where each $S\in\fk L(\MH,(\MK^\Co)^*)$ corresponds to the bounded bilinear form
\begin{align*}
\MK^\Co\times\MH\rightarrow\Cbb\qquad (\ovl\eta,\xi)\mapsto \bk{\ovl\eta,S\xi}
\end{align*}
equivalently, the bounded sesquilinear form
\begin{align*}
\MK\times\MH\rightarrow\Cbb\qquad (\eta,\xi)\mapsto \bk{\ovl\eta,S\xi}
\end{align*}
Now, suppose that $S=\Phi\circ T$ where $T\in\fk L(\MH,\MK)$, and $\Phi:\MK\xlongrightarrow{\simeq}(\MK^\Co)^*$ is the Riesz-isomorphism of $\MK$ defined in Thm. \ref{lb135}. Then $\bk{\ovl\eta|\Phi\mu}=\bk{\eta|\mu}$ for each $\mu,\eta\in\MK$, and hence
\begin{align*}
\bk{\ovl\eta,S\xi}=\bk{\ovl\eta,\Phi\circ T\xi}=\bk{\eta|T\xi}=\omega_T(\eta|\xi)
\end{align*}
Therefore, the isomorphism
\begin{align*}
\fk L(\MH,\MK)\xlongrightarrow[\simeq]{T\mapsto\Phi\circ T}\fk L(\MH,(\MK^\Co)^*)\simeq\Ses(\MK|\MH)
\end{align*}
sends $T$ to $\omega_T$.
\end{proof}


\subsubsection{Adjoint operators, self-adjoint operators and positive operators}


Let $\MH,\MK$ be Hilbert spaces. With the help of Thm. \ref{lb136}, we can define adjoint operators:


\begin{df}
Recall that for each $\omega\in\Ses(\MK|\MH)$, the \textbf{adjoint sesquilinear form} $\omega^*\in\Ses(\MH|\MK)$ is defined by $\omega^*(\xi|\eta)=\ovl{\omega(\eta|\xi)}$ for each $\xi\in\MH,\eta\in\MK$. It is clear that
\begin{align*}
\Vert\omega^*\Vert=\Vert\omega\Vert
\end{align*}
Now, for each $T\in\fk L(\MH,\MK)$, define the \textbf{adjoint operator} \index{00@Adjoint operator} $T^*\in\fk L(\MK,\MH)$ such that
\begin{align*}
\omega_{T^*}=(\omega_T)^*
\end{align*}
More explicitly, $T^*$ is determined by the fact that for each $\xi\in\MH,\eta\in\MK$,
\begin{align*}
\bk{\eta|T\xi}=\bk{T^*\eta|\xi}
\end{align*}
Then, we clearly also have $\Vert T\Vert=\Vert T^*\Vert$.
\end{df}



\begin{exe}
Show that
\begin{align*}
*:\fk L(\MH,\MK)\rightarrow\fk L(\MK,\MH)\qquad T\mapsto T^*
\end{align*}
is a bijective antilinear map, and that $(T^*)^*=T$. Prove that if $\MM$ is a Hilbert space and $T\in\fk L(\MH,\MK),S\in\fk L(\MK,\MM)$, then
\begin{align*}
(ST)^*=T^*S^*
\end{align*}
\end{exe}


\begin{df}
A bounded linear operator $T\in\fk L(\MH)$ is called \textbf{self-adjoint} \index{00@Self-adjoint bounded linear operators} if $T=T^*$, equivalently, if $\omega_T$ is self-adjoint.
\end{df}


\begin{df}
Let $A,B\in\fk L(\MH)$. We write
\begin{align*}
\pmb{A\leq B}
\end{align*}
if $\omega_A\leq\omega_B$ in the sense of Def. \ref{lb140}, that is, $\bk{\xi|A\xi}\leq\bk{\xi|B\xi}$ for all $\xi\in\MH$. We say that $A\in\fk L(\MH)$ is \textbf{positive} \index{00@Positive bounded linear operators} if $A\geq0$, equivalently, if $\omega_A$ is positive. 
\end{df}




\subsubsection{Composition of bounded linear operators and bounded sesquilinear forms}


Let $\MH,\MK,\MM$ be Hilbert spaces.

One of the major advantages of working with bounded linear operators rather than bounded sesquilinear forms is the ease with which one can handle problems involving operator composition. This does not mean, however, that a notion of composition cannot be defined on the side of sesquilinear forms. In fact, the following lemma illustrates how such a composition can be defined.

\begin{lm}\label{lb138}
Let $S\in\fk L(\MK,\MM)$ and $T\in\fk L(\MH,\MK)$. Let $(e_i)_{i\in I}$ be an orthonormal basis of $\MK$. Then for each $\xi\in\MH$, we have
\begin{align}\label{eq69}
S\circ T\xi=\sum_{i\in I}Se_i\cdot\bk{e_i|T\xi}
\end{align}
where the unordered sum on the RHS converges in norm to the LHS.
\end{lm}

\begin{proof}
By Thm. \ref{lb123}, we have $T\xi=\sum_i e_i\cdot\bk{e_i|T\xi}$. Therefore, by the linearity and the continuity of $S$, we get \eqref{eq69}.
\end{proof}


\begin{df}
Let $\sigma\in\Ses(\MM|\MK)$ and $\omega\in\Ses(\MK|\MH)$. Then the \textbf{composition} \pmb{$\sigma\circ\omega$} \index{00@Composition of sesquilinear forms} is the element of $\Ses(\MM|\MH)$ defined by
\begin{align*}
(\sigma\circ\omega)(\psi|\xi)=\sum_{i\in I}\sigma(\psi|e_i)\cdot\omega(e_i|\xi)\qquad\text{for all }\psi\in\MM,\xi\in\MH
\end{align*}
where $(e_i)_{i\in I}$ is a basis of $\MK$. This definition is independent of the choice of basis. Moreover, by Lem. \ref{lb138}, for each $S\in\fk L(\MK,\MM)$ and $T\in\fk L(\MH,\MK)$, we have
\begin{align*}
\omega_{S\circ T}=\omega_S\circ\omega_T
\end{align*}
\end{df}



However, many properties about composition that are straightforward from the perspective of bounded linear operators become far less transparent when viewed in terms of sesquilinear forms. For instance, consider the following basic result:

\begin{pp}
Let $\MU,\MV,\MW$ be normed vector spaces. Let  $S\in\fk L(\MV,\MW)$ and $T\in\fk L(\MU,\MV)$. Then
\begin{align*}
\Vert ST\Vert\leq \Vert S\Vert\cdot\Vert T\Vert
\end{align*}
\end{pp}

\begin{proof}
Apply $\sup$ over all $\xi\in\ovl B_\MU(0,1)$ to
\begin{align*}
\Vert ST\xi\Vert\leq\Vert S\Vert\cdot \Vert T\xi\Vert\leq \Vert S\Vert\cdot\Vert T\Vert\cdot\Vert\xi\Vert
\end{align*}
\end{proof}





Before we explore further examples, let us examine another foundational perspective that played a central role in the early development of functional analysis: the viewpoint of bounded matrices.

\subsubsection{Bounded matrices}

As mentioned in Subsec. \ref{lb141}, early developments in functional analysis focused primarily on bounded sesquilinear forms rather than bounded linear operators. Closely tied to this approach was the study of infinite matrices, which provided a concrete representation of these abstract objects.


The notion of boundedness was first defined in this matrix context. Hilbert introduced this concept in \cite{Hil06}, where he also introduced the space $l^2(\Zbb)$. As established in Prop. \ref{lb35}, boundedness in the context of linear maps or sesquilinear forms is equivalent to (Lipschitz) continuity. However, as we will see below, in the setting of infinite matrices, boundedness takes on a stronger meaning---it implies equicontinuity. More precisely, it ensures that a family of linear maps or sesquilinear forms shares a uniform Lipschitz constant.

This distinction highlights a deeper philosophical insight under the perspective of infinite matrices: \uwave{a bounded linear operator or sesquilinear form is regarded as the limit of a sequence (or net) of finite-rank operators or forms}. This philosophy is central to our treatment of spectral theory in Ch. \ref{lb114}, and it resonates not only with the historical approaches of Hilbert and F. Riesz, but also with the viewpoint that \uwave{the Stieltjes integral arises as the weak-* completion of finite sums} (see Table \ref{tb3}). For this reason, it is worthwhile to study bounded matrices and their relationship to bounded linear operators and sesquilinear forms.



















\hypertarget{current}{}


\newpage



\section{Spectral theorem for bounded self-adjoint operators}\label{lb114}


\subsection{Prehistory of spectral theory: continued fractions}






\subsection{Prehistory of spectral theory: the polynomial moment problem}































\printindex	






	\begin{thebibliography}{999999}
		\footnotesize	

\bibitem[Fol-R]{Fol-R}
Folland, G. B. (1999). Real analysis: modern techniques and their applications. 2nd ed.

\bibitem[Gray84]{Gray84}
Gray, J. D. (1984). The shaping of the Riesz representation theorem: A chapter in the history of analysis. Archive for History of Exact Sciences, 31, 127-187.

\bibitem[Gud74]{Gud74}
Gudder, S. (1974). Inner product spaces. The American Mathematical Monthly, 81(1), 29-36.

\bibitem[Gui-A]{Gui-A}
Bin Gui, Qiuzhen Lectures on Analysis. See \url{https://binguimath.github.io/Pages/2023_Analysis.html}
%See the ``Notes" section of \url{https://binguimath.github.io}

\bibitem[Haw-L]{Haw-L}
Hawkins, T. (1979) Lebesgue's theory of integration: Its origins and development. Corrected reprint of the 2nd edition. 

\bibitem[Hil06]{Hil06}
Hilbert, D. (1906) Grundz\"uge einer allgemeinen Theorie der linearen Integralgleichungen. The fourth part (Vierter Abschnitt, Theorie der quadratischen Formen mit unendlich vielen Variablen).

\bibitem[Jah]{Jah}
Jahnke, H. N. (2003). A history of analysis (No. 24). American Mathematical Soc..

\bibitem[Rie09]{Rie09}
Riesz, F. (1909). Sur les op\'erations functionnelles lin\'eaires. Gauthier-Vllars.

\bibitem[Rie10]{Rie10}
Riesz, F. (1910). Untersuchungen \"uber systeme integrierbarer funktionen. Mathematische Annalen, 69(4), 449-497.


\bibitem[Rie11]{Rie11}
Riesz, F. (1911). Sur certains syst\'emes singuliers d'\'equations int\'egrales. In Annales scientifiques de l'\'Ecole Normale Sup\'erieure (Vol. 28, pp. 33-62).

\bibitem[Rie13]{Rie13}
Riesz, F. (1913). Les syst\`emes d'\'equations lin\'eaires \`a une infinite d'inconnues.


\bibitem[Rie14]{Rie14}
Riesz, F. (1914). D{\'e}monstration nouvelle d'un th{\'e}or{\`e}me concernant les op{\'e}rations fonctionelles lin{\'e}aires. Ann. Sci. {\'E}c. Norm. Sup{\'e}r. (3).

\bibitem[Rie18]{Rie18}
Riesz, F. (1918). \"Uber lineare funktionalgleichungen. Acta math, 41(1), 71-98.

\bibitem[Rud-R]{Rud-R}
Rudin, W. (1987). Real and complex analysis. 3rd ed.


		
\end{thebibliography}

%\noindent {\small \sc Yau Mathematical Sciences Center, Tsinghua University, Beijing, China.}

%\noindent {\textit{E-mail}}: binguimath@gmail.com\qquad bingui@tsinghua.edu.cn
\end{document}