% !TeX spellcheck = en_US
% !TEX program = pdflatex
\documentclass[12pt,b5paper,notitlepage]{article}
\usepackage[b5paper, margin={0.5in,0.65in}]{geometry}
%\usepackage{fullpage}
\usepackage{amsmath,amscd,amssymb,amsthm,mathrsfs,amsfonts,layout,indentfirst,graphicx,caption,mathabx, stmaryrd,appendix,calc,imakeidx,upgreek} % mathabx for \wtidecheck
%\usepackage{ulem} %wave underline
\usepackage[dvipsnames,table]{xcolor}
\usepackage{palatino}  %template

\usepackage{slashed} % Dirac operator
\usepackage{mathrsfs} % Enable using \mathscr
%\usepackage{eufrak}  another template/font
\usepackage{extarrows} % long equal sign, \xlongequal{blablabla}
\usepackage{enumitem} % enumerate label change e.g. [label=(\alph*)]  shows (a) (b) 

 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage{fontspec}
%\setmainfont{Palatino Linotype}
%\usepackage{emoji}


% emoji, use lualatex  remove \usepackage{palatino}

%%%%%%%%%%%%%


\usepackage{CJK}   % Chinese package





\usepackage{csquotes} % \begin{displayquote}   \begin{displaycquote}  for quotation
\usepackage{epigraph}   %\epigraph{}{}  for quotation
%\pmb  mandatory math bold 

\usepackage{fancyhdr} % date in footer

%\usepackage{soul}  %\ul underline break line automatically

\usepackage{ulem}  % \uline  underline break line   also    \uwave

\usepackage{relsize} % use \mathlarger \larger \text{\larger[2]$...$} to enlarge the size of math symbols

\usepackage{verbatim}  % comment environment


\usepackage{halloweenmath} % Interesting halloween math symbols

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tcolorbox}
\tcbuselibrary{theorems}
% box around equations   \tcboxmath
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\usepackage{float}

%%%%%%%%%%%%

% Force images and tables to be placed in a specified location.

%\begin{table}[H]

%\begin{figure}[H]

%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% circled colon and thick colon \hcolondel and \colondel

\usepackage{pdfrender}

\newcommand*{\hollowcolon}{%
	\textpdfrender{
		TextRenderingMode=Stroke,
		LineWidth=.1bp,
	}{:}%
}

\newcommand{\hcolondel}[1]{%
	\mathopen{\hollowcolon}#1\mathclose{\hollowcolon}%
}
\newcommand{\colondel}[1]{%
	\mathopen{:}#1\mathclose{:}%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\usepackage{tikz}
\usetikzlibrary{fadings}
\usetikzlibrary{patterns}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes}

\usepackage{tikz-cd}
\usepackage[nottoc]{tocbibind}   % Add  reference to ToC


\makeindex


% The following set up the line spaces between items in \thebibliography
\usepackage{lipsum}  
\let\OLDthebibliography\thebibliography
\renewcommand\thebibliography[1]{
	\OLDthebibliography{#1}
	\setlength{\parskip}{0pt}
	\setlength{\itemsep}{2pt} 
}


%\hyperref{page.10}{...}

\allowdisplaybreaks  %allow aligns to break between pages
\usepackage{latexsym}
\usepackage{chngcntr}
\usepackage[colorlinks,linkcolor=blue,anchorcolor=blue, linktocpage,
%pagebackref
]{hyperref}
\hypersetup{ urlcolor=cyan,
	citecolor=[rgb]{0,0.5,0}}


\setcounter{tocdepth}{2}	 %hide subsections in the content


\counterwithin{figure}{section}
\counterwithin{table}{section}

\counterwithin*{footnote}{section}   % Footnote numbering is recounted from the beginning of each subsection



\pagestyle{plain}

\captionsetup[figure]
{
	labelsep=none	
}













\theoremstyle{definition}
\newtheorem{df}{Definition}[subsection]
\newtheorem{eg}[df]{Example}
\newtheorem{exe}[df]{Exercise}
\newtheorem{rem}[df]{Remark}
\newtheorem{obs}[df]{Observation}
\newtheorem{ass}[df]{Assumption}
\newtheorem{cv}[df]{Convention}
\newtheorem{prin}[df]{Principle}
\newtheorem{nota}[df]{Notation}
\newtheorem{problem}[df]{Problem}
\newtheorem{question}[df]{Question}
\newtheorem{principle}[df]{Principle}
\newtheorem{coa}[df]{Theorem}
\newtheorem{srem}[df]{$\star$ Remark}
\newtheorem{seg}[df]{$\star$ Example}
\newtheorem{sexe}[df]{$\star$ Exercise}
\newtheorem{sdf}[df]{$\star$ Definition}




\newtheorem{prob}{\color{red}Problem}[section]
%\renewcommand*{\theprob}{{\color{red}\arabic{section}.\arabic{prob}}}
\newtheorem{sprob}[prob]{\color{red}$\star$ Problem}
%\renewcommand*{\thesprob}{{\color{red}\arabic{section}.\arabic{sprob}}}
% \newtheorem{ssprob}[prob]{$\star\star$ Problem}
\newtheorem{dprob}[prob]{\color{red}$\dagger$ Problem}


\theoremstyle{plain}
\newtheorem{thm}[df]{Theorem}
\newtheorem{ccl}[df]{Conclusion}
\newtheorem{thd}[df]{Theorem-Definition}
\newtheorem{pp}[df]{Proposition}
\newtheorem{co}[df]{Corollary}
\newtheorem{lm}[df]{Lemma}
\newtheorem{sthm}[df]{$\star$ Theorem}
\newtheorem{slm}[df]{$\star$ Lemma}
\newtheorem{claim}[df]{Claim}
\newtheorem{spp}[df]{$\star$ Proposition}
\newtheorem{scorollary}[df]{$\star$ Corollary}
\newtheorem{cond}[df]{Condition}


\newtheorem{Mthm}{Main Theorem}
\renewcommand{\thecond}{\Alph{cond}} % ``letter-numbered'' theorems



%\substack   multiple lines under sum
%\underset{b}{a}   b is under a


% Remind: \overline{L_0}



\usepackage{calligra}
\DeclareMathOperator{\shom}{\mathscr{H}\text{\kern -3pt {\calligra\large om}}\,}
\DeclareMathOperator{\sext}{\mathscr{E}\text{\kern -3pt {\calligra\large xt}}\,}
\DeclareMathOperator{\Rel}{\mathscr{R}\text{\kern -3pt {\calligra\large el}~}\,}
\DeclareMathOperator{\sann}{\mathscr{A}\text{\kern -3pt {\calligra\large nn}}\,}
\DeclareMathOperator{\send}{\mathscr{E}\text{\kern -3pt {\calligra\large nd}}\,}
\DeclareMathOperator{\stor}{\mathscr{T}\text{\kern -3pt {\calligra\large or}}\,}
\DeclareMathOperator{\Bor}{\mathscr{B}\text{\kern -2pt {\calligra\large or}}\,}
\DeclareMathOperator{\Borb}{{\mathscr{B}\text{\kern -2pt {\calligra\large or}}\,}_{\mathrm b}}
\DeclareMathOperator{\Cay}{\mathscr{C}\text{\kern -3pt {\calligra\large ay}}\,}




\usepackage{aurical}
\DeclareMathOperator{\VVir}{\text{\Fontlukas V}\text{\kern -0pt {\Fontlukas\large ir}}\,}
\DeclareMathOperator{\Ses}{\text{\Fontlukas S}\text{\kern -0pt {\Fontlukas\large es}}\,}
\DeclareMathOperator{\Rr}{\text{\Fontlukas R}\text{\kern -0pt {\Fontlukas\large r}}\,}


\newcommand{\vol}{\text{\Fontlukas V}}
\newcommand{\dvol}{d~\text{\Fontlukas V}}



\usepackage{aurical}
\usepackage[T1]{fontenc}








\newcommand{\fk}{\mathfrak}
\newcommand{\mc}{\mathcal}
\newcommand{\wtd}{\widetilde}
\newcommand{\wht}{\widehat}
\newcommand{\wch}{\widecheck}
\newcommand{\ovl}{\overline}
\newcommand{\udl}{\underline}
\newcommand{\tr}{\mathrm{t}} %transpose
\newcommand{\Tr}{\mathrm{Tr}}
\newcommand{\End}{\mathrm{End}} %endomorphism
\newcommand{\idt}{\mathbf{1}}
\newcommand{\id}{\mathrm{id}}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\Conf}{\mathrm{Conf}}
\newcommand{\Res}{\mathrm{Res}}
\newcommand{\res}{\mathrm{res}}
\newcommand{\KZ}{\mathrm{KZ}}
\newcommand{\ev}{\mathrm{ev}}
\newcommand{\coev}{\mathrm{coev}}
\newcommand{\opp}{\mathrm{opp}}
\newcommand{\Rep}{\mathrm{Rep}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\Dom}{\mathscr{D}}
\newcommand{\Domain}{\mathrm{Dom}}
\newcommand{\loc}{\mathrm{loc}}
\newcommand{\con}{\mathrm{c}}
\newcommand{\uni}{\mathrm{u}}
\newcommand{\ssp}{\mathrm{ss}}
\newcommand{\di}{\slashed d}
\newcommand{\Diffp}{\mathrm{Diff}^+}
\newcommand{\Diff}{\mathrm{Diff}}
\newcommand{\PSU}{\mathrm{PSU}(1,1)}
\newcommand{\Vir}{\mathrm{Vir}}
\newcommand{\Witt}{\mathscr W}
\newcommand{\Span}{\mathrm{Span}}
\newcommand{\pri}{\mathrm{p}}
\newcommand{\ER}{E^1(V)_{\mathbb R}}
\newcommand{\prth}[1]{( {#1})}
\newcommand{\bk}[1]{\langle {#1}\rangle}
\newcommand{\bigbk}[1]{\big\langle {#1}\big\rangle}
\newcommand{\Bigbk}[1]{\Big\langle {#1}\Big\rangle}
\newcommand{\biggbk}[1]{\bigg\langle {#1}\bigg\rangle}
\newcommand{\Biggbk}[1]{\Bigg\langle {#1}\Bigg\rangle}
\newcommand{\GA}{\mathscr G_{\mathcal A}}
\newcommand{\vs}{\varsigma}
\newcommand{\Vect}{\mathrm{Vec}}
\newcommand{\Vectc}{\mathrm{Vec}^{\mathbb C}}
\newcommand{\scr}{\mathscr}
\newcommand{\sjs}{\subset\joinrel\subset}
\newcommand{\Jtd}{\widetilde{\mathcal J}}
\newcommand{\gk}{\mathfrak g}
\newcommand{\hk}{\mathfrak h}
\newcommand{\xk}{\mathfrak x}
\newcommand{\yk}{\mathfrak y}
\newcommand{\zk}{\mathfrak z}
\newcommand{\pk}{\mathfrak p}
\newcommand{\hr}{\mathfrak h_{\mathbb R}}
\newcommand{\Ad}{\mathrm{Ad}}
\newcommand{\DHR}{\mathrm{DHR}_{I_0}}
\newcommand{\Repi}{\mathrm{Rep}_{\wtd I_0}}
\newcommand{\im}{\mathbf{i}}
\newcommand{\Co}{\complement}
%\newcommand{\Cu}{\mathcal C^{\mathrm u}}
\newcommand{\RepV}{\mathrm{Rep}^\uni(V)}
\newcommand{\RepA}{\mathrm{Rep}(\mathcal A)}
\newcommand{\RepN}{\mathrm{Rep}(\mathcal N)}
\newcommand{\RepfA}{\mathrm{Rep}^{\mathrm f}(\mathcal A)}
\newcommand{\RepAU}{\mathrm{Rep}^\uni(A_U)}
\newcommand{\RepU}{\mathrm{Rep}^\uni(U)}
\newcommand{\RepL}{\mathrm{Rep}^{\mathrm{L}}}
\newcommand{\HomL}{\mathrm{Hom}^{\mathrm{L}}}
\newcommand{\EndL}{\mathrm{End}^{\mathrm{L}}}
\newcommand{\Bim}{\mathrm{Bim}}
\newcommand{\BimA}{\mathrm{Bim}^\uni(A)}
%\newcommand{\shom}{\scr Hom}
\newcommand{\divi}{\mathrm{div}}
\newcommand{\sgm}{\varsigma}
\newcommand{\SX}{{S_{\fk X}}}
\newcommand{\DX}{D_{\fk X}}
\newcommand{\mbb}{\mathbb}
\newcommand{\mbf}{\mathbf}
\newcommand{\bsb}{\boldsymbol}
\newcommand{\blt}{\bullet}
\newcommand{\Vbb}{\mathbb V}
\newcommand{\Ubb}{\mathbb U}
\newcommand{\Xbb}{\mathbb X}
\newcommand{\Kbb}{\mathbb K}
\newcommand{\Abb}{\mathbb A}
\newcommand{\Wbb}{\mathbb W}
\newcommand{\Mbb}{\mathbb M}
\newcommand{\Gbb}{\mathbb G}
\newcommand{\Cbb}{\mathbb C}
\newcommand{\Nbb}{\mathbb N}
\newcommand{\Zbb}{\mathbb Z}
\newcommand{\Qbb}{\mathbb Q}
\newcommand{\Pbb}{\mathbb P}
\newcommand{\Rbb}{\mathbb R}
\newcommand{\Ebb}{\mathbb E}
\newcommand{\Dbb}{\mathbb D}
\newcommand{\Hbb}{\mathbb H}
\newcommand{\Tbb}{\mathbb T}
\newcommand{\Jbb}{\mathbb J}
\newcommand{\Ibb}{\mathbb I}
\newcommand{\cbf}{\mathbf c}
\newcommand{\Rbf}{\mathbf R}
\newcommand{\wt}{\mathrm{wt}}
\newcommand{\Lie}{\mathrm{Lie}}
\newcommand{\btl}{\blacktriangleleft}
\newcommand{\btr}{\blacktriangleright}
\newcommand{\svir}{\mathcal V\!\mathit{ir}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cok}{\mathrm{Coker}}
\newcommand{\Sbf}{\mathbf{S}}
\newcommand{\low}{\mathrm{low}}
\newcommand{\Sp}{\mathrm{Sp}}
\newcommand{\Rng}{\mathrm{Rng}}
\newcommand{\vN}{\mathrm{vN}}
\newcommand{\Ebf}{\mathbf E}
\newcommand{\Nbf}{\mathbf N}
\newcommand{\Stb}{\mathrm {Stb}}
\newcommand{\SXb}{{S_{\fk X_b}}}
\newcommand{\pr}{\mathrm {pr}}
\newcommand{\SXtd}{S_{\wtd{\fk X}}}
\newcommand{\univ}{\mathrm {univ}}
\newcommand{\vbf}{\mathbf v}
\newcommand{\ubf}{\mathbf u}
\newcommand{\wbf}{\mathbf w}
\newcommand{\CB}{\mathrm{CB}}
\newcommand{\Perm}{\mathrm{Perm}}
\newcommand{\Orb}{\mathrm{Orb}}
\newcommand{\Lss}{{L_{0,\mathrm{s}}}}
\newcommand{\Lni}{{L_{0,\mathrm{n}}}}
\newcommand{\UPSU}{\widetilde{\mathrm{PSU}}(1,1)}
\newcommand{\Sbb}{{\mathbb S}}
\newcommand{\Gc}{\mathscr G_c}
\newcommand{\Obj}{\mathrm{Obj}}
\newcommand{\bpr}{{}^\backprime}
\newcommand{\fin}{\mathrm{fin}}
\newcommand{\Ann}{\mathrm{Ann}}
\newcommand{\Real}{\mathrm{Re}}
\newcommand{\Imag}{\mathrm{Im}}
%\newcommand{\cl}{\mathrm{cl}}
\newcommand{\Ind}{\mathrm{Ind}}
\newcommand{\Supp}{\mathrm{Supp}}
\newcommand{\Specan}{\mathrm{Specan}}
\newcommand{\red}{\mathrm{red}}
\newcommand{\uph}{\upharpoonright}
\newcommand{\Mor}{\mathrm{Mor}}
\newcommand{\pre}{\mathrm{pre}}
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\Jac}{\mathrm{Jac}}
\newcommand{\emb}{\mathrm{emb}}
\newcommand{\Sg}{\mathrm{Sg}}
\newcommand{\Nzd}{\mathrm{Nzd}}
\newcommand{\Owht}{\widehat{\scr O}}
\newcommand{\Ext}{\mathrm{Ext}}
\newcommand{\Tor}{\mathrm{Tor}}
\newcommand{\Com}{\mathrm{Com}}
\newcommand{\Mod}{\mathrm{Mod}}
\newcommand{\nk}{\mathfrak n}
\newcommand{\mk}{\mathfrak m}
\newcommand{\Ass}{\mathrm{Ass}}
\newcommand{\depth}{\mathrm{depth}}
\newcommand{\Coh}{\mathrm{Coh}}
\newcommand{\Gode}{\mathrm{Gode}}
\newcommand{\Fbb}{\mathbb F}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\Modf}{\mathrm{Mod}^{\mathrm f}}
\newcommand{\codim}{\mathrm{codim}}
\newcommand{\card}{\mathrm{card}}
\newcommand{\dps}{\displaystyle}
\newcommand{\Int}{\mathrm{Int}}
\newcommand{\Nbh}{\mathrm{Nbh}}
\newcommand{\Pnbh}{\mathrm{PNbh}}
\newcommand{\Cl}{\mathrm{Cl}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\eps}{\varepsilon}
\newcommand{\Vol}{\mathrm{Vol}}
\newcommand{\LSC}{\mathrm{LSC}}
\newcommand{\LSCb}{\mathrm{LSC}_{\mathrm b}}
\newcommand{\USC}{\mathrm{USC}}
\newcommand{\Ess}{\mathrm{Rng}^{\mathrm{ess}}}
\newcommand{\Jbf}{\mathbf{J}}
\newcommand{\SL}{\mathrm{SL}}
\newcommand{\GL}{\mathrm{GL}}
\newcommand{\Lin}{\mathrm{Lin}}
\newcommand{\ALin}{\mathrm{ALin}}
\newcommand{\bwn}{\bigwedge\nolimits}
\newcommand{\nbf}{\mathbf n}
\newcommand{\dive}{\mathrm{div}}
\newcommand{\vkp}{\varkappa}
\newcommand{\MU}{\mathcal U}
\newcommand{\MV}{\mathcal V}
\newcommand{\MW}{\mathcal W}
\newcommand{\MB}{\mathcal B}
\newcommand{\MG}{\mathcal G}
\newcommand{\MD}{\mathcal D}
\newcommand{\MF}{\mathcal F}
\newcommand{\MH}{\mathcal H}
\newcommand{\MK}{\mathcal K}
\newcommand{\ML}{\mathcal L}
\newcommand{\MM}{\mathcal M}
\newcommand{\MT}{\mathcal T}
\newcommand{\RM}{\mathcal {RM}}
\newcommand{\Rp}{\mathbb R_{\geq0}}
%\newcommand{\Ses}{\mathrm{Sesq}_{\mathrm b}}
\newcommand{\SI}{\mathscr I}
\newcommand{\SJ}{\mathscr J}
\newcommand{\SA}{\mathscr A}
\newcommand{\SF}{\mathscr F}
\newcommand{\SG}{\mathscr G}
\newcommand{\Mbf}{\mathbf M}
\newcommand{\pbf}{\mathbf p}








\newcommand{\hqed}{\hfill\qedsymbol}




\usepackage{tipa} % wierd symboles e.g. \textturnh
\newcommand{\tipar}{\text{\textrtailr}}
\newcommand{\tipaz}{\text{\textctyogh}}
\newcommand{\tipaomega}{\text{\textcloseomega}}
\newcommand{\tipae}{\text{\textrhookschwa}}
\newcommand{\tipaee}{\text{\textreve}}
\newcommand{\tipak}{\text{\texthtk}}
\newcommand{\mol}{\upmu}
\newcommand{\dmol}{d\upmu}




\usepackage{tipx}
\newcommand{\tipxgamma}{\text{\textfrtailgamma}}
\newcommand{\tipxcc}{\text{\textctstretchc}}
\newcommand{\tipxphi}{\text{\textqplig}}















\numberwithin{equation}{section}




\title{Qiuzhen Lectures on Functional Analysis}
\author{{\sc Bin Gui}
	\\
	{\small \sc Yau Mathematical Sciences Center, Tsinghua University.}\\
	{\small binguimath@gmail.com\qquad bingui@tsinghua.edu.cn}
}
%\date{}

%\definecolor{mycolor}{RGB}{227,237,205} \pagecolor{mycolor}

\begin{document}\sloppy % avoid stretch into margins
	\pagenumbering{arabic}
	%\pagenumbering{gobble}
	\setcounter{page}{1}
	%\setcounter{section}{-1}
	%\setcounter{equation}{6}



	






	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



	
	\maketitle
\small   
\qquad 

\hyperlink{current}{Current writing}\qquad \hyperlink{page.3}{Last page of TOC}\qquad
\hyperlink{proofread}{Current proofread}

%\hyperlink{beforeindex}{Last page before index}~~~~~~  
%\hypertarget{beforeindex}{}



%\noindent Sections on history include but are not limited to: 
%\ref{lb55} (point-set topology),  \ref{lb550} (integral theory, Fourier series), \ref{lb543} (Banach-Alaoglu, Hahn-Banach),  \ref{lb548} (quotient Banach spaces, Hahn-Banach), \ref{lb671} and most part of Ch. \ref{lb672} (Hilbert spaces, integral equations), \ref{lb733} (measurable sets), \ref{mc89} (Riesz-Fischer theorem, $L^p$-$L^q$ duality), \ref{lb896} (functional calculus, spectral theory)
%\normalsize
%\thispagestyle{empty}	 %remove page number of this page


%Contents hyperlinks: \hyperlink{page.2}{Page 2}, \hyperlink{page.3}{Page 3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-0.5cm}

%\makeatletter
%\newcommand*{\toccontents}{\@starttoc{toc}}
%\makeatother
%\toccontents



	
% title and table of contents same page, no content title

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\normalsize
\tableofcontents






\newpage



\section{Preliminaries}

\subsection{Notation}\label{lb251}

In this monograph, unless otherwise stated, we understand the field $\Fbb$ as either $\Rbb$ or $\Cbb$.

We use frequently the abbreviations:
\begin{gather*}
\text{iff=if and only if}\\
\text{LHS=left hand side}\qquad
\text{RHS=right hand side}\\
\text{$\exists$=there exists}\qquad \text{$\forall$=for all}\\
\text{i.e.=id est=that is=namely}\qquad\text{e.g.=for example}\\
\text{cf.=compare/check/see/you are referred to}\\
\text{resp.=respectively}\qquad 
\text{WLOG=without loss of generality}\\
\text{LCH=locally compact Hausdorff\index{00@LCH=locally compact Hausdorff}}\\
\text{MCT=monotone convergence theorem}\index{00@MCT=monotone convergence theorem}\\
\text{DCT=dominated convergence theorem}\index{00@DCT=dominated convergence theorem}
\end{gather*}

%If $P,Q$ are properties, then
%\begin{align*}
%P\land Q=P\text{ and }Q\qquad P\lor Q=P\text{ or }Q\qquad \neg P=\text{ Not }P
%\end{align*}
When we write $A:=B$ or $A\xlongequal{\mathrm{def}}B$, we mean that $A$ is defined by the expression $B$. When we write $A\equiv B$, we mean that $A$ are $B$ are different symbols of the same object.





Unless otherwise stated, an inner product space $V$ denotes a complex inner product space, and its sesquilinear form $\bk{\cdot|\cdot}$ is \uwave{linear on the right argument $|\cdot\rangle$ and antilinear on the left argument $\langle\cdot|$}. Note that this convention is different from that of \cite{Gui-A}, where the right variable is antilinear.


If $V$ is an $\Fbb$-vector space, then for each $v\in V$ and each linear map $\varphi:V\rightarrow\Fbb$, we write
\begin{align*}
\bk{v,\varphi}=\bk{\varphi,v}:=\varphi(v)
\end{align*}

We assume $a\cdot(+\infty)=(+\infty)\cdot a=+\infty$ if $a\in(0,+\infty]$, and $0\cdot(+\infty)=(+\infty)\cdot 0=0$.

An increasing function/sequence/net means a non-decreasing one, that is, $x\leq y\Rightarrow f(x)\leq f(y)$.


Unless otherwise stated, when mentioning a function space, i.e., a linear subspace of $\Fbb^X$ where $X$ is a set, we assume that $X$ is non-empty.




\begin{itemize}
\item Unless otherwise specified, completeness of a metric space or normed vector space refers to Cauchy completeness.
\item $\Nbb=\{0,1,2,\dots\}$, $\Zbb_+=\{1,2,\dots\}$.
\item $\Rbb_{\geq0}=[0,+\infty)$, $\ovl\Rbb_{\geq0}=[0,+\infty]$, $\ovl\Rbb=[-\infty,+\infty]$. We equip $\ovl\Rbb$ with the topology generated by all $(a,b),(a,+\infty],[-\infty,b)$ where $a,b\in\Rbb$. The space $\ovl\Rbb$ is a compact and Hausdorff.
\item An \textbf{interval} \index{00@Interval} denotes a connected subset of $\ovl\Rbb$. A \textbf{proper interval} \index{00@Proper interval} denotes an interval with non-zero Lebesgue measure.
\item $Y^X$ is the set of functions with domain $X$ and codomain $Y$.
\item $2^X$ is the set of subsets of $X$.
\item $\fin(2^X)$ is the set of finite subsets of $X$.
\item For each vector space $V$, we let $V[x_1,\dots,x_k]$ be the space of polynomials of the (mutually commuting) abstract variables $x_1,\dots,x_k$ with coefficients in $V$. Therefore, its elements are of the form
\begin{align*}
\sum_{n_1,\dots,n_k\in E}v_{n_1,\dots,n_k}x_1^{n_1}\cdots x_k^{n_k}\qquad\text{ where $E\in\fin(2^\Nbb)$ and $v_{n_1,\dots,n_k}\in V$}
\end{align*}
\item If $f:X\rightarrow Y$ is a map, then \index{Rng@$\Rng(f)$, the range of $f$}
\begin{align*}
\Rng(f)=f(X)
\end{align*}
If $X,Y$ are vector spaces and $f$ is linear, then
\begin{align*}
\Ker(f)=f^{-1}(0)
\end{align*}
\item If $V$ is a vector space and $X$ is a set, then $V^X$ is viewed as a vector space whose linear structure is defined by
\begin{gather*}
(af+bg)(x)=af(x)+bg(x)\qquad\text{for all }f,g\in V^X\text{ and }a,b\in\Fbb
\end{gather*}
\item If $X$ is a set and $A\subset X$, the \textbf{characteristic function} \index{zz@$\chi_A$} is
\begin{align*}
\chi_A:X\rightarrow\{0,1\}\qquad x\mapsto\left\{
\begin{array}{ll}
1&\text{ if }x\in A\\[0.5ex]
0&\text{ if }x\in X\setminus A
\end{array}
\right.
\end{align*} 
\item If $X$ is a metric space and $p\in X,r\in[0,+\infty]$, we let \index{B@$B_X(p,r),\ovl B_X(p,r)$}
\begin{gather*}
B_X(p,r)=\{x\in X:d(x,p)<r\}\qquad \ovl B_X(p,r)=\{x\in X:d(x,p)\leq r\}
\end{gather*}
For each $E\subset X$, we define the \textbf{diameter} \index{diam@$\diam(E)$} \index{00@Diameter $\diam(E)$}
\begin{align*}
\diam(E)=\sup\{d(x,y):x,y\in E\}
\end{align*}
\item If $X$ is a topological space, then $\mc T_X$ \index{TX@$\mc T_X$, the topology of $X$} denotes the topology of $X$, i.e.,
\begin{align*}
\mc T_X=\{\text{open subsets of }X\}
\end{align*}
If $x\in X$, a \textbf{neighborhood} \index{00@Neighborhood} of $x$ denotes an \textit{open} subset of $X$ containing $x$. We let \index{Nbh@$\Nbh_X(x)=\Nbh(x)$}
\begin{align*}
\Nbh_X(x)\equiv \Nbh(x):=\{\text{neighborhoods of $x$ in $X$}\}
\end{align*}
\item $\Cl_X(A)$, \index{Cl@$\Cl_X(A)=\ovl A$, the closure of $A$ in the ambient space $X$.} also denoted by $\Cl(A)$ or $\ovl A$, is the closure of $A\subset X$ with respect to the topological space $X$.
\item $\Int_X(A)$, \index{Int@$\Int_X(A)=\Int(A)$} also denoted by $\Int(A)$, is the interior of $A\subset X$ with respect to the topological space $X$. In other words, $\Int_X(A)$ consists of all $x\in A$ such that $A$ contains $U$ for some $U\in\Nbh_X(x)$. 
\item If $X,Y$ are topological spaces, then \index{Bor@$\Bor(X,Y)$, the Borel maps $X\rightarrow Y$}
\begin{gather*}
C(X,Y)=\{f\in Y^X:f\text{ is continuous}\}\\
\fk B_X=\text{the Borel $\sigma$-algebra of }X\\
\Bor(X,Y)=\{f\in Y^X:f\text{ is Borel}\}
\end{gather*}
\item $m^n$, as a measure, denotes the Lebesgue measure on $\Rbb^n$, and is abbreviated to $m$ when no confusion arises.
\item $\pmb{\Tbb}=\Sbb^1=\{z\in\Cbb:|z|=1\}\simeq\Rbb/2\pi\Zbb$. \index{T@$\Tbb$} \index{S1@$\Sbb^1$} If $f$ is a function on $\Sbb^1$, equivalently, a $2\pi$-periodic function on $\Rbb$, then
\begin{align*}
\wht f(n)=\frac 1{2\pi}\int_{-\pi}^\pi f(x)e^{-\im nx}dm(x)
\end{align*}
is its $n$-th Fourier coefficient (whenever the integral can be defined).
\item $(X,\fk M,\mu)$, often abbreviated to $(X,\mu)$, denotes a measure space where $\fk M$ is the $\sigma$-algebra and $\mu:\fk M\rightarrow\ovl\Rbb_{\geq0}$ is the measure.
\item Let $V$ be a normed vector space. Let $X$ be either a set or a topological space, depending on the context. Let $1\leq p<+\infty$. For each $f\in V^X$, 
\begin{gather*}
\Supp_X(f)\equiv\Supp(f)=\Cl_X(\{x\in X:f(x)\neq0\})\\
\Vert f\Vert_{l^\infty(X,V)}=\Vert f\Vert_{l^\infty}=\sup_{x\in X}\Vert f(x)\Vert\\
\Vert f\Vert_{l^p(X,V)}=\Vert f\Vert_{l^p}=\Big(\sum_{x\in X}\Vert f(x)\Vert^p\Big)^{\frac 1p}\\
|f|\text{ is the function }X\rightarrow \Rbb_{\geq0}\text{ such that }|f|(x)=\Vert f(x)\Vert
\end{gather*}
We call $|f|$ the \textbf{absolute value function} of $f$. For each $E\subset V$, we let\index{Borb@$\Borb(X,V)$} \index{Cc@$C_c(X,E)$}
\begin{gather*}
C_c(X,E)=\{f\in C(X,E):\Supp(f)\text{ is compact in $X$}\}\\
l^\infty(X,V)=\{f\in V^X:\Vert f\Vert_\infty<+\infty\}\\
l^p(X,V)=\{f\in V^X:\Vert f\Vert_p<+\infty\}\\
\Borb(X,V)=\Bor(X,V)\cap l^\infty(X,V)=\{f\in V^X:f\text{ is Borel and bounded}\}
\end{gather*}
We are particularly interested in the case that $E=V$, $E=[0,1]$, and $E=\Rbb_{\geq0}$.
\item Let $k\in\Nbb\cup\{\infty\}$. Suppose that $X$ is a subset of $\Rbb^m$ (or more generally, a subset of a $C^k$-manifold $M$ with or without boundary). Let $Y\subset\Rbb^n$. We let \index{Ck@$C^k(X,Y),C_c^k(X,Y)$}
\begin{gather*}
C^k(X,\Rbb^n)=\{C^k\text{-functions }X\rightarrow \Rbb^n\}\\
C^k(X,Y)=\{f\in C^k(X,\Rbb^n):f(X)\subset Y\}\\
C_c^k(X,Y)=\{f\in C^k(X,Y):\Supp_X(f)\text{ is compact}\}
\end{gather*}
Here, a function $f:X\rightarrow\Rbb^m$ is called a \textbf{\pmb{$C^k$}-function} if for each $x\in X$ there exists $U\in\Nbh_M(x)$ such that $f|_{U\cap X}$ can be extended to a $C^k$-function $U\rightarrow\Rbb^n$. A $C^\infty$-function is called a \textbf{smooth function}. \index{00@Smooth functions}
\item Unless otherwise stated, if $f:X\rightarrow\Cbb$ where $X$ is a set, we let
\begin{align*}
f^*:X\rightarrow\Cbb\qquad f^*(x)=\ovl{f(x)}
\end{align*} 
Thus $f=f^*$ iff $f$ is real-valued.
\item Let $V$ be a normed vector space. Let $X$ be a set. We say that a family $(f_\alpha)_{\alpha\in\scr A}$ in $V^X$ is \textbf{uniformly bounded} \index{00@Uniformly bounded families of functions} if $\sup_{\alpha\in\scr A}\Vert f_\alpha\Vert_{l^\infty(X,V)}<+\infty$.
\item If $X$ is LCH and $V$ is a normed $\Fbb$-vector space, we understand $C_c(X,V)$ as a normed $\Fbb$-vector space whose linear structure inherits from that of $V^X$, and \uwave{whose norm is chosen to be the $l^\infty$-norm}.
\item If $(X,\fk M)$ and $(Y,\fk N)$ are measurable spaces, then
\begin{gather*}
\mc L(X,Y)=\text{\{measurable functions $X\rightarrow Y$\}}
\end{gather*}
If $V$ is a normed vector space, for each $f\in\mc L(X,V)$ and $1\leq p<+\infty$, we let
\begin{gather*}
\Vert f\Vert_{L^p(X,\mu)}=\Vert f\Vert_{L^p}=\Big(\int_X|f|^pd\mu\Big)^{\frac 1p}\\
\Vert f\Vert_{L^\infty(X,\mu)}=\Vert f\Vert_{L^\infty}=\inf\{\lambda\in\ovl\Rbb_{\geq0}:\mu\{x\in X:\Vert f(x)\Vert>a\}=0\}
\end{gather*}
which are potentially infinite.
\item If $V,W$ are $\Fbb$-linear maps, we let
\begin{align*}
\Lin(V,W)=\{\text{$\Fbb$-linear maps }V\rightarrow W\}\qquad \Lin(V)=\Lin(V,V)
\end{align*}
If $A,B\in\Lin(V)$, we let
\begin{align*}
[A,B]=AB-BA
\end{align*}
\item If $(V_\alpha)_{\alpha\in\scr A}$ is a family of linear subspaces of a vector space $V$, we let
\begin{align*}
\sum_{\alpha\in\scr A}V_\alpha=\Span\{\xi\in V_\alpha\text{ where }\alpha\in\scr A\}
\end{align*}
\item In the notation of function spaces, the codomain is understood to be $\Cbb$ when it is suppressed. For example,
\begin{gather*}
C_c(X)=C_c(X,\Cbb)\qquad \Bor(X)=\Bor(X,\Cbb)\qquad L^p(X,\mu)=L^p(X,\mu,\Cbb)
\end{gather*}
However, this convention does not apply to $\fk L(V)$ and $\Lin(V)$: If $V$ is a normed vector space, then $\fk L(V)$ denotes $\fk L(V,V)$, the space of bounded linear operators on $V$. Likewise, if $V$ is a vector space, then $\Lin(V)$ denotes $\Lin(V,V)$.
\item Given an abstract set $X$ without prescribed topology, we understand $2^X$ as the topology of $X$. In this context, for instance, $C_c(X)$ is the set of functions $f:X\rightarrow\Cbb$ such that
\begin{align}\label{eq201}
\Supp_X(f)=\{x\in X:f(x)\neq0\}
\end{align}
is a finite set. 
\end{itemize}



\subsection{Nets}


In this section, we present results on nets that are essential for the topics covered in this course. For more details, see \cite{Gui-A}.

\subsubsection{Basic definitions}

\begin{df}\label{lb352}
A relation $\leq$ on a set $I$ is called a \textbf{preorder} \index{00@Preorder, and preordered set} if for all $\alpha,\beta,\gamma\in I$, the following are satisfied:
\begin{itemize}
\item (Reflexivity) $\alpha\leq \alpha$.
\item (Transitivity) If $\alpha\leq \beta$ and $\beta\leq \gamma$ then $a\leq \gamma$.
\end{itemize}
The pair $(I,\leq)$ (or simply $I$) is called a \textbf{preordered set}. For each $\beta\in I$, we write \index{I@$I_{\geq\beta}$}
\begin{gather}\label{eq183}
I_{\geq\beta}=\{\alpha\in I:\alpha\geq\beta\}
\end{gather}
\end{df}

\begin{df}
A preordered set $(I,\leq)$ is called a \textbf{directed set} \index{00@Direct set} if 
\begin{align}
\forall\alpha,\beta\in I~~~\exists\gamma\in I~~\text{ such that }\alpha\leq \gamma,\beta\leq\gamma  \label{eq123}
\end{align}
If $I$ is a directed set and $X$ is a set, then a function $x:I\rightarrow X$ is called a \textbf{net} \index{00@Net $(x_\alpha)_{\alpha\in I}$} with directed set/index set $I$. We often write $x(\alpha)$ as $x_\alpha$ if $\alpha\in I$, and write $x$ as $(x_\alpha)_{\alpha\in I}$.

Unless otherwise stated, for any net $(x_\alpha)_{\alpha\in I}$ we assume that $I\neq\emptyset$.  \hqed
\end{df}


\begin{eg}
$(\Zbb_+,\leq)$ is a directed set. A net with index set $\Zbb_+$ in a set $X$ is precisely a sequence in $X$.
\end{eg}


\begin{eg}
Let $X$ be a topological space and $x\in X$. Then $\Nbh_X(x)$, together with the preorder $\supset$ (that is, $U\leq V$ iff $U\supset V$), is a directed set. Unless otherwise stated, the preorder on $\Nbh_X(x)$ is always chosen to be $\supset$.
\end{eg}

\begin{df}\label{lb207}
Suppose that $(I,\leq_I )$ and $(J,\leq_J)$ are preordered sets (resp. directed sets), then the \textbf{product} \index{00@Product preordered/directed set} $(I\times J,\leq)$ is a preordered set (resp. directed set) if for every $\alpha,\alpha'\in I,\beta,\beta'\in J$ we define
\begin{align}\label{eq122}
(\alpha,\beta)\leq (\alpha',\beta')\qquad\Longleftrightarrow\qquad \alpha\leq_I \alpha'~~\text{and}~~\beta\leq_J\beta'
\end{align}
Unless otherwise stated, the preorder on $I\times J$ is assumed to be defined by \eqref{eq122}.
\end{df}


\begin{df}
If $X$ is a set, then $(2^X,\subset)$ and $(\fin(2^X),\subset)$ \index{fin@$\fin(2^X)$} are directed sets where
\begin{align}
\fin(2^X)=\{A\subset X:A\text{ is a finite set}\}
\end{align}
\end{df}


\begin{df}
Let $P$ be a property about elements of a set $X$, i.e., $P$ is a function $X\rightarrow\{\text{true, false}\}$. Let $(x_\alpha)_{\alpha\in I}$ be a net in $X$. 

We say that $x_\alpha$ \textbf{eventually} \index{00@Eventually} satisfies $P$ (equivalently, we say that $x_\alpha$ satisfies $P$ for \textbf{sufficiently large} \index{00@Sufficiently large} $\alpha$) if:
\begin{itemize}
\item There exists $\beta\in I$ such that for every $\alpha\in I_{\geq\beta}$, the element $x_\alpha$ satisfies $P$.
\end{itemize}
``Sufficiently large'' is also called ``\textbf{large enough}''. \index{00@Large enough=sufficiently large}

We say that $x_\alpha$ \textbf{frequently} \index{00@Frequently} satisfies $P$ if:
\begin{itemize}
\item For every $\beta\in I$ there exists $\alpha\in I_{\geq\beta}$ such that $x_\alpha$ satisfies $P$.
\end{itemize}
\hfill\qedsymbol
\end{df}


\begin{rem}\label{lb208}
Let $P$ and $Q$ be two properties about elements of $X$. Then
\begin{gather*}
\neg(\text{$x_\alpha$ eventually satisfies $P$})~~=~~(\text{$x_\alpha$ frequently satisfies $\neg P$})
\end{gather*}
By the crucial condition \eqref{eq123} for directed sets, we have
\begin{subequations}
\begin{gather}\label{eq124}
\begin{gathered}
(x_\alpha\text{ eventually satisfies }P)\land(x_\alpha\text{ eventually satisfies }Q)\\
\Downarrow \\
x_\alpha\text{ eventually satisfies }P\land Q
\end{gathered}
\end{gather}
We will use \eqref{eq124} very frequently without explicitly mentioning it. Clearly, we also have
\begin{gather}\label{eq125}
\begin{gathered}
(x_\alpha\text{ eventually satisfies }P)\land(x_\alpha\text{ frequently satisfies }Q)\\
\Downarrow \\
x_\alpha\text{ frequently satisfies }P\land Q
\end{gathered}
\end{gather}
\end{subequations}
\end{rem}


\subsubsection{Nets and topological spaces}

Let $(X,\MT_X)$ and $(Y,\MT_Y)$ be topological spaces.

\begin{df}
Let $(x_\alpha)_{\alpha\in I}$ be a net in $X$. Let $x\in X$. We say that $(x_\alpha)$ \textbf{converges to} $x$ and write \index{lim@$\lim_{\alpha\in I}x_\alpha\equiv \lim_\alpha x_\alpha$}
\begin{align*}
\lim_{\alpha\in I}x_\alpha\equiv \lim_\alpha x_\alpha=x
\end{align*}
or simply $x_\alpha\rightarrow x$ if the following statement holds:
\begin{itemize}
\item For every $U\in\Nbh_X(x)$, the net $(x_\alpha)$ is eventually in $U$.
\end{itemize}
\end{df}


\begin{cv}
If $I$ is a directed set, and if $(x_{\alpha_1,\dots,\alpha_n})_{(\alpha_1,\dots,\alpha_n)\in I^n}$ is a net in $X$ (where $I^n$ is equipped with the product preorder, cf. Def. \ref{lb207}), we 
\begin{align*}
\text{abbreviate}\qquad\lim_{(\alpha_1,\dots,\alpha_n)\in I^n}x_{\alpha_1,\dots,\alpha_n}\qquad\text{to}\qquad \lim_{\alpha_1,\dots,\alpha_n\in I}x_{\alpha_1,\dots,\alpha_n}
\end{align*}
\end{cv}


\begin{eg}
Let $(x_n)_{n\in\Zbb_+}$ be a sequence in a metric space. Then $(x_n)_{n\in\Zbb_+}$ is a Cauchy sequence iff $\lim_{m,n\in\Zbb_+}d(x_m,x_n)=0$.
\end{eg}

\begin{pp}\label{lb214}
Let $(x_\alpha)_{\alpha\in I}$ be an increasing (resp. decreasing) net in $\ovl\Rbb$. Let $x$ be the supremum (resp. infimum) of $\{x_\alpha:\alpha\in I\}$. Then $\lim_\alpha x_\alpha=x$.
\end{pp}


\begin{proof}
We address the case that $(x_\alpha)$ is increasing; the other case is similar. Let $S=\{x_\alpha:\alpha\in I\}$. Since $x=\sup S$, for each interval $U$ open in $\ovl\Rbb$ and containing $x$, we have $S\cap U\neq\emptyset$, and hence there exists $\alpha\in I$ such that $x_\alpha\in U$. Since the net is increasing, we have $x_\alpha\leq x_\beta\leq x$ for each $\beta\geq\alpha$. Since $U$ is an interval containing $x_\alpha,x$, it must contain $x_\beta$ for all $\beta\geq\alpha$. This proves that $\lim_\alpha x_\alpha=x$..
\end{proof}



\begin{df}
A net $(x_\alpha)_{\alpha\in I}$ in a metric space $X$ is called a \textbf{Cauchy net} if $\lim_{\alpha,\beta\in I}d(x_\alpha,x_\beta)=0$.
\end{df}

\begin{pp}
Let $(x_\alpha)$ be a convergent net in a metric space $X$. Then $(x_\alpha)$ is a Cauchy net.
\end{pp}

\begin{proof}
Let $x$ be the limit of $(x_\alpha)$. Then for each $\eps>0$, there exists $\gamma\in I$ such that $d(x,x_\alpha)<\eps$ for all $\alpha\geq\gamma$. Therefore, for all $\alpha,\beta\geq\gamma$ we have $d(x_\alpha,x_\beta)\leq d(x_\alpha,x)+d(x,x_\beta)<2\eps$.
\end{proof}


Recall that a metric space $X$ is called \textbf{(Cauchy) complete} \index{00@Cauchy completeness} if each Cauchy sequence in $X$ converges.

\begin{thm}\label{lb269}
Suppose that $X$ is a complete metric space. Then every Cauchy net in $X$ converges.
\end{thm}

\begin{proof}
Let $(x_\alpha)_{\alpha\in I}$ be a Cauchy net in $X$. Then for each $n\in\Zbb_+$ there exists $\gamma_n\in I$ such that $d(x_\alpha,x_\beta)<1/n$ for all $\alpha,\beta\geq\gamma_n$. Since $I$ is directed, by successively replacing $\gamma_1,\gamma_2,\dots$ with larger ones, we may assume that $(\gamma_n)_{n\in\Zbb_+}$ is increasing. Thus $d(x_{\gamma_m},x_{\gamma_n})<1/m$ whenever $m\leq n$, and hence $(x_{\gamma_n})_{n\in\Zbb_+}$ is a Cauchy sequence in $X$. Since $X$ is complete, $(x_{\gamma_n})_{n\in\Zbb_+}$ converges to some $x\in X$.

Now, for each $n$, and for each $\alpha\geq\gamma_n$ and $k\geq n$, we have $d(x_\alpha,x_{\gamma_k})<1/n$. Since $\lim_k d(x_{\gamma_k},x)=0$, we may find $k\geq n$ such that $d(x_{\gamma_k},x)<1/n$. Therefore $d(x_\alpha,x)<2/n$ for all $\alpha\geq\gamma_n$. This proves $\lim_\alpha x_\alpha=x$.
\end{proof}


\begin{pp}\label{lb217}
$X$ is Hausdorff iff every net in $X$ has at most one limit.
\end{pp}


\begin{proof}
First, assume that $X$ is not Hausdorff. Then there exist $x\neq y$ in $X$ such that every neighborhood of $x$ intersects every neighborhood of $y$. Let $I=\Nbh_X(x)\times\Nbh_X(y)$. For each $\alpha=(U,V)\in I$, by assumption, there exists $x_\alpha\in U\cap V$. Then $(x_\alpha)_{\alpha\in I}$ is a net in $X$ converging to both $x$ and $y$.

Conversely, assume that $X$ has a net $(x_\alpha)$ converging to distinct points $x,y\in X$. Then for each $U\in\Nbh_X(x)$, $(x_\alpha)$ is eventually in $X$. Similarly, for each $V\in\Nbh_X(y)$, $(x_\alpha)$ is eventually in $Y$. By Rem. \ref{lb208}, $(x_\alpha)$ is eventually in $U\cap V$. In particular, there exists $\alpha$ such that $x_\alpha\in U\cap V$. So $U\cap V\neq\emptyset$. Thus, $X$ is not Hausdorff.
\end{proof}


\begin{pp}\label{lb209}
Let $A\subset X$ and $x\in X$. Then $x\in\Cl_X(A)$ iff there exists a net $(x_\alpha)$ in $A$ such that $x$ is a limit of $(x_\alpha)$.
\end{pp}


\begin{proof}
Suppose that $x\in\ovl A$. Then each $U\in\Nbh_X(x)$ intersects $A$, and hence there exists $x_U\in U\cap A$. Then $(x_U)_{U\in\Nbh_X(x)}$ is a net in $A$ converging to $x$.

Conversely, assume that $x\notin\ovl A$. Then there exists $U\in\Nbh_X(x)$ disjoint from $A$. Therefore, any net $(x_\alpha)$ in $A$ is never in $U$, and hence does not converge to $x$.
\end{proof}



\begin{thm}\label{lb210}
Let $f:X\rightarrow Y$ be a map. Let $x\in X$. Then the following are equivalent:
\begin{enumerate}
\item[(1)] $f$ is continuous at $x$, that is, for each $V\in\Nbh_Y(f(x))$, there exists $U\in\Nbh_X(x)$ that is contained in $f^{-1}(V)$.
\item[(2)] For each net $(x_\alpha)$ in $X$ converging to $x$, the net $f(x_\alpha)$ converges to $f(x)$.
\item[(3)] For each net $(x_\alpha)$ in $X\setminus\{x\}$ converging to $x$, the net $f(x_\alpha)$ converges to $f(x)$.
\end{enumerate}
\end{thm}


\begin{proof}
(1)$\Rightarrow$(2): Assume (1). Let $(x_\alpha)$ be a net in $X$ converging to $x$. Then for any $V\in\Nbh(f(x))$, by choosing $U\in\Nbh(x)$ contained in $f^{-1}(V)$, we have that $(x_\alpha)$ is eventually in $U$, and hence $(f(x_\alpha))$ is eventually in $V$. Therefore $f(x_\alpha)\rightarrow f(x)$. This proves (2).

(2)$\Rightarrow$(3): Obvious.

$\neg$(1)$\Rightarrow$$\neg$(3): %Note that $f$ is continuous at any discrete point, i.e., any point $x$ such that $\{x\}$ is open in $X$. Therefore, it suffices to assume that $\{x\}$ is not open. Let us assume that (1) is not true, and prove that (3) is not true.
Since (1) is not true, there exists $V\in\Nbh(f(x))$ such that any $U\in\Nbh(x)$ is not contained in $f^{-1}(V)$. Since $x\in f^{-1}(V)$, the set $U\setminus\{x\}$ is not contained in $f^{-1}(V)$. (In particular, $U\setminus\{x\}$ is not empty.) Therefore, we can choose $x_U\in U\setminus\{x\}$ such that $f(x_U)\notin V$. It follows that $(x_U)_{U\in\Nbh_X(x)}$ is a net in $X\setminus\{x\}$ converging to $x$ that is always outside $V$. Thus $f(x)$ is not a limit of $(f(x_U))_{U\in\Nbh_X(x)}$, because $f(x_U)$ is always outside $V$. Therefore, (3) is not true.
\end{proof}


\begin{co}\label{lb325}
Let $f:X\rightarrow Y$ be continuous. Let $A\subset X$. Then
\begin{align*}
f(\ovl A)\subset \ovl{f(A)}
\end{align*}
\end{co}

\begin{proof}
For each $x\in\ovl A$, by Prop. \ref{lb209}, there exists a net $(x_\alpha)$ in $A$ converging to $x$. By Thm. \ref{lb210}, $(f(x_\alpha))$ converges to $f(x)$. By Prop. \ref{lb209} again, we conclude that $f(x)\in\ovl{f(A)}$.
\end{proof}


\begin{co}\label{lb211}
Let $f:X\rightarrow Y$ be a bijection. Then the following are equivalent.
\begin{enumerate}
\item[(1)] $f$ is a homeomorphism.
\item[(2)] For each $x\in X$ and each net $(x_\alpha)$ in $X$, we have $\lim_\alpha x_\alpha=x$ iff $\lim_\alpha f(x_\alpha)=f(x)$. 
\end{enumerate}
\end{co}

\begin{proof}
This follows immediately from Thm. \ref{lb210}.
\end{proof}

\begin{co}\label{lb212}
Let $\MT_X$ and $\MT'_X$ be two topologies on $X$. Then the following are equivalent.
\begin{enumerate}
\item[(1)] $\MT_X=\MT_X'$.
\item[(2)] For each $x\in X$ and each net $(x_\alpha)$ in $X$, the net $(x_\alpha)$ converges to $x$ in $\MT_X$ iff $(x_\alpha)$ converges to $x$ in $\MT'_X$. 
\end{enumerate}
\end{co}

In other words, \uwave{topologies are determined by net convergence}.


\begin{proof}
Apply Cor. \ref{lb211} to the identity map of $X$.
\end{proof}

\begin{df}
Recall that a topological space $X$ is called \textbf{first-countable} \index{00@First-countable} if for each $x\in X$, there exists a sequence $(U_n)_{n\in\Zbb_+}$ in $\Nbh_X(x)$ such that $\{U_n:n\in\Zbb_+\}$ is cofinal in $\Nbh_X(x)$ (i.e., for each $V\in\Nbh_X(x)$ there exists $n$ such that $U_n\subset V$). Moreover, once we have such $(U_n)_{n\in\Zbb_+}$, by replacing $U_n$ with $U_1\cap\cdots\cap U_n$, we may assume that $U_1\supset U_2\supset\cdots$. Therefore, $X$ being first-countable means that for each $x\in X$, the net $(U)_{U\in\Nbh_X(x)}$ has a subnet that is also a sequence.
\end{df}


\begin{rem}\label{lb221}
In Prop. \ref{lb217}, Prop. \ref{lb209}, Thm. \ref{lb210}, Cor. \ref{lb211}, and Cor. \ref{lb212}, if all the topologies involved are assumed to be first-countable, then the statements remain valid when nets are replaced by sequences. We leave the proof to the readers. 

For example, Cor. \ref{lb212} can be modified as follows: If $\MT_X$ and $\MT'_X$ are two first-countable topologies on $X$, then $\MT_X=\MT_X'$ iff any sequence $(x_n)$ converges to $x$ under $\MT_X$ iff $(x_n)$ converges to $x$ under $\MT'_X$.


Note that in Thm. \ref{lb210}, only the domain $X$ needs to be first-countable; the codomain $Y$ does not. \hqed
\end{rem}



\subsubsection{Subnets}

\begin{df}
A subset $E$ of a directed set $I$ is called \textbf{cofinal} \index{00@Cofinal subset} if:
\begin{align*}
\forall\alpha\in I~~~\exists\beta\in E~~~\text{such that }\alpha\leq\beta
\end{align*}
By the transitivity in Def. \ref{lb352} and property \eqref{eq183}, we clearly have
\begin{align*}
\forall\alpha_1,\dots,\alpha_n\in I~~~\exists\beta\in E~~~\text{such that }\alpha_1\leq\beta,\dots,\alpha_n\leq\beta
\end{align*}
\end{df}



\begin{df}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a set $X$. A \textbf{subnet} \index{00@Subnet} of $(x_\alpha)_{\alpha\in I}$ is, by definition, of the form $(x_{\alpha_s})_{s\in S}$ where $S$ is a directed set, and
\begin{align*}
(\alpha_s)_{s\in S}:S\rightarrow I\qquad s\mapsto \alpha_s
\end{align*}
is an increasing function (i.e. $s\leq s'\Rightarrow \alpha_s\leq\alpha_{s'}$) satisfying one of the following (clearly) equivalent conditions:
\begin{enumerate}
\item[(a)] The range $\{\alpha_s:s\in S\}$ is cofinal in $I$.
\item[(b)] For each $\beta\in I$, the net $(\alpha_s)_{s\in S}$ is eventually $\geq\beta$.
\end{enumerate}
\end{df}


\begin{eg}
A subsequence of a sequence is a subnet of that sequence.
\end{eg}


\begin{pp}\label{lb236}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a topological space $X$ converging to $x\in X$. Then every subnet $(x_{\alpha_s})_{s\in S}$ converges to $x$.
\end{pp}

\begin{proof}
Choose any $U\in\Nbh(x)$. Since $x_\alpha\rightarrow x$, there exists $\beta\in I$ such that for all $\alpha\geq\beta$ we have $x_\alpha\in U$. Since $\alpha_t$ is eventually $\geq\beta$, we see that $x_{\alpha_t}$ is eventually in $U$.
\end{proof}


Note that a subnet does not necessarily have the same index set as the original net. This definition of subnets is motivated largely by the following important property, which will play a crucial role in Subsec. \ref{lb229}.

\begin{thm}\label{lb213}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a topological space $X$. Let $x\in X$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $(x_\alpha)_{\alpha\in I}$ has a subnet converging to $x$.
\item For every $U\in\Nbh_X(x)$, the net $(x_\alpha)$ is frequently in $U$.
\item $x$ belongs to $\dps\bigcap_{\alpha\in I}\ovl{\{x_\beta:\beta\geq\alpha\}}$.
\end{enumerate}
Any $x\in X$ satisfying one of these three conditions is called a \textbf{cluster point} \index{00@Cluster point of a net in a topological space} of $(x_\alpha)_{\alpha\in I}$.
\end{thm}


\begin{proof}
(2)$\Leftrightarrow$(3): (3) holds iff $x$ belongs to $\ovl{\{x_\beta:\beta\geq\alpha\}}$ for each $\alpha$, iff each $U\in\Nbh(x)$ intersects $\{x_\beta:\beta\geq\alpha\}$ for each $\alpha$, iff for each $U\in\Nbh(x)$ and each $\alpha$, there exists $\beta\geq\alpha$ such that $x_\beta\in U$, iff (2) holds.

(1)$\Rightarrow$(2): Let $(x_{\alpha_s})$ be a subnet converging to $x$. Then for each $U\in\Nbh_X(x)$ and $\beta\in I$, the net $(x_{\alpha_s})$ is eventually in $U$, and $\alpha_s$ is eventually $\geq\beta$. Therefore, by Rem. \ref{lb208}, it is eventually true that $x_{\alpha_s}$ is in $U$ and, simultaneously,  $\alpha_s\geq\beta$. In particular, there exists $s$ such that $x_{\alpha_s}\in U$ and $\alpha_s\geq\beta$. This proves that $(x_\alpha)$ is frequently in $U$.

(2)$\Rightarrow$(1): Assume (2). Define a preordered set $(J,\leq)$ by
\begin{gather}
\begin{gathered}
J=\{(\alpha,U)\in I\times\Nbh_X(x):x_\alpha\in U \}\\[0.5ex]
(\alpha,U)\leq (\alpha',U')\qquad\Longleftrightarrow\qquad \alpha\leq \alpha'\text{ and }U\supset U'
\end{gathered}
\end{gather}
Let us prove that $J$ is directed: Suppose that $(\alpha_1,U_1)$ and $(\alpha_2,U_2)$ belong to $J$. Since $(\alpha)_{\alpha\in I}$ is eventually $\geq\alpha_1$ and eventually $\geq\alpha_2$, and since (by (2)) $(x_\alpha)$ is frequently in $U_1\cap U_2$, by Rem. \ref{lb208}, it is frequently true that $\alpha\geq\alpha_1,\alpha_2$ and $x_\alpha\in U_1\cap U_2$. Choose $\alpha\in I_{\geq\alpha_1}\cap I_{\geq\alpha_2}$ such that $x_\alpha\in U_1\cap U_2$. Then $(\alpha,U_1\cap U_2)$ belongs to $J$ and is $\geq(\alpha_1,U_1)$ and $\geq(\alpha_2,U_2)$. This proves that $J$ is directed.


The map $(\alpha,U)\in J\mapsto \alpha\in I$ is clearly increasing; its range is cofinal, since $(\alpha,X)\in J$ for each $\alpha\in I$. Therefore, $(x_{\alpha,U})_{(\alpha,U)\in J}$ is a subnet of $(x_\alpha)$. To prove (1), it remains to show that $(x_{\alpha,U})_{(\alpha,U)\in J}$ converges to $x$. For each $U\in\Nbh_X(x)$, by (2) there exists $\alpha\in I$ such that $x_\alpha\in U$, and hence $(\alpha,U)\in J$. For each $(\beta,V)\in J_{\geq(\alpha,U)}$, we have $x_\beta\in V\subset U$. This verifies $\lim_{(\alpha,U)\in J}x_{\alpha,U}=x$.
\end{proof}

\begin{thm}\label{lb218}
Assume that $X$ is first-countable, and let $(x_n)$ be a sequence in $X$. Let $x\in X$. Then $x$ is a cluster point of $(x_n)$ iff $(x_n)$ has a subsequence converging to $x$.
\end{thm}


\begin{proof}
We leave the proof to the reader as an exercise.
\end{proof}


\subsubsection{First-countable nets}


\begin{df}
Let $(I,\leq)$ be a directed set. Let $\infty_I$ (often abbreviated to $\infty$) be a new symbol not in $I$. Then
\begin{align*}
I^*=I\cup\{\infty_I\}
\end{align*}
is also a directed set if we extend the preorder $\leq$ of $I$ to $I^*$ by setting
\begin{align*}
\alpha\leq\infty_I\qquad(\forall\alpha\in I^*)
\end{align*}
For each $\alpha\in I$, let
\begin{align*}
I^*_{\geq\alpha}=\{\beta\in I^*:\beta\geq\alpha\}
\end{align*}
The \textbf{standard topology} \index{00@Topology of $\mc I^*=I\cup\{\infty_I\}$ where $I$ is an index set} on $I^*$ is defined to be the one induced by the basis
\begin{align}\label{eq127}
\mc B=\big\{\{\alpha\}:\alpha\in I \big\}\cup \big\{I^*_{\geq\alpha}:\alpha\in I \big\}
\end{align}
\end{df}


\begin{rem}\label{lb222}
Suppose that $(x_\alpha)_{\alpha\in I}$ is a net in a topology space $X$. Let $x_\infty\in X$. Extend $(x_\alpha)$ to a function
\begin{align*}
x:I^*\rightarrow X\qquad \alpha\mapsto x_\alpha,\quad \infty\mapsto x_\infty
\end{align*}
The following facts are easy to check:
\begin{enumerate}
\item $x$ is continuous at every point of $I$.
\item $x$ is continuous at $\infty$ iff the net $(x_\alpha)_{\alpha\in I}$ converges to $x_\infty$.
\end{enumerate}
In particular, $(x_\alpha)_{\alpha\in I}$ converges to $x_\infty$ iff the function $x:I^*\rightarrow X$ is continuous.
\end{rem}



\begin{df}
A directed set $I$ is called \textbf{first countable} \index{00@First countable directe sets and nets} if one of the following equivalent conditions holds:
\begin{enumerate}[label=(\arabic*)]
\item The standard topology on $I^*$ is first-countable.
\item $I$ has a countable cofinal subset.
\item The net $(\alpha)_{\alpha\in I}$ has a subnet which is also a sequence. (In other words, there is an increasing sequence in $I$ converging to $\infty$.) 
\end{enumerate} 
If $(x_\alpha)_{\alpha\in I}$ is a net in a set $X$ such that the index set $I$ is first-countable, we also say that $(x_\alpha)_{\alpha\in I}$ is a \textbf{first-countable net}. 
\end{df}

\begin{proof}[Proof of equivalence]
(1)$\Rightarrow$(2): Assume (1). Then $\Nbh_{I^*}(\infty)$ has a countable cofinal subset, which (due to \eqref{eq127}) can be chosen to be of the form $I_{\geq\alpha_1}^*,I_{\geq\alpha_2}^*,\dots$ where $(\alpha_n)_{n\in\Zbb_+}$ is a sequence in $I$. Since $(I_{\geq\alpha_n}^*)_{n\in\Zbb_+}$ is cofinal in $\Nbh_{I^*}(\infty)$, for each $\beta\in I$ there exists $n$ such that $I_{\geq\alpha_n}^*\subset I_{\geq\beta}^*$, and hence $\alpha_n\geq\beta$. This proves that $\{\alpha_n:n\in\Zbb_+\}$ is a countable cofinal subset of $I$. Hence (2) is proved.

(2)$\Rightarrow$(1): Assume (2). For every $\alpha\in I$, the direct set $\Nbh_{I^*}(\alpha)$ clearly has a countable cofinal subset, namely $\{\{\alpha\}\}$. Let $(\alpha_n)$ be a countable cofinal sequence in $I$. One checks easily that $(I_{\geq\alpha_n}^*)_{n\in\Zbb_+}$ is a cofinal sequence in $\Nbh_{I^*}(\infty)$. This proves (1).

(3)$\Rightarrow$(2): Obvious.

(2)$\Rightarrow$(3): Let $(\alpha_n)_{n\in\Zbb_+}$ be a cofinal sequence in $I$. Since $I$ is directed, by increasing $\alpha_2,\alpha_3,\dots$ successively, we can assume that $(\alpha_n)_{n\in\Zbb_+}$ is increasing. Clearly $(\alpha_n)$ converges to $\infty$.
\end{proof}



\begin{eg}
If $X$ is a topological space, then $X$ is first-countable iff $\Nbh_X(x)$ is a first-countable directed set for each $x\in X$.
\end{eg}


\begin{eg}
If $I,J$ are first-countable directed sets, then the directed set $I\times J$ is also first-countable. In particular, double sequences (i.e., nets of the form $(x_{m,n})_{m,n\in\Zbb_+}$) are first-countable nets.
\end{eg}




\begin{thm}\label{lb223}
Let $(x_\alpha)_{\alpha\in I}$ be a first-countable net in a topological space $X$. Let $x_\infty\in X$. Then the following are equivalent.
\begin{enumerate}
\item[(1)] $(x_\alpha)$ converges to $x_\infty$.
\item[(2)] For each sequence $(\alpha_n)_{n\in\Zbb_+}$ in $I$ converging to $\infty$, the sequence $(x_{\alpha_n})_{n\in\Zbb_+}$ converges to $x_\infty$.
\end{enumerate}
\end{thm}


\begin{proof}
This follows immediately from Thm. \ref{lb210} and Rem. \ref{lb221}.
\end{proof}

With the help of Thm. \ref{lb223}, one can easily generalize the MCT, the DCT, and Fatou's lemma from sequences to first-countable nets of functions. We leave the details of the proofs to the reader.

\begin{thm}[\textbf{Monotone convergence theorem (MCT)}] \index{00@Monotone convergence theorem}\label{lb224}
Let $(X,\mu)$ be a measure space. Let $(f_\alpha)$ be an increasing first-countable net of measurable functions $X\rightarrow\ovl\Rbb_{\geq0}$. Let $f:X\rightarrow\ovl\Rbb_{\geq0}$ be the pointwise limit of $(f_\alpha)$. Then $f$ is measurable, and
\begin{align*}
\lim_\alpha\int_Xf_\alpha d\mu=\int_X fd\mu
\end{align*}
\end{thm} 

\begin{thm}[\textbf{Dominated convergence theorem (DCT)}] \index{00@Dominated convergence theorem}\label{lb225}
Let $(X,\mu)$ be a measure space. Let $(f_\alpha)$ be a first-countable net of measurable functions $X\rightarrow\Cbb$. Assume that $(f_\alpha)$ converges pointwise to a measurable function $f:X\rightarrow\Cbb$. Suppose that there exists an integrable function $g:X\rightarrow\ovl\Rbb_{\geq0}$ such that $|f_\alpha|\leq g$ for all $\alpha$. Then $f_\alpha,f$ are integrable, and 
\begin{align*}
\lim_\alpha\int_Xf_\alpha d\mu=\int_X fd\mu
\end{align*}
\end{thm}

Note that without assuming the monotonicity of $(f_\alpha)$, the measurability of the limit function $f$ must be included as an assumption.

\begin{thm}[\textbf{Fatou's lemma}]\index{00@Fatou's lemma}\label{lb226}
Let $(X,\mu)$ be a measure space. Let $(f_\alpha)$ be a first-countable net of measurable functions $X\rightarrow\ovl\Rbb_{\geq0}$. Assume that $(f_\alpha)$ converges pointwise to a measurable function $f:X\rightarrow\ovl\Rbb_{\geq0}$. Then
\begin{align*}
\liminf_\alpha\int_Xf_\alpha d\mu\geq\int_X fd\mu
\end{align*}
\end{thm}

See Def. \ref{lb228} for the definition of $\liminf$.


\subsubsection{Unordered sum}



In this subsection, we fix a normed vector space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$. Fix a set $X$. Recall that $\fin(2^X)$ is a directed set, ordered by the inclusion ($A\leq B$ meaning $A\subset B$).


\begin{df}\label{lb230}
Let $f:X\rightarrow V$ be a map. The expression
\begin{align*}
\sum_{x\in X}f(x)
\end{align*}
(or simply $\sum_X f$) is called an \textbf{unordered sum}.\index{00@Unordered sum} If $v\in V$, we say that $\sum_{x\in X}f(x)$ equals (or \text{converges} to) $v$, if
\begin{align}\label{eq129}
\lim_{A\in\fin(2^X)}\sum_{x\in A}f(x)=v
\end{align}
In this case, we write
\begin{align}
\sum_{x\in X}f(x)=v 
\end{align}
\end{df}

Unwinding the definition of net convergence, \eqref{eq129} says that for every $\eps>0$, there exists a finite set $B\subset X$ such that for every finite set $A$ satisfying $B\subset A\subset X$, we have $\Vert v-\sum_{x\in A}f(x)\Vert<\eps$.


\begin{rem}\label{lb232}
If $V$ is complete, then $\sum_Xf$ converges precisely when the associated net $(\sum_A f)_{A\in\fin(2^X)}$ satisfies the Cauchy condition. Let us spell out what this Cauchy condition means:
\begin{itemize}
\item[(1)] For every $\eps>0$, there exists a finite set $B\subset X$ such that for any finite sets $A_1,A_2$ satisfying $B\subset A_1\subset X,B\subset A_2\subset X$, we have
\begin{align*}
\Big\Vert \sum_{A_1\setminus A_2}f-\sum_{A_2\setminus A_1}f \Big\Vert<\eps
\end{align*} 
\end{itemize}
Note that the term inside the norm is $\sum_{A_1}f-\sum_{A_2}f$. This is also equivalent to:
\begin{itemize}
\item[(2)] For every $\eps>0$, there exists a finite set $B\subset X$ such that for any finite set $E\subset X\setminus B$, we have 
\begin{align*}
\Big\Vert \sum_Ef\Big\Vert<\eps
\end{align*}
\end{itemize}
In practice, we will mainly use (2) as the Cauchy criterion for the convergence of $\sum_Xf$.
\end{rem}


\begin{proof}[Proof of the equivalence]
(2) follows from (1) by taking $A_1=B$ and $A_2=B\cup E$. (1) follows from (2) by taking $E_1=A_1\setminus A_2$ and $E_2=A_2\backslash A_1$ and then concluding $\Vert \sum_{E_1}f-\sum_{E_2}f\Vert<2\eps$.
\end{proof}



\begin{df}\label{lb231}
Let $g:X\rightarrow\ovl\Rbb_{\geq0}$ be a map. Note that the net $(\sum_A g)_{A\in\fin(2^X)}$ is increasing. Hence, its limit exists in $\ovl\Rbb$ and equals $\sup_{A\in\fin(2^X)}\sum_Ag$ (by Prop. \ref{lb214}). We write this as $\sum_Xg$, or more precisely:
\begin{align}
\sum_Xg\equiv\sum_{x\in X}g(x)\xlongequal{\mathrm{def}} \lim_{A\in \fin(2^X)}\sum_A g=\sup_{A\in \fin(2^X)}\sum_A g
\end{align}
We say that $\sum_Xg$ \textbf{converges} or \textbf{converges absolutely}, if $\sum_Xg<+\infty$. 
\end{df}


It is clear that $\sum_Xg<+\infty$ iff there exists $C\in\Rbb_{\geq0}$ such that $\sum_Ag\leq C$ for all $A\in\fin(2^X)$.


\begin{rem}
Note that when $g:X\rightarrow\Rbb_{\geq0}$, the convergence in Def. \ref{lb231} agrees with that in Def. \ref{lb230}. Therefore, Rem. \ref{lb232} still gives a Cauchy criterion for convergence.
\end{rem}



\begin{df}
Let $f:X\rightarrow V$. We say that $\sum_Xf$ \textbf{converges absolutely} \index{00@Absolutely convergent unordered sum} if 
\begin{align*}
\sum_{x\in X}\Vert f(x)\Vert<+\infty
\end{align*}
\end{df}

\begin{pp}\label{lb235}
Let $f:X\rightarrow V$, and assume that $\sum_Xf$ converges absolutely. Then $\Supp(f):=\{x\in X:f(x)\neq0\}$ is a countable set.
\end{pp}

\begin{proof}
For each $\eps>0$, let $A_\eps=\{x\in X:|f(x)|\geq \eps\}$. Then
\begin{align*}
\sum_X|f|\geq\sum_{A_\eps}|f|\geq\eps\sum_{A_\eps}1
\end{align*}
So $\sum_{A_\eps}1<+\infty$, and hence $A_\eps$ is a finite set. Since $\Supp(f)=\bigcup_{n\in\Zbb_+}A_{1/n}$, the set $\Supp(f)$ must be countable.
\end{proof}





\begin{pp}\label{lb234}
Assume that $V$ is complete. Let $f:X\rightarrow V$. If  $\sum_Xf$ converges absolutely, then it converges, and
\begin{align}\label{eq130}
\Big\Vert \sum_{x\in X} f(x) \Big\Vert\leq\sum_{x\in X} \Vert f(x)\Vert 
\end{align}
We write this simply as $\Vert\sum_X f\Vert\leq\sum_X |f|$.
\end{pp}

\begin{proof}
\eqref{eq130} clearly holds when $X$ is finite. In the general case, assume that $\sum_Xf $ converges absolutely. Then by the Cauchy criterion, for every $\eps>0$ there is $A\in \fin(2^X)$ such that for each finite $E\subset X\setminus A$ we have $\sum_E|f|<\eps$, and hence $\Vert \sum_E f\Vert<\eps$. Therefore $\sum_Xf$ converges by Cauchy criterion again.

By the continuity of the norm function $v\in V\mapsto \Vert v\Vert\in\Rbb_{\geq0}$ (cf. Rem. \ref{lb59}),
\begin{align*}
\Big\Vert \sum_X f \Big\Vert=\Big\Vert \lim_A \sum_Af \Big\Vert=\lim_A \Big\Vert \sum_Af \Big\Vert
\end{align*}
Since $\Vert \sum_A f\Vert\leq\sum_A|f|$, by Prop. \ref{lb214}, the above expression is no greater than
\begin{align*}
\lim_A\sum_A|f|=\sum_X|f|
\end{align*}
\end{proof}



\begin{eg}
Let $X$ be a set, equipped with the \textbf{counting measure} $\mu:2^X\rightarrow[0,+\infty]$. \index{00@Counting measure} That is, for each $A\subset X$, we have $\mu(A)=|A|$ if $A$ is a finite set, and $\mu(A)=+\infty$ if $A$ is infinite. Then for each $f:X\rightarrow\ovl\Rbb_{\geq0}$, we have
\begin{align}\label{eq172}
\int_X fd\mu=\sum_{x\in X}f(x)
\end{align}
If $f:X\rightarrow\Cbb$ satisfies $\sum_X|f|<+\infty$, then \eqref{eq172} still holds. The details are left to the reader.
\end{eg}


\begin{eg}
Let $f:\Zbb_+\rightarrow V$, and assume that $\sum_{\Zbb_+}f$ converges. Then
\begin{align*}
\sum_{\Zbb_+}f=\lim_{n\rightarrow\infty} (f(1)+\cdots+f(n))
\end{align*}
\end{eg}

\begin{proof}
By assumption, the net $(\sum_Af)_{A\in\fin(2^{\Zbb_+})}$ converges to $v:=\sum_{\Zbb_+}f$. By Prop. \ref{lb236}, the subnet $(\sum_{\{1,\dots,n\}}f)_{n\in\Zbb_+}$ also converges to $v$.
\end{proof}







\subsection{Nets and compactness}

\subsubsection{Compactness and cluster points}\label{lb229}


\begin{pp}\label{lb215}
Let $X$ be a topological space. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $X$ is compact.
\item (\textbf{Increasing chain property}) If $(U_\mu)_{\mu\in I}$ is an increasing net of open subsets of $X$ satisfying $\bigcup_{\mu\in I}U_\mu=X$, then $U_\mu=X$ for some $\mu$.
\item (\textbf{Decreasing chain property}) If $(E_\mu)_{\mu\in I}$ is a decreasing net of nonempty closed subsets of $X$, then $\bigcap_{\mu\in I}E_\mu\neq\emptyset$.
\end{enumerate}
\end{pp}

Here, ``increasing net'' means $U_\mu\subset U_\nu$ if $\mu\leq \nu$, and ``decreasing net'' means the opposite.

\begin{proof}
(1)$\Rightarrow$(2): Assume (1). Then $X=\bigcup_\mu U_\mu$ is an open cover of $X$. So, by the compactness of $X$, we have $X=U_{\mu_1}\cup\cdots\cup U_{\mu_n}$ for some $\mu_1,\dots,\mu_n\in I$. Choose $\mu\in I$ which is $\geq \mu_1,\dots,\mu_n$. Then $X=U_\mu$.

(2)$\Rightarrow$(1): Assume (2). Let $X=\bigcup_{\alpha\in\scr A} W_\alpha$ be an open cover of $X$. Let $I=\fin(2^{\scr A})$. For each $\mu=\{\alpha_1,\dots,\alpha_n\}\in I$, let $U_\mu=W_{\alpha_1}\cup\cdots\cup W_{\alpha_n}$. Then $(U_\mu)_{\mu\in I}$ is an increasing net of open sets covering $X$. Thus, by (2), we have $U_\mu=X$ for some $\mu$. This proves (1).

(2)$\Leftrightarrow$(3): If we let $E_\mu=X\setminus U_\mu$, then (2) says that if $(E_\mu)$ is a decreasing net of closed sets whose intersection is $\emptyset$, then $E_\mu=\emptyset$ for some $\mu$. This is the contraposition of (3).
\end{proof}


\begin{thm}\label{lb216}
Let $X$ be a topological space. Then $X$ is compact iff every net in $X$ has at least one cluster point.
\end{thm}


\begin{proof}
Assume that $X$ is compact. Let $(x_\alpha)_{\alpha\in I}$ be a net in $X$. Define $F_\alpha$ by 
\begin{align}
F_\alpha=\{x_\beta:\beta\in I,\beta\geq\alpha \}\label{eq126}
\end{align}
Then $(\ovl F_\alpha)_{\alpha\in I}$ is a decreasing net of nonempty closed subsets. So $\bigcap_\alpha\ovl F_\alpha$ is nonempty by the decreasing chain property (cf. Prop. \ref{lb215}). By Thm. \ref{lb213}, $\bigcap_\alpha\ovl F_\alpha$ is the set of cluster points of $(x_\alpha)$. Therefore, $(x_\alpha)$ has a cluster point.


Conversely, assume that every net of $X$ has a cluster point. By Prop. \ref{lb215}, to prove that $X$ is compact, it suffices to prove that $X$ satisfies the decreasing chain property. Let $(E_\alpha)_{\alpha\in I}$ be a decreasing net of nonempty closed subsets of $X$. For each $\alpha$ we choose $x_\alpha\in E_\alpha$, which gives a net $(x_\alpha)_{\alpha\in I}$ in $X$. The fact that $(E_\alpha)$ is decreasing implies that $F_\alpha\subset E_\alpha$ if we let $F_\alpha=\eqref{eq126}$. Thus, the closure $\ovl F_\alpha$ is a subset of $E_\alpha$ since $E_\alpha$ is closed. 

By Thm. \ref{lb213},  $\bigcap_{\alpha\in I}\ovl F_\alpha$ is the set of cluster points of $(x_\alpha)$, which is non-empty by assumption. Therefore, $\bigcap_\alpha E_\alpha$ is nonempty.
\end{proof}


\begin{df}
Recall that $X$ is called
\begin{itemize}
\item \textbf{separable} \index{00@Separable space} if $X$ has a countable dense subset.
\item \textbf{second countable} \index{00@Second countable} if the topology $\MT_X$ has a countable basis.
\item \textbf{Lindel\"of} \index{00@Lindel\"of space} if every open cover of $X$ has a countable subcover. 
\end{itemize}
\end{df}

















\begin{eg}
Any subspace of a second countable space is second countable.
\end{eg}


\begin{pp}\label{lb220}
We have
\begin{align*}
\text{separable}\quad\Longleftarrow\quad\text{second countable}\quad\Longrightarrow\quad\text{Lindel\"of}
\end{align*}
Moreover, for metrizable spaces, we have
\begin{align*}
\text{separable}\quad\Longleftrightarrow\quad\text{second countable}
\end{align*}
\end{pp}

In fact, Lindel\"of metrizable spaces are also second countable. We will not need this fact.

\begin{proof}
Step 1. Suppose that $X$ is second countable. Let $\{U_1,U_2,\dots\}$ be a countable basis of $\MT_X$. We may assume WLOG that each $U_n$ is nonempty. Choose $x_n\in U_n$. Then $\{x_n:n\in\Zbb_+\}$ is a countable dense subset of $X$. Therefore, $X$ is separable. 

Let $\MW$ be an open cover of $X$. For each $n$, let $W_n$ be any member of $\MW$ containing $U_n$; if no such $W_n$ exists then we set $W_n=\emptyset$. By the fact that $\{U_1,U_2,\dots\}$ is a basis of $\MT_X$, one easily shows that $\bigcup_nW_n=X$. Therefore, $(W_n)$ is a countable subcover of $\MW$. This proves that $X$ is Lindel\"of.

Step 2. Suppose that $X$ is a separable metric space. Let $\{x_1,x_2,\dots\}$ be a dense subset of $X$. Then $(B(x_n,1/k))_{n,k\in\Zbb_+}$ is a countable basis of $\MT_X$. This proves that $X$ is second countable.
\end{proof}



\begin{df}
Recall that a topological space $X$ is called \textbf{sequentially compact} \index{00@Sequential compact spaces} if every sequence in $X$ has a convergent subsequence. By Thm. \ref{lb218}, if $X$ is first-countable (in particular, if $X$ metrizable or second-countable), then $X$ is sequentially compact iff every sequence in $X$ has a cluster point.
\end{df}


\begin{thm}\label{lb219}
Let $X$ be a second-countable topological space. Then $X$ is compact iff $X$ is sequentially compact.
\end{thm}


\begin{proof}
Similar to the proof of Thm. \ref{lb216}, one shows that every sequence $(x_n)$ has a cluster point (i.e., $\bigcap_n\ovl\{x_k:k\geq n\}$ is nonempty, cf. Thm. \ref{lb213}) iff the intersection of a decreasing \textit{sequence} of non-empty closed subsets of $X$ is non-empty. The latter condition is equivalent to that $X$ is \textbf{countably compact}, that is, every countable open cover of $X$ has a finite subcover. Since $X$ is Lindel\"of (Prop. \ref{lb220}), compactness and countable compactness are equivalent.
\end{proof}



\begin{co}\label{lb354}
Let $X$ be a metric space. Then $X$ is compact iff $X$ is sequentially compact.
\end{co}

\begin{proof}
By Thm. \ref{lb219} and Prop. \ref{lb220}, it suffices to prove that $X$ is separable. Note that for each $\eps>0$, there exists a finite set $E_\eps\subset X$ such that the distance from any point of $X$ to $E_\eps$ is $\leq \eps$. (Otherwise, one can find a sequence $(x_n)_{n\in\Zbb_+}$ such that for each $n$, the distance from $x_{n+1}$ to $\{x_1,\dots,x_n\}$ is $>1/\eps$. Then any subsequence of $(x_n)$ is not a Cauchy sequence, and hence does not converge.) Then $\bigcup_{n\in\Zbb_+}E_{1/n}$ is a countable dense subset of $X$.
\end{proof}




\subsubsection{$\pmb\liminf$ and $\pmb\limsup$}



\begin{thm}\label{lb227}
Let $(x_\alpha)$ be a net in a compact Hausdorff space $X$, and let $x\in X$. The following are equivalent.
\begin{enumerate}
\item[(1)] $(x_\alpha)$ converges to $x$.
\item[(2)] $x$ is the only cluster point of $(x_\alpha)$.
\end{enumerate}
\end{thm}

In other words, $(x_\alpha)$ converges to $x$ iff any convergent subnet converges to $x$.

\begin{proof}
(1)$\Rightarrow$(2): This is obvious even without assuming that the Hausdorff space $X$ is compact.

$\neg$(1)$\Rightarrow$$\neg$(2): Assume that (1) is not true. Since $(x_\alpha)$ does not converge to $x$, there exists $U\in\Nbh_X(x)$ such that $(x_\alpha)$ is frequently not in $U$. Therefore, $J=\{\alpha\in I:x_\alpha\notin U\}$ is a cofinal subset of $I$. Note that $J$ is also directed: if $\alpha,\beta\in J$, choose $\gamma\in I$ such that $\alpha,\beta\leq\gamma$, then there exists $\delta\in I_{\geq\gamma}$ such that $x_\delta\notin U$, and hence $\delta\in J$. It follows that $(x_\alpha)_{\alpha\in J}$ is a subnet of $(x_\alpha)_{\alpha\in I}$ that is always outside $U$.

Since $X$ is compact, by Thm. \ref{lb216}, $(x_\alpha)_{\alpha\in J}$ has a subnet $(x_\mu)_{\mu\in K}$ converging to some $y\in X$. Then $y\notin U$, since $(x_\mu)$ is always not in $U$. Therefore, $x\neq y$, and $y$ is a cluster point of $(x_\alpha)$. Hence (2) is not true.
\end{proof}









\begin{df}\label{lb228}
Let $(x_\alpha)_{\alpha\in I}$ be a net in the compact Hausdorff space $\ovl\Rbb$. Let $S$ be the set of cluster points of $(x_\alpha)$ in $\ovl\Rbb$. Recall that $S$ is a closed subset by Thm. \ref{lb213}, and is non-empty by Thm. \ref{lb216}. Define \index{liminfsup@$\liminf,\limsup$}
\begin{align}
\pmb{\liminf_{\alpha\in I}x_\alpha}=\inf S\qquad \pmb{\limsup_{\alpha\in I}x_\beta}=\sup S
\end{align}
Since $S$ is closed, $\liminf_{\alpha\in I}x_\alpha$ and $\limsup_{\alpha\in I}x_\beta$ are both cluster points of $(x_\alpha)$. Therefore, they are the smallest and the largest cluster points of $(x_\alpha)$, respectively.
\end{df}


\begin{rem}
Let $(x_\alpha)$ be a net in $\ovl\Rbb$. Clearly $\liminf_\alpha x_\alpha\leq\limsup_\alpha x_\alpha$. By Thm. \ref{lb227}, if $x\in\ovl\Rbb$, then
\begin{align}
\lim_\alpha x_\alpha=x\qquad\Longleftrightarrow\qquad \liminf_\alpha x_\alpha=x=\limsup_\alpha x_\alpha
\end{align}
\end{rem}



\begin{pp}
Let $(x_\alpha)$ be a net in $\ovl\Rbb$. For each $\alpha\in I$, define  
\begin{gather}
A_\alpha=\inf\{x_\beta:\beta\geq \alpha \}\qquad  B_\alpha=\sup\{x_\beta:\beta\geq  \alpha \}
\end{gather}
Then $(A_\alpha)$ is increasing and $(B_\alpha)$ is decreasing; in particular, they converge in $\ovl\Rbb$. Moreover, we have
\begin{align}\label{eq128}
\lim_{\alpha\in I}A_\alpha=\liminf_{\alpha\in I}x_\alpha\qquad \lim_{\alpha\in I}B_\alpha=\limsup_{\alpha\in I}x_\alpha
\end{align}
\end{pp}

\begin{proof}
The monotonicities of $(A_\alpha)$ and $(B_\alpha)$ are obvious. Let $E_\alpha=\{x_\beta:\beta\geq\alpha\}$. Then $B_\alpha=\sup E_\alpha=\sup \ovl{E_\alpha}$. By Thm. \ref{lb213}, we have $\limsup_\alpha x_\alpha=\sup\bigcap_\alpha \ovl{E_\alpha}$. Since $\bigcap_\alpha \ovl{E_\alpha}\subset \ovl{E_\beta}$, we have $\limsup_\alpha x_\alpha\leq \sup \ovl E_\beta=B_\beta$. Therefore $\limsup x_\alpha\leq\lim B_\alpha$. 


For each open interval $U$ in $\ovl\Rbb$ containing $\lim B_\alpha$, the net $(B_\alpha)_{\alpha\in I}=(\sup E_\alpha)_{\alpha\in I}$ must be eventually in $U$. From the definition of $E_\alpha$, we see that $(x_\alpha)$ is frequently in $U$. It follows from Thm. \ref{lb213} that $\lim B_\alpha$ is a cluster point of $(x_\alpha)$. Therefore $\limsup x_\alpha\geq\lim B_\alpha$. This proves one of the two relations in \eqref{eq128}; the other one can be proved in the same way.
\end{proof}









\subsection{Review of important facts in point-set topology}

Fix a normed vector space $\mc V$.

\subsubsection{Miscellaneous definitions and properties}


\begin{df}
If $X,Y$ are metric spaces and $f:X\rightarrow Y$ is map, we say that $C\in\Rbb_{\geq0}$ is a \textbf{Lipschitz constant} \index{00@Lipschitz constant} of $f$ if
\begin{align*}
d(f(x_1),f(x_2))\leq Cd(x_1,x_2)\qquad\text{for all }x_1,x_2\in X
\end{align*}
If $f$ has a Lipschitz constant, we say that $f$ is \textbf{Lipschitz continuous}. \index{00@Lipschitz continuous}
\end{df}


\begin{df}
If $d$ and $d'$ are two metrics on a set $X$, we say that $d$ and $d'$ are \textbf{equivalent} \index{00@Equivalent metrics} if there exist $\alpha,\beta\in\Rbb_{>0}$ such that
\begin{align*}
d(x,y)\leq \alpha d'(x,y)\qquad d'(x,y)\leq\beta d(x,y)\qquad\text{for all }x,y\in X
\end{align*}
\end{df}

\begin{df}\label{lb33}
Let $X_1,\dots,X_N$ be metric spaces. For each $1\leq p<+\infty$, the \textbf{\pmb{$l^\infty$}-product metric} $d_\infty$ \index{00@$l^\infty$-product metric} and the \textbf{\pmb{$l^p$}-product metric} \index{00@$l^p$-product metric} $d_p$ are the metrics on $X_1\times\cdots\times X_N$ defined by
\begin{gather*}
d_\infty((x_1,\dots,x_N),(y_1,\dots,y_N)):=\max\{d(x_1,y_1),\dots,d(x_N,y_N)\}\\
d_p((x_1,\dots,x_N),(y_1,\dots,y_N)):=\sqrt[p]{d(x_1,y_1)^p+\cdots+d(x_N,y_N)^p}
\end{gather*}
for all $x_i,y_i\in X_i$. These metrics are equivalent. We equip $X_1\times\cdots\times X_N$ with any metric equivalent to $l^\infty$ and $l^p$.
\end{df}

\begin{rem}\label{lb34}
Recall that if $f:X\rightarrow Y$ is a map of topological spaces, and $X=\bigcup_{i\in I} U_i$ is an open cover of $X$, then $f$ is continuous iff $f|_{U_i}:U_i\rightarrow Y$ is continuous for any $i\in I$.
\end{rem}


\begin{df}
Let $f:X\rightarrow Y$ be a map where $(Y,\mc T_Y)$ is a topological space. The \textbf{pullback topology} \index{00@Pullback topology} on $X$ is defined to be
\begin{align*}
f^*\mc T_Y:=f^{-1}(\mc T_Y)=\{f^{-1}(V):V\in\mc T_Y\}
\end{align*}
Then, a net $(x_\alpha)$ in $X$ converges under $f^*\mc T_Y$ to $x$ iff
\begin{align*}
\lim_\alpha f(x_\alpha)=f(x)
\end{align*}
\end{df}

The following facts are well-known.

\begin{pp}\label{lb324}
Let $X$ be a metric space. Let $A\subset X$, whose metric inherits from that of $X$. If $A$ is complete, then $A$ is closed. Conversely, if $A$ is closed and $X$ is complete, then $A$ is complete.
\end{pp}



\begin{pp}\label{lb353}
Let $X$ be a Hausdorff space. Let $A\subset X$. If $A$ is compact, then $A$ is closed. Conversely, if $A$ is closed and $X$ is compact, then $A$ is compact.
\end{pp}


\subsubsection{Semicontinuous functions}


Let $X$ be a topological space.


\begin{df}
We say that $f:X\rightarrow\ovl\Rbb$ is \textbf{lower semicontinuous} \index{00@Lower semicontinuous} if $f^{-1}(a,+\infty]$ is open for each $a\in\ovl\Rbb$. We say that $f$ is  \textbf{upper semicontinuous} \index{00@Upper semicontinuous} if $f^{-1}[-\infty,a)$ is open for each $a\in\ovl\Rbb$. 
\end{df}

\begin{eg}
Let $A\subset X$. Then $\chi_A$ is lower semicontinuous iff $A$ is open.
\end{eg}

\begin{pp}\label{lb256}
Let $(f_i)_{i\in I}$ be a family of lower semicontinuous functions $X\rightarrow\ovl\Rbb$. Let $f(x)=\sup_{i\in I}f_i(x)$. Then $f:X\rightarrow\ovl\Rbb$ is lower semicontinuous.
\end{pp}

\begin{proof}
Let $x\in f^{-1}(a,+\infty]$. Since $f(x)>a$, there exists $i$ such that $f_i(x)>a$. Since $f_i$ is lower semi-continuous, there exists $U\in\Nbh(x)$ such that $f_i|_U>a$ (e.g. $U=f_i^{-1}(a,+\infty]$), and hence $f|_U>a$. So $U\subset f^{-1}(a,+\infty]$. We have thus proved that any $x\in f^{-1}(a,+\infty]$ is an interior point of $f^{-1}(a,+\infty]$.
\end{proof}


\begin{pp}
Let $f:X\rightarrow\ovl\Rbb$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $f$ is lower semicontinuous.
\item For each $x\in X$ and each net $(x_\alpha)$ in $X$ converging to $x$, we have $\liminf_\alpha f(x_\alpha)\geq f(x)$.
\item For each $x\in X$ and each net $(x_\alpha)$ in $X$ converging to $x$, we have $\limsup_\alpha f(x_\alpha)\geq f(x)$.
\end{enumerate}
\end{pp}


\begin{proof}
(1)$\Rightarrow$(2): Assume (1). Let $x\in X$, and let $(x_\alpha)$ be a net converging to $x$. If $\lambda\in\Rbb$ satisfies $\lambda<f(x)$, then by (1), $f^{-1}(\lambda,+\infty]$ is a neighborhood of $x$. Therefore, $x_\alpha$ is eventually in $f^{-1}(\lambda,+\infty]$, and hence $f(x_\alpha)$ is eventually $>\lambda$. Therefore $\liminf_\alpha f(x_\alpha)\geq\lambda$. Since $\lambda$ is arbitrary, we must have $\liminf_\alpha f(x_\alpha)\geq f(x)$. This proves (2).

(2)$\Rightarrow$(3): This is obvious.

$\neg$(1)$\Rightarrow$$\neg$(3): Assume that $f$ is not lower semicontinuous. Then there exists $\lambda\in[-\infty,+\infty)$ such that $f^{-1}(\lambda,+\infty]$ is not open, and hence has non-interior point $x$. Therefore, $f(x)>\lambda$, and for any $U\in\Nbh_X(x)$ there exists $x_U\in U$ such that $f(x_U)\leq\lambda$. So $(x_U)_{U\in\Nbh_X(x)}$ is a net in $X$ converging to $x$, and $\limsup_U f(x_U)\leq\lambda<f(x)$. Hence (3) is false. 
\end{proof}







\subsubsection{Product topology and pointwise convergence}

Let $(X_\alpha)_{\alpha\in\scr A}$ be a family of topological spaces. Elements of the product space
\begin{align*}
S=\prod_{\alpha\in\scr A}X_\alpha
\end{align*}
are denoted by $x=(x_\alpha)_{\alpha\in\scr A}$. Let
\begin{align*}
\pi_\alpha:S\rightarrow X_\alpha\qquad x\mapsto x(\alpha)
\end{align*}
It is easy to check that
\begin{align*}
\mc B=\Big\{&\prod_{\alpha\in\scr A} U_\alpha: \text{each $U_\alpha$ is open in $X_\alpha$},\\
& \text{$U_\alpha=X_\alpha$ for all but finitely many $\alpha$}\Big\}\\
=&\Big\{\bigcap_{\alpha\in E} \pi_\alpha^{-1}(U_\alpha):E\in\fin(2^{\scr A}), \text{ $U_\alpha$ is open in $X_\alpha$ for each $\alpha\in E$}    \Big\}
\end{align*}
is a base for a topology, namely, for each $W_1,W_2\in\mc B$ and $x\in W_1\cap W_2$, there exists $W_3\in\mc B$ such that $W_3\subset W_1\cap W_2$. Therefore, $\mc B$ generates a topology.
\begin{df}
The topology of $S$ generated by $\mc B$ is called the \textbf{product topology} \index{00@Product topology} or \textbf{pointwise convergence topology} \index{00@Pointwise convergence topology} of $S$. Unless otherwise stated, the product of a family of topological spaces is equipped with the product topology.
\end{df}

\begin{rem}
If each $X_\alpha$ is Hausdorff, then $S$ is clearly Hausdorff.
\end{rem}


\begin{thm}\label{lb50}
Let $(x_\mu)_{\mu\in I}$ be a net in $S$, and let $x\in S$. Then the following conditions are equivalent:
\begin{enumerate}[label=(\alph*)]
\item $\dps\lim_{\mu\in I}x_\mu=x$ in the product topology.
\item $(x_\mu)_{\mu\in I}$ converges pointwise to $x$, namely, for each $\alpha\in\scr A$ we have $\dps\lim_{\mu\in I}x_\mu(\alpha)=x(\alpha)$ in $X_\alpha$.
\end{enumerate}
\end{thm}


\begin{proof}
(a)$\Rightarrow$(b): Fix $\alpha\in\scr A$. For each open $U_\alpha\subset X_\alpha$, we have $\pi^{-1}(U_\alpha)\in\mc B$. Therefore,
\begin{align}
\pi_\alpha:S\rightarrow X_\alpha\qquad\text{is continuous}
\end{align}
Thus, if $\lim_\mu x_\mu=x$, then $\lim_\mu \pi_\alpha(x_\mu)=\pi_\alpha(x)$. This proves (b).

(b)$\Rightarrow$(a): Assume (b). Choose any $W\in\MB$ containing $x$. Then there exists $E\in\fin(2^{\scr A})$ such that $W=\bigcap_{\alpha\in E}\pi_\alpha^{-1}(U_\alpha)$, where each $U_\alpha\subset X_\alpha$ is open and containing $x_\alpha$. For such $\alpha\in E$, since $\lim_\mu x_\mu(\alpha)=x(\alpha)$, we know that $(x_\mu(\alpha))$ is $\mu$-eventually in $U_\alpha$. Therefore, since $E$ is finite, we conclude that $(x_\mu)$ is eventually in $W$. This proves (a).
\end{proof}

\begin{co}\label{lb55}
Let $Z$ be a topological space. Suppose that for each $\alpha\in\scr A$, a map $f_\alpha:Z\rightarrow X_\alpha$  is chosen. Then \index{zz@$\bigvee_{\alpha\in\scr A}f_\alpha$}
\begin{gather}
\bigvee_{\alpha\in\scr A}f_\alpha:Z\rightarrow\prod_{\alpha\in\scr A}X_\alpha\qquad z\mapsto (f_\alpha(z))_{\alpha\in\scr A}
\end{gather}
is continuous iff $f_\alpha$ is continuous for each $\alpha\in\scr A$.
\end{co}

\begin{proof}
If $F:=\bigvee_{\alpha\in\scr A}f_\alpha$ is continuous, then since $\pi_\alpha$ is continuous, $f_\alpha=\pi_\alpha\circ f_\alpha$ is also continuous. Conversely, suppose that each $f_\alpha$ is continuous. Let $(z_i)$ be a net in $Z$ converging to $z\in Z$. For each $\alpha$, since $f_\alpha$ is continuous, we see that $\lim_if_\alpha(z_i)=f_\alpha(z)$. By Thm. \ref{lb50}, $F(z_i)$ converges to $F(z)$. This proves that $F$ is continuous.
\end{proof}




\begin{pp}\label{lb51}
Suppose that $\scr A$ is countable. If each $X_\alpha$ is second countable, then $S$ is second countable. If each $X_\alpha$ is metrizable, then $S$ is metrizable.
\end{pp}

\begin{proof}
If $\mc U_\alpha$ is a base of the topology of $X_\alpha$, then
\begin{align*}
\mc U:=\Big\{\bigcap_{\alpha\in E} \pi_\alpha^{-1}(U_\alpha):E\in\fin(2^{\scr A}), U_\alpha\in \MU_\alpha    \Big\}
\end{align*}
is a base of the the product topology, which is countable if each $\MU_\alpha$ is countable.

Now assume that each $X_\alpha$ is equipped with a metric $d_\alpha$. Fix any $R\in\Rbb_{>0}$, let $\wtd d_\alpha$ be metric on $X_\alpha$ inducing the same topology as $d_\alpha$ and satisfying $\wtd d_\alpha\leq R$. For example,
\begin{subequations}\label{eq32}
\begin{align}
\wtd d_\alpha(x_\alpha,y_\alpha)=\min\{d_\alpha(x_\alpha,y_\alpha),R\}\qquad\text{for each }x_\alpha,y_\alpha\in X_\alpha
\end{align}
Let $\nu:\scr A\rightarrow\Zbb_+$ be an injective map, and define a metric $d$ on $S$ by
\begin{align}
d(x,y)=\sum_{\alpha\in\scr A}2^{-\nu(\alpha)}\wtd d_\alpha(x(\alpha),y(\alpha))\qquad\text{for each }x,y\in S
\end{align}
\end{subequations}
One shows easily that a net $(x_\mu)$ in $S$ converges in the metric $d$ to $x\in S$ iff $\lim_\mu \wtd d_\alpha(x_\mu(\alpha),x(\alpha))=0$ for all $\alpha\in\scr A$. Thus, by Thm. \ref{lb50}, $d$ induces the product topology.
\end{proof}








\begin{thm}[\textbf{Tychonoff theorem}]\index{00@Tychonoff theorem}\label{lb61}
Assume that $X_\alpha$ is compact for each $\alpha\in\scr A$. Then $S$ is compact.
\end{thm}


\begin{proof}[$\star$ Proof]
Assume WLOG that $\scr A$ is non-empty, and that each $X_\alpha$ is non-empty. Let $(x_\mu)_{\mu\in I}$ be a net in $S$. We want to show that $(x_\mu)_{\mu\in I}$ has a cluster point.

For each $\scr E\subset\scr A$, let $S_{\scr E}=\prod_{\alpha\in\scr E}X_\alpha$. For each $x\in S_{\scr E}$, we write $\Domain(x)=\scr E$.  For each $\scr E\subset\scr F\subset\scr A$ and $y\in S_{\scr F}$, let $y|_{\scr E}=(y(\alpha))_{\alpha\in\scr E}$. Let
\begin{align*}
P=\bigcup_{\scr E\subset\scr A}\big\{x\in S_{\scr E}:x\text{ is a cluster point of $(x_\mu|_{\scr E})_{\mu\in I}$ in $S_{\scr E}$} \big\}
\end{align*} 
equipped with the partial order ``$\subset$''. In other words, if $x,y\in P$, then $x\leq y$ means that $\Domain(x)\subset\Domain(y)$ and $x=y|_{\scr E}$.

Since each $X_\alpha$ is compact, $P$ is clearly non-empty. Let us show that every totally ordered non-empty subset $Q\subset P$ has an upper bound in $P$, so that Zorn's lemma can be applied. Let $x$ be the union of all elements of $Q$. Thus $x\in S_{\scr E}$ where $\scr E=\bigcup_{y\in Q}\Domain(y)$, and we have $x|_{\Domain(y)}=y$ for each $y\in Q$. 

To show that $x$ is a cluster point of $(x_\mu|_{\scr E})_{\mu\in I}$ in $S_{\scr E}$, we pick any neighborhood of $x$ in $S_{\scr E}$, which, after shrinking if necessary, is of the form $W=\prod_{\alpha\in\scr E}U_\alpha$ where each $U_\alpha\subset X_\alpha$ is open, and there exists $K\in\fin(2^{\scr E})$ such that $U_\alpha=X_\alpha$ whenever $\alpha\notin K$. Since $\scr E=\bigcup_{y\in Q}\Domain(y)$, there exists $y\in Q$ such that $K\subset\Domain(y)$. Namely,   $(x_\mu|_{\Domain(y)})_{\mu\in I}$ has cluster point $y$, and $K\subset\Domain(y)$. Therefore $(x_\mu|_K)_{\mu\in I}$ has cluster point $y|_K$ (which equals $x|_K$ because $x|_{\Domain(y)}=y$), and hence is frequently in $\prod_{\alpha\in K}U_\alpha$. Thus $(x_\mu|_{\scr E})_{\mu\in I}$ is frequently in $W$. This finishes the proof that $x\in P$. Clearly $x$ is an upper bound of $Q$.

Now we can apply Zorn's lemma, which claims that $P$ has a maximal element $x\in P$. The proof of the Tychonoff theorem will be finished by showing that $\scr E:=\Domain(x)$ equals $\scr A$. Suppose not. Choose $\beta\in\scr A\setminus\scr E$. Since $x\in P$, there is a subnet $(x_{\mu_\nu}|_{\scr E})_{\nu\in J}$ of $(x_\mu|_{\scr E})_{\mu\in I}$ converging pointwise to $x$. Since $X_\beta$ is compact, $(x_{\mu_\nu}(\beta))_{\nu\in J}$ has a converging subnet $(x_{\mu_{\nu_\upsilon}}(\beta))_{\upsilon\in L}$. Define $\wtd x\in S_{\scr E\cup\{\beta\}}$ to be $x$ when restricted to $\scr E$, and $\wtd x(\beta):=\lim_\upsilon x_{\mu_{\nu_\upsilon}}(\beta)$. Then $\wtd x\in P$, and $\wtd x$ is strictly larger than $x$, contradicting the maximality of $x$.
\end{proof}



\begin{rem}\label{lb52}
If $\scr A$ is a countable set, and if each $X_\alpha$ is compact and second-countable, the \textbf{diagonal method} \index{00@Diagonal method} can be used in place of Zorn's lemma to prove that $S$ (which is second countable by Prop. \ref{lb51}) is compact.

We consider the case that $\scr A=\Zbb_+$. (The case that $\scr A$ is finite is even simpler.) Let $(x_n)_{n\in\Zbb_+}$ be a sequence in $S$. We construct inductively a double sequence $(x_{m,n})_{m,n\in\Zbb_+}$ in $S$ as follows. Since (by Thm. \ref{lb219}) $X_1$ is sequentially compact, $(x_n)$ has subseqeunce $(x_{1,n})_{n\in\Zbb_+}$ whose first component $(x_{1,n}(1))_{n\in\Zbb_+}$ converges to some $x(1)\in X_1$. Suppose that $(x_{m-1,n})_{n\in\Zbb_+}$ has been constructed (where $m-1\geq 1$). Since $X_m$ is sequentially compact, $(x_{m-1,n})_{n\in\Zbb_+}$ has a subsequence $(x_{m,n})_{n\in\Zbb_+}$ whose $m$-th component $(x_{m,n}(m))_{n\in\Zbb_+}$ to some $x(m)\in X_m$. In this way, the double sequence $(x_{m,n})$ in $S$ and the element $x\in S$ are constructed. One checks easily that $(x_{n,n})_{n\in\Zbb_+}$ is a subsequence of $(x_n)$ converging to $x$.  

We have thus proved that $S$ is sequentially compact. By Thm. \ref{lb219}, $S$ is compact. \hqed 
\end{rem}











\subsubsection{Precompact sets}


Let $X$ be a Hausdorff space. 

\begin{df}
Let $A\subset X$. We say that $A$ is \textbf{precompact} relative to $X$ and \index{zz@$\Subset$} write 
\begin{align*}
A\Subset X
\end{align*}
if $\Cl_X(A)$ is compact, equivalently, if $A$ is contained in a compact subset of $X$.
\end{df}

Recall that a subset of a compact Hausdorff space is closed iff it is compact (cf. Prop. \ref{lb353}).

\begin{proof}[Proof of equivalence]
``$\Rightarrow$'': Obvious. ``$\Leftarrow$'': Let $B\subset X$ be compact and containing $A$. Then $B$ is closed in $X$. So $\Cl_X(A)\subset B$. Since $\Cl_X(A)$ is closed in $X$ and hence closed in $B$, it is compact.
\end{proof}

\begin{rem}\label{lb1}
Let $W\subset X$. Then for each $A\subset W$, we have 
\begin{align*}
A\Subset W\qquad\Longleftrightarrow\qquad A\Subset X\text{ and }\Cl_X(A)\subset W
\end{align*}
When either side is true, we have $\Cl_W(A)=\Cl_X(A)$. Thus, both $\Cl_W(A)$ and $\Cl_X(A)$ can be denoted unambiguously by $\ovl A$.
\end{rem}

In practice, we often choose $W$ to be an open subset of $X$.

\begin{proof}
``$\Leftarrow$'': $\Cl_X(A)$ is a compact set inside $W$ and contains $A$. So $A\Subset W$.

``$\Rightarrow$'': We have a compact set $B$ such that $A\subset B\subset W$. So $A\Subset X$. Since $B$ is closed in $X$, we have $\Cl_X(A)\subset B$ and hence $\Cl_X(A)\subset W$.

It is obvious that $\Cl_W(A)\subset\Cl_X(A)$. Assume $A\Subset W$. Then $\Cl_W(A)$ is compact. In the above paragraph, if we choose $B=\Cl_W(A)$. then we have $\Cl_X(A)\subset B=\Cl_W(A)$. This proves $\Cl_W(A)=\Cl_X(A)$.
\end{proof}

\begin{rem}\label{lb2}
Let $U$ be an open subset of $X$. Let $f\in C_c(U,\mc V)$. Then by zero-extension, $f$ can be viewed as an element of $C_c(X,\mc V)$ supported in $U$. Briefly speaking, we have
\begin{align*}
C_c(U,\mc V)\subset C_c(X,\mc V)
\end{align*}
Moreover, for each $f\in C_c(U,\mc V)$, we have
\begin{align*}
\Supp_U(f)=\Supp_X(f)
\end{align*}
\end{rem}

\begin{proof}
Let $f$ take value $0$ outside $U$. Let $K=\Supp_U(f)$, which is compact by assumption. Since $f|_U$ and $f|_{K^c}=0$ are continuous, and since $X=U\cup K^c$ is an open cover on $X$, $f$ is continuous. By the Rem. \ref{lb1}, we have $\Supp_U(f)=\Supp_X(f)$. Therefore $f\in C_c(X,\mc V)$.
\end{proof}


Under the setting of Rem. \ref{lb2}, it is clear that
\begin{align}
C_c(U,\mc V)=\{f\in C_c(X,\mc V):\Supp_X(f)\subset U\}
\end{align}



\begin{pp}\label{lb180}
Assume that $X$ is a metric space, and let $A\subset X$. Then $A$ is precompact iff every sequence $(x_n)$ in $A$ has a subsequence converging to some $x\in X$. 
\end{pp}

\begin{proof}
The direction ``$\Rightarrow$'' follows from the sequential compactness of $\ovl A$ (cf. Cor. \ref{lb354}). Conversely, assume that every sequence in $A$ has a subsequence convering in $X$. Let us prove that $\ovl A$ is sequentially compact. Let $(x_n)$ be a sequence in $\ovl A$. For each $n$, choose $y_n\in A$ such that $d(x_n,y_n)<1/n$. By assumption, $(y_n)$ has a subsequence $(y_{n_k})$ converging to some $x\in X$. One easily checks that $(x_{n_k})$ converges to $x$.
\end{proof}




\subsubsection{LCH spaces}

Let $X$ be LCH.

\begin{pp}\label{lb3}
Any closed or open subset of $X$ is LCH.
\end{pp}

\begin{proof}
See \cite[Subsec. 8.6.2]{Gui-A}.
\end{proof}

\begin{co}\label{lb54}
Let $W\subset X$ be an open subset. Let $K\subset W$ be compact. Then there exists an open subset $U$ of $X$ such that $K\subset U\Subset W$. 
\end{co}
\begin{proof}
The case that $K$ is a single point follows from the fact that $W$ is LCH, cf. Prop. \ref{lb3}. The general case follows from the compactness of $K$.
\end{proof}

\begin{co}\label{lb102}
Let $K_1,K_2$ be mutually disjoint compact subsets of $X$. Then there exist open subsets $U_1,U_2$ of $X$ such that $K_1\subset U_1$ and $K_2\subset U_2$.
\end{co}

\begin{proof}
This corollary in fact holds even without the assumption that $X$ is locally compact, and its proof is a straightforward exercise in point-set topology. However, it also follows directly from the results established above. Indeed, by Prop. \ref{lb3}, $X\setminus K_2$ is LCH. Therefore, by Cor. \ref{lb54}, there exists an open set $U_1$ such that $K_1\subset U_1\Subset X\setminus K_2$. Let $U_2=X\setminus\ovl U_1$.
\end{proof}





\begin{thm}[\textbf{Urysohn's lemma}]\label{lb56}\index{00@Urysohn's lemma}
Let $K\subset X$ be compact. Then there exists a (continuous) \textbf{Urysohn function} \index{00@Urysohn function} $f$ with respect to $K$ and $X$, i.e., $f\in C_c(X,[0,1])$ and $f|_K=1$.
\end{thm}

\begin{proof}
See \cite[Sec. 15.4]{Gui-A}.
\end{proof}


\begin{rem}\label{lb57}
Urysohn's lemma can be used in the following way. Suppose that $K\subset U\subset X$ where $K$ is compact and $U$ is open in $X$. By Prop. \ref{lb3}, $U$ is LCH. Therefore, by Thm. \ref{lb56}, there exists $f\in C_c(U,[0,1])$ such that $f|_K=1$. By Rem. \ref{lb2}, $f$ can be viewed as an element of $C_c(X,[0,1])$ satisfying $f|_K=1$ and $\Supp_X(f)\subset U$.
\end{rem}


\begin{thm}\label{lb100}
Let $K$ be a compact subset of $X$. Let $\fk U=(U_1,\dots,U_n)$ be a finite collection of open subsets of $X$ covering $K$ (i.e. $K\subset U_1\cup\cdots\cup U_n$). Then there exist $h_i\in C_c(U_i,\Rbb_{\geq0})$ (for all $1\leq i\leq n$) satisfying the following conditions:
\begin{enumerate}[label=(\arabic*)]
\item $0\leq \dps \sum_{i=1}^nh_i\leq 1$ on $X$. 
\item  $\dps\sum_{i=1}^nh_i\big|_K=1$.
\end{enumerate}
Such $h_1,\dots,h_n$ are called a \textbf{partition of unity of \pmb{$K$} subordinate to \pmb{$\fk U$}}. \index{00@Partition of unity in LCH spaces}
\end{thm}

In fact, $h_1,\dots,h_n$ should be viewed as a partition of the Urysohn function $h:=h_1+\cdots+h_n$.


\begin{proof}
See \cite[Sec. 15.4]{Gui-A}. Note that condition (1) is not stated in some textbooks on partitions of unity.  However, even if (1) is not initially satisfied, one can enforce it by setting $g(x)=\max\{\sum_i h_i(x),1\}$ and replacing each $h_i$ with $h_i/g$.
\end{proof}






\begin{thm}[\textbf{Tietze extension theorem}]\index{00@Tietze extension theorem}\label{lb83}
Let $K$ be a compact subset of $X$. Let $f\in C(K,\Fbb)$. Then there exists $\wtd f\in C_c(X,\Fbb)$ such that $\wtd f|_K=f$, and that $\Vert\wtd f\Vert_{l^\infty(X)}=\Vert f\Vert_{l^\infty(K)}$.
\end{thm}

\begin{proof}
See \cite[Sec. 15.4]{Gui-A}.
\end{proof}

\begin{rem}\label{lb359}
Let $k\in\Nbb\cup\{\infty\}$. Suppose that $X$ is an open subset of $\Rbb^n$ (or more generally, a $C^k$-manifold with or without boundary, e.g. $[a,b]$). Then Urysohn's lemma (Thm. \ref{lb56}), the partition of unity (Thm. \ref{lb100}), and the Tietze extension theorem (Thm. \ref{lb83}) hold verbatim with $C_c$ replaced by $C_c^k$. See \cite[Sec. 30.6]{Gui-A} for detailed explanations.

As an application of the $C^k$-Urysohn lemma, we see that elements of $C^k_c(X,\Fbb)$ vanishes nowhere and separates the points of $X$. It follows from the Stone-Weierstrass Theorem (see Thm. \ref{lb360}) that $C_c^k(X,\Fbb)$ is $l^\infty$-dense in $C_0(X,\Fbb)$.   \hqed
\end{rem}




\begin{df}
We let \index{C0@$C_0(X,\mc V),C_0(X,E)$} $\pmb{C_0(X,\mc V)}$ be the set of all $f\in C(X,\mc V)$ whose zero-extension to the one-point compactification of $X$ is continuous at $\infty$. Equivalently, $C_0(X,\mc V)$ is the set of all $f\in C(X,\mc V)$ such that for any $\eps>0$ there exists a compact $K\subset X$ such that $\Vert f\Vert_{l^\infty(X\setminus K)}<\eps$. See \cite[Subsec. 15.8.1]{Gui-A} for more discussions. For each $E\subset\mc V$, we let
\begin{align*}
C_0(X,E)=C_0(X,V)\cap E^X
\end{align*}
Unless otherwise stated, we equip $C_0(X,\MV)$ with the $l^\infty$-norm.
\end{df}


\begin{rem}\label{lb357}
$C_c(X,\mc V)$ is dense in $C_0(X,\mc V)$ under the $l^\infty$-norm.
\end{rem}

\begin{proof}
Choose any $f\in C_0(X,\mc V)$. Then for each $\eps>0$ there exists a compact $K\subset X$ such that $\Vert f\Vert_{l^\infty(K^c)}<\eps$. By Urysohn's lemma, there exists $h\in C_c(X,[0,1])$ such that $h|_K=1$. Then $\Vert hf\Vert_{l^\infty(K^c)}<\eps$, and hence $\Vert f-hf\Vert_{l^\infty(X)}<2\eps$. This finishes the proof, since $hf\in C_c(X,\mc V)$.
\end{proof}


\begin{exe}
Suppose that $\MV$ is complete. Show that $C_0(X,\MV)$ is also complete. 
\end{exe}


\begin{rem}\label{lb84}
Suppose that $X$ is second countable. Then $X$ is Lindel\"of by Prop. \ref{lb220}. Therefore, $X$ has a countable open cover $\fk U=(U_n)_{n\in\Zbb_+}$ whose members $U_n$ are precompact open subsets of $X$. In particular, $X$ is $\sigma$-compact, since $X=\bigcup_{n\in\Zbb_+}\ovl{U_n}$ where each $\ovl{U_n}$ is compact. 

Since any open subset $W\subset X$ is second-countable and is LCH (by Prop. \ref{lb3}), it follows that $W$ is a countable union of precompact open subsets of $W$; in particular, $W$ is $\sigma$-compact.  \hqed
\end{rem}




\subsubsection{Equicontinuity and the Arzel\`a-Ascoli theorem}

Let $X$ be a topological space. Let $V$ be a normed vector space.

\begin{df}
Let $(f_\alpha)_{\alpha\in\scr A}$ be a family of functions $X\rightarrow V$. We say that $(f_\alpha)_{\alpha\in\scr A}$ is \textbf{equicontinuous at \pmb{$x\in X$}} \index{00@Equicontinuity} if for each $\eps>0$ there exists $U_x\in\Nbh_X(x)$ such that
\begin{align}\label{eq93}
\Vert f_\alpha(y)-f_\alpha(x)\Vert\leq\eps\qquad\text{for all }\alpha\in\scr A,y\in U_x
\end{align}
This is equivalent to saying that
\begin{align*}
\lim_{y\rightarrow x}\sup_\alpha\Vert f_\alpha(y)-f_\alpha(x)\Vert=0
\end{align*}
We say that $(f_\alpha)_{\alpha\in\scr A}$ is an \textbf{equicontinuous family of functions} if it is equicontinuous at every point of $X$.
\end{df}


\begin{thm}\label{lb179}
Let $(f_\alpha)_{\alpha\scr A}$ be an equicontinuous net of functions $X\rightarrow V$ converging pointwise to some $f:X\rightarrow V$. Then $f$ is continuous. Moreover, if $X$ is compact, then $(f_\alpha)_{\alpha\scr A}$ converges uniformly to $f$.
\end{thm}

\begin{proof}
For each $x\in X$ and $\eps>0$, choose  $U_x\in\Nbh_X(x)$ such that \eqref{eq93} holds. Applying $\lim_\alpha$, we see that $\Vert f(y)-f(x)\Vert\leq\eps$ for all $y\in U_x$. This proves that $f$ is continuous at every $x\in X$.

Next, assume that $X$ is compact. Then there exist $x_1,\dots,x_n\in X$ such that $X=U_1\cup\cdots\cup U_n$ if we set $U_i=U_{x_i}$. For each $y\in X$, choose $i$ such that $y\in U_i$. Then
\begin{align*}
&\Vert f_\alpha(y)-f(y)\Vert\leq\Vert f_\alpha(y)-f_\alpha(x_i)\Vert+\Vert f_\alpha(x_i)-f(x_i)\Vert+\Vert f(x_i)-f(y)\Vert\\
\leq& 2\eps+\Vert f_\alpha(x_i)-f(x_i)\Vert
\end{align*}
and hence
\begin{align*}
\sup_{y\in X}\Vert f_\alpha(y)-f(y)\Vert\leq 2\eps+\sum_{i=1}^n\Vert f_\alpha(x_i)-f(x_i)\Vert
\end{align*}
Since $f_\alpha$ converges to $f$ at $x_1,\dots,x_n$, we conclude that
\begin{align*}
\limsup_\alpha ~\sup_{y\in X}\Vert f_\alpha(y)-f(y)\Vert\leq 2\eps
\end{align*}
for all $\eps>0$. Hence $\lim_\alpha\sup_{y\in X}\Vert f_\alpha(y)-f(y)\Vert=0$.
\end{proof}

\begin{thm}[\textbf{Arzel\`a-Ascoli theorem}]\index{00@Arzel\`a-Ascoli theorem}
Assume that $X$ is LCH. Let $\scr F$ be an equicontinuous set of functions $X\rightarrow\Fbb$. If $X$ is non-compact, we assume that 
\begin{align}
\lim_{x\rightarrow\infty}\sup_{f\in\scr F}|f(x)|=0
\end{align}
which means that for each $\eps>0$, there exists a compact $K\subset X$ such that
\begin{align*}
|f(x)|\leq\eps\qquad\text{for all }f\in\scr F,x\in X\setminus K
\end{align*}
Assume that $\scr F$ is \textbf{pointwise bounded}, i.e., $\sup_{f\in\scr F}|f(x)|<+\infty$ for each $x\in X$. Then $\scr F$ is precompact in $C_0(X,\Fbb)$ (in the $l^\infty$-norm).
\end{thm}


\begin{proof}
It is easy to check that $\ovl{\scr F}$, the closure of $\scr F$, satisfies the same properties as $\scr F$. Therefore, replacing $\scr F$ with its closure, we assume WLOG that $\scr F$ is closed. 

We first consider the case that $X$ is compact. Since $\scr F$ is pointwise bounded, it can be viewed as a subset of $\prod_{x\in X}D_x$ where $D_x$ is a compact set in $\Fbb$. Therefore, by the Tychonoff Thm. \ref{lb61}, every net $(f_\alpha)$ in $\scr F$ has a pointwise convergent subnet $(f_\beta)$. Since $(f_\beta)$ is equicontinuous and $X$ is compact, by Thm. \ref{lb179}, $(f_\beta)$ converges uniformly to some $f\in C(X,\Fbb)$. Since $\scr F$ is closed, we have $f\in\scr F$. This proves that $\scr F$ is compact.

Next, assume that $X$ is not compact. Let $\wht X=X\cup\{\infty\}$ be the one-point compactification of $X$. Extend each $f\in\scr F$ to $\wht X\rightarrow\Fbb$ by setting $f(0)=0$. Then $\scr F$ is a pointwise bounded and equicontiuous family of functions $\wht X\rightarrow\Cbb$. By the previous paragraph, every net in $\scr F$ has a uniformly convergent subnet. Thus, $\scr F$ is compact.
\end{proof}






\subsection{*-algebras and the Stone-Weierstrass theorem}


Recall that $\Fbb\in\{\Rbb,\Cbb\}$. In this section, we let $\Kbb$ be any subfield of $\Cbb$ closed under complex conjugation, such as $\Rbb,\Cbb,\Qbb,\Qbb+\im\Qbb$.


\begin{df}
A \textbf{$\Kbb$-algebra} \index{00@Algebra}  is defined to be a ring $\scr A$ (not necessarily having $1$) that is also a $\Kbb$-vector space, together with a bilinear map
\begin{align*}
\scr A\times\scr A\rightarrow\scr A\qquad (x,y)\mapsto xy
\end{align*}
satisfying the associacitity rule
\begin{align*}
(xy)z=x(yz)\qquad\text{for all }x,y,z\in \scr A
\end{align*}

A $\Kbb$-algebra is called \textbf{unital} \index{00@Unital algebra} if $\scr A$, as a ring, has a multiplicative identity $1_\SA=1$ (i.e. $1x=x1=1$ for all $x\in\SA$). In this case, we write $\lambda\cdot 1$ as $\lambda$ if $\lambda\in\Kbb$. 

A $\Kbb$-algebra is called \textbf{commutative} or \textbf{abelian} \index{00@Commutative algebra} \index{00@Abelian algebra} if $xy=yx$ for all $x,y\in\scr A$.

If $\scr A$ is a $\Kbb$-algebra, then a \textbf{($\pmb\Kbb$-)subalgebra} \index{00@Subalgebra} is a subset $\scr B$ which is closed under the ring addition, ring multiplication, and scalar multiplication. (Namely, $\scr B$ is a subring and also a linear subspace of $\scr A$.) If $\scr A$ is unital, then a \textbf{unital ($\pmb\Kbb$-)subalgebra} of $\scr A$ is a $\Kbb$-subalgebra containing the identity of $\scr A$.  \hfill\qedsymbol
\end{df}


\begin{comment}
\begin{rem}
A unital $\Kbb$-algebra $\scr A$ can equivalently be described as a ring with identity, together with a ring homomorphism $\Cbb\rightarrow Z(\scr A)$ where $Z(\scr A)$ is the \textbf{center} of $\scr A$, i.e.
\begin{align*}
Z(\scr A)=\{x\in\scr A:xy=yx\text{ for every }y\in\scr A\}
\end{align*}
We leave the verification of this equivalence to the reader.
\end{rem}
\end{comment}




\begin{eg}
If $V$ is a $\Fbb$-vector space, then $\End(V)$, the set of $\Fbb$ linear maps $V\rightarrow V$, is naturally an $\Fbb$-algebra. If $V$ is a normed vector space, then $\fk L(V)$ is an $\Fbb$-algebra.
\end{eg}

\begin{df}\label{lb53}
A \textbf{*-$\pmb\Kbb$-algebra}  \index{00@*-$\Kbb$-algebra} is defined to be a $\Kbb$-algebra together with an \textbf{antilinear map} \index{00@Antilinear map} $*:\scr A\rightarrow\scr A$ sending $x$ to $x^*$ (where ``antilinear'' means that for every $a,b\in\Cbb$ and $x,y\in\scr A$ we have $(ax+by)^*=\ovl ax^*+\ovl by^*$) such that for every $x,y\in\scr A$, we have
\begin{align*}
(x^*)^*=x\qquad (xy)^*=y^*x^*
\end{align*}
Note that $*$ must be bijective. We call $*$ an \textbf{involution}. 
\index{00@Involution} A \textbf{*-$\Kbb$-subalgebra} \index{00@*-$\pmb\Kbb$-subalgebra} $\scr B$ is defined to be a subalgebra satisfying $x\in\scr B$ iff $x^*\in\scr B$. If $\scr A$ is a unital algebra with unit $1_\SA$, we say that $\scr A$ is a \textbf{unital *-$\pmb\Kbb$-algebra} if $\scr A$ is equipped with an involution $*:\scr A\rightarrow\scr A$ such that $\scr A$ is a *-algebra, and that
\begin{align*}
1_\SA^*=1_\SA
\end{align*}
A \textbf{unital *-$\pmb\Kbb$-subalgebra} of $\SA$ is defined to be a $*$-$\Kbb$-subalgebra of $\SA$ containing $1_\SA$.
\end{df}

\begin{cv}
We omit ``$\Kbb$-'' when $\Kbb$ is $\Cbb$. For example, a \textbf{unital *-algebra} means a unital *-$\Cbb$-algebra.
\end{cv}

\begin{eg}
The set $\Rbb[x_\blt]\equiv\Rbb[x_1,\dots,x_N]$ \index{Rx@$\Rbb[x_\blt]$} of real polynomials of $x_1,\dots,x_N$ is a unital *-$\Rbb$-algebra, whose involution $*$ is the identity map.
\end{eg}

\begin{eg}\label{lb300}
The set \index{Cz@$\Cbb[z_\blt,{\ovl z_\blt}]$}
\begin{align*}
\Cbb[z_\blt,\ovl {z_\blt}]\equiv\Cbb[z_1,\ovl{z_1},\dots,z_N,\ovl{z_N}]
\end{align*}
of complex polynomials of the $2N$ mutually-independent (and mutually commuting) variables $z_1,\dots,z_N$ and $\ovl {z_1},\dots,\ovl{z_N}$ is a unital *-algebra. The involution is described by
\begin{align*}
(z_i)^*=\ovl{z_i}\qquad (\ovl{z_i})^*=z_i
\end{align*}
for each $1\leq i\leq N$.
\end{eg}




\begin{eg}
The set of complex $n\times n$ matrices $\Cbb^{n\times n}$ is naturally a unital *-algebra if for every $A\in\Cbb^{n\times n}$ we define $A^*=\ovl A^\tr$, the complex conjugate of the transpose of $A$.
\end{eg}


\begin{comment}
\begin{eg}
Let $X$ be a set. Then $\Kbb^X$ is naturally a unital $\Kbb$-algebra, and $l^\infty(X,\Kbb)$ is its unital $\Kbb$-subalgebra. If $X$ is a topological space, then $C(X,\Kbb)$ is a unital $\Kbb$-subalgebra of $\Kbb^X$. If $X$ is compact, then $C(X,\Kbb)$ is a unital $\Kbb$-subalgebra of $l^\infty(X,\Kbb)$.
\end{eg}
\end{comment}




\begin{eg}\label{lb255}
Let $X$ be a set. Then $\Kbb^X$ is a unital *-algebra if for every $f\in\Kbb^X$ we define \index{f@$f^*(x)=\ovl{f(x)}$}
\begin{align}\label{eq33}
f^*:X\rightarrow\Kbb\qquad \pmb{f^*(x)}=\ovl{f(x)}
\end{align}
and $l^\infty(X,\Kbb)$ is a unital *-$\Kbb$-subalgebras of $\Kbb^X$.

If $f_1,\dots,f_n\in \Kbb^X$, then $\pmb{\Kbb[f_1,\dots,f_n]}$, \index{F@$\Fbb[f_1,\dot,f_n]$} the set of polynomials of $f_1,\dots,f_n$ with coefficients in $\Kbb$, is a unital $\Kbb$-subalgebra of $C(X,\Fbb)$. And $\Kbb[f_1,f_1^*,\dots,f_n,f_n^*]$ is a unital *-$\Kbb$-subalgebra of $C(X,\Kbb)$.  \hqed
\end{eg}


More generally, we have:

\begin{eg}
Let $\scr A$ be a unital $\Kbb$-algebra. Let $\fk S\subset\scr A$. Then \index{FS@$\Fbb\bk{\fk S},\Fbb[\fk S]$}
\begin{align}
\pmb{\Kbb\bk{\fk S}}=\Span_\Kbb\{x_1^{n_1}\cdots x_k^{n_k}:k\in\Zbb_+,x_i\in\fk S,n_i\in\Nbb\}
\end{align}
the set of (possibly non-commutative) polynomials of elements in $\fk S$, is the smallest unital $\Kbb$-subalgebra containing $\fk S$, called the \textbf{unital $\pmb\Kbb$-subalgebra generated by $\fk S$}. \index{00@Subalgebra generated by...} (Here, we understand $x^0=1$ if $x\in\scr A$.) Thus, if $\scr A$ is an abelian unital *-algebra, then $\Cbb\bk{\fk S\cup\fk S^*}$ (where $\fk S^*=\{x^*:x\in\fk S\}$) is the smallest unital *-algebra containing $\fk S$, called the \textbf{unital *-$\pmb\Kbb$-subalgebra generated by $\fk S$}. 

If $\SA$ is commutative, we write $\Kbb\bk{\fk S}$ as $\pmb{\Kbb[\fk S]}$. \hqed
\end{eg}



\begin{df}
Let $X$ be a set. Let $(f_\alpha)_{\alpha\in\fk A}$ be a family of maps where $f_\alpha:X\rightarrow Y_\alpha$ and each $Y_\alpha$ is a set.  We say that $(f_\alpha)_{\alpha\in\fk A}$ \textbf{separates the points of $\pmb X$} \index{00@Seperate points} if for any distinct $x_1,x_2\in X$ there exists $\alpha\in\fk A$ such that $f_\alpha(x_1)\neq f_\alpha(x_2)$. This is equivalent to saying that the map
\begin{gather}
\bigvee_{\alpha\in\fk A}f_\alpha:X\rightarrow \prod_{\alpha\in\fk A}Y_\alpha\qquad x\mapsto (f_\alpha(x))_{\alpha\in\fk A}
\end{gather}
is injective.
\end{df}


\begin{eg}\label{lb58}
Let $X$ be an LCH space. Then $C_c(X,[0,1])$ separates the points of $X$.
\end{eg}

\begin{proof}
Choose any distinct points $x,y\in X$. By Urysohn's lemma (Rem. \ref{lb57}), there exists $f\in C_c(X,[0,1])$ such that $f(x)=1$ and $\Supp(f)\subset X\setminus\{y\}$. So $f$ separates $x$ and $y$.
\end{proof}

\begin{thm}[\textbf{Stone-Weierstrass theorem}]\index{00@Stone-Weierstrass}\label{lb87}
Let $X$ be a compact Hausdorff space. Suppose that $\fk S\subset C(X,\Fbb)$ contains $1_X$. Suppose that $\fk S$ separates the points of $X$. Then the (unital) *-$\Fbb$-subalgebra $\Fbb[\fk S\cup\fk S^*]$ generated by $\fk S$ is dense in $C(X,\Fbb)$ in the $l^\infty$-norm.
\end{thm}

Note that if $\Fbb=\Rbb$, then $\fk S^*=\fk S$ by \eqref{eq33}.

If $\Fbb=\Cbb$, then since $(\Qbb+\im\Qbb)[\fk S\cup\fk S^*]$ is $l^\infty$-dense in $\Cbb[\fk S\cup\fk S^*]$, it follows that $(\Qbb+\im\Qbb)[\fk S\cup\fk S^*]$ is $l^\infty$-dense in $C(X)$. Similarly, if $\Fbb=\Rbb$, then $\Qbb[\fk S]$ is $l^\infty$-dense in $C(X,\Rbb)$.

\begin{proof}
See \cite[Ch. 15]{Gui-A}.
\end{proof}


\begin{thm}[\textbf{Stone-Weierstrass theorem}]\label{lb360}
Let $X$ be an LCH space. Let $\fk S\subset C_0(X,\Fbb)$. Suppose that the following conditions are satisfied:
\begin{itemize}
\item[(1)] $\fk S$ separates the points of $X$.
\item[(2)] $\fk S$ vanishes nowhere, that is, for each $x\in X$ there exists $f\in\fk S$ such that $f(x)\neq0$.
\end{itemize}
Then the *-$\Fbb$-subalgebra $\Fbb[\fk S\cup\fk S^*]$ generated by $\fk S$ is dense in $C_c(X,\Fbb)$ in the $l^\infty$-norm.
\end{thm}


\begin{proof}
Let $\wht X=X\cup\{\infty\}$ be the one-point compactification of $X$. Extend each $f\in C_c(X,\Fbb)$ to $\wtd f\in C(\wht X,\Fbb)$ by setting $f(\infty)=0$. By (1) and (2), the set $\wht{\fk S}=\{\wtd f:f\in C_c(X,\Fbb)\}\sqcup\{1_{\wht X}\}$ separates the points of $\wht X$. (In particular, condition (2) guarantees that $\wht{\fk S}$ separates $\infty$ from any point of $X$.) By Thm. \ref{lb87}, $\Fbb[\wht{\fk S}\cup\wht{\fk S}^*]$ is dense in $C(\wht X,\Fbb)$. This implies that $\Fbb[\fk S\cup\fk S^*]$ is dense in $C_c(X,\Fbb)$.
\end{proof}



The following application of the Stone-Weierstrass theorem will be used in the study of weak-* topology, particularly in the proof of Thm. \ref{lb76}. Recall that $C(X,\Fbb)$ is equipped with the $l^\infty$-norm.

\begin{thm}\label{lb75}
Let $X$ be a compact Hausdorff space. Then the following are equivalent:
\begin{enumerate}[label=(\alph*)]
\item $X$ is metrizable.
\item $X$ is second countable.
\item There is a sequence $(f_n)_{n\in\Zbb_+}$ in $C(X,\Fbb)$ separating the points of $X$.
\item $C(X,\Fbb)$ is separable.
\end{enumerate}
\end{thm}

\begin{comment}
Moreover, if (c) is satisfied, then for each $R\in\Rbb_{>0}$, a compatible metric $d$ on $X$ can be chosen to be
\begin{gather}\label{eq34}
d(x,y)=\sum_{n\in\Zbb_+}2^{-n}\min\{|f_n(x)-f_n(y)|,R\}\qquad\text{for each }x,y\in X
\end{gather}


In particular, if (c) is satisfied and $\sup_{n\in\Zbb_+}\Vert f_n\Vert_{l^\infty}<+\infty$, we can choose $R=2\sup_{n\in\Zbb_+}\Vert f_n\Vert_{l^\infty}$. Then \eqref{eq34} becomes
\begin{gather}\label{eq35}
d(x,y)=\sum_{n\in\Zbb_+}2^{-n}|f_n(x)-f_n(y)|\qquad\text{for each }x,y\in X
\end{gather}
\end{comment}




The Stone-Weierstrass theorem will be used in the direction (c)$\Rightarrow$(d). The equivalence of (a), (b), and (c) does not rely on the Stone-Weierstrass theorem. In this course, we will mainly use the equivalence of (b), (c), and (d).

\begin{proof}
(a)$\Rightarrow$(b): Fix a metric on $X$. By the compactness, for each $n\in\Zbb_+$, $X$ is covered by finitely many open balls with radius $1/n$. One checks easily that the collection of all these open balls for all $n\in\Zbb_+$ is a countable basis of the topology of $X$.\\[-1ex]

(b)$\Rightarrow$(c): Since $X$ is second countable, we can choose an infinite countable base $(U_n)_{n\in\Zbb}$ of the topology. For each $m,n\in\Zbb_+$, if $U_n\Subset U_m$, we choose $f_{m,n}\in C_c(U_m,[0,1])\subset C_c(X,[0,1])$ such that $f|_{\ovl {U_n}}=1$ (which exists by Urysohn's lemma); otherwise, we let $f_{m,n}=0$. 

Let us prove that $\{f_{m,n}:m,n\in\Zbb_+\}$ separates the points of $X$: Choose distinct $x,y\in X$. Since $X\setminus\{y\}\in\Nbh_X(x)$, there exists $U_m$ containing $x$ and is contained in $X\setminus\{y\}$. By Cor. \ref{lb54}, there exists $n$ such that $\{x\}\subset U_n\Subset U_m$. Then $f_{m,n}(x)=1$ and $f_{m,n}(y)=0$.\\[-1ex]

(c)$\Rightarrow$(a,b): Since $(f_n)$ separates points, the map
\begin{gather*}
\Phi=\bigvee_{n\in\Zbb_+} f_n:X\rightarrow\Fbb^{\Zbb_+}\qquad x\mapsto (f_n(x))_{n\in\Zbb_+}
\end{gather*}
is injective. By Cor. \ref{lb55}, $\Phi$ is continuous. Since $X$ is compact, the map $\Phi$ restricts to a homeomorphism $\Phi:X\rightarrow\Phi(X)$, where $\Phi(X)$ is equipped with the subspace topology of the product topology of $\Fbb^{\Zbb_+}$. By Prop. \ref{lb51}, $\Fbb^{\Zbb_+}$ is metrizable and second countable, so $\Phi(X)$, and hence $X$, is metrizable and second countable. This proves (a) and (b).\\[-1ex]

%By \eqref{eq32}, the product topology of $\Fbb^{\Zbb_+}$ is induced by the metric
%\begin{align*}
%\delta(u,v)=\sum_{n\in\Zbb_+}2^{-n}\min\{|u(n)-v(n)|,R\}\qquad\text{for each }u,v\in\Fbb^{\Zbb_+}
%\end{align*}
%Therefore, the pullback metric $\Phi^*\delta$ on $X$ (defined by $\Phi^*\delta(x,y)=\delta(\Phi(x),\Phi(y))$) induces the topology of $X$. Clearly $\Phi^*\delta(x,y)$ equals \eqref{eq34}. 

(c)$\Rightarrow$(d): Let $\Kbb=\Fbb\cap(\Qbb+\im\Qbb)$. By Stone-Weierstrass, the countable set $\Kbb[\{f_n:n\in\Zbb_+\}]$ is dense in $C(X,\Fbb)$. Thus $C(X,\Fbb)$ is separable.\\[-1ex]

(d)$\Rightarrow$(c): By Exp. \ref{lb58}, $C(X,\Fbb)$ separates the points of $X$. Therefore, any dense subset of $C(X,\Fbb)$ separates the points of $X$. Since $C(X,\Fbb)$ is separable, it has a countable dense subset separating the points of $X$.
\end{proof}







\subsection{Review of measure theory: general facts}

Recall the following basic property:

\begin{pp}\label{lb310}
Let $(X,\mu)$ be a measure space, and let $f:X\rightarrow[0,+\infty]$ be measurable. Then $\int_Xfd\mu=0$ iff $f=0$ $\mu$-a.e..
\end{pp}




\subsubsection{Some useful definitions and their basic properties}

\begin{df}
Let $X$ be a set. Let $\Kbb\in\{\Rbb_{\geq0},\Rbb,\Cbb\}$. Suppose that $\scr C$ is an $\Kbb$-linear subspace of $\Kbb^X$. A \textbf{positive linear functional} \index{00@Positive linear functional} on $\scr C$ denotes an $\Kbb$-linear map $\Lambda:\scr C\rightarrow\Kbb$ such that $\Lambda(f)\geq0$ for all $f\in\scr C\cap \Rbb_{\geq0}^X$. Note that this condition is redundant when $\Kbb=\Rbb_{\geq0}$.
\end{df}

Recall that if $(X,\fk M)$ is a measurable space, an \textbf{\pmb{$\Fbb$}-valued simple function} on $X$ \index{00@Simple function} is an $\Fbb$-linear combination of characteristic functions over measurable sets; that is, an element of $\Span_\Fbb\{\chi_E:E\in\fk M\}$.


\begin{df}\label{lb98}
Let $X$ be a set. Let $x\in X$. The \textbf{Dirac measure \pmb{$\delta_x$}} \index{00@Diract measure} \index{zz@$\delta_x$, the Dirac measure at $x$} of $x$ is defined to be the measure $\delta_x:2^X\rightarrow\ovl\Rbb_{\geq0}$ satisfying $\delta_x(A)=1$ if $x\in A$, and $\delta_x(A)=0$ if $x\notin A$.
\end{df}


\begin{df}\label{lb298}
Let $(X,\mc T_X)$ be a topological space. Let $\fk M\subset 2^X$ be a $\sigma$-algebra containing the Borel $\sigma$-algebra $\fk B_X$. Let $\mu:\fk M\rightarrow\ovl\Rbb_{\geq0}$ be a measure. Assume that one of the following conditions holds:
\begin{enumerate}[label=(\arabic*)]
\item $X$ is second countable.
\item $X$ is LCH, and $\mu|_{\fk B_X}$ is a Radon measure.
\end{enumerate}
The \textbf{support \pmb{$\Supp(\mu)$}} \index{00@Support of a measure} \index{Supp@$\Supp(\mu)$} is defined to be
\begin{align*}
\Supp(\mu)=\{x\in X:\mu(U)>0\text{ for each }U\in\Nbh_X(x)\}
\end{align*}
Then $\Supp(\mu)$ is a closed subset of $X$, because we clearly have
\begin{align*}
X\setminus\Supp(\mu)=\bigcup_{U\in\mc T_X,\mu(U)=0}U
\end{align*}
Moreover, we have $\mu(X\setminus\Supp(\mu))=0$. Thus, $\Supp(\mu)$ is the smallest closed subset whose complement is $\mu$-null.
\end{df}

\begin{proof}[Proof that $X\setminus\Supp(\mu)$ is null]
It suffices to show that if a family of open subsets $(U_\alpha)_{\alpha\in\scr A}$ is null, then the union $U:=\bigcup_\alpha U_\alpha$ is null. 

Assume that condition (1) holds. Since any subset of a second countable space is second countable and hence Lindel\"of, the set $U$ is Lindel\"of. So $(U_\alpha)$ has a countable subfamily covering $U$. Therefore, by the countable additivity, $U$ is null. 

Assume that condition (2) holds. Since Radon measures are inner regular on open sets (cf. Def. \ref{lb97}), $\mu(U)$ is the supremum of $\mu(K)$ where $K$ runs through all compact subsets of $U$. Since $K$ is compact,  $(U_\alpha)$ has a finite subfamily covering $K$. Therefore $K$ is null, and hence $U$ is null.
\end{proof}


\begin{lm}\label{lb163}
Let $\mu:\fk M\rightarrow\ovl\Rbb_{\geq0}$ be as in Def. \ref{lb298}, and assume that Condition (1) or (2) of Def. \ref{lb298} holds. The following are equivalent:
\begin{enumerate}[label=(\alph*)]
\item $\Supp(\mu)$ is a finite set.
\item $\mu$ is a linear combination of Dirac measures (restricted to $\fk M$).
\end{enumerate}
\end{lm}

\begin{proof}
(b)$\Rightarrow$(a): This is obvious.

(a)$\Rightarrow$(b): Write $E=\Supp(\mu)$. Choose any measurable $f:X\rightarrow\ovl\Rbb_{\geq0}$. Then, since $\mu|_{X\setminus E}=0$, the integral of any measurable function $g:X\rightarrow\ovl\Rbb_{\geq0}$ vanishing ourside $E$ is zero. In particular, we can choose $g$ to be the unique one such that $g+\sum_{x\in E}f(x)\chi_{\{x\}}=f$. Therefore
\begin{align*}
\int_Xfd\mu=\int_X \sum_{x\in E}f(x)\chi_{\{x\}}d\mu=\sum_{x\in E}f(x)\cdot \mu(\{x\})
\end{align*}
This shows that $\mu=\sum_{x\in E}\mu(\{x\})\delta_x$.
\end{proof}




\begin{df}\label{lb319}
Let $\Phi:(X,\fk M)\rightarrow (Y,\fk N)$ be a measurable map between two measurable spaces. Let $\mu$ be a measure on $\fk M$. The \textbf{pushforward measure} \index{00@Pushforward measure $\Phi_*\mu$} of \index{zz@$\Phi_*\mu$, the pushforward measure of $\mu$ by $\Phi$} $\mu$ by $\Phi$ is defined to be
\begin{align}
\Phi_*\mu:\fk N\rightarrow[0,+\infty]\qquad B\mapsto \mu(\Phi^{-1}(B))
\end{align} 
Then
\begin{align}
\int_Yfd\Phi_*\mu=\int_X(f\circ\Phi)d\mu
\end{align}
holds for any simple function $f:X\rightarrow\Rbb_{\geq0}$, and hence (by MCT) for any measurable $f:X\rightarrow\ovl{\Rbb}_{\geq0}$. If $Y$ is a topological space and $\fk N$ contains $\fk B_Y$, we call
\begin{align*}
\pmb{\Ess(\Phi,\mu)}:=\Supp(\Phi_*\mu)
\end{align*}
the \textbf{essential range} of $\Phi$ with respect to $\mu$ \index{00@Essential range $\Ess(\Phi,\mu)=\Ess(\Phi)$} and \index{Rngess@$\Ess(\Phi,\mu)=\Ess(\Phi)$} abbreviate it to $\Ess(\Phi)$ when no confusion arises.
\end{df}


\begin{rem}
Let $(X,\mu)$ be a measure space, and let $f:X\rightarrow\Cbb$ be measurable. It is a standard fact that
\begin{align*}
\Vert f\Vert_{l^\infty(X,\mu)}=\sup\{|z|:z\in\Ess(f,\mu)\}
\end{align*}
\end{rem}


\begin{df}\label{lb431}
Let $(X,\fk M)$ and $(Y,\fk N)$ be measurable spaces. A bijection $f:X\rightarrow Y$ such that both $f$ and $f^{-1}$ are measurable is called a \textbf{measurable isomorphism}. \index{00@Measurable isomorphism} If $X,Y$ are topological spaces and $\fk M=\fk B_X,\fk N=\fk B_Y$, a measurable isomorphism is called a \textbf{Borel isomorphism}. \index{00@Borel isomorphisms}

If $f:X\rightarrow Y$ is a measurable bijection and $\nu:Y\rightarrow[0,+\infty]$ is a measure, then \index{zz@$\Phi^*\nu$, the pullback measure}
\begin{align*}
\pmb{\Phi^*\nu}=(\Phi^{-1})_*\nu
\end{align*}
is called the \textbf{pullback measure} \index{00@Pullback measure} of $\nu$ by $\Phi$. It can be equivalently described by
\begin{align}\label{eq224}
\int_Yfd\nu=\int_X(f\circ\Phi)d\Phi^*\mu
\end{align}
for each $f:X\rightarrow\ovl{\Rbb}_{\geq0}$.  \hqed
\end{df}



\subsubsection{Radon-Nikodym derivatives}

Fix a measurable space $(X,\fk M)$. 

\begin{df}
Let $\mu,\nu:\fk M\rightarrow[0,+\infty]$ be measures. We say that $\nu$ is \textbf{absolutely continuous} with respect to $\mu$ \index{00@Absolute continuity of measures} and write $\pmb{\nu\ll\mu}$ \index{zz@$\nu\ll\mu$} if any $\mu$-null set is $\nu$-null. We say that $h\in\mc L(X,\ovl\Rbb_{\geq0})$ is a \textbf{Radon-Nikodym derivative} of $\nu$ with respect to $\mu$ if 
\begin{align*}
\int_X fd\nu=\int_X fhd\mu\quad \text{ for all }f\in\mc L(X,\ovl\Rbb_{\geq0})
\end{align*}
By MCT, the above condition is equivalent to
\begin{align*}
\nu(E)=\int_E hd\mu\qquad\text{ for all }E\in\fk M
\end{align*}
We write $\pmb{d\nu=hd\mu}$.
\end{df}

\begin{rem}
If $\mu$ is $\sigma$-finite, and if $h_1,h_2$ are both Radon-Nikodym derivatives of $\nu$ with respect to $\mu$, then $h_1(x)=h_2(x)$ for $\mu$-a.e. $x\in X$.
\end{rem}


\begin{proof}
It suffices to assume that $\mu(X)<+\infty$. For each $k\in\Nbb$, let
\begin{align*}
A_k=\{x\in X:h_1(x)<h_2(x)\text{ and }h_1(x)\leq k\}
\end{align*}
Then $\int_{A_k} h_1d\mu\leq k\mu(X)<+\infty$, and
\begin{align*}
\int_{A_k} h_1d\mu=\int_{A_k} d\nu=\int_{A_k}h_2d\mu
\end{align*}
Taking subtraction, we get $\int_{A_k}(h_2-h_1)d\mu=0$. Let $A=\bigcup_k A_k=\{x\in X:h_1(x)<h_2(x)\}$. By MCT,  $\int_A(h_2-h_1)d\mu=0$. Since $h_2-h_1\geq0$ on $A$, we conclude from Prop. \ref{lb310} that $h_2-h_1=0$ $\mu$-a.e. on $A$, and hence $\mu(A)=0$. Similarly, $\mu(B)=0$ where $B=\{x\in X:h_1(x)>h_2(x)\}$.
\end{proof}

\begin{rem}
If $\nu$ is $\sigma$-finite, and if $d\nu=hd\mu$, then $h(x)<+\infty$ for $\mu$-a.e. $x\in X$. 
\end{rem}

\begin{proof}
Let $A=\{x\in A:h(x)=+\infty\}$. Since $\nu$ is $\sigma$-finite, we can write $A=\bigcup_{k\in\Nbb}A_k$ where $A_k\in\fk M$ and $\nu(A_k)<+\infty$. Since $\nu(A_k)=\int_{A_k}hd\mu=+\infty \mu(A_k)$, we have $\mu(A_k)=0$, and hence $\mu(A)=0$.
\end{proof}





\begin{thm}[\textbf{Radon-Nikodym theorem}]\label{lb27} \index{00@Radon-Nikodym theorem}
Assume that $\mu,\nu:\fk M\rightarrow[0,+\infty]$ are $\sigma$-finite measures. Then $\nu\ll\mu$ iff $\nu$ has a Radon-Nikodym derivative with respect to $\mu$.
\end{thm}


\begin{proof}[Proof]
``$\Leftarrow$'' is obvious. Let us prove ``$\Rightarrow$''. It is easy to reduce to the case that $\mu(X),\nu(X)<+\infty$. Let $d\psi=d\mu+d\nu$. So $\mu,\nu\leq\psi$. Therefore, the linear functional
\begin{gather*}
\Lambda: L^2(X,\psi)\rightarrow\Cbb\qquad \xi\mapsto \int_X \xi d\mu
\end{gather*}
is bounded (with operator norm $\leq\psi(X)$). Since $L^2(X,\psi)$ is a Hilbert space (Thm. \ref{lb26}), by the Riesz-Fr\'echet Thm. \ref{lb135}, there exists $f\in L^2(X,\psi)$ such that $\int_X\xi d\mu=\int_X \xi fd\psi$ for all $\xi\in L^2(X,\psi)$. Since $\Lambda$ sends positive functions to $\Rbb_{\geq0}$, after replacing $f$ with $\Real(f)$ and adding a measurable $\psi$-a.e. zero function to $f$, we have $f\geq0$ everywhere.


We have found $f\in\mc L(X,\Rbb_{\geq0})$ such that $d\mu=fd\psi$. Similarly, we have $g\in\mc L(X,\Rbb_{\geq0})$ such that $d\nu=gd\psi$.  Since $\mu\leq\psi \ll \mu$, we have $f>0$ outside a $\psi$-null set $\Delta$. Let $h=g/f$ outside $\Delta$, and $h=0$ on $\Delta$. Then $d\nu=hd\mu$. 
\end{proof}












\subsubsection{$L^p$-spaces}


Let $(X,\fk M,\mu)$ be a measure space. Let $1\leq p,q\leq +\infty$ such that $p^{-1}+q^{-1}=1$.

\begin{thm}\label{lb79}
Let $1\leq p<+\infty$. Then the set of integrable $\Fbb$-valued simple functions is dense in $L^p(X,\mu,\Fbb)$. In other words,
\begin{align*}
\{\chi_E:E\subset\fk M,\mu(E)<+\infty\}
\end{align*}
spans a dense subspace of $L^p(X,\mu,\Fbb)$.
\end{thm}

\begin{proof}
See \cite[Sec. 27.2]{Gui-A}.
\end{proof}


\begin{thm}[\textbf{Riesz-Fischer theorem}, the modern form]\index{00@Riesz-Fischer theorem, the modern form}\label{lb26}
The normed vector space $L^p(X,\mu,\Fbb)$ is (Cauchy) complete. Moreover, if $(f_n)$ is a sequence in $L^p(X,\mu,\Fbb)$ converging (in $L^p$) to $f\in L^p(X,\mu,\Fbb)$, then $(f_n)$ has a subsequence converging $\mu$-a.e. to $f$.
\end{thm}



\begin{proof}
See \cite[Sec. 27.3]{Gui-A}.
\end{proof}


\begin{lm}\label{lb28}
Assume that $(X,\mu)$ is $\sigma$-finite. Let $\mc S_+$ be the set of simple functions $X\rightarrow\Rbb_{\geq0}$. Then for each $f\in\mc L(X,\ovl\Rbb_{\geq0})$ we have
\begin{align}\label{eq15}
\Vert f\Vert_{L^p(X,\mu)}=\sup\Big\{\int_X fgd\mu:g\in\mc S_+, \Vert g\Vert_{L^q(X,\mu)}\leq 1 \Big\}
\end{align}
Consequently, for each $f\in\mc L(X,\Cbb)$ we have
\begin{align}\label{eq16}
\Vert f\Vert_{L^p(X,\mu)}=\sup\Big\{\int_X |fg|:g\in L^q(X,\mu), \Vert g\Vert_q\leq 1 \Big\}
\end{align}
\end{lm}



\begin{proof}
By H\"older's inequality, we have ``$\geq$''.  To prove ``$\leq$'', we note that \eqref{eq16} follows immediately from \eqref{eq15} by writing $f=u|f|$ where $u\in\mc L(X,\Sbb^1)$ and applying \eqref{eq15} to $|f|$. Thus, in the following, we assume $f\in\mc L(X,\ovl\Rbb_{\geq0})$. Moreover, we assume $\Vert f\Vert_{L^p}>0$; otherwise, the inequality is trivial.

Case $1<p<+\infty$: Choose an increasing sequence $(f_n)$ (i.e. $f_1\leq f_2\leq\cdots$) in $\mc S_+$ converging pointwise to $f$ such that each $f_n$ vanishes outside a measurable $\mu$-finite set. Let $g_n=(f_n)^{p-1}$. After removing the first several terms, we assume $\Vert g_n\Vert_{L^q}>0$ for all $n$. Then
\begin{align*}
0<\Vert g_n\Vert_q=\Vert f_n\Vert_p^{p/q}<+\infty
\end{align*}
By MCT, we have $\lim_n \Vert g_n\Vert_p=\Vert f\Vert_p^{p/q}$ and $\lim_n \int_X fg_n=\Vert f\Vert_p^p$. Thus, if $\Vert f\Vert_p<+\infty$, then
\begin{align*}
\lim_n\Vert g_n\Vert_q^{-1}\int_X fg_n=\Vert f\Vert_p^{-p/q}\cdot \Vert f\Vert_p^p=\Vert f\Vert_p
\end{align*}
This proves \eqref{eq15} when $\Vert f\Vert_p<+\infty$. If $\Vert f\Vert_p=+\infty$, then, by MCT, $\Vert f_n\Vert_p<+\infty$ can be sufficiently large. Applying \eqref{eq15} to $f_n$ instead of $f$, we obtain $g\in\mc S_+$ such that $\Vert g\Vert_q\leq 1$ and $\int f_ng$ is sufficiently large, and hence $\int fg$ is sufficiently large. Thus \eqref{eq15} holds again.

Case $p=1$: Let $g=1$.

Case $p=+\infty$: Write $X=\bigcup_{n\in\Nbb} \Omega_n$ where $\Omega_n\in\fk M$ and $\mu(\Omega_n)<+\infty$. Choose any $0\leq\lambda<\Vert f\Vert_\infty$. Then $A:=\{f>\lambda\}$ satisfies $\mu(A)>0$. Thus, there exists $n$ such that $0<\mu(A\cap\Omega_n)<+\infty$. Let $g=\chi_{A\cap\Omega_n}/\mu(A\cap\Omega_n)$. Then $g\in\mc S_+$, $\Vert g\Vert_1=1$, and $\int fg\geq\lambda$. This proves \eqref{eq15}.
\end{proof}















\begin{thm}\label{lb13}
Assume that $(X,\mu)$ is $\sigma$-finite. Assume $1<p\leq+\infty$. Then we have an isomorphism of normed vector spaces
\begin{gather}\label{eq31}
\Psi: L^p(X,\mu,\Fbb)\rightarrow L^q(X,\mu,\Fbb)^*\qquad f\mapsto \Big(g\in L^q(X,\mu,\Fbb)\mapsto \int_Xfgd\mu \Big)
\end{gather}
\end{thm}


When $p<+\infty$, the assumption on $\sigma$-finiteness can be removed. See \cite[Sec. 6.2]{Fol-R}. When $p=2$, this is simply due to the completeness of $L^2(X,\mu,\Fbb)$ and the Riesz-Fr\'echet theorem.

\begin{proof}[Proof]
By H\"older's inequality and Lem. \ref{lb28}, $\Psi$ is an isometry. Let us show that any $\Lambda\in L^q(X,\mu,\Fbb)^*$ belongs to the range of $\Psi$. \\[-1ex]


Step 1. By considering the real and imaginary parts
\begin{gather*}
(\Real\Lambda)(f)=\frac{\Lambda(f)+\ovl{\Lambda(\ovl f)}}{2}\qquad (\Imag\Lambda)(f)=\frac{\Lambda(f)-\ovl{\Lambda(\ovl f)}}{2\im}
\end{gather*}
separately, we can assume that $\Lambda$ is real, i.e., $\Lambda(f)\in\Rbb$ for any $f\in L^q(X,\mu,\Rbb_{\geq0})$. 

Let us define $\Rbb_{\geq0}$-linear maps $\Lambda^+,\Lambda^-:L^q(X,\mu,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ with operator norms $\leq \Vert\Lambda\Vert$, i.e.,
\begin{align}\label{eq18}
\Vert\Lambda^\pm(g)\Vert\leq\Vert\Lambda\Vert\cdot\Vert g\Vert_q\qquad\text{for all }g\in L^q(X,\mu,\Rbb_{\geq0})
\end{align}
and let us check that 
\begin{align}\label{eq19}
\Lambda(g)=\Lambda^+(g)-\Lambda^-(g)\qquad\text{for all }g\in L^q(X,\mu,\Rbb_{\geq0})
\end{align}
Eq. \eqref{eq19} is called the \textbf{Jordan decomposition} of $\Lambda$.

Define the  $\Lambda^\pm:L^q(X,\mu,\Rbb_{\geq0})\rightarrow \ovl\Rbb$ by sending each $g\in L^q(X,\mu,\Rbb_{\geq0})$ to
\begin{gather}\label{eq17}
\Lambda^\pm(g)=\sup\{\pm\Lambda (h):h\in L^q(X,\mu,\Rbb_{\geq0}),h\leq g\}
\end{gather}
Since $0\leq g$, we clearly have $\Lambda^+(g)\geq0$. Since $\Lambda$ is bounded and $\Vert h\Vert_q\leq\Vert g\Vert_q$, we clearly have $\Vert\Lambda^+(g)\Vert\leq \Vert\Lambda\Vert\cdot\Vert g\Vert_q$. In particular, $\Lambda^+$ has range in $\Rbb_{\geq0}$. Since $\Lambda^\pm=(-\Lambda)^\mp$, a similar property holds for $\Lambda^-$. Thus, we have checked \eqref{eq18}.

Clearly, for each $f,g\in L^q(X,\mu,\Rbb_{\geq0})$, we have $\Lambda^+(f+g)\geq\Lambda^+(f)+\Lambda^+(g)$. To prove the other direction, choose any $h\in L^q(X,\mu,\Rbb_{\geq0})$ such that $h\leq f+g$. Let $h_1=fh/(f+g)$ and $h_2=gh/(f+g)$, understood to be zero where the denominator vanishes. Then $h_1,h_2\in L^q(X,\mu,\Rbb_{\geq0})$ and $h_1\leq f$ and $h_2\leq g$. This proves $\Lambda^+(f+g)\leq\Lambda^+(f)+\Lambda^+(g)$. Thus $\Lambda^+$ (and similarly $\Lambda^-$) is $\Rbb_{\geq0}$-linear.

From \eqref{eq17}, one easily checks $\Lambda(g)+\Lambda^-(g)\leq\Lambda^+(g)$ for each $g\in L^q(X,\mu,\Rbb_{\geq0})$. Replacing $\Lambda$ with $-\Lambda$, we get $-\Lambda(g)+\Lambda^+(g)\leq \Lambda^-(g)$. Thus \eqref{eq19} holds.\\[-1ex]




Step 2. Let us prove that $\Lambda^+$ is represented by some $f^+\in L^p(X,\mu,\Rbb_{\geq0})$, namely,
\begin{align}\label{eq21}
\Lambda^+(g)=\int_X f^+gd\mu\qquad\text{for all }g\in L^q(X,\mu,\Rbb_{\geq0})
\end{align}
Then, similarly, $\Lambda^-$ is represented by some $f^-\in L^p(X,\mu,\Rbb_{\geq0})$. Thus $\Lambda$ is represented by $f^+-f^-$, finishing the proof.

Write $X=\bigsqcup_n X_n$ where $\mu(X_n)<+\infty$. Suppose that we can find $f_n^+\in L^p(X_n,\mu)$ representing $\Lambda^+|_{L^q(X_n,\mu)}$, then we can define $f^+:X\rightarrow\Rbb_{\geq0}$ such that $f^+|_{X_n}=f_n$ for all $n$. Clearly $f^+$ represents $\Lambda^+$. In particular, by Lem. \ref{lb28} and \eqref{eq18}, $\Vert f^+\Vert_p\leq\Vert\Lambda\Vert<+\infty$. Thus $f\in L^p(X,\mu)$.


Therefore, according to the previous paragraph, we may assume at the beginning that $\mu(X)<+\infty$. Define
\begin{align*}
\nu:\fk M\rightarrow[0,+\infty]\qquad E\mapsto \Lambda(\chi_E)
\end{align*}
Then one checks easily that $\nu$ is a measure,\footnote{To check the countable additivity, we let $E_1\subset E_2\subset\cdots$ be measurable and $E=\bigcup_n E_n$. Let $F_n=E\setminus E_n$. By \eqref{eq18}, $\nu(F_n)\leq\Vert\Lambda\Vert\mu(F_n)^{\frac 1q}\rightarrow0$. Thus $\nu(E_n)\rightarrow\nu(E)$.} and that $\nu\ll\mu$. Therefore, by the Radon-Nikodym Thm. \ref{lb27}, there exists $f^+\in\mc L(X,\Rbb_{\geq0})$ such that $d\nu=f^+d\mu$. Thus
\begin{align}\label{eq20}
\Lambda^+(g)=\int_X gd\nu=\int_X f^+gd\mu\quad\text{for each simple function $g\in L^q(X,\mu,\Rbb_{\geq0})$}
\end{align}
Lem. \ref{lb28} and \eqref{eq18} then imply $\Vert f^+\Vert_p\leq \Vert\Lambda\Vert<+\infty$, and hence $f\in L^p(X,\mu,\Rbb_{\geq0})$. 

Finally, for $g\in L^q(X,\mu,\Rbb_{\geq0})$, find an increasing sequence of simple functions $g_n\in L^q(X,\mu,\Rbb_{\geq0})$ converging pointwise to $g$. By \eqref{eq18}, $\Lambda^+(g-g_n)\leq \Vert\Lambda\Vert\cdot\Vert g-g_n\Vert_q$ where the RHS converges to zero by DCT. By MCT, $\int_Xf^+g_nd\mu\rightarrow\int_X f^+gd\mu$. Thus, by \eqref{eq20}, we conclude \eqref{eq21}.
\end{proof}






\subsection{Review of measure theory: Radon measures}



\subsubsection{Radon measures and the Riesz-Markov representation theorem}

Let $X$ be LCH. The reference for this subsection is \cite[Ch. 25]{Gui-A}.

\begin{df}
Let $\fk M\subset 2^X$ be a $\sigma$ algebra containing $\fk B_X$, and let $\mu:\fk M\rightarrow\ovl\Rbb_{\geq0}$ be a measure. Let $E\in\fk M$. We say that $\mu$ is \textbf{outer regular}\index{00@Outer and inner regularity of measures} on $E$ if
\begin{align*}
\mu(E)=\inf\{\mu(U):U\supset E,U\text{ is open}\}
\end{align*}
We say that $\mu$ is \textbf{inner regular} on $E$ if
\begin{align*}
\mu(E)=\sup\{\mu(K):K\subset E,K\text{ is compact}\}
\end{align*}
We say that $\mu$ is \textbf{regular} on $E$ if $\mu$ is both outer and inner regular on $E$.
\end{df}




\begin{lm}\label{lb4}
Let $\mu:\fk B_X\rightarrow\ovl\Rbb_{\geq0}$ be a Borel measure. Let $U\subset X$ be open. Then
\begin{align*}
\sup\big\{\mu(K):K\subset U,K\text{ is compact}\big\}=\sup\Big\{\int_Xfd\mu:f\in C_c(U,[0,1])  \Big\}
\end{align*}
Therefore, $\mu$ is inner regular on $U$ iff
\begin{align*}
\mu(U)=\sup\Big\{\int_Xfd\mu:f\in C_c(U,[0,1])  \Big\}
\end{align*}
\end{lm}


\begin{proof}
Let $A,B$ denote the LHS and the RHS. If $f\in C_c(U,[0,1])$, then setting $K=\Supp(f)$, we have $\mu(K)=\int_X\chi_Kd\mu\geq\int_X fd\mu$. This proves $A\geq B$.

Conversely, let $K\subset U$. By Urysohn's lemma, there exists $f\in C_c(U,[0,1])$ such that $f|_K=1$. So $\mu(K)=\int_X\chi_Kd\mu\leq\int_X fd\mu$. This proves $A\leq B$.
\end{proof}


\begin{df}\label{lb97}
A Borel measure $\mu:\fk B_X\rightarrow\ovl\Rbb_{\geq0}$ is called a \textbf{Radon measure} \index{00@Radon measure} if the following conditions are satisfied:
\begin{enumerate}[label=(\alph*)]
\item $\mu$ is outer regular on Borel sets. 
\item $\mu$ is inner regular on open sets. Equivalently, for each open $U\subset X$, we have
\begin{align}\label{eq47}
\mu(U)=\sup\Big\{\int_Xfd\mu:f\in C_c(U,[0,1])  \Big\}
\end{align}
\item $\mu(K)<+\infty$ if $K$ is a compact subset of $X$. Equivalently, for each $f\in C_c(X,\Rbb_{\geq0})$ we have
\begin{align}
\dps\int_Xfd\mu<+\infty
\end{align}
\end{enumerate}
\end{df}

\begin{proof}[Proof of equivalence]
The equivalence in (b) is due to Lem. \ref{lb4}. The equivalence in (c) can be proved in a similar way to Lem. \ref{lb4}.
\end{proof}


Note that Radon measures are determined by their integrals against functions in $C_c(X,[0,1])$. Indeed, by (a), $\mu$ is determined by its values on open sets. (b) shows that those values on open sets are determined by the integrals $\int_Xfd\mu$ where $f\in C_c(X,[0,1])$.










\begin{rem}\label{lb12}
There exist canonical bijections among:
\begin{itemize}
\item $\Rbb_{\geq0}$-linear maps $C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$.
\item Positive linear functionals on $C_c(X,\Rbb)$.
\item Positive linear functionals on $C_c(X)=C_c(X,\Cbb)$.
\end{itemize}
\end{rem}
\begin{proof}
An $\Rbb_{\geq0}$-linear map $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ can be extended uniquely to a linear map $\Lambda:C_c(X,\Rbb)\rightarrow\Rbb$ due to the following Lem. \ref{lb5}. The latter can be extended to a linear functional on $C_c(X)$ by setting
\begin{align}\label{eq143}
\Lambda(f)=\Lambda(\Real f)+\im\Lambda(\Imag f)
\end{align}
for all $C_c(X)$. 
\end{proof}

\begin{lm}\label{lb5}
Let $K$ be an $\Rbb_{\geq0}$-linear subspace of an $\Rbb$-vector space $V$. Let $W$ be an $\Rbb$-linear space. Let $\Gamma:K\rightarrow W$ be an $\Rbb_{\geq0}$-linear map. Suppose that $V=\Span_\Rbb K$. Then $\Gamma$ can be extended uniquely to an $\Rbb$-linear map $\Lambda:V\rightarrow W$. 
\end{lm}


\begin{proof}
The uniqueness is obvious. To prove the existence, note that any $v\in V$ can be written as
\begin{align*}
v=v^+-v^-
\end{align*}
where $v^+,v^-\in K$. (Proof: Since $V=\Span_\Rbb K$, we have $v=a_1u_1+\cdots+a_mu_m-b_1w_1-\cdots-b_nw_n$ where each $u_i,w_j$ are in $K$, and each $a_i,b_j$ are in $\Rbb_{\geq0}$. One sets $v^+=\sum_i a_iu_i$ and $v^-=\sum_j b_jw_j$.) We then define $\Lambda(v)=\Gamma(v^+)-\Gamma(v^-)$. 

Let us show that this gives a well-defined map $\Lambda:V\rightarrow W$. Assume that $v=v^+-v^-=w^+-w^-$ where $v^\pm,w^\pm\in K$. Then $\Gamma(v^+)-\Gamma(v^-)=\Gamma(w^+)-\Gamma(w^-)$ iff $\Gamma(v^+)+\Gamma(w^-)=\Gamma(v^-)+\Gamma(w^+)$, iff (by the additivity of $\Gamma$) $\Gamma(v^++w^-)=\Gamma(v^-+w^+)$. The last statement is true because $v^+-v^-=w^+-w^-$ implies $v^++w^-=v^-+w^+$.

It is easy to see that $\Lambda$ is additive. If $c\geq0$, then $cv=cv^+-cv^-$ where $cv^+,cv^-\in K$. So $\Lambda(cv)=\Gamma(cv^+)-\Gamma(cv^-)$, which (by the $\Rbb_{\geq0}$-linearity of $\Gamma$) equals $c\Gamma(v^+)-c\Gamma(v^-)=c\Lambda(v)$. Since $-v=v^--v^+$, we have $\Lambda(-v)=\Gamma(v^-)-\Gamma(v^+)=-\Lambda(v)$. Hence $\Lambda(-cv)=c\Lambda(-v)=-c\Lambda(v)$. This proves that $\Lambda$ commutes with the $\Rbb$-multiplication.
\end{proof}


\begin{thm}[\textbf{Riesz-Markov representation theorem}]\label{lb7} \index{00@Riesz-Markov representation theorem}
For every positive linear $\Lambda:C_c(X,\Fbb)\rightarrow\Fbb$ there exists a unique Radon measure $\mu:\fk B_X\rightarrow\ovl\Rbb_{\geq0}$ such that
\begin{align}
\Lambda(f)=\int_Xfd\mu
\end{align}
for all $f\in C_c(X,\Fbb)$. Moreover, every Radon measure on $X$ arises from some $\Lambda$ in this way.

In addition, the operator norm $\Vert\Lambda\Vert$ equals $\mu(X)$. Therefore, $\Lambda$ is bounded iff $\mu$ is a finite measure. 
\end{thm}

\begin{proof}
See \cite[Sec. 25.3]{Gui-A} for the first paragraph. The second paragraph asserts that
\begin{align*}
\sup_{f\in\ovl B_{C_c(X)}(0,1)}|\Lambda(f)|= \mu(X)
\end{align*}
The inequality ``$\leq$'' is obvious. The reverse inequality ``$\geq$'' follows from \eqref{eq47}.
\end{proof}



\subsubsection{Basic properties of Radon measures}

\begin{thm}\label{lb101}
Let $\mu$ be a Radon measure (or its completion) on $X$. Then $\mu$ is regular on any measurable set $E$ satisfying $\mu(E)<+\infty$.
\end{thm}

\begin{proof}
See \cite[Sec. 25.4]{Gui-A}. A sketch of the proof (different from that in \cite{Gui-A}) is as follows. 

Assume WLOG that $E$ is Borel. Since Radon measures are outer regular on Borel sets, it remains to prove that $\mu$ is inner regular on $E$. Pick an open set $\mu(U)$ such that $\mu(U\setminus E)$ is small. Since $\mu$ is inner regular on $U$, there is a compact $K\subset U$ such that $\mu(U\setminus K)$ is small. However, $K$ is not necessarily contained in $E$. 

To fix this issue, we note that since $\mu$ is outer regular on $U\setminus E$, we can find an open set $V\subset U$ containing $U\setminus E$ whose measure is close to $\mu(U\setminus E)$. In particular, $\mu(V)$ is small. Then $K\setminus V$ is a compact subset of $E$ whose measure is close to $\mu(E)$.
\end{proof}


The following criterion for Radon measures is of fundamental importance and will be used repeatedly throughout this course.

\begin{thm}\label{lb64}
Assume that $X$ is second countable. Let $\mu$ be a Borel measure on $X$. Then $\mu$ is Radon iff $\mu(K)<+\infty$ for any compact $K\subset X$.
\end{thm}

In particular, a finite Borel measure on $\Rbb^n$ (where $n\in\Nbb$) is Radon.

\begin{proof}
See \cite[Sec. 25.5]{Gui-A}. The rough idea is as follows. By Thm. \ref{lb7}, there exists a Radon measure $\nu$ such that $\int fd\mu=\int fd\nu$ for all $f\in C_c(X)$. It suffices to show $\mu=\nu$. 

If $U\subset X$ is open, then $U$ is $\sigma$-compact by Rem. \ref{lb84}. Using Urysohn's lemma, we can find an increasing sequence $(f_n)$ in $C_c(I,[0,1])$ converging pointwise to $\chi_U$. By MCT, we have $\mu(U)=\lim_n \int f_nd\mu=\lim_n\int f_nd\nu=\nu(U)$.

Next, let $E\in\fk B_X$ such that $\nu(E)<+\infty$. Since $\nu$ is Radon, by Thm. \ref{lb101}, there exist a compact $K\subset E$ and an open $U\supset E$ such that $\nu(U\setminus K)$ is small. By the above paragraph, $\mu(U\setminus K)=\nu(U\setminus K)$ is also small, and $\mu(U)=\nu(U)$. Thus $\mu(E)\approx\mu(U)=\nu(U)\approx\nu(E)$. Hence $\mu(E)=\nu(E)$.

Finally, choose any $E\in\fk B_X$. Since $X$ is $\sigma$-compact, it is covered by an increasing sequence $(K_n)$ of compact subsets. Since $\nu$ is Radon, we have $\nu(K_n)<+\infty$ and hence $\nu(E\cap K_n)<+\infty$. By the above paragraph, we have $\mu(E\cap K_n)=\nu(E\cap K_n)$. Hence $\mu(E)=\nu(E)$.
\end{proof}





\subsubsection{Approximation and density}

The main reference for this subsection is \cite[Sec. 27.2]{Gui-A}.





\begin{thm}[\textbf{Lusin's theorem}]\label{lb82}\index{00@Lusin's theorem}
Let $X$ be LCH. Let $\mu$ be a Radon measure (or its completion) on $X$ with $\sigma$-algebra $\fk M$. Let $f:X\rightarrow\Fbb$ be measurable. Let $A\in\fk M$ such that $\mu(A)<+\infty$. Then for each $\eps>0$ there exists a compact $K\subset A$ such that $\mu(A\setminus K)<\eps$ and that $f|_K:K\rightarrow\Fbb$ is continuous.
\end{thm}

With the help of the Tietze extension Thm. \ref{lb83}, Lusin's theorem implies that for each $\eps>0$ there exist a compact $K\subset A$ and some $\wtd f\in C_c(X,\Fbb)$ such that $\wtd f|_K=f|_K$ and $\mu(A\setminus K)<\eps$.

\begin{proof}
See \cite[Sec. 25.4]{Gui-A}. The rough idea is that one first uses Thm. \ref{lb101} to prove the case where $\wtd f:=f\chi_A$ is a simple function. The general case follows by choosing an increasing sequence of simple functions converging uniformly to $\wtd f\chi_{F_n}$, where $F_n=|\wtd f|^{-1}([0,n])$ and $n$ is sufficiently large.
\end{proof}


\begin{thm}\label{lb14}
Let $1\leq p<+\infty$. Let $\mu$ be a Radon measure (or its completion) on an LCH space $X$. Then, in the $L^p$-norm, the space $C_c(X,\Fbb)$ is dense in $L^p(X,\mu,\Fbb)$. More precisely, the map $f\in C_c(X,\Fbb)\mapsto f\in L^p(X,\mu,\Fbb)$ has dense range.
\end{thm}


\begin{proof}
See \cite[Sec. 27.2]{Gui-A}. Rough idea: Choose $f\in L^p$. Use Lusin's theorem to approximate $f\chi_{E_n}$ by functions of $C_c(X,\Fbb)$, where $E_n=\{1/n<|f|<n\}$ and $n$ is sufficiently large. Alternatively, first approximate $f$ by a simple function $g$ (cf. Thm. \ref{lb79}). Then use Thm. \ref{lb101} and Urysohn's lemma to approximate $g$ by functions of $C_c(X,\Fbb)$.
\end{proof}


\begin{thm}\label{lb361}
Let $1\leq p<+\infty$. Let $k\in\Nbb\cup\{\infty\}$. Assume that $X$ is an open subset of $\Rbb^n$ (or more generally, a $C^k$-manifold with or without boundary). Let $\mu$ be a Radon measure (or its completion) on $X$. Then, in the $L^p$-norm, the space $C_c^k(X,\Fbb)$ is dense in $L^p(X,\mu,\Fbb)$.
\end{thm}


\begin{proof}
See \cite[Sec. 30.7]{Gui-A}. Rough idea: Due to Thm. \ref{lb14}, a function $f\in L^p(X,\mu,\Fbb)$ can be approximated in $L^p$ by some $g\in C_c(X,\Fbb)$. Choose a precompact open set $U\subset X$ containing $\Supp(g)$. By Rem. \ref{lb359}, $g$ can be approximated uniformly by functions of $C_c^k(U,\Fbb)$. This is also an $L^p$-approximation, because $\mu(U)<+\infty$.
\end{proof}






\begin{rem}
One easily checks that
\begin{align*}
&\Span_\Fbb\{\chi_I:I\subset\Rbb\text{ is a bounded interval}\}\\
=&\Span_\Fbb\{\chi_I:I\subset\Rbb\text{ is a compact interval}\}\\
=&\Span_\Fbb\{\chi_I:I\subset\Rbb\text{ is a bounded open interval}\}
\end{align*}
An element in these sets is called an $\Fbb$-valued \textbf{step function}. \index{00@Step functions} Moreover, one checks that
\begin{gather*}
\{\text{right-continuous $\Fbb$-valued step functions}\}=\Span_\Fbb\{\chi_{[a,b)}:a,b\in\Rbb\}\\
\{\text{left-continuous $\Fbb$-valued step functions}\}=\Span_\Fbb\{\chi_{(a,b]}:a,b\in\Rbb\}
\end{gather*}
\end{rem}


\begin{thm}\label{lb77}
Let $1\leq p<+\infty$. Let $\mu$ be a Radon measure (or its completion) on $\Rbb$. Then each of the following classes of functions form a dense subset of $L^p(\Rbb,\mu,\Fbb)$:
\begin{enumerate}[label=(\alph*)]
\item Right-continuous $\Fbb$-valued step functions.
\item Left-continuous $\Fbb$-valued step functions.
\item Elements of $\Span_\Fbb\{\chi_{(-\infty,b]}:b\in\Rbb\}$.
\item Elements of $\Span_\Fbb\{\chi_{(-\infty,b)}:b\in\Rbb\}$.
\end{enumerate}
\end{thm}

\begin{proof}
With the help of Thm. \ref{lb14}, the density of (a) and (b) can be proved by approximating a function $f\in C_c(X,\Fbb)$ with left/right-continuous step functions. See \cite[Sec. 27.2]{Gui-A} for details.

Since (a)$\subset$(c) and (b)$\subset$(d), the density of (c) and (d) follows.
\end{proof}




\begin{thm}\label{lb85}
Let $1\leq p<+\infty$. Let $\mu$ be a Radon measure (or its completion) on a second countable LCH space $X$. Then $L^p(X,\mu,\Fbb)$ is separable.
\end{thm}


\begin{proof}
See \cite[Sec. 27.2]{Gui-A}. The rough idea is as follows. First assume that $X$ is compact. Then $\mu(X)<+\infty$. By Thm. \ref{lb75}, $C(X,\Fbb)$ is $l^\infty$-separable, and hence $L^p$-separable. Therefore, by Thm. \ref{lb14}, $L^p(X,\mu,\Fbb)$ is separable.

In the general case, one writes $X=\bigcup_n K_n$ where $K_1\subset K_2\subset\cdots$ are compact. Clearly $\sum_n L^p(K_n,\mu|_{K_n},\Fbb)$ is dense in $L^p(X,\mu,\Fbb)$. By Thm. \ref{lb64}, each $\mu|_{K_n}$ is Radon. By the above paragraph, each $L^p(K_n,\mu|_{K_n},\Fbb)$ is separable. Thus $L^p(X,\mu,\Fbb)$ is separable.
\end{proof}






\subsubsection{Complex Radon measures}


\begin{df}
If $X$ is a set and $\fk M\subset 2^X$ is a $\sigma$-algebra, a \textbf{complex measure} \index{00@Complex measure} (resp. \textbf{signed measure}) \index{00@Signed measure} is a function $\fk M\rightarrow \Cbb$ (resp. $\fk M\rightarrow\Rbb$) that can be written as a $\Cbb$-linear (resp. $\Rbb$-linear) combination of finite measures on $\fk M$.
\end{df}



We now assume that $X$ is LCH. 

\begin{df}
A complex (resp. signed) measure on $\fk B_X$ is called \textbf{Radon} if it is a $\Cbb$-linear (resp. $\Rbb$-linear) combination of finite Radon measures. 
\end{df}

Suppose that $\mu$ is a complex Radon measure on $X$. Then similar to the proof of Rem. \ref{lb12}, for each $f\in C_0(X)$, we can extend the $\Rbb_{\geq0}$-linear functional $\mu\mapsto\int_X fd\mu$ (for all finite Radon measures $\mu$) to $\mu\mapsto \int_X fd\mu$ (for all complex Radon measures $\mu$). This gives a $\Cbb$-bilinear map
\begin{align*}
(f,\mu)\mapsto\int_X fd\mu\qquad\in\Cbb
\end{align*}
for $f\in C_0(X)$ and complex Radon measures $\mu$.



\begin{thm}[\textbf{Riesz-Markov representation theorem}] \index{00@Riesz-Markov representation theorem}\label{lb8}
Let $\Fbb=\Cbb$ (resp. $\Fbb=\Rbb$.) Then the elements of $C_c(X,\Fbb)^*$ are precisely linear functionals
\begin{align*}
\Lambda:C_c(X,\Fbb)\rightarrow\Fbb \qquad f\mapsto \int_X fd\mu
\end{align*}
where $\mu$ is complex (resp. signed) Radon measure on $X$.
\end{thm}




\begin{proof}
It suffices to assume that $\Lambda$ is real, i.e., sending $C_c(X,\Rbb)$ into $\Rbb$. Similar to the proof of Thm. \ref{lb13}, one writes $\Lambda=\Lambda^+-\Lambda^-$ where $\Lambda^\pm$ are positive. Then apply Thm. \ref{lb7} to $\Lambda^\pm$. See \cite[Subsec. 25.10.2]{Gui-A} for details.
\end{proof}




\begin{rem}
By Rem. \ref{lb357}, $C_c(X,\Fbb)$ is $l^\infty$-dense in $C_0(X,\Fbb)$. Therefore, by Cor. \ref{lb44}, the dual spaces $C_c(X,\Fbb)^*$ and $C_0(X,\Fbb)^*$ are canonically identified. Therefore, Thm. \ref{lb8} holds verbatim if $C_c(X,\Fbb)$ is replaced by $C_0(X,\Fbb)$.  
\end{rem}


\begin{comment}
\begin{df}
Let $\mu$ be a complex Radon measure on $X$. Let $\Lambda\in C_c(X,\Fbb)^*=C_0(X,\Fbb)^*$ be the linear functional corresponding to $\mu$ as in Thm. \ref{lb8}. The \textbf{total variation} \pmb{$\Vert\mu\Vert$} \index{00@Total variation $\Vert\mu\Vert$} \index{zz@$\Vert\mu\Vert$, the total variation} is defined to be the operator norm of $\Lambda$, i.e.,
\begin{align*}
\Vert\mu\Vert=\Vert\Lambda\Vert=\sup_{f\in \ovl B_{C_c(X)}(0,1)}|\Lambda(f)|=\sup_{f\in \ovl B_{C_0(X)}(0,1)}|\Lambda(f)|
\end{align*}
\end{df}
\end{comment}





\subsection{Basic facts about increasing functions}\label{lb88}

\subsubsection{Notation}\label{lb89}

If $I\subset\Rbb$ is a proper interval, a function $\rho:I\rightarrow\Rbb$ is called \textbf{increasing} if it is non-decreasing, i.e., $\rho(x)\leq \rho(y)$ whenever $x,y\in I$ and $x\leq y$. For each $t\in\Rbb$, let
\begin{align*}
I_{\leq t}=I\cap (-\infty,t]\quad I_{<t}=I\cap (-\infty,t)\quad I_{\geq t}=I\cap [t,+\infty)\quad I_{>t}=I\cap (t,+\infty)
\end{align*}

Suppose that $a=\inf I$ and $b=\sup I$. Let $\rho:I\rightarrow \Rbb$ be increasing. If $x\in(a,b)$, then the left and right limits\footnote{When taking the limit $\lim_{y\rightarrow x^\pm}$, we do not allow $y$ to be equal to $x$.}
\begin{align}
\rho(x^-)=\lim_{y\rightarrow x^-}\rho(y)\qquad \rho(x^+)=\lim_{y\rightarrow x^+}\rho(y)
\end{align}
exist, and
\begin{align*}
\rho(x^-)\leq \rho(x)\leq \rho(x^+)
\end{align*}
If $a\in I$, then $\rho(a^+)$ exists, and $\rho(a)\leq \rho(a^+)$. If $b\in I$, then $\rho(b^-)$ exists, and $\rho(b^-)\leq \rho(b)$. Let
\begin{align*}
\Omega_\rho=\{x\in (a,b):\rho|_{(a,b)}\text{ is continuous at }x\}
\end{align*}
Then for each $x\in (a,b)$, we have
\begin{gather}\label{eq38}
\begin{gathered}
x\in\Omega_\rho\quad\Leftrightarrow\quad \rho(x^-)=\rho(x^+) \quad\Leftrightarrow\quad \rho(x^-)=\rho(x)=\rho(x^+)
\end{gathered}
\end{gather}


\subsubsection{Basic properties of increasing functions}

Let $I\subset\Rbb$ be a proper interval with $a=\inf I,b=\sup I$.

\begin{pp}\label{lb62}
If $\rho:I\rightarrow\Rbb$ is increasing, then $I\setminus\Omega_\rho$ is countable.
\end{pp}

\begin{proof}
Replacing $\rho$ with $\arctan\circ\rho$, we may assume that $\rho$ is bounded. Let $C=\diam(\rho(I))=\sup_{x,y\in I}|\rho(x)-\rho(y)|$. Let $A=(a,b)\setminus\Omega_\rho$. Then for each $B\in\fin(2^A)$, we have
\begin{align*}
\sum_{x\in B}(\rho(x^+)-\rho(x^-))\leq C
\end{align*}
Applying $\lim_B$, we get $\sum_{x\in A}(\rho(x^+)-\rho(x^-))\leq C<+\infty$. It follows from Prop. \ref{lb235} that $A$ is countable.
\end{proof}


\begin{df}
Let $\rho:I\rightarrow\Rbb$ be increasing. The \textbf{right-continuous normalization} \index{00@Right-continuous normalization} of $\rho$ is the function $\wtd\rho:I\rightarrow \Rbb$ defined by
\begin{gather*}
\wtd\rho(x)=\left\{
\begin{array}{ll}
\rho(x^+)&\text{if }x<b\\[0.5ex]
\rho(b)&\text{if }x=b
\end{array}
\right.
\end{gather*}
The function $\wtd\rho$ is clearly increasing and right-continuous. Moreover, $\wtd\rho$ clearly agrees with $\rho$ on $\Omega_\rho$. Therefore, $\wtd\rho$ and $\rho$ are almost equal, as defined by the following proposition.
\end{df}



\begin{pp}\label{lb70}
Let $\rho_1,\rho_2:I\rightarrow\Rbb$ be increasing. Then the following are equivalent:
\begin{enumerate}[label=(\alph*)]
\item There exists a dense subset $E\subset I$ such that $\rho_1|_E=\rho_2|_E$.
\item $\Omega_{\rho_1}=\Omega_{\rho_2}$, and $\rho_1|_{\Omega_{\rho_1}}=\rho_2|_{\Omega_{\rho_2}}$.
\item The right-continuous normalizations of $\rho_1$ and $\rho_2$ agree on $I_{<b}$.
\end{enumerate}
If any of these statements are true, we say that $\rho_1,\rho_2$ are \textbf{almost equal}. \index{00@Almost equal increasing functions}
\end{pp}


\begin{proof}
(a)$\Rightarrow$(b): Assume (a). Choose any $x\in I$. If $x>a$ then
\begin{subequations}\label{eq40}
\begin{align}\label{eq40a}
\rho_1(x^-)=\lim_{E\ni y\rightarrow x^-}\rho_1(y)=\lim_{E\ni y\rightarrow x^-}\rho_2(y)=\rho_2(x^-)
\end{align}
Similarly, if $x<b$ then
\begin{align}\label{eq40b}
\rho_1(x^+)=\rho_2(x^+)
\end{align}
\end{subequations}
Thus (b) follows from \eqref{eq38}.\\[-1ex]

(b)$\Rightarrow$(a): By Prop. \ref{lb62}, $E:=(a,b)\cap\Omega_{\rho_1}$ is a dense subset of $(a,b)$.\\[-1ex]

(b)$\Leftrightarrow$(c): Let $\wtd\rho_i$ be the right continuous normalization of $\rho_i$. Then by (a)$\Rightarrow$(b), we have $\Omega_{\rho_i}=\Omega_{\wtd\rho_i}$ and $\rho_i|_{\Omega_{\rho_i}}=\wtd\rho_i|_{\Omega_{\wtd\rho_i}}$. Therefore, (b) holds iff
\begin{align}\label{eq39}
\Omega_{\wtd\rho_1}=\Omega_{\wtd\rho_2}\qquad \text{and}\qquad \wtd\rho_1|_{\Omega_{\wtd\rho_1} }=\wtd\rho_2|_{\Omega_{\wtd\rho_2} }
\end{align}
Clearly (c) implies \eqref{eq39}. Suppose that \eqref{eq39} is true. Then for each $x\in I_{<b}$ we have
\begin{align*}
\wtd\rho_1(x)=\wtd\rho_1(x^+)\xlongequal{\eqref{eq40b}}\wtd\rho_2(x^+)=\wtd\rho_2(x)
\end{align*}
Thus \eqref{eq39} implies (c). Therefore (b) and (c) are equivalent.
\end{proof}






\subsection{The Stieltjes integral}


\subsubsection{Definitions and basic properties}

In this subsection, we fix a proper interval $I\subset\Rbb$, and let $\rho:I\rightarrow\Rbb_{\geq0}$ be an increasing function.



\begin{df}
Let $J$ be any proper bounded interval. Let $a=\inf J,b=\sup J$. A \textbf{partition} \index{00@Partition of an interval} of the interval $J$ is defined to be an element of the form
\begin{align}
\sigma=\{a_0,a_1,\dots,a_n\in [a,b]:a_0=a<a_1<a_2<\cdots<a_n=b,n\in\Zbb_+\}
\end{align}
The \textbf{mesh} \index{00@Mesh} of $\sigma$ is defined to be
\begin{align*}
\max\{a_i-a_{i=1}:i=1,\dots,n\}
\end{align*}
If $\sigma,\sigma'\in \fin(2^J)$ are partitions of $J$, we say that $\sigma'$ is a \textbf{refinement} \index{00@Refinement of a partition} \index{00@Finer partition} of $\sigma$ (or that $\sigma'$ is \textbf{finer than} $\sigma$), if $\sigma\subset\sigma'$. In this case, we also write  \index{zz@$\sigma\prec\sigma'$} 
\begin{align*}
\sigma\prec\sigma'
\end{align*}
We define $\mc P(J)$ to be\index{PI@$\mc P(I)$, the set of partitions of the bounded interval $I$}
\begin{align*}
\mc P(J)=\{\text{partitions of $J$}\}
\end{align*}
\end{df}


\begin{rem}
If $\sigma,\sigma'\in\mc P(J)$, then clearly $\sigma\cup\sigma'\in\mc P(J)$ and $\sigma,\sigma'\prec \sigma\cup\sigma$. Therefore, $\prec$ is a partial order on $\mc P(J)$. We call $\sigma\cup\sigma'$ the \textbf{common refinement} \index{00@Common refinement} of $\sigma$ and $\sigma'$.
\end{rem}


\begin{df}\label{lb268}
A \textbf{tagged partition} \index{00@Tagged partition} of $I$ is an ordered pair
\begin{align}\label{eq41}
(\sigma,\xi_\blt)=\big(\{a_0=a<a_1<\cdots<a_n=b\},(\xi_1,\dots,\xi_n) \big)
\end{align}
where $\sigma\in\mc P(J)$ and 
\begin{align*}
\xi_i\in(a_{j-1},a_j]
\end{align*}
for all $1\leq j\leq n$. The set\index{QI@$\mc Q(I)$, the directed set of tagged partitions}
\begin{align*}
\mc Q(J)=\{\text{tagged partitions of $J$}\}
\end{align*}
equipped with the preorder $\prec$ defined by
\begin{align}
(\sigma,\xi_\blt)\prec(\sigma',\xi_\blt')\qquad\Longleftrightarrow\qquad \sigma\subset\sigma'
\end{align}
is a directed set.
\end{df}



\begin{df}\label{lb66}
Let $V$ be a complete normed vector space. Assume $[a,b]\subset I$ and $a<b$. Let $f\in C([a,b],V)$. For each $(\sigma,\xi_\blt)\in\mc Q(I)$, define the \textbf{Stieltjes sum}\index{00@Stieltjes sum} \index{Sf@$S_\rho(f,\sigma,\xi_\blt)$}
\begin{align*}
S_\rho(f,\sigma,\xi_\blt)=\sum_{j\geq 1}f(\xi_j)\big(\rho(a_j)-\rho(a_{j-1})\big)
\end{align*}
abbreviated to $S(f,\sigma,\xi_\blt)$ when no confusion arises. The \textbf{Stieltjes integral} \index{00@Stieltjes integral} on $(a,b]$ is defined to be the limit of the net $(S_\rho(f,\sigma,\xi_\blt))_{(\sigma,\xi_\blt)\in\mc Q([a,b])}$:
\begin{align}\label{eq1}
\int_{(a,b]} fd\rho=\lim_{(\sigma,\xi_\blt)\in\mc Q(I)}S_\rho(f,\sigma,\xi_\blt)
\end{align}
The \textbf{Stieltjes integral} on $[a,b]$ is defined to be
\begin{align}
\int_{[a,b]}fd\rho=f(a)\rho(a)+\int_{(a,b]}fd\rho
\end{align}
\end{df}


Note that when $f(a)\neq0$, the integral $\int_{(a,b]}fd\rho$ depends not only on $\rho|_{(a,b]}$ but also on the value $\rho(a)$. On the other hand, it is clear that
\begin{gather}
\int_{(a,b]}fd\rho=\int_{(a,b]}fd\rho|_{[a,b]}\qquad \int_{[a,b]}fd\rho=\int_{[a,b]}fd\rho|_{[a,b]}
\end{gather}


\begin{proof}[Proof of the convergence of \eqref{eq1}]
Since $f$ is uniformly continuous, for each $\eps>0$, there exists $\delta>0$ such that $\Vert f(x)-f(y)\Vert\leq\eps$ for all $x,y\in[a,b]$ and $|x-y|\leq\delta$. Choose any tagged partition $(\sigma,\xi_\blt)$ of $[a,b]$ with mesh $\leq\delta$. Then one easily sees that for any $(\sigma',\xi_\blt')\succ(\sigma,\xi)$ we have
\begin{align}\label{eq149}
\Vert S_\rho(f,\sigma',\xi_\blt')-S_\rho(f,\sigma,\xi_\blt)\Vert\leq \eps(\rho(b)-\rho(a))
\end{align}
Therefore, the net $(S(f,\sigma,\xi_\blt))_{(\sigma,\xi_\blt)\in\mc Q(I)}$ is Cauchy. So it must converge due to Thm. \ref{lb269} and the completeness of $V$.
\end{proof}

\begin{rem}\label{lb63}
The above proof implies the following useful fact: Let $f\in[a,b]$. Let $\eps,\delta>0$ such that $\Vert f(x)-f(y)\Vert\leq\eps$ for all $x,y\in[a,b]$ satisfying $|x-y|\leq\delta$. Then for each tagged partition $(\sigma,\xi_\blt)$ of $[a,b]$ with mesh $\leq\delta$, we have
\begin{align}
\Big\Vert \int_{(a,b]}fd\rho-S_\rho(f,\sigma,\xi_\blt)\Big\Vert\leq \eps(\rho(b)-\rho(a))
\end{align}
and hence
\begin{align}
\Big\Vert \int_{[a,b]}fd\rho-f(a)\rho(a)-S_\rho(f,\sigma,\xi_\blt)\Big\Vert\leq \eps(\rho(b)-\rho(a))
\end{align}
\end{rem}


\begin{eg}\label{lb71}
The integrals of the constant function $1$ are
\begin{align*}
\int_{(a,b]}d\rho=\rho(b)-\rho(a)\qquad \int_{[a,b]}d\rho=\rho(b)
\end{align*}
\end{eg}

\begin{comment}
\begin{eg}\label{lb68}
Suppose that $\rho|_{(a,b]}=1$. Then
\begin{align*}
\int_{(a,b]}fd\rho=f(a)(1-\rho(a))\qquad \int_{[a,b]}fd\rho=f(a)
\end{align*}
In particular, if $\rho|_{[a,b]}=1$, then $\dps\int_{(a,b]}fd\rho=0$ and $\dps\int_{[a,b]}fd\rho=f(a)$.
\end{eg}
\end{comment}






\begin{rem}\label{lb65}
It is easy to see that 
\begin{align*}
\Lambda:C([a,b],V)\rightarrow V\qquad f\mapsto \int_{[a,b]}fd\rho
\end{align*}
is linear. Moreover, since $\Vert S(f,\sigma,\xi_\blt)\Vert\leq (\rho(b)-\rho(a))\Vert f\Vert_{l^\infty}$ and hence $\Vert f(a)\rho(a)+ S(f,\sigma,\xi_\blt)\Vert\leq \rho(b)\Vert f\Vert_{l^\infty}$, the operator norm $\Vert\Lambda\Vert$ satisfies $\Vert\Lambda\Vert\leq \rho(b)$, that is
\begin{align*}
\Big\Vert\int_{[a,b]}fd\rho\Big\Vert\leq \rho(b)\Vert f\Vert_{l^\infty}\qquad\text{for all }f\in C([a,b],V)
\end{align*}
In particular, $\Lambda$ is bounded. Similarly, the linear functional
\begin{align*}
C([a,b],V)\rightarrow V\qquad f\mapsto \int_{(a,b]}fd\rho
\end{align*}
has operator norm $\leq\rho(b)-\rho(a)$.
\end{rem}

\begin{rem}\label{lb6}
It is easy to check that $\rho\mapsto\int_{(a,b]} fd\rho$ and $\rho\mapsto\int_{[a,b]} fd\rho$ are $\Rbb_{\geq0}$-linear over increasing functions $\rho:[a,b]\rightarrow\Rbb_{\geq0}$. Moreover, if $c\in(a,b)$, one easily shows
\begin{align}
\int_{(a,b]}fd\rho=\int_{(a,c]}fd\rho+\int_{(c,b]}fd\rho
\end{align}
by considering tagged partitions finer than $\{a,c,b\}$.
\end{rem}


%Exp. \ref{lb68} suggests that the value of $\int_{[a,b]}fd\rho$ is independent of $\rho(a)$:

\begin{lm}\label{lb69}
Suppose that $\rho_1,\rho_2:[a,b]\rightarrow\Rbb_{\geq0}$ are increasing and satisfies $\rho_1|_{(a,b]}=\rho_2|_{(a,b]}$. Then for each $f\in C([a,b],V)$ we have $\dps\int_{[a,b]}fd\rho_1=\int_{[a,b]}fd\rho_2$.
\end{lm}

See Thm. \ref{lb67} for a generalization of this lemma.

\begin{proof}
Since $f$ is continuous, for each increasing $\rho:[a,b]\rightarrow\Rbb_{\geq0}$, the integral $\int_{[a,b]}fd\rho$ can be approximated by $f(a)\rho(a)+S_\rho(f,\sigma,\xi_\blt)$ where $(\sigma,\xi_\blt)=\eqref{eq41}$ and $\xi_1=a$. Then
\begin{align*}
f(a)\rho(a)+S_\rho(f,\sigma,\xi_\blt)=f(a)\rho(a_1)+\sum_{j\geq2}f(\xi_j)(\rho(a_j)-\rho(a_{j-1}))
\end{align*}
is independent of $\rho(a)$. Hence $\int_{[a,b]}fd\rho$ is independent of $\rho(a)$.
\end{proof}



\begin{comment}
\begin{rem}
The Stieltjes integral can be defined on unbounded intervals. For example, if $\rho:[a,+\infty)\rightarrow\Rbb$ is \textit{bounded} and increasing, for $f\in C_0([a,+\infty),V)$, we define
\begin{align*}
\int_{[a,+\infty)} fd\rho=\lim_{\lambda\rightarrow+\infty}\int_{[a,\lambda]} fd\rho
\end{align*}
where the RHS converges. Similarly, we can define $\int_{-\infty}^{+\infty}fd\rho$ for bounded increasing $\rho:\Rbb\rightarrow\Rbb$ and $f\in C_0(\Rbb,V)$.
\end{rem}
\end{comment}





\subsubsection{Dependence of the Stieltjes integral on $\rho$}


Let $I\subset\Rbb$ be a proper interval, and let $a=\inf I$ and $b=\sup I$. Note that $I$ is not assumed to be bounded. 

\begin{df}
For each $f\in C_c(I,V)$ and each increasing $\rho:I\rightarrow\Rbb_{\geq0}$, we can still define the \textbf{Stieltjes integral} \index{00@Stieltjes integral}
\begin{align*}
\int_I fd\rho:=\int_Jfd\rho
\end{align*}
where $J$ is any compact sub-interval of $I$ containing $\Supp_I(f)$. The value of the integral is clearly independent of the choice of such $J$. Moreover, this definition is compatible with the definitions of $\int_{[a,b]}fd\rho$ and $\int_{(a,b]}fd\rho$ in Def. \ref{lb66}.
\end{df}


\begin{thm}\label{lb67}
Let $\rho_1,\rho_2:I\rightarrow\Rbb_{\geq0}$ be increasing functions satisfying the following condition:
\begin{itemize}
\item $\rho_1$ and $\rho_2$ are almost equal, and $\rho_1(b)=\rho_2(b)$ if $b\in I$. (By Prop. \ref{lb70}, this is equivalent to that $\rho_1,\rho_2$ have the same right-continuous normalization.)
\end{itemize}
Then for each $f\in C_c(I,V)$, we have
\begin{align*}
\int_I fd\rho_1=\int_I fd\rho_2
\end{align*}
\end{thm}



\begin{proof}
By Lem. \ref{lb69}, we may assume that $\rho_1(a)=\rho_2(a)$ if $a\in I$. 

Fix $f\in C_c(I,V)$. Choose $\alpha,\beta\in\Rbb$ satisfying $\Supp_I(f)\subset[\alpha,\beta]\subset I$. Due to the assumption on $\rho_1,\rho_2$, we may slightly enlarge the compact interval $J:=[\alpha,\beta]$ so that
\begin{align*}
\rho_1(\alpha)=\rho_2(\alpha)\qquad \rho_1(\beta)=\rho_2(\beta)
\end{align*}
(When $a\in I$ resp. $b\in I$, one can even set $\alpha=a$ resp. $\beta=b$.) Then $\int_I fd\rho_i=\int_J fd\rho_i$.


Let $C=\max\{\rho_i(\beta)-\rho_i(\alpha):i=1,2\}$. Choose any $\eps>0$. Since $f$ is uniformly continuous, there exists $\delta>0$ such that $|f(x)-f(y)|\leq\eps$ whenever $x,y\in I$ and $|x-y|\leq\delta$. Choose a tagged partition
\begin{align*}
(\sigma,\xi_\blt)=\big(\{a_0=\alpha<a_1<\cdots<a_n=\beta\},(\xi_1,\dots,\xi_n) \big)
\end{align*}
of $J$ with mesh $<\delta$. Moreover, due to the assumption on $\rho_1,\rho_2$, by a slight adjustment, we may assume that $\rho_1(a_j)=\rho_2(a_j)$ for each $0\leq j\leq n$. This implies
\begin{align*}
S_{\rho_1}(f,\sigma,\xi_\blt)=S_{\rho_2}(f,\sigma,\xi_\blt)
\end{align*}
Therefore, by Rem. \ref{lb63}, we obtain
\begin{align*}
\Big\Vert \int_J fd\rho_1-\int_J fd\rho_2\big\Vert\leq 2\eps\cdot C
\end{align*}
This completes the proof by choosing arbitrary $\eps$.
\end{proof}


\begin{thm}\label{lb72}
Let $\rho_1,\rho_2:I\rightarrow\Rbb_{\geq0}$ be increasing functions satisfying
\begin{gather}\label{eq48}
\begin{gathered}
%\lim_{x\rightarrow a^+}\rho_1(x)=\lim_{x\rightarrow a^+}\rho_2(x)\qquad\text{if}\qquad a\in I\\
\lim_{x\rightarrow a^+}\rho_1(x)=\lim_{x\rightarrow a^+}\rho_2(x)=0\qquad\text{if }a\notin I
\end{gathered}
\end{gather}
Then the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $\rho_1$ and $\rho_2$ are almost equal, and $\rho_1(b)=\rho_2(b)$ if $b\in I$. (By Prop. \ref{lb70}, this is equivalent to that $\rho_1,\rho_2$ have the same right-continuous normalization.)
\item For each $f\in C_c(I,\Fbb)$ we have
\begin{align*}
\int_I fd\rho_1=\int_I fd\rho_2
\end{align*}
\end{enumerate}
\end{thm}


\begin{proof}
By Thm. \ref{lb67}, we have ``(1)$\Rightarrow$(2)''. Assume (2). Let us prove (1). Let $\wtd\rho_i$ be the right-normalization of $\rho_i$. By ``(1)$\Rightarrow$(2)'', we have $\int_I fd\rho_i=\int_I fd\wtd\rho_i$. Therefore, to prove (1), it suffices to assume that $\rho_1$ and $\rho_2$ are right-continuous on $I$.

We shall prove (1) by choosing an arbitrary bounded increasing right-continuous $\rho:I\rightarrow\Rbb_{\geq0}$, and show that for each $x\in I$, the value $\rho(x)$ can be recovered from the integrals $\int_Ifd\rho$ where $f\in C_c(I,\Rbb)$.

Case 1: Assume $a\notin I$ and $a<x<b$. For each real numbers $v,y$ satisfying
\begin{align*}
a<v<x<y<b
\end{align*}
choose $\varphi_{v,y}\in C_c(I,[0,1])$ satisfying
\begin{align*}
\chi_{[v,x]}\leq\varphi_{v,y}\leq \chi_{(a,y]}
\end{align*}
Choose $u\in(a,v)$ such that $\varphi_{v,y}$ vanishes outside $[u,y]$. Then by Rem. \ref{lb6},
\begin{align*}
&\int_I\varphi_{v,y}d\rho=\int_{[u,y]}\varphi_{v,y}d\rho=\int_{[u,v]}\varphi_{v,y}d\rho+\int_{(v,x]}\varphi_{v,y}d\rho+\int_{(x,y]}\varphi_{v,y}d\rho\\
=&\int_{[u,v]}\varphi_{v,y}d\rho+\rho(x)-\rho(v)+\int_{(x,y]}\varphi_{v,y}d\rho
\end{align*}
where Exp. \ref{lb71} is used in the last equality. By Rem. \ref{lb65}, we have $\int_{[u,v]}\varphi_{v,y}d\rho\leq\rho(v)$ and $\int_{(x,y]}\varphi_{v,y}d\rho\leq \rho(y)-\rho(x)$. Since $\rho$ is right-continuous and satisfies \eqref{eq48}, we have
\begin{align*}
\lim_{v\searrow a^+}\rho(v)=\lim_{y\searrow x^+}(\rho(y)-\rho(x))=0
\end{align*}
Therefore, the above calculation of $\int_I\varphi_{v,y}d\rho$ shows
\begin{align*}
\lim_{
\begin{subarray}{c}
v\searrow a^+\\
y\searrow x^+
\end{subarray}}
\int_I \varphi_{v,y}d\rho=\lim_{v\searrow a^+}(\rho(x)-\rho(v))=\rho(x)
\end{align*}



Case 2: Assume $a\in I$ and $a\leq x<b$. For each $y\in(x,b)$, choose $\varphi_y\in C_c(I,[0,1])$ such that $\chi_{[a,x]}\leq\varphi_y\leq\chi_{[a,y]}$. Similar to the argument in Case 1, one shows
\begin{align*}
\int_I\varphi_yd\rho=\int_{[a,x]}\varphi_yd\rho+\int_{(x,y]}\varphi_yd\rho=\rho(x)+\int_{(x,y]}\varphi_yd\rho
\end{align*}
where Exp. \ref{lb71} is used. By Rem. \ref{lb65}, $\int_{(x,y]}\varphi_yd\rho\leq \rho(y)-\rho(x)$. Therefore, the right-continuity of $\rho$ implies
\begin{align*}
\lim_{y\searrow x^+}\int_I \varphi_yd\rho=\rho(x)
\end{align*}


Case 3: Assume $I=(a,b]$ and $x=b$.  For each $v\in(a,x)$, choose $\varphi_v\in C_c(I,[0,1])$ such that $\chi_{[v,b]}\leq \varphi_v\leq \chi_I$. Similar to the argument above,
\begin{align*}
\lim_{v\searrow a^+}\int_I\varphi_vd\rho=\rho(b)
\end{align*}

Case 4: Assume $I=[a,b]$ and $x=b$. Then $\dps\int_I d\rho=\rho(b)$.
\end{proof}


\begin{rem}\label{lb93}
The assumption \eqref{eq48} imposes little restriction. Indeed, suppose $a\notin I$. Then for each $f\in C_c(I)$, since there exists $v\in\Rbb_{>a}$ such that $f$ vanishes on $(a,v]$, for any constant $\varkappa\in\Rbb$ with $\rho+\varkappa\geq0$, we clearly have
\begin{align}
\int_I fd\rho=\int_I fd(\rho+\varkappa)
\end{align}
Therefore, when $a\notin I$, given any two increasing functions $\rho_1,\rho_2:I\rightarrow\Rbb_{\geq0}$, we can freely add constants to $\rho_1$ and $\rho_2$ to ensure that \eqref{eq48} holds.
\end{rem}







\subsection{The Riesz representation theorem via the Stieltjes integral}

In this section, we fix a proper interval $I\subset\Rbb$, and let $a=\inf I$ and $b=\sup I$.

\subsubsection{The positive case}




\begin{thm}[\textbf{Riesz representation theorem}]\label{lb9}
We have a bijection between:
\begin{enumerate}[label=(\alph*)]
\item A bounded increasing right-continuous function $\rho:I\rightarrow\Rbb_{\geq0}$ satisfying $\lim_{x\rightarrow a^+}\rho(a)=0$ if $a\notin I$.
\item A bounded positive linear functional $\Lambda:C_c(I,\Fbb)\rightarrow\Fbb$.
\end{enumerate}
$\Lambda$ is determined by $\rho$ by
\begin{align}\label{eq43}
\Lambda:C(I,\Fbb)\rightarrow\Fbb\qquad f\mapsto\int_I fd\rho
\end{align}
$\rho$ is determined by $\Lambda$ by 
\begin{align}\label{eq42}
\rho(x)=\mu(I_{\leq x})\qquad\text{for all }x\in I
\end{align}
where $\mu$ is the finite Borel measure on $I$ associated to $\Lambda$ as in the Riesz-Markov representation Thm. \ref{lb7}. 
\end{thm}

Note that by Thm. \ref{lb64}, finite Borel measures on $I$ and finite Radon measures on $I$ coincide.


\begin{proof}
Step 1. Thm. \ref{lb7} establishes the equivalence between a bounded positive linear functional $\Lambda$ and a finite Borel measure $\mu$. Let us prove the equivalence between the radon measures $\mu$ and the functions $\rho$ satisfying (a).

More precisely, given a Radon measure $\mu$ on $I$, let $\rho_\mu:I\rightarrow\Rbb_{\geq0}$ be defined by \eqref{eq42}, that is, for each $x\in I$ we have 
\begin{align}\label{eq184}
\rho_\mu(x)=\mu(I_{\leq x})
\end{align}
Then $\rho_\mu$ is clearly bounded and increasing. By DCT,  $\rho_\mu$ is right-continuous, and we have $\lim_{x\rightarrow a^-}\rho(x)=0$ when $a\notin I$. Therefore, $\rho_\mu$ satisfies (a). 

Conversely, given any $\rho$ satisfying (a), let $\mu_\rho$ be the unique Radon measure corresponding to $\rho$ via \eqref{eq43}, i.e., for each $f\in C_c(I,\Fbb)$ we have
\begin{align}\label{eq46}
\int_I f d\mu_\rho=\int_I fd\rho
\end{align}
By Rem. \ref{lb65}, the linear functional $f\in C_c(I,\Fbb)\mapsto \int_Ifd\rho$ is bounded with operator norm $\leq\sup_{x\in I}\rho(x)$. Thus, $\mu_\rho$ is a finite measure.

We want to show that $\Phi:\rho\mapsto\mu_\rho$ and $\Psi:\mu\mapsto\rho_\mu$ are inverses of each other. By Thm. \ref{lb72}, the map $\Phi$ is injective. Therefore, it suffices to prove that $\Phi\circ\Psi=\id$, i.e., that $\mu_{\rho_\mu}=\mu$. This means proving
\begin{align}\label{eq45}
\int_I fd\mu=\int_Ifd\rho_\mu
\end{align}
for each $f\in C_c(I,\Fbb)$. \\[-1ex]

Step 2.  Let us fix $f\in C_c(I,\Fbb)$ and prove \eqref{eq45}. Choose $\alpha,\beta\in\Rbb$ such that $J:=[\alpha,\beta]$ is a sub-interval of $I$ containing $\Supp_I(f)$. Choose any $\eps>0$. Since $f$ is uniformly continuous, there exists $\delta>0$ such that $|f(x)-f(y)|\leq\eps$ whenever $x,y\in I$ and $|x-y|\leq\delta$. Choose a tagged partition
\begin{align*}
(\sigma,\xi_\blt)=\big(\{a_0=\alpha<a_1<\cdots<a_n=\beta\},(\xi_1,\dots,\xi_n) \big)
\end{align*}
of $J$ with mesh $\leq\delta$. By Rem. \ref{lb63}, we have
\begin{align}\label{eq44}
\Big| \int_Jfd\rho_\mu-f(\alpha)\rho_\mu(\alpha)-S_{\rho_\mu}(f,\sigma,\xi_\blt)\Big|\leq \eps(\rho_\mu(\beta)-\rho_\mu(\alpha))=\eps\cdot\mu((\alpha,\beta])
\end{align}


Also, we have $\Vert f-g\Vert_{l^\infty(I)}\leq\eps$ where
\begin{align*}
g=f(\alpha)\chi_{\{a\}}+\sum_{i=1}^n f(\xi_i)\chi_{(a_{i-1},a_i]}
\end{align*}
By \eqref{eq184}, we have
\begin{align*}
\mu(\{\alpha\})=\rho_\mu(\alpha)-\mu(I_{<\alpha})\qquad \mu((a_{i-1},a_i])=\rho_\mu(a_i)-\rho_\mu(a_{i-1})
\end{align*}
Note that if $f(\alpha)\neq 0$, then by $\Supp_I(f)\subset[\alpha,\beta]$, we must have $\alpha=a\in I$ and hence $I_{<\alpha}=\emptyset$. Therefore, we must have
\begin{align*}
\int_I gd\mu=f(\alpha)\rho_\mu(\alpha)+ S_{\rho_\mu}(f,\sigma,\xi_\blt)
\end{align*}
Combining this fact with $\Vert f-g\Vert_{l^\infty(I)}\leq\eps$, we get
\begin{align*}
\Big| \int_I fd\mu-f(\alpha)\rho_\mu(\alpha)-S_{\rho_\mu}(f,\mu,\xi_\blt)\Big|\leq \eps\cdot\mu(J)
\end{align*}
This inequality, together with \eqref{eq44}, implies
\begin{align*}
\Big| \int_I fd\mu-\int_I fd\rho_\mu\Big|\leq 2\eps\cdot\mu(J)
\end{align*}
Since $\eps$ is arbitrary, we conclude \eqref{eq45}.
\end{proof}







\begin{comment}
\begin{rem}
There is a bijection between:
\begin{itemize}
\item An increasing right-continuous function $\rho:(a,b]\rightarrow\Rbb_{\geq0}$.
\item An increasing right-continuous function $\varrho:[a,b]\rightarrow\Rbb_{\geq0}$.
\end{itemize}
They are related by
\begin{align}
\rho=\varrho|_{(a,b]}
\end{align}
Equivalently, viewing $\rho$ as a function on $[a,b]$ (cf. Conv. \ref{lb10}),
\begin{align}
\rho=\varrho-\varrho(a)\cdot\chi_{\{a\}}\qquad 
\end{align}
Since $\rho=\varrho-\varrho(a)+\varrho(a)\chi_{(a,b]}$ and $\int_a^b fd\chi_{(a,b]}=f(a)$, by Rem. \ref{lb6}, we have
\begin{align}
\int_a^b fd\rho=f(a)\varrho(a)+\int_a^bfd\varrho
\end{align}
These relations allow us to convert the setting of \cite[Sec. 25.7]{Gui-A}, which uses $\varrho$ to present the Riesz representation theorem, to the current setting.
\end{rem}
\end{comment}




\subsubsection{The general case}


\begin{df}
 A real-valued function $I\rightarrow\Fbb$ is called of \textbf{bounded variation} (or simply \textbf{BV}) \index{BV@BV=bounded variation} if it is an $\Fbb$-linear combination of bounded increasing functions $I\rightarrow\Rbb_{\geq0}$. The space of BV functions from $I$ to $\Fbb$ is denoted by $BV(I,\Fbb)$. \index{BV@$BV(I,\Fbb)$}
\end{df}

\begin{rem}
By Rem. \ref{lb65} and \ref{lb6}, we have an $\Rbb_{\geq0}$-bilinear functional
\begin{align*}
(f,\rho)\mapsto \int_I fd\rho\qquad\in\Rbb_{\geq0}
\end{align*}
for $f\in C_c(I,\Rbb_{\geq0})$ and bounded increasing $\rho:I\rightarrow\Rbb_{\geq0}$. Similar to the proof of Rem. \ref{lb12}, it can be extended to a positive $\Cbb$-bililinear functional 
\begin{align*}
C_c(I,\Cbb)\times BV(I,\Cbb)\rightarrow\Cbb\qquad (f,\rho)\mapsto \int_I fd\rho
\end{align*}
\end{rem}


\begin{thm}[\textbf{Riesz representation theorem}]\label{lb10}
The elements of the dual space $C_c(I,\Fbb)^*$ are precisely linear functionals of the form
\begin{gather*}
\Lambda:C(I,\Fbb)\rightarrow\Fbb\qquad f\mapsto\int_I fd\rho
\end{gather*}
where $\rho\in BV(I,\Fbb)$. Moreover, the BV function $\rho$ can be chosen such that it is right-continuous on $I$, and that $\lim_{x\rightarrow a^+}\rho(x)=0$ if $a\notin I$.
\end{thm}

\begin{proof}
This is immediate from Thm. \ref{lb8} and \ref{lb9}.
\end{proof}







\newpage







\section{Normed vector spaces and their dual spaces}


\subsection{The origin of dual spaces in the calculus of variations}\label{lb24}



Linear functional analysis treats function spaces as linear spaces with appropriate geometric/topological structures and analytic properties. In the foundational theory of functional analysis, two analytic properties are especially important: (Cauchy) completeness and duality. In this course, our focus is primarily on normed vector spaces $V$. For such spaces, Cauchy completeness is interpreted in the same way as in any metric space. Duality, on the other hand, refers to the natural identification of $V$ as the dual space $U^*$ of another normed vector space $U$.



Many early results in functional analysis were related to duality, while the significance of completeness was not immediately recognized. In fact, the history of functional analysis experienced a paradigm shift from the study of (scalar-valued) functionals to linear maps between vector spaces. Specifically, attention moved from continuous bilinear maps of the form $U \times V \rightarrow \mathbb{F}$ to the analysis of continuous linear maps $V \rightarrow W$, where $U,V,W$ are normed vector spaces. With this shift, completeness became increasingly central to modern analysis. See Sec. \ref{lb43} for further illustrations.




The early part of this course will also focus more on dual spaces. If $V$ is a normed $\Fbb$-vector space, then the \textbf{dual space} $V^*=\fk L(V,\Fbb)$ is defined to be the space of bounded (i.e. continuous) linear maps $V\rightarrow\Fbb$. One of the major themes in early functional analysis was the characterization of dual spaces of various function spaces under appropriate norms. Among the most notable results are F. Riesz's characterization of $C([a,b], \Rbb)^*$ (cf. Thm. \ref{lb10}) in \cite{Rie09, Rie11}, and his proof that $L^q([a,b],m, \Rbb)^* \simeq L^p([a,b],m, \Rbb)$ (cf. Thm. \ref{lb13}) in \cite{Rie10}. These results highlight a profound connection between dual spaces and measure/integration theory. Nevertheless, the study of dual spaces originally arose from a somewhat different field: the calculus of variations in the 19th century.


Consider a nonlinear functional $S:f\mapsto S(f)\in\Rbb$, for example, of the form
\begin{gather*}
S(f)=\int_a^b L(f(t),f'(t),\dots,f^{(r)}(t))dt
\end{gather*}
where $L$ is a ``nice'' real valued function with $r$-variables, and $f$ is defined on $[a,b]$. If we perturb $f$ slightly by a variation $\eta$, then the corresponding change in $S$ can be approximated by
\begin{align}\label{eq2}
\delta S[f,\eta]:=S(f+\eta)-S(f)\approx \int_a^b  \beta_f(t)\cdot \eta(t)dt
\end{align}
where $\beta_f:[a,b]\rightarrow\Rbb$ is a function depending on $f$. This function should be interpreted loosely. In some cases, it may involve delta functions or similar objects that are not functions in the classical sense, but rather distributions:


\begin{eg}
Consider the case where $L$ is smooth and $r=1$, i.e.
\begin{align*}
S(f)=\int_a^b L(f(t),f'(t))dt
\end{align*}
(For example, $L(x,y)=T(y)-V(x)$ where $T(y)=\frac 12 my^2$ the kinetic energy for the mass $m\in\Rbb_{>0}$, and $V(x)$ is the potential energy at $x$.) Then
\begin{align*}
&\delta S[f,\eta]=\int_a^b L(f+\eta,f'+\eta')\approx \int_a^b (\partial_x L(f,f')\eta+\partial_y L(f,\eta)\eta')\\
=&\partial_yL(f,f')\eta\big|_a^b+\int_a^b (\partial_xL(f,f')-\partial_t\partial_yL(f,f'))\eta
\end{align*}
If we assume that the function $f$ and its variation $\eta$ always vanish at the endpoints $a,b$, then we obtain \eqref{eq2} with
\begin{align*}
\beta_f(t)=\partial_xL(f(t),f'(t))-\partial_t\partial_yL(f(t),f'(t))
\end{align*}
The equation $\beta_f=0$ is called the \textbf{Euler-Lagrange equation}. 

However, if no boundary conditions are imposed on the endpoints, then the term $\partial_yL(f,f')\eta\big|_a^b$ is not necessarily zero. As a result, we have
\begin{align*}
\beta_f=L(f(b),f'(b))\delta_b-L(f(a),f'(a))\delta_a+\partial_xL(f,f')-\partial_t\partial_y(f,f')
\end{align*}
where, for each $c\in\Rbb$, $\delta_c$ is the ``\textbf{delta function}'' \index{00@Delta function $\delta_c$} at $c$, namely, the imaginary function $\Rbb\rightarrow\Rbb_{\geq0}$ vanishing outside $c$ and satisfying $\int_\Rbb\delta_c=1$. The situation becomes even more singular if we define $S$ by
\begin{align*}
S(f)=\sum_{i=1}^n \lambda_i f(c_i)+\int_a^b L(f(t),f'(t))dt
\end{align*} 
where $\lambda_i\in\Rbb$ and $a<c_i<b$, then
\begin{align*}
\beta_f=\sum_{i=1}^n \lambda_i\delta_{c_i}+L(f(b),f'(b))\delta_b-L(f(a),f'(a))\delta_a+\partial_xL(f,f')-\partial_t\partial_y(f,f')
\end{align*}
This raises the question: what should the function $\beta_f$, alternatively the integral operator $\dps\eta\mapsto \int_a^b\beta_f\eta$, actually look like in the general case?  \hfill\qedsymbol
\end{eg}



It is in this context that the problem of classifying bounded linear functionals on $C([a,b],\Rbb)$, originally posed by Hadamard in 1903, should be understood. Recall that if $V,W$ are normed vector spaces, $\Omega\subset V$ is open, and $S:\Omega\rightarrow W$ is a map, one says that $S$ is differentiable at $f\in\Omega$ if 
\begin{align*}
S(f+\eta)-S(f)=\Lambda(\eta)+o(\eta)
\end{align*}
where $\Lambda:V\rightarrow W$ is a bounded linear operator (called the \textbf{differential} of $S$ at $f$), and $\lim_{\Vert\eta\Vert\rightarrow0}o(\eta)/\Vert\eta\Vert=0$. In the calculus of variations, one sets $W=\Fbb$. Then $\Lambda\in V^*$. One can thus understand $\eta\mapsto\delta S[f,\eta]$ as a bounded linear functional on a function space $V$ equipped with a suitable norm.



The problem of expressing $\delta S[f,\eta]$ as an integral involving $\eta$ is therefore transformed to the problem of characterizing the dual space $V^*$. More precisely, the space $V$---and in particular its norm---is not fixed in advance. The situation is not that one starts with a given normed space and is then asked to characterize its dual. Rather, the task is to find an appropriate norm on a suitable function space $V$ such that the bounded linear functionals on $V$, once studied and classified as integrals, are well-suited to capturing the variation of $S$. \footnote{The same function space $V$, when equipped with different norms, leads to different classifications of bounded linear functionals. For example, let $V=C([a,b])$. If the norm is $l^\infty$, then by Thm. \ref{lb10}, the bounded linear functionals are the Stieltjes integrals with respect to BV functions. If the norm is $L^2$, then by Exp. \ref{lb49}, the bounded linear functionals are those of the form $f\mapsto\int fgdm$ where $g\in L^2([a,b],m)$.} \uwave{The two perspectives on $\delta S[f,\eta]$---as a bounded linear functional on $V$, and as an integral involving $\eta$---together offer a deeper and more complete understanding of the variation of $S$.}

More discussion of the relationship between dual spaces and the calculus of variations can be found in \cite{Gray84}.





\subsection{Moment problems: a bridge between integral theory and dual spaces}\label{lb41}




The theory of dual spaces would not have reached its current depth and sophistication if it were developed solely within the framework of the calculus of variations. For instance, Riesz’s classification of the duals of $C([a,b])$ and $L^p([a,b],m)$ would have been impossible without the Lebesgue and Stieltjes integrals. In fact, the very form of Riesz’s theorems presents a striking connection between integration theory and  dual spaces.

But why should such a connection exist in the first place? The way this relationship appears in Riesz’s theorems calls for a deeper explanation.  My short answer is this: \uwave{it is the moment problems that form the bridge between integration theory and the theory of dual spaces}. (Readers may jump ahead to Subsection \ref{lb25} for the detailed final conclusion.)

To clarify my point, consider the first major example of a duality theorem: the identification $(L^2)^*\simeq L^2$ proved by Riesz and Fr\'echet in 1907:

\begin{thm}[\textbf{Riesz-Fr\'echet theorem}, the classical form]\label{lb15}  \index{00@Riesz-Fr\'echet theorem, the classical form}
We have a linear isomorphism
\begin{gather*}
\Lambda:L^2\big([-\pi,\pi],\frac m{2\pi}\big)\rightarrow L^2\big([-\pi,\pi],\frac m{2\pi}\big)^*\\
\bk{\Lambda(f),g}=\frac 1{2\pi}\int_{-\pi}^\pi fgdm
\end{gather*}
\end{thm}
In fact, Riesz studied $L^2$ spaces several years before introducing the more general $L^p$ spaces. His interest in $L^2$ spaces was clearly influenced by Hilbert’s earlier work on the Hilbert space $l^2(\Zbb)$ and its applications to the theory of integral equations. It was Hilbert’s insights that served as the crucial bridge leading to the Riesz-Fr\'echet Thm. \ref{lb15}---the first major result linking Lebesgue integration with dual spaces. 

As I will explain in the following, Hilbert’s role in this development is best understood through the lens of moment problems.


\subsubsection{Moment problems and dual spaces}\label{lb202}


Let me begin by introducing moment problems and explaining how they relate to dual spaces---particularly to the characterization of dual spaces in terms of integral representations.


\begin{problem}[\textbf{Moment problem}, original version]\index{00@Moment problem}\label{lb16}
Let $(\xi_n)$ be a sequence of scalar-valued functions defined on a space, e.g., an interval $I\subset\Rbb$. Choose a sequence of scalars $(c_n)$ satisfying certain conditions. Find a scalar valued function $f$ on $I$ such that for all $n$, we have
\begin{align}\label{eq10}
\int \xi_n f=c_n\qquad\text{resp.}\qquad \int \xi_ndf=c_n
\end{align} 
The numbers $c_1,c_2,\dots$ are called the \textbf{moments}\index{00@Moment} of $f$ resp. $df$. 
\end{problem}



There are two typical types of moment problems:
\begin{itemize}
\item \textbf{Trigonometric moment problem}:\index{00@Trigonometric moment problem} Here $I=\Sbb^1\simeq\Rbb/2\pi\Zbb$, and $\xi_n(x)=e^{-\im nx}$ for $n\in\Zbb$. The problem then amounts to finding a function $f$ with prescribed Fourier coefficients $c_1,c_2,\dots$.
\item \textbf{Polynomial moment problem}:\index{00@Polynomial moment problem} Here $I\subset\Rbb$ is an interval, not necessarily bounded, and $\xi_n(x)=x^n$ for $n\in\Nbb$. One is asked to find an increasing or BV function $f$ such that $df$ has moments $c_1,c_2,\dots$.
\end{itemize}


Many (but not all) moment problems can be reformulated in the language of bounded linear functionals and dual spaces as follows:

\begin{problem}[\textbf{Moment problem}, dual space version]\label{lb17}
Let $(\xi_n)$ be a sequence in a normed vector space $V$, and let  $(c_n)$ be a sequence of scalars. Suppose that there exists $M\in\Rbb_{\geq0}$ such that
\begin{align}\label{eq3}
\Big|\sum_n a_nc_n\Big|\leq M\Big \Vert\sum_n a_n\xi_n\Big\Vert 
\end{align}
for each sequence of scalars $(a_n)$ with finitely many nonzero terms. Find $\varphi\in V^*$ such that
\begin{align}\label{eq4}
\bk{\xi_n,\varphi}=c_n\qquad\text{for all }n
\end{align}
\end{problem}

\begin{rem}
Note that \eqref{eq3} is necessary for the existence of $\varphi$ satisfying \eqref{eq4}, because
\begin{align*}
\Big|\sum_n a_nc_n\Big|=\Big|\bigbk{\sum_n a_n\xi_n,\varphi} \Big|\leq \Vert\varphi\Vert\cdot \Big\Vert\sum_n a_n\xi_n\Big\Vert 
\end{align*}
where $\Vert\varphi\Vert$ is the operator norm. Hence \eqref{eq3} holds for any $M$ satisfying $\Vert\varphi\Vert\leq M$. 

Conversely, if we know that $V_0=\Span\{\xi_n\}$ is dense in $V$, then \eqref{eq3} guarantees that the linear functional
\begin{align*}
\varphi:V_0\rightarrow\Fbb\qquad \sum_n a_n\xi_n\mapsto \sum_n a_n c_n
\end{align*}
is well-defined and bounded, with operator norm $\Vert\varphi\Vert\leq M$. By boundedness, $\varphi$ extends uniquely to a bounded linear functional on all of $V$, cf. Thm. \ref{lb31}. Therefore, Problem \ref{lb17} can always be solved.

The case where $V_0$ is not dense in $V$ is more subtle and will be treated in detail in Ch. \ref{lb355}.   \hqed
\end{rem}


Once Problem \ref{lb17} is resolved---for example, when $\Span\{\xi_n\}$ is dense in $V$---Problem \ref{lb16} can be solved by answering the following:

\begin{problem}[\textbf{Characterization of the dual space}]\label{lb22}
Characterize the elements of $V^*$ as precisely those linear functionals $\varphi:V\rightarrow\Fbb$ of the form
\begin{align*}
\bk{\xi,\varphi}=\int\xi f{\text{~ resp.~ }} \int\xi df
\end{align*}
(for all $\xi\in V$), where $f$ is a function satisfying suitable regularity or integrability conditions.
\end{problem}


Conversely, Problem \ref{lb22} can be reduced to the moment Problem \ref{lb16} by choosing a densely-spanning $(\xi_n)$ and taking $c_n=\bk{\xi_n,\varphi}$. The solution to Problem \ref{lb16} then yields a function $f$ such that $\bk{\xi_n,f}=\bk{\xi_n,\varphi}$. By the density of $\Span\{\xi_n\}$ in $V$, it follows that $\varphi$ is represented by $f$. 

Thus, we conclude that when $(\xi_n)$ spans a dense subspace of $V$, \uwave{the moment problem (Problem \ref{lb16}) and the characterization of dual spaces (Problem \ref{lb22}) are equivalent}.





\subsubsection{Moment problems and integral theory/function theory}\label{lb19}


In the remainder of this section, we focus on the case where the sequence of functions $(\xi_n)$ is ``sufficiently rich'', for example, when it spans a dense subspace of $V$ in Problem \ref{lb17}. Under this assumption, the function $f$ (resp. $df$) in Problem \ref{lb16} or the functional $\varphi$ in Problem \ref{lb17} is uniquely determined by the moments $(c_n)$. Therefore, $(c_n)$ can be understood as the \textbf{coordinates} of $f$ (resp. $df$) and $\varphi$ under the \textbf{coordinate system} $(\xi_n)$.


We now explain how the moment problems connect to integral theory---in other words, to \textbf{function theory}. A central theme in function theory is the approximation of abstract or complicated functions by simpler, more elementary ones. This motivation often arises from practical mathematical problems, particularly those originating in physics, where one seeks to express the solution as a series of elementary functions, such as a power series or a Fourier series. The question of how such series should converge---uniformly, pointwise, or in some other sense---and what kinds of functions they can approximate was a central focus of function theory in the 18th and 19th centuries.


The first step in understanding and solving the approximation problem is to analyze the corresponding moment problem. A typical scenario unfolds as follows. In the setting of Problem \ref{lb16}, suppose there exists a sequence of elementary functions $(f_n)$ such that
\begin{align}\label{eq5}
\int \xi_k f_n\quad\text{resp.}\quad \int \xi_kdf_n\quad=c_k\qquad \text{when $|k|\leq |n|$}
\end{align}
This situation arises, for instance, in the study of continued fractions and polynomial moments, where $\xi_k(x)=x^k$. In the case of Fourier series, an even stronger condition holds:
\begin{align}\label{eq6}
\int \xi_k f_n\quad\text{resp.}\quad\int \xi_k df_n\quad=\left\{
\begin{array}{ll}
c_k&\text{if }|k|\leq |n|\\[0.5ex]
0&\text{if }|k|>|n|
\end{array}
\right.
\end{align}
where $\xi_k(x)=e^{-\im kx}$ and $f_n(x)=\sum_{|k|\leq n}c_k e^{\im kx}$. The approximation problem asks:

\begin{problem}\label{lb18}
Does the sequence $(f_n)$ converge to some function $f$? If so, in what sense does it converge? 
\end{problem}

To approach this problem, observe that if such a function $f$ exists, and if the integral commutes with the convergence of sequence of functions, then
\begin{subequations}\label{eq7}
\begin{align}
\int \xi_k f=\int\lim_{|n|\rightarrow\infty}\xi_kf_n=\lim_{|n|\rightarrow\infty}\int \xi_kf_n\xlongequal{\eqref{eq5}}c_k
\end{align}
resp.
\begin{align}\label{eq7b}
\int \xi_k df=\int\lim_{|n|\rightarrow\infty}\xi_kdf_n=\lim_{|n|\rightarrow\infty}\int \xi_kdf_n\xlongequal{\eqref{eq5}}c_k
\end{align}
\end{subequations}
Therefore, \uwave{the first step in solving Problem \ref{lb18} is to find a function $f$ solving the moment Problem \ref{lb16}}. Once such an $f$ is found, the next step is to prove that the sequence $(f_n)$ converges to $f$, and investigate the mode of convergence.


Historically, the understanding of convergence, the properties of the limiting function $f$, and the integrals appearing in \eqref{eq7} was often insufficient to resolve the approximation problem at the outset. In many cases, addressing the approximation problem required the development of new theories of integration or the extension of the class of integrable functions. Both the Lebesgue and Stieltjes integrals emerged from such needs. For instance, the challenges posed by Fourier series played a central role in motivating the development of the Riemann and later the Lebesgue integral. See \cite[Ch. 6, 9]{Jah} and \cite{Haw-L} for a detailed discussion of how Fourier series drove this evolution. The connection between continued fractions and the Stieltjes integral will be explored in Ch. \ref{lb114}. 

\begin{table}[h]
\centering
 \begin{tabular}{|c|c|c|}
    \hline 
Function theory& \rule{0pt}{0.45cm} Moment Problems & Dual spaces\\
\hline
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Lebesgue integral} \\
\&\\
\text{Fourier series}
\end{array}$& Fourier coefficients&$L^2([a,b],m)^*$\\
\hline 
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Stieltjes integral} \\
\&\\
\text{Continued fractions}
\end{array}$
&Polynomial moments&$C([a,b])^*$\\
\hline
  \end{tabular}
\caption{The origin of moment problems in function theory}\label{tb2}
\end{table}



\subsubsection{Convergence of functions, moments, and linear functionals}





In the previous subsection, we noted that solving moment problems determines the function $f$ that appears in Problem \ref{lb18}. But can the moment problem perspective also help us understand the convergence of $f_n$ to $f$? Or conversely, can the convergence behavior of $f_n$ toward $f$ offer deeper insight into the structure of moment problems themselves? Thanks to Hilbert's foundational work on the Hilbert space $l^2(\Zbb)$---especially his groundbreaking 1906 paper \cite{Hil06}---the answer is yes.\footnote{Indeed, Hilbert originally worked with the real Hilbert space $l^2(\Zbb,\Rbb)$, rather than the complex one $l^2(\Zbb)=l^2(\Zbb,\Cbb)$. For clarity and simplicity, however, we will work with $l^2(\Zbb)$ in what follows.} 


A key concept introduced by Hilbert in \cite{Hil06} is \textbf{weak convergence}: If $(\psi_n)$ is a sequence in $l^2(\Zbb)$ with uniformly bounded norm, i.e.,
\begin{align}\label{eq11}
\sup_n\Vert\psi_n\Vert_2<+\infty
\end{align}
we say that $(\psi_n)$ converges weakly to $\psi\in l^2(\Zbb)$ if it converges pointwise $\Zbb$, i.e.,
\begin{align}\label{eq8}
\lim_n\psi_n(k)=\psi(k)\qquad\text{for all }k\in\Zbb
\end{align}
Since $l^2(\Zbb)$ is typically interpreted as the space of Fourier series of $L^2$-integrable functions, Hilbert's notion of weak convergence corresponds to the (pointwise) convergence of Fourier coefficients. That is,
\begin{align*}
\lim_n \wht f_n(k)=\wht f(k)\qquad\text{for all }k\in\Zbb
\end{align*}
where $f_n$ and $f$ are $L^2$-integrable functions on $[-\pi,\pi]$.\footnote{Hilbert himself did not initially connect $l^2(\Zbb)$ with the Lebesgue integral. The precise relationship between $l^2(\Zbb)$ and $L^2([-\pi,\pi],\frac m{2\pi})$ was later clarified by Riesz and Fischer in 1907.}


The notion of weak convergence---later extended to weak-* convergence---provided a fundamentally new insight into the study of moment problems and their connection to dual spaces and function theory/integral theory. Since Fourier coefficients are simply trigonometric moments, the weak convergence described by \eqref{eq8} can be understood as the (pointwise) \textbf{convergence of moments}, which means, in the setting of the moment Problem \ref{lb16}, that
\begin{align}\label{eq9}
\lim_n\int \xi_kf_n\quad\text{resp.}\quad\lim_n\int\xi_k df_n\quad=c_n\qquad\text{for all }k
\end{align}


The translation of \eqref{eq9} into the setting of the dual space version of the moment Problem \ref{lb17} is straightforward: One considers a sequence $(\varphi_k)$ in $V^*$ such that $\lim_n\bk{\xi_k,\varphi_n}=\bk{\xi_k,\varphi}$ holds for all $k$. Since we have assumed at the beginning of Subsec. \ref{lb19} that $(\xi_n)$ spans a dense subspace of $V$, it follows from \eqref{eq11} that \uwave{this convergence of moments is equivalent to the \textbf{weak-* convergence}} of $(\varphi_n)$ to $\varphi$. That is, we say that $(\varphi_n)$ converges weak-* to $\varphi$ if
\begin{align}\label{eq13}
\lim_n\bk{\xi,\varphi_n}=\bk{\xi,\varphi}\qquad\text{for all }\xi\in V
\end{align}
Thus, the second and third columns of Table \ref{tb1} are equivalent. See Thm. \ref{lb80} for the formal statement of this equivalence.



On the other hand, \eqref{eq9} generalizes the condition \eqref{eq5}, which, as previously mentioned, arises naturally in the study of Fourier series and continued fractions. As such, its function-theoretic interpretation---highlighted by the following theorems---provides a general framework for understanding the convergence of the sequence $(f_n)$ to $f$ in Problem \ref{lb18}. 


\begin{thm}\label{lb356}
Let $1<p\leq+\infty$ and $p^{-1}+q^{-1}=1$. Let $(f_n)$ be a uniformly $L^p$-norm bounded sequence in $L^p([a,b],m)$. Suppose that $(f_n)$ converges pointwise to $f$. Then we have $f\in L^p([a,b],m)$. Moreover,  $(f_n)$ converges weak-* to $f$, which means that $\lim_n\int f_ngdm=\int fgdm$ for all $g\in L^q([a,b],m)$.
\end{thm}

\begin{proof}
See Thm. \ref{lb81}.
\end{proof}




\begin{thm}\label{lb20}
Let $1<p\leq+\infty$ and $p^{-1}+q^{-1}=1$. Let $(f_n)$ be a uniformly $L^p$-norm bounded sequence in $L^p([a,b],m)$. Then $(f_n)$ converges weak-* to some element of $L^p([a,b],m)$  iff the limit
\begin{align}\label{eq14}
F(x):=\lim_n \int_a^x f_ndm
\end{align}
exists for every $x\in[a,b]$. Moreover, if $f\in L^p([a,b],m)$, then $(f_n)$ converges weak-* to $f\in L^p([a,b],m)$ iff for each $x\in[a,b]$ we have
\begin{align}\label{eq12}
F(x)=\int_a^x fdm
\end{align}
\end{thm}

\begin{proof}
If $(f_n)$ converges weak-* to $f$, then $\lim_n \int f_n\chi_{[a,x]}=\int f\chi_{[a,x]}$, which implies that $F(x)$ exists and equals $\int_a^x fdm$. 

The other direction is more difficult. Indeed, it is almost equivalent to the duality $L^p([a,b],m)\simeq L^q([a,b],m)^*$. See Thm. \ref{lb78}. A classical proof is as follows. One shows that $F:=\eqref{eq14}$ is absolutely-continuous. Thus, its a.e. derivative $f=F'$ is integrable, and $\int f\chi_{[a,x]}=\int_a^x F'=F(x)=\lim_n \int f_n\chi_{[a,x]}$ by the fundamental theorem of calculus for the Lebesgue integral. Thus $\int fg=\lim_n \int f_ng$ for each step function $g$. From this fact and the density of step functions in $L^p([a,b],m)$ (cf. Thm. \ref{lb77}), one shows that $f\in L^p$ (by showing $\Vert f\Vert_p\leq\sup_n\Vert f_n\Vert_p$) and that $(f_n)$ converges weak-* to $f$.
\end{proof}

\begin{comment}

Conversely, assume that $F(x)$ exists for all $x$. Let $M=\sup_n\Vert f_n\Vert_p$, which by assumption is finite. For each $\eps>0$ and for each mutually disjoint intervals $I_1=(a_1,b_1),\dots,I_k=(a_k,b_k)$ in $[a,b]$ with total length $\leq M^{-q}\eps^q$, setting $I=I_1\cup\cdots\cup I_k$, we have
\begin{align*}
\sum_{i=1}^k |F(b_i)-F(a_i)|\leq\sum_{i=1}^k \limsup_n\int_{I_i} |f_n|dm\leq M\Vert\chi_I\Vert_q=M\cdot m(I)^{\frac 1q}\leq \eps
\end{align*}
Therefore $F$ is absolutely continuous. Thus, $f:=F'$ exists a.e. and is $L^1$, and \eqref{eq12} holds for all $f$.
\end{comment}



\begin{thm}\label{lb21}
Let $(\rho_n)$ be a uniformly $l^\infty$-bounded sequence of increasing functions $[a,b]\rightarrow\Rbb_{\geq0}$.  The following are true.
\begin{enumerate}
\item Let $\rho:[a,b]\rightarrow\Rbb_{\geq0}$ be bounded and increasing. Then $(d\rho_n)$ converges weak-* to $d\rho$ iff $(\rho_n)$ converges pointwise to $\rho$ at $b$ and at any point where $\rho|_{(a,b)}$ is continuous.
\item $(d\rho_n)$ converges weak-* to $d\rho$ for some bounded increasing $\rho:[a,b]\rightarrow\Rbb_{\geq0}$ iff $(\rho_n)$ converges pointwise at $b$ and on a dense subset of $I$.
\end{enumerate}
\end{thm}

By saying that $(d\rho_n)$ converges weak-* to $d\rho$, we mean $\lim_n \int gd\rho_n=\int gd\rho$ for all $g\in C([a,b],m)$.

\begin{proof}
See Thm. \ref{lb92} and Cor. \ref{lb95}.
\end{proof}

The above theorems establish an intimate connection between the (pointwise) convergence of moments and the pointwise convergence of (the antiderivatives of) a sequence of functions.\footnote{We are viewing $\rho_n$ and $\rho$ as the antiderivatives of $d\rho_n$ and $d\rho$.} Our understanding of convergence from various perspectives can thus be summarized in Table \ref{tb1}.

\begin{table}[H]
\centering
 \begin{tabular}{|c|c|c|}
    \hline \rule{0pt}{0.45cm}
Function theory & Moment Problems & Dual spaces\\
\hline 
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Pointwise convergence} \\
\text{of (antiderivatives of)}\\
\text{a sequence of functions}
\end{array}$
& 
$\begin{array}{c}
\text{Pointwise convergence} \\
\text{of moments}\\
\end{array}$
 & Weak-* convergence\\
\hline
  \end{tabular}
\caption{Equivalence of convergence notions}\label{tb1}
\end{table}


\subsubsection{Equivalence of the first and second columns of Table \ref{tb1}}\label{lb107}



Thm. \ref{lb20} and \ref{lb21}, which establish the equivalence of the first and second columns of Table \ref{tb1}, are not easy to prove. In fact, proving Thm. \ref{lb20} typically requires the duality $L^p([a,b])\simeq L^q([a,b])^*$, or at least techniques closely related to those used in establishing this duality. 


Therefore, the solvability of the moment problems (Problems \ref{lb16})---equivalently, the solvability of Problem \ref{lb22} concerning the characterization of dual spaces---is closely related to the equivalence between the first and second columns of Table \ref{tb1}. This close connection rests on the following principle:

\begin{principle}\label{lb23}
Usually, if $V$ is a normed vector space consisting of functions,  any element $\varphi$ of $V^*$ can be weak-* approximated by elementary functions with uniformly bounded norms. More precisely, there exists a sequence (or a net) of elementary functions $(f_n)$ such that the operator norms of the linear functionals $\xi\in V\mapsto\int \xi f_n$ are uniformly bounded, and
\begin{align*}
\lim_n \int\xi f_n=\bk{\xi,\varphi}\qquad\text{for all }\xi\in V
\end{align*}
\end{principle}


\begin{rem}\label{lb110}
Here is how, with the help of Principle \ref{lb23}, the characterization of $V^*$ can be derived from the equivalence of the first and second columns of Table \ref{tb1}: 

By this principle, for each $\varphi\in V^*$, we can select a sequence $(f_n)$  approximating weak-* to $\varphi$. Since the second column of Table \ref{tb1} implies the first column, the sequence $(f_n)$ converges to some function $f$ in the sense described in the first column of Table \ref{tb1}. Then, by the equivalence of the three modes of convergence in that table, it follows that $(f_n)$ converges weak-* to $f$. Consequently, $\varphi$ is represented by integration against $f$, thereby solving the problem of characterizing the dual space $V^*$. \hqed
\end{rem}

The idea outlined in Rem. \ref{lb110} is roughly the approach Riesz employed in \cite{Rie07a} to solve the following trigonometric moment problem. See \cite[Ch. 6]{Haw-L} or \cite{Rie07a}.

\index{00@Riesz-Fischer theorem, Riesz's original version}
\begin{thm}[\textbf{Riesz-Fischer theorem}, Riesz's original version]\footnote{The modern interpretation of the Riesz-Fischer theorem as stating that $L^2(X,\mu)$ (or more generally $L^p(X,\mu)$) is Cauchy-complete for any measure space $(X,\mu)$ has led to a significant misunderstanding. In fact, while Fischer formulated the theorem for $L^2([-\pi,\pi],\frac m{2\pi})$ in terms of Cauchy sequences, Riesz understood it quite differently---through the lens of moment problems.

Therefore, once Riesz realized that solving moment problems is equivalent to the characterization of dual spaces, he immediately obtained the Riesz-Fr\'echet Thm. \ref{lb15} in \cite{Rie07b}. As we have emphasized at the beginning of Sec. \ref{lb24}, completeness and duality are fundamentally distinct properties, each serving distinct purposes and arising from different considerations. The fact that they coincide in the case of inner product spaces is purely a coincidence.}
For each $(c_k)_{k\in\Zbb}$ in $l^2(\Zbb)$, there is a (necessarily unique) $f\in L^2([-\pi,\pi],\frac m{2\pi})$ whose Fourier series is equal to $(c_k)$.
\end{thm}


\begin{proof}[\textbf{Riesz's proof}]
Choose $(c_k)_{k\in\Zbb}$ in $l^2(\Zbb)$. Riesz aimed to solve the moment problem that there exists $f\in L^2$ such that $\frac{1}{2\pi}\int fe_{-k}=c_k$ for all $k\in\Zbb$, where $e_k(x)=e^{\im kx}$. For each $0<r<1$, let
\begin{align*}
f_r=\sum_{n\in\Zbb}r^{|n|}c_ne_n
\end{align*}
which belongs to $C^\infty(\Sbb^1)$. Then $\lim_{r\rightarrow 1}f_r$ converges weak-* to the bounded linear functional $\varphi\in (L^2)^*$ satisfying $\bk{e_{-k},\varphi}=c_k$ for all $k$. (This is an instance of Principle \ref{lb23}.) %\footnote{Riesz's original proof does not use the language of linear functionals.} 


Using a result of Fatou, Riesz showed that $\lim_{r\rightarrow 1}f_r$ converges a.e. to some Lebesgue-measurable function $f$, thereby partially illustrating that the second cell of Table \ref{tb1} implies the first. %\footnote{Indeed, $f$ was defined in \cite{Rie07a} as the derivative of the absolutely continuous function $F(x)=\lim_{n\rightarrow\infty}\int_{-\pi}^x g_n$ where $g_n=\sum_{k=-n}^n c_ke_k$. Note that $(g_n)$ also converges weak-* to $\varphi$, again illustrating Principle \ref{lb23}.}
Using Thm. \ref{lb356}, Riesz deduced that $f\in L^2$, and that $\lim_{r\rightarrow 1}f_r$ converges weak-* to $f$. This can be seen as an example that the first cell of Table \ref{tb1} implies the second one. Since $\lim_{r\rightarrow 1}f_r$ also converges weak-* to $\varphi$, we conclude that $\varphi$ is represented by the integral against $f$, and hence $f$ solves the desired moment problem. \footnote{Another proof using the equivalence in Table \ref{tb1}: Let $f_n=\sum_{k=-n}^n c_ke_k$. Then $(f_n)$ converges weak-* to $\varphi$, again illustrating Principle \ref{lb23}. One easily shows that $\lim_n\int_{-\pi}^xf_n$ converges for each $x$. Therefore, by Thm. \ref{lb20}, $(f_n)$ converges weak-* to some $L^2$-function $f$. Hence $f$ solves the desired moment problem.}
\end{proof}

%Note that the fundamental theorem of calculus for the Lebesgue integral is crucial to the above proof. Likewise, the Radon-Nikodym Thm. \ref{lb27}---a modern form of the fundamental theorem of calculus---also plays a central role in the proof of Theorem \ref{lb13}, which establishes the duality \ref{lb13} on $L^p(X,\mu)\simeq L^q(X,\mu)^*$. This reinforces the point that the characterization of dual spaces is deeply connected to the equivalence between the first and second columns of Table \ref{tb1}. 

See \cite[Sec. 27.3]{Gui-A} for further discussion on the relationship between the classical and modern proofs of the duality $L^p\simeq(L^q)^*$, and the connection between this duality and the completeness of $L^p$-spaces. In Ch. \ref{lb114}, we will see that the strategy outlined in Rem. \ref{lb110} was also the original approach used to study polynomial moment problems, i.e., the moment problems related to the dual space of $C(I)$.

%and the role of derivatives---both in the classical sense and in the form of Radon-Nikodym derivatives---in this context.



\subsubsection{Conclusion}\label{lb25}


We now summarize the discussion so far by addressing the question posed at the beginning of this section: Why are dual spaces related to integral theory? More specifically, from the mathematical-historical perspective, why is it possible to characterize the dual spaces of $L^p(X,\mu)$ and $C(X)$?

\begin{table}[h]
\centering
 \begin{tabular}{|c|c|c|}
    \hline \rule{0pt}{0.45cm}
Function theory & Moment Problems & Dual spaces\\
\hline & \rule{0pt}{0.5cm} Solving moment problems &Characterizing $V^*$\\
\hline\multicolumn{3}{|c|}{\rule{0pt}{0.5cm}  Related by \scalebox{1.3}{$\Updownarrow$} Principle \ref{lb23} } \\
\hline 
\cellcolor{gray!20}$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Pointwise convergence} \\
\text{of (antiderivatives of)}\\
\text{a sequence of functions}
\end{array}$
& 
\cellcolor{gray!20}$\begin{array}{c}
\text{Pointwise convergence} \\
\text{of moments}\\
\end{array}$
 & Weak-* convergence\\
\hline
  \end{tabular}
\caption{The cells in each row are equivalent}\label{tb4}
\end{table}



The answer, in my view, is captured in Table \ref{tb4}: The power of the Lebesgue and Stieltjes integrals lies in their ability to establish the equivalence between the two gray cells in that table. Once this equivalence is established, with the help of Principle \ref{lb23}, the characterization of dual spaces in terms of integrals becomes straightforward.

But why are these two integrals powerful enough to establish the equivalence between the two gray cells in Table \ref{tb4}?---Because both the Lebesgue and Stieltjes integrals arise from the study of moment problems, which in turn are rooted in the corresponding approximation problems, as illustrated in Table \ref{tb2}. The emphasis of these integral theories on the commutativity of limits and integration anticipates the equivalence of the two gray cells.

In light of the equivalences in Table \ref{tb4}, the Lebesgue integral, as the completion of the Riemann integral, can be interpreted as the weak-* completion of trigonometric functions and continuous functions. Similarly, the Stieltjes integral, as the completion of finite sums, can be viewed as the weak-* completion of discrete spectra---a perspective that will be one of the main themes of Ch. \ref{lb114} and \ref{lb181}. See Table \ref{tb3}.







\begin{table}[H]
\centering
 \begin{tabular}{|c|c|c|}
    \hline 
Completion of Integrals &$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Extension of} \\
\text{classes of functions}
\end{array}$  & \textbf{Weak-* completion}\\
\hline 
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Riemann integral} \\
\cap\\
\text{Lebesgue integral}
\end{array}$
& 
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Continuous functions} \\
\cap\\
\text{Measurable functions}
\end{array}$
 & of continuous functions\\
\hline 
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Finite sum} \\
\cap\\
\text{Stieltjes integral}
\end{array}$
& 
$\begin{array}{c}
\rule{0pt}{0.45cm}\text{Discrete spectra} \\
\cap\\
\text{Continuous spectra}
\end{array}$
 & of discrete spectra\\
\hline
  \end{tabular}
\caption{}\label{tb3}
\end{table}







\begin{comment}
Let us return to Hilbert’s contribution in \cite{Hil06} from the perspective of moment problems. 
\begin{itemize}
\item In his study of integral equations, Hilbert introduced the general notion of weak convergence in $l^2(\Zbb)$, which takes the form of pointwise convergence of moments and anticipates the future notion of  weak-* convergence. 

More specifically, Hilbert considered a completely continuous, self-adjoint, bounded linear operator\footnote{More precisely, Hilbert worked with a bilinear form.} $T$ on $l^2(\Zbb)$, and his goal was to find the eigenvectors of $T$. To identify an eigenvector $\xi\in l^2(\Zbb)$ of unit norm corresponding to the largest (real) eigenvalue $\lambda$, he constructed a sequence $(\xi_n)$ in the closed unit ball $\ovl B_{l^2(\Zbb)}(0,1)$ such that $\bk{T\xi_n|\xi_n}\rightarrow\lambda$, and that $(\xi_n)$ converges weakly to some $\xi\in \ovl B_{l^2(\Zbb)}(0,1)$. 
\item In his proof of the spectral theorem for bounded self-adjoint operators on $l^2(\Zbb)$---not necessarily completely continuous---Hilbert approximated the continuous spectrum using discrete spectra. This approximation takes the form of the convergence of a sequence of increasing functions $\rho_n\rightarrow\rho$. This mode of convergence is more general than that used earlier by Stieltjes in his study of continued fractions---just as the convergence of moments described in \eqref{eq9} is a generalization of the more specific form given in \eqref{eq5}.\footnote{Hilbert did not express his approximation in terms of the pointwise convergence of moments. This reformulation, connecting Hilbert's approach to the framework of moment problems and dual spaces, was later introduced by Riesz in \cite{Rie13}.}
\end{itemize}


For a detailed discussion of the first part, see \cite[Sec. 22.5]{Gui-A}; we will also revisit this topic in Ch. 6. The second part will be addressed in the following chapter.
\end{comment}



\noindent \small\textit{Side note.}  A common viewpoint---motivated by the completeness of $L^1$-spaces---regards the Lebesgue integral and the Lebesgue measurable/integrable functions as the Cauchy completion of Riemann integrals and continuous functions. In my view, this perspective is not only historically inaccurate, but also mathematically misleading.

Historically, the first $L^p$-space considered is $L^2([a,b],m)$, due to its close relation with $l^2(\Zbb)$, the space of trigonometric moments of $L^2$-integrable functions. The space $l^2(\Zbb)$ was introduced by Hilbert in \cite{Hil06}, where weak convergence (equivalently, pointwise convergence of moments) plays a central role in his proof of the Hilbert-Schmidt theorem. In \cite{Rie10}, Riesz studied the space $L^p([a,b],m)$ for $1<p<+\infty$, and in particular proved the duality $L^p([a,b],m)\simeq L^q([a,b],m)^*$. The completeness of $L^p([a,b],m)$ follows as a corollary. However, $L^1([a,b],m)$ was not considered, likely due to its lack of a satisfactory duality structure. This clearly shows that duality was originally viewed as more fundamental than Cauchy completeness.


Mathematically, to perform a Cauchy completion, one needs a norm, which in this context is defined via an integral. Yet, while integrals are linear functionals, norms only satisfy the subadditivity. As a result, norms and Cauchy completions do not provide the right conceptual framework for understanding the nature of the Lebesgue integral from a functional-analytic perspective.


The more appropriate viewpoint is to regard the Lebesgue integral as arising from weak-* completion, not Cauchy completion.

\normalsize





\subsection{Bounded multilinear maps}


\subsubsection{Seminorms, norms, and normed vector spaces}

\begin{df}\label{lb45}
If $V$ is an $\Fbb$-vector space, a function $\Vert\cdot\Vert:V\rightarrow\Rbb_{\geq0}$ is called a \textbf{seminorm} \index{00@Seminorm} if
\begin{align}\label{eq28}
\Vert av\Vert=|a|\cdot\Vert v\Vert\qquad \Vert u+v\Vert\leq\Vert u\Vert+\Vert v\Vert\qquad\text{for any $u,v\in V$ and $a\in\Fbb$}
\end{align}
A seminorm is called a \textbf{norm} if any $v\in V$ satisfying $\Vert v\Vert=0$ is the zero vector $0$. A vector space $V$, equipped with a norm, is called a \textbf{normed vector space}.

If $V$ is a normed vector space, then a \textbf{normed vector subspace} \index{00@Normed vector subspace} of $V$ denotes a linear subspace $U\subset V$ equipped with the norm inherited from $V$, i.e., the restriction of $V$'s norm to $U$.  

We say that $V$ is \textbf{separable} \index{00@Separable normed vector spaces} if it is so in the \textbf{norm topology}, \index{00@Norm topology} namely, the topology induced by the metric $d(u,v)=\Vert u-v\Vert$. \hqed
\end{df}

\begin{rem}\label{lb46}
In Def. \ref{lb45}, the condition $\Vert av\Vert=|a|\cdot\Vert v\Vert$ can be weakened to
\begin{align}\label{eq29}
\Vert av\Vert\leq|a|\cdot\Vert v\Vert\qquad\text{for any $v\in V$ and $a\in\Fbb$}
\end{align}
Therefore, \eqref{eq28} can be weakened to
\begin{align}
\Vert au+bv\Vert\leq |a|\cdot\Vert u\Vert+|b|\cdot\Vert v\Vert\qquad\text{for any $u,v\in V$ and $a,b\in\Fbb$}
\end{align}
\end{rem}

\begin{proof}
Suppose that \eqref{eq29} is true. Then we clearly have $\Vert av\Vert=|a|\cdot\Vert v\Vert$ when $a=0$. Suppose that $a\neq 0$. Then $\Vert v\Vert=\Vert a^{-1}av\Vert\leq |a|^{-1}\Vert a v\Vert$, and hence $\Vert av\Vert\geq |a|\cdot\Vert v\Vert$. Therefore $\Vert av\Vert=|a|\cdot\Vert v\Vert$.
\end{proof}



\begin{rem}\label{lb59}
The norm function $\Vert\cdot\Vert:V\rightarrow\Rbb_{\geq0}$ is continuous. This is because
\begin{align}
\Vert u\Vert-\Vert v\Vert\leq \Vert u-v\Vert
\end{align}
Therefore, if $(v_\alpha)$ is a net in $V$ converging (in norm) to $v$, then
\begin{align*}
\Vert v\Vert=\lim_\alpha\Vert v_\alpha\Vert
\end{align*}
\end{rem}

\begin{pp}\label{lb47}
Let $\Vert\cdot\Vert_V$ be a seminorm on an $\Fbb$-vector space $V$. Let $V_0=\{v\in V:\Vert v\Vert_V=0\}$. Then $V_0$ is a linear subspace on $V$, and there is a (clearly unique) norm $\Vert\cdot\Vert_{V/V_0}$ on the quotient space $V/V_0$ such that
\begin{align}\label{eq27}
\Vert v+V_0\Vert_{V/V_0}=\Vert v\Vert_V\qquad\text{for all }v\in V
\end{align}
\end{pp}

In the future, unless otherwise stated, we will always equip $V/V_0$ with this norm $\Vert\cdot\Vert_{V/V_0}$.

\begin{proof}
We abbreviate $\Vert\cdot\Vert_V$ to $\Vert\cdot\Vert$. If $u,v\in V_0$ and $a,b\in\Fbb$, then
\begin{align*}
\Vert au+bv\Vert\leq |a|\Vert u\Vert+|b|\Vert v\Vert=0
\end{align*}
This shows that $V_0$ is a linear subspace of $V$. On the other hand, if $u,v\in V$ satisfy $u+V_0=v+V_0$, then $u-v\in V_0$, and hence
\begin{align*}
\Vert v\Vert=\Vert u+v-u\Vert\leq\Vert u\Vert+\Vert v-u\Vert=\Vert u\Vert
\end{align*}
Similarly, $\Vert u\Vert\leq\Vert v\Vert$. Therefore $\Vert u\Vert=\Vert v\Vert$. This implies that we have a well-defined function $\Vert\cdot\Vert_{V/V_0}:V/V_0\rightarrow\Rbb_{\geq0}$ satisfying \eqref{eq27}.

If $u,v\in V$ and $a,b\in\Fbb$, then
\begin{align*}
&\Vert a(u+V_0)+b(v+V_0)\Vert_{V/V_0}=\Vert au+bv+V_0\Vert_{V/V_0}=\Vert au+bv\Vert\\
\leq& |a|\Vert u\Vert+|b|\Vert v\Vert=|a|\Vert u+V_0\Vert_{V/V_0}+|b|\Vert v+V_0\Vert_{V/V_0}
\end{align*}
\end{proof}








\subsubsection{Bounded multilinear maps}

In the rest of this section,  $V_1,V_2,\dots$ and $U,V,W$ all denote normed $\Fbb$-vector spaces.

\begin{df}
Let $N\in\Zbb_+$. A map $T:V_1\times\cdots\times V_N\rightarrow W$ is called a \textbf{multilinear map} \index{00@Multilinear map} if for each $1\leq i\leq N$ and each fixed $v_j\in V_j$ (for all $j\neq i$), the map
\begin{align*}
v_i\in V_i\mapsto T(v_1,\dots,v_N)\in W
\end{align*}
is $\Fbb$-linear. We let \index{Lin@$\Lin(V_1\times\cdots\times V_N,W)$}
\begin{align*}
\pmb{\Lin(V_1\times\cdots\times V_N,W)}=\{\text{multilinear maps }V_1\times\cdots\times V_N\rightarrow W\}
\end{align*}
For each $T\in \Lin(V_1\times\cdots\times V_N,W)$, we define the \textbf{operator norm}\index{00@Operator norm $\Vert T\Vert$}\index{T@$\Vert T\Vert$, the operator norm of $T$}
\begin{align*}
\Vert T\Vert:=\Vert T\Vert_{l^\infty(\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1),W)}=\sup_{v_1\in\ovl B_{V_1}(0,1),\dots,v_N\in\ovl B_{V_N}(0,1)}\Vert T(v_1,\dots,v_N)\Vert
\end{align*}
We say that $T$ is \textbf{bounded} \index{00@Bounded multilinear map} if $\Vert T\Vert<+\infty$. 
\end{df}


\begin{df}\label{lb116}
We let \index{LV@$\fk L(V_1\times\cdots\times V_N,W)$}
\begin{gather}\label{eq26}
\pmb{\fk L(V_1\times\cdots\times V_N,W)}:=\{\text{bounded multilinear maps }V_1\times\cdots\times V_N \rightarrow W\}
\end{gather}
viewed as an $\Fbb$-linear subspace of $W^{V_1\times\cdots\times V_N}$. We let \index{LV@$\fk L(V)$} \index{V@$V^*=\fk L(V,\Fbb)$}
\begin{align*}
\fk L(V):=\fk L(V,V)\qquad V^*:=\fk L(V,\Fbb)
\end{align*}
Elements of $\fk L(V)$ are called \textbf{bounded linear operators on} $V$. An element $T\in\fk L(V)$ is called \textbf{invertible} if there exists $T^{-1}\in\fk L(V)$ such that
\begin{align*}
TT^{-1}=T^{-1}T=\id_V
\end{align*}
The space $V^*$ is called the \textbf{dual space} of $V$.
\end{df}

\begin{rem}
In this course, the most frequently encountered cases of \eqref{eq26} are $\fk L(V)$, $V^*$, and $\fk L(U\times V,\Fbb)$. 
\end{rem}

\begin{comment}
In Ch. \ref{lb181}, we also consider spaces such as $\fk L(U\times V\times V_*,\Fbb)$, where $V_*$ is a normed vector space with dual space $V$. In such cases, Prop. \ref{lb40} gives isomorphisms
\begin{align*}
\fk L(U\times V\times V_*,\Fbb)\simeq\fk L(U,\fk L(V\times V_*,\Fbb))\simeq \fk L(U,\fk L(V))
\end{align*}
\end{comment}



\begin{rem}\label{lb30}
$\Vert T\Vert$ is the smallest element in $\ovl\Rbb_{\geq0}$ satisfying
\begin{align}\label{eq22}
\Vert T(v_1,\dots,v_N)\Vert\leq \Vert T\Vert\cdot \Vert v_1\Vert\cdots\Vert v_N\Vert
\end{align}
\end{rem}

\begin{proof}
If one of $v_1,\dots,v_N$ is zero, then $T(v_1,\dots,v_N)=0$ by the multilinearity, and hence \eqref{eq22} holds. So we assume that $v_1,\dots,v_N$ are all non-zero. So their norms are all nonzero. Since $v_i/\Vert v_i\Vert\in B_{V_i}(0,1)$, we have
\begin{align*}
\Big\Vert T\Big(\frac{v_1}{\Vert v_1\Vert},\cdots,\frac{v_N}{\Vert v_N\Vert}\Big)\Big\Vert\leq\Vert T\Vert
\end{align*}
which implies \eqref{eq22} by the multilinearity. 

We have proved that $\Vert T\Vert$ satisfies \eqref{eq22}. Now, suppose that $C\in\ovl\Rbb_{\geq0}$ and
\begin{align*}
\Vert T(v_1,\dots,v_N)\Vert\leq C\cdot \Vert v_1\Vert\cdots\Vert v_N\Vert
\end{align*}
for all $v_i\in V_i$. Taking $v_i\in\ovl B_V(0,1)$, we see that $\Vert T\Vert\leq C$.
\end{proof}

Recall Def. \ref{lb33}.

\begin{pp}\label{lb35}
Let $T:V_1\times\cdots\times V_N\rightarrow W$ be multilinear. The following are equivalent.
\begin{enumerate}[label=(\alph*)]
\item $T$ is continuous.
\item $T$ is continuous at $0\times\cdots\times 0$.
\item $T$ is bounded.
\item $T$ is Lipschitz continuous on $\ovl B_{V_1}(0,R)\times\cdots\times\ovl B_{V_N}(0,R)$ for every $R\in\Rbb_{>0}$.
\item $T$ is Lipschitz continuous on $\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1)$.
\end{enumerate}
Moreover, if $T$ is bounded, and if $V_1\times\cdots\times V_N$ is equipped with the $l^\infty$-product metric, then the Lipschitz constant in (d) can be chosen to be $NR^{N-1}\Vert T\Vert$.
\end{pp}

What matters about the Lipschitz constant above is not its exact formula, but the implication it carries: namely, that any family $(T_\alpha)$ in $\fk L(V_1\times\cdots\times V_N,W)$ satisfying $\sup_\alpha\Vert T_\alpha\Vert<+\infty$, when restricted to a bounded subset of $V_1\times\cdots\times V_N$, admits a uniform Lipschitz constant.



\begin{proof}
Clearly (a)$\Rightarrow$(b).

(b)$\Rightarrow$(c): Assume (b). Then $0\times\cdots\times 0$ is an interior point of $T^{-1}(B_W(0,1))$, and hence contains $B_{V_1}(0,2\delta_1)\times\cdots\times B_{V_N}(0,2\delta_N)$ for some $\delta_1,\dots,\delta_N>0$. So $T$ sends $\ovl B_{V_1}(0,\delta_1)\times\cdots\times\ovl B_{V_N}(0,\delta_N)$ (which equals $\delta_1\ovl B_{V_1}(0,1)\times\cdots\times\delta_N\ovl B_{V_N}(0,1)$) into $B_W(0,1)$. By multilinearity, $T$ sends $\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1)$ into $B_W(0,\delta_1^{-1}\cdots\delta_N^{-1})$. This proves (c). 

(c)$\Rightarrow$(d): Assume (c). Choose $v_i\in \ovl B_{V_i}(0,R)$. Then, for each $\xi_i\in \ovl B_{V_i}(0,R)$,
\begin{align*}
&\Vert T(\xi_1,\dots,\xi_N)-T(v_1,\dots,v_N)\Vert\\
\leq&\Vert T(\xi_1-v_1,\xi_2,\xi_3,\dots,\xi_N)\Vert+\Vert T(v_1,\xi_2-v_2,\xi_3,\dots,\xi_N)\Vert\\
&+\Vert T(v_1,v_2,\xi_3-v_3,\dots,\xi_N)\Vert+\cdots+\Vert T(v_1,v_2,v_3,\dots,\xi_N-v_N)\Vert\\
\leq&NR^{N-1}\Vert T\Vert\cdot \max\{\Vert \xi_1-v_1\Vert,\dots,\Vert \xi_N-v_N\Vert\}
\end{align*}
where \eqref{eq22} is used in the last inequality. Thus $T$ has Lipschitz constant $NR^{N-1}\Vert T\Vert$.

(e)$\Leftrightarrow$(d): This is clear by scaling the vectors.

(d)$\Rightarrow$(a): This is clear from Rem. \ref{lb34}.
\end{proof}


\begin{co}\label{lb147}
Let $T\in\fk L(V,W)$. Then $\Ker(T)$ is a closed linear subspace of $V$.
\end{co}

\begin{proof}
By Prop. \ref{lb35}, $T$ is continuous. Since the preimage of any closed set under a continuous map is closed, $\Ker(T)=T^{-1}(0)$ is closed.
\end{proof}



\begin{eg}
A linear map $T:V\rightarrow W$ is called a \textbf{linear isometry} if it is an isometry of metric spaces, i.e., $\Vert Tv_1-Tv_2\Vert=\Vert v_1-v_2\Vert$ for all $v_1,v_2\in V$. This is clearly equivalent to
\begin{align*}
\Vert Tv\Vert=\Vert v\Vert\qquad\text{for all }v\in V
\end{align*}
A linear isometry is clearly bounded with operator norm $\Vert T\Vert=1$ (unless when $V=\{0\}$). Moreover, a linear isometry is clearly injective. A linear isometry $T:V\rightarrow W$ which is also surjective (and hence bijective) is called an \textbf{isomorphism of normed vector spaces}.\index{00@Isomorphism of normed vector spaces} In that case, we say that the normed vector spaces $V,W$ are \textbf{isomorphic}. \index{00@Isomorphic normed vector spaces}
\end{eg}


\begin{rem}
Suppose that $\Phi:V\rightarrow W$ is a linear map of vector spaces, and $W$ is a normed vector space. Then $V$ has a seminorm defined by
\begin{align*}
\Vert v\Vert_V:=\Vert \Phi(v)\Vert_V
\end{align*}
Equip $V/\Ker\Phi$ with the norm defined by Prop. \ref{lb47}. Then $\Phi$ descends to a linear map $\wtd\Phi:V/\Ker\Phi\rightarrow W$, which is clearly a linear isometry. 
\end{rem}

\begin{eg}\label{lb48}
Let $1\leq p\leq+\infty$, let $X$ be an LCH space, let $\mu$ be a Radon measure (or its completion) on $X$. Let $\Phi:C_c(X,\Fbb)\rightarrow L^p(X,\mu,\Fbb)$ be the obvious map. Then $\Phi$ descends to a linear isometry of normed vector spaces
\begin{gather}\label{eq30}
C_c(X,\Fbb)\big/\big\{f\in C_c(X,\Fbb):f=0\text{ $\mu$-a.e.}\big\}\longrightarrow L^p(X,\mu,\Fbb)
\end{gather}
Now assume $p<+\infty$. Then by Thm. \ref{lb14}, the map \eqref{eq30} has dense range. This is often expressed by saying that $C_c(X,\Fbb)\big/\big\{f\in C_c(X,\Fbb):f=0\text{ $\mu$-a.e.}\big\}$ is dense in $L^p(X,\mu,\Fbb)$, or simply that $C_c(X,\Fbb)$ is dense in $L^p(X,\mu,\Fbb)$.
\end{eg}





\subsection{Fundamental properties of bounded multilinear maps}

Let $V_1,V_2,\dots,U,V,W$ be normed vector spaces. In this section, we establish several fundamental properties of bounded multilinear maps that will be used frequently throughout the course. We first note the elementary fact:

\begin{rem}\label{lb29}
Let $U$ be a linear subspace of $V$. Let $R\in\Rbb_{>0}$. Then $U$ is dense in $V$ iff $\ovl B_U(0,R)$ is dense in $\ovl B_V(0,R)$. 
\end{rem}

\begin{proof}
The direction ``$\Leftarrow$'' is obvious. Let us prove ``$\Rightarrow$''. Let $\xi\in\ovl B_V(0,R)$, choose a sequence $(\xi_n)$ in $U$ converging to $\xi$. Assume WLOG that $\xi\neq0$ and $R\in\Rbb_{>0}$; otherwise, the approximation is obvious. Since the norm function is continuous, $\Vert\xi_n\Vert\rightarrow\Vert\xi\Vert$. In particular, $\Vert\xi_n\Vert$ is eventually nonzero. Thus $\frac{\Vert\xi\Vert}{\Vert\xi_n\Vert}\xi_n\rightarrow \xi$.
\end{proof}

Recall that two sequences $(x_n),(y_n)$ in a metric space $X$ is called \textbf{Cauchy equivalent} \index{00@Cauchy equivalence of two sequences} if $\lim_n d(x_n,y_n)=0$.


\begin{thm}\label{lb31}
Suppose that $W$ is complete. For each $i$, let $U_i$ be a dense linear subspace of $V_i$. Then we have an isomorphism of normed vector spaces
\begin{gather}\label{eq23}
\begin{gathered}
\fk L(V_1\times\cdots\times V_N,W)\xlongrightarrow{\simeq} \fk L(U_1\times\cdots\times U_N,W)\\
T\mapsto T\big|_{U_1\times\cdots\times U_N}
\end{gathered}
\end{gather}
\end{thm}

The following proof shows that the map \eqref{eq23} is a linear isometry even without assuming that $W$ is complete.


\begin{proof}
By Rem. \ref{lb29}, $\ovl B_{U_1}(0,1)\times\cdots\times\ovl B_{U_N}(0,1)$ is dense in $\ovl B_{U_1}(0,1)\times\cdots\times\ovl B_{U_N}(0,1)$. Since the $l^\infty$-norm of a continuous function is unchanged when the domain is restricted to a dense subset, it follows that $T\big|_{U_1\times\cdots\times U_N}$ have the same operator norm. Thus \eqref{eq23} is a linear isometry.

We now show that \eqref{eq23} is surjective. Here, the completeness of $W$ is needed. Let $T\in \fk L(U_1\times\cdots\times U_N,W)$. It suffices to extend $T$ in the first component to a bounded multilinear $V_1\times U_2\times U_3\times\cdots\times U_N\rightarrow W$. Then, a similar argument applies to the second component, extending $T$ to a bounded multilinear $V_1\times V_2\times U_3\times\cdots\times U_N\rightarrow W$. By repeating this procedure, we obtain a bounded multilinear map $V_1\times\cdots\times V_N\rightarrow W$ extending $T$.

Let $\xi\in V_1,u_2\in U_2,\dots,u_N\in U_N$. Let $(\xi_n)$ be a sequence in $U_1$ converging to $\xi$. In particular, $(\xi_n)$ is a Cauchy sequence. By Rem. \ref{lb30}, $T(\xi_n,v_2,\dots,v_N)$ is a Cauchy sequence in $W$. Therefore, by the completeness of $W$, $T(\xi_n,v_2,\dots,v_N)$ converges to some element, which we denote by $T(\xi,v_2,\dots,v_N)$.

Let us show that the definition of $T(\xi,v_2,\dots,v_N)$ is independent of the choice of sequence converging to $\xi$. Suppose that $(\xi_n')$ is another sequence converging to $\xi$. Then $(\xi_n)$ and $(\xi_n')$ are Cauchy equivalent. By Rem. \ref{lb30}, $T(\xi_n,v_2,\dots,v_N)$ and $T(\xi_n',v_2,\dots,v_N)$ are Cauchy equivalent. So they converge to the same element.

Thus, we have defined a map $T:V_1\times U_2\times\cdots\times U_N\rightarrow W$. We leave it to the reader to check that $T$ is bounded multi-linear map.
\end{proof}


\begin{co}\label{lb44}
Let $U$ be a dense linear subspace of $V$. Then we have an isomorphism of normed vector spaces
\begin{gather}
V^*\xlongrightarrow{\simeq} U^*\qquad \varphi\mapsto\varphi|_U
\end{gather}
\end{co}

\begin{proof}
This follows immediate from Thm. \ref{lb31}.
\end{proof}

\begin{eg}\label{lb49}
Let $1\leq q<+\infty$ and $p^{-1}+q^{-1}=1$. Let $X$ be an LCH space. Let $\mu$ be a Radon measure (or its completion) on $X$. By Exp. \ref{lb48}, the $L^q$-seminorm on $C_c(X,\Fbb)$ descends to the $L^q$-norm on $V=C_c(X,\Fbb)/\{f\in C_c(X,\Fbb):f=0\text{ $\mu$-a.e.}\}$, and $V$ is dense in $L^p(X,\mu)$. Therefore, by Thm. \ref{lb13} and Cor. \ref{lb44}, the map \eqref{eq31} gives an isomorphism of normed vector spaces $V^*\simeq L^p(X,\mu)$.
\end{eg}

The following Prop. \ref{lb73} and Thm. \ref{lb32} will imply Thm. \ref{lb80}, which establishes the equivalence of the second and third columns of Table \ref{tb1}.

\begin{pp}\label{lb73}
For each $i$, let $E_i$ be a densely spanning subset of $V_i$. Let $(T_\alpha)$ be a net in $\fk L(V_1\times\cdots\times V_N,W)$ with \textbf{uniformly bounded operator norms}, \index{00@Uniformly bounded operator norms} i.e., $\sup_\alpha\Vert T_\alpha\Vert<+\infty$. Choose $T\in\fk L(V_1\times\cdots\times V_N,W)$, and assume that $(T_\alpha)$ converges pointwise on $E_1\times\cdots\times E_N$ to $T$. Then $(T_\alpha)$ converges pointwise on $V_1\times\cdots\times V_N$ to $T$.
\end{pp}

\begin{proof}
Let $U_i=\Span(E_i)$, which is dense in $V_i$. Then $(T_\alpha)$ converges pointwise on $U_1\times\cdots\times U_N$ to $T$.

Choose any $\xi_i\in V_i$. Choose $R\in\Rbb_{>0}$ such that $\Vert\xi_i\Vert\leq R$ for each $i$. Since $\sup_\alpha\Vert T_\alpha\Vert<+\infty$, by Prop. \ref{lb35}, $\{T_\alpha,T:\alpha\in I\}$ has a uniform Lipschitz constant $C\in \Rbb_{\geq0}$ (with respect to the $l^\infty$-product metric) when restricted to $\ovl B_{V_1}(0,R)\times\cdots\times \ovl B_{V_N}(0,R)$. By Rem. \ref{lb29}, for each $\eps>0$, there exists $v_i\in\ovl B_{U_i}(0,R)$ such that $\Vert \xi_i-v_i\Vert\leq\eps$. Then
\begin{align*}
&\limsup_\alpha \Vert T(\xi_1,\dots,\xi_N)-T_\alpha(\xi_1,\dots,\xi_N)\Vert\\
\leq&\limsup_\alpha \Vert T(v_1,\dots,v_N)-T_\alpha(v_1,\dots,v_N)\Vert+2C\eps=2C\eps
\end{align*}
Since $\eps$ is arbitrary, we conclude that $T_\alpha(\xi_1,\dots,\xi_N)\rightarrow T(\xi_1,\dots,\xi_N)$.
\end{proof}



\begin{thm}\label{lb32}
Suppose that $W$ is complete. For each $i$, let $E_i$ be a densely spanning subset of $V_i$. Let $(T_\alpha)$ be a net in $\fk L(V_1\times\cdots\times V_N,W)$ satisfying $\sup_\alpha\Vert T_\alpha\Vert<+\infty$. Suppose that $(T_\alpha)$ converges pointwise on $E_1\times\cdots\times E_N$. Then $(T_\alpha)$ converges pointwise on $V_1\times\cdots\times V_N$ to some $T\in\fk L(V_1\times\cdots\times V_N,W)$, and 
\begin{align}\label{eq37}
\Vert T\Vert\leq\liminf_\alpha\Vert T_\alpha\Vert
\end{align}
\end{thm}

Inequality \eqref{eq37} is sometimes referred to as \textbf{Fatou's lemma}.


\begin{proof}
Let $U_i=\Span(E_i)$, which is dense in $V_i$. Let $T:U_1\times\cdots\times U_N\rightarrow W$ be the pointwise limit of $(T_\alpha)_{\alpha\in I}$ restricted to $U_1\times\cdots\times U_N$, which is clearly linear. Moreover, for each $v_i\in\ovl B_{U_i}(0,1)$ we have
\begin{align*}
\Vert T(v_1,\dots,v_N)\Vert=\liminf_\alpha \Vert T_\alpha(v_1,\dots,v_N)\Vert\leq \liminf_\alpha \Vert T_\alpha\Vert
\end{align*}
Taking $\sup$ over all $v_i\in\ovl B_{U_i}(0,1)$, we see that $\Vert T\Vert\leq\liminf_\alpha\Vert T_\alpha\Vert<+\infty$. In particular, $T\in\fk L(U_1\times\cdots\times U_N,W)$. By Thm. \ref{lb31}, $T$ can be extended to a bounded multilinear map $T:V_1\times\cdots\times V_N\rightarrow W$ with $\Vert T\Vert$ unchanged. By Prop. \ref{lb73}, this extended $T$ is the pointwise limit of $(T_\alpha)$ on the whole domain $V_1\times\cdots\times V_N$. 
\end{proof}


\begin{rem}\label{lb36}
Recall that if $X$ is a set, then $l^\infty(X,W)$, equipped with the $l^\infty$-norm, is a normed vector space.

By the definition of operator norms, we have a linear isometry of normed vector spaces
\begin{gather}\label{eq24}
\begin{gathered}
\fk L(V_1\times\cdots\times V_N,W)\rightarrow l^\infty(\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1),W)\\
T\mapsto T|_{\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1)}
\end{gathered}
\end{gather}
Therefore, by identifying $\fk L(V_1\times\cdots\times V_N,W)$ with its image under \eqref{eq24}, we view $\fk L(V_1\times\cdots\times V_N,W)$ as a normed vector subspace of $l^\infty(\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N},W)$. 

Consequently, if $(T_\alpha)$ is a net in $\fk L(V_1\times\cdots\times V_N,W)$, and if $T\in\fk L(V_1\times\cdots\times V_N,W)$, then $\lim_\alpha\Vert T-T_\alpha\Vert=0$ is equivalent to that $(T_\alpha)$ converges uniformly to $T$ on $\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1)$.  \hqed
\end{rem}




\begin{thm}\label{lb37}
$\fk L(V_1\times\cdots\times V_N,W)$ is a closed linear subspace of $l^\infty(\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1),W)$. 
\end{thm}

\begin{proof}
Let $T\in l^\infty(\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1),W)$ be the limit of a sequence $(T_n)$ in $\fk L(V_1\times\cdots\times V_N,W)$. Then $(T_n)$ converges uniformly on $\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1)$ to $T$. By scaling the vectors, we see that $(T_n)$ converges uniformly on $\ovl B_{V_1}(0,R)\times\cdots\times\ovl B_{V_N}(0,R)$ for any $R>0$. Let $T:V_1\times\cdots\times V_N\rightarrow W$ be the pointwise limit of $(T_n)$, which automatically extends the original $T$ defined on $\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N}(0,1)$.

Since each $T_n$ is multilinear, clearly $T$ is multilinear. Thus $T\in\fk L(V_1\times\cdots\times V_N,W)$. This proves that $\fk L(V_1\times\cdots\times V_N,W)$ is a closed.
\end{proof}


\begin{co}\label{lb39}
Suppose that $W$ is complete. Then $\fk L(V_1\times\cdots\times V_N,W)$ is complete.
\end{co}

\begin{proof}
Since $W$ is complete, by the following Prop. \ref{lb38}, $l^\infty(\ovl B_{V_1}(0,1)\times\cdots\times\ovl B_{V_N},W)$ is complete. Since any closed subset of a complete space is complete, by Thm. \ref{lb37}, $\fk L(V_1\times\cdots\times V_N,W)$ is complete.
\end{proof}



\begin{pp}\label{lb38}
Suppose that $W$ is complete. Then for each $1\leq p\leq+\infty$, the normed vector space $l^p(X,W)$ is complete.
\end{pp}

\begin{proof}
Let $(f_n)$ be a Cauchy sequence in $l^p(X,W)$. Then for each $x\in X$, $(f_n(x))$ is a Cauchy sequence in $W$, and hence converges to some $f(x)\in W$. This defines $f:X\rightarrow W$. 

Case $p=+\infty$: For each $\eps>0$, choose $N\in\Zbb_+$ such that for all $m,n\geq N$ we have $\Vert f_n-f_m\Vert_{l^\infty}\leq\eps$, i.e.,  $\Vert f_n(x)-f_m(x)\Vert\leq\eps$ for every $x\in X$.  Applying $\lim_{m\rightarrow\infty}$, we get $\Vert f_n(x)-f(x)\Vert\leq\eps$ for all $x\in X$ and $n\geq N$. Thus, for all $n\geq N$ we have $\Vert f_n-f\Vert_{l^\infty}\leq \eps$; in particular, we have $f\in l^\infty(X,W)$. Thus $\Vert f_n-f\Vert_{l^\infty}\rightarrow0$.

Case $p<+\infty$: For each $\eps>0$, choose $N\in\Zbb_+$ such that for all $m,n\geq N$ we have $\Vert f_n-f_m\Vert_{l^p(X)}\leq\eps$, equivalently, $\Vert f_n-f_m\Vert_{l^p(A)}\leq\eps$ for each $A\in\fin(2^X)$. Applying $\lim_{m\rightarrow\infty}$, we get $\Vert f_n-f\Vert_{l^p(A)}\leq\eps$ for all $n\geq N$ and $A\in\fin(2^X)$. Thus $\Vert f_n-f\Vert_{l^p(X)}\leq\eps$ for all $n\geq N$; in particular, we have $f\in l^p(X,W)$. This proves $\Vert f_n-f\Vert_p\rightarrow0$.
\end{proof}


\begin{co}\label{lb128}
The dual space $V^*$, equipped with the operator norm, is complete.
\end{co}


\begin{proof}
This follows immediately from Cor. \ref{lb39}.
\end{proof}




\subsection{The roles of duality and Cauchy completeness}\label{lb43}

Let $V_1,\dots,V_N$ and $V,W$ be normed vector spaces.


\subsubsection{The role of Cauchy completeness}\label{lb141}



In functional analysis, Cauchy completeness plays two primary roles:
\begin{enumerate}
\item Completeness as a domain property, where it is often used in conjunction with the Baire category theorem.
\item Completeness as a codomain property, which ensures that linear operators can be restricted from the whole space to a dense subspace without loss. Thm. \ref{lb31} and \ref{lb32} are typical examples illustrating this usage.
\end{enumerate}



Among these two, completeness as a codomain is the more widely encountered in practice. This suggests that \uwave{the recognition and widespread appreciation of \textbf{Cauchy completeness} in function spaces developed alongside the study of linear operators}---that is, linear maps from $V$ to $W$---rather than with linear, bilinear, or multilinear functionals, such as $V\times W\rightarrow\Fbb$. In the early days of functional analysis, particularly in Hilbert’s foundational work \cite{Hil06}, the dominant perspective was centered not on linear operators, but on bilinear forms and linear functionals. Within this (bi)linear framework, completeness is not required---indeed, in Thm \ref{lb31}, \ref{lb32}, and Corollary \ref{lb39}, when $W=\Fbb$, none of the remaining vector spaces involved (namely $V_1,\dots,V_N$) are assumed to be complete.


Historically, the focus on bilinear forms gradually gave way to the linear operator viewpoint. As this shift took place, Cauchy completeness came to occupy a central role in functional analysis. The fact that the bilinear form or multilinear functional viewpoint can be reformulated in terms of linear operators is a consequence of the following elementary observation:



\begin{pp}\label{lb40}
Let $U_1,\dots,U_M$ be normed vector spaces. Then we have an isomorphism of normed vector spaces
\begin{gather}\label{eq25}
\begin{gathered}
\fk L(U_1\times\cdots\times U_M\times V_1\times\cdots\times V_N,W)\xlongrightarrow{\simeq}\fk L(U_1\times\cdots\times U_M,\fk L(V_1\times\cdots\times V_N,W))\\
T\mapsto \Big((u_1,\dots,u_M)\mapsto T(u_1,\dots,u_M,-,\dots,-)\Big)
\end{gathered}
\end{gather}
where $T(u_1,\dots,u_M,-,\dots,-)$ denotes the multilinear map $V_1\times\cdots\times V_N\rightarrow W$ sending $(v_1,\dots,v_N)$ to $T(u_1,\dots,u_M,v_1,\dots,v_N)$.
\end{pp}

\begin{proof}
It is easy to verify that the second line of \eqref{eq25} defines a linear isomorphism
\begin{align*}
\Psi:&\Lin(U_1\times\cdots\times U_M\times V_1\times\cdots\times V_N,W)\\
&\xlongrightarrow{\simeq}\Lin(U_1\times\cdots\times U_M,\Lin(V_1\times\cdots\times V_N,W))
\end{align*}
To explain the idea of comparing the operator norms, we assume for simplicity that $M=N=1$, and write $U_1=U$ and $V_1=V$. 

Choose any $T\in\Lin(U\times V,W)$. Then $\Psi(T):U\rightarrow\Lin(V,W)$ sends each $u\in V$ to the linear map
\begin{align*}
\Psi(T)(u):v\in\Lin(V,W)\mapsto T(u,v)
\end{align*}
Thus, for each $u\in U$ and $v\in V$, we have
\begin{align*}
\Vert T(u,v)\Vert=\Vert \Psi(T)(u)(v)\Vert\leq \Vert \Psi(T)(u)\Vert\cdot \Vert v\Vert\leq\Vert\Psi(T)\Vert\cdot\Vert u\Vert\cdot\Vert v\Vert
\end{align*}
This proves $\Vert T\Vert\leq\Vert\Psi(T)\Vert$. Conversely, for each $u\in U$,
\begin{align*}
&\Vert \Psi(T)(u)\Vert=\sup_{v\in\ovl B_V(0,1)}\Vert\Psi(T)(u)(v)\Vert=\sup_{v\in\ovl B_V(0,1)}\Vert T(u,v)\Vert\\
\leq&\sup_{v\in\ovl B_V(0,1)}\Vert T\Vert\cdot\Vert u\Vert\cdot\Vert v\Vert=\Vert T\Vert\cdot\Vert u\Vert
\end{align*}
This proves $\Vert\Psi(T)\Vert\leq\Vert T\Vert$. 

We have proved that $\Vert\Psi(T)\Vert=\Vert T\Vert$. In particular, if $T$ is bounded, then $\Psi(T)(u)$ is bounded for each $u\in U$, and $\Psi(T)$ is bounded. Conversely, if $\Psi(T)(u)$ is bounded for each $u$, and if $\Psi(T)$ is bounded, then $T$ is bounded. This proves that $\Psi$ restricts to the linear isomorphism \eqref{eq25}, which is an isometry because $\Vert\Psi(T)\Vert=\Vert T\Vert$.
\end{proof}


\subsubsection{The role of duality}\label{lb132}


The following two corollaries follow immediate from Prop. \ref{lb40}.

\begin{co}\label{lb134}
We have an isomorphism of normed vector spaces
\begin{gather}
\fk L(U\times V,\Fbb)\xlongrightarrow{\simeq}\fk L(U,V^*)\qquad T\mapsto\big(u\mapsto T(u,-)\big)
\end{gather}
\end{co}


\begin{co}\label{lb42}
Suppose that $V$ is the dual space of another normed vector space $V_*$. Then we have an isomorphism of normed vector spaces
\begin{gather}
\fk L(V\times V_*,\Fbb)\xlongrightarrow{\simeq}\fk L(V)\qquad T\mapsto\big(v\mapsto T(v,-)\big)
\end{gather}
\end{co}


In Sec. \ref{lb24} and \ref{lb41}, we explored the motivation for introducing dual spaces from the perspectives of the calculus of variations and moment problems. Cor. \ref{lb42} now offers yet another compelling reason for the study of duality: when a space $V$ possesses a \textbf{dual structure}---specifically, \uwave{when $V$ is the dual of some normed space $V_*$---it allows us to approach problems from both the bilinear form and linear operator perspectives}. 

What are the respective advantages of these two viewpoints? To address this, I would like to revisit the arguments presented in \cite{Gui-A}, particularly in the Introduction and in Ch. 21 and 25 of \cite{Gui-A}:


\begin{enumerate}
\item The bilinear form framework allows us to draw upon the full strength of measure theory. In fact, measure theory can be understood as a method of \textbf{monotone convergence extension}---a procedure for extending linear functionals in such a way that the monotone convergence theorem (or its variants) holds; see Sec. \ref{lb257} for details. \index{00@Monotone convergence extension} This type of extension aligns naturally with the structure of bilinear forms.
\item The space $\fk L(V)$ of bounded linear operators on $V$ is not just a vector space but also an algebra, with multiplication given by composition. This algebraic structure enables the use of \textbf{symbolic calculus}, a technique developed in the mid-19th century in the study of linear algebras, and it connects directly to the representation-theoretic perspectives that flourished in the 20th century.
\end{enumerate}

As discussed in \cite[Sec. 25.8, 25.9]{Gui-A}, and as we will also explore in Ch. \ref{lb181}, Riesz’s spectral theorem provides a striking example of how these two advantages can be fruitfully combined.



\subsection{Dual spaces and the weak-* topology}


Let $V_1,V_2,\dots,U,V,W$ be normed $\Fbb$-vector spaces.


\begin{df}
By viewing $V^*$ as a subset of $\Cbb^V$, the subspace topology on $V^*$ inherited from the product topology of $\Cbb^V$ is called the \textbf{weak-* topology} \index{00@Weak-* topology} on $V^*$. By Thm. \ref{lb50}, this is the unique topology such that for any net $(\varphi_\alpha)$ in $V^*$ and any $\varphi\in V$, the net $(\varphi_\alpha)$ \textbf{converges weak-*} \index{00@Weak-* convergence} to $\varphi$---that is, converges to $\varphi$ in the weak-* topology---iff 
\begin{align}\label{eq49}
\lim_\alpha\bk{\varphi_\alpha,v}=\bk{\varphi,v}\qquad\text{for any }v\in V
\end{align}
Since $\Cbb^V$ is Hausdorff, the weak-* topology is also Hausdorff.
\end{df}



Weak-* topology is mainly considered for closed balls of $V^*$, rather than the whole dual space $V^*$, because for such subsets, pointwise convergence of moments is equivalent to weak-* convergence---that is, the second and third columns of Table \ref{tb1} are equivalent. This equivalence is formally stated in the following theorem.

\begin{thm}\label{lb80}
Suppose that $E$ is a densely spanning subset of $V$. Let $(\varphi_\alpha)$ be a net in $V^*$ satisfying $\sup_\alpha\Vert\varphi_\alpha\Vert<+\infty$. Then $(\varphi_\alpha)$ converges weak-* in $V^*$ iff the limit $\lim_\alpha\bk{\varphi_\alpha,v}$ exists for any $v\in E$. 

Moreover, if  $\varphi\in V^*$ satisfies that
\begin{align*}
\lim_\alpha\bk{\varphi_\alpha,v}=\bk{\varphi,v}\qquad\text{for any }v\in E
\end{align*}
then $(\varphi_\alpha)$ converges weak-* to $\varphi$.
\end{thm}

\begin{proof}
This is clear from Prop. \ref{lb73} and  Thm. \ref{lb32}.
\end{proof}


\begin{rem}\label{lb96}
Let $U$ be a dense linear subspace of $V$. (For example, take $V=C_0(X,\Fbb)$ and $U=C_c(X,\Fbb)$.) Recall the canonical isomorphism $V^*\simeq U^*$ given in Cor. \ref{lb44}. Then by Prop. \ref{lb80}, for each $R\in\Rbb_{\geq0}$, the weak-* topology on $\ovl B_{V^*}(0,R)$ agrees with the weak-* topology on $\ovl B_{U^*}(0,R)$. However, the weak-* topology on $V^*$ is in general not equal to the weak-* topology on $U^*$. 
\end{rem}



In Prop. \ref{lb80}, one might further ask whether a net $(\varphi_\alpha)$ in $\ovl B_{V^*}(0,R)$ that converges weak-* has its limit also in $\ovl B_{V^*}(0,R)$. The answer is yes:

\begin{pp}[\textbf{Fatou's lemma for weak-* convergence}]\index{00@Fatou's lemma for weak-* convergence}\label{lb106}
Let $(\varphi_\alpha)$ be a net in $V^*$ converging weak-* to some $\varphi\in V^*$. Then
\begin{align}\label{eq36}
\Vert\varphi\Vert\leq\liminf_\alpha\Vert\varphi_\alpha\Vert
\end{align}
In other words, the norm function $\Vert\cdot\Vert:V^*\rightarrow\Rbb_{\geq0}$ is lower semicontinuous with respect to the weak-* topology on $V^*$.
\end{pp}


In contrast, if $(\varphi_\alpha)$ converges in the operator norm to $\varphi$, then $\Vert\varphi\Vert=\lim_\alpha\Vert\varphi_\alpha\Vert$. Cf. Rem. \ref{lb59}.


\begin{proof}
For each $v\in\ovl B_V(0,1)$, we have
\begin{align*}
|\bk{\varphi,v}|=\lim_\alpha |\bk{\varphi_\alpha,v}|=\liminf_\alpha |\bk{\varphi_\alpha,v}|\leq\liminf_\alpha\Vert\varphi_\alpha\Vert\cdot\Vert v\Vert=\Vert\varphi_\alpha\Vert
\end{align*}
Applying $\sup_{v\in\ovl B_V(0,1)}$ to the LHS above yields \eqref{eq36}. (See also Thm. \ref{lb32}.)
\end{proof}



\begin{thm}[\textbf{Banach-Alaoglu theorem}]\index{00@Banach-Alaoglu theorem}\label{lb60}
$\ovl B_{V^*}(0,1)$ is \textbf{weak-* compact}---that is, it is compact in the weak-* topology. \index{00@Weak-* compact}
\end{thm}

Thus, $\ovl B_{V^*}(0,1)$ is a compact Hausdorff space.


\begin{proof}[\textbf{First proof}]
Let $(\varphi_\alpha)$ be a net $\ovl B_{V^*}(0,1)$. Since $|\bk{\varphi_\alpha,v}|\leq\Vert v\Vert$ for each $v\in V$, we can view $(\varphi_\alpha)$ as a net in
\begin{align*}
S=\prod_{v\in V} \ovl B_\Fbb(0,\Vert v\Vert)
\end{align*}
By Tychonoff's Thm. \ref{lb61}, $S$ is compact. Therefore, $(\varphi_\alpha)$ has a subnet $(\varphi_{\alpha_\mu})$ converging pointwise on $V$ to some function $\varphi:V\rightarrow\Fbb$. The function $\varphi$ is clearly linear and satisfies $\Vert\varphi\Vert\leq\sup_\mu\Vert\varphi_{\alpha_\mu}\Vert\leq 1$, cf. Thm. \ref{lb32}.  Thus $(\varphi_{\alpha_\mu})$ converges weak-* to $\varphi\in\ovl B_{V^*}(0,1)$. This finishes the proof that $\ovl B_{V^*}(0,1)$ is compact.
\end{proof}

The above proof relies on Tychonoff's theorem, which in turn relies on Zorn's lemma. When $V$ is separable, one can prove the Banach-Alaoglu theorem without using Zorn's lemma:

\begin{proof}[\textbf{Second proof assuming that $V$ is separable}]
Let $E$ be a countable dense subset of $V$. Then
\begin{align*}
\Phi:\ovl B_{V^*}(0,1)\rightarrow\Fbb^E\qquad\varphi\mapsto\varphi|_E
\end{align*}
is injective. Moreover, if $(\varphi_\alpha)$ is a net in $\ovl B_{V^*}(0,1)$ and $\varphi\in\ovl B_{V^*}(0,1)$, then Prop. \ref{lb73} indicates that $(\varphi_\alpha)$ converges weak-* to $\varphi$ iff $(\varphi_\alpha)$ converges pointwise on $E$ to $\varphi$. Therefore, $\Phi$ restricts to a homeomorphism from $\ovl B_{V^*(0,1)}$ to its image. Thus, since $\Fbb^E$ is second countable (cf. Prop. \ref{lb51}), so is any subset---in particular, $\ovl B_{V^*}(0,1)$. 

Therefore, by Thm. \ref{lb219}, showing that $\ovl B_{V^*}(0,1)$ is compact is equivalent to showing that it is sequentially compact. Let $(\varphi_n)$ be a sequence in $\ovl B_{V^*}(0,1)$. By the diagonal method (cf. Rem. \ref{lb52}), $(\varphi_n)$ has a subsequence $(\varphi_{n_k})$ converging pointwise on $E$. Thm. \ref{lb32} now implies that $(\varphi_{n_k})$ converges weak-* to some $\varphi\in\ovl B_{V^*}(0,1)$.
\end{proof}


The above proof shows that when $V$ is separable, then $\ovl B_{V^*}(0,1)$ is second-countable and therefore sequentially compact in the weak-* topology. The converse is also true:

\begin{thm}\label{lb76}
The following statements are equivalent.
\begin{enumerate}[label=(\alph*)]
\item The normed vector space $V$ is separable.
\item When equipped with the weak-* topology, the compact Hausdorff space $\ovl B_{V^*}(0,1)$ is second countable. 
\end{enumerate}
\end{thm}


\begin{proof}
(a)$\Rightarrow$(b) has been proved above. Here, we give a more direct argument of the equivalence (a)$\Leftrightarrow$(b). By the following Lem. \ref{lb74}, $V$ can be viewed as a subset of $C(X,\Fbb)$ where $X=\ovl B_{V^*}(0,1)$ is compact by Banach-Alaoglu. Clearly $V$ separates the points of $X$. Therefore, if $V$ is separable, then $X$ is second countable by (c)$\Rightarrow$(b) of Thm. \ref{lb75}. Conversely, if $X$ is second countable, then $C(X,\Fbb)$ is separable by (c)$\Rightarrow$(d) of Thm. \ref{lb75}. Therefore, the subset $V$ of $C(X,\Fbb)$ is also separable.
\end{proof}

\begin{lm}\label{lb74}
For each $\varphi\in V$, the function
\begin{align*}
\ovl B_{V^*}(0,1)\rightarrow\Fbb\qquad \varphi\mapsto \bk{\varphi,v}
\end{align*}
is continuous with respect to the weak-* topology.
\end{lm}


\begin{proof}
This is clear by \eqref{eq49}.
\end{proof}

\begin{comment}
\begin{rem}
When $V$ is separable, a metric $d$ generating the weak-* topology of $\ovl B_{V^*}(0,1)$ can be explicitly given: Let $(v_n)_{n\in\Zbb_+}$ be a dense sequence in $V$. Replacing $v_n$ with $v_n/\Vert v_n\Vert$ if $v_n\neq 0$, we assume that $\Vert v_n\Vert\leq 1$. Then, by \eqref{eq35}, the metric $d$ can be chosen to be
\begin{align}
d(\varphi_1,\varphi_2)=\sum_{n\in\Zbb_+}2^{-n}|\varphi_1(v_n)-\varphi_2(v_n)|\qquad\text{for each }\varphi_1,\varphi_2\in \ovl B_{V^*}(0,1)
\end{align}
\end{rem}
\end{comment}






\subsection{Weak-* convergence in $L^p$-spaces}

Let $(X,\fk M,\mu)$ be a $\sigma$-finite measure space.\footnote{The condition on $\sigma$-finiteness can be removed at least when $p=2$. See the paragraph after Thm. \ref{lb13}.} Let $1<p\leq+\infty$ and $p^{-1}+q^{-1}=1$. 

We identify $L^p(X,\mu,\Fbb)$ with the dual space $L^q(X,\mu,\Fbb)^*$ via the isomorphism described in Thm. \ref{lb13}. This defines the \textbf{weak-* topology on \pmb{$L^p(X,\mu,\Fbb)$}} \index{00@Weak-* topology on $L^p(X,\mu,\Fbb)$}. In particular, a net $(f_\alpha)$ in $L^p(X,\mu,\Fbb)$ converges weak-* to $f\in L^p(X,\mu,\Fbb)$ iff
\begin{align*}
\lim_\alpha\int_X f_\alpha gd\mu=\int_Xfgd\mu\qquad\text{for all }g\in L^q(X,\mu,\Fbb)
\end{align*}


\subsubsection{Pointwise convergence and weak-* convergence}


Let us prove Thm. \ref{lb20} in a slightly more general setting. Note that a finite Borel measure $\mu$ on an interval $I\subset\Rbb$ can be extended by zero to a finite Borel measure on $\Rbb$, which is Radon by Thm. \ref{lb64}. Therefore, to generalize Thm. \ref{lb20}, it suffices to consider finite Borel (equivalently, finite Radon) measures on $\Rbb$.

\begin{thm}\label{lb78}
Let $\mu$ be a finite Borel measure on $\Rbb$. Let $(f_\alpha)$ be a net in $L^p(\Rbb,\mu,\Fbb)$ satisfying $\sup_\alpha\Vert f_\alpha\Vert_{L^p}<+\infty$. Then $(f_\alpha)$ converges weak-* to some element of $L^p(\Rbb,\mu,\Fbb)$  iff the following limit exists for every $x\in \Rbb$:
\begin{align}\label{eq50}
F(x):=\lim_\alpha \int_{(-\infty,x]} f_\alpha d\mu
\end{align}
Moreover, if $f\in L^p(\Rbb,\mu,\Fbb)$, then $(f_\alpha)$ converges weak-* to $f$ iff for each $x\in\Rbb$ we have
\begin{align}\label{eq51}
F(x)=\int_{(-\infty,x]} fd\mu
\end{align}
\end{thm}

Note that since $\mu$ is finite, the constant function $1$ belongs to $L^q$. Therefore, by H\"older's inequality, any function in $L^p(\Rbb,\mu,\Fbb)$ is integrable.

\begin{proof}
First, assume that $(f_\alpha)$ converges weak-* to $f$ in $L^p(\Rbb,\mu,\Fbb)$. Then for each $x\in\Rbb$, we have $\lim_\alpha \int f_\alpha\chi_{(-\infty,x]}d\mu=\int f\chi_{(-\infty,x]}d\mu$. This proves that \eqref{eq50} exists and \eqref{eq51} holds.

Next, we assume that \eqref{eq50} exists for every $x$. In the following, we give two proofs that $(f_\alpha)$ converges weak-* to some $f\in L^p(\Rbb,\mu,\Fbb)$. Then \eqref{eq51} will follow from the first paragraph.\\[-1ex]

First proof. Let $\varphi_\alpha\in L^q(\Rbb,\mu,\Fbb)^*$ be the linear functional associated to $f_\alpha$, i.e., $\bk{\varphi_\alpha,g}=\int f_\alpha gd\mu$ for each $g\in L^q$. By assumption, $\varphi_\alpha$ converges when evaluated with any member of
\begin{align*}
\mc E=\Span_\Fbb\{\chi_{(-\infty,x]}:x\in\Rbb\}
\end{align*}
By Thm. \ref{lb77}, $\mc E$ is dense in $L^q$. Therefore, since
\begin{align*}
\sup_\alpha\Vert\varphi_\alpha\Vert=\sup_\alpha \Vert f_\alpha\Vert_p<+\infty
\end{align*}
by Thm. \ref{lb80}, $(\varphi_\alpha)$ converges weak-* to some $\varphi\in (L^q)^*$. By Thm. \ref{lb13}, $\varphi$ is represented by some $f\in L^p(\Rbb,\mu,\Fbb)$. Thus $(f_\alpha)$ converges weak-* to $f$.\\[-1ex]

Second proof. In this proof, we use the fact that any bounded closed ball of $L^p(\Rbb,\mu,\Fbb)$ is weak-* compact, which is due to Thm. \ref{lb13} and the Banach-Alaoglu theorem.  

Since $\sup_\alpha \Vert f_\alpha\Vert_p<+\infty$, the net $(f_\alpha)$ has a subnet $(f_{\alpha_\nu})$ converging weak-* to some $f\in L^p$. By the first paragraph, for each $x\in\Rbb$ we have
\begin{align*}
\lim_\nu\int_{(-\infty,x]}f_{\alpha_\nu} d\mu=\int_{(-\infty,x]}fd\mu
\end{align*} 
Since \eqref{eq50} converges, we conclude
\begin{align*}
\lim_\alpha\int_{(-\infty,x]}f_\alpha d\mu=\int_{(-\infty,x]}fd\mu
\end{align*} 
That is, if we let $\varphi_\alpha\in(L^q)^*$ represent $f_\alpha$ and let $\varphi\in(L^q)^*$ represent $f$, then $(\varphi_\alpha)$ converges to $\varphi$ when evaluated on $\mc E$. By Thm. \ref{lb77}, $\mc E$ is dense in $L^q$. Therefore, by Thm. \ref{lb80}, $(\varphi_\alpha)$ converges weak-* to $\varphi$. That is, $(f_\alpha)$ converges weak-* to $f$. 
\end{proof}


We now present another connection between pointwise convergence and weak-* convergence.


\begin{thm}\label{lb81}
Let $(f_n)$ be a sequence in $L^p(X,\mu,\Fbb)$ satisfying $\sup_n\Vert f_n\Vert_{L^p}<+\infty$. Suppose that $(f_n)$ converges pointwise to $f$. Then $f\in L^p(X,\mu,\Fbb)$, and $(f_n)$ converges weak-* to $f$.
\end{thm}


\begin{proof}
By Fatou's lemma, we have $f\in L^p$, since
\begin{align*}
\int |f|^p\leq\liminf_n\int |f_n|^p<+\infty
\end{align*}
Thm. \ref{lb78} suggests that when $X=\Rbb$ and $\mu$ is a finite Borel measure, to prove that $(f_n)$ converges weak-* to $f$, it suffices to verify that $\lim_n \int_{(-\infty,x]}f_n=\int_{(-\infty,x]}f$ for each $x\in\Rbb$. Motivated by this, we claim that in the general case, it suffices to prove
\begin{align}\label{eq52}
\lim_n \int_E f_nd\mu=\int_E fd\mu
\end{align}
for each $E\in\fk M$ satisfying $\mu(E)<+\infty$. (Note that any $L^p$ function is integrable in $E$ by H\"older's inequality.) Indeed, suppose \eqref{eq52} is true. Then, by the density of integrable simple functions in $L^p$ (Thm. \ref{lb79}), and by Thm. \ref{lb80}, the sequence $(f_n)$ converges weak-* to $f$.

Let us prove \eqref{eq52}. Since $(f_n)$ converges pointwise to $f$, and since $\mu(E)<+\infty$, it follows that $(f_n)$ converges in measure to $f$ on $E$. That is, for each $\eps>0$,
\begin{align*}
\lim_n \mu(A_n)=0\qquad\text{where }A_n=\{x\in E:|f(x)-f_n(x)|\geq\eps\}
\end{align*}
(Proof: Let $g_n=|f-f_n|$. Then $(g_n)$ converges pointwise to $0$. Let $h_n(x)=\sup_{k\geq n}g_n(x)$. Then $(h_n)$ is decreasing, and $\lim_n h_n(x)=\limsup_n g_n(x)=0$. Thus, the sequence of sets $(B_n)$ defined by $B_n=\{x\in E:h_n(x)\geq\eps\}$ is decreasing and $\bigcap B_n=\emptyset$. Hence $\lim_n\mu(B_n)=0$. Since $g_n\leq h_n$, we have $\mu(A_n)\leq\mu(B_n)$, and hence $\lim_n\mu(A_n)=0$.)

For each $\eps>0$ and $A_n$ as above, we have
\begin{align*}
\int_{E\setminus A_n}|f_n-f|d\mu\leq \eps \mu(E)
\end{align*}
Let $C=\sup_n\Vert f_n\Vert_{L^p}$. By H\"older's inequality, we have
\begin{align*}
\limsup_n\int_{A_n}|f_n-f|d\mu \leq\limsup_n\big(\Vert f_n-f\Vert_{L^p}\cdot \mu(A_n)^{\frac 1q}\big)\leq 2C\limsup_n \mu(A_n)^{\frac 1q}=0
\end{align*}
where the last equality is due to $\lim_n\mu(A_n)=0$. Thus
\begin{align*}
\limsup_n \Big|\int_E(f_n-f)d\mu\Big|\leq \eps\mu(E)
\end{align*}
Since $\eps$ is arbitrary, we conclude \eqref{eq52}.
\end{proof}



\subsubsection{Weak-* approximation by elementary functions}

Let $X$ be an LCH space, and let $\mu$ be a Radon measure (or its completion) on $X$ with $\sigma$-algebra $\fk M$. We assume that $\mu$ is $\sigma$-finite. This condition holds, for example, when $X$ is $\sigma$-compact (in particular, when $X$ is second countable; cf. Rem. \ref{lb84}.)


In this subsection, we examine Principle \ref{lb23} in the context of $L^p$-spaces. We begin with the following observation:

\begin{rem}
Let $V$ be a normed vector space, and let $U$ be a linear subspace of $V^*$. Let $R\in\Rbb_{>0}$. By Rem. \ref{lb29}, $U$ is norm-dense in $V^*$ iff $\ovl B_U(0,R)$ is norm-dense in $\ovl B_{V^*}(0,R)$. 

It is clear from linearity that if $\ovl B_U(0,R)$ is weak-* dense in $\ovl B_{V^*}(0,R)$, then $U$ is weak-* dense in $V^*$. However, the weak-* density of $U$ in $V^*$ does not imply the weak-* density of $\ovl B_U(0,R)$ in $\ovl B_{V^*}(0,R)$. Therefore, when studying weak-* approximation in $V^*$, we aim---when possible---to approximate any $\varphi\in V^*$ by a net $(\varphi_\alpha)$ in $U$ such that $\Vert \varphi_\alpha\Vert\leq\Vert\varphi\Vert$. This ensures not only convergence but also control of norms.  \hqed
\end{rem}


\begin{thm}\label{lb86}
The closed unit ball of $C_c(X,\Fbb)$ is weak-* dense in the closed unit ball of $L^p(X,\mu,\Fbb)$. More precisely, the obvious map $C_c(X,\Fbb)\rightarrow L^p(X,\mu,\Fbb)$ sends $\ovl B_{C_c(X,\Fbb)}(0,1)$ to a weak-* dense subset of $\ovl B_{L^p(X,\mu,\Fbb)}(0,1)$.
\end{thm}


\begin{proof}
By Thm. \ref{lb14}, if $p<+\infty$, then $\ovl B_{C_c(X,\Fbb)}(0,1)$ is norm-dense in $\ovl B_{L^p(X,\mu,\Fbb)}(0,1)$, and hence also weak-* dense.

Now, we assume $p=+\infty$. let $\scr I$ be the directed set
\begin{gather*}
\scr I=\{(\MG,\eps):\MG\in\fin(2^{C_c(X,\Fbb)}),\eps\in\Rbb_{>0}\}\\
(\MG_1,\eps_1)\leq(\MG_2,\eps_2)\qquad\text{means}\qquad \MG_1\subset\MG_2,\eps_1\geq\eps_2
\end{gather*}
Fix any $f\in \ovl B_{L^\infty(X,\mu,\Fbb)}(0,1)$. By adding a $\mu$-a.e. zero function to $f$, we assume that $\Vert f\Vert_{l^\infty(X)}=\Vert f\Vert_{L^\infty(X,\mu,\Fbb)}\leq 1$. We claim that for any $(\MG,\eps)\in\scr I$, there exists $f_{\MG,\eps}\in \ovl B_{C_c(X,\Fbb)}(0,1)$ such that
\begin{align*}
\Big| \int_X (f-f_{\MG,\eps})gd\mu\Big|\leq\eps\qquad\text{for all }g\in\MG
\end{align*}
If this is true, then $(f_{\MG,\eps})_{(\MG,\eps)\in\scr I}$ converges to $f$ when integrated against any element of $C_c(X,\Fbb)$. Since $C_c(X,\Fbb)$ is dense in $L^1(X,\mu,\Fbb)$ (Thm. \ref{lb14}), it follows from Thm. \ref{lb80} that $(f_{\MG,\eps})_{(\MG,\eps)\in\scr I}$ converges weak-* to $f$, finishing the proof.

Let us prove the claim. We write $\MG=\{g_1,\dots,g_n\}$. Let $A_i=\Supp(g_i)$ and $A=A_1\cup\cdots\cup A_n$. Since $A$ is compact, we have $\mu(A)<+\infty$. Let $M=\Vert g_1\Vert_\infty+\cdots+\Vert g_n\Vert_\infty$. By Lusin's Thm. \ref{lb82} and the Tietze extension Thm. \ref{lb83}, there exist a compact set $K\subset A$ and a function $f_{\MG,\eps}\in C_c(X,\Fbb)$ satisfying
\begin{align*}
f_{\MG,\eps}|_K=f|_K\qquad\Vert f_{\MG,\eps}\Vert_{l^\infty}=\Vert f\Vert_{l^\infty}\qquad \mu(A\setminus K)\leq\eps/2M
\end{align*}
Recall that $\Vert f\Vert_{l^\infty}\leq 1$. Thus, for each $1\leq i\leq n$, we have
\begin{align*}
&\Big| \int_X (f-f_{\MG,\eps})g_i\Big|=\Big| \int_{A\setminus K} (f-f_{\MG,\eps})g_i\Big|\leq M\int_{A\setminus K}(|f|+|f_{\MG,\eps}|)\\
\leq&2M\cdot \mu(A\setminus K)\leq \eps
\end{align*}
\end{proof}


\begin{co}
Let $\mu$ be a finite Borel measure on $\Sbb^1$. Let $U=\Span_\Cbb\{e_n:n\in\Zbb\}$ where $e_n:z\in\Sbb^1\mapsto z^n\in\Cbb$. Then for each $f\in L^p(\Sbb^1,\mu)$, there exists a sequence $(f_n)$ in $U$ converging weak-* to $f$ and satisfying $\sup_n\Vert f\Vert_{L^p}\leq\Vert f\Vert_{L^p}$.
\end{co}

\begin{proof}
By Thm. \ref{lb85}, the normed vector space $L^q(\Sbb^1,\mu)$ is separable. Therefore, by Thm. \ref{lb76}, the weak-* topology of $\ovl B_{L^p(\Sbb^1,\mu)}(0,1)$ is second countable (and hence first countable). Therefore, by Prop. \ref{lb209} and Rem. \ref{lb221}, to prove the corollary, it suffices to show that $\ovl B_U(0,1)$ is weak-* dense in $\ovl B_{L^p(\Sbb^1,\mu)}(0,1)$. 

By Thm. \ref{lb86}, $\ovl B_{C(\Sbb^1)}(0,1)$ is weak-* dense in $\ovl B_{L^p(\Sbb^1,\mu)}(0,1)$. By the Stone-Weierstrass Thm. \ref{lb87}, $U$ is $l^\infty$-dense (and hence $L^p$-dense) in $C(\Sbb^1)$. Thus, $\ovl B_U(0,1)$ is $L^p$-norm-dense (and hence weak-* dense) in $\ovl B_{C(\Sbb^1)}(0,1)$. This finishes the proof.
\end{proof}






\subsection{Weak-* convergence in $l^p$-spaces}



Let $X$ be a set, and let $1\leq p\leq+\infty$ and $p^{-1}+q^{-1}=1$. In this section, we prove the equivalence of the first two columns of Table \ref{tb1} for $V=l^q(X,\Fbb)$, cf. Thm. \ref{lb111}. The most important case is when $X$ is countable and $p=q=2$. For example, $l^2(\Zbb^n)$ corresponds to the space of Fourier coefficients of $L^2$-functions on $\mathbb T^n:=(\Sbb^1)^n$.

Recall from the text near \eqref{eq201} that $X$ is equipped with the discrete topology $2^X$. Therefore, the support of each $f:X\rightarrow\Fbb$ is $\Supp(f)=\{x\in X:f(x)\neq0\}$.

%The key reason that the duality $(l^q)^*\simeq l^p$ does not how for $p=+\infty$ is due to the fact that the following lemma does not hold when $p=+\infty$.







\subsubsection{The linear isometry $l^p(X,\Fbb)\rightarrow l^q(X,\Fbb)^*$}

\begin{pp}\label{lb109}
Assume that $1\leq p<+\infty$. Then $C_c(X,\Fbb)$ is dense in $l^p(X,\Fbb)$, where
\begin{align}\label{eq60}
C_c(X,\Fbb):=\{f\in\Fbb^X:\Supp(f)\text{ is a finite set}\}
\end{align}
\end{pp}

The notation of $C_c(X,\Fbb)$ in \eqref{eq60} is compatible with our usual notation for LCH spaces if $X$ is equipped with the discrete topology $\mc T_X=2^X$.

\begin{proof}
Choose $f\in l^p(X,\Fbb)$. Then, since
\begin{align*}
\lim_{A\in\fin(2^X)}\sum_A|f|^p=\sum_X|f|^p
\end{align*}
we have
\begin{align*}
\lim_{A\in\fin(2^X)} \Vert f-f\chi_A\Vert_{l^p}^p=\lim_{A\in\fin(2^X)}\sum_{X\setminus A}|f|=\sum_X|f|^p-\lim_{A\in\fin(2^X)}\sum_A|f|^p=0
\end{align*}
Thus, $(f\chi_A)_{A\in\fin(2^X)}$ is a net in $C_c(X,\Fbb)$ converging to $f$.
\end{proof}




\begin{rem}\label{lb108}
We have a linear map
\begin{gather}\label{eq58}
\begin{gathered}
\Psi:l^p(X,\Fbb)\rightarrow l^q(X,\Fbb)^*\\
f\mapsto\Big(g\in l^q(X,\Fbb)\mapsto \sum_{x\in X}f(x)g(x)\Big)
\end{gathered}
\end{gather}
Indeed, by H\"older's inequality, for each $A\in\fin(2^X)$,
\begin{align*}
\Big|\sum_A fg\Big|\leq\sum_A|fg|\leq \Vert f\Vert_{l^p(A)}\cdot\Vert g\Vert_{l^q(X)}\leq \Vert f\Vert_{l^p(X)}\cdot\Vert g\Vert_{l^q(X)}
\end{align*}
Applying $\lim_A$, we see that $\sum_Xfg$ is absolutely convergent (i.e. $\sum_X|fg|<+\infty$), and 
\begin{align*}
\Big|\sum_X fg\Big|\leq\sum_X|fg|\leq\Vert f\Vert_{l^p(X)}\cdot\Vert g\Vert_{l^q(X)}
\end{align*}
This justifies the claim that $\Psi$ has range in $l^q(X,\Fbb)^*$ (rather than just in $\Lin(l^q(X,\Fbb),\Fbb)$), and that $\Vert\Psi\Vert\leq 1$.
\end{rem}

\begin{pp}\label{lb112}
The map $\Psi$ in \eqref{eq58} is a linear isometry.
\end{pp}

\begin{proof}
We already know $\Vert\Psi\Vert\leq 1$, and we want to show $\Vert\Psi\Vert=1$. 

Case $p<+\infty$: By Prop. \ref{lb109} and Thm. \ref{lb31}, we have $\Vert\Psi\Vert=\Vert\Psi|_{C_c(X,\Fbb)}\Vert$. Therefore, it suffices to show that $\Vert\Psi(f)\Vert=\Vert f\Vert$ for each $f\in C_c(X,\Fbb)$. We assume WLOG that $f\neq0$. Then
\begin{align*}
\bk{\Psi(f),g}=\Vert f\Vert_{l^p}\cdot\Vert g\Vert_{l^q}
\end{align*}
if we write $f=u|f|$ (where $u:X\rightarrow\Sbb^1$) and let $g=\ovl u\cdot |f|^{p-1}$. Since $\Vert\Psi(f)\Vert\cdot\Vert g\Vert_{l^q}\geq|\bk{\Psi(f),g}|$ and $\Vert g\Vert_{l^q}>0$, we conclude that $\Vert\Psi(f)\Vert\geq\Vert f\Vert_{l^p}$, and hence $\Vert\Psi(f)\Vert=\Vert f\Vert_{l^p}$.

Case $p=+\infty$: For each $0\leq\lambda<1$, let $x\in X$ such that $|f(x)|\geq \lambda\Vert f\Vert_{l^\infty}$. Take $g=\ovl u\chi_{\{x\}}$ where $u\in\Sbb^1$ is such that $f(x)=u|f(x)|$. Then
\begin{align*}
\bk{\Psi(f),g}=|f(x)|\geq\lambda\Vert f\Vert_{l^\infty}=\lambda\Vert f\Vert_{l^\infty}\cdot\Vert g\Vert_{l^1}
\end{align*}
This, together with $\Vert\Psi(f)\Vert\cdot\Vert g\Vert_{l^1}\geq|\bk{\Psi(f),g}|$, implies $\Vert\Psi(f)\Vert\geq\lambda\Vert f\Vert_{l^\infty}$. Since $\lambda$ is arbitrary, we conclude $\Vert\Psi(f)\Vert=\Vert f\Vert_{l^\infty}$.
\end{proof}




\subsubsection{Weak-* convergence in $l^p(X,\Fbb)$}

\begin{df}
Assume that $1<p\leq+\infty$. The \textbf{weak-* topology on $\pmb{l^p(X,\Fbb)}$} \index{00@Weak-* topology on $l^p(X,\Fbb)$} is defined to be the pullback topology via the (injective) map $\Phi:l^p(X,\Fbb)\rightarrow l^q(X,\Fbb)^*$ of the weak-* topology of $l^q(X,\Fbb)^*$. In other words, a net $(f_\alpha)$ in $l^p(X,\Fbb)$ converges weak-* to $f\in l^p(X,\Fbb)$ iff for each $g\in l^q(X,\Fbb)$ we have
\begin{align}\label{eq59}
\lim_\alpha\sum_X f_\alpha g=\sum_X fg
\end{align}
\end{df}


\begin{thm}\label{lb111}
Assume $1<p\leq+\infty$. Let $(f_\alpha)$ be a net in $L^p(X,\Fbb)$ satisfying $\sup_\alpha\Vert f_\alpha\Vert_{l^p}<+\infty$. Then $(f_\alpha)$ converges weak-* to some element of $l^p(X,\Fbb)$ iff $\lim_\alpha f_\alpha(x)$ converges for each $x\in X$. 

Moreover, if $f\in l^p(X,\Fbb)$, then $(f_\alpha)$ converges weak-* to $f$ iff $f(x)=\lim_\alpha f_\alpha(x)$ for each $x\in X$.
\end{thm}

Consequently, if $p>1$ and $(f_\alpha)$ is a uniformly $l^p$-bounded net in $L^p(X,\Fbb)$ converging pointwise to $f:X\rightarrow\Fbb$, then $f\in l^p(X,\Fbb)$. (Indeed, by Thm. \ref{lb111}, $(f_\alpha)$ converges weak-* to some $\wtd f\in l^p(X,\Fbb)$, and $\wtd f$ is the pointwise limit of $(f_\alpha)$. Therefore $f=\wtd f$ belongs to $l^p(X,\Fbb)$.) 

However, as we will see below, this conclusion must in fact be established first in order to complete the proof of  Thm. \ref{lb111}


\begin{proof}
First, assume that $(f_\alpha)$ converges weak-* to $f\in l^p(X,\Fbb)$. Applying \eqref{eq59} to $g=\chi_{\{x\}}$ (for each $x\in X$), we see that $(f_\alpha)$ converges pointwise to $f$.

Conversely, assume that $(f_\alpha)$ converges pointwise on $X$. Let $f\in\Fbb^X$ be the pointwise limit of $(f_\alpha)$. Recall that $C=\sup_\alpha\Vert f_\alpha\Vert_{l^p}$ is finite. We claim that $f\in l^p(X,\Fbb)$. Indeed, if $p=+\infty$, then for each $x\in X$, we have
\begin{align*}
|f(x)|=\lim_\alpha|f_\alpha(x)|\leq\sup_\alpha \Vert f_\alpha\Vert_{l^\infty}<+\infty
\end{align*}
If $p<+\infty$, then for each $A\in\fin(2^X)$, 
\begin{align*}
\sum_A |f|^p=\lim_\alpha\sum_A |f_\alpha|^p\leq\sup_\alpha \Vert f_\alpha\Vert^p_{l^p}\leq C^p 
\end{align*}
Applying $\lim_A$, we see that $\sum_X|f|^p\leq C^p$, and hence $f\in l^p(X,\Fbb)$.

Let $\Psi$ be as in \eqref{eq58}. By Prop. \ref{lb109}, $C_c(X,\Fbb)$ is dense in $L^q(X,\Fbb)$. Therefore, to show that $(f_\alpha)$ converges weak-* to $f$, by Thm. \ref{lb80} and the observation that
\begin{align*}
\sup_\alpha\Vert\Psi(f_\alpha)\Vert=\sup_\alpha\Vert f_\alpha\Vert_{l^p}<+\infty
\end{align*}
it suffices to show that $\bk{\Psi(f_\alpha),g}$ converges to $\bk{\Psi(f),g}$ (that is, $\sum f_\alpha g$ converges to $\sum fg$) for each $g\in C_c(X,\Fbb)$. But this follows from the fact that $(f_\alpha)$ converges pointwise to $f$.
\end{proof}


As an application of Thm. \ref{lb111}, we prove a variant of Prop. \ref{lb109}.

\begin{pp}
Let $1<p\leq+\infty$. Then $\ovl B_{C_c(X,\Fbb)}(0,1)$ is weak-* dense in $\ovl B_{l^\infty(X,\Fbb)}$.
\end{pp}


\begin{proof}
Let $f\in \ovl B_{l^\infty(X,\Fbb)}$. Then $(f\chi_A)_{A\in\fin(2^X)}$ is a net in $\ovl B_{C_c(X,\Fbb)}(0,1)$ converging pointwise to $f$. By Thm. \ref{lb111}, this net converges weak-* to $f$. 
\end{proof}


\subsubsection{The isomorphism $l^p(X,\Fbb)\simeq l^q(X,\Fbb)^*$}


Now that the equivalence of the first two columns of Table \ref{tb1} for $V=l^q(X,\Fbb)$ has been established in Thm. \ref{lb111} for $p>1$, we can prove the isomorphism $l^p(X,\Fbb)\simeq l^q(X,\Fbb)^*$ by following the strategy outlined in Rem. \ref{lb110}. 

Of course, at least when $X$ is countable, this isomorphism is a special case of the duality $L^p(X,\mu,\Fbb)\simeq L^q(X,\mu,\Fbb)^*$ from Thm. \ref{lb13}, by taking $\mu:2^X\rightarrow[0,+\infty]$ to be the counting measure. However, there are good reasons to study the proof of $l^q(X,\Fbb)^*\simeq l^p(X,\Fbb)$ independently. 

First, the proof of Thm. \ref{lb13} is significantly more involved than the direct proof in the $l^p$ setting. Whenever a result admits a simpler proof in a special case, it is worthwhile to examine that proof directly. Second, Thm. \ref{lb13} depends crucially on the Radon-Nikodym Thm. \ref{lb27}, which in turn can be derived from the Riesz-Fr\'echet Thm. \ref{lb135}. The latter can be proved with the help of the isomorphism $l^2(X,\Fbb)\simeq l^2(X,\Fbb)^*$. 

%Third, since the proof below follows the idea in Rem. \ref{lb110}, it also serves as another concrete illustration of Table \ref{tb4}.


%We note that the reason that $(l^q)^*\simeq l^p$ does not hold for $p=1$ is that Principle \ref{lb23} does not hold for $V=l^\infty(X,\Fbb)$ (when $X$ is infinite), that is, not all elements of $l^\infty(X,\Fbb)^*$ can be weak-* approximated 



\begin{thm}\label{lb127}
Assume that $1<p\leq+\infty$. Then the map $\Psi:l^p(X,\Fbb)\rightarrow l^q(X,\Fbb)^*$ is an isomorphism of normed vector spaces.
\end{thm}



\begin{proof}
By Prop. \ref{lb112}, it remains to show that $\Psi$ is surjective. Choose $\varphi\in l^q(X,\Fbb)^*$. We want to find $f\in l^p(X,\Fbb)$ such that $\Psi(f)=\varphi$. 


Define $f:X\rightarrow\Fbb$ by $f(x)=\varphi(\chi_{\{x\}})$. Then
\begin{align}\label{eq185}
\varphi(g)=\sum_X fg
\end{align}
holds whenever $g=\chi_{\{x\}}$ for some $x\in X$, and hence for all $g\in C_c(X,\Fbb)$. For each finite set $A\subset X$, due to the canonical linear isometry $l^p(A,\Fbb)\rightarrow l^q(A,\Fbb)^*$ (as in \eqref{eq58}), we have
\begin{align*}
\Vert f|_A\Vert_{l^p}=\sup_{g\in l^q(A,\Fbb),\Vert g\Vert_q\leq 1}\Big|\sum_A fg  \Big|=\sup_{g\in l^q(A,\Fbb),\Vert g\Vert_q\leq 1}|\varphi(g)|\leq\Vert \varphi\Vert
\end{align*}
Hence, if $p=+\infty$, we clearly have $\Vert f\Vert_{l^\infty}\leq\Vert\varphi\Vert$; if $p<+\infty$, we have
\begin{align*}
\sum_X|f|^p=\lim_{A\in\fin(2^X)}\sum_A |f|^p=\lim_{A\in\fin(2^X)}\Vert f|_A\Vert_{l^p}^p\leq\Vert\varphi\Vert^p
\end{align*}
and hence $\Vert f\Vert_{l^p}\leq\Vert\varphi\Vert$. In both cases, we have $f\in l^p(X,\Fbb)$.

By \ref{lb185}, the bounded linear functionals $\varphi$ and $\Psi(f)$ agree on $C_c(X,\Fbb)$. Since $C_c(X,\Fbb)$ is dense in $l^q(X,\Fbb)$ (cf. Prop. \ref{lb109}), we must have $\varphi=\Psi(f)$.
\end{proof}







\subsection{Weak-* convergence of distribution functions}


In this section, we fix a proper interval $I\subset\Rbb$, and let $a=\inf I, b=\sup I$. We use freely the notation in Subsec. \ref{lb89}. In particular, for each function $\rho$ on $I$, we let
\begin{align*}
\Omega_\rho=\{x\in(a,b):\rho|_{(a,b)}\text{ is continuous at }x\}
\end{align*}
A family of functions $(\rho_\alpha)$ from $I$ to $\Rbb$ is called \textbf{uniformly bounded} if $\sup_\alpha \Vert\rho_\alpha\Vert_{l^\infty(I,\Rbb)}<+\infty$.

The goal of this section is to prove Thm. \ref{lb21}, which characterizes the relationship between pointwise convergence and weak-* convergence for increasing functions. To this end, we begin with several preparatory results concerning the pointwise convergence of such functions.


\subsubsection{Almost convergence of increasing functions}



\begin{lm}\label{lb90}
Let $(\rho_\alpha)$ be a uniformly bounded net of increasing functions $I\rightarrow\Rbb_{\geq0}$. Suppose that $(\rho_\alpha)$ converges pointwise on a dense subset $E\subset I$. Then there exists a bounded increasing function $\rho:I\rightarrow\Rbb_{\geq0}$ such that $(\rho_\alpha)$ converges pointwise on $E$ to $\rho$.
\end{lm}

\begin{proof}
Let $\varrho:E\rightarrow\Rbb_{\geq0}$ be the pointwise limit of $(\rho_\alpha)$, which is clearly bounded and increasing. Extend $\varrho|_{E\cap I_{<b}}$ to a function $\rho:I_{<b}\rightarrow\Rbb_{\geq0}$ by setting
\begin{align*}
\rho(x)=\lim_{E\ni y\rightarrow x^+}\varrho(y)
\end{align*} 
for any $x\in I\setminus E$. If $b\notin I$ then we are done. If $b\in E$, set $\rho(b)=\varrho(b)$. If $b\in I\setminus E$, set $\rho(b)=\lim_{x\rightarrow b^-}\rho(x)$. Then $\rho$ is bounded and increasing, and $(\rho_\alpha)$ converges pointwise to $\rho$ on $E$.
\end{proof}



\begin{pp}\label{lb91}
Let $(\rho_\alpha)$ be a uniformly bounded net of increasing functions $I\rightarrow\Rbb_{\geq0}$. Let $\rho:I\rightarrow\Rbb_{\geq0}$ be increasing. Then the following are equivalent:
\begin{enumerate}[label=(\alph*)]
\item There exists a dense subset $E\subset(a,b)$ such that $(\rho_\alpha)$ converges pointwise on $E$ to $\rho$.
\item The net $(\rho_\alpha)$ converges pointwise on $\Omega_\rho$ to $\rho$.
\end{enumerate}
If either of these two statements are true, we say that $(\rho_\alpha)$ \textbf{almost converges} to $\rho$. \index{00@Almost convergence of a net of increasing functions}
\end{pp}


\begin{proof}
Since $\Omega_\rho$ is dense (Prop. \ref{lb62}), clearly (b) implies (a).

Now assume (a). Choose any $x\in\Omega_\rho$. We will show that every convergent subnet $(\rho_{\alpha_\nu}(x))$ of $(\rho_\alpha(x))$ converges to $\rho(x)$. Then by Thm. \ref{lb227}, we have $\lim_\alpha\rho_\alpha(x)=\rho(x)$, proving (b).

By Lem. \ref{lb90},  there exists an increasing function $\wtd\rho:I\rightarrow\Rbb_{\geq0}$ such that $(\rho_{\alpha_\nu})$ converges on $E\cup\{x\}$ to $\wtd\rho$. Since $(\rho_{\alpha_\nu})$ converges pointwise on $E$ to $\rho$, the functions $\rho$ and $\wtd\rho$ agree on $E$. Namely, $\rho$ and $\wtd\rho$ are almost equal. Therefore, by Prop. \ref{lb70}, $\rho$ and $\wtd\rho$ agree on $\Omega_\rho$, and in particular at $x$. This proves $\lim_\nu\rho_{\alpha_\nu}(x)=\rho(x)$.
\end{proof}


The following theorem can be viewed as a concrete manifestation of the Banach-Alaoglu Thm. \ref{lb60} in the setting of $C_c(I)^*$. It will be used in the proof of Thm. \ref{lb92}.


\begin{thm}[\textbf{Helly selection theorem}]\index{00@Helly selection theorem}\label{lb94}
Let $(\rho_\alpha)$ be a uniformly bounded net (resp. sequence) of increasing functions $I\rightarrow\Rbb_{\geq0}$. Then $(\rho_\alpha)$ admits a pointwise convergent subnet (resp. subsequence).
\end{thm}

\begin{proof}
The existence of a pointwise convergent subnet follows directly from the Tychonoff Thm. \ref{lb61}. Therefore, let us assume that $(\rho_\alpha)$ is a sequence $(\rho_n)$. Let $E=I\cap\Qbb$. Then, by the diagonal method (cf. Rem. \ref{lb52}), $(\rho_n)$ has a subsequence $(\rho_{n_k})$ converging pointwise on $E$. By Lem. \ref{lb90}, there exists a bounded increasing $\rho:I\rightarrow\Rbb_{\geq0}$ such that $(\rho_{n_k})$ converges pointwise on $E$ to $\rho$. Therefore, by Prop. \ref{lb91}, $(\rho_{n_k})$ converges pointwise on $\Omega_\rho$ to $\rho$. Since $I\setminus\Omega_\rho$ is countable, by the diagonal method again, $(\rho_{n_k})$ has a subsequence converging pointwise on $I\setminus\Omega_\rho$, and hence on $I$. 
\end{proof}



\subsubsection{Almost convergence and weak-* convergence}

\begin{df}
Let $(\rho_\alpha)$ be a net in $BV(I,\Fbb)$. Let $\rho\in BV(I,\Fbb)$. Let $\Lambda_\alpha$ and $\Lambda$ be the elements of $C_c(I,\Fbb)^*$ corresponding to $\rho_\alpha$ and $\rho$, respectively, via the Riesz representation Thm. \ref{lb10}.  We say that the net $(d\rho_\alpha)$ \textbf{converges weak-*} \index{00@Weak-* convergence of $(d\rho_\alpha)$ where $(\rho_\alpha)$ is a net of BV functions} to $d\rho$ if $(\Lambda_\alpha)$ converges weak-* to $\Lambda$. Namely, for each $f\in C_c(I,\Fbb)$, we have
\begin{align}\label{eq53}
\lim_\alpha \int_I f d\rho_\alpha=\int_I fd\rho
\end{align}
\end{df}

\begin{rem}\label{lb186}
Suppose that $(\rho_\alpha)$ is a uniformly bounded net of increasing functions $I\rightarrow\Rbb_{\geq0}$. Let $\rho:I\rightarrow\Rbb_{\geq0}$ be increasing. Recall from Rem. \ref{lb357} that $C_c(I,\Fbb)$ is dense in $C_0(I,\Fbb)$. Therefore, by Thm. \ref{lb80}, the net $(d\rho_\alpha)$ converges weak-* to $d\rho$ iff \eqref{eq53} holds for any $f\in C_0(I,\Fbb)$.
\end{rem}

The following Thm. \ref{lb92} is parallel to Thm. \ref{lb78}. However, unlike Thm. \ref{lb78} whose proof relies on the isomorphism $L^p\simeq(L^q)^*$, Thm. \ref{lb92} does not rely on the Riesz representation theorem. (Note that when the measure in Thm. \ref{lb78} is the Lebesgue measure, one can also prove Thm. \ref{lb78} from the fundamental theorem of calculus, without invoking the duality $L^p\simeq(L^q)^*$; see the proof of Thm. \ref{lb20}.)

\begin{thm}\label{lb92}
Let $(\rho_\alpha)_{\alpha\in\scr A}$ be a uniformly bounded net of bounded increasing functions $I\rightarrow\Rbb_{\geq0}$. Let $\rho:I\rightarrow\Rbb_{\geq0}$ be bounded and increasing. Then the following are equivalent:
\begin{enumerate}[label=(\alph*)]
\item There exists a bounded family $(\varkappa_\alpha)_{\alpha\in\scr A}$ in $\Rbb$ (assumed to be zero if $a\in I$) satisfying the following conditions:
\begin{itemize}
\item $(\rho_\alpha+\varkappa_\alpha)$ almost converges to $\rho$.
\item $\lim_\alpha(\rho_\alpha(b)+\varkappa_\alpha)=\rho(b)$ if $b\in I$.
\end{itemize}
\item The net $(d\rho_\alpha)$ converges weak-* to  $d\rho$.
\end{enumerate}
\end{thm}

The boundedness of $(\varkappa_\alpha)_{\alpha\in\scr A}$ means that $\sup_\alpha|\vkp_\alpha|<+\infty$.

\begin{proof}
(a)$\Rightarrow$(b): Assume (a). We verify \eqref{eq53} for each $f\in C_c(I,\Fbb)$, which established (b). Recall from Rem. \ref{lb93} that if $a\notin I$, adding constants to $\rho_\alpha$ and $\rho$ does not affect the values of $\int_I fd\rho_\alpha$ and $\int_I fd\rho$. 

Since $(\rho_\alpha)$ is uniformly bounded and $(\vkp_\alpha)$ is bounded, there exists $c\geq0$ such that $\rho_\alpha+\vkp_\alpha+c\geq0$ for all $\alpha$. Therefore, replacing $\rho_\alpha$ with $\rho_\alpha+\vkp_\alpha+c$ and $\rho$ with $\rho+c$, we assume that there exists a dense subset $E\subset I$ such that $(\rho_\alpha)$ converges pointwise on $E$ to $\rho$, and that $b\in E$ if $b\in I$.

Choose any $f\in C_c(I,\Fbb)$. Choose $u,v\in\Rbb$ satisfying $\Supp_I(f)\subset[u,v]\subset I$, and let $J=[u,v]$. By increasing $v$ if possible, we may assume that $v\in E$. (When $b\in I$, one simply choose $v=b$.) 

In the case where $a\in I$, by Lem. \ref{lb69}, the values of $\int_J fd\rho_\alpha$ and $\int_J fd\rho$ remain unchanged if we change the values of $\rho_\alpha(a)$ and $\rho(a)$ to $0$. Therefore,  we may assume that $\rho_\alpha(a)=\rho(a)=0$ (so that $a$ can be included to $E$), and we may also choose $u=a$. In the case where $a\notin I$, by the density of $E$, we can slightly decrease $u$ so that $u\in E$. To summarize, whether $a$ or $b$ belongs to $I$ or not, we can assume 
\begin{align*}
u,v\in E
\end{align*}

Since $f$ is uniformly continuous, for each $\eps>0$ there exists $\delta>0$ such that $|f(x)-f(y)|\leq\eps$ for each $x,y\in I$ satisfying $|x-y|\leq\delta$. Choose a tagged partition
\begin{align*}
(\sigma,\xi_\blt)=\big(\{a_0=u<a_1<\cdots<a_n=v\},(\xi_1,\dots,\xi_n) \big)
\end{align*}
of $J$ with mesh $<\delta$. Since $E$ is dense, by a slight adjustment, we may assume that $a_0,a_1,\dots,a_n\in E$. This implies
\begin{align*}
\lim_\alpha \big(f(u)\rho_\alpha(u)+S_{\rho_\alpha}(f,\sigma,\xi_\blt)\big)=f(u)\rho(u)+S_\rho(f,\sigma,\xi_\blt)
\end{align*}
Therefore, if we let $C=\sup\{\rho_\alpha(v)-\rho_\alpha(u),\rho(v)-\rho(u):\alpha\in\scr A\}$, then Rem. \ref{lb63} implies
\begin{align*}
\limsup_\alpha \Big|\int_J fd\rho_\alpha-\int_J fd\rho\Big|\leq 2\eps\cdot C
\end{align*}
This finishes the proof of \eqref{eq53}.\\[-1ex]

(b)$\Rightarrow$(a): Assume (b). We first consider the case where $a\notin I$. Fix $t\in\Omega_\rho$, and let
\begin{align*}
\varkappa_\alpha=\rho(t)-\rho_\alpha(t)
\end{align*}
Then $(\vkp_\alpha)$ is bounded. Therefore, $(\rho_\alpha+\vkp_\alpha)$ is uniformly bounded, and hence there exists $c\geq0$ such that $\rho_\alpha+\vkp_\alpha+c\geq0$ for all $\alpha$. Replacing $\rho_\alpha$ with $\rho_\alpha+c$ and $\rho$ with $\rho+c$, we assume that $\rho_\alpha+\vkp_\alpha\geq0$ for all $\alpha$. (Of course, we still have $\rho\geq0$.) 

Choose any $x\in\Omega_\rho$. To show that $(\rho_\alpha(x)+\vkp_\alpha)_\alpha$ converges to $\rho(x)$, by Thm. \ref{lb227}, it suffices to show that every convergent subnet $(\rho_\beta(x)+\vkp_\beta)_\beta$ converges to $\rho(x)$.

By the Helly selection Thm. \ref{lb94}, the net of functions $(\rho_\beta+\vkp_\beta)_\beta$ has a pointwise convergent subnet $(\rho_\gamma+\vkp_\gamma)_\gamma$. Let $\wtd\rho:I\rightarrow\ovl\Rbb_{\geq0}$ be the pointwise limit of this subnet, which is clearly bounded and increasing. By (a)$\Rightarrow$(b), the net $(d(\rho_\upgamma+\vkp_\gamma))_\gamma$ converges weak-* to $d\wtd\rho$. By assumption, it also converges weak-* to $d\rho$. Therefore, we have $\int_I fd\wtd\rho=\int_I fd\rho$ for each $f\in C_c(I)$. 

By Thm. \ref{lb72} (and noting Rem. \ref{lb93}), we have
\begin{align*}
\wtd\rho-\lim_{y\rightarrow a^+}\wtd\rho(y)=\rho-\lim_{y\rightarrow a^+}\rho(y)\qquad\text{on }\Omega_\rho
\end{align*}
In other words, there exists a constant $c\in\Rbb$ such that
\begin{align}\label{eq54}
\wtd\rho+c=\rho\qquad\text{on }\Omega_\rho
\end{align}

Since $\rho_\alpha(t)+\vkp_\alpha=\rho(t)$ is constant over $\alpha$, and since its subnet $(\rho_\gamma(t)+\vkp_\gamma)_\gamma$ converges to $\wtd\rho(t)$, we conclude $\wtd\rho(t)=\rho(t)$. Therefore, since $t\in\Omega_\rho$, by \eqref{eq54}, we have $c=0$. Since $x\in\Omega_\rho$, by \eqref{eq54}, we obtain $\wtd\rho(x)=\rho(x)$. This proves that $(\rho_\gamma(x)+\vkp_\gamma)_\gamma$ converges to $\rho(x)$, and hence $(\rho_\beta(x)+\vkp_\beta)_\beta$ converges to $\rho(x)$.

Now consider the case where $a\in I$. We set $\vkp_\alpha=0$.  Similar to the above argument, we choose any $x\in\Omega_\rho$, choose a subnet $\rho_\beta$ converging at $x$, and further choose a subnet $\rho_\gamma$ converging pointwise on $I$ to $\wtd\rho:I\rightarrow\ovl\Rbb_{\geq0}$. By (a)$\Rightarrow$(b), we have $\int_I fd\wtd\rho=\int_I fd\rho$ for each $f\in C_c(I)$. Consequently, Thm. \ref{lb72} implies that $\wtd\rho=\rho$ on $\Omega_\rho$. Since $x\in\Omega_\rho$, we obtain again $\lim_\beta \rho_\beta(x)=\lim_\gamma \rho_\gamma(x)=\wtd\rho(x)=\rho(x)$. Therefore $(\rho_\alpha(x))_\alpha$ converges to $\rho(x)$ for each $x\in\Omega_\rho$.
\end{proof}


\begin{co}\label{lb95}
Let $(\rho_\alpha)_{\alpha\in\scr A}$ be a uniformly bounded net of increasing functions $I\rightarrow\Rbb_{\geq0}$. Then the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item There exists a bounded family $(\varkappa_\alpha)_{\alpha\in\scr A}$ in $\Rbb$ (assumed to be zero if $a\in I$) such that $(\rho_\alpha+\varkappa_\alpha)$ converges pointwise on a dense subset $E\subset I$, and also at $b$ if $b\in I$.
\item There exists a bounded increasing $\rho:I\rightarrow\Rbb_{\geq0}$ such that $(d\rho_\alpha)_{\alpha\in\scr A}$ converges weak-* to $d\rho$.
\end{enumerate}
\end{co}


\begin{proof}
``(2)$\Rightarrow$(1)'' follows immediately from Thm. \ref{lb92}. Conversely, assume (1). By Lem. \ref{lb90}, there exists a bounded increasing $\rho:I\rightarrow\Rbb_{\geq0}$ such that $(\rho_\alpha+\varkappa_\alpha)$ converges pointwise on $E\cup\{I\cap\{b\}\}$ to $\rho$. Then Thm. \ref{lb92} implies (2).
\end{proof}


In Thm. \ref{lb92}, if $a\notin I$, one might suspect that the appearance of the family $(\varkappa_\alpha)_{\alpha\in\SA}$ is needed only because $(\rho_\alpha)$ and $\rho$ are not normalized, that is, because $\lim_{x\rightarrow a^+}\rho_\alpha(x)$ and $\lim_{x\rightarrow a^+}\rho(x)$ don't vanish. However, even when both limits are zero, a nontrivial family $(\varkappa_\alpha)_{\alpha\in\SA}$ may still be required, as the following example shows:

\begin{eg}
Let $I=\Rbb$ and $\rho_n=\chi_{[-n,+\infty)}$. Then $\lim_{x\rightarrow-\infty}\rho_n(x)=0$, and the sequence $(d\rho_n)_{n\in\Zbb_+}$ converges weak-* to $0$. In this case, the family $(\varkappa_n)$ is chosen to be the constant sequence $-1$.
\end{eg}









\subsection{Weak-* approximation of Radon measures by Dirac measures}


Fix an LCH space $X$. Recall that we have assumed throughout the notes that $\Fbb\in\{\Rbb,\Cbb\}$. Let \index{RM@$\RM(X,\Kbb)$ where $\Kbb$ is $\ovl\Rbb_{\geq0},\Rbb_{\geq0},\Rbb,\Cbb$}
\begin{gather}
\begin{gathered}
\RM(X,\ovl\Rbb_{\geq0})=\{\text{Radon measures on $X$}\}\\
\RM(X,\Rbb_{\geq0})=\{\text{finite Radon measures on $X$}\}\\
\RM(X,\Rbb)=\{\text{signed Radon measures on $X$}\}\\
\RM(X,\Cbb)=\{\text{complex Radon measures on $X$}\}
\end{gathered}
\end{gather}
which are vectors spaces over $\ovl\Rbb_{\geq0},\Rbb_{\geq0},\Rbb,\Cbb$ respectively. Note the inclusion relation
\begin{align*}
\RM(X,\Rbb_{\geq0})\subset\RM(X,\ovl\Rbb_{\geq0})\qquad \RM(X,\Rbb_{\geq0})\subset \RM(X,\Rbb)\subset\RM(X,\Cbb)
\end{align*}
Recall that for each $x\in X$, the Dirac measure at $x$ is denoted by $\delta_x$.

The goal of this section is to prove Principle \ref{lb23} for $V=C_c(X,\Fbb)$. In this context, elementary functions are understood as linear combinations of Dirac measures. When $X$ is an interval $I\subset\Rbb$, these elementary functions correspond to bounded increasing functions $I\rightarrow\Rbb_{\geq0}$ whose ranges are finite sets.

\subsubsection{Definitions and basic properties}


\begin{df}\label{lb374}
Recall the $\Fbb$-linear isomorphism
\begin{align*}
\RM(X,\Fbb)\simeq C_c(X,\Fbb)^*
\end{align*}
defined by the Riesz-Markov representation Thm. \ref{lb8}. The pullback of the operator norm on $C_c(X,\Fbb)^*$ to $\mu\in\RM(X,\Fbb)$ is called the \textbf{total variation} of $\mu$, and is denoted by \pmb{$\Vert\mu\Vert$}. \index{00@Total variation of a complex measure} \index{zz@$\Vert\mu\Vert$, the total variation of $\mu$} In other words,
\begin{align*}
\Vert\mu\Vert=\sup\Big\{\Big|\int fd\mu\Big|:f\in C_c(X,\Fbb),|f|\leq1 \Big\}
\end{align*}
A family of complex Radon measures $(\mu_\alpha)_{\alpha\in\scr A}$ is called \textbf{uniformly bounded} \index{00@Uniformly bounded family of complex measures} if
\begin{align*}
\sup_{\alpha\in\scr A}\Vert\mu_\alpha\Vert<+\infty
\end{align*}
The weak-* topology on $C_c(X,\Fbb)^*$ defines the \textbf{weak-* topology on \pmb{$\RM(X,\Fbb)$}}. Thus, if $(\mu_\alpha)$ is a uniformly bounded net in $\RM(X,\Fbb)$, and if $\mu\in\RM(X,\Fbb)$, then $(\mu_\alpha)$ converges weak-* to $\mu$ \footnote{We also say that $(d\mu_\alpha)$ converges weak-* to $d\mu$.} iff for each $f\in C_c(X,\Fbb)$ we have
\begin{align}\label{eq55}
\lim_\alpha\int_Xfd\mu_\alpha=\int_X fd\mu
\end{align}
By Rem. \ref{lb357} and Thm. \ref{lb80}, $(\mu_\alpha)$ converges weak-* to $\mu$ iff \eqref{eq55} holds for all $f\in C_0(X,\Fbb)$.
\end{df}






\begin{eg}\label{lb99}
By Thm. \ref{lb7}, if $\mu\in\RM(X,\Rbb_{\geq0})$, then
\begin{align*}
\Vert\mu\Vert=\mu(X)
\end{align*}
\end{eg}


\begin{eg}\label{lb103}
Let $E\subset X$ be a finite set, and let $c:E\rightarrow\Fbb$ be a function. Then
\begin{align}
\Big\Vert  \sum_{x\in E}c(x)\delta_x\Big\Vert=\sum_{x\in E}|c(x)|
\end{align}
\end{eg}

\begin{proof}
Let $\mu=\sum_{x\in E}c(x)\delta_x$. By Exp. \ref{lb99}, we have $\Vert\delta_x\Vert=1$. Since norms satisfy the sub-additivity, we have
\begin{align*}
\Vert\mu\Vert\leq\sum_{x\in E}|c(x)|\cdot\Vert\delta_x\Vert=\sum_{x\in E}|c(x)|
\end{align*}
By Urysohn's lemma, there exists $f\in C_c(X,\Fbb)$ such that $\Vert f\Vert_{l^\infty}\leq 1$, and that for each $x\in E$, we have $|f(x)|=1$ and $f(x)c(x)=|c(x)|$. Then $\int_X fd\mu=\sum_{x\in E}|c(x)|$. This proves $\Vert\mu\Vert\geq\sum_{x\in E}|c(x)|$.
\end{proof}


\begin{lm}\label{lb104}
Let $\mu\in\RM(X,\Fbb)$. Let $A_1,\dots,A_k$ be mutually disjoint Borel subsets of $X$. Then
\begin{align*}
\Vert\mu\Vert\geq\sum_{j=1}^k |\mu(A_j)|
\end{align*}
\end{lm}

\begin{proof}
Since $\mu$ is a linear combination of finite Radon measures, there exists $\wht\mu\in\RM(X,\Rbb_{\geq0})$ such that $|\int_X gd\mu|\leq\int_X|g|d\wht\mu$ for each bounded Borel $g:X\rightarrow\Cbb$. \footnote{For example, if $\mu$ is a finite sum $\sum_j\lambda_j\mu_j$ where $\lambda_j\in\Fbb$ and $\mu_j\in\RM(X,\Rbb_{\geq0})$, set $\wht\mu=\sum_j|\lambda_j|\mu_j$.} Since Radon measures are regular on Borel sets with finite measures (Thm. \ref{lb101}), for each $\eps>0$ there exists compact $K_j\subset A_j$ such that $\wht\mu(A_j\setminus K_j)\leq \eps$. 

By Cor. \ref{lb102}, there exist mutually disjoint open subsets $U_1,\dots,U_k\subset X$ such that $U_j\supset K_j$. Since $\wht\mu$ is regular on $K_j$, we may assume that $\wht\mu(U_j\setminus K_j)<\eps$. By Urysohn's lemma, there exists $f_j\in C_c(U_j,\Fbb)$ such that $|f_j|\leq 1$, that $f_j|_{K_j}$ equals a constant $c_j\in\Fbb$, and that $c_j\mu(K_j)=|\mu(K_j)|$. Let $f=f_1+\cdots f_k$, which is an element of $C_c(X,\Fbb)$ satisfying $|f|\leq 1$. Then 
\begin{align*}
\int_{\bigcup_j K_j}fd\mu=\sum_j|\mu(K_j)|\qquad \Big|\int_{X\setminus\bigcup_j K_j} fd\mu\Big|\leq k\eps
\end{align*}
Since $|\mu(A_j)-\mu(K_j)|=|\mu(A_j\setminus K_j)|\leq\wht\mu(A_j\setminus K_j)\leq\eps$, we obtain $|\mu(K_j)|\geq |\mu(A_j)|-\eps$, and hence
\begin{align*}
\Vert\mu\Vert\geq\Big|\int_X fd\mu\Big|\geq\Big|\int_{\bigcup_j K_j}fd\mu\Big|-\Big|\int_{X\setminus\bigcup_j K_j} fd\mu \Big|\geq \sum_j |\mu(A_j)|-2k\eps
\end{align*}
Since $\eps$ is arbitrary, we obtain the desired inequality.
\end{proof}



\subsubsection{Approximation of Radon measures by Dirac measures}

In this section, we let $\Kbb\in\{\Rbb_{\geq0},\Rbb,\Cbb\}$. 

\begin{thm}\label{lb105}
Define
\begin{align*}
\MD(X,\Kbb)=\Span_\Kbb\{\delta_x:x\in X\}
\end{align*}
Then the closed unit ball of $\MD(X,\Kbb)$ is weak-* dense in the closed unit ball of $\RM(X,\Kbb)$. In other words, $\ovl B_{\MD(X,\Kbb)}(0,1)$ is weak-* dense in $\ovl B_{\RM(X,\Kbb)}(0,1)$.
\end{thm}


The most important case is where $\Kbb=\Rbb_{\geq0}$. In this case, the following proof can be slightly simplified by choosing $\wht\mu$ to be $\mu$.

\begin{proof}
Fix $\mu\in\RM(X,\Kbb)$ satisfying $\Vert\mu\Vert\leq 1$. Similar to the proof of Thm. \ref{lb86}, we let $\scr I$ be the directed set
\begin{gather*}
\scr I=\{(\MG,\eps):\MG\in\fin(2^{C_c(X,\Kbb)}),\eps\in\Rbb_{\geq0}\}\\
(\MG_1,\eps_1)\leq(\MG_2,\eps_2)\qquad\text{means}\qquad \MG_1\subset\MG_2,\eps_1\geq\eps_2
\end{gather*}
We claim that for any $(\MG,\eps)\in\scr I$, there exists $\mu_{\MG,\eps}\in\ovl B_{\MD(X,\Kbb)}(0,1)$ such that
\begin{align*}
\Big|\int_X fd\mu-\int_X fd\mu_{\MG,\eps}\Big |\leq\eps\qquad\text{for all }f\in\MG
\end{align*}
If this is true, then $(\mu_{\MG,\eps})_{(\MG,\eps)\in\scr I}$ is a net in $\ovl B_{\MD(X,\Kbb)}(0,1)$ converging weak-* to $\mu$. This will finish the proof.

Let us prove the claim. Since $\mu$ is a linear combination of finite Radon measures, similar to the proof of Lem. \ref{lb104}, there exists $\wht\mu\in\RM(X,\Rbb_{\geq0})$ such that
\begin{align*}
\Big|\int_X gd\mu\Big|\leq\int_X |g|d\wht\mu
\end{align*}
for each bounded Borel function $g:X\rightarrow\Cbb$.

Let $K\subset X$ be compact and containing $\Supp(f)$ for all $f\in\MG$. By the compactness of $K$, there exist open sets $U_1,\dots,U_k\subset X$ whose union contains $K$, such that $\diam(f(U_j))\leq \eps/\wht\mu(K)$ for each $j$ and $f\in\MG$. Choose a Borel set $A_j\subset U_j$ such that  $K=A_1\sqcup\cdots\sqcup A_k$.\footnote{For example, take $A_1=K\cap U_1$ and $A_j=K\cap U_j\setminus (U_1\cup\cdots\cup U_{j-1})$ if $j>1$.} Choose any $x_j\in A_j$ if $A_j\neq\emptyset$, and choose any $x_j\in X$ if $A_j=\emptyset$. Let
\begin{align}\label{eq56}
\mu_{\MG,\eps}=\sum_{j=1}^k\mu_j(A_j)\delta_{x_j}
\end{align}
Then, for each $f\in\MG$,
\begin{align*}
&\Big| \int_X fd(\mu-\mu_{\MG,\eps})\Big|\leq\sum_{j=1}^k\Big|\int_{A_i}fd(\mu-\mu_{\MG,\eps})\Big|=\sum_{j=1}^k\Big|\int_{A_i}fd\mu -\mu_j(A_j)f(x_i)\Big|\\
=&\sum_{j=1}^k\Big|\int_{A_i}(f-f(x_j))d\mu\Big|\leq\sum_{j=1}^k\int_{A_j}|f-f(x_j)|d\wht\mu\leq \frac{\eps}{\wht\mu(K)}\sum_{j=1}^k\wht\mu(A_j)=\eps
\end{align*}
This proves the desired inequality. Moreover, by Exp. \ref{lb103} and Lem. \ref{lb104},
\begin{align*}
\Vert\mu_{\MG,\eps}\Vert=\sum_{j=1}^k|\mu_j(A_j)|\leq\Vert\mu\Vert\leq1
\end{align*}
This proves that $\mu_{\MG,\eps}\in\ovl B_{\MD(X,\Kbb)}(0,1)$.
\end{proof}



The proof of Thm. \ref{lb105} immediately implies:


\begin{thm}
For each $\mu\in\RM(X,\Fbb)$, we have
\begin{align}\label{eq57}
\Vert\mu\Vert=\sup\Big\{\sum_{j=1}^k|\mu(A_j)|:k\in\Zbb_+\text{, and $A_1,\dots,A_k\in\fk B_X$ are mutually disjoint}\Big\}
\end{align}
\end{thm}

\begin{proof}
Lem. \ref{lb104} implies ``$\geq$''. Let us prove ``$\leq$''. Let $(\mu_{\MG,\eps})_{(\MG,\eps)\in\SI}$ be the net in $\MD(X,\Fbb)$ converging weak-* to $\mu$ and satisfying $\Vert\mu_{\MG,\eps}\Vert\leq\Vert\mu\Vert$, where each $\mu_{\MG,\eps}$ is of the form \eqref{eq56}. By Lem. \ref{lb103}, the RHS of \eqref{eq57} is $\geq\Vert\mu_{\MG,\eps}\Vert$. Since the net $(\mu_{\MG,\eps})_{(\MG,\eps)\in\SI}$ converges weak-* to $\mu$, by Fatou's lemma for weak-* convergence (Prop. \ref{lb106}), the RHS of \eqref{eq57} is $\geq\Vert\mu\Vert$.
\end{proof}



\subsection{Problems}

\begin{comment}
\begin{prob}
Let $X$ be an LCH space. Let $f:X\rightarrow\ovl\Rbb_{\geq0}$ be lower semicontinuous. Prove that there exists an increasing net of continuous functions $X\rightarrow\Rbb_{\geq0}$ converging pointwise to $f$.
\end{prob}

\begin{proof}[Hint]
Let $\SA=\{g\in C_c(X,\Rbb_{\geq0}):g\leq f\}$. Consider $(g)_{g\in\SA}$.
\end{proof}
\end{comment}





\begin{prob}
Let $X$ be an LCH space. Let $(\mu_\alpha)_{\alpha\in\SI}$ be a net of finite Radon measures on $X$ satisfying $\sup_\alpha \mu_\alpha(X)<+\infty$ and converging weak-* to some finite Radon measure $\mu$ on $X$ (cf. Def. \ref{lb374}). Let $E\subset X$ be a Borel set.
\begin{enumerate}
\item Prove that $\dps\mu(E)\leq\liminf_\alpha\mu_\alpha(E)$ if $E$ is open, and that $\dps\mu(E)\geq\limsup_\alpha\mu_\alpha(E)$ if $E$ is compact.
\item Suppose that $\Cl_X(E)$ is compact and $\Cl_X(E)\setminus\Int_X(E)$ is $\mu$-null. Prove that $\mu(E)=\lim_\alpha\mu_\alpha(E)$.
\item Assume that $X$ is a compact interval $[a,b]$ in $\Rbb$ where $a<b$. Find an example of a sequence $(\mu_n)$ of Borel measures on $[a,b]$ with $\sup_n\mu_n([a,b])<+\infty$ converging weak-* to some finite Borel measure $\mu$, such that $\lim_n\mu_n([a,x])$ does not converge to $\mu([a,x])$ for some $x\in[a,b]$.
\end{enumerate}
\end{prob}

Note that part 2 is a generalization of the direction (b)$\Rightarrow$(a) in Thm. \ref{lb92}.

\begin{proof}[Hint]
Part 1. Recall \eqref{eq47}. If $E$ is compact, use the outer regularity and Urysohn's lemma to show that $\mu(E)$ can be approximated from above by $\int fd\mu$ where $f\in C_c(X,[0,1])$ and $f|_E=1$.

Part 3. Reduce the problem to one concerning the convergence of distribution functions.
\end{proof}



\begin{comment}
\begin{prob}
Let $[a,b]\subset\Rbb$ with $a<b$. Let $(\mu_\alpha)_{\alpha\in\SI}$ be a net of finite Borel measures on $[a,b]$ converging weak-* to some finite Borel measure $\mu$. Assume that $\mu\{x\}=0$ for each $x\in[a,b]$. Prove that $(\rho_\alpha)_{\alpha\in\SI}$ converges uniformly to $\rho$, where $\rho_\alpha(x)=\mu([a,x])$ and $\rho(x)=\mu([a,x])$ for each $x\in[a,b]$.
\end{prob}
\end{comment}









\newpage








\section{Basics of inner product spaces}




\subsection{Sesquilinear forms}



Let $V,W$ be $\Cbb$-vector spaces.



\subsubsection{Sesquilinear forms}



\begin{df}
A map of $\Cbb$-vector spaces $T:V\rightarrow W$ is called \textbf{antilinear} or \textbf{conjugate linear} \index{00@Antilinear map} if for every $a,b\in\Cbb$ and $\xi,\eta\in V$ we have
\begin{align*}
T(a\xi+b\eta)=\ovl a\xi+\ovl b\eta
\end{align*}
where $\ovl a,\ovl b$ are the complex conjugates of $a,b$.
\end{df}


\begin{df}
A function $\bk{\cdot|\cdot}:V\times V\rightarrow\Cbb$ (sending $\xi\times \eta\in V^2$ to $\bk{\xi|\eta}$) is called a \textbf{sesquilinear form} \index{00@Sesquilinear form} if it is antilinear on the first variable, and linear on the second one.\footnote{This is different from \cite{Gui-A}, where the second variable is assumed to be antilinear} Namely, for each $a,b\in\Cbb$ and $\xi,\eta,\psi\in V$ we have
\begin{gather*}
\bk{a\xi+b\eta|\psi}=\ovl a\bk{\xi|\psi}+\ovl b\bk{\eta|\psi}\qquad \bk{\psi|a\xi+b\eta}=a\bk{\psi|\xi}+b\bk{\psi|\eta}
\end{gather*}
More generally, a map $V\times W\rightarrow\Cbb$ is also called \textbf{sesquilinear} if it is antilinear on the $V$-component and linear on the $W$-component. The function
\begin{align*}
V\rightarrow\Cbb\qquad \xi\mapsto\bk{\xi|\xi}
\end{align*}
is called the \textbf{quadratic form} \index{00@Quadratic form associated to a sesquilinear form} associated to the sesquilinear form $\bk{\cdot|\cdot}$.
\end{df}

Notice the difference between the notations $\bk{\xi|\eta}$ and $\bk{\xi,\eta}$: the latter always means a bilinear form, i.e., a function which is linear on both variables.


\begin{rem}\label{lb237}
For each sesquilinear form $\bk{\cdot|\cdot}$ on $V$, we have the \textbf{polarization identity} \index{00@Polarization identity}
\begin{align}\label{eq134}
\begin{aligned}
&\bk{\xi|\eta}=\frac 14\sum_{t=0,\frac \pi 2,\pi,\frac{3\pi}2}~ \bk{e^{\im t}\xi+\eta|e^{\im t}\xi+\eta}e^{\im t}\\
=&\frac 14\Big(\bk{\xi+\eta|\xi+\eta}-\bk{-\xi+\eta|-\xi+\eta}+\im\bk{\im \xi+\eta|\im \xi+\im \eta}-\im\bk{-\im \xi+\eta|-\im \xi+\eta}\Big)
\end{aligned}
\end{align}
Therefore, sesquilinear forms are determined by their associated quadratic forms.
\end{rem}



\begin{df}
Let $\omega(\cdot|\cdot):V\times W\rightarrow\Cbb$ be a sesquilinear form. The \textbf{adjoint sesequilinear form $\pmb{\omega^*}$} \index{00@Adjoint sesquilinear form} \index{zz@$\omega^*$, the adjoint sesquilinear form of $\omega$} is defined to be
\begin{align*}
\omega^*:W\times V\rightarrow\Cbb\qquad \omega^*(\eta|\xi)=\ovl{\omega(\xi|\eta)}
\end{align*}
\end{df}


\begin{df}
A sesquilinear form $\bk{\cdot|\cdot}:V\times V\rightarrow\Cbb$ is called a \textbf{Hermitian form} \index{00@Hermitian form} if is equal to its adjoint, namely, 
\begin{align*}
\bk{\eta|\xi}=\ovl{\bk{\xi|\eta}}\qquad\text{for each }\xi,\eta\in V
\end{align*}
\end{df}



\begin{pp}\label{lb113}
Let $\bk{\cdot|\cdot}$ be a sesquilinear form on $V$. The following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $\bk{\cdot|\cdot}$ is a Hermitian form.
\item The quadratic form associated to $\bk{\cdot|\cdot}$ is real-valued, that is, for each $\xi\in V$ we have $\bk{\xi|\xi}\in\Rbb$.
\end{enumerate}
\end{pp}


\begin{proof}
Let $\omega=\bk{\cdot|\cdot}$. By the polarization identity, we have $\omega^*=\omega$ iff $\omega^*(\xi|\xi)=\omega(\xi|\xi)$ (i.e. $\ovl{\omega(\xi|\xi)}=\omega(\xi|\xi)$) for each $\xi\in V$. 
\end{proof}



\subsubsection{Positive sesquilinear forms}


\begin{df}\label{lb139}
A sesquilinear form $\bk{\cdot|\cdot}$ on $V$ is called \textbf{positive semi-definite} (or simply \textbf{positive}) and written as $\bk{\cdot|\cdot}\geq0$, \index{00@Positive sesquilinear form} if $\bk{\xi|\xi}\geq0$ for all $\xi\in V$. If a positive sesquilinear form $\bk{\cdot|\cdot}$ on $V$ is fixed, we define
\begin{align}
\Vert \xi\Vert=\sqrt{\bk{\xi|\xi}}\qquad\text{ for all }\xi\in V
\end{align} 
Then it is clear that $\Vert\lambda \xi\Vert=|\lambda|\cdot\Vert \xi\Vert$ for each $\xi\in V$ and $\lambda\in\Cbb$. A vector $\xi\in V$ satisfying $\Vert \xi\Vert=1$ is called a \textbf{unit vector}. \index{00@Unit vector} 
\end{df}

By Prop. \ref{lb113}, a positive sesquilinear form is Hermitian. More generally, we have the following definition:

\begin{df}\label{lb140}
Let $\omega_1,\omega_2$ be Hermitian forms on $V$. We write\index{zz@$\omega_1\leq\omega_2$ where $\omega_1,\omega_2$ are Hermitian forms}
\begin{align*}
\pmb{\omega_1\leq\omega_2}
\end{align*}
(equivalently, $\omega_2\geq\omega_1$) if the (real-valued) quadratic forms associated to $\omega_1$ and $\omega_2$ satisfy the corresponding inequality, that is,
\begin{align*}
\omega_1(\xi|\xi)\leq\omega_2(\xi|\xi)\qquad\text{for each }\xi\in V
\end{align*}
Thus, ``$\leq$'' defines a partial order on the set of Hermitian forms on $V$. Moreover, the meaning of $0\leq\omega$ agrees with that in Def. \ref{lb139}
\end{df}




\begin{thm}[\textbf{Cauchy-Schwarz inequality}] \index{00@Cauchy-Schwarz inequality}\label{lb165}
Let $\bk{\cdot|\cdot}$ be a positive sesquilinear form on $V$. Then for each $\xi,\eta\in V$ we have
\begin{align*}
|\bk{\xi|\eta}|\leq\Vert \xi\Vert\cdot\Vert \eta\Vert
\end{align*}
\end{thm}

\begin{proof}
By linear algebra, if $f:\Rbb^2\rightarrow\Rbb$ is a quadratic form
\begin{align*}
f(x,y)=\begin{pmatrix}
x&y
\end{pmatrix}\begin{pmatrix}
a&b\\
b&c
\end{pmatrix}
\begin{pmatrix}
x\\
y
\end{pmatrix}
=ax^2+2bxy+cy^2
\end{align*}
where $a,b,c\in\Rbb$, then $f\geq0$ iff $a\geq0,b\geq0$ and
\begin{align*}
ac-b^2\equiv\det\begin{pmatrix}
a&b\\
b&c
\end{pmatrix}\geq0
\end{align*}
Indeed, we only need the fact that if $f\geq0$ then $ac-b^2\geq0$. To see this, note that if $f$ is not always $0$, then one of $a,c$ must be nonzero; otherwise, $f(x,y)=2bxy$ cannot be always $\geq0$. Thus, assume WLOG that $a\neq0$. Then $f(x,1)=ax^2+2bx+c=a(x+b/a)^2+c-b^2/a$, which implies $a>0$ and $c-b^2/a\geq0$, and hence $ac-b^2\geq0$.

Now, we let $f:\Rbb^2\rightarrow\Rbb_{\geq0}$ be the quadratic form defined by pulling back the form $\xi\in V\mapsto\bk{\xi|\xi}$ via the map $(x,y)\in\Rbb^2\mapsto x\xi+y\eta\in V$, that is,
\begin{align*}
f(x,y)=\bk{x\xi+y\eta|x\xi+y\eta}=\Vert \xi\Vert^2\cdot x^2+2\Real\bk{\xi|\eta}\cdot xy+\Vert \eta\Vert^2\cdot y^2
\end{align*}
Then, the above paragraph shows that $\Vert \xi\Vert^2\cdot\Vert \eta\Vert^2-(\Real\bk{\xi|\eta})^2\geq0$, equivalently,
\begin{align*}
|\Real\bk{\xi|\eta}|\leq \Vert \xi\Vert\cdot\Vert \eta\Vert
\end{align*}
Choose $\lambda\in\Sbb^1$ such that $\lambda\bk{\xi|\eta}\in\Rbb$. Since the above inequality holds when $\eta$ is replaced by $\lambda \eta$, we get
\begin{align*}
|\bk{\xi|\eta}|=|\Real\bk{\xi|\lambda \eta}|\leq\Vert \xi\Vert\cdot\Vert \lambda \eta\Vert=\Vert \xi\Vert\cdot\Vert \eta\Vert
\end{align*}
\end{proof}

\begin{co}\label{lb164}
Let $\bk{\cdot|\cdot}$ be a positive sesquilinear form on $V$. Then we have
\begin{align*}
\{\xi\in V:\Vert \xi\Vert=0\}=\{\xi\in V:\bk{\xi|\psi}=0\text{ for all }\psi\in V\}
\end{align*}
where the RHS is clearly a linear subspace of $V$. We call this space the \textbf{null space} of $\bk{\cdot|\cdot}$. \index{00@Null space of a positive sesquilinear form}
\end{co}

\begin{proof}
Let $\xi\in V$. If $\bk{\xi|V}=0$, then $\Vert \xi\Vert^2=\bk{\xi|\xi}=0$. Conversely, if $\Vert \xi\Vert=0$, then by the Cauchy-Schwarz inequality, for each $\psi\in V$ we have $|\bk{\xi|\psi}|\leq \Vert \xi\Vert\cdot\Vert\psi\Vert=0$.
\end{proof}





\begin{co}\label{lb115}
Let $\bk{\cdot|\cdot}$ be a positive sesquilinear form on $V$. Then $\xi\in V\mapsto\Vert \xi\Vert\in\Rbb_{\geq0}$ is a seminorm on $V$. 
\end{co}

\begin{proof}
It remains to check the subadditivity: for each $\xi,\eta\in V$, the Cauchy-Schwarz inequality imlies
\begin{align*}
&\Vert \xi+\eta\Vert^2=\bk{\xi+\eta|\xi+\eta}=\Vert \xi\Vert^2+2\Real\bk{\xi|\eta}+\Vert \xi\Vert^2\\
\leq& \Vert \xi\Vert^2+2\Vert \xi\Vert\cdot\Vert \eta\Vert+\Vert \eta\Vert^2=(\Vert \xi\Vert+\Vert \eta\Vert)^2
\end{align*}
\end{proof}






\subsection{Inner product spaces and bounded sesquilinear forms}




\subsubsection{Inner product spaces}




\begin{df}
Let $\bk{\cdot|\cdot}$ be a positive sesquilinear form on a $\Cbb$-vector space $V$. We call $\bk{\cdot|\cdot}$ an \textbf{inner product} \index{00@Inner product} if it is  \textbf{non-degenerate}, i.e., the null space is $0$.  We call the pair $(V,\bk{\cdot|\cdot})$ (or simply call $V$) an \textbf{inner product space} or a \textbf{pre-Hilbert space} \index{00@Inner product space, also called pre-Hilbert space}.
\end{df}



\begin{exe}\label{lb346}
Let $\bk{\cdot|\cdot}$ be a positive sesquilinear form on $V$ with null space $\scr N$. Prove that there is a (necessarily unique) inner product $\bk{\cdot|\cdot}_{V/\scr N}$ on the quotient space $V/\scr N$ such that for any $\xi,\eta\in V$, the cosets $\xi+\scr N$ and $\eta+\scr N$ satisfy
\begin{align*}
\bk{\xi+\scr N|\eta+\scr N }_{V/\scr N}=\bk{\xi|\eta}
\end{align*}
\end{exe}


\begin{eg}
Let $X$ be a set. Then $l^2(X)=l^2(X,\Cbb)$ is an inner product space, where
\begin{align*}
\bk{f|g}=\sum_{x\in X} \ovl{f(x)}g(x)\qquad\text{for any }f,g\in l^2(X)
\end{align*} 
\end{eg}


\begin{eg}
Let $(X,\mu)$ be a measure space. Then $L^2(X,\mu)$ is an inner product space, where
\begin{align*}
\bk{f|g}=\int_X \ovl fgd\mu\qquad\text{for any }f,g\in L^2(X,\mu)
\end{align*}
\end{eg}


\begin{rem}
By Rem. \ref{lb115}, an inner product space $V$ is equipped with the norm defined by $\Vert \xi\Vert=\sqrt{\bk{\xi|\xi}}$. In particular, $V$ is a metric space with metric $d(\xi,\eta)=\Vert \xi-\eta\Vert$. The topology on $V$ induced by this metric is called the \textbf{norm topology} \index{00@Norm topology} of $V$. 
\end{rem}

\begin{rem}
Let $V,W$ be inner product spaces. If $T:V\rightarrow V$ is a linear map, then $T$ is an isometry of metric spaces iff $T$ is an isometry of normed vector spaces, i.e., 
\begin{align*}
\bk{T\xi|T\xi}=\bk{\xi|\xi}\qquad \text{for all }\xi\in V
\end{align*}
By the polarization identity, this is equivalent to
\begin{align*}
\bk{T\xi|T\eta}=\bk{\xi|\eta}\qquad \text{for all }\xi,\eta\in V
\end{align*} 
A surjective linear isometry $T:V\rightarrow W$ is called a \textbf{unitary map}. \index{00@Unitary maps} If $T:V\rightarrow W$ is unitary, we say that $V,W$ are \textbf{isomorphic inner product spaces} (or that $V,W$ are \textbf{unitarily equivalent}). \index{00@Unitarily equivalent} 


Similarly, if $T:V\rightarrow V$ is antilinear map between inner product spaces, then $T$ is an isometry of metric spaces iff
\begin{align*}
\bk{T\xi|T\xi}=\bk{\xi|\xi}\qquad \text{for all }\xi\in V
\end{align*}
By the polarization identity, this is equivalent to
\begin{align*}
\bk{T\xi|T\eta}=\bk{\eta|\xi}\qquad \text{for all }\xi,\eta\in V
\end{align*}
A surjective antilinear isometry $T:V\rightarrow W$ is called an \textbf{antiunitary map}. \index{00@Antiunitary map} If $T:V\rightarrow W$ is antiunitary, we say that $V$ and $W$ are \textbf{antiunitarily equivalent}. \hqed
\end{rem}



\subsubsection{Bounded sesquilinear forms}




Let $V,W$ be inner product spaces.



\begin{df}
The \textbf{(complex) conjugate} \index{00@Conjugate inner product space $V^\Co$} of $V$ is the inner product space $V^\Co$ \index{VCo@$V^\Co$} defined as follows. The elements of $V^\Co$ correspond bijectively to those of $V$ by the map \index{zz@$\xi^\Co=\ovl \xi$}
\begin{align*}
\Co:V\rightarrow V^\Co\qquad \xi\mapsto \xi^\Co\equiv\ovl \xi
\end{align*}
where $\xi^\Co\equiv\ovl \xi$ is an abstract element, called the \textbf{conjugate} of $\xi$. Moreover, the structure of an inner product space on $V^\Co$ is defined in such a way that $\Co$ is antiunitary. In other words, for each $\xi,\eta\in V$ and $a,b\in\Cbb$, we have
\begin{gather*}
\ovl a\cdot\ovl \xi+\ovl b\cdot\ovl \eta:=\ovl{a\xi+b\eta}\\
\bk{\ovl \xi|\ovl \eta}_{V^\Co}:=\ovl{\bk{\xi|\eta}_V}=\bk{\eta|\xi}_V
\end{gather*}

The conjugate of $V^\Co$ is defined to be $V$, that is,
\begin{align*}
(V^\Co)^\Co=V
\end{align*}
Moreover, the conjugate map $\Co:V^\Co\rightarrow V$ is defined by
\begin{align*}
\Co:V^\Co\rightarrow V\qquad \ovl \xi\mapsto \xi
\end{align*}
Thus $\ovl{\ovl \xi}=\xi$ for each $\xi\in V$. \hqed
\end{df}


\begin{rem}
An antilinear map $T:V\rightarrow W$ is equivalent to the linear map
\begin{subequations}\label{eq61}
\begin{gather}\label{eq61a}
V\rightarrow W^\Co\qquad \xi\mapsto \ovl{T\xi}
\end{gather}
and is also equivalent to the linear map
\begin{align}\label{eq61b}
V^\Co\rightarrow W\qquad \ovl \xi\mapsto T\xi
\end{align}
\end{subequations}
It is clear that $T$ is an antilinear isometry (resp. antiunitary) iff \eqref{eq61a} is a linear isometry (resp. unitary) iff \eqref{eq61b} is a linear isometry (resp. unitary).
\end{rem}


\begin{rem}
A sesquilinear form $\omega:V\times W\rightarrow \Cbb$ is equivalent to a bilinear form
\begin{align*}
\wtd\omega:V^\Co\times W\rightarrow\Cbb\qquad (\ovl \xi,\eta)\mapsto \bk{\xi|\eta}
\end{align*}
Unless otherwise stated, we always view $\omega$ and $\wtd\omega$ as the same.
\end{rem}

\begin{df}
Let $\omega:V\times W\rightarrow\Cbb$ be a sesquilinear form. The \textbf{norm} \index{00@Norm of sesquilinear forms} $\Vert\omega\Vert$ is defined to be the norm of the associated bilinear form $V^\Co\times W\rightarrow\Cbb$. That is, 
\begin{align*}
\Vert\omega\Vert=\sup_{\xi\in\ovl B_V(0,1),\eta\in\ovl B_W(0,1)}|\omega(\xi|\eta)|
\end{align*}
Recalling the notation \eqref{eq26}, we let \index{Sesq@$\Ses(V\vert W)$ and $\Ses(V)$}
\begin{align*}
\Ses(V|W):=\fk L(V^\Co\times W,\Cbb)
\end{align*}
which is the space of bounded sesquilinear forms $V\times W\rightarrow\Cbb$. We write
\begin{align*}
\Ses(V):=\Ses(V|V)
\end{align*}
The elements of $\Ses(V|W)$ (resp. $\Ses(V)$) are called \textbf{bounded sesquilinear forms} \index{00@Bounded sesquilinear forms} on $V\times W$ (resp. on $V$).
\end{df}


\begin{eg}\label{lb125}
The inner product
\begin{align*}
\bk{\cdot|\cdot}:V\times V\rightarrow\Cbb\qquad (\xi,\eta)\mapsto\bk{\xi|\eta}
\end{align*}
has norm $1$, and hence belongs to $\Ses(V)$. Therefore, by Prop. \ref{lb35}, this map is continuous.
\end{eg}

The following useful property says that a sesquilinear form is bounded iff the associated quadratic form is bounded.

\begin{pp}\label{lb238}
Let $\omega$ be sesquilinear form on $V$. Let $M\in\Rbb_{\geq0}$. Assume that
\begin{align*}
|\omega(\xi|\xi)|\leq M\Vert\xi\Vert^2
\end{align*}
for each $\xi\in V$. Then $\Vert\omega\Vert\leq 4M$.
\end{pp}

\begin{proof}
Choose any $\xi,\eta\in \ovl B_V(0,1)$. For each $\lambda\in\Sbb^1$, we have
\begin{align*}
|\omega(\lambda\xi+\eta|\lambda\xi+a\eta)|\leq M\Vert \lambda\xi+\eta\Vert^2\leq M(\Vert\xi\Vert+\Vert\eta\Vert)^2\leq 4M
\end{align*}
Therefore, by the polarization identity \eqref{eq134},
\begin{align*}
|\omega(\xi|\eta)|=\frac 14\Big\Vert\sum_{t=0,\frac \pi 2,\pi,\frac{3\pi}2}~ \omega(e^{\im t}\xi+\eta|e^{\im t}\xi+
\eta)e^{\im t}\Big\Vert\leq 4M
\end{align*}
\end{proof}



\subsection{Orthogonality}



Let $V$ be an inner product space.



\subsubsection{Orthogonal and orthonormal vectors}

\begin{df}
A set $\fk S$ of vectors of $V$ are called \textbf{orthogonal} \index{00@Orthogonal} if $\bk{\xi|\eta}=0$ for any distinct $\xi,\eta\in V$. An orthogonal set $\fk S$ is called \textbf{orthonormal} \index{00@Orthonormal} if $\Vert \xi\Vert=1$ for all $\xi\in \fk S$. 
\end{df}

\begin{rem}
We will also talk about an \textbf{orthogonal} resp.  \textbf{orthonormal family of vectors} $(e_i)_{i\in I}$. This means that $\bk{e_i|e_j}=0$ for any distinct $i,j\in I$ (resp. $\bk{e_i|e_j}=\delta_{i,j}$ for any $i,j\in I$). 
\end{rem}

In particular, two vectors $u,v\in V$ are called orthogonal and written as \index{zz@$\xi\perp \eta$}
\begin{align*}
\xi\perp \eta
\end{align*}
when $\bk{\xi|\eta}=0$. A fundamental fact about orthogonal vectors is
\begin{pp}[\textbf{Pythagorean identity}]\index{00@Pythagorean identity}
Suppose that $\xi,\eta\in V$ are orthogonal. Then
\begin{align}\label{eq62}
\Vert \xi+\eta\Vert^2=\Vert \xi\Vert^2+\Vert \eta\Vert^2
\end{align}
In particular,
\begin{align}\label{eq63}
\Vert \xi\Vert\leq\Vert \xi+\eta\Vert
\end{align}
\end{pp}


\begin{proof}
$\Vert \xi+\eta\Vert^2=\bk{\xi+\eta|\xi+\eta}=\bk{\xi|\xi}+\bk{\eta|\eta}+2\Real \bk{\xi|\eta}=\bk{\xi|\xi}+\bk{\eta|\eta}$.
\end{proof}


Note that by applying \eqref{eq62} repeatedly, we see that if $\xi_1,\dots,\xi_n\in V$ are orthogonal, then
\begin{align}\label{eq64}
\Vert \xi_1+\cdots+\xi_n\Vert^2=\Vert \xi_1\Vert^2+\cdots+\Vert \xi_n\Vert^2
\end{align}



\begin{rem}
Suppose that $\fk S$ is an orthonormal set of vectors of $V$. Then $\fk S$ is clearly linearly independent. (If $e_1,\dots,e_n\in\fk S$ and $\sum_i a_ie_i=0$, then $a_j=\sum_i\bk{e_j|a_ie_i}=\bk{e_j|0}=0$.) Thus, by linear algebra, if $\fk S=\{e_1,\dots,e_n\}$ is finite, then for each $\xi\in V$, one can find uniquely $a_1,\dots,a_n\in\Cbb$ and $\eta\in V$ such that $\xi=a_1e_1+\cdots+a_ne_n+\eta$ and that $\eta$ is orthogonal to $e_1,\dots,e_n$. The expressions of $a_1,\dots,a_n,\eta$ can be expressed explicitly:
\end{rem}


\begin{pp}[\textbf{Gram-Schmidt}]\index{00@Gram-Schmidt}
Let $e_1,\dots,e_n$ be orthonormal vectors in $V$. Let $\xi\in V$. Then
\begin{align}
\xi-\sum_{i=1}^n e_i\cdot \bk{e_i|\xi}
\end{align}
is orthogonal to $e_1,\dots,e_n$.
\end{pp}

\begin{proof}
This is a direct calculation and is left to the readers.
\end{proof}


\begin{rem}\label{lb117}
``Gram-Schmidt'' usually refers to the following process. Let $\xi_1,\dots,\xi_n$ be a set of linearly independent vectors of $V$. Then there is an algorithm of finding an orthonormal basis of $U=\Span\{\xi_1,\dots,\xi_n\}$: Let $e_1=\xi_1/\Vert \xi_1\Vert$. Suppose that a set of orthonormal vectors $e_1,\dots,e_k$ in $U$ have been found. Then $e_{k+1}$ is defined by $\wtd \xi_{k+1}/\Vert\wtd \xi_{k+1}\Vert$ where $\wtd \xi_{k+1}=\xi_{k+1}-\sum_{i=1}^k e_i\cdot\bk{e_i|\xi_{k+1}}$.
\end{rem}



Combining Pythagorean with Gram-Schmidt, we have:
\begin{co}[\textbf{Bessel's inequality}]\label{lb118}
Let $(e_i)_{i\in I}$ be a family of orthonormal vectors of $V$. Then for each $\xi\in V$ we have
\begin{align}\label{eq65}
\sum_{i\in I}|\bk{e_i|\xi}|^2\leq \Vert \xi\Vert^2
\end{align}
In particular, the set $\{i\in I:\bk{e_i|\xi}\neq0\}$ is countable.
\end{co}




\begin{proof}
The LHS of \eqref{eq65} is $\lim_{J\in\fin(2^I)}\sum_{j\in J}|\bk{e_j|\xi}|^2$. Thus, it suffices to show that for each $J\in\fin(2^I)$ we have $\sum_{j\in J}|\bk{e_j|\xi}|^2\leq \Vert \xi\Vert^2$. Let 
\begin{align*}
\eta_1=\sum_{j\in J}e_j\cdot\bk{e_j|\xi} \qquad \eta_2=\xi-\eta_1
\end{align*}
(Namely, $\xi=\eta_1+\eta_2$ is the orthogonal decomposition of $\xi$ with respect to $\Span\{e_j:j\in J\}$.) By Gram-Schmidt, we have $\bk{\eta_1|\eta_2}=0$. By Pythagorean, we have $\Vert \eta_1\Vert^2\leq\Vert \xi\Vert^2$. But Pythagorean \eqref{eq64} also implies
\begin{align*}
\Vert \eta_1\Vert^2=\sum_{j\in J}|\bk{e_j|\xi}|^2
\end{align*}
The last statement about countability follows from Prop. \ref{lb235}.
\end{proof}



\subsubsection{Orthogonal decomposition}


\begin{df}\label{lb119}
Let $U$ be a linear subspace of $V$. Let $\xi\in V$. An \textbf{orthogonal decomposition} \index{00@Orthogonal decomposition and orthonal projection} of $\xi$ with respect to $U$ is an expression of the form
\begin{align*}
\xi=\eta+\psi\qquad \text{where $\eta\in U$ and $\psi\perp U$}
\end{align*}
Orthogonal decompositions of $\xi$ are unique if exist. We call $\eta$ the \textbf{orthogonal projection} of $\xi$ onto $U$.
\end{df}

\begin{proof}[Proof of uniqueness]
Suppose that $\xi=\eta'+\psi'$ is another orthogonal decomposition. Then $\eta-\eta'$ equals $\psi'-\psi$. Let $\mu=\eta-\eta'$. Then $\mu\in U$ and $\mu\perp U$. So $\bk{\mu|\mu}=0$, and hence $\mu=0$. So $\eta=\eta'$ and $\psi=\psi'$.
\end{proof}


\begin{df}\label{lb246}
Let $U$ be a linear subspace of $V$. We say that $V$ \textbf{has a projection onto $U$} \index{00@Projection onto a linear subspace} if every vector has an orthogonal decomposition with respect to $U$. In that case, we define the map
\begin{align*}
P:V\rightarrow V
\end{align*}
determined by the fact that each $\xi\in V$ has orthogonal decomposition $\xi=P\xi+(\xi-P\xi)$ where $P\xi\in U$ and $\xi-P\xi\perp U$. Clearly $P$ is linear. By the Pythagorean identity, we have $\Vert P\xi\Vert\leq\Vert \xi\Vert$, and hence 
\begin{align*}
\Vert P\Vert\leq 1
\end{align*} 
Thus $P\in\fk L(V)$. We say that $P$ is the \textbf{projection (operator) associated to $U$}. \index{00@Projection (operator) associated to a linear subspace}
\end{df}


\begin{eg}\label{lb124}
Let $e_1,\dots,e_n$ be orthonormal vectors of $V$. Let $U=\Span\{e_1,\dots,e_n\}$. Choose any $\xi\in V$. Then by Gram-Schmidt,
\begin{align}
\xi=\eta+w\qquad\text{where }\eta=\sum_{i=1}^ne_i\cdot\bk{e_i|\xi}\text{ and }\psi=\xi-\eta
\end{align}
is the orthogonal decomposition of $\xi$ with respect to $U$. Therefore, the projection operator associated to $U$ is 
\begin{align*}
V\rightarrow V\qquad \xi\mapsto\sum_{i=1}^n e_i\cdot\bk{e_i|\xi}
\end{align*}
\end{eg}

\begin{pp}\label{lb120}
Let $U$ be a linear subspace of $V$. Suppose that $\xi\in V$ has orthogonal decomposition $\xi=\eta+\psi$ with respect to $U$. Then
\begin{align}
\Vert \xi-\eta\Vert=\inf_{\mu\in U}\Vert \xi-\mu\Vert
\end{align}
\end{pp}


\begin{proof}
Clearly ``$\geq$'' holds. Choose any $\xi\in U$. Then $\xi-\mu=\xi-\eta+\eta-\mu=\psi+(\eta-\mu)$. Since $\eta-\mu\in U$, we have $\psi\perp \eta-\mu$. Thus, by Pythagorean, we have $\Vert \psi\Vert\leq\Vert \xi-\mu\Vert$.
\end{proof}



\subsubsection{Direct sums and orthogonal decomposition}

Next, we give a more explicit description of orthogonal decomposition in terms of direct sum.


\begin{df}
Let $V_1,\dots,V_n$ be inner product spaces. Their \textbf{(orthogonal) direct sum} \index{00@Direct sums of inner product spaces} \pmb{$V_1\oplus\cdots\oplus V_n$} is an inner product space defined as follows. As a set, $V_1\oplus\cdots\oplus V_n$ equals $V_1\times\cdots\times V_n$. So it consists of elements of the form $(\xi_1,\dots,\xi_n)$ where $\xi_i\in V_i$. We write $(\xi_1,\dots,\xi_n)$ as $\xi_1\oplus\cdots\oplus \xi_n$. The linear structure is defined by
\begin{gather*}
(\xi_1\oplus\cdots\oplus \xi_n)+(\xi_1'\oplus\cdots\oplus \xi_n')=(\xi_1+\xi_1')\oplus\cdots\oplus (\xi_n+\xi_n')\\
a(\xi_1\oplus\cdots\oplus \xi_n)=a\xi_1\oplus\cdots\oplus a\xi_n
\end{gather*}
where $\xi_i,\xi_i'\in V_i$ and $a\in\Cbb$. The inner product is defined by
\begin{align*}
\bk{\xi_1\oplus\cdots\oplus \xi_n|\xi_1'\oplus\cdots\oplus \xi_n'}=\bk{\xi_1|\xi_1'}+\cdots+\bk{\xi_n|\xi_n'}
\end{align*}
We view $V_i$ as an inner product subspace of $V_1\oplus\cdots\oplus V_n$ by identifying $\xi_i\in V_i$ with $0\oplus\cdots\oplus \xi_i\oplus\cdots\oplus 0\in V_1\oplus\cdots\oplus V_n$. Then, it is clear that $V_i\perp V_j$ if $i\neq j$.
\end{df}

\begin{rem}
Suppose that $U_1,\dots,U_n$ are mutually orthogonal linear subspaces of $V$. Then we clearly have a linear isometry
\begin{gather}\label{eq73}
U_1\oplus\cdots\oplus U_n\longrightarrow V\qquad u_1\oplus\cdots\oplus u_n\mapsto u_1+\cdots+u_n
\end{gather}
Therefore, if $V$ is spanned by $U_1,\dots,U_n$, then \eqref{eq73} is surjective, and hence is an isomorphism of normed vector spaces. In that case, we say that \eqref{eq73} is the \textbf{canonical isomorphism} from $U_1\oplus\cdots\oplus U_n$ to $V$. With abuse of notation, we also say that $V$ ``is'' the direct sum $U_1\oplus\cdots\oplus U_n$. 
\end{rem}


\begin{eg}\label{lb145}
Let $U_1,U_2$ be inner product spaces and $V=U_1\oplus U_2$. Then $V$ has a projection onto $U_1$. The projection operator associated to $U_1$ is defined by sending each $u_1\oplus u_2$ to $u_1$.
\end{eg}


We now show that any projection is unitarily equivalent to the one given in Exp. \ref{lb145}.

\begin{df}
If $\fk S$ is a subset of $V$, we define the \textbf{orthogonal complement} \index{00@Orthogonal complement} of $\fk S$ (in $V$) to be \index{S@$\fk S^\perp$}
\begin{align*}
\pmb{\fk S^\perp}=\{\xi\in V:\bk{\xi|u}=0\text{ for all }u\in \fk S\}
\end{align*}
In the case that $\fk G$ is a linear subspace $U$, we also write \index{VU@$V\ominus U$}
\begin{align*}
\pmb{V\ominus U}:=U^\perp
\end{align*}
\end{df}

\begin{rem}\label{lb150}
Let $U$ be a linear subspace of $V$. Then $U^\perp$ is closed in $V$, since it is the intersection of kernels of the bounded linear map $\xi\in V\mapsto\bk{\xi|u}$ over all $u\in U$. Moreover, by the continuity of $\bk{\cdot|\cdot}:V\times V\rightarrow\Cbb$, a vector of $V$ is orthogonal to $U$ iff it is orthogonal to $\ovl U=\Cl_V(U)$, that is,
\begin{align*}
U^\perp=\ovl U^\perp
\end{align*}
\end{rem}



\begin{eg}
If $U_1,U_2$ are inner product spaces, then $U_1$ and $U_2$ are the orthogonal complements of each other in $U_1\oplus U_2$. 
\end{eg}

\begin{pp}\label{lb146}
Let $U$ be a linear subspace of $V$. Suppose that $V$ has a projection onto $U$, and let $P$ the projection operator onto $U$. Then $V$ is canonically isomorphic to $U\oplus U^\perp$. Moreover, identifying $U\oplus U^\perp$ with $V$ (by identifying $u\oplus v$ with $u+v$ if $u\in U,v\in U^\perp$), then
\begin{align*}
P:U\oplus U^\perp\rightarrow U\oplus U^\perp\qquad u\oplus v\mapsto u=u\oplus 0
\end{align*}
Consequently, $1-P$ is the projection of $V$ onto $U^\perp$, and we have 
\begin{align}\label{eq140}
\Rng(P)=\Ker(1-P)=U\qquad \Ker(P)=\Rng(1-P)=U^\perp
\end{align}
\end{pp}

It follows from $V=U\oplus U^\perp$ that $U$ is the orthogonal complement of $U^\perp$, i.e., $U=U^{\perp\perp}$.

\begin{proof}
The surjectivity of the linear isometry
\begin{gather*}
U\oplus U^\perp\rightarrow V\qquad u\oplus v\mapsto u+v
\end{gather*}
follows from the fact that $V$ has a projection onto $U$. Clearly $P$ sends $u+v$ to $u$. The rest of this proposition is obvious.
\end{proof}




\begin{co}
Suppose that $U$ is a finite-dimensional linear subspace of $V$. Then $U$ is closed in $V$.
\end{co}


\begin{proof}
By Exp. \ref{lb124}, there is a projection operator $P$ of $V$ onto $U$. By Prop. \ref{lb146}, $U$ is the orthogonal complement of $U^\perp$, and hence is closed.
\end{proof}


\begin{co}\label{lb171}
Let $U$ be a linear subspace of $V$, and suppose that $V$ has a projection onto $U$. Let $P$ be the projection operator associated to $U$. Then $P^2=P$, and the sesquilinear form $\omega_P:V\times V\rightarrow\Cbb$ defined by $\omega_P(\xi|\eta)=\bk{\xi|P\eta}$ is positive.
\end{co}


\begin{proof}
By Prop. \ref{lb146}, we assume that $V=U\oplus U^\perp$, and $P$ sends each $u\oplus v\in U\oplus U^\perp$ to $\xi=\xi\oplus 0$. Then it is easy to verify that $P^2=P$. Moreover, $\omega_P(u\oplus v)=\Vert u\Vert^2\geq0$.
\end{proof}




\subsubsection{Orthonormal basis}



\begin{df}\label{lb121}
A set $\fk S$ (or a family $(e_i)_{i\in I}$) of orthonormal vectors of $V$ is called an \textbf{orthonormal basis} \index{00@Orthonormal basis} of $V$ if it spans a dense subspace of $V$.  
\end{df}

\begin{eg}
If $X$ is a set, by Prop. \ref{lb109}, $l^2(X)$ has an orthonormal basis $(\chi_{\{x\}})_{x\in X}$.
\end{eg}


\begin{eg}\label{lb122}
If $V$ is separable, then $V$ has a countable orthonormal basis.
\end{eg}

\begin{proof}
Let $\{v_1,v_2,\dots\}$ be a dense subset of $V$ where $v_1\neq 0$. Then by Gram-Schmidt (Rem. \ref{lb117}), we can find $e_1,e_2,\dots\in V$ such that the set $\{e_1,e_2,\dots\}$ is orthnormal (after removing the duplicated terms), and that $\Span\{v_1,\dots,v_n\}=\Span\{e_1,\dots,e_n\}$ for each $n$. Then $\{e_1,e_2,\dots\}$ clearly spans a dense subspace of $V$.
\end{proof}

We remark that there are non-separable and non-complete inner product spaces that do not have orthonormal bases. See \cite{Gud74}.


\begin{thm}\label{lb123}
Suppose that $(e_i)_{i\in I}$ is an orthonormal basis of $V$. Then for each $\xi\in V$, the RHS of the following converges (in the norm of $V$) to the LHS:
\begin{align}
\xi=\sum_{i\in I}e_i\cdot\bk{e_i|\xi}
\end{align}
\end{thm}

\begin{proof}
Note that for $J\in\fin(2^I)$, the expression
\begin{align*}
\Big\Vert \xi-\sum_{j\in J}e_j\cdot\bk{e_j|\xi}\Big\Vert^2=\Vert \xi\Vert^2-\sum_{j\in J}|\bk{e_j|\xi}|^2
\end{align*}
decreases when $J$ increases. Thus, it suffices to prove that the $\inf_{J\in \fin(2^I)}$ of this expression is $0$. 

By assumption,  we can find $J\in\fin(2^I)$ and $(\lambda_j)_{j\in J}$ in $\Cbb$ such that $\Vert \xi-\sum_{j\in J}\lambda_je_j\Vert$ is small enough. On the other hand, applying Prop. \ref{lb120} to the orthogonal projection $\xi=\eta+\psi$ where $\eta=\sum_{j\in J}e_j\cdot\bk{e_j|\xi}$ (cf. Exp. \ref{lb124}), we have
\begin{align}
\Big\Vert \xi-\sum_{j\in J}e_j\cdot\bk{e_j|\xi}\Big\Vert\leq \Big\Vert \xi-\sum_{j\in J}\lambda_je_j\Big\Vert
\end{align}
Thus, the infimum of the LHS over $J\in\fin(2^I)$ is zero.
\end{proof}



\begin{co}[\textbf{Parseval's identity}]\index{00@Parseval's identity}\label{lb601}
Suppose that $(e_i)_{i\in I}$ is an orthonormal basis of $V$. Then for each $\xi,\eta\in V$ we have
\begin{align}\label{eq246}
\bk{\xi|\eta}=\sum_{i\in I}\bk{\xi|e_i}\cdot\bk{e_i|\eta}
\end{align}
In particular,
\begin{align}
\Vert \xi\Vert^2=\sum_{i\in I}|\bk{e_i|\xi}|^2
\end{align}
\end{co}

\begin{proof}
By Thm. \ref{lb123}, $\xi=\lim_{J\in\fin(2^I)}\xi_J$ where $\xi_J=\sum_{j\in J}e_j\cdot\bk{\xi|e_j}$. By the continuity of $\bk{\cdot|\cdot}:V\times V\rightarrow\Cbb$ (Exp. \ref{lb125}), we have
\begin{align*}
\bk{\eta|\xi}=\lim_{J\in\fin(2^I)}\bk{\eta|\xi_J}=\lim_{J\in\fin(2^I)}\sum_{j\in J}\bk{\eta|e_j}\cdot\bk{e_j|\xi}=\sum_{i\in I}\bk{\eta|e_i}\cdot\bk{e_i|\xi}
\end{align*}
\end{proof}



\begin{co}\label{lb126}
Suppose that $(e_x)_{x\in X}$ is an orthonormal basis of $V$. Then there is a linear isometry
\begin{gather}\label{eq66}
\Phi:V\rightarrow l^2(X)\qquad \xi\mapsto \big(\bk{e_x|\xi})_{x\in X}
\end{gather} 
whose range is dense in $l^2(X)$.
\end{co}




\begin{proof}
Parseval's identity shows that $(\bk{e_x|\xi})_{x\in X}$ has finite $l^2$-norm $\Vert \xi\Vert$. So the map $\Phi$ defined by \eqref{eq66} is clearly a linear isometry. The density of the range of $\Phi$ follows from the fact that $l^2(X)$ contains all $\chi_{\{x\}}=\Phi(e_x)$, and that $\Span\{\chi_{\{x\}}:x\in X\}$ is dense in $l^2(X)$ (cf. Prop. \ref{lb109}).
\end{proof}




\subsection{Hilbert spaces}


\begin{thm}\label{lb129}
Let $\MH$ be an inner product space. Then the following three conditions are equivalent:
\begin{enumerate}[label=(\alph*)]
\item $\MH$ is (Cauchy) complete.
\item For each orthonormal family $(e_i)_{i\in I}$ in $\MH$, and for each family $(a_i)_{i\in I}$ in $\Cbb$ satisfying $\sum_{i\in I}|a_i|^2<+\infty$, the unordered sum $\sum_{i\in I}a_ie_i$ converges (in the norm of $\MH$).
\item $\MH$ is unitarily equivalent to $l^2(X)$ for some set $X$.
\end{enumerate} 
If $\MH$ satisfies any of these conditions, we say that $\MH$ is a \textbf{Hilbert space}.
\end{thm}



\begin{proof}
(c)$\Rightarrow$(a): By Prop. \ref{lb38}, $l^2(X)$ is complete.

(a)$\Rightarrow$(b): Since $\sum_i |a_i|^2<+\infty$, for each $\eps>0$ there exists $J\in\fin(2^I)$ such that for all finite $K\subset I\setminus J$ we have $\sum_{k\in K}|a_k|^2<\eps$, and hence, by the Pythagorean identity,
\begin{align*}
\Big\Vert \sum_{k\in K}a_ke_k\Big\Vert^2=\sum_{k\in K}\Vert a_ke_k\Vert^2<\eps
\end{align*}
Thus $(\sum_{j\in J}a_je_j)_{J\in\fin(2^I)}$ is a Cauchy net. Since any Cauchy net in a complete metric space converges (Thm. \ref{lb269}), by the completeness of $\MH$, the unordered sum $\sum_{i\in I}a_ie_i$ must converge.

(b)$\Rightarrow$(c): Assume (b). We first show that $\MH$ has an orthonormal basis. By Zorn's lemma, we can find a maximal (with respect to the partial order $\subset$) set of orthonormal vectors, written as a family $(e_i)_{i\in I}$. The maximality implies that every nonzero vector $\xi\in \MH$ is not orthogonal to some $e_i$. (Otherwise, $\{e_i:i\in I\}$ can be extended to $\{e_i:i\in I\}\cup\{\xi/\Vert\xi\Vert\}$.)

Let us prove that $(e_i)_{i\in I}$ is an orthonormal basis. Suppose not. Then $U=\Span\{e_i:i\in I\}$ is not dense in $\MH$. Let $\xi\in \MH\setminus \ovl{U}$. By Bessel's inequality, we have
\begin{align*}
\sum_{i\in I}|\bk{e_i|\xi}|^2<+\infty
\end{align*}
Therefore, by (b),
\begin{align}
\sum_{i\in I}e_i\cdot\bk{e_i|\xi}
\end{align}
converges to some vector $\eta\in \MH$. By the continuity of $\bk{\cdot|\cdot}$ (Exp. \ref{lb125}), we see that $\bk{e_i|\eta}=\bk{e_i|\xi}$ for all $i$, and hence
\begin{align}\label{eq74}
\bk{e_i|\xi-\eta}=0\qquad\text{ for all }i\in I
\end{align}
Since $\eta\in\ovl U$ and $\xi\notin\ovl U$, we conclude that $\xi-\eta$ is a nonzero vector orthogonal to all $e_i$. This contradicts the maximality of $(e_i)_{i\in I}$.

Now we have an orthonormal basis $(e_i)_{i\in I}$. By Cor. \ref{lb126}, we have a linear isometry
\begin{align*}
\Phi:\MH\rightarrow l^2(I)\qquad \xi\mapsto \big(\bk{e_i|\xi}\big)_{i\in I}
\end{align*}
with dense range. If $(a_i)_{i\in I}$ belongs to $l^2(I)$, by (b), the unordered sum $\sum_{i\in I}a_ie_i$ converges to some $\xi\in \MH$. Clearly $\Phi(\xi)=(a_i)_{i\in I}$. This proves that $\Phi$ is surjective, and hence is a unitary map. So $\MH\simeq l^2(I)$.
\end{proof}


In the proof of Thm. \ref{lb129}, we use Zorn's lemma to show that every Hilbert space $\MH$ admits an orthonormal basis. The same argument yields a stronger result:



%When $\MH$ is separable, this proposition can be proved without invoking Zorn's lemma, by applying mathematical induction together with the Gram-Schmidt process (Rem. \ref{lb117}). We leave the details of the proof of Prop. \ref{lb137} to the reader.



\begin{eg}
By Thm. \ref{lb129}, if $X$ is a set, then $l^2(X)$ is a Hilbert space.
\end{eg}


\begin{eg}
Let $(X,\mu)$ be a measure space. By the Riesz-Fischer Thm. \ref{lb26}, the inner product space $L^2(X,\mu)$ is a Hilbert space.
\end{eg}

\begin{eg}\label{lb148}
If $V$ is a closed linear subspace of $\MH$ whose inner product is inherited from that of $\MH$, then $V$ is a Hilbert space. This is either due to Thm. \ref{lb129}-(b), or due to the fact that a closed subset of a complete metric space is complete (Prop. \ref{lb324}). A closed linear subspace of the Hilbert space $\MH$ is called a \textbf{Hilbert subspace} of $\MH$. \index{00@Hilbert subspace}
\end{eg}


\begin{co}\label{lb130}
Every Hilbert space $\mc H$ has an orthonormal basis. Moreover, $\mc H$ is separable iff the orthonormal basis can be chosen to be countable.
\end{co}

\begin{proof}
That $\mc H$ has an orthonormal basis follows from the proof of Thm. \ref{lb129} or from the fact that $l^2(X)$ has an orthonormal basis $(\chi_{\{x\}})_{x\in X}$. If $X$ is countable, then $l^2(X)$ has dense subset $\Span_{\Qbb+\im\Qbb}\{\chi_{\{x\}}:x\in X\}$ and hence is separable. Conversely, we have proved in Exp. \ref{lb122} that every separable inner product space has a countable orthonormal basis.
\end{proof}


\begin{thm}\label{lb131}
Let $(e_x)_{x\in X}$ be an orthonormal basis of a Hilbert space $\mc H$. Then we have a unitary map
\begin{gather}
\mc H\xlongrightarrow{\simeq} l^2(X)\qquad \xi\mapsto\big(\bk{e_x|\xi}\big)_{x\in X}
\end{gather}
\end{thm}



\begin{proof}
This is clear from the proof of Thm. \ref{lb129}.
\end{proof}


\begin{thm}\label{lb149}
Let $V$ be a closed linear subspace of $\MH$. Then $\MH$ has a projection onto $V$. Consequently, by Prop. \ref{lb146}, $V\oplus V^\perp$ is canonically isomorphic to $\MH$.
\end{thm}

\begin{proof}
By Exp. \ref{lb148}, $V$ is a Hilbert space, and hence admits an orthonormal basis $(e_i)_{i\in I}$. For each $\xi\in\MH$, since Bessel's inequality implies $\sum_i|\bk{e_i|\xi}|^2<\Vert\xi\Vert^2<+\infty$, by Thm. \ref{lb129}-(b), the following sum converges:
\begin{align*}
P\xi=\sum_{i\in I}e_i\cdot \bk{e_i|\xi}
\end{align*}
and is clearly in $V$. Similar to the argument around \eqref{eq74}, $\xi-P\xi$ is orthogonal to every $e_i$. Hence $V_0:=\Span\{e_i:i\in I\}$ is orthogonal to $\xi-P\xi$, i.e., $\xi-P\xi\in V_0^\perp$. Since $V$ is the closure of $V_0$, by Rem. \ref{lb150}, we have $\xi-P\xi\in V^\perp$. Therefore, $\xi=P\xi+(\xi-P\xi)$ is the orthogonal decomposition of $\xi$ with respect to $V$.
\end{proof}


\begin{co}\label{lb151}
Let $V$ be a linear subspace of $\MH$. Then $(V^\perp)^\perp=\Cl_\MH(V)$. 
\end{co}

Note that since $V^\perp$ is closed, Cor. \ref{lb151} implies $V^{\perp\perp\perp}=V^\perp$.

\begin{proof}
By Rem. \ref{lb150}, we have $V^\perp=\ovl V^\perp$. By Thm. \ref{lb149}, $\MH$ has a projection onto $\ovl V$. Therefore, by Prop. \ref{lb146}, we have $\MH=\ovl V\oplus \ovl V^\perp=\ovl V\oplus V^\perp$. Therefore, $\ovl V$ is the orthogonal complement of $V^\perp$.
\end{proof}

\begin{co}\label{lb369}
Let $V$ be a linear subspace of $\MH$. Then $V$ is dense in $\MH$ iff $V^\perp=\{0\}$. 
\end{co}


\begin{proof}
If $V$ is dense, then $V^\perp=\ovl V^\perp=\MH^\perp=0$. Conversely, if $V^\perp=\{0\}$, then $V^{\perp\perp}=0^\perp=\MH$. By Cor. \ref{lb151}, we have $\ovl V=V^{\perp\perp}=\MH$. Hence $V$ is dense. 
\end{proof}


\begin{exe}\label{lb281}
Let $V$ be a closed linear subspace of $\MH$. Show that an orthonormal basis of $V$, together with an orthonormal basis of $V^\perp$, forms an orthonormal basis of $\MH$. (Consequently, any set $\fk S$ of orthonormal vectors of $\MH$ can be extended to an orthonormal basis of $\MH$ by choosing an orthonormal basis of $V^\perp$ where $V=\Span\fk S$.)
\end{exe}





\subsection{Bounded linear maps and bounded sesquilinear forms}



In this section, we let $U,V,W$ be inner product spaces.



In Subsec. \ref{lb132}, we discussed the close relationship between bounded linear maps and bounded bilinear forms in the general setting of normed vector spaces. This connection allows us to combine the strengths of both perspectives. One key advantage of the perspective of linear operators is that the space $\fk L(V)$ is particularly well-suited for symbolic calculus.


In this section, we explore this relationship in the context of inner product spaces and Hilbert spaces. We will see that the passage from $\fk L(V)$ to bounded sesquilinear forms fundamentally relies on the Riesz-Fr\'echet theorem, a pivotal result that enables this correspondence.


\subsubsection{The Riesz-Fr\'echet representation theorem}


\begin{df}
If $T\in\Lin(V,W)$, we let $\omega_T$ be the sesquilinear form \index{zz@$\omega_T$}
\begin{gather*}
\omega_T:W\times V\rightarrow\Cbb \qquad (w,v)\mapsto \bk{w|Tv}
\end{gather*}
\end{df}

\begin{pp}\label{lb133}
For each $T\in\Lin(V,W)$, we have
\begin{align*}
\Vert T\Vert=\Vert\omega_T\Vert
\end{align*}
Consequently, $T$ is bounded iff $\omega_T$ is so, and the map $T\in\Lin(V,W)\mapsto \omega_T$ is injective.
\end{pp}



\begin{proof}
For each $v\in V,w\in W$, we have
\begin{align*}
|\omega_T(w|v)|=|\bk{w|Tv}|\leq\Vert Tv\Vert\cdot\Vert w\Vert\leq \Vert T\Vert\cdot\Vert v\Vert\cdot\Vert w\Vert
\end{align*}
Applying $\sup$ over all $v,w$ in the closed unit balls, we get $\Vert\omega_T\Vert\leq\Vert T\Vert$. Moreover,
\begin{align*}
\Vert Tv\Vert^2=\omega_T(Tv|v)\leq\Vert \omega_T\Vert\cdot \Vert Tv\Vert\cdot\Vert v\Vert
\end{align*}
and hence $\Vert Tv\Vert\leq \Vert\omega_T\Vert\cdot\Vert v\Vert$. Applying $\sup$ over all $v$ in the closed unit ball, we get $\Vert T\Vert\leq\Vert\omega_T\Vert$.
\end{proof}




\begin{comment}
By Prop. \ref{lb133}, the map $T\in\Lin(V,W)$ restricts to a linear isometry of normed vector spaces
\begin{gather}
\fk L(V,W)\rightarrow \Ses(W|V)\qquad T\mapsto\omega_T
\end{gather}
On the other hand, Cor. \ref{lb134} implies
\begin{align*}
\Ses(W|V)=\fk L(W^\Co\times V,\Cbb)\simeq\fk L(V,(W^\Co)^*)
\end{align*}
and hence a linear isometry
\begin{align}\label{eq67}
\fk L(V,W)\rightarrow \fk L(V,(W^\Co)^*)
\end{align}

\begin{exe}
Show that the map \eqref{eq67} sends each $T\in\fk L(V,W)$ to $\Phi\circ T$, where $\Phi:W\rightarrow (W^\Co)^*$ is defined below.
\end{exe}

\end{comment}



\begin{thm}[\textbf{Riesz-Fr\'echet representation theorem}] \index{00@Riesz-Fr\'echet representation theorem}\label{lb135}
The following map is a linear isometry:
\begin{subequations}\label{eq68}
\begin{align}
\Phi:W\rightarrow (W^\Co)^*\qquad \xi\mapsto \bk{\ovl\xi|-}
\end{align}
where $\bk{\ovl\xi|-}$ denotes the bounded linear functional
\begin{align}
\bk{\ovl\xi|-}:W^\Co\rightarrow\Cbb\qquad \ovl w\mapsto\bk{\ovl\xi|\ovl w}_{W^\Co}=\bk{w|\xi}_W
\end{align}
\end{subequations}
Moreover, $W$ is a Hilbert space iff $\Phi$ is surjective (and hence an isomorphism of normed vector spaces).
\end{thm}

In other words, $\Phi$ is determined by the fact that for each $w,\xi\in W$, 
\begin{align}
\bk{\ovl w,\Phi\xi}=\bk{w|\xi}
\end{align}


\begin{proof}
First, note that for each $\xi\in W$,
\begin{align}
\Vert\xi\Vert=\sup_{w\in\ovl B_W(0,1)}|\bk{w|\xi}|
\end{align}
Indeed, the Cauchy-Schwarz inequality implies ``$\geq$''. The equality can be achieved by choosing $w=\xi/\Vert\xi\Vert$ if $\xi\neq0$. Therefore,
\begin{align*}
\Vert\Phi(\xi)\Vert=\sup_{\ovl w\in\ovl B_{W^\Co}(0,1)}|\bk{\ovl w,\Phi(\xi)}|=\sup_{w\in\ovl B_W(0,1)}|\bk{w|\xi}|=\Vert\xi\Vert
\end{align*}
This proves that $\Phi$ is a linear isometry.

If $\Phi$ is surjective, then the normed vector space $W$ is isomorphic to the dual space $(W^\Co)^*$ where the latter is complete by Cor. \ref{lb128}. Therefore, $W$ is a Hilbert space.

Conversely, assume that $W$ is a Hilbert space. By Thm. \ref{lb129}, we can assume that $W=l^2(X)$ for some set $X$. The surjectivity of $\Phi$ then follows from the surjectivity of the map
\begin{align*}
l^2(X)\rightarrow l^2(X)^*\qquad \xi\mapsto \bk{-,\xi}
\end{align*}
due to Thm. \ref{lb127}.
\end{proof}


\begin{df}
The map $\Phi$ in Thm. \ref{lb135} is called the \textbf{Riesz isometry} of $W$. If $W$ is a Hilbert space, then $\Phi$ is called the \textbf{Riesz isomorphism} of $W$. \index{00@Riesz isometry/isomorphism} An equivalent description of $\Phi$ is as follows: In view of the isomorphism
\begin{align*}
\Ses(W)=\fk L(W^\Co\times W,\Cbb)\simeq\fk L(W,(W^\Co)^*)
\end{align*}
due to Cor. \ref{lb134}, the Riesz isometry $\Phi$ is the element of $\fk L(W,(W^\Co)^*)$ corresponding the the inner product $\bk{\cdot|\cdot}_W$ as an element of $\Ses(W)$.
\end{df}


\subsubsection{Equivalence between bounded linear maps and bounded sesquilinear forms}






With the help of the Riesz-Fr\'echet theorem, we can establish the equivalence between bounded linear maps and bounded sesquilinear forms.

\begin{thm}\label{lb136}
Let $\MH,\MK$ be Hilbert spaces. Then we have an isomorphism of normed vector spaces
\begin{gather}
\fk L(\MH,\MK)\xlongrightarrow{\simeq}\Ses(\MK|\MH)\qquad T\mapsto\omega_T
\end{gather}
In particular, when $\MH=\MK$, the above isomorphism becomes
\begin{gather}
\fk L(\MH)\xlongrightarrow{\simeq}\Ses(\MH)\qquad T\mapsto\omega_T
\end{gather}
\end{thm}


\begin{proof}
By Cor. \ref{lb134}, we have
\begin{align*}
\fk L(\MH,(\MK^\Co)^*)\simeq\fk L(\MK^\Co\times\MH,\Cbb)=\Ses(\MK|\MH)
\end{align*}
where each $S\in\fk L(\MH,(\MK^\Co)^*)$ corresponds to the bounded bilinear form
\begin{align*}
\MK^\Co\times\MH\rightarrow\Cbb\qquad (\ovl\eta,\xi)\mapsto \bk{\ovl\eta,S\xi}
\end{align*}
equivalently, the bounded sesquilinear form
\begin{align*}
\MK\times\MH\rightarrow\Cbb\qquad (\eta,\xi)\mapsto \bk{\ovl\eta,S\xi}
\end{align*}
Now, suppose that $S=\Phi\circ T$ where $T\in\fk L(\MH,\MK)$, and $\Phi:\MK\xlongrightarrow{\simeq}(\MK^\Co)^*$ is the Riesz-isomorphism of $\MK$ defined in Thm. \ref{lb135}. Then $\bk{\ovl\eta|\Phi\mu}=\bk{\eta|\mu}$ for each $\mu,\eta\in\MK$, and hence
\begin{align*}
\bk{\ovl\eta,S\xi}=\bk{\ovl\eta,\Phi\circ T\xi}=\bk{\eta|T\xi}=\omega_T(\eta|\xi)
\end{align*}
Therefore, the isomorphism
\begin{align*}
\fk L(\MH,\MK)\xlongrightarrow[\simeq]{T\mapsto\Phi\circ T}\fk L(\MH,(\MK^\Co)^*)\simeq\Ses(\MK|\MH)
\end{align*}
sends $T$ to $\omega_T$.
\end{proof}


\subsubsection{Adjoint operators, self-adjoint operators and positive operators}


Let $\MH,\MK$ be Hilbert spaces. With the help of Thm. \ref{lb136}, we can define adjoint operators:


\begin{df}
Recall that for each $\omega\in\Ses(\MK|\MH)$, the \textbf{adjoint sesquilinear form} $\omega^*\in\Ses(\MH|\MK)$ is defined by $\omega^*(\xi|\eta)=\ovl{\omega(\eta|\xi)}$ for each $\xi\in\MH,\eta\in\MK$. It is clear that
\begin{align*}
\Vert\omega^*\Vert=\Vert\omega\Vert
\end{align*}
Now, for each $T\in\fk L(\MH,\MK)$, define the \textbf{adjoint operator} \index{00@Adjoint operator} $T^*\in\fk L(\MK,\MH)$ such that
\begin{align*}
\omega_{T^*}=(\omega_T)^*
\end{align*}
More explicitly, $T^*$ is determined by the fact that for each $\xi\in\MH,\eta\in\MK$,
\begin{align*}
\bk{\eta|T\xi}=\bk{T^*\eta|\xi}
\end{align*}
Then, we clearly also have $\Vert T\Vert=\Vert T^*\Vert$.
\end{df}



\begin{exe}
Show that
\begin{align*}
*:\fk L(\MH,\MK)\rightarrow\fk L(\MK,\MH)\qquad T\mapsto T^*
\end{align*}
is a bijective antilinear map, and that $(T^*)^*=T$. Prove that if $\MM$ is a Hilbert space and $T\in\fk L(\MH,\MK),S\in\fk L(\MK,\MM)$, then
\begin{align*}
(ST)^*=T^*S^*
\end{align*}
\end{exe}


\begin{df}
A bounded linear operator $T\in\fk L(\MH)$ is called \textbf{self-adjoint} \index{00@Self-adjoint bounded linear operators} if $T=T^*$, equivalently, if $\omega_T$ is Hermitian.
\end{df}


\begin{df}\label{lb247}
Let $A,B\in\fk L(\MH)$ be self-adjoint. We write
\begin{align*}
\pmb{A\leq B}
\end{align*}
if $\omega_A\leq\omega_B$ in the sense of Def. \ref{lb140}, that is, $\bk{\xi|A\xi}\leq\bk{\xi|B\xi}$ for all $\xi\in\MH$. We say that $A\in\fk L(\MH)$ is \textbf{positive} \index{00@Positive bounded linear operators} if $A\geq0$, equivalently, if $\omega_A$ is positive. 
\end{df}



\begin{eg}
Let $A\in\fk L(\MH,\MK)$. Then $A^*A\in\fk L(\MH)$ is positive, because
\begin{align*}
\bk{\xi|A^*A\xi}=\Vert A\xi\Vert^2\geq0
\end{align*}
\end{eg}

\begin{eg}\label{lb201}
Let $A\in\fk L(\MH)$, and let $a\geq0$ such that $\Vert A\Vert\leq a$. Then $-a\leq A\leq a$.
\end{eg}

\begin{proof}
Since $|\bk{\eta|A\xi}|\leq a\Vert\eta\Vert\cdot\Vert\xi\Vert$, we obtain $-a\Vert\xi\Vert^2\leq\bk{\xi|A\xi}\leq a\Vert\xi\Vert^2$, and hence $-a\leq A\leq a$. 
\end{proof}





\subsubsection{Composition of bounded linear operators and bounded sesquilinear forms}\label{lb152}


Let $\MH,\MK,\MM$ be Hilbert spaces.

One of the major advantages of working with bounded linear operators rather than bounded sesquilinear forms is the ease with which one can handle problems involving operator composition. This does not mean, however, that a notion of composition cannot be defined on the side of sesquilinear forms. In fact, the following lemma illustrates how such a composition can be defined.

\begin{lm}\label{lb138}
Let $T\in\fk L(\MK,\MH)$ and $S\in\fk L(\MM,\MK)$. Let $(e_i)_{i\in I}$ be an orthonormal basis of $\MK$. Then for each $\xi\in\MM$, we have
\begin{align}\label{eq69}
T\circ S\xi=\sum_{i\in I}Te_i\cdot\bk{e_i|S\xi}
\end{align}
where the unordered sum on the RHS converges in norm to the LHS.
\end{lm}

\begin{proof}
By Thm. \ref{lb123}, we have $S\xi=\sum_i e_i\cdot\bk{e_i|S\xi}$. Therefore, by the linearity and the continuity of $T$, we get \eqref{eq69}.
\end{proof}


\begin{df}\label{lb144}
Let $\omega\in\Ses(\MH|\MK)$ and $\sigma\in\Ses(\MK|\MM)$. Then the \textbf{composition} \pmb{$\omega\circ\sigma$} \index{00@Composition of sesquilinear forms} is the element of $\Ses(\MM|\MH)$ defined by \footnote{This definition clearly also applies when $\MH$ and $\MK$ are merely inner product spaces admitting orthonormal bases, in particular, when $\MH,\MK$ are separable inner product spaces (cf. Exp. \ref{lb122}).}
\begin{align*}
(\omega\circ\sigma)(\psi|\xi)=\sum_{i\in I}\omega(\psi|e_i)\cdot\sigma(e_i|\xi)\qquad\text{for all }\psi\in\MH,\xi\in\MM
\end{align*}
where $(e_i)_{i\in I}$ is a basis of $\MK$. This definition is independent of the choice of basis (and applies even to bounded sesquilinear forms on inner product spaces). Moreover, by Lem. \ref{lb138}, for each $T\in\fk L(\MK,\MH)$ and $S\in\fk L(\MM,\MK)$, we have
\begin{align*}
\omega_{T\circ S}=\omega_T\circ\omega_S
\end{align*}
\end{df}





However, many properties about composition that are straightforward from the perspective of bounded linear operators become far less transparent when viewed in terms of sesquilinear forms. For instance, consider the following basic result:

\begin{pp}\label{lb143}
Let $\MU,\MV,\MW$ be normed vector spaces. Then for any  $T\in\fk L(\MV,\MW)$ and $S\in\fk L(\MU,\MV)$, we have
\begin{align*}
\Vert TS\Vert\leq \Vert T\Vert\cdot\Vert S\Vert
\end{align*}
In other words, the multiplication map
\begin{align*}
\fk L(\MV,\MW)\times\fk L(\MU,\MV)\rightarrow\fk L(\MU,\MW)\qquad (T,S)\mapsto TS
\end{align*}
is a bounded bilinear map with operator norm $\leq 1$.
\end{pp}


\begin{proof}
Apply $\sup$ over all $\xi\in\ovl B_\MU(0,1)$ to
\begin{align*}
\Vert TS\xi\Vert\leq\Vert T\Vert\cdot \Vert S\xi\Vert\leq \Vert T\Vert\cdot\Vert S\Vert\cdot\Vert\xi\Vert
\end{align*}
\end{proof}



\begin{co}
Let $\MV$ be a normed $\Fbb$-vector space. Let $\scr A$ be an $\Fbb$-subalgebra of $\fk L(\MV)$. Let $\ovl{\scr A}$ be the closure of $\scr A$ in $\fk L(\MV)$. Then $\scr A$ is also an $\Fbb$-subalgebra of $\fk L(\MV)$.
\end{co}

\begin{proof}
Clearly $\ovl{\scr A}$ is an $\Fbb$-linear subspace of $\fk L(\MV)$. If $T,S\in\scr A$, then there exist sequences $(T_n)$ and $(S_n)$ in $\scr A$ converging in the operator norm to $T$ and $S$, respectively. By Prop. \ref{lb143}, the multiplication map $\fk L(\MV)\times\fk L(\MV)\rightarrow\fk L(\MV)$ is continuous. Thus $(T_nS_n)$ converges in the operator norm to $TS$. This proves that $TS\in\ovl{\scr A}$. Therefore, $\ovl{\scr A}$ is an $\Fbb$-subalgebra.
\end{proof}



\begin{co}\label{lb233}
Let $T\in\fk L(\MH)$. Let $\Omega=\{z\in\Cbb:|z|>\Vert T\Vert\}$. Then for each $z\in\Omega$, the operator $z-T$ is invertible (cf. Def. \ref{lb116}). Moreover, for each $\xi,\eta\in\MH$, the function
\begin{align*}
z\in\Omega\mapsto \bk{\eta|(z-T)^{-1}\xi}=\omega_{(z-T)^{-1}}(\eta|\xi)
\end{align*}
is holomorphic.
\end{co}

The expression $(z-T)^{-1}$ is called the \textbf{resolvent} of $T$. \index{00@Resolvent operator}

\begin{proof}
By Prop. \ref{lb143}, we have $\Vert T^k\Vert\leq\Vert T\Vert^k$. Therefore, if $z\in\Omega$, then
\begin{align*}
\sum_{k=0}^\infty \Vert z^{-k-1}T^k\Vert\leq\sum_{k=0}^\infty |z|^{-k-1}\Vert T\Vert^k<+\infty
\end{align*}
Therefore, if we define
\begin{align}
S_n(z)=\sum_{k=0}^nz^{-k-1}T^k
\end{align}
Then $(S_n(z))_{n\in\Nbb}$ is a Cauchy sequence in the normed vector space $\fk L(\MH)$. By Cor. \ref{lb39}, $\fk L(\MH)\simeq\Ses(\MH)$ is complete. Therefore, $(S_n(z))$ converges in the operator norm to some $S(z)\in\fk L(\MH)$. Since
\begin{align*}
(z-T)S_n(z)=S_n(z)\cdot (z-T)=1-z^{-n-1}T^{n+1}
\end{align*}
and since $\Vert z^{-n-1}T^{n+1}\Vert\leq |z|^{-n-1}\Vert T\Vert^{n+1}\rightarrow0$, we have $(z-T)S(z)=S(z)(z-T)=1$. This proves that $z-T$ is invertible.

For each $\xi,\eta\in\MH$, and for each compact $K\subset \Omega$, we have
\begin{align*}
\sup_{z\in K}\sum_{k=0}^\infty |z^{-k-1}\bk{\eta|T^k\xi}|\leq \sup_{z\in K}\sum_{k=0}^\infty |z|^{-k-1}\Vert T\Vert^k\cdot\Vert\eta\Vert\cdot\Vert\xi\Vert<+\infty
\end{align*}
Therefore, the series of functions
\begin{align*}
z\in\Omega\mapsto \sum_{k=0}^\infty\bk{\eta|z^{-k-1}T^k\xi}
\end{align*}
converges absolutely and uniformly on compact subsets of $\Omega$. Since the limit of this series of functions is $z\in\Omega\mapsto\omega_{S_n(z)}(\eta|\xi)$, the latter is holomorphic.
\end{proof}



Before we explore further examples, let us examine another foundational perspective that played a central role in the early development of functional analysis: the viewpoint of bounded matrices.






\subsection{Bounded matrices}\label{lb154}


Let $\MH,\MK,\MM$ be Hilbert spaces.

As mentioned in Subsec. \ref{lb141}, early developments in functional analysis focused primarily on bounded sesquilinear forms rather than bounded linear operators. Closely tied to this approach was the study of infinite matrices, which provided a concrete representation of these abstract objects. The notion of boundedness was first defined in this matrix context. Hilbert introduced this concept in \cite{Hil06}, where he also introduced the space $l^2(\Zbb)$. 

%As established in Prop. \ref{lb35}, boundedness in the context of linear maps or sesquilinear forms is equivalent to (Lipschitz) continuity. However, as we will see below, in the setting of infinite matrices, boundedness takes on a stronger meaning---it implies equicontinuity. More precisely, it ensures that a family of linear maps or sesquilinear forms shares a uniform Lipschitz constant. See Step 2 of the proof of Thm. \ref{lb142}.

%This distinction highlights a deeper philosophical insight under the perspective of infinite matrices: \uwave{a bounded linear operator or sesquilinear form is regarded as the limit of a sequence (or net) of finite-rank operators or forms}. This philosophy is central to our treatment of spectral theory in Ch. \ref{lb181}, and it resonates not only with the historical approaches of Hilbert and F. Riesz, but also with the viewpoint that \uwave{the Stieltjes integral arises as the weak-* completion of finite sums} (see Table \ref{tb3}, Sec. \ref{lb182}, and Sec. \ref{lb188}). For this reason, it is worthwhile to study bounded matrices and their relationship to bounded linear operators and sesquilinear forms.



\begin{df}
Let $X,Y$ be sets. The elements of $\Cbb^{X\times Y}$, which are of the form
\begin{align*}
A=(A(x,y))_{x\in X,y\in Y}\qquad\text{where }A(x,y)\in\Cbb
\end{align*}
are called \textbf{\pmb{$X\times Y$} (complex) matrices}. For each $A\in \Cbb^{X\times Y}$, the \textbf{norm \pmb{$\Vert A\Vert$}} \index{00@Norm of matrices} is defined to be
\begin{gather}\label{eq71}
\Vert A\Vert=\sup\bigg\{\bigg|\sum_{x\in X,y\in Y}\ovl{\xi(x)}A(x,y)\eta(y)\bigg|:\xi\in C_c(X),\eta\in C_c(Y),\Vert \xi\Vert_{l^2}\leq1,\Vert\eta\Vert_{l^2}\leq1\bigg\}
\end{gather}
where $C_c(X)$ and $C_c(Y)$ are the spaces of complex functions on $X$ and $Y$ with finite supports, respectively. We say that $A$ is \textbf{bounded} \index{00@Bounded matrix} if $\Vert A\Vert<+\infty$.
\end{df}


\begin{df}\label{lb280}
Suppose that $(e_x)_{x\in X}$ and $(e_y)_{y\in Y}$ are orthonormal basis of $\MH$ and $\MK$, respectively. The \textbf{matrix representation} \index{00@Matrix representation} of each $\omega\in\Ses(\MH|\MK)$ is the element $[\omega]\in\Cbb^{X\times Y}$ defined by
\begin{align*}
[\omega](x,y)=\omega(e_x|e_y)\qquad\text{for each }x\in X,y\in Y
\end{align*}  
If $\omega=\omega_T$ where $T\in\fk L(\MK,\MH)$, we also say that $[\omega]$ is the \textbf{matrix representation} of $T$ and write it as $[T]$. In other words, we say that $[T]\in\Cbb^{X\times Y}$ is the matrix representation of $T$ if
\begin{align*}
[T](x,y)=\bk{e_x|Te_y}\qquad\text{for each }x\in X,y\in Y
\end{align*}
\end{df}



\begin{thm}\label{lb142}
Suppose that $(e_x)_{x\in X}$ and $(e_y)_{y\in Y}$ are orthonormal bases of $\MH$ and $\MK$, respectively. Then the linear map
\begin{gather}\label{eq70}
\Ses(\MH|\MK)\rightarrow\Cbb^{X\times Y}\qquad \omega\mapsto[\omega]
\end{gather}
is injective, and its range is the set of all bounded matrices. Moreover, for each $\omega\in\Ses(\MH|\MK)$, we have
\begin{align*}
\big\Vert\omega\big\Vert=\big\Vert[\omega]\big\Vert
\end{align*}
\end{thm}

\begin{proof}
Step 1. We assume WLOG that $\MH=l^2(X),\MK=l^2(Y)$ and $e_x=\{\chi_{\{x\}}\}_{x\in X}$ and $e_y=\{\chi_{\{y\}}\}_{y\in Y}$. Recall that $C_c(X)$ is dense in $l^2(X)$ and $C_c(Y)$ is dense in $l^2(Y)$.

Let $\omega\in\Ses(\MH|\MK)$. From \eqref{eq71}, it is clear that $\Vert[\omega]\Vert$ is the norm of the restriction of $\omega$ to $C_c(X)\times C_c(Y)$. Therefore, by the continuity of $\omega$, we have $\Vert[\omega]\Vert=\Vert\omega\Vert<+\infty$. In particular, we have proved that the matrices in the range of \eqref{eq70} are bounded. Moreover, if $[\omega]=0$, then $\Vert\omega\Vert=\Vert[\omega]\Vert=0$, and hence $\omega=0$. This proves that \eqref{eq70} is injective.\\[-1ex]


Step 2. Choose any bounded $A\in\Cbb^{X\times Y}$. We want to find $\omega\in\Ses(\MH|\MK)$ such that $[\omega]=A$. Define a sesquilinear form $\omega:C_c(X)\times C_c(Y)\rightarrow\Cbb$ by
\begin{align*}
\omega(\xi|\eta)=\sum_{x\in X,y\in Y}\ovl{\xi(x)}A(x,y)\eta(y)
\end{align*}
Then $\Vert\omega\Vert=\Vert A\Vert$, and hence $\omega$ is bounded. By Thm. \ref{lb31}, $\omega$ can be extended to a bounded sesquilinear form on $\MH\times\MK$ with $\Vert\omega\Vert$ unchanged. Clearly $A$ is the matrix representation of $\omega$.
\end{proof}



\begin{df}
Let $X,Y,Z$ be sets. Let $A\in\Cbb^{X\times Y}$ and $B\in\Cbb^{Y\times Z}$ be bounded matrices. Then the \textbf{matrix multiplication} $AB\in\Cbb^{X\times Z}$ \index{00@Matrix multiplication} is defined to be
\begin{align*}
(AB)(x,z)=\sum_{y\in Y}A(x,y)B(y,z)
\end{align*}
where the RHS is convergent for each $x\in X,z\in Z$. This definition is clearly compatible with Def. \ref{lb144}, that is, if $\MH,\MK,\MM$ have orthonormal basis $(e_x)_{x\in X},(e_y)_{y\in Y},(e_z)_{z\in Z}$ respectively, and if $\omega\in\Ses(\MH|\MK),\sigma\in\Ses(\MK|\MM)$, then the corresponding matrix representations satisfy
\begin{align*}
[\omega\circ\sigma]=[\omega]\cdot[\sigma]
\end{align*}
\end{df}


We now return to the topic discussed at the end of Sec. \ref{lb152}: the subtlety of defining and understanding composition on the side of bounded sesquilinear forms---a subtlety that also arises in the context of bounded matrices. For simplicity, we restrict attention to a fixed Hilbert space $\MH$ with orthonormal basis $(e_x)_{x\in X}$. 

For $R,S,T\in\fk L(\MH)$, associativity of composition,
\begin{align*}
(RS)T=R(ST)
\end{align*}
is almost tautological. However, when working with bounded sesquilinear forms or bounded matrices, associativity is far less transparent. To see this, consider $\sigma,\omega,\tau\in\Ses(\MH)$. Then the associativity $(\sigma\omega)\tau=\sigma(\omega\tau)$ amounts to the commutativity of the two unordered sums: for all $\xi,\eta\in\MH$,
\begin{align}\label{eq78}
\sum_{y\in X}\sum_{x\in X} \sigma(\xi|e_x)\omega(e_x|e_y)\tau(e_y|\eta)=\sum_{x\in X}\sum_{y\in X}\sigma(\xi|e_x)\omega(e_x|e_y)\tau(e_y|\eta)
\end{align}
Similarly, if $A,B,C\in\Cbb^{X\times X}$ are bounded matrices, associativity of matrix multiplications means that for each $i,j\in X$, 
\begin{align}\label{eq144}
\sum_{y\in X}\sum_{x\in X} A(i,x)B(x,y)C(y,j)=\sum_{x\in X}\sum_{y\in X}A(i,x)B(x,y)C(y,j)
\end{align}
At first glance, the commutativity of $\sum_{x\in X}$ and $\sum_{y\in X}$ is not at all obvious.

The issue of commutativity of unordered sums---which appears in the frameworks of sesquilinear forms and matrices---disappears in the perspective of linear maps. Where is this Fubini-type property hidden in the linear map viewpoint? And how can one understand the commutativity of such unordered sums in a more general context? We will answer this question in the next section.









\subsection{SOT and WOT}



Let $U,V,W$ be inner product spaces.

\subsubsection{Convergence of vectors}


\begin{df}
The \textbf{weak topology} on $V$ \index{00@Weak topology on inner product spaces} is defined to be the pullback of the weak-* topology on $(V^\Co)^*$ by the Riesz isometry $V\rightarrow (V^\Co)^*$. Therefore, a net $(\xi_\alpha)$ in $V$ converges weakly to $\xi \in V$ iff
\begin{align}\label{eq75}
\lim_\alpha\bk{\eta|\xi_\alpha}=\bk{\eta|\xi}
\end{align}
holds for each $\eta\in V$
\end{df}

It is clear that norm convergence implies weak convergence.


\begin{rem}
Let $(\xi_\alpha)$ be a uniformly bounded net in $V$, and let $\xi\in V$. Let $U$ be a dense linear subspace of $V$. Applying Thm. \ref{lb80} to the images of $(\xi_\alpha)$ and $\xi$ in $(V^\Co)^*$, we see that $(\xi_\alpha)$ converges weakly to $\xi$ iff \eqref{eq75} holds for each $\eta\in U$. 
\end{rem}



\begin{pp}[\textbf{Fatou's lemma for weak convergence}]\label{lb153} \index{00@Fatou's lemma for weak convergence in inner product spaces}
Let $(\xi_\alpha)$ be a net in $V$ converging weakly to $\xi\in V$. Then
\begin{align}\label{eq76}
\Vert\xi\Vert\leq\liminf_\alpha\Vert\xi_\alpha\Vert
\end{align}
Moreover, $(\xi_\alpha)$ converges in norm to $\xi$ iff  $\lim_\alpha\Vert\xi_\alpha\Vert$ converges to $\Vert\xi\Vert$.
\end{pp}



\begin{proof}
The inequality \eqref{eq76} follows from Prop. \ref{lb106} and the fact that the Riesz isometry $V\rightarrow(V^\Co)^*$ is an isometry. But it can also be proved directly:
\begin{align*}
\Vert\xi\Vert^2=\lim_\alpha|\bk{\xi|\xi_\alpha}|=\liminf_\alpha|\bk{\xi|\xi_\alpha}|\leq\liminf_\alpha\Vert\xi\Vert\cdot\Vert\xi_\alpha\Vert
\end{align*}

If $(\xi_\alpha)$ converges in norm to $\xi$, then by the continuity of $\Vert\cdot\Vert:V\rightarrow\Rbb_{\geq0}$, $\lim_\alpha\Vert\xi_\alpha\Vert$ converges to $\Vert\xi\Vert$. Conversely, suppose that $\lim_\alpha\Vert\xi_\alpha\Vert=\Vert\xi\Vert$. Then, since $\bk{\xi|\xi_\alpha}\rightarrow\bk{\xi|\xi}$, we have
\begin{align*}
\bk{\xi-\xi_\alpha|\xi-\xi_\alpha}=\Vert \xi\Vert^2-2\Re\bk{\xi|\xi_\alpha}+\Vert\xi_\alpha\Vert^2\rightarrow\Vert\xi\Vert^2-2\Re\Vert\xi\Vert^2+\Vert\xi\Vert^2=0
\end{align*}
This shows that $\Vert\xi-\xi_\alpha\Vert\rightarrow0$.
\end{proof}


\begin{eg}
Let $\MH$ be an infinite-dimensional Hilbert space. Let $(e_n)_{n\in \Zbb_+}$ be a sequence of orthonormal vectors. By Bessel's inequality (Cor. \ref{lb118}), for each $\xi\in\MH$ we have $\sum_{n\in\Zbb_+}|\bk{e_n|\xi}|^2<+\infty$, and hence $\lim_n\bk{e_n|\xi}=0$. Therefore, the sequence $(e_n)_{n\in\Zbb_+}$ converges weakly to $0$. However, it does not converge in norm to $0$. 
\end{eg}



\subsubsection{Convergence of operators}


Recall that the \textbf{norm topology} on $\fk L(V,W)$ is the topology determined by the operator norm on $\fk L(V,W)$.

\begin{df}
The \textbf{strong operator topology (SOT)} \index{00@Strong operator topology} \index{00@SOT} on $\fk L(V,W)$ is defined to be the pullback of the product topology on $W^V$ by the inclusion map
\begin{align*}
\fk L(V,W)\hookrightarrow W^V
\end{align*}
The \textbf{weak-* topology} \index{00@Weak-* topology on $\Ses(W\vert V)$} on $\Ses(W|V)$ is defined to be the pullback of the product topology on $\Cbb^{W\times V}$ by the inclusion map
\begin{align*}
\Ses(W|V)\hookrightarrow \Cbb^{W\times V}
\end{align*}
The \textbf{weak operator topology (WOT)} \index{00@Weak operator topology} \index{00@WOT} on $\fk L(V,W)$ is defined to be the pullback of the weak-* topology on $\Ses(W|V)$ by the linear isometry
\begin{align*}
\fk L(V,W)\rightarrow\Ses(W|V)\qquad T\mapsto \omega_T
\end{align*}
\end{df}


\begin{rem}
Let $(T_\alpha)$ be a net in $\fk L(V,W)$ and $T\in\fk L(V,W)$. Then $(T_\alpha)$ converges in SOT to $T$ iff
\begin{align}
\lim_\alpha T_\alpha\xi=T\xi
\end{align}
holds for each $\xi\in V$. $(T_\alpha)$ converges in WOT to $T$ iff
\begin{align}
\lim_\alpha \bk{\eta|T_\alpha\xi}=\bk{\eta|T\xi}
\end{align}
holds for each $\xi\in V,\eta\in W$. It is clear that
\begin{align*}
\text{convergence in norm}\quad\Rightarrow\quad\text{convergence in SOT}\quad\Rightarrow\quad\text{convergence in WOT}
\end{align*}
\end{rem}


\begin{rem}\label{lb241}
Let $(T_\alpha)$ be a net in $\fk L(V,W)$ and $T\in\fk L(V,W)$. Then it is clear that $(T_\alpha)$ converges in WOT to $T$ iff
\begin{align*}
\lim_\alpha T\xi_\alpha\quad\text{converges weakly to}\quad\xi
\end{align*}
for each $\xi\in V$. By Prop. \ref{lb153}, $(T_\alpha)$ converges in SOT to $T$ iff the following two conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item $(T_\alpha)$ converges in WOT to $T$.
\item $\lim_\alpha \Vert T_\alpha\xi\Vert=\Vert T\xi\Vert$ for each $\xi\in V$.
\end{enumerate}
\end{rem}


\begin{eg}\label{lb157}
Suppose that $V$ has a basis $(e_x)_{x\in X}$. For each $I\in\fin(2^X)$, let $P_I$ be the projection of $V$ onto $V_I=\Span\{e_x:x\in I\}$, that is,
\begin{align*}
P_I\xi=\sum_{x\in I}e_x\cdot\bk{e_x|\xi}\qquad\text{for all }\xi\in V
\end{align*}
Then by Thm. \ref{lb123}, $\lim_{I\in\fin(2^X)}P_I$ converges in SOT to $\idt$. 

However, if $X$ is infinite, then $\lim_{I\in\fin(2^X)}P_I$ does not converge in norm to $\idt$. Indeed, for each $I$, choose $x\in X\setminus I$. Then $(\idt-P_I)e_x=e_x$, and hence
\begin{align*}
\Vert\idt-P_I\Vert\geq 1
\end{align*}
Indeed, by Prop. \ref{lb146}, $\idt-P_I$ is the projection operator associated to $U_I^\perp$, and hence has operator norm $1$.  \hqed
\end{eg}




\subsubsection{SOT and composition of operators}


Let us examine the commutativity of unordered sums from Sec. \ref{lb154} through the lens of SOT.


\begin{pp}\label{lb156}
Let $(T_\alpha)_{\alpha\in\scr A}$ be a net in $\fk L(V,W)$ converging in SOT to $T\in\fk L(V,W)$. Let $(\xi_\beta)_{\beta\in\scr B}$ be a net in $V$ converging in norm to $\xi\in V$. Then 
\begin{align}
\lim_\alpha \lim_\beta T_\alpha \xi_\beta=\lim_\beta\lim_\alpha T_\alpha \xi_\beta=T\xi
\end{align}
\end{pp}

\begin{proof}
We compute that
\begin{align*}
\lim_\alpha\lim_\beta T_\alpha \xi_\beta=\lim_\alpha T_\alpha \xi=T\xi
\end{align*}
and
\begin{align*}
\lim_\beta\lim_\alpha T_\alpha \xi_\beta=\lim_\beta T\xi_\beta=T\xi
\end{align*}
where the last equality is due to the continuity of $T$.
\end{proof}


\begin{co}\label{lb158}
Let $(T_\alpha)_{\alpha\in\scr A}$ be a net in $\fk L(V,W)$ converging in SOT to $T\in\fk L(V,W)$. Let $(S_\beta)_{\beta\in\scr B}$ be a net in $\fk L(U,V)$ converging in SOT to $S\in\fk L(U,V)$. Then for each $u\in U$ we have
\begin{align}
\lim_\alpha \lim_\beta T_\alpha S_\beta u=\lim_\beta\lim_\alpha T_\alpha S_\beta u=TSu
\end{align}
\end{co}

\begin{proof}
Apply Prop. \ref{lb156} to $\xi_\beta= S_\beta u$.
\end{proof}

Cor. \ref{lb158} can be easily generalized to products of more than two nets of operators. We leave the details to the reader.


\begin{eg}\label{lb160}
Let $\MH$ be a Hilbert space with basis $(e_x)_{x\in X}$. Let $(P_I)_{I\in\fin(2^X)}$ be the net of projections where $P_I$ projects $\MH$ onto $V_I=\Span\{e_x:x\in I\}$. By Exp. \ref{lb157}, $\lim_I P_I$ converges in SOT to $\idt$. Choose any $R,S,T\in\fk L(\MH)$. Then $\lim_I P_IS$ converges in SOT to $S$, and $\lim_I P_IT$ converges in SOT to $T$. Therefore, by Cor. \ref{lb158}, for each $\eta\in\MH$ we have
\begin{align*}
\lim_{J\in\fin(2^X)}\lim_{I\in\fin(2^X)}RP_ISP_JT\eta=\lim_{I\in\fin(2^X)}\lim_{J\in\fin(2^X)}RP_ISP_JT\eta=RST\eta
\end{align*}
Therefore, for each $\xi,\eta\in\MH$ we have
\begin{align}\label{eq77}
\lim_{J\in\fin(2^X)}\lim_{I\in\fin(2^X)}\bk{\xi|RP_ISP_JT\eta}=\lim_{I\in\fin(2^X)}\lim_{J\in\fin(2^X)}\bk{\xi|RP_ISP_JT\eta}=\bk{\xi|RST\eta}
\end{align}
The commutativity of the two iterated limits in \eqref{eq77} is equivalent to the commutativity of the two limits in \eqref{eq78}.
\end{eg}




Next, we introduce an elementary yet fundamental property of SOT. This property was first highlighted by Riesz in \cite{Rie13} as a key tool in his proof of the spectral theorem for bounded self-adjoint operators. In Ch. \ref{lb181}, we will also rely on it in our study of spectral theory, in particular when reproducing Riesz's argument from \cite{Rie13} (see the proof of Thm. \ref{lb283}). This property roughly says that in Cor. \ref{lb158}, if the nets of operators are uniformly bounded, and if $\scr A=\scr B$, then $\lim_\alpha T_\alpha S_\alpha$ converges in SOT to $TS$.


\begin{thm}\label{lb155}
Let $(T_\alpha)_{\alpha\in\scr A}$ be a net in $\fk L(V,W)$ satisfying $\sup_\alpha\Vert T_\alpha\Vert<+\infty$ and converging in SOT to $T\in\fk L(V,W)$. Let $(\xi_\beta)_{\beta\in\scr B}$ be a net in $V$ converging to $\xi\in V$. Then the double net $(T_\alpha\xi_\beta)_{(\alpha,\beta)\in\scr A\times\scr B}$ converges to $T\xi$, that is,
\begin{align*}
\lim_{(\alpha,\beta)\in\scr A\times\scr B}T_\alpha\xi_\beta=T\xi
\end{align*}
\end{thm}

In particular, if $\scr A=\scr B$, since $(T_\alpha\xi_\alpha)_{\alpha\in\scr A}$ is a subnet of $(T_\alpha\xi_\beta)_{(\alpha,\beta)\in\scr A\times\scr A}$ (defined by $\alpha\in\scr A\mapsto(\alpha,\alpha)\in\scr A$), we conclude that
\begin{align*}
\lim_\alpha T_\alpha\xi_\alpha=T\xi
\end{align*}

\begin{proof}
Let $C=\sup_\alpha\Vert T_\alpha\Vert$, which is finite. We compute that
\begin{align*}
\Vert T\xi-T_\alpha\xi_\beta\Vert\leq\Vert T\xi-T_\alpha\xi\Vert+\Vert T_\alpha\xi-T_\alpha\xi_\beta\Vert\leq \Vert T\xi-T_\alpha\xi\Vert+C\Vert\xi-\xi_\beta\Vert
\end{align*}
where the RHS converges to $0$ under $\lim_{\alpha,\beta}$.
\end{proof}


\begin{co}\label{lb159}
Let $V_0,V_1,\dots,V_k$ be inner product spaces. For each $1\leq i\leq k$, let $(T^i_{\alpha_i})_{\alpha_i\in\scr A_i}$ be a net in $\fk L(V_{i-1},V_i)$ converging in SOT to $T^i\in\fk L(V_{i-1},V_i)$. Assume that
\begin{align*}
\sup_{\alpha_i\in\scr A_i}\Vert T^i_{\alpha_i}\Vert<+\infty\qquad\text{for all }2\leq i\leq k
\end{align*}
Then for each $\xi\in V_0$, we have
\begin{align*}
\lim_{(\alpha_1,\dots,\alpha_k)\in\scr A_1\times\cdots\times\scr A_k}T^k_{\alpha_k}\cdots T^1_{\alpha_1}\xi= T^k\cdots T^1\xi
\end{align*}
\end{co}

Similar to Thm. \ref{lb155}, if we also assume $\scr A_1=\cdots=\scr A_k=\scr A$, then
\begin{align*}
\lim_{\alpha\in\scr A} T^k_\alpha\cdots T^1_\alpha\xi=T^k\cdots T^1\xi
\end{align*}


\begin{proof}
This follows immediately from Thm. \ref{lb155}.
\end{proof}


\begin{co}\label{lb161}
Let $(T_\alpha)_{\alpha\in\scr A}$ be a net in $\fk L(V)$ satisfying $\sup_\alpha\Vert T_\alpha\Vert<+\infty$ and converging in SOT to $T\in\fk L(V)$. Then for each polynomial $f\in\Cbb[z]$ and $\xi\in V$,
\begin{align*}
\lim_\alpha f(T_\alpha)\xi=f(T)\xi
\end{align*}
\end{co}


\begin{proof}
This is clear by Cor. \ref{lb159}.
\end{proof}



\begin{eg}
In Exp. \ref{lb160}, since $\sup_{I\in\fin(2^X)}\Vert E_I\Vert=1<+\infty$, by Cor. \ref{lb159} we have
\begin{align*}
\lim_{I\in\fin(2^X)}RP_ISP_IT\eta=RST\eta\qquad\text{for each $\eta\in\MH$}
\end{align*}
\end{eg}




\begin{eg}\label{lb397}
Let $\MH$ be a Hilbert space with basis $(e_x)_{x\in X}$. For each $I\in\fin(2^X)$, let $P_I$ be the projection onto $U_I=\Span\{e_x:x\in I\}$. By Thm. \ref{lb155}, $\lim_I P_ITP_I$ converges in SOT to $T$, and 
\begin{align*}
\sup_I\Vert P_ITP_I\Vert\leq\sup_I \Vert P_I\Vert\cdot\Vert T\Vert\cdot\Vert P_I\Vert\leq \Vert T\Vert<+\infty
\end{align*}
Therefore, by Cor. \ref{lb161}, for each $T\in\fk L(H)$ and $f\in\Cbb[z]$, 
\begin{align*}
\lim_{I\in\fin(2^X)} f(P_ITP_I)\qquad\text{converges in SOT to }f(T)
\end{align*}
\end{eg}







\subsection{Problems}


Let $V$ be an inner product space.


\begin{prob}
Let $\omega$ be a Hermitian form on $V$. Prove the following sharpened polarization identity: For each $\xi,\eta\in V$ we have
\begin{align}\label{eq145}
\omega(\xi|\eta)=\frac 14\big(\omega(\xi+\eta|\xi+\eta)-\omega(\xi-\eta|\xi-\eta)\big)
\end{align}
Conclude that if $M\in\Rbb_{\geq0}$ and
\begin{align*}
|\omega(\xi|\xi)|\leq M\Vert\xi\Vert^2
\end{align*}
for each $\xi\in V$, then $\Vert\omega\Vert\leq M$. This sharpens Prop. \ref{lb238} in the Hermitian case.
\end{prob}


\begin{proof}[Hint]
First show $|\omega(\xi|\eta)|\leq (\Vert\xi\Vert^2+\Vert\eta\Vert^2)/2$.
\end{proof}



\begin{df}
Let $V$ be an inner product space. A \textbf{Hilbert space completion} \index{00@Hilbert space completion} denotes a linear isometry $\Phi:V\rightarrow\MH$ such that $\MH$ is a Hilbert space and $\Phi(V)$ is dense in $\MH$. Replacing $V$ with $\Phi(V)$, one may view $V$ as a dense inner product subspace of $\MH$
\end{df}


\begin{dprob}\label{lb350}
Prove that any inner product space $V$ admits a Hilbert space completion.
\end{dprob}

Note that when $V$ admits an orthonormal basis (e.g. when $V$ is separable), the problem is directly solved by Cor. \ref{lb126}.

\begin{proof}[Hint]
Let $\MH$ be the metric space completion of $V$. Define vector additions, scalar multiplications, and the sesquilinear form $\bk{\cdot|\cdot}$ in an appropriate way, and prove that $\bk{\cdot|\cdot}$ is positive definite. 
\end{proof}




\newpage



\section{The polynomial moment problem: a prehistory of spectral theory}\label{lb114}


\subsection{Divergent series and the birth of the Stieltjes integral}\label{lb182}


\subsubsection{Divergent series and the Pad\'e approximation}

In 1894, Stieltjes introduced the Stieltjes integral in \cite{Sti94} (see \cite[Vol. II]{Sti-C} for an English translation) for the purpose of studying continued fractions. One key motivation for investigating continued fractions was to better understand the behavior of the series
\begin{align}\label{eq94}
\frac{c_0}{z}+\frac{c_1}{z^2}+\frac{c_2}{z^3}+\cdots\qquad\text{where each }c_n\geq0
\end{align}
in the divergent case---that is, when $\sum_n c_nr^n=+\infty$ for each $r>0$. The core idea is that even when the power series in \eqref{eq94} diverges, it may still define a meaningful function outside a closed interval $I\subset\Rbb$, provided we adopt a different notion of convergence. 

Specifically, under suitable conditions on the sequence $(c_n)_{n\in\Nbb}$, one can construct a sequence of rational functions $(f_n(z))_{n\in\Nbb}$, 
\begin{align}
f_n(z)=\frac{q_n(z)}{p_{n+1}(z)}\qquad\text{where }p_{n+1},q_n\in\Cbb[z],\deg p_{n+1}=n+1,\deg q_n=n
\end{align}
Moreover, when $|z|$ is sufficiently large, $f_n(z)$ has Laurent expansion
\begin{subequations}\label{eq97}
\begin{gather}
f_n(z)=\sum_{m\in\Nbb}c_{n,m}z^{-m-1}\qquad\text{with $c_{n,m}=c_n$ when $m\leq 2n+1$}
\end{gather}
In other words,
\begin{align}
f_n(z)=\frac{c_0}{z}+\frac{c_1}{z^2}+\cdots+\frac{c_{2n+1}}{z^{2n+2}}+\frac{?}{z^{2n+3}}+\cdots
\end{align}
\end{subequations}
The sequence $(f_n)$ (or a subsequence thereof) converges locally uniformly on $\Cbb\setminus I$ to a holomorphic function $f$. This  approximation is referred to as a \textbf{Pad\'e approximation}. \index{00@Pad\`e approximation} In such cases, we say that the holomorphic function $f(z)$ represents the series \eqref{eq94} and write
\begin{align*}
f(z)\sim \frac{c_0}{z}+\frac{c_1}{z^2}+\frac{c_2}{z^3}+\cdots
\end{align*}



\subsubsection{Stieltjes integral as the weak-* completion of finite sum}


With the help of Pad\'e approximation, we can understand how the Stieltjes integral naturally arises as the weak-* completion of finite sums. As we will see in the following sections, under suitable assumptions on the sequence $(c_n)$, each rational function $f_n(z)$ has only simple poles. Consequently, $f_n(z)$ admits the representation
\begin{align}\label{eq95}
f_n(z)=\sum_i \frac{a_{n,i}}{z-\lambda_{n,i}}
\end{align}
where the sum is finite. Moreover, we have $a_{n,i}\geq0$ and $\lambda_{n_i}\in I$.


The general Stieltjes integral appears when one tries to understand the behavior of the finite sum on the RHS of \eqref{eq95} under the limit $n\rightarrow+\infty$. To understand this behavior, we define an increasing function $\rho_n:I\rightarrow\Rbb_{\geq0}$ by setting
\begin{align*}
\rho_n(x)=\sum_{\lambda_{n,i}\leq x}a_{n,i}
\end{align*}
That is, $\rho_n$ is the right-continuous increasing function associated to the measure $\sum_i a_{n,i}\delta_{\lambda_{n,i}}$. Then \eqref{eq95} can be rewritten as
\begin{align*}
f_n(z)=\int_I \frac{d\rho_n(x)}{z-x}
\end{align*}


The sequence $(\rho_n)$ is indeed uniformly bounded. Therefore, by passing to a subsequence if necessary, we may assume that $(\rho_n)$ almost converges to some increasing right-continuous function $\rho$. Therefore, by Thm. \ref{lb92}, $(\rho_n)$ converges weak-* to $\rho$. It follows that $(f_n)$ converges locally uniformly on $\Cbb\setminus I$ to
\begin{align}\label{eq96}
f(z)=\int_I\frac{d\rho(x)}{z-x}
\end{align}
This gives a holomorphic function $f$ on $\Cbb\setminus I$ representing the series \ref{lb94}.

\begin{df}
For each increasing function $\rho:I\rightarrow\Rbb_{\geq0}$, the function $f(z)$ defined by \eqref{eq96} is called the \textbf{Stieltjes transform} \index{00@Stieltjes transform} of $\rho$. If $\mu$ is a finite Borel measure on $I$, we also call the function
\begin{align*}
\Cbb\setminus I\rightarrow\Cbb\qquad z\mapsto\int_I\frac{d\mu(x)}{z-x}
\end{align*}
the \textbf{Stieltjes transform} of $\mu$.
\end{df}


We have thus seen that, via Pad\'e approximation, the Stieltjes integral with respect to a general increasing function emerges as the (weak-*) limit of finite sums. This marks the first historical appearance of approximating a continuous spectrum by discrete spectra.


In the next section, we will see that \uwave{the approximation of $\rho$ by the sequence $(\rho_n)$ can be interpreted as the finite-rank approximation of a (not necessarily bounded) Hermitian operator}. Since this type of approximation plays a central role in the development of spectral theory by Hilbert and Riesz, it is crucial to understand its origin in the study of divergent series and its connection with Pad\'e approximation.


\subsubsection{The polynomial moment problem}\label{lb184}




We now investigate the following question: What assumption should we impose on $(c_n)_{n\in\Nbb}$ so that the above strategy can be carried out? Note that when $|z|>|\lambda_{n,i}|$, we have
\begin{align*}
(z-\lambda_{n,i})^{-1}=\sum_{m\in\Nbb} z^{-m-1}(\lambda_{n,i})^m
\end{align*}
Therefore, \eqref{eq95} becomes $f_n(z)=\sum_{m\in\Nbb}\sum_i z^{-m-1}\cdot a_{n,i}(\lambda_{n,i})^m$, and hence
\begin{align*}
f_n(z)=\sum_{m\in\Nbb}z^{-m-1}\cdot\int_I x^md\rho_n
\end{align*}
Comparing this with \eqref{eq97}, we obtain
\begin{align*}
c_{n,m}=\int_I x^m d\rho_n
\end{align*}

On the one hand, \eqref{eq97} shows that $\lim_n c_{n,m}=c_n$. On the other hand, the weak-* convergence of $(d\rho_n)$ to $d\rho$ actually implies that $\lim_n\int_I x^m d\rho_n(\lambda)$ converges to $\int_I x^m d\rho(\lambda)$. Thus, we obtain
\begin{align}\label{eq98}
c_m=\int_I x^md\rho\qquad\text{for all }m\in\Nbb
\end{align}
Therefore, a necessary condition for the above strategy to work is the existence of an increasing function $\rho$ satisfying \eqref{eq98}. As we shall see in the next section, this condition is also sufficient. In this way, the problem of representing a divergent series and approximating it using rational functions is closely related to the polynomial moment problem.





\hypertarget{proofread}{}




\subsection{Pad\'e approximation via the finite-rank approximation of Hermitian operators}\label{lb188}



In this section, we let $I\subset\Rbb$ be a proper closed interval. For simplicity, we assume that $I$ is one of the following intervals
\begin{align*}
\Rbb\qquad [0,+\infty)\qquad [0,1]
\end{align*} 
Let $\Rr(I)$ \index{Rr@$\Rr(I)$} be the set of functions $\rho:I\rightarrow\Rbb_{\geq0}$ satisfying condition (a) of the Riesz representation Thm. \ref{lb9}. That is,
\begin{align}\label{eq100}
\begin{aligned}
\Rr(I)=\{&\text{Increasing right continuous function }\rho:I\rightarrow\Rbb_{\geq0}\\
&\text{satisfying }\lim_{x\rightarrow-\infty}\rho(x)=0\text{ if }I=\Rbb\}
\end{aligned}
\end{align}
Fix a family $(c_n)_{n\in\Nbb}$ in $\Rbb$. 

\subsubsection{The goal}



\begin{problem}[\textbf{Polynomial moment problem}] \index{00@Polynomial moment problem}\label{lb162}
Does there exists $\rho\in\Rr(I)$ such that
\begin{align}\label{eq79}
c_n=\int_I x^nd\rho\qquad\text{for each $n\in\Nbb$}
\end{align}
where the RHS is integrable, i.e., $\int_I |x|^nd\rho<+\infty$? Depending on whether $I$ is $\Rbb$, $\Rbb_{\geq0}$, or $[0,1]$, this problem is referred to as the \textbf{Hamburger moment problem}, \index{00@Hamburger moment problem} the \textbf{Stieltjes moment problem}, \index{00@Stieltjes moment problem} or the \textbf{Hausdorff moment problem}, \index{00@Hausdorff moment problem} respectively.
\end{problem}

The goal of this section is to give a complete solution of this problem; see Thm. \ref{lb169}. Moreover, when the moment problem is solvable for the given sequence $(c_n)$, we will find $\rho\in\Rr(I)$ whose Stieltjes transform
\begin{align*}
f(z)=\int_I\frac{d\rho(x)}{z-x}
\end{align*}
represents the series $\sum_{n=0}^\infty c_nz^{-n-1}$ in the sense of Pad\'e approximation. That is, there is a sequence of rational functions $(f_n(z))_{n\in\Nbb}$ satisfying \eqref{eq97}, and a subsequence $(f_{n_k}(z))$ converging locally uniformly on $\Cbb\setminus I$ to $f(z)$. \footnote{When the solution to the moment problem is unique, the original sequence $(f_n)$ indeed converges locally uniformly to $f$. The uniqueness aspect of moment problems, however, will not be addressed in this course.} Thus, the problem of representing the (possibly divergent) series $\sum_{n=0}^\infty c_nz^{-n-1}$ for such $(c_n)$ is solved. See Thm. \ref{lb183}.



The classical construction of the sequence $(f_n)$ relies crucially on the idea of orthogonal polynomials. The approach presented in this section reformulates that classical method using the language of inner product spaces---a modern reinterpretation shaped by the development of spectral theory in Hilbert spaces. Of course, this reformulation is a retrospective abstraction that emerged only after the development of spectral theory in Hilbert spaces. In this section, we adopt this modern perspective, while aiming to present it in a way that remains mindful of its historical origins. In the following sections, we will explain how this approach connects to continued fractions and the classical formulation using orthogonal polynomials.












\subsubsection{Preliminary}

Let us clarify the meaning of \eqref{eq79}, since we have so far defined $\int_Ifd\rho$ only for $f\in C_c(I)$.

\begin{df}
Let $f$ be a Borel function from $I$ to $\Cbb$ or $\ovl\Rbb_{\geq0}$. Let $\rho\in\Rr(I)$. Let $\mu_\rho$ be the finite Borel measure on $I$ associated to $\rho$ as in the Riesz representation Thm. \ref{lb9}. We define the \textbf{Stieltjes integral} $\int_I fd\rho$ to be \index{00@Stieltjes integral}
\begin{align*}
\int_I fd\rho:=\int_If\mu_\rho
\end{align*}
provided that the integral on the RHS exists.
\end{df}


\begin{rem}\label{lb176}
When $f:I\rightarrow\Rbb_{\geq0}$ is continuous, the computation of the integral $\int_Ifd\rho$ can be reduced to those of compactedly supported continuous functions. Indeed, for each $\lambda\geq0$, let $\beta_\lambda:\Rbb\rightarrow[0,1]$ be the (continuous) piecewise linear functions such that
\begin{align*}
\beta_\lambda|_{[-\lambda,\lambda]}=1\qquad \beta_\lambda|_{(-\infty,-\lambda-1]\cup[\lambda+1,+\infty)}=0
\end{align*}
Then $f\beta_\lambda\in C_c(I)$, and $\int_I f\beta_\lambda d\rho$ is increasing as $\lambda$ increases. Therefore, by MCT, we have
\begin{align*}
\int_I fd\rho=\lim_{\lambda\rightarrow+\infty}\int_I f\beta_\lambda d\rho
\end{align*}
\end{rem}

\begin{comment}
\begin{eg}
If $I=[0,1]$, then $\int_I d\rho=\rho(1)$. If $I$ equals $\Rbb$ or $\Rbb_{\geq0}$, then
\begin{align*}
\int_I d\rho=\lim_{x\rightarrow+\infty}\rho(x)
\end{align*}
\end{eg}

\begin{proof}
When $I=[0,1]$, the definition of Stieltjes integral clearly imply $\int_Id\rho=\rho(1)$. Assume that $I$ is $\Rbb$ or $\Rbb_{\geq0}$. Recall from \eqref{eq42} that $\rho(x)=\mu(I_{\leq x})$, and hence
\begin{align*}
\lim_{x\rightarrow+\infty}\rho(x)=\lim_{x\rightarrow+\infty} \int_I \chi_{I_{\leq x}}d\rho=\int_Id\rho
\end{align*}
where the last equality is due to MCT.
\end{proof}
\end{comment}






\subsubsection{The Hankel matrix}


\begin{df}
Let $H\in\Cbb^{\Nbb\times\Nbb}$. Associate to $H$ the unique sesquilinear form
\begin{align*}
\bk{\cdot|\cdot}:\Cbb[x]\times\Cbb[x]\rightarrow\Cbb\qquad (x^m,x^n)\mapsto H(m,n)
\end{align*} 
We say that $H$ is \textbf{Hermitian} (resp. \textbf{positive}, \textbf{positive definite}) if $\bk{\cdot|\cdot}$ is Hermitian (resp. positive (semi-definite), positive definite). 

For each $n\in\Nbb$, the \textbf{\pmb{$n$}-th truncation $\pmb{H_n}$} of $H$ is the $(n+1)\times(n+1)$ matrix defined by the first $(n+1)$ rows and columns of $H$. \hfill
\end{df}


\begin{rem}
By linear algebra, $H$ is positive definite iff $\det H_n>0$ for each $n$; $H$ is positive (semi-definite) iff the determinant of each principal submatrix is $\geq0$.
\end{rem}


\begin{df}\label{lb203}
The \textbf{Hankel matrix $\pmb H$} \index{00@Hankel matrix} of $(c_n)_{n\in\Nbb}$ is defined by
\begin{align*}
H(m,n)=c_{m+n}
\end{align*}
That is,
\begin{align*}
H=\begin{pmatrix}
c_0&c_1&c_2&c_3&\cdots\\
c_1&c_2&c_3&c_4&\cdots\\
c_2&c_3&c_4&c_5&\cdots\\
c_3&c_4&c_5&c_6&\cdots\\
\vdots&\vdots&\vdots&\vdots&\ddots
\end{pmatrix}
\end{align*}
Equivalently, the associated sesquilinear form is determined by
\begin{subequations}\label{eq80}
\begin{gather}
\bigbk{f\big|g}=\bigbk{1\big|\ovl fg}\qquad\text{for each }f,g\in\Cbb[x]\label{eq80a}\\
\bigbk{1\big|x^n}=c_n\qquad\text{for each }n\in\Nbb\label{eq80b}
\end{gather}
\end{subequations}
Since each $c_n$ is real, $H$ is Hermitian.

We also let $H'\in\Rbb^{\Nbb\times \Nbb}$ be the defined by $H'(m,n)=c_{m+n+1}$, that is,
\begin{align*}
H'=\begin{pmatrix}
c_1&c_2&c_3&c_4&\cdots\\
c_2&c_3&c_4&c_5&\cdots\\
c_3&c_4&c_5&c_6&\cdots\\
c_4&c_5&c_6&c_7&\cdots\\
\vdots&\vdots&\vdots&\vdots&\ddots
\end{pmatrix}
\end{align*}
In other words, its associated sesquilinear form is
\begin{align}\label{eq81}
\Cbb[x]\times\Cbb[x]\rightarrow\Cbb\qquad (f,g)\mapsto \bk{f|xg}
\end{align}
Since $c_n\in\Rbb$, $H'$ is also Hermitian. It follows that
\begin{align}\label{eq82}
\Cbb[x]\times\Cbb[x]\rightarrow\Cbb\qquad (f,g)\mapsto \bk{f|(1-x)g}
\end{align}
is the (Hermitian) sesquilinear form associated to $H-H'$. \hqed
\end{df}

\begin{rem}\label{lb166}
Note that by \eqref{eq80a}, for each $f,g,h\in\Cbb[x]$ we have
\begin{align}
\bigbk{f\big|hg}=\bigbk{\ovl hf\big|g}
\end{align}
since $\bk{f|hg}=\bk{1|\ovl fhg}=\bk{1|\ovl{\ovl hf}g}=\bk{\ovl hf|g}$.
\end{rem}


The construction of $H$ and $H'$ can be understood in a more general context; see Rem. \ref{lb349}.



In the rest of this section, we always let $H$ denote the Hankel matrix of $(c_n)_{n\in\Nbb}$, and equip $\Cbb[x]$ with the sesquilinear form associated to $H$.


\begin{pp}\label{lb168}
Suppose that Pb. \ref{lb162} has a solution $\rho$. Then $H$ must be positive, and the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $H$ is positive definite.
\item The range of the solution $\rho$ is not a finite set (equivalently, the associated measure $\mu_\rho$ is not supported in a finite set, cf. Lem. \ref{lb163}).
\end{enumerate}
Moreover, if $I=[0,+\infty)$, then $H'$ is positve; if $I=[0,1]$, then both $H'$ and $H-H'$ are positive.
\end{pp}


\begin{proof}
Let $\rho$ be a solution of Pb. \ref{lb162}. Then for each $f,g\in\Cbb[x]$, we have
\begin{align}\label{eq101}
\bk{f|g}= \int_I \ovl f gd\rho
\end{align}
since this is clearly true when $f=x^m,g=x^n$. Thus $\bk{f|f}=\int_I |f|^2d\rho\geq0$. 

If $H$ is not non-degenerated, then there exists $0\neq f\in\Cbb[x]$ such that $\bk{f|f}=0$, and hence $\int_I|f|^2d\rho=0$. From this, one easily checks that $\Supp(\rho)$ is a subset of the finite set $f^{-1}(0)$. Conversely, if $\mu_\rho$ is supported in a finite set $E\subset I$, we choose a non-zero $f\in\Cbb[x]$ such that $f|_E=0$. Then $\bk{f|f}=\int_I|f|^2d\mu_\rho=0$. This shows that $H$ is not non-degenerate. This proves the equivalence of (1) and (2).

If $I=[0,+\infty)$, then for each $f\in\Cbb[x]$, since $x|f|^2\geq0$ on $I$, we have
\begin{align*}
\bk{f|xf}=\int_{[0,+\infty)}x|f|^2d\rho\geq0
\end{align*}
Therefore, $H'$ is positive. Similarly, if $I=[0,1]$, then for each $f\in\Cbb[x]$, both $x|f|^2$ and $(1-x)|f|^2$ are $\geq0$ on $I$. Therefore
\begin{align*}
\bk{f|xf}=\int_{[0,1]}x|f|^2d\rho\geq0\qquad  \bk{f|(1-x)f}=\int_{[0,1]}(1-x)|f|^2d\rho\geq0
\end{align*}
This proves that both $H'$ and $H-H'$ are positive. 
\end{proof}


Therefore, to solve the polynomial moment problem, we should at least assume that $H$ is positive. Indeed, Prop. \ref{lb168} implies a half of the following theorem.
\begin{thm}\label{lb169}
Let $H$ be the Hankel matrix for $(c_n)_{n\in\Nbb}$. The following are true
\begin{enumerate}
\item The Hamburger moment problem (i.e. $I=\Rbb$) has a solution iff $H$ is positive.
\item The Stieltjes moment problem (i.e. $I=[0,+\infty)$) has a solution iff $H,H'$ are positive.
\item The Hausdorff moment problem (i.e. $I=[0,1]$) has a solution iff $H,H',H-H'$ are positive.
\end{enumerate}
\end{thm}


\begin{proof}
The direction ``$\Rightarrow$'' follows from Prop. \ref{lb168}. The direction ``$\Rightarrow$'' will follow immediately from Thm. \ref{lb177} once the latter has been established.
\end{proof}



\subsubsection{An abstract formulation of the Hankel matrix and its positivity}

Assume that $H$ is positive. In this subsection, we express the positivity of $H,H',H-H'$ in terms of the positivity of certain Hermitian operator $T$ and the operator $1-T$ on an inner product space $V$.

\begin{thm}\label{lb167}
Then there exists an inner product space $V$, a vector $\Omega\in V$, and a linear operator $T\in\Lin(V)$ satisfying the following properties:
\begin{enumerate}[label=(\arabic*)]
\item For each $n\in\Nbb$ we have
\begin{align}\label{eq85}
\bk{\Omega|T^n\Omega}=c_n
\end{align}
\item $\omega_T$ is Hermitian, i.e., $\bk{\eta|T\xi}=\bk{T\eta|\xi}$ for each $\xi,\eta\in V$.
\item (\textbf{Algebraic cyclicity})\index{00@Algebraic cyclicity} $V$ is spanned by $T^n\Omega$ for all $n\in\Nbb$.
\end{enumerate}
\end{thm}

Note that \eqref{eq85} implies
\begin{align}\label{eq86}
\Vert \Omega\Vert^2=c_0
\end{align}


\begin{proof}
Recall that $H$ determines a positive sesquilinear form $\bk{\cdot|\cdot}$ on $\Cbb[x]$. By Cor. \ref{lb164}, the null space
\begin{align}
\scr N=\{f\in\Cbb[x]:\Vert f\Vert^2=0\}
\end{align}
is a linear subspace of $\Cbb[x]$, and $\bk{\cdot|\cdot}$ descends to an inner product of
\begin{align*}
V=\Cbb[x]/\scr N
\end{align*}
Let
\begin{align*}
T:\Cbb[x]\rightarrow\Cbb[x]\qquad f\mapsto xf
\end{align*}
If $f\in\scr N$, by Cauchy-Schwarz (cf. Thm. \ref{lb165}) and Rem. \ref{lb166},
\begin{align*}
0\leq\bk{xf|xf}=\bk{x^2f|f}\leq\Vert x^2f\Vert\cdot\Vert f\Vert=0
\end{align*}
and hence $xf\in\scr N$. Therefore, the above map $T$ descends to a linear map
\begin{align}\label{eq121}
T:V\rightarrow V\qquad f+\scr N\mapsto xf+\scr N
\end{align}
Let $\Omega\in V$ be
\begin{align*}
\Omega=1+\scr N
\end{align*}
Then $\bk{\Omega|T^n\Omega}=\bk{1|x^n}=c_n$. By Rem. \ref{lb166}, $\omega_T$ is Hermitian. The algebraic cyclicity is obvious.
\end{proof}

\begin{rem}\label{lb170}
From the above proof, it is clear that for each $f,g\in\Cbb[x]$, we have
\begin{align*}
\bk{f(T)\Omega|g(T)\Omega}=\bk{f|g}
\end{align*}
Therefore, $\omega_T\geq0$ holds iff $\bk{f(T)\Omega|Tf(T)\Omega}\geq0$ for all $f\in\Cbb[x]$, iff $\bk{f|xf}\geq0$ for all $f\in\Cbb[x]$, iff $H'$ is positive. Similarly, $\omega_{1-T}\geq0$ iff $H-H'$ is positive.
\end{rem}


\begin{comment}
\begin{rem}
The triple $(V,\Omega,T)$ satisfying the requirements in Thm. \ref{lb167} are unique up to unitary operators. Namely, if $(\wtd V,\wtd\Omega,\wtd T)$ is another triple satisfying the requirements in Thm. \ref{lb167}, then there is a (necessarily unique) unitary operator $\Phi:V\rightarrow\wtd V$ satisfying $\Phi\Omega=\wtd\Omega$ and $\Phi T=\wtd T\Phi$.
\end{rem}


\begin{proof}
For each $f\in\Cbb[x]$, since $\omega_T$ is Hermitian, we have $\bk{\eta|f(T)\xi}=\bk{\ovl f(T)\eta|\xi}$ for each $\xi,\eta\in V$. A similar property holds for $\wtd T$. Therefore, 
\begin{align*}
\bigbk{f(T)\Omega\big|f(T)\Omega}=\bigbk{\Omega\big||f|^2(T)\Omega}=\bigbk{\wtd\Omega\big||f|^2(\wtd T)\wtd\Omega}=\bigbk{f(\wtd T)\wtd\Omega\big|f(\wtd T)\wtd\Omega}
\end{align*}
In particular, $f(T)\Omega=0$ iff $f(\wtd T)\wtd\Omega=0$. Therefore, by the algebraic cyclicity, we have a unitary map
\begin{align}
\Phi:V\rightarrow\wtd V\qquad f(T)\Omega\mapsto f(\wtd T)\wtd\Omega
\end{align}
This map clearly satisfies the desired property.

Conversely, if $\Phi$ satisfies the requirements in the remark, then $\Phi$ must send $f(T)\Omega$ to $f(\wtd T)\wtd\Omega$. Therefore, such $\Phi$ must be unique. 
\end{proof}
\end{comment}





\subsubsection{Solving the moment problem: the degenerate case}

Assume $H\geq0$.

In this subsection, we explain how the moment problem can be solved when $\dim V<+\infty$. This happens when $H$ is degenerate. In that case, if we let $f(x)=x^n+a_{n-1}x^{n-1}+\cdots+a_0$ be the polynomial with lowest degree satisfying $\bk{f|f}=0$, then $f(T)\Omega=0$. Then $V$ has basis $\Omega,T\Omega,\cdots,T^{n-1}\Omega$, and $f$ is a minimal polynomial of $T$ on $V$. Conversely, it is also clear that if $\dim V<+\infty$, then $H$ is degenerate.


Assume $\dim V<+\infty$. Then $T$ is a Hermitian operator on the finite-dimensional inner product space $V$, and hence can be diagonalized. More precisely, there exists an orthonormal basis $e_1,\dots,e_n$ of $V$ such that $Te_j=\lambda_je_j$ for all $1\leq j\leq n$, where $\lambda_j\in\Rbb$. Write
\begin{align*}
\Omega=a_1e_1+\cdots+a_ne_n
\end{align*}
where $a_j\in\Cbb$. Then, for each $f\in\Cbb[x]$, we have
\begin{align*}
f(T)\Omega=\sum_{j=1}^n a_jf(\lambda_j)e_j
\end{align*}
and hence
\begin{align*}
\bk{\Omega|f(T)\Omega}=\sum_{j=1}^n f(\lambda_j)|a_j|^2=\int_\Rbb fd\rho
\end{align*}
where $\rho:\Rbb\rightarrow\Rbb_{\geq0}$ is an increasing function corresponding to the measure $\mu=\sum_{j=1}^n |a_j|^2\delta_{\lambda_j}$. In particular, by Thm. \ref{lb167}-(1), we conclude
\begin{align*}
\int_\Rbb x^nd\rho=\bk{\Omega|T^n\Omega}=c_n
\end{align*}
Thus, the Hamburger moment problem is solved.

Next, assume $I=[0,+\infty)$ and $H'\geq0$. By Rem. \ref{lb170}, $T$ is positive, and hence each $\lambda_j$ belongs to $[0,+\infty)$. Therefore, the measure $\mu$ constructed in the above paragraph is supported in $[0,+\infty)$, and hence $\int_{[0,+\infty)}x^nd\rho=c_n$. This solves the Stieltjes moment problem.

Finally, assume $I=[0,1]$ and $H',H-H'$ are positive. By Rem. \ref{lb170}, $T$ and $1-T$ are positive. Therefore, each $\lambda_j$ belongs to $[0,1]$, and hence $\int_{[0,1]}x^nd\rho=c_n$. This solves the Hausdorff moment problem.

To summarize, we have proved Thm. \ref{lb169} when $\dim V<+\infty$, equivalently, when $H$ is positive but not positive definite.





\subsubsection{Finite-rank approximation of $T$}\label{lb285}


In this subsection, we assume the following condition.

\begin{cond}\label{lb178}
Assume that $H\geq0$. Moreover:
\begin{itemize}
\item If $I=[0,+\infty)$, assume that $H'\geq0$ (equivalently, $\omega_T\geq0$, cf. Rem. \ref{lb170}).
\item If $I=[0,1]$, assume that $H',H-H'$ are both positive (equivalently, $\omega_T$ and $\omega_{1-T}$ are positive, cf. Rem. \ref{lb170}). 
\end{itemize}
\end{cond}


In this subsection, we construct a uniformly bounded sequence $(\rho_n)$ in $\Rr (I)$ whose Stieltjes transforms---or those of a subsequence---will provide the Pad\'e approximation of a function representing the series $\sum_{n\in\Nbb}c_nz^{-n-1}$.

\begin{df}\label{lb189}
Let $T$ be as in Thm. \ref{lb167}. For each $n\in\Nbb$, let
\begin{align*}
E_n\text{ be the projection of $V$ onto }V_n=\Span\{\Omega,T\Omega,\dots,T^n\Omega\}
\end{align*}
Then we clearly have
\begin{align}\label{eq84}
\Omega\in V_0\qquad TV_n\subset V_{n+1}
\end{align}
\end{df}



\begin{rem}\label{lb173}
Since $\omega_T$ and $\omega_{E_n}$ are Hermitian (Cor. \ref{lb171}), for each $n$ and $\xi\in V$ we have
\begin{align*}
\bk{\xi|E_nTE_n\xi}=\bk{TE_n\xi|TE_n\xi}=\omega_T(E_n\xi|E_n\xi)\geq0
\end{align*}
It follows that $\omega_{PTP}$ is Hermitian. Similarly, if $H'\geq0$ (equivalently, $\omega_T\geq0$), then
\begin{align*}
\bk{\xi|E_nTE_n\xi}=\bk{E_n\xi|TE_n\xi}\geq0
\end{align*}
and hence $\omega_{E_nTE_n}\geq0$. If both $H'$ and $H-H'$ are positive, then 
\begin{align*}
\bk{\xi|E_nTE_n\xi}=\bk{E_n\xi|TE_n\xi}\geq0\qquad\bk{\xi|E_n(1-T)E_n\xi}=\bk{E_n\xi|(1-T)E_n\xi}\geq0
\end{align*}
and hence $\omega_{E_nTE_n},\omega_{E_n(1-T)E_n}$ are positive.
\end{rem}


\begin{df}
For each $n\in\Nbb$, define a family $(c_{n,m})_{m\in\Nbb}$ in $\Rbb$ by
\begin{align}
c_{n,m}=\bk{\Omega|(E_nTE_n)^m\Omega}
\end{align}
\end{df}

\begin{rem}\label{lb185}
We have
\begin{align}\label{eq83}
c_{n,m}=c_m\qquad\text{if }m\leq 2n+1
\end{align}
Consequently,
\begin{align}\label{eq90}
\lim_{n\rightarrow\infty}c_{n,m}=c_m
\end{align}
\end{rem}

\begin{proof}
By \eqref{eq84}, we have 
\begin{subequations}\label{eq102}
\begin{gather}
(E_nTE_n)^k\Omega=T^k\Omega\in V_k\qquad \text{if }0\leq k\leq n\\
(E_nTE_n)^{n+1}\Omega=E_nT^{n+1}\Omega
\end{gather}
\end{subequations}
where the first line is proved by induction on $k$. Thus, for each $m\leq 2n+1$, writing $m=a+b$ where $a,b\in\Nbb$ and $a\leq n$ and $b\leq n+1$, we have
\begin{align*}
&\bk{\Omega|(E_nTE_n)^m\Omega}=\bk{(E_nTE_n)^a\Omega|(E_nTE_n)^b\Omega}=\bk{T^a\Omega|E_nT^b\Omega}=\bk{E_nT^a\Omega|T^b\Omega}\\
=&\bk{T^a\Omega|T^b\Omega}=\bk{\Omega|T^{a+b}\Omega}=c_m
\end{align*}
\end{proof}

\begin{pp}\label{lb174}
For each $n\in\Nbb$, there exists $\rho_n\in\Rr(I)$ such that $\Rng(\rho_n)$ is a finite subset of $[0,c_0]$, and that  for all $m\in\Nbb$ we have
\begin{align}\label{eq87}
c_{n,m}=\int_I x^md\rho_n
\end{align}
\end{pp}


\begin{proof}
We view $E_nTE_n$ as a linear operator $T_n$ on $V_n$, i.e.,
\begin{align}\label{eq120}
T_n:=E_nTE_n\big|_{V_n}
\end{align}
By Rem. \ref{lb173}, $T_n$ is Hermitian. Therefore, by linear algebra, $V_n$ has an orthonormal basis $e_{n,0},e_{n,1},\dots$ such that
\begin{align}
T_ne_{n,i}=\lambda_{n,i}e_{n,i}\qquad\text{for all }i
\end{align}
where $\lambda_{n,i}\in\Rbb$. Moreover, by Rem. \ref{lb173}, if $I=\Rbb_{\geq0}$ then $T_n\geq0$, and hence $\lambda_{n,i}\geq0$; if $I=[0,1]$ then $0\leq T_n\leq\id_{V_n}$, and hence $0\leq\lambda_{n,i}\leq 1$. It follows that
\begin{align*}
\lambda_{n,i}\in I
\end{align*}
in all cases. Write
\begin{align}
\Omega=\sum_i a_{n,i}e_{n,i}
\end{align}
where $a_n\in\Cbb$. (So $a_{n,i}=\bk{e_{n,i}|\Omega}$.) Thus
\begin{align*}
c_{n,m}=\bk{\Omega|(T_n)^m\Omega}=\sum_i (\lambda_{n,i})^m\cdot |a_{n,i}|^2=\int_I x^md\rho_n
\end{align*}
where $\rho_n$ is the unique element in $\Rr(I)$ whose associated finite Borel measure is $\sum_{i=0}^n|a_{n,i}|^2\delta_{\lambda_{n,i}}$, that is,
\begin{align}\label{eq119}
\rho_n(x)=\sum_{
\begin{subarray}{c}
\text{all $i$ satisfying}\\
\lambda_{n,i}\leq x
\end{subarray}
}|a_{n,i}|^2
\end{align}
In particular, by Parseval's identity, we have
\begin{align*}
0\leq \rho_n(x)\leq\sum_i |a_{n,i}|^2=\Vert\Omega\Vert^2\xlongequal{\eqref{eq86}}c_0
\end{align*}
\end{proof}


\subsubsection{From discrete spectra to continuous spectra}\label{lb205}


We continue to assume Condition \ref{lb178}. In this subsection, we solve the moment problem (i.e., complete the proof of Thm. \ref{lb169}) by proving Thm. \ref{lb177}.


\begin{df}\label{lb175}
Let $(\rho_n)_{n\in\Nbb}$ be the uniformly bounded sequence in $\Rr(I)$ described by Prop. \ref{lb174}. By Helly's selection Thm. \ref{lb94}, $(\rho_n)$ has a subsequence $(\rho_{n_k})_{k\in\Nbb}$ converging pointwise to some increasing function $\wtd\rho:I\rightarrow\Rbb_{\geq0}$. Define $\rho\in\Rr(I)$ as follows.
\begin{itemize}
\item If $I$ is $\Rbb_{\geq0}$ or $[0,1]$, we let $\rho$ be the right-continuous normalization of $\wtd\rho$.
\item If $I$ is $\Rbb$, we let $\rho$ be the right-continuous normalization of $\wtd\rho-\lim_{x\rightarrow-\infty}\wtd\rho(x)$.
\end{itemize}
Then by Thm. \ref{lb72} and Rem. \ref{lb93}, $d\rho$ and $d\wtd\rho$ represent the same element of $C_c(I,\Fbb)^*$. By Thm. \ref{lb92}, the sequence $(d\rho_{n_k})$ converges weak-* to $d\rho$.
\end{df}


\begin{thm}\label{lb177}
Assume Condition \ref{lb178}, and let $\rho\in\Rr(I)$ be as in Def. \ref{lb175}. Then for each $m\in\Nbb$, we have
\begin{align*}
c_m=\int_I x^md\rho
\end{align*}
where the RHS is integrable.
\end{thm}

\begin{proof}
The easiest case is where $I=[0,1]$. In that case, $x^m\in C_c(I)$. Therefore, by the weak-* convergence of $(d\rho_{n_k})$ to $d\rho$,
\begin{align*}
\int_I x^md\rho=\lim_k\int_I x^md\rho_{n_k}\xlongequal{\eqref{eq87}}\lim_k c_{n_k,m}\xlongequal{\eqref{eq90}}c_m
\end{align*}

Next, we consider the case where $I=\Rbb$. Let $\beta_\lambda$ be as in Rem. \ref{lb176}, and let $\alpha_\lambda=1-\beta_\lambda$. Let
\begin{align*}
0\leq \alpha_\lambda\leq \chi_{J_\lambda}\qquad\text{where }J_\lambda=(-\infty,-\lambda]\cup[\lambda,+\infty)
\end{align*}


We first consider the case where $m$ is even (so that $x^m\geq0$). Then $\int_Ix^md\rho$ exists as an element of $\ovl\Rbb_{\geq0}$. Moreover, we have
\begin{align}\label{eq91}
\lambda^2\alpha_\lambda\cdot x^m\leq \lambda^2\chi_{J_\lambda}\cdot x^m\leq x^{m+2}
\end{align}
Therefore,
\begin{align*}
\int_\Rbb \alpha_\lambda\cdot x^md\rho_{n_k}\leq\lambda^{-2}\int_\Rbb x^{m+2}d\rho_{n_k}
\end{align*}
By \eqref{eq83}, the RHS above is equal to $c_{m+2}$ when $1+2n_k\geq m$. Therefore, 
\begin{align}\label{eq88}
\lim_{\lambda\rightarrow+\infty}\sup_k\int_\Rbb \alpha_\lambda\cdot x^md\rho_{n_k}=0
\end{align}


Since $\beta_\lambda\cdot x^m$ is compactly supported, by the weak-* convergence of $(d\rho_{n_k})$ to $d\rho$,
\begin{align}\label{eq89}
\int_\Rbb \beta_\lambda\cdot x^m d\rho=\lim_k  \int_\Rbb \beta_\lambda\cdot x^m d\rho_{n_k}
\end{align}
By \eqref{eq88} and \eqref{eq89} and the fact that $\alpha_\lambda+\beta_\lambda=1$, for each $\eps>0$, we have
\begin{align*}
\bigg| \int_\Rbb \beta_\lambda\cdot x^m d\rho-\lim_k\int_\Rbb x^md\rho_{n_k}\bigg|\leq\eps\qquad\text{for sufficiently large } \lambda
\end{align*}
Therefore, by \eqref{eq83} and \eqref{eq90}, we have
\begin{align}\label{eq92}
\bigg| \int_\Rbb \beta_\lambda\cdot x^m d\rho-c_m\bigg|\leq\eps\qquad\text{for sufficiently large } \lambda
\end{align}
Since $\beta_\lambda\cdot x^m$ is increasing and converging pointwise to $x^m$ as $\lambda\nearrow+\infty$, by MCT, we conclude that $\int_\Rbb x^md\rho=c_m$. In particular, $x^m$ is $d\rho$-integrable.



Next, assume that $m$ is odd. Since $|x|^m\leq 1+x^{m+1}$ and since both $1=x^0$ and $x^{m+1}$ have been proved to be $d\rho$-integrable, we conclude that $x^m$ is $d\rho$-integrable.

Similar to \eqref{eq91}, we have
\begin{align*}
\lambda\alpha_\lambda\cdot x^m\leq \lambda\chi_{J_\lambda}\cdot x^m\leq x^{m+1}
\end{align*}
Therefore, a similar argument as above shows that for each $\eps>0$, \eqref{eq92} holds for the odd number $m$. By DCT, we conclude that $\int_\Rbb x^md\rho=c_m$.

The proof for the case that $I=\Rbb_{\geq0}$ is similar and is left to the reader. This case is even simpler, since $x^m\geq0$ for all $m$.
\end{proof}




\subsubsection{Pad\'e approximation and the representation of divergence series}


We continue to assume Condition \ref{lb178}. Let $(\rho_n)_{n\in\Nbb}$ be described by Prop. \ref{lb174}. Let $(\rho_{n_k})$ be a subsequence as in Def. \ref{lb175}. That is, there exists $\rho\in\Rr(I)$ such that $(d\rho_{n_k})$ converges weak-* to $d\rho$.


\begin{thm}\label{lb183}
Let $f_n,f:\Cbb\setminus I\rightarrow\Cbb$ be the Stieltjes transforms of $\rho_n$ and $\rho$, respectively. That is,
\begin{gather*}
f_n(z)=\int_I\frac{d\rho_n(x)}{z-x}\qquad f(x)=\int_I\frac{d\rho(x)}{z-x}
\end{gather*}
Then each $f_n(z)$ has the Laurent expansion
\begin{align}\label{eq99}
f_n(z)=\frac{c_0}{z}+\frac{c_1}{z^2}+\cdots+\frac{c_{2n+1}}{z^{2n+2}}+\frac{?}{z^{2n+3}}+\cdots
\end{align}
when $|z|$ is sufficiently large. Moreover, $(f_{n_k})$ converges locally uniformly on $\Cbb\setminus I$ to $f$.
\end{thm}


Therefore, the subsequence $(f_{n_k})$ provides a Pad\'e approximation of $f$, and hence
\begin{align*}
f\sim \frac{c_0}{z}+\frac{c_1}{z^2}+\frac{c_2}{z^3}+\cdots
\end{align*}



\begin{proof}
Recall from Prop. \ref{lb174} that $c_{m,n}=\int_I x^md\rho_n$. Therefore, by the argument in Subsec. \ref{lb184}, $f_n(z)$ has the Laurent expansion $\sum_n c_{m,n}z^{-n-1}$. Combined with Rem. \ref{lb185}, this establishes \eqref{eq99}.

For each $z\in \Cbb\setminus I$, let $f_z\in C_0(I)$ be defined by $f_z(x)=(z-x)^{-1}$. For each $z\in\Cbb\setminus I$, one easily checks that $\lim_{\zeta\rightarrow z}f_\zeta$ converges uniformly on $I$ to $f_z$. Thus, we have a continuous map
\begin{align*}
\Phi:\Cbb\setminus I\rightarrow C_0(I)\qquad z\mapsto f_z
\end{align*}
where $C_0(I)$ is equipped with the $l^\infty$-norm. Therefore, for each compact $K\subset\Cbb\setminus I$, the family $\Phi(K)$ is compact in $C_0(I)$. Since $(d\rho_{n_k})$  converges weak-* to $d\rho$ as linear functionals on $C_0(I)$ (cf. Rem. \ref{lb186}), it follows from Thm. \ref{lb187} below that $(d\rho_{n_k})$ converges uniformly to $d\rho$ when evaluated on functions in $\Phi(K)$. This proves that $(f_{n_k})$ converges locally uniformly to $f$.
\end{proof}




\begin{thm}\label{lb187}
Let $\MV,\MW$ be normed vector spaces. Let $(T_\alpha)$ be a net in $\fk L(\MV,\MW)$ satisfying $\sup_\alpha \Vert T_\alpha\Vert<+\infty$ and converging pointwise to some $T\in\fk L(\MV,\MW)$. Let $K$ be a precompact subset of $V$. Then $(T_\alpha)$ converges uniformly on $K$ to $T$. That is,
\begin{align*}
\lim_\alpha \sup_{\xi\in K}\Vert T\xi-T_\alpha\xi\Vert=0
\end{align*}
\end{thm}


\begin{proof}
Replacing $K$ with $\ovl K$, we assume that $K$ is compact. Since $C:=\sup_\alpha\Vert T_\alpha\Vert<+\infty$ is a uniform Lipschitz of $(T_\alpha)$, the family $(T_\alpha)$ is equicontinuous. Therefore, by Thm. \ref{lb179}, $(T_\alpha)$ converges uniformly on $K$ to $T$.
\end{proof}


\subsection{Pad\'e approximation via orthogonal polynomials}


\subsubsection{The setting}\label{lb194}


Fix $I\in\{\Rbb,\Rbb_{\geq0},[0,1]\}$, and choose a sequence $(c_n)_{n\in\Nbb}$ in $\Rbb$ satisfying Condition \ref{lb178}. 
Moreover, we assume that the Hankel matrix $H$ of $(c_n)$ is positive-definite. Therefore, the triple $(V,\Omega,T)$ in Thm. \ref{lb167} can be described as follows: $V$ is the vector space $\Cbb[x]$ together with the inner product determined by $H$, the cyclic vector $\Omega$ is chosen to be the constant $1$, and $T$ is the multiplication by $x$. We assume for simplicity that
\begin{align*}
c_0=1
\end{align*}
Therefore, $\Vert\Omega\Vert=1$.

Recall that $E_n$ is the projection operator of $V$ onto $V_n=\Span\{1,x,\dots,x^n\}=\Span\{\Omega,T\Omega,\dots,T^n\Omega\}$. By Rem. \ref{lb173},
\begin{align*}
T_n:=E_nTE_n\big|_{V_n}
\end{align*}
is a self-adjoint operator on $V_n$. Note that
\begin{align*}
\dim V_n=n+1
\end{align*}

Recall \eqref{eq100} for the meaning of $\Rr(I)$. Let $(\rho_n)_{n\in\Nbb}$ be the sequence in $\Rr(I)$ constructed in the proof of Prop. \ref{lb174}. That is,
\begin{subequations}\label{eq114}
\begin{align}
\rho_n(x)=\sum_{
\begin{subarray}{c}
\text{all $i$ satisfying}\\
\lambda_{n,i}\leq x
\end{subarray}
}|\bk{e_{n,i}|\Omega}|^2
\end{align}
where $e_{n,0},\dots,e_{n,n}$ form an orthonormal basis of $V_n$ such that
\begin{align}
T_ne_{n,i}=\lambda_{n,i}e_{n,i}\qquad\text{for all }i
\end{align}
\end{subequations}
and $\lambda_{n,i}\in I$. As in Thm. \ref{lb183}, we let $f_n(z)$ be the Stieltjes transform of $\rho_n$, i.e.,
\begin{align*}
f_n(z)=\int_I\frac{d\rho_n(x)}{z-x}
\end{align*}
Since $\rho_n$ has finite range, $f_n(z)$ is a rational function. 




\subsubsection{Expressing $f_n(z)$ as a quotient of determinants}\label{lb191}


As shown in Thm. \ref{lb183}, a subsequence of $(f_n)$ forms a Pad\'e approximation to a holomorphic function $f$ representing the series $\sum_{n\in\Nbb}c_nz^{-n-1}$. The goal of this section is to provide an elementary description of $f_n$ in terms of orthogonal polynomials. This description not only offers insight into the historical development of Pad\'e approximation but is also essential for connecting Pad\'e approximation to continued fractions, as we will see in the next section.


\begin{pp}\label{lb195}
For sufficiently large $|z|$, we have
\begin{align*}
f_n(z)=\bigbk{\Omega\big|(z-T_n)^{-1}\Omega}
\end{align*}
\end{pp}

\begin{proof}
By \eqref{eq114}, we have $(z-T_n)^{-1}e_{n,i}=(z-\lambda_{n,i})^{-1}e_{n,i}$. Hence, the relation $\Omega=\sum_{i=0}^n e_{n,i}\cdot\bk{e_{n,i}|\Omega}$ implies
\begin{align*}
\bigbk{\Omega\big|(z-T_n)^{-1}\Omega}=\sum_i |\bk{e_{n,i}|\Omega}|^2\cdot (z-\lambda_{n,i})^{-1}=\int_I\frac{d\rho_n(x)}{z-x}
\end{align*}
\end{proof}


Therefore, if we extend the unit vector $\Omega$ to an orthonormal basis of $V_n$, then by Cramer's rule, $f_n(z)$ can be expressed as a quotient 
\begin{align}\label{eq104}
f_n(z)=\frac{\wtd q_n(z)}{\wtd p_{n+1}(z)}
\end{align}
where $\wtd p_{n+1}(z)=\det(z-T_n)$, and $\wtd q_n(z)$ is a minor of $z-T_n$ of order $n$. In particular, we have
\begin{align*}
\deg\wtd p_{n+1}=n+1\qquad \deg\wtd q_n=n
\end{align*}
Remarkably, the sequence $(\wtd p_n)_{n\in\Nbb}$ turns out to be orthogonal polynomials, as we will explain below.



\subsubsection{Orthogonal polynomials}


\begin{df}\label{lb190}
Let $(p_n)_{n\in\Nbb}$ be a sequence in $\Cbb[x]$. We say that $(p_n)$ are \textbf{orthogonal polynomials} (resp. \textbf{orthonormal polynomials}) \index{00@Orthogonal and orthonormal polynomials} with respect to $(c_n)_{n\in\Nbb}$ if the following conditions are satisfied:
\begin{enumerate}[label=(\arabic*)]
\item $\deg p_n=n$.
\item $(p_n)$ is orthogonal (resp. orthonormal) in the inner product space $\Cbb[x]$ defined by the Hankel matrix $H$ of $c_n$. Equivalently, $(p_n(T)\Omega)_{n\in\Nbb}$ is an orthonormal (resp. orthogonal) basis of $V$.
\end{enumerate}
Unless otherwise stated, we also assume that
\begin{align}
\text{the leading coefficient of $p_n$ is $>0$}
\end{align}
We say that $p_n$ is \textbf{monic} if the leading coefficient of $p_n$ is $1$.
\end{df}

\begin{rem}
The orthonormal polynomials $(p_n)$ are uniquely determined by $(c_n)$, and can be constructed by the Gram-Schmidt process. Since $c_0=1$, it is clear that
\begin{align*}
p_0=1
\end{align*}
Moreover, since each $c_n$ is real, the Gram-Schmidt process indicates that all the coefficients of $p_n$ are real numbers.

Similarly, the monic orthogonal polynomials $(\wtd p_n)$ are uniquely determined by $(c_n)$.   \hfill\qed
\end{rem}


\begin{rem}
Moreover, if $\rho\in\Rr(I)$ solves the polynomial moment Problem \ref{lb162} for $(c_n)$, then by \eqref{eq101}, condition (2) of Def. \ref{lb190} is equivalent to
\begin{align}
\int_I \ovl{p_m}p_n d\rho=\delta_{m,n}\qquad\text{for each }m,n\in\Nbb
\end{align}
(But note that $\ovl{p_m}=p_m$.) In that case, we also say that $(\rho_n)$ are \textbf{orthonormal polynomials} with respect to $\rho$.
\end{rem}



\begin{thm}\label{lb196}
Let $\wtd p_{n+1}(z)=\det(z-T_n)$ and $\wtd p_0(z)=1$. Then $(\wtd p_n(x))_{n\in\Nbb}$ are the (unique) monic orthogonal polynomials with respect to $(c_n)$.
\end{thm}

\begin{proof}
We want to show that $\wtd p_{n+1}$ is orthogonal to $V_n$, equivalently, that $\wtd p_{n+1}(T)\Omega\perp V_n$.

Applying the Cayley-Hamilton theorem to $T_n$, we have $\wtd p_{n+1}(T_n)=0$, equivalently, $\wtd p_{n+1}(E_nTE_n)=0$. Therefore, if $\wtd p_{n+1}(x)=\sum_{k=0}^{n+1} \gamma_kx^k$ where $\gamma_i\in\Rbb$, then
\begin{align*}
\sum_{k=0}^{n+1} \gamma_k (E_nTE_n)^k\Omega=0
\end{align*}
Together with \eqref{eq102}, this implies
\begin{align*}
\sum_{k=0}^{n+1} \gamma_k E_nT^k\Omega=0
\end{align*}
and hence $E_n\wtd p_{n+1}(T)\Omega=0$. This proves $\wtd p_{n+1}(T)\Omega\perp V_n$.
\end{proof}


\begin{co}
We have
\begin{align}\label{eq103}
\det(z-T_n)=
\begin{vmatrix}
c_0&c_1&\cdots&c_{n+1}\\
c_1&c_2&\cdots&c_{n+2}\\
\vdots&\vdots&\ddots&\vdots\\
c_n&c_{n+1}&\cdots&c_{2n+1}\\
1&z&\cdots& z^{n+1}
\end{vmatrix}
\end{align}
\end{co}

\begin{proof}
Denote the RHS by $\wtd p_{n+1}(z)$. Then $\wtd p_{n+1}(z)$ is a monic polynomial of degree $n+1$. Moreover, if we let $D_{i,j}$ be the $(i,j)$-th minor of the determinant on the RHS of \eqref{eq103}, then for each $0\leq k\leq n$, we have
\begin{align*}
\bk{x^k|\wtd p_{n+1}(x)}=\sum_{i=0}^{n+1}c_{k+i}D_{n+2,i+1}=\begin{vmatrix}
c_0&c_1&\cdots&c_{n+1}\\
c_1&c_2&\cdots&c_{n+2}\\
\vdots&\vdots&\ddots&\vdots\\
c_n&c_{n+1}&\cdots&c_{2n+1}\\
c_k&c_{1+k}&\cdots& c_{n+k}
\end{vmatrix}=0
\end{align*}
This proves that $\wtd p_{n+1}\perp V_n$.
\end{proof}


\subsubsection{The Jacobi matrix}






We now study the numerator $\wtd q_n(z)$ in \eqref{eq104}. As discussed in Subsec. \ref{lb191}, $\wtd q_n(z)$ is a minor of $z-T_n$ of order $n$ under the orthonormal basis $p_0,\dots,p_n$ of $V_n$. To compute this minor, let us find the matrix representation of $T$ under this basis.


\begin{df}\label{lb193}
Let $(a_n)_{n\in\Nbb}$ and $(b_n)_{n\in\Nbb}$ be sequences in $\Rbb$ with $a_n>0$ for each $n$. Define $J,J^+\in\Rbb^{\Nbb\times\Nbb}$ by
\begin{align*}
J=\begin{pmatrix}
b_0&a_0&0&0&0&\cdots\\
a_0&b_1&a_1&0&0&\cdots\\
0&a_1&b_2&a_2&0&\cdots\\
0&0&a_2&b_3&a_3&\cdots\\
0&0&0&a_3&b_4&\ddots\\
\vdots&\vdots&\vdots&\vdots&\ddots&\ddots
\end{pmatrix}
\qquad
J^+=\begin{pmatrix}
b_1&a_1&0&0&0&\cdots\\
a_1&b_2&a_3&0&0&\cdots\\
0&a_2&b_3&a_3&0&\cdots\\
0&0&a_3&b_4&a_4&\cdots\\
0&0&0&a_4&b_5&\ddots\\
\vdots&\vdots&\vdots&\vdots&\ddots&\ddots
\end{pmatrix}
\end{align*}
The matrix $J$ is called the \textbf{Jacobi matrix} \index{00@Jacobi matrix $J$} for $(a_n)$ and $(b_n)$. We also call $(a_n)$ and $(b_n)$, the \textbf{off-diagonal sequence} and the \textbf{diagonal sequence} of $J$, respectively. 
\end{df}

By this definition, $J^+$ is the Jacobi matrix for
\begin{gather}
(a_n)^+=(a_1,a_2,\dots)\qquad (b_n)^+=(b_1,b_2,\dots)
\end{gather}


\begin{thm}\label{lb192}
There is a bijection between:
\begin{itemize}
\item[(1)] A sequence $(c_n)_{n\in\Nbb}$ in $\Rbb$ where $c_n=1$, and the associated Hankel matrix $H$ is positive-definite.\footnote{In other words, $(c_n)$ satisfies the assumptions in Subsec. \ref{lb194} for the case $I=\Rbb$.}
\item[(2)] A pair of sequences $(a_n)_{n\in\Nbb},(b_n)_{n\in\Nbb}$ in $\Rbb$ where $a_n>0$ for each $n$.
\end{itemize}
The bijection is described as follows. 
\begin{itemize}
\item Given $(c_n)$ satisfying (1), let $(p_n)_{n\in\Nbb}$ be the orthonormal polynomials with respect to $(c_n)$. Then the Jacobi matrix $J$ for $(a_n)$ and $(b_n)$ is the matrix representation of $T:V\rightarrow V$ under $(p_n)$. 
\item Given $(a_n)$ and $(b_n)$ satisfying (2), then $c_n$ is the $(0,0)$-entry (i.e., the top-left entry) of $J^n$.
\end{itemize}
\end{thm}


The Jacobi matrix $J$ for $(a_n),(b_n)$ is called the \textbf{Jacobi matrix associated to the Hankel matrix of \pmb{$(c_n)$}}. \index{00@Jacobi matrix associated to the Hankel matrix of $(c_n)_{n\in\Nbb}$}


\begin{rem}\label{lb198}
The fact that $J$ is the matrix representation of $T$ under $(p_n)$ can be made explicit as follows: The sequence $(p_n)_{n\in\Nbb}$ satisfies the \textbf{three-term recurrence relation} \index{00@Three-term recurrence relation}
\begin{subequations}\label{eq105}
\begin{align}
xp_n(x)=a_np_{n+1}(x)+b_np_n(x)+a_{n-1}p_{n-1}(x)\qquad\text{for all }n\in\Nbb
\end{align}
where we set $p_{-1}(x)=0$, and let $a_{-1}$ be any number. Rewriting this relation as
\begin{align*}
a_np_{n+1}(x)=(x-b_n)p_n(x)-a_{n-1}p_{n-1}(x)
\end{align*}
and noting that
\begin{align}
p_{-1}(x)=0\qquad p_0(x)=1
\end{align}
\end{subequations}
we see that $(p_n)$ is uniquely determined by $(a_n)$ and $(b_n)$ through \eqref{eq105}.
\end{rem}

\begin{proof}[\textbf{Proof of Thm. \ref{lb192}}]
Step 1. Given $(c_n)$, let $J$ be the matrix representation of $T$ with respect to the orthonormal polynomials $(p_n)$. Since $\deg p_k=k$, we have
\begin{align}
xp_n(x)=a_np_{n+1}(x)+ b_n x^n+? x^{n-1}+\cdots+? x+?
\end{align}
where $a_{n+1}\in\Rbb_{>0}$ and $b_n\in\Rbb$. Therefore, $J$ is of the form
\begin{align*}
J=\begin{pmatrix}
b_0&?&?&?&?&\cdots\\
a_0&b_1&?&?&?&\cdots\\
0&a_1&b_2&?&?&\cdots\\
0&0&a_2&b_3&?&\cdots\\
0&0&0&a_3&b_4&\ddots\\
\vdots&\vdots&\vdots&\vdots&\ddots&\ddots
\end{pmatrix}
\end{align*}
Since $\omega_T$ is Hermitian, $J$ must be of the form given in Def. \ref{lb193}. This establishes the map
\begin{align}\label{eq106}
(c_n)\mapsto (a_n),(b_n)
\end{align}
equivalently, the map $H\mapsto J$. Moreover, we compute
\begin{align*}
c_n=\bk{1|x^n}=\bk{\Omega|T^n\Omega}=\bk{e_0|J^n e_0}
\end{align*}
This shows that $c_n$ is the $(0,0)$-entry of $J^n$. Consequently, the map \eqref{eq106} is injective.\\[-1ex]

Step 2. It remains to prove that the map \eqref{eq106} is surjective. Let $J$ be the Jacobi matrix of $(a_n)$ and $(b_n)$ satisfying (2). Let $C_c(\Nbb)$ be the set of functions $\Nbb\rightarrow\Cbb$ with finite supports. The inner product on $C_c(\Nbb)$ is chosen to be the one inherited from that of $l^2(\Nbb)$. Then $J$ can be viewed as a linear operator on $C_c(\Nbb)$. Moreover, it is clear that
\begin{align*}
J^n\chi_{\{0\}}=a_0\cdots a_{n-1} \chi_{\{n\}}+?\chi_{\{n-1\}}+\cdots+?\chi_{\{0\}}
\end{align*}
where $a_0\cdots a_{n-1}$ is understood as $1$ if $n=0$. Therefore, $(J^n\chi_{\{0\}})_{n\in\Nbb}$ is a basis of $C_c(\Nbb)$, and there exists $p_n\in\Rbb[x]$ satisfying
\begin{subequations}\label{eq108}
\begin{gather}
p_n(x)=(a_0\cdots a_{n-1})^{-1}x^n+?x^{n-1}+\cdots+?x+?\label{eq108a}\\
\chi_{\{n\}}=p_n(J)\chi_{\{0\}}\label{eq108b}
\end{gather}
\end{subequations}


We define
\begin{align}\label{eq110}
c_n=\bk{\chi_{\{0\}}|J^n\chi_{\{0\}}}
\end{align}
Then the sesquilinear form $\bk{\cdot|\cdot}$ on $V=\Cbb[x]$ determined by $(c_n)$ satisfies
\begin{align}\label{eq107}
\bk{g|h}=\bk{1|\ovl gh}\xlongequal{\eqref{eq110}}\bk{\chi_{\{0\}}|\ovl g(J)h(J)\chi_{\{0\}}}=\bk{g(J)\chi_{\{0\}}|h(J)\chi_{\{0\}}}
\end{align}
for each $g,h\in\Cbb[x]$. (Note that in the last equality of \eqref{eq107}, we have used the fact that $\bk{\eta|J\xi}=\bk{J\eta|\xi}$ for each $\xi,\eta\in C_c(\Nbb)$.) Therefore, $\bk{g|g}\geq0$. If $g\neq0$, by the fact that $(J^n\chi_{\{0\}})_{n\in\Nbb}$ is a basis, we have $g(J)\chi_{\{0\}}\neq0$, and hence
\begin{align*}
\bk{g|g}=\bk{g(J)\chi_{\{0\}}|g(J)\chi_{\{0\}}}>0
\end{align*}
Therefore, $\bk{\cdot|\cdot}$ is positive-definite. Thus, $(c_n)$ satisfies (1).

Let us show that the map \eqref{eq106} sends $(c_n)$ to $(a_n),(b_n)$. By \eqref{eq107}, we have a unitary map
\begin{gather}\label{eq109}
\Phi:V=\Cbb[x]\rightarrow C_c(\Nbb)\qquad g=g(T)\Omega\mapsto g(J)\chi_{\{0\}} 
\end{gather}
By \eqref{eq108b}, $\Phi$ sends $\chi_{\{n\}}$ to $p_n$. Therefore, since $(\chi_{\{n\}})$ is an orthonormal basis of $C_c(\Nbb)$, the sequence $(p_n)_{n\in\Nbb}$ is an orthonormal basis of $V$. This, together with \eqref{eq108a}, shows that $(p_n)$ is the orthogonal polynomials with respect to $(c_n)$. 

From \eqref{eq108}, we have $J\Phi=\Phi T$. Therefore, $J$ is the matrix representation of $T$ under $(p_n)$. This finishes the proof that \eqref{eq106} sends $(c_n)$ to $(a_n),(b_n)$.
\end{proof}



\begin{co}\label{lb197}
Let $(p_n)_{n\in\Nbb}$ be the orthonormal polynomials with respect to $(c_n)$, and let $(a_n)$ be the off-diagonal sequence of the Jacobi matrix associated to $(c_n)$. Then the leading coefficient of $p_n$ is $(a_0\cdots a_{n-1})^{-1}$, understood to be $1$ if $n=0$.
\end{co}

\begin{proof}
This is clear from the proof of Thm. \ref{lb192}, especially from \eqref{eq108}.
\end{proof}



\begin{co}\label{lb199}
Let $(a_n)$ and $(b_n)$ be sequences in $\Rbb$ with $a_n>0$. Let $J$ be the associated Jacobi matrix. Let $(p_n)_{n\in\Nbb}$ be the sequence of polynomials satisfying \eqref{eq105}. Then $(p_n)$ can be described by
\begin{align}
a_0\cdots a_n\cdot p_{n+1}(z)=\det(z-J_{n+1})\qquad p_0(z)=1
\end{align}
where $J_{n+1}\in\Rbb^{(n+1)\times(n+1)}$ is the matrix formed by taking the first $n+1$ rows and columns of $J$.
\end{co}


\begin{proof}
By Thm. \ref{lb192}, $J$ is the Jacobi matrix associated to the positive-definite Hankel matrix of a sequence $(c_n)$ satisfying $c_0=1$, and $(p_n)$ are the orthonormal polynomial with respect to $(c_n)$. Therefore, $J_{n+1}$ is the matrix representation of $T_n$ with respect to the orthonormal basis $p_0,\dots,p_n$ of $V_n$. It follows from Thm. \ref{lb196} that the monic orthonormal polynomials $(\wtd p_n)$ satisfy $\wtd p_{n+1}(z)=\det(z-J_{n+1})$. By Cor. \ref{lb197}, we have $\wtd p_n=a_0\cdots a_n p_{n+1}(z)$. This finishes the proof.
\end{proof}




\subsubsection{The main theorem}

Recall the sequence of rational functions $(f_n(z))_{n\in\Nbb}$ as in Subsec. \ref{lb194}.


\begin{thm}\label{lb200}
Let $J$ be the Jacobi matrix associated to the Hankel matrix of $(c_n)$, and let $(b_n)$ and $(a_n)$ be the diagonal and off-diagonal sequences of $J$, respectively. Choose sequences of polynomials $(p_n(x))_{n\in\Nbb}$ and $(q_n(x))_{n\in\Nbb}$ determined by
\begin{gather}
xp_n(x)=a_np_{n+1}(x)+b_np_n(x)+a_{n-1}p_{n-1}(x)\qquad p_{-1}(x)=0\quad p_0(x)=1\label{eq111}\\
xq_n(x)=a_{n+1}q_{n+1}(x)+b_{n+1}q_n(x)+a_nq_{n-1}(x)\qquad q_{-1}(x)=0\quad q_0(x)=\frac{1}{a_0}\label{eq112}
\end{gather}
for each $n\in\Nbb$. Then
\begin{align}\label{eq113}
f_n(z)=\frac{q_n(z)}{p_{n+1}(z)}
\end{align}
\end{thm}


\begin{proof}
Let $J_{n+1}$ (resp. $J^+_n$) be the $(n+1)\times (n+1)$ (resp. $n\times n$)  matrix formed by taking the first $n+1$ (resp. first $n$) rows and columns of $J$ (resp. $J^+$). By the description of $J$ in Thm. \ref{lb192}, $J_n$ is the matrix representation of $T_n$ with respect to the orthonormal basis $p_0,\dots,p_n$. Therefore, since $p_0=1=\Omega$, by Prop. \ref{lb195} and Cramer's rule (or the inverse matrix formula), we have
\begin{align}
f_n(z)=\frac{\det(z-J^+_n)}{\det(z-J_{n+1})}
\end{align}
Applying Cor. \ref{lb199} to the Jacobi matrix $J$ (resp. $J^+$) and the sequence $(p_n)$ (resp. $(a_0q_n)$), we see that $\det(z-J_{n+1})=a_0\cdots a_np_{n+1}$ (resp. $\det(z-J^+_n)=a_1\cdots a_n\cdot a_0 q_n(z)$). This establishes \eqref{eq113}.
\end{proof}





\subsection{Pad\'e approximation via continued fractions}



We continued to work in the setting of Subsec. \ref{lb194} and freely use the notations recalled there. In particular, we consider the sequence of rational functions $(f_n(z))_{n\in\Nbb}$ described by $f_n(z)=\bk{\Omega|(z-T_n)^{-1}\Omega}$ (cf. Prop. \ref{lb195}), which admits a subsequence that Pad\'e-approximates a holomorphic function $f$ representing the (possibly) divergent series $\sum_{n\in\Nbb}c_nz^{-n-1}$. 

In this section, we use Thm. \ref{lb200} to express $(f_n)$ as finite approximations of a continued fraction. In \cite{Sti94}, Stieltjes's reasoning proceeds in the opposite direction: he begins with a continued fraction, derives the three-term recurrence relation satisfied by its finite approximants, and then uses orthogonality to obtain the Pad\'e approximation.

\begin{thm}
Let $J$ be the Jacobi matrix associated to the Hankel matrix of $(c_n)$, and let $(b_n)$ and $(a_n)$ be the diagonal and off-diagonal sequences of $J$, respectively. Then $f_n(z)$ is the $n$-th approximation of the continued fraction
\begin{align*}
\cfrac{1}{z-b_0-\cfrac{a_0^2}{z-b_1-\cfrac{a_1^2}{z-b_2-\cfrac{a_2^2}{z-b_3-\ddots}  } } }
\end{align*}
That is, for each $n\in\Nbb$, we have
\begin{align}\label{eq115}
f_n(z)=\cfrac{1}{z-b_0-\cfrac{a_0^2}{\ddots-\cfrac{a_{n-2}^2}{z-b_{n-1}-\cfrac{a_{n-1}^2}{z-b_n} } } }
\end{align}
\end{thm}

\begin{proof}
By Thm. \ref{lb200}, we have $f_n=q_n/p_{n+1}$ where $(p_n)$ and $(q_n)$ satisfy
\begin{subequations}\label{eq116}
\begin{gather}
a_np_{n+1}(z)=(z-b_n)p_n(z)-a_{n-1}p_{n-1}(z)\qquad p_{-1}(z)=0\quad p_0(z)=1\label{eq116a}\\
a_nq_n(z)=(z-b_n)q_{n-1}(z)-a_{n-1}q_{n-2}(z)\qquad q_{-1}(z)=0\quad q_0(z)=\frac{1}{a_0}\label{eq116b}
\end{gather}
\end{subequations}
In particular, we have $p_1(z)=(b_0-z)/a_0$, and hence $f_0(z)=1/(z-b_0)$. This proves \eqref{eq115} for $n=0$. Note that \eqref{eq116b} originally holds only when $n\geq0$. However, by setting $a_{-1}=1$ and $q_{-2}(z)=-1$, Eq. \eqref{eq116} also holds when $n=0$. 

We denote the RHS of \eqref{eq115} by $\Upsilon_n$. We view $(p_n),(q_n),(\Upsilon_n)$ as sequences of rational functions of $z,a_0,b_0,a_1,b_1,\dots$. Assume that \eqref{eq115} holds for $n-1$ where $n\in\Zbb_+$, i.e.,
\begin{align*}
\frac{q_{n-1}}{p_n}=\Upsilon_{n-1}
\end{align*}
Note that $\Upsilon_n$ is obtained from $\Upsilon_{n-1}$ by replacing $b_{n-1}$ with $b_{n-1}+\frac{a_{n-1}^2}{z-b_n}$. To prove that \eqref{eq115} holds for $n$, it suffices to show that $a_np_{n+1}/(z-b_n)$ (resp. $a_nq_n/(z-b_n)$) is also obtained from $p_n$ (resp. $q_{n-1}$) by replacing $b_{n-1}$ with $b_{n-1}+\frac{a_{n-1}^2}{z-b_n}$. 

Note that
\begin{align}\label{eq117}
a_{n-1}p_n=(z-b_{n-1})p_{n-1}-a_{n-2}p_{n-2}
\end{align}
and $p_{n-1}$ does not involve $b_{n-1}$. Replacing the $b_{n-1}$ on the RHS of \eqref{eq117} with $b_{n-1}+\frac{a_{n-1}^2}{z-b_n}$, what we want to prove is
\begin{align*}
a_np_{n+1}/(z-b_n)=a_{n-1}^{-1}\Big(z-b_{n-1}-\frac{a_{n-1}^2}{z-b_n}\Big)p_{n-1}-a_{n-1}^{-1}a_{n-2}p_{n-2}
\end{align*}
equivalently,
\begin{align*}
a_{n-1}a_np_{n+1}=\Big((z-b_{n-1})(z-b_n)-a_{n-1}^2\Big)p_{n-1}-a_{n-2}(z-b_n)p_{n-2}
\end{align*}
But this follows from \eqref{eq116a} and \eqref{eq117}, since
\begin{align*}
&a_{n-1}a_np_{n+1}=(z-b_n)\cdot a_{n-1}p_n-a_{n-1}^2p_{n-1}\\
=&(z-b_n)\cdot \big((z-b_{n-1})p_{n-1}-a_{n-2}p_{n-2}\big)-a_{n-1}^2p_{n-1}\\
=&\Big((z-b_{n-1})(z-b_n)-a_{n-1}^2\Big)p_{n-1}-a_{n-2}(z-b_n)p_{n-2}
\end{align*}
This proves the desired property for $a_np_{n+1}/(z-b_n)$. A similar argument proves the desired property for $a_nq_n/(z-b_n)$. 
\end{proof}



\subsection{Application: an alternative proof of the Riesz representation theorem}\label{lb244}


In Sec. \ref{lb202}, we noted that solving a moment problem and characterizing a dual space are often equivalent tasks. For the Hamburger and Stieltjes moment problems, the interval $I$ is non-compact, so there is no suitable norm on $C(I)$ that would allow us to reformulate the moment problem as a dual space problem. In contrast, the Hausdorff moment problem can be translated into such a characterization because $I$ is compact in this case.

Since we have already solved all types of polynomial moment problems in Thm. \ref{lb169}, it is natural to expect that this theorem also yields an alternative proof of the main part of the Riesz representation Thm. \ref{lb9} for a compact interval
$I$, namely, the classification of positive linear functionals on 
$C(I)$. This is exactly what we will do in this section.

For that purpose, Thm. \ref{lb31} must be adapted so that the moment-problem interpretation of the classification of \textit{bounded} linear functionals (discussed in Sec. \ref{lb202} and relying crucially on Thm. \ref{lb31}) admits an analogue for \textit{positive} linear functionals. This analogue is stated as Thm. \ref{lb254}. To prove it we first establish a preliminary result which abstracts the elementary fact that any positive integral operator is bounded whenever the constant function $1$ is integrable.





%we first need to show that positive linear functionals are bounded. This result is essentially an abstraction of the elementary fact that any positive integral operator is bounded whenever the constant function $1$ is integrable. We state this result in a general form:



\begin{pp}\label{lb204}
Let $X$ be a set. Let $\scr A$ be a unital *-$\Fbb$-subalgebra of $l^\infty(X,\Fbb)$.  Let $\Lambda:\scr A\rightarrow\Fbb$ be a linear map which is \textbf{positive} in the sense that $\Lambda(f)\geq0$ for each $f\geq0$. Then $\Lambda$ is bounded with operator norm $\leq \Lambda(1)$. 
\end{pp}


Recall from Exp. \ref{lb254} that the involution $*$ on $l^\infty(X,\Fbb)$ is defined by $f^*=\ovl f$.


\begin{proof}
In the case that $\Fbb=\Rbb$, since $-\Vert f\Vert_{l^\infty}\leq f\leq\Vert f\Vert_{l^\infty}$, we have and since $\Lambda(a)=a\Lambda(1)$ for each scalar $a$, we obtain $-\Vert f\Vert_{l^\infty}\cdot\Lambda(1)\leq \Lambda(f)\leq\Vert f\Vert_{l^\infty}\cdot\Lambda(1)$, and hence $|\Lambda(f)|\leq\Vert f\Vert_{l^\infty}\cdot\Lambda(1)$.

In the case that $\Fbb=\Cbb$, by the positivity of $\Lambda$, the sesequilinear form
\begin{align*}
\scr A\times\scr A\rightarrow\Cbb\qquad (f,g)\mapsto \Lambda(f^*g)
\end{align*}
is positive. Therefore, by Cauchy Schwarz,
\begin{align*}
|\Lambda(f)|^2\leq\Lambda(f^*f)\Lambda(1)\leq\Vert f\Vert_{l^\infty}^2\cdot\Lambda(1)^2
\end{align*}
where the last inequality is due to $f^*f\leq \Vert f\Vert_{l^\infty}^2$. 
\end{proof}


\begin{thm}\label{lb254}
Let $X$ be a set. Let $\scr A$ be a unital *-$\Fbb$-subalgebra of $l^\infty(X,\Fbb)$ with $l^\infty$-closure $\ovl{\scr A}$. Suppose that for each $f\in\ovl{\scr A}$ satisfying $f\geq0$, there exists $g\in\ovl{\scr A}$ such that $f=\ovl gg$ (i.e. $f=g^*g$). Then we have an $\ovl\Rbb_{\geq0}$-linear isomorphism
\begin{gather}\label{eq142}
\begin{gathered}
\{\text{positive linear functionals on $\ovl{\scr A}$}\}\xlongrightarrow{\simeq}\{\text{positive linear functionals on $\scr A$}\}\\
\Lambda\mapsto\Lambda|_{\scr A}
\end{gathered}
\end{gather}
\end{thm}

Note that $\ovl{\scr A}$ is also a unital *-$\Fbb$-subalgebra of $l^\infty(X,\Fbb)$.

\begin{proof}
By Prop. \ref{lb204}, positive linear functionals on $\ovl{\scr A}$ are bounded. Therefore, by Thm. \ref{lb31}, they are determined by their restrictions to $\scr A$. Hence the map \eqref{eq142} is injective.

To prove that \eqref{eq142} is surjective, we pick any positive linear functional $\Lambda:\scr A\rightarrow\Fbb$, which is bounded (by Prop. \ref{lb204}) and hence can be extended to a bounded linear functional $\Lambda:\ovl{\scr A}\rightarrow\Fbb$ (by Thm. \ref{lb31}). Suppose that $f\in\ovl{\scr A}$ satisfies $f\geq0$. By assumption, $f=\ovl gg$ for some $g\ovl{\scr A}$. Therefore, there is a sequence $(g_n)$ in $\scr A$ converging uniformly to $g$. So $(\ovl{g_n}g_n)$ converges uniformly to $f$. Since $\Lambda$ is continuous, and since $\Lambda(\ovl{g_n}g_n)\geq0$, we conclude that $\Lambda(f)\geq0$. This proves that $\Lambda:\ovl{\scr A}\rightarrow\Fbb$ is a positive linear functional.
\end{proof}




\begin{thm}[\textbf{Riesz representation theorem}]\label{lb206}
Let $I$ be a compact interval. Then positive linear functionals on $C(I)$ are precisely linear functionals of the form
\begin{align*}
C(I)\rightarrow\Cbb\qquad f\mapsto \int_Ifd\rho
\end{align*}
where $\rho:I\rightarrow\Rbb_{\geq0}$ is increasing.
\end{thm}

Recall from Thm. \ref{lb72} that replacing $\rho$ with its right-continuous normalization does not change the values of the Stieltjes integrals. Therefore, in the above theorem, one may assume that $\rho$ is right-continuous.

\begin{proof}
Clearly, any increasing function $\rho:I\rightarrow\Rbb_{\geq0}$ defines a positive linear functional. Conversely, let $\Lambda:C(I)\rightarrow\Cbb$ be a positive linear functional. We assume WLOG that $I=[0,1]$. Define a sequence $(c_n)_{n\in\Nbb}$ in $\Rbb$ by
\begin{align*}
c_n=\Lambda(x^n)
\end{align*}
Then, in view of Def. \ref{lb203}, the Hankel matrix $H$ of $(c_n)$ determines the sesquilinear form $\bk{\cdot|\cdot}$ on $\Cbb[x]$ satisfying $\bk{1|f}=\Lambda(f)$ for all $f\in\Cbb[x]$, and hence
\begin{align*}
\bk{f|g}=\bk{1|f^*g}=\Lambda(f^*g)
\end{align*}
for all $f,g\in\Cbb[x]$. Therefore, the positivity of $\Lambda$ implies that $\bk{\cdot|\cdot}$ is positive. Moreover, for each $f\in\Cbb[x]$ we have
\begin{align*}
\bk{xf|f}=\Lambda(xf^*f)\geq0\qquad \bk{(1-x)f|f}=\Lambda((1-x)f^*f)\geq0
\end{align*}
because $xf^*f$ and $(1-x)f^*f$ belong to $C([0,1],\Rbb_{\geq0})$. Therefore, $(c_n)$ satisfies the assumption of the Hausdorff moment problem. Hence, by Thm. \ref{lb169}, there exists an increasing $\rho:[0,1]\rightarrow\Rbb_{\geq0}$ such that $c_n=\int_Ix^nd\rho$ for all $n$, and hence
\begin{align*}
\Lambda(f)=\int_Ifd\rho
\end{align*}
for all $f\in\Cbb[x]$. In other words, the positive linear operators $\Lambda$ and $\int_Id\rho$ agree on $\Cbb[x]$. By Thm. \ref{lb254}, they agree on the closure of $\Cbb[x]$, which is $C(I)$ by Stone-Weierstrass.
\end{proof}


\begin{rem}
The above proof of the Riesz representation theorem aligns perfectly with Table \ref{tb4}. The reason is that the core of the proof of Thm. \ref{lb206} is the solution of the polynomial moment problem, namely, the proof of Thm. \ref{lb169}. Our proof of Thm. \ref{lb169} in Sec. \ref{lb188} (especially Subsec. \ref{lb205}) is an excellent illustration of Table \ref{tb4}: Principle \ref{lb23} is verified by approximating the linear functional
\begin{gather*}
\Lambda:\Cbb[x]\rightarrow\Cbb\qquad x^m\mapsto c_m
\end{gather*}
with a sequence $(\rho_n)$ of increasing functions (or a subsequence thereof), where each $\rho_n$ (defined in \eqref{eq119}) has finite range. The equivalence between pointwise convergence of functions and convergence of moments---that is, the equivalence of the two shaded areas in Table \ref{tb4}---is captured by Thm. \ref{lb92}, which is invoked in Def. \ref{lb175} in the process of solving the polynomial moment problem.

It is worth noting that our use of $(\rho_n)$ to approximate $\Lambda$ is an instance of approximating the infinite by the finite. This is not only because each $\rho_n$ has finite range, but also because the definition of $\rho_n$ arises from the diagonalization of the finite-rank operator $T_n$ given in \eqref{eq120}.  In other words, approximating $\Lambda$ by $\rho_n$ is, at its core, an approximation of $T$ (described in Thm. \ref{lb167}) by $T_n$.

Riesz, in contrast, proved the Riesz representation theorem using the method of linear extension rather than finite approximation. As we will discuss in Ch. \ref{lb181}, Riesz's treatment of the Riesz representation theorem and the spectral theorem of bounded self-adjoint operators marked a paradigm shift in functional analysis: the transition from finite approximation to linear extension. This paradigm shift will be one of the key themes of this course.    \hqed
\end{rem}



\subsection{Problems}


\begin{prob}\label{lb348}
Let $\SA$ be a unital *-algebra. Let $\Lambda:\SA\rightarrow\Cbb$ be a linear map satisfying $\Lambda(x^*x)\geq0$ for each $x\in\SA$. In other words, the sesquilinear form
\begin{gather}\label{eq182}
\bk{\cdot|\cdot}:\SA\times\SA\rightarrow\Cbb\qquad (x,y)\mapsto \Lambda(x^*y)
\end{gather}
is positive (semidefinite).
\begin{enumerate}
\item Let $V=\SA/\scr N$ where $\scr N=\{g\in\SA:\bk{g|g}=0\}$ (cf. Cor. \ref{lb164}). Recall from Exe. \ref{lb346} that $\bk{\cdot|\cdot}$ descends to an inner product of $V$. Prove that there is a linear map satisfying
\begin{align*}
\pi:\SA\rightarrow\Lin(V)\qquad \pi(f)(g+\scr N)=fg+\scr N
\end{align*}
\item Set $\Omega=1_{\scr A}+\scr N$, which is an element of $V$. Prove that $(\pi,V)$ is a pre-unitary representation of $\SA$ (cf. Def. \ref{lb347}) satisfying 
\begin{gather}
\begin{gathered}
\SA\Omega=V\qquad \Vert\Omega\Vert=\Lambda(1_\SA)\\
\bk{\Omega|\pi(f)\Omega}=\Lambda(f)\quad\text{for each }f\in\SA
\end{gathered}
\end{gather}
\item Suppose that $(\pi',V')$ is a pre-unitary representation of $\SA$ (where $V'$ is an inner product space), and $\Omega'\in V'$ satisfies
\begin{gather}
\begin{gathered}
\SA\Omega'=V'\qquad \Vert\Omega'\Vert=\Lambda(1_\SA)\\
\bk{\Omega'|\pi'(f)\Omega'}=\Lambda(f)\quad\text{for each }f\in\SA
\end{gathered}
\end{gather}
Prove that there exists a unique unitary map $\Phi:V\rightarrow V'$ such that
\begin{gather*}
\Phi\Omega=\Omega'\qquad \Phi\pi(f)=\pi'(f)\Phi\quad\text{for each }f\in\SA
\end{gather*}
\end{enumerate}
\end{prob}

\begin{proof}[Hint]
Compare this problem with the proof of Thm. \ref{lb167}.
\end{proof}



\begin{rem}\label{lb349}
The pre-unitary representation $(\pi,V)$ of $\SA$ constructed in Pb. \ref{lb348} is commonly known as the \textbf{GNS construction} \index{00@GNS construction} (after Gelfand-Naimark-Segal). It may be regarded as an abstraction of the construction of the Hankel matrix $H$ and the associated matrix $H'$ from the moments $(c_n)$ in Sec. \ref{lb188}.

To see how the GNS construction generalizes the classical setting, define $\Lambda:\Cbb[x]\rightarrow\Cbb$ to be the unique linear functional with $\Lambda(x^n)=c_n$ for each $n\in\Nbb$. Then the sesquilinear form \eqref{eq182} is precisely the one whose Gram matrix, with respect to the basis $1,x,x^2,\dots$, is the Hankel matrix $H$ defined in Def. \ref{lb203}. Similarly, the matrix $H'$, also from Def. \ref{lb203}, is the matrix representation of $\pi(x)$ under the same basis.  \hqed
\end{rem}











\newpage

\section{The spectral theorem for bounded self-adjoint operators}\label{lb181}



\subsection{Hilbert's spectral theorem}\label{lb442}


\subsubsection{Introduction}

After Stieltjes' pioneering work on continued fractions \cite{Sti94}, the Stieltjes integral once again came into prominence with Hilbert’s spectral theorem for bounded symmetric bilinear forms \cite{Hil06}. It is fair to say that without Hilbert's discovery of the spectral theorem---and its subsequent refinement by later mathematicians, most notably F. Riesz---the Stieltjes integral might never have become the central and influential concept it is today. The reason modern readers are often unfamiliar with the Stieltjes integral is simply that its theory has been fully absorbed into modern measure theory. One should not forget that Stieltjes integrals are equivalent to integrals over intervals with respect to finite Borel measures.


The formulation of the spectral theorem for bounded self-adjoint operators on Hilbert spaces has undergone significant evolution throughout history. In this chapter, we will encounter four versions: 
\begin{itemize}
\item Hilbert's original version.
\item Riesz's version.
\item The Borel functional calculus version.
\item The multiplication operator version.
\end{itemize}
The relationships among these formulations are not immediate, nor are they obviously equivalent. In fact, to meaningfully compare them, we must take a practical perspective, that is, consider the problems that these versions can solve or help illuminate. Among them, the Borel functional calculus version and the multiplication operator version are the more modern and practically useful formulations. However, to fully appreciate their significance, we must not overlook their historical development, particularly Hilbert's and Riesz's versions, as well as the background of the polynomial moment problem discussed in the previous chapter.




In \cite{Hil06}, Hilbert introduced the Hilbert space $l^2(\Zbb)$ and proved the spectral theorem for bounded Hermitian forms on it \cite[Satz 31]{Hil06}. We first present a formulation of this theorem, slightly adapted to modern terminology, and then provide some comments.


\subsubsection{The spectral theorem of Hilbert}

\begin{thm}[\textbf{Hilbert's spectral theorem}]\label{lb239} \index{00@Hilbert's spectral theorem}
Let $V$ be a separable inner product space, and let $\omega\in\Ses(V)$ be Hermitian. Choose $r\geq0$ such that $\Vert\omega\Vert\leq r$. Then for each $\xi\in V$, there is an increasing function $\rho_\xi:[-r,r]\rightarrow\Rbb_{\geq0}$ such that for $z\in\Cbb$ satisfying $|z|>r$, the resolvent form $(z-\omega)^{-1}\in\Ses(V)$ satisfies
\begin{align}\label{eq132}
(z-\omega)^{-1}(\xi|\xi)=\int_{[-r,r]}\frac{d\rho_\xi(\lambda)}{z-\lambda}
\end{align}
\end{thm}


The resolvent form $(z-\omega)^{-1}$ will be defined in the proof, and is related to the resolvent operator introduced in Cor. \ref{lb233}. The precise relationship will be discussed after the proof.


\begin{proof}
Let $u_1,u_2,\dots$ be an orthonormal basis of $V$. Similar to Def. \ref{lb189}, we let
\begin{align*}
V_n=\Span\{u_1,\dots,u_n\}\qquad V_\infty=\bigcup_{n\in\Zbb_+}=\Span\{u_1,u_2,\dots\}
\end{align*}
We shall first establish \eqref{eq132} for $\xi$ in dense subset of $V$, and then extend it to all $\xi\in V$.\\[-1ex]



Step 1. Similar to \eqref{eq120}, we let $\omega_n\in\Ses(V_n)$ be the restriction of $\omega$ to $V_n\times V_n$. Then $\omega_n$ is Hermitian, and satisfies $\Vert\omega_n\Vert\leq r$. Hence $\omega_n=\omega_{T_n}$ for some self-adjoint $T_n\in\Lin(V_n)$, that is,
\begin{align*}
\omega_n(\xi|\eta)=\bk{\xi|T_n\eta}\qquad\text{for each }\xi,\eta\in V_n
\end{align*}
and $\Vert T_n\Vert\leq r$.

By the spectral theorem for Hermitian operators on finite-dimensional inner product spaces, $T_n$ is diagonal. Therefore, there exist $\lambda_{n,1},\dots,\lambda_{n,n}\in\Rbb$ and an orthonormal basis $e_{n,1},\dots,e_{n,n}$ of $V_n$ such that
\begin{align*}
T_ne_{n,i}=\lambda_{n,i}e_{n,i}\qquad\text{for each }1\leq i\leq n
\end{align*}
Since $\Vert T\Vert\leq r$, we have $|\lambda_{n,i}|=\Vert Te_{n,i}\Vert\leq\Vert T\Vert\leq r$, and hence
\begin{align*}
\lambda_{n,1},\dots,\lambda_{n,n}\in [-r,r]
\end{align*}


Step 2. Let $\Kbb=\Qbb+\im\Qbb$. Let $U$ be a dense $\Kbb$-linear subspace of $V_\infty$ with countable cardinality, e.g.
\begin{align*}
U=\Span_\Kbb\{u_1,u_2,\dots\}
\end{align*}
In this step, we define $(z-\omega)^{-1}$ as a bounded $\Kbb$-sesquilinear form on $U$ admitting an integral representation as in \eqref{eq132}. Roughly speaking, $(z-\omega)^{-1}$ on $U$ will be defined to be the limit of a convergent subsequence of the sesquilinear forms associated to $(z-T_n)^{-1}$. The details are as follows.

For each $\xi\in V_\infty$, we have $V_n\ni\xi$ for sufficiently large $n$. Moreover, for such $n$, we clearly have $(z-T_n)^{-1}\xi=\sum_{i=1}^n(z-\lambda_{n,i})^{-1}e_{n,i}\cdot\bk{e_{n,i}|\xi}$, and hence
\begin{align}\label{eq131}
\bk{\xi|(z-T_n)^{-1}\xi}=\sum_{i=1}^n (z-\lambda_{n,i})^{-1}\bk{\xi|e_{n,i}}\cdot \bk{e_{n,i}|\xi}
\end{align}
Similar to \eqref{eq119}, for each $\xi\in V_\infty$, we let $\rho_{\xi,n}:[-r,r]\rightarrow\Rbb_{\geq0}$ be
\begin{align}
\rho_{\xi,n}(x)=\sum_{
\begin{subarray}{c}
\text{all $i$ satisfying}\\
\lambda_{n,i}\leq x
\end{subarray}
}|\bk{e_{n,i}|\xi}|^2
\qquad\text{for all }V_n\ni\xi
\end{align}
We set $\rho_{\xi,n}=0$ if $V_n\notni\xi$. Then $(\rho_{\xi,n})_{n\in\Zbb_+}$ is a uniformly bounded sequence, since Bessel's inequality implies $0\leq\rho_{\xi,n}(x)\leq\Vert\xi\Vert^2$. It follows from \eqref{eq131} that
\begin{align*}
\bk{\xi|(z-T_n)^{-1}\xi}=\int_{[-r,r]}\frac{d\rho_{\xi,n}(\lambda)}{z-\lambda}\qquad\text{for all }V_n\ni\xi
\end{align*}




By Helly's selection Thm. \ref{lb94} and the diagonal method (Rem. \ref{lb52}), there exist strictly positive integers $n_1<n_2<\dots$ such that \footnote{When Hilbert wrote \cite{Hil06}, the Helly selection theorem had not yet been discovered. His argument proceeded as follows. He first applied the Arzel\`a-Ascoli theorem to obtain a uniformly convergent subsequence of the antiderivatives of $(\rho_{\xi,n})$. The limit of this subsequence is a convex function, and its derivative (which exists outside a countable set) is then taken as the definition of $\rho_\xi$.}
\begin{align*}
\lim_k \rho_{\xi,n_k}\text{ converges pointwise to some function }\rho_\xi\qquad\text{for each }\xi\in U
\end{align*}
with $0\leq\rho_\xi\leq\Vert\xi\Vert^2$. By Thm. \ref{lb92}, for each $\xi\in U$, the sequence $(d\rho_{\xi,n_k})$ converges weak-* to $d\rho_\xi$ as positive linear functionals on $C([-r,r])$. Therefore
\begin{align}\label{eq133}
\lim_k\bk{\xi|(z-T_{n_k})^{-1}\xi}=\int_{[-r,r]}\frac{d\rho_\xi(\lambda)}{z-\lambda}\qquad\text{for all }\xi\in U
\end{align}
By the polarization identity (cf. Rem. \ref{lb237}), $\lim_k\bk{\xi|(z-T_{n_k})^{-1}\eta}$ converges for each $\xi,\eta\in U$. We can thus define a $\Kbb$-sesquilinear form
\begin{align}\label{eq135}
(z-\omega)^{-1}:U\times U\rightarrow\Cbb\qquad (z-\omega)^{-1}(\xi|\eta)=\lim_k\bk{\xi|(z-T_{n_k})^{-1}\eta}
\end{align}
By \eqref{eq133}, the relation \eqref{eq132} is satisfied for all $\xi\in U$. Therefore, for each $\xi\in U$, since $0\leq\rho_\xi\leq\Vert\xi\Vert$, we have
\begin{align}\label{eq136}
\big| (z-\omega)^{-1}(\xi|\xi)\big|\leq \Vert\xi\Vert^2/\inf_{\lambda\in[-r,r]}|z-\lambda|
\end{align}
By the proof of Prop. \ref{lb238}, we conclude that $(z-\omega)^{-1}$ is a bounded $\Kbb$-sesquilinear form.\\[-1ex]


Step 3. From the proof of Thm. \ref{lb31}, we know that $(z-\omega)^{-1}$ can be uniquely extended to a bounded ($\Cbb$-)sesquilinear form on $V$. We know that \eqref{eq132} holds for all $\xi\in U$. Let us establish the integral representation \eqref{eq132} for any $\xi\in V$.

Suppose that $\xi\in V\setminus U$. Let $(\xi_n)$ be a sequence in $U$ converging to $\xi$. From the above proof, we know that $0\leq\rho_{\xi_n}\leq\Vert\xi_n\Vert$. In particular, the sequence $(\rho_{\xi_n})$ is bounded. By the Helly selection theorem,  $(\rho_{\xi_n})$ has a subsequence $(\rho_{\xi_{n_k}})$ converging pointwise to some increasing $\rho:[-r,r]\rightarrow\Rbb_{\geq0}$. By Thm. \ref{lb92}, $(d\rho_{\xi_{n_k}})$ converges to $d\rho_\xi$ when integrated against the function $\lambda\in[-r,r]\mapsto 1/(z-\lambda)$. This establishes \eqref{eq132} for all $\xi\in V$.
\end{proof}




\subsubsection{Q\&A}


We give some comments on Hilbert's spectral theorem (Thm. \ref{lb239}) in the form of Q\&A.


\begin{question}\label{lb242}
Assume that the inner product space $V$ in Thm. \ref{lb239} is a Hilbert space, so that there is a canonical isomorphism $\fk L(V)\simeq\Ses(V)$ (cf. Thm. \ref{lb136}). Write $\omega=\omega_T$ where $T\in\fk L(V)$ is self-adjoint. Is $(z-\omega)^{-1}$ equal to the bounded sesquilinear form associated to the resolvent operator $(z-T)^{-1}$?
\end{question}

\begin{proof}[Answer]
Yes, but this is not immediate. Let us first summarize how $(z-\omega)^{-1}$ is constructed in the proof of Thm. \ref{lb239}, now using the language of bounded operators.

Choose $r\in\Rbb$ such that $r\geq\Vert\omega\vert=\Vert T\Vert$.As in Def. \ref{lb189}, we let $E_n$ be the projection of $V$ onto $V_n=\{u_1,\dots,u_n\}$. Then $E_nTE_n$ is a self-adjoint operator on $V$ with operator norm $\leq r$. For $|z|>r$, the limit
\begin{align}\label{eq137}
\lim_n (z-E_nTE_n)^{-1}
\end{align}
converges in WOT. However, this fact was not known at the time of Hilbert's work \cite{Hil06}. 

As seen in the proof of Thm. \ref{lb239}, Hilbert's idea was instead to show that for each $\xi\in V$, a subsequence of \eqref{eq137} converges when evaluated in $\bk{\xi|-\xi}$. One then selects a subsequence that converges simultaneously on a sufficiently large countable set of vectors, and finally uses the uniform boundedness of the operator norms of $(z-E_nTE_n)^{-1}$to conclude convergence on all pairs of vectors in $V$. (Compare this with Prop. \ref{lb73}.)

In summary, $(z-\omega)^{-1}$ is defined to be the bounded sesquilinear form obtained as the limit along a suitable subsequence:
\begin{align}
(z-\omega)^{-1}(\xi|\eta)=\lim_k \bk{\xi|(z-E_{n_k}TE_{n_k})^{-1}\eta}
\end{align}
where the subsequence is independent of the choice of $z,\xi,\eta$.

Thus, the question reduces to whether $(z-\omega)^{-1}$ coincides with the bounded sesquilinear form associated to $(z-T)^{-1}$. The answer is yes, once one shows that
\begin{align}
\lim_n (z-E_nTE_n)^{-1}=(z-T)^{-1}
\end{align}
in WOT. This will be proved in Rem. \ref{lb305}.
\end{proof}




\begin{question}\label{lb243}
The proofs of Hilbert's spectral theorem (Thm. \ref{lb239}) and of the polynomial moment problems (Thm. \ref{lb169}) share many similarities. For instance, both make use of finite-rank approximations of Hermitian operators of the form $E_nTE_n\rightarrow T$; in both cases, the increasing function $\rho_n$ for $E_nTE_n$ is constructed by diagonalizing $E_nTE_n$; and in both, the increasing function $\rho$ for $T$ is obtained by taking a pointwise convergent subsequence of $(\rho_n)$. 

In view of these similarities, what exactly are the novelties in Hilbert’s proof of his spectral theorem?
\end{question}


\begin{proof}[Answer]
As noted in Subsec. \ref{lb162}, Stieltjes' treatment of the polynomial moment problem did not rely on the diagonalization theory of linear algebra. He obtained Pad\'e approximations not via finite-rank approximations of Hermitian operators, but through continued fractions and detailed analyses of determinants and polynomials. It was Hilbert's work that established the connection between the polynomial moment problem, inner product spaces, and spectral theory, thereby allowing us to approach polynomial moment problems from the perspective of spectral theory, as developed in Ch. \ref{lb114}.

I should also mention that although the resolvent form $(z-\omega)^{-1}$ considered by Hilbert bears a striking resemblance to the Stieltjes transforms arising in the polynomial moment problem with divergent series as background (see Thm. \ref{lb183})---indeed, this similarity justifies \uwave{viewing the resolvent of an operator $T$ as its Stieltjes transform}---the notion of resolvent in functional analysis actually first appeared in Fredholm's study of integral equations \cite{Fre03}. 

In \cite{Fre03}, Fredholm sought to analyze the solutions of integral equations of the form
\begin{align*}
f(x)+\int_0^1K(x,y)f(y)=g(y)
\end{align*}
where $K,g$ are given continuous functions and $f$ is the unkown solution. Fredholm considered the resolvent of the integral operator $S:C([0,1])\rightarrow C([0,1])$ defined by $(Sf)(x)=\int_0^1K(x,y)f(y)$. As in Question \ref{lb242}, this resolvent was not defined directly as the inverse operator of $z-S$, but rather as the limit of $(z-S_n)^{-1}$, where $(S_n)$ is a sequence of finite-rank matrices (with increasing ranks) obtained by partioning the interval $[0,1]$. Moreover, the inverse $(z-S_n)^{-1}$ was expressed in terms of determinants, thanks to Cramer's rule/the inverse matrix formula. Fredholm studied the invertibility of $z-S$ by analyzing the zeros of the holomorphic function $\Delta(z):=\lim_n \det(z-S_n)$.



Thus, another major novelty of Hilbert’s proof of the spectral theorem was the way it connected Fredholm’s notion of the resolvent, developed in the study of integral equations, with the Stieltjes transforms arising from the polynomial moment problem and divergent series.
\end{proof}


\begin{question}\label{lb250}
I noticed that the more modern versions of the spectral theorem we will encounter later (such as Riesz's version, the Borel functional calculus version, and the multiplication operator version) are more powerful and widely applicable than Hilbert's spectral theorem. In fact, Hilbert's version seems more like a special case of these modern results. So what is the significance of studying the proof of Hilbert's spectral theorem?
\end{question}


\begin{proof}[Answer]
The proofs of modern spectral theorems share a common trait: they rely heavily on sophisticated algebraic machinery, often employing the Riesz representation theorem (for spaces of continuous functions) as a ``black box'' at critical junctures. Studying these proofs alone can leave learners puzzled:
\begin{itemize}
\item How did mathematicians first realize that the Riesz representation theorem could be used to prove spectral theorems?
\item Why is it applied in this specific way?
\end{itemize}


While Hilbert's spectral theorem is less general than its modern counterparts, its proof avoids this complex abstraction. Instead, the connection with the Riesz representation theorem occupies most of the argument: As mentioned in Question \ref{lb243}, the proofs of Hilbert's spectral theorem (Thm. \ref{lb239}) and of the Hausdorff moment problem (cf. Thm. \ref{lb169}) run in close parallel. And as discussed in Subsec. \ref{lb202} and Sec. \ref{lb244}, the latter problem is almost equivalent to classifying positive linear functionals on $C(I)$ for a compact interval $I$.




Thus, the real significance of Hilbert's spectral theorem is that it makes transparent why the Riesz representation theorem enters spectral theory in the first place. 
\begin{tcolorbox}
Hilbert's proof of his spectral theorem, the earliest version of the spectral theorem, can be viewed as a linear-algebraic reinterpretation of all the key steps in the proof of the Hausdorff moment problem---and hence as an almost equivalent reformulation of the Riesz representation theorem for $C(I)$.
\end{tcolorbox}
\noindent The additional layers found in modern spectral theorems---those not directly tied to the moment problem/Riesz representation paradigm---were introduced later, as part of the refinement and expansion of the theory.
\end{proof}




\subsection{Towards Riesz's spectral theorem: projections}\label{lb258}


\subsubsection{Hilbert's spectral theorem holds for inner product spaces}


It is often said that one of the main differences between mathematicians and physicists in their approaches to the mathematics of quantum mechanics is that mathematicians stress the completeness of Hilbert spaces, emphasizing that they are more than just inner product spaces, whereas physicists find the notion of completeness largely irrelevant. Mathematicians commonly justify this emphasis by pointing out that the spectral theorem for self-adjoint operators requires completeness. This is certainly true for the spectral theorems developed after Hilbert. However, as we saw in Thm. \ref{lb239}, Hilbert's own spectral theorem already holds for general inner product spaces.---If this observation causes a degree of unease for the reader, then I have achieved my aim.




The fact that Hilbert's spectral theorem holds for all inner product spaces, while later versions hold only for Hilbert spaces, shows that Hilbert's version is less powerful and can therefore be established under weaker assumptions. Even so, completeness still plays a role in Hilbert's theorem---though not the Cauchy completeness of the inner product space. Rather, it is the weak-* completeness of Stieltjes integrals against increasing functions, already noted in Table \ref{tb3}. Since Hilbert's spectral theorem is the ancestor of all later versions, we may conclude that the truly central analytic condition underlying all spectral theorems is not the Cauchy completeness of Hilbert spaces (or, equivalently, the Riesz isomorphism $\mc H\simeq (\mc H^\Co)^*$, cf. Thm. \ref{lb135}), but instead the weak-* completeness of increasing functions/finite Borel measures.





\subsubsection{Why Riesz’s spectral theorem requires Hilbert spaces}\label{lb260}


Riesz's spectral theorem, proved in \cite[Ch. V]{Rie13}, is a significant improvement over Hilbert's. Beginning with this section, we prepare for the introduction of Riesz's version.

An important drawback of Hilbert's spectral theorem is that it is unclear how the increasing function $\rho_\xi$ in Thm. \ref{lb239} relies on $\xi$. The first highlight of Riesz's spectral theorem is that, under the assumption that $\MH$ is a Hilbert space and $T\in\fk L(\MH)$ is self-adjoint with $\Vert T\Vert\leq r$, he realizes $\rho_\xi$ through an increasing net of projections $(E(\lambda))_{\lambda\in[-r,r]}$ associated to $T$ (called the \textbf{spectral projections} of $T$), more precisely:
\begin{align*}
\bk{\xi|E(\lambda)\xi}=\rho_\xi(\lambda)\qquad\text{for all }\lambda\in[-r,r]\text{ and }\xi\in\MH
\end{align*}

As we will learn in this section, for each Hilbert space $\MH$ there is an order-preserving bijection between projection operators and closed linear subspaces of $\MH$, related by $P\mapsto \Rng(P)$. Therefore, Riesz's replacement of scalar-valued increasing functions $\rho_\xi$ with projection-valued increasing functions $E$ brings the geometry of Hilbert spaces into the formulation of the spectral theorem. In fact, when $\dim \MH<+\infty$, the subspace associated to $E(\lambda)$ is spanned by eigenvectors of $T$ with eigenvalues $\leq\lambda$.


Interestingly, even for non-complete inner product spaces, the correspondence $P\mapsto\Rng(P)$ is still injective (cf. the proof of Thm. \ref{lb248}), which is sufficient for the spectral theorem. The essential reason Riesz's spectral theorem applies only to Hilbert spaces and not to general inner product spaces is that he constructs $E(\lambda)$ by first constructing its associated sesquilinear form $\omega_{E(\lambda)}$, as we will see in Sec. \ref{lb245}. However, if an inner product space $V$ is not complete, there are even no natural injective maps from the set of \textbf{projection forms} \index{00@Projective forms} (i.e., bounded Hermitian forms $\omega$ satisfying $\omega\circ\omega=\omega$, cf. Def. \ref{lb144} for the definition of $\omega\circ\omega$) to the set of linear subspaces of $V$. 

To turn a projection form into a projection operator, one needs the isomorphism $\Ses(\MH)\simeq\fk L(\MH)$ in Thm. \ref{lb136}, which holds only for Hilbert spaces $\MH$ due to the Riesz-Fr\'echet Thm. \ref{lb135}. This is one major reason why completeness is essential in Riesz's spectral theorem---though not in the form of Cauchy completeness, but rather through the duality $\MH\simeq(\MH^\Co)^*$. 

In Sec. \ref{lb245}, we will see another fundamental way in which the duality $\MH\simeq(\MH^\Co)^*$ enters Riesz's proof of the spectral theorem, once again through the isomorphism $\Ses(\MH)\simeq\fk L(\MH)$.


\subsubsection{Projections}





\begin{df}
A \textbf{projection operator} (or simply a \textbf{projection}) \index{00@Projection} on an inner product $V$ is an element $P\in\fk L(V)$ such that $\omega_P$ is Hermitian (i.e. $\bk{\xi|P\eta}=\bk{P\xi|\eta}$ for all $\xi,\eta\in V$) and $P^2=\id_V$. It is easy to check that \index{P@$P^\perp=1-P$}
\begin{align*}
P^\perp:=1-P
\end{align*}
is also a projection.
\end{df}

Recall that if $V$ is a Hilbert space, $\omega_P$ being Hermitian is equivalent to $P^*=P$.


\begin{eg}
Let $U$ be a linear subspace of an inner product space $V$, and suppose that $V$ has a projection onto $U$. Then by Cor. \ref{lb171}, the projection operator associated to $U$ is a projection.
\end{eg}


In what follows, we will mainly discuss projections on Hilbert spaces, although many of the results extend naturally to general inner product spaces.



\begin{thm}\label{lb248}
Let $\MH$ be a Hilbert space. We have a bijection
\begin{gather}\label{eq139}
\{\text{projections on $\MH$}\}\xlongrightarrow{\simeq}\{\text{closed linear subspaces of $\MH$}\}\qquad P\mapsto \Rng(P)
\end{gather}
Moreover, $P$ is the projection operator associated to $\Rng(P)$ in the sense of Def. \ref{lb246}. That is, for each $\xi\in\MH$, we have $P\xi\in\Rng(P)$ and $\xi-P\xi\in\Rng(P)^\perp$.
\end{thm}

\begin{proof}
If $P$ is a projection on $\MH$, then clearly $1-P$ is also a projection (i.e. $1-P$ is self-adjoint and $(1-P)^2=1-P$). Moreover, we have
\begin{align}\label{eq138}
\Rng(P)=\Ker(1-P)
\end{align}
Indeed, for each $\xi\in\MH$ we have $(1-P)P\xi=P\xi-P^2\xi=0$ and hence $\Rng(P)\subset\Ker(1-P)$; if $(1-P)\xi=0$, then $\xi=P\xi$, and hence $\Ker(1-P)\subset\Rng(P)$. This proves $\Rng(P)=\Ker(1-P)$. We have thus proved that $\Rng(P)$ is a closed linear subspace of $\MH$, since the kernel of any bounded linear operator is a close linear subspace (Cor. \ref{lb147}).

If $\xi\in\MH$, then clearly $P\xi\in\Rng(P)$. For each $\eta\in\MH$, we have $\bk{P\eta|\xi-P\xi}=\bk{\eta|P\xi-P^2\xi}=0$. Thus $\xi-P\xi\in\Rng(P)^\perp$. This proves that $P$ is the (unique) projection associated to $\Rng(P)$. In particular, $P$ is determined by $\Rng(P)$, and hence the map \eqref{eq139} is injective. The surjectivity follows from Thm. \ref{lb149}.
\end{proof}


Recall Def. \ref{lb247} for the meaning of $A\leq B$ where $A,B$ are bounded self-adjoint operators on a Hilbert space. The following property says that the bijection \eqref{eq139} is an isomorphism of partially ordered sets.


\begin{thm}\label{lb249}
Let $P,Q$ be projections on a Hilbert space $\MH$. The following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item[(1)] $\Rng(P)\subset \Rng(Q)$.
\item[(2)] $QP=P$.
\item[(2')] $PQ=P$. 
\item[(3)] $P\leq Q$, namely, $\bk{\xi|P\xi}\leq \bk{\xi|Q\xi}$ for all $\xi\in\mc H$.
\item[(3')] $\Vert P\xi\Vert\leq\Vert Q\xi\Vert$ for all $\xi\in\MH$.
\end{enumerate}
\end{thm}

\begin{proof}
(1)$\Rightarrow$(2): Assume (1). Choose any $\xi\in\MH$. Since $P\xi\in \Rng(Q)$, and since (by \eqref{eq138} or \eqref{eq140}) $\Rng(Q)=\Ker(Q-1)$, we have $(Q-1)P\xi=0$. This proves (2).

(2)$\Leftrightarrow$(2'): This follows from $(QP)^*=PQ$.

(3)$\Leftrightarrow$(3'): This follows from $\Vert P\xi\Vert^2=\bk{P\xi|P\xi}=\bk{\xi|P^*P\xi}=\bk{\xi|P\xi}$ and, similarly, $\Vert Q\xi\Vert^2=\bk{\xi|Q\xi}$.

(2')$\Rightarrow$(3'): Since $\xi=P\xi+(1-P)\xi$ where $P\xi\perp(1-P)\xi$, by the Pythagorean identity, we have $\Vert P\xi\Vert\leq \Vert\xi\Vert$. Replacing $\xi$ with $Q\xi$, we get $\Vert PQ\xi\Vert\leq\Vert Q\xi\Vert$. Therefore, (3') follows from (2'). 


(3')$\Rightarrow$(1'): Assume (3'). Then $\Vert Q\xi\Vert=0$ implies $\Vert P\xi\Vert=0$, i.e.,  $\Ker(Q)\subset\Ker(P)$. Therefore, $\Ker(P)^\perp\subset\Ker(Q)^\perp$. By \eqref{eq140}, we have $\Ker(P)^\perp=\Rng(P)$ and $\Ker(Q)^\perp=\Rng(Q)$. This proves (1').
\end{proof}

\begin{co}\label{lb322}
Let $P,Q$ be projections on a Hilbert space $\MH$. The following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $\Rng(P)\perp\Rng(Q)$.
\item $QP=0$.
\item $PQ=0$. 
\item $P+Q\leq 1$.
\end{enumerate}
Moreover, if any of these conditions holds, then $P+Q$ is the projection onto the $\Rng(P)+\Rng(Q)$.
\end{co}

If $P$ and $Q$ satisfies one of these conditions, we say that $P$ is \textbf{orthogonal} to $Q$. \index{00@Orthogonal projections}

\begin{proof}
Note that (1) is equivalent to $\Rng(P)\subset\Rng(Q)^\perp$. By \eqref{eq140}, we have $\Rng(Q)^\perp=\Rng(1-Q)$. Thus (1) is equivalent to $\Rng(P)\subset\Rng(1-Q)$, and hence (by Thm. \ref{lb249}) is equivalent to each of the following three conditions: $P(1-Q)=0$,  $(1-Q)P=0$, and $P\leq 1-Q$. This proves the equivalence of the four conditions.

Now, assume that these four conditions hold. Clearly $P+Q$ is a projection operator, and its range lies inside $\Rng(P)+\Rng(Q)$. Conversely, any vector in $\Rng(P)+\Rng(Q)$ can be written as $P\xi+Q\eta$ where $\xi,\eta\in\MH$. Then
\begin{align*}
P\xi+Q\eta=(P+Q)(P\xi+Q\eta)
\end{align*}
This proves that $\Rng(P)+\Rng(Q)$ is the range of $P+Q$.
\end{proof}




\begin{co}\label{lb263}
Let $P,Q$ be projections on a Hilbert space such that $P\leq Q$. Then $Q-P$ is the projection operator associated to $\Rng(Q)\cap\Rng(P)^\perp$, that is,
\begin{align*}
(Q-P)(\MH)=Q(\MH)\cap P(\MH)^\perp
\end{align*}
\end{co}

\begin{proof}
Clearly $E:=Q-P$ is a projection, and $PE=EP=0$. By Cor. \ref{lb322}, we have $Q(\MH)=P(\MH)+E(\MH)$ where $P(\MH)\perp E(\MH)$. From this one easily shows $E(\MH)=Q(\MH)\cap P(\MH)^\perp$.
\end{proof}


The convergence of an increasing net of projections also has a geometric meaning:

\begin{thm}\label{lb264}
Let $(E_\alpha)_{\alpha\in I}$ be a net of projections on $\MH$. Assume that $(E_\alpha)$ is increasing, i.e., $E_\alpha\leq E_\beta$ whenever $\alpha\leq\beta$. Let $E$ be the projection operator such that
\begin{align}
\Rng(E)=\Cl_\MH\Big(\bigcup_{\alpha\in I}\Rng(E_\alpha)\Big)
\end{align}
Then $E_\alpha\leq E$ for each $\alpha$, and $\lim_\alpha E_\alpha$ converges in SOT to $E$.
\end{thm}

Consequently, if an increasing net of projections $(E_\alpha)$ converges in WOT to some $F\in\fk L(\MH)$, then clearly $F=E$. It follows that $F$ is a projection, that $(E_\alpha)$ in SOT to $E$, and that $\Rng(F)=\Cl_\MH\big(\bigcup_{\alpha\in I}\Rng(E_\alpha)\big)$.

\begin{proof}
Since $\Rng(E_\alpha)\subset\Rng(E)$, we have $E_\alpha\leq E$. Let $\xi\in\MH$. By the definition of $E$, for each $\eps>0$ there exists $\alpha\in I$ such that
\begin{align*}
\Vert E\xi-E_\alpha\eta\Vert\leq\eps
\end{align*}
for some $\eta\in\MH$. Since $E\xi-E_\alpha\eta=(E-E_\alpha)\xi+E_\alpha(\xi-\eta)$ with $(E-E_\alpha)\xi$ orthogonal to $E_\alpha(\xi-\eta)$ (cf. Cor. \ref{lb263}), the Pythagorean identity shows that $(E-E_\alpha)\xi\Vert\leq\Vert E\xi-E_\alpha\eta\Vert$ and hence
\begin{align*}
\Vert (E-E_\alpha)\xi\Vert\leq\eps
\end{align*}
Therefore, for each $\beta\geq\alpha$, we have $E-E_\beta\leq E-E_\alpha$ due to Cor. \ref{lb263}, and hence $\Vert (E-E_\beta)\xi\Vert\leq\eps$. This proves $\lim_\alpha E_\alpha\xi=E\xi$.
\end{proof}


\begin{co}\label{lb266}
Let $(E_\alpha)_{\alpha\in I}$ be a decreasing net of projections on $\MH$. Let $E$ be the projection operator onto
\begin{align*}
\Rng(E)=\bigcap_{\alpha\in I}\Rng(E_\alpha)
\end{align*}
Then $E_\alpha\geq E$ for each $\alpha$, and $\lim_\alpha E_\alpha$ converges in SOT to $E$.
\end{co}


\begin{proof}
Apply Thm. \ref{lb264} to the increasing net $(E_\alpha^\perp)$ and use the following Exe. \ref{lb265}.
\end{proof}


\begin{exe}\label{lb265}
Let $(\MK_\alpha)_{\alpha\in\scr A}$ be a family of closed linear subspaces of $\MH$. Prove that
\begin{gather}
\Cl_\MH\Big(\bigcup_\alpha\MK_\alpha\Big)^\perp=\bigcap_\alpha\MK_\alpha^\perp \qquad\Big(\bigcap_\alpha \MK_\alpha\Big)^\perp=\Cl_\MH\Big(\bigcup_\alpha\MK_\alpha^\perp\Big)
\end{gather}
(Hint: use Cor. \ref{lb151}.)
\end{exe}





\subsection{Towards Riesz's spectral theorem: monotone convergence extension}\label{lb257}


\subsubsection{Paradigm shift: from finite approximation to linear extension}\label{lb290}


Another of Riesz's innovations on Hilbert's spectral theorem is his entirely different approach to the polynomial moment problem/the Riesz representation theorem. One year after his proof of the spectral theorem in \cite{Rie13}, Riesz gave a new proof of the Riesz representation theorem in \cite{Rie14}; this proof draws on key steps from his treatment of the spectral theorem in \cite{Rie13} and simplifies the method he originally used in \cite{Rie11}.

We will not discuss \cite{Rie11}, since it offers little insight for this course. Instead we compare the method used in \cite{Rie13,Rie14}---which I call the monotone convergence extension---with the Stieltjes-Hilbert method for treating the moment problem. (Recall again that the Riesz representation theorem for $C(I)$, with $I$ a compact interval, is roughly equivalent to the Hausdorff moment problem, cf. the answer to Question \ref{lb250}.) The transition from the Stieltjes-Hilbert method to Riesz's method marked \uwave{a paradigm shift in the early development of functional analysis: the move from finite approximations to linear extensions}. We explain this in more detail below.



As discussed in Sec. \ref{lb41} and summarized in Table \ref{tb4}, the traditional approach to moment problems and to characterizing dual spaces proceeds in two steps: (1) establish the link between pointwise convergence of functions and convergence of moments; (2) show that any bounded (or positive) linear functional can be approximated in the weak-* topology by elementary functions. The treatment of polynomial moment problems in Ch. \ref{lb114} exemplifies this strategy: the connection in step (1) is captured by Thm. \ref{lb92} together with the Helly selection theorem (Thm. \ref{lb94}), while step (2) is achieved via Pad\'e approximation, implemented as finite-rank approximations of Hermitian operators.\uwave {This approach clearly belongs to the paradigm of finite approximation.}


This finite-approximation paradigm gave way to the linear-extension paradigm, with F. Riesz as its prime mover. The guiding philosophy of this paradigm is:
\begin{tcolorbox}
To characterize a (positive or bounded) linear functional $\Lambda$ on a function space $V$, extend $\Lambda$ to a suitable linear functional on a larger function space $\wtd V$, whose linear functionals are easier to characterize.
\end{tcolorbox}




In this course we will exhibit two main patterns of the linear-extension paradigm:
\begin{itemize}
\item The \textbf{monotone convergence extension}, the main subject of this section (and treated in greater detail in \cite[Ch.  24-25]{Gui-A}), which is closely tied to integration theory.
\item The \textbf{bounded linear extension}, which is intimately connected with convexity in normed spaces and with various forms of the Hahn-Banach theorem.
\end{itemize}
The monotone convergence extension may be regarded as a gift from integration theory to functional analysis. Whereas Lebesgue developed integration by first defining measurable sets, the approach of monotone convergence extension---originally introduced by Young \cite{You10,You13} as an alternative to Lebesgue's approach that appealed to more conservative contemporaries \footnote{See \cite[Sec.~6.6]{Pes}.}---builds the integral by enlarging the class of integrable functions in such a way that the integral satisfies the monotone convergence theorem.


\subsubsection{Monotone convergence extension as a theorem}

Fix $\Kbb\in\{\Rbb_{\geq0},\Rbb,\Cbb\}$. Let $X$ be a topological space. Recall from Sec. \ref{lb251} that\index{Borb@$\Bor(X,\Kbb)$}
\begin{align}
\Borb(X,\Kbb)=\{\text{bounded Borel functions }X\rightarrow\Kbb\}
\end{align}
As usual, $\Borb(X)$ denotes $\Borb(X,\Cbb)$.


\begin{df}\label{lb273}
A positive linear functional $\Lambda:\Borb(X,\Kbb)\rightarrow\Kbb$ is called \textbf{normal} \footnote{This terminology is borrowed from the theory of von Neumann algebras. We avoid using the term ``Borel'', as it is reserved for describing maps between topological spaces: a map is called Borel if the preimage of every Borel set is itself Borel.} \index{00@Nomality of positive linear functionals} if it satisfies the monotone convergence theorem, that is, if $(f_n)$ is an increasing sequence in $\Borb(X,\Rbb_{\geq0})$ converging pointwise to $f\in\Borb(X,\Rbb_{\geq0})$, then
\begin{align*}
\lim_n\Lambda(f_n)=\Lambda(f)
\end{align*}
\end{df}


\begin{pp}\label{lb252}
We have a bijective map
\begin{gather}\label{eq141}
\begin{gathered}
\{\text{finite Borel measures on $X$}\}\xlongrightarrow{\simeq}\{\text{normal positive linear functionals}\}\\
\mu\mapsto\Lambda_\mu
\end{gathered}
\end{gather}
where $\Lambda_\mu(f)=\int_Xfd\mu$ for each $f\in\Borb(X,\Kbb)$. The measure $\mu$ is determined by $\Lambda_\mu$ by the relation $\mu(E)=\Lambda_\mu(\chi_E)$ for each Borel set $E\subset X$.
\end{pp}

\begin{proof}
Given each finite Borel measure $\mu$, $\Lambda_\mu$ satisfies the MCT. Therefore the map \eqref{eq141} is well-defined. Since $\Lambda_\mu$ is determined by its values on $\Borb(X,\Rbb_{\geq0})$, and since each $f\in\Borb(X,\Rbb_{\geq0})$ is the pointwise limit of an increasing sequence of simple functions, $\Lambda_\mu$ must be determined by the values $\Lambda_\mu(\chi_E)=\mu(E)$ for all any Borel set $E\subset X$. Therefore, the map \eqref{eq141} is injective.

To prove that \eqref{eq141} is surjective, we pick an arbitrary normal positive linear functional $\Lambda:X\rightarrow\Kbb$. Then $\Lambda$ being normal implies that $\mu:E\in\fk B_X\mapsto \Lambda(\chi_E)\in\Rbb_{\geq0}$ is a (Borel) measure on $X$. So $\Lambda$ and $\Lambda_\mu$ agree on simple functions. Since both $\Lambda$ and $\Lambda_\mu$ and satisfy MCT, by the argument in the first paragraph, we conclude $\Lambda=\Lambda_\mu$.
\end{proof}


\begin{eg}\label{lb318}
Let $Y$ be a topological space. Let $\Phi:X\rightarrow Y$ be a Borel map. Let $\mu$ be a finite Borel measure on $X$. Then the positive linear functional
\begin{align*}
f\in\Borb(Y)\rightarrow \int_X (f\circ\Phi)d\mu
\end{align*}
is clearly normal. Indeed, by Def. \ref{lb319}, this functional is represented by the pushforward measure $\Phi_*\mu$.
\end{eg}


Prop. \ref{lb252}, which gives us a linear functional interpretation of measure theory, allows us to formulate the Riesz-Markov representation theorem (Thm. \ref{lb7}) for second-countable compact Hausdorff spaces in the form of monotone convergence extension.


\begin{thm}[\textbf{Riesz-Markov representation theorem}]\label{lb253} \index{00@Riesz-Markov representation theorem}
Let $X$ be a second-countable compact Hausdorff space. Then we have an $\Rbb_{\geq0}$-linear isomorphism
\begin{gather}
\begin{gathered}
\begin{array}{c}
\{\text{normal positive linear functionals $\Borb(X,\Fbb)\rightarrow\Fbb$}\}\\
\raisebox{0.3cm}{\rotatebox{-90}{$\xlongrightarrow{\rotatebox{90}{$\simeq$}}$}}\\
\{\text{positive linear functionals $C(X,\Fbb)\rightarrow\Fbb$}\}
\end{array}
\\
\Lambda\mapsto\Lambda|_{C(X,\Fbb)}
\end{gathered}
\end{gather}
\end{thm} 

Note that for second-countable compact Hausdorff spaces, finite Borel measures and finite Radon measures are synonymous (cf. Thm. \ref{lb64}).

\begin{proof}
This follows immediately from Thm. \ref{lb7} and Prop. \ref{lb252}.
\end{proof}


\begin{co}[\textbf{Abstract Hausdorff moment theorem}]\label{lb261}\index{00@Abstract Hausdorff moment theorem}\
Let $X$ be a second-countable compact Hausdorff space. Let $\scr A$ be a unital *-$\Fbb$-subalgebra of $C(X,\Fbb)$ separating points of $X$. Then we have an $\Rbb_{\geq0}$-linear isomorphism
\begin{gather}
\begin{gathered}
\begin{array}{c}
\{\text{normal positive linear functionals $\Borb(X,\Fbb)\rightarrow\Fbb$}\}\\
\raisebox{0.3cm}{\rotatebox{-90}{$\xlongrightarrow{\rotatebox{90}{$\simeq$}}$}}\\
\{\text{positive linear functionals $\scr A\rightarrow\Fbb$}\}
\end{array}
\\
\Lambda\mapsto\Lambda|_{\scr A}
\end{gathered}
\end{gather}
\end{co}

\begin{proof}
By Stone-Weierstrass, the $l^\infty$-closure of $\scr A$ is $C(X,\Fbb)$. Therefore, the corollary follows from Thm. \ref{lb253} and \ref{lb254}.
\end{proof}



\begin{rem}\label{lb275}
Suppose that $X$ is an LCH, not necessarily second-countable. A positive linear functional $\Lambda:\Borb(X,\Fbb)\rightarrow\Fbb$ is called \textbf{Radon} \index{00@Radon positive linear functional} if there exists a finite Radon measure $\mu$ on $X$ such that
\begin{align*}
\Lambda(f)=\int_X fd\mu\qquad\text{for all }f\in\Borb(X,\Fbb)
\end{align*}
In view of Def. \ref{lb97}, $\Lambda$ is Radon iff $\Lambda$ is normal and satisfies the following two extra conditions:
\begin{enumerate}[label=(\alph*)]
\item For each Borel set $E\subset X$ we have
\begin{align*}
\Lambda(\chi_E)=\inf\big\{\Lambda(\chi_U):U\in\MT_X\text{ and }U\supset E  \big\}
\end{align*} 
\item For each open $U\subset X$ we have
\begin{align*}
\Lambda(\chi_U)=\sup\big\{\Lambda(f):f\in C(X,[0,1])  \big\}
\end{align*}
\end{enumerate}
It is clear that Thm. \ref{lb253} and Cor. \ref{lb261} can be generalized to this situation, with normal positive linear functionals replaced by Radon positive linear functionals.
\end{rem}



\subsubsection{Monotone convergence extension as a method}


The connection between Thm. \ref{lb253} and the monotone convergence extension is straightforward: the theorem asserts that every positive linear functional on $C(X,\Fbb)$ extends uniquely to a positive linear functional on $\Borb(X,\Fbb)$ satisfying the monotone convergence theorem. However, the monotone convergence extension is not only the statement of a theorem, but also provides the mechanism for constructing the proof. 

In what follows, we outline how this method of monotone convergence extension is applied to prove Thm. \ref{lb253}. For simplicity, we restrict attention to an $\Rbb_{\geq0}$-linear functional $\Lambda:C(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$, and explain how such a linear functional is extended.

\textbf{The first main step} is to extend $\Lambda$ to an $\Rbb_{\geq0}$-linear functional on \index{LSCb@$\LSCb(X,\Rbb_{\geq0})$}
\begin{align}\label{eq162}
\LSCb(X,\Rbb_{\geq0})=\{\text{bounded lower semicontinuous functions }X\rightarrow\Rbb_{\geq0}\}
\end{align}
by the following procedure of \textbf{monotone convergence extension}:\index{00@Monotone convergence extension}
\begin{enumerate}[label=(\arabic*)]
\item For each $f\in\LSCb(X,\Rbb_{\geq0})$, set
\begin{align*}
\Lambda(f)=\sup\{\Lambda(h):h\leq f,h\in C(X,\Rbb_{\geq0})\}
\end{align*}
\item Prove the following version of the MCT: If $(f_n)$ is a uniformly bounded increasing sequence in $\LSCb(X,\Rbb_{\geq0})$ converging pointwise to $f:X\rightarrow\Rbb_{\geq0}$. Then $\Lambda(f)=\lim_n\Lambda(f_n)$. (Note that $f\in\LSCb(X,\Rbb_{\geq0})$ by Prop. \ref{lb256}.)
\item Show that any $f\in\LSCb(X,\Rbb_{\geq0})$ is the pointwise limit of an increasing sequence of functions in $C(X,\Rbb_{\geq0})$. Together with Step 2, this implies that the extended $\Lambda$ is still $\Rbb_{\geq0}$-linear.
\end{enumerate}


Readers familiar with measure theory will recognize that this is the same method used to define the integral on a measure space: one extends the integral from nonnegative simple functions to nonnegative measurable functions such that the MCT is satisfied. However, in \cite{Rie13,Rie14}, Riesz employed an equivalent but seemingly different procedure:
\begin{enumerate}[label=(\alph*)]
\item Show that any $f\in\LSCb(X,\Rbb_{\geq0})$ is the pointwise limit of an increasing sequence of functions $(f_n)$ in $C(X,\Rbb_{\geq0})$.
\item Define $\Lambda(f)$ to be $\lim_n\Lambda(f_n)$ where $(f_n)$ is any increasing sequence in $C(X,\Rbb_{\geq0})$ converging pointwise to $f\in\LSCb(X,\Rbb_{\geq0})$.
\item Show that $\Lambda(f)$ is well-defined, i.e., independent of the choice of $(f_n)$ approximating $f$. (The linearity of $\Lambda$ is obvious.)
\end{enumerate}
Step (c) plays the role of Step (2) mentioned above, since the arguments required in both cases are essentially the same.



The above approach (adapted to nets so that it applies to general locally compact Hausdorff spaces) is used in \cite[Ch. 25]{Gui-A} to prove the Riesz-Markov representation Thm. \ref{lb7}. To complete the proof, \textbf{the second main step} is of course to extend $\Lambda$ from $\LSCb(X,\Rbb_{\geq0})$ to $\Borb(X,\Fbb)$. In \cite{Gui-A}, this extension is carried out via a more measurable-set--based approach rather than the monotone convergence extension. Nevertheless, it is possible to proceed using monotone convergence extension as follows. 

First, extend $\Lambda$ from $\LSCb(X,\Rbb_{\geq0})$ to
\begin{align*}
\scr C_0=\{f+h:f\in\LSCb(X,\Rbb_{\geq0}),h\geq0,h=0\text{ almost everywhere}\}
\end{align*}
by setting $\Lambda(f+h)=0$ (with ``almost everywhere'' interpreted appropriately \footnote{One defines ``almost everywhere'' by defining a set $E\subset X$ to be null if it is contained in some open set $U\subset X$ with $\Lambda(\chi_U)=0$.}). Then apply steps (a)-(c) above to extend $\Lambda$ from $\scr C_0$ to the class $\scr C_1$ of functions that are pointwise limits of increasing sequences in $\scr C_0$. Finally, using Lem. \ref{lb5} and Eq. \eqref{eq143}, extend $\Lambda$ to $\scr C_2:=\Span_\Fbb(\scr C_1)$. One then verifies that $\scr C_2$ coincides with the space of bounded measurable functions. 


The above approach was in fact used by Riesz and Sz.-Nagy to construct the Lebesgue integral on a compact interval $I\subset\Rbb$, though with nonnegative step functions in place of $\LSCb(X,\Rbb_{\geq0})$. See \cite[Sec. 16-22]{RN} or \cite[Ch. 10]{Apo}. However, to prove the Riesz representation theorem for $C(I,\Fbb)$---that is, to represent a positive linear functional
\begin{align*}
\Lambda:C(I,\Fbb)\rightarrow\Fbb
\end{align*}
by a Stieltjes-integral against an increasing function $\rho:I\rightarrow\Rbb_{\geq0}$---it suffices to extend $\Lambda$ to $\LSCb(I,\Fbb)$ using the monotone convergence extension described in the first main step (namely, (a)-(c), or equivalently, (1)-(3)). By Lem. \ref{lb5} and Eq. \eqref{eq143}, $\Lambda$ is further extended to $\Span_\Fbb\LSCb(I,\Fbb)$, which then allows us to define a desired increasing function $\rho:I=[a,b]\rightarrow\Rbb_{\geq0}$ by
\begin{align*}
\rho(x)=\Lambda(\chi_{[a,x]})
\end{align*}
where $\chi_{I_{\leq x}}$ is an upper semicontinuous function (and hence lies to $\Span_\Fbb\LSCb(I,\Fbb)$). The MCT shows that this function $\rho$ is right-continuous. This is precisely the approach taken by Riesz in \cite{Rie13} to prove the Riesz representation theorem in the form needed for his spectral theorem.


For a more detailed discussion of the monotone convergence extension method, see \cite[Ch. 25]{Gui-A}.






\subsection{Riesz's spectral theorem: two paradigm shifts}\label{lb245}

\subsubsection{Three paradigm shifts, and why Riesz's spectral theorem is related to the first two}


The theme of this course is the three major paradigm shifts in functional analysis:
\begin{subequations}\label{eq147}
\begin{gather}
\text{From finite approximations to linear extensions}\label{eq147a}\\
\text{From (muti)linear forms to linear operators}\label{eq147b}\\
\text{From duality to Cauchy completeness}\label{eq147c}
\end{gather}
\end{subequations}
Riesz's proof of the spectral theorem in \cite{Rie13} was a major milestone for the first two shifts. We have already discussed the first shift in detail in Sec. \ref{lb257}; we now turn to the second.


As discussed before (for instance, in Sec. \ref{lb24} and \ref{lb43}), functional analysis moved its focus from scalar-valued functions (especially linear functionals and bilinear or sesquilinear forms) to vector-valued functions (linear operators acting on a normed or inner-product space $V$). This is the second paradigm shift mentioned above.



We have seen that Hilbert's spectral theorem (Thm. \ref{lb239}) is stated in the language of bilinear/sesquilinear forms. As noted in Sec. \ref{lb258}, one reason Riesz's spectral theorem is framed in the language of linear operators is that projection operators correspond more naturally to linear subspaces of an inner-product space than do projection forms. Another reason---mentioned in Subsec. \ref{lb132}---is that symbolic calculus is easier to manipulate in the operator framework, i.e. one may replace the real or complex variable $x$ in a function $f(x)$ by an operator or a sesquilinear form. We will explore this in more detail in the following sections. For now, we answer some questions that readers might naturally ask.


\begin{question}\label{lb286}
What's the role played by symbolic calculus in Riesz's spectral theorem?
\end{question}

\begin{proof}[Answer]
Let $T\in\fk L(\MH)$ be a bounded self-adjoint operator on a Hilbert space $\MH$. Starting with the polynomial functional calculus, i.e. the linear map
\begin{align*}
\pi_T:\Cbb[x]\rightarrow \fk L(\MH)\qquad x^n\mapsto T^n
\end{align*}
Riesz applied the Riesz representation theorem to extend $\pi_T$ to a homomorphism
\begin{align*}
\pi_T:\Span\LSCb([-r,r])\rightarrow \fk L(\MH)
\end{align*}
where $r\in\Rbb_{\geq0}$ satisfies $r\geq\Vert T\Vert$. This extended linear map is not only linear but also multiplicative (i.e. $\pi_T(fg)=\pi_T(f)\pi_T(g)$) and preserves the involutions (i.e. $\pi_T(\ovl f)=\pi_T(f)^*$). Therefore, since for each $\lambda\in[-a,a]$ we have $\ovl{\chi_{[a,\lambda]}}=\chi_{[a,\lambda]}$ and $\chi_{[a,\lambda]}^2=\chi_{[a,\lambda]}$, the operator
\begin{align*}
E(\lambda):=\pi_T(\chi_{[a,\lambda]})
\end{align*}
is a projection. This yields the construction of the spectral projections mentioned in Subsec. \ref{lb260}. See Rem. \ref{lb287} for further discussion.
\end{proof}


Note that the above answer also explains how the Riesz representation theorem is used in the proof of Riesz's spectral theorem.




\begin{question}
Why does symbolic/functional calculus require the linear-operator perspective rather than the bilinear/sesquilinear form perspective?
\end{question}



\begin{proof}[Answer]
Of course, to perform symbolic/functional calculus one must first define multiplication of operators, sesquilinear forms, or matrices. As noted in Subsec. \ref{lb260}, multiplication of bounded sesquilinear forms or bounded matrices can be defined as in Def. \ref{lb144}; this historical approach was indeed the one originally adopted by mathematicians. 

The principal complexity with the sesquilinear-form and matrix perspectives---which does not arise in finite-dimensional linear algebra---is not their definition but the associativity of multiplication: one must address the Fubini-type issues for infinite sums appearing in \eqref{eq78}, in \eqref{eq144}, and in more complicated expressions. For bounded sesquilinear forms and bounded matrices, defining products in terms of orthonormal bases introduces many inconveniences that are absent in the finite-dimensional setting, whereas the operator framework avoids this subtlety.
\end{proof}


\subsubsection{Riesz's spectral theorem, and why the third paradigm shift is missing}


Fix a Hilbert space $\MH$. 

\begin{df}
Let $I$ be an interval. An \textbf{increasing net of projections} indexed by $I$ is defined to be a function
\begin{align*}
E:I\rightarrow\{\text{projections on }\MH\}
\end{align*}
such that $E(\lambda)\leq E(\mu)$ (cf. Thm. \ref{lb249}) for all $\lambda,\mu\in I$ satisfying $\lambda\leq\mu$. We say that $E$ is \textbf{right-continuous}, if for each $\lambda\in[a,b)$ we have
\begin{align}
\lim_{\lambda\rightarrow\lambda_0} E(\lambda)=E(\lambda_0)
\end{align}
By Cor. \ref{lb266}, the SOT and WOT of the above limit are equivalent; moreover, this limit is equivalent to
\begin{align*}
\Rng(E(\lambda_0))=\bigcap_{\lambda>\lambda_0}\Rng(E(\lambda))
\end{align*}
\end{df}


The following theorem was proved in \cite[Ch. V, Sec. 94]{Rie13}.


\begin{thm}[\textbf{Riesz's spectral theorem}]\label{lb267}
Let $T\in\fk L(\MH)$ be self-adjoint. Let $r\in\Rbb_{\geq0}$ such that $\Vert T\Vert\leq r$. Then there exists a right-continuous increasing net of projections $E:I\rightarrow\fk L(\MH)$ (called the \textbf{spectral projections}) \index{00@Spectral projections} such that for any $f\in C([-r,r])$, the continuous functional calculus $f(T)$ satisfies
\begin{align}\label{eq146}
f(T)=\int_{[-r,r]}f(\lambda)dE(\lambda)
\end{align}
\end{thm}

Right-continuity is not essential; it is imposed to ensure uniqueness of the net $E$ satisfying \eqref{eq146}. We will not need this uniqueness in the course.


Neither the continuous functional calculus nor the integral on the RHS of \eqref{eq146} has been defined yet. We will do this in Sec. \ref{lb278}.

\begin{question}\label{lb271}
What is the essence of Riesz's spectral theorem?
\end{question}


\begin{proof}[Answer]
As noted in the answer to Question \ref{lb250}, the proof of Hilbert's spectral theorem may be regarded as a linear-algebraic proof (see Sec. \ref{lb188}) of the Hausdorff moment problem/Riesz representation theorem, carried out in the paradigm of finite approximation. In contrast,
\begin{tcolorbox}
Riesz's spectral theorem should be viewed as the operator-valued Riesz representation theorem for $C([-r,r])$, with its proof situated in the paradigm of linear extension (cf. the paradigm shift \eqref{eq147a}).
\end{tcolorbox}
Indeed, just as the Riesz representation theorem (Thm. \ref{lb9}) expresses a positive linear functional $\Lambda$ as a Stieltjes integral, Eq. \eqref{eq146} expresses the continuous functional calculus as an operator-valued Stieltjes integral.
\end{proof}


\begin{question}\label{lb270}
Is the Cauchy completeness of $\MH$ used in Riesz's proof of his spectral theorem?
\end{question}



\begin{proof}[Answer]
No. What plays the essential role is the Riesz isomorphism $\MH\simeq(\MH^\Co)^*$ (cf. Thm. \ref{lb135}), or more precisely its consequence $\Ses(\MH)\simeq\fk L(\MH)$ (cf. Thm. \ref{lb136}). This isomorphism makes it possible to pass seamlessly between the paradigms of bilinear/sesquilinear forms and linear operators, thereby taking advantage of the strengths of both: As noted in Subsec. \ref{lb132}, the bilinear/sesquilinear form paradigm is well suited for carrying out the monotone-convergence extension, while the linear operator paradigm provides the natural setting for symbolic calculus.
\end{proof}




\begin{question}
In Subsec. \ref{lb141}, you remarked that the transition from the bilinear/sesquilinear form paradigm to the linear-operator paradigm (cf. \eqref{eq147b}) necessarily increases the role of Cauchy-completeness in functional analysis, thereby leading to the paradigm shift \eqref{eq147c} from duality to Cauchy-completeness. Yet, according to the answers to the previous two questions, Riesz's proof of his spectral theorem exhibits the shift \eqref{eq147b} but not \eqref{eq147c}. Why is that?
\end{question}


\begin{proof}[Answer]
The fact that Riesz's proof of his spectral theorem reflects the shift \eqref{eq147b} but not \eqref{eq147c} shows that he did not fully abandon the bilinear/sesquilinear form paradigm in favor of the linear-operator paradigm. In other words, the paradigm shift \eqref{eq147b} in Riesz's proof of his spectral theorem is not complete.
\end{proof}


\begin{question}
From the perspective of modern functional analysis textbooks, does this incomplete realization of the paradigm shift \eqref{eq147b} imply that Riesz's approach to his spectral theorem is outdated?
\end{question}


\begin{proof}[Answer]
In a sense, yes. However, this incompleteness, in my view, is precisely the merit of Riesz's approach. In his approach, neither of the two paradigms in \eqref{eq147b} is eliminated; instead, he allows them to meet and reinforce one another, rather than reducing one to a black-box result.

By contrast, many modern expositions of the spectral theorem, fully committed to the linear operator paradigm, typically invoke the Riesz representation Thm. \ref{lb9} (or more generally, the Riesz-Markov representation Thm. \ref{lb7}) as an external result, without exposing its intimate connection to the paradigm of bilinear/sesquilinear form---the more natural paradigm for understanding the Riesz representation theorem. Riesz's own proof thus illustrates a broader methodological lesson: a good proof not only reaches the conclusion correctly, but also creates a setting where multiple conceptual frameworks can coexist and interact fruitfully.
\end{proof}


\subsection{Proof of Riesz's spectral Thm. \ref{lb267}}\label{lb278}


In this section, we prove the Riesz spectral theorem (Thm. \ref{lb267}).


\subsubsection{The Stieltjes integral against increasing projections}\label{lb288}


Let $-\infty<a<b<+\infty$.

\begin{df}
Let $E:[a,b]\rightarrow\fk L(\mc H)$ be an increasing net of projections. Let $f\in C([a,b])$. For each tagged partition 
\begin{align*}
(\sigma,\lambda_\blt)=\big(\{a_0=a<a_1<\cdots<a_n=b\},(\lambda_1,\dots,\lambda_n) \big)
\end{align*}
(cf. Def. \ref{lb268}), define the Stieltjes sum
\begin{align*}
S_E(f,\sigma,\lambda_\blt)=\sum_{j=1}^n f(\lambda_j)(E(a_j)-E(a_{j-1}))
\end{align*}
Define the \textbf{operator-valued Stieltjes integrals}
\begin{gather}
\int_{(a,b]} f(\lambda)dE(\lambda)=\lim_{(\sigma,\lambda_\blt)\in\mc Q([a,b])}S_E(f,\sigma,\lambda_\blt)\label{eq148}\\
\int_{[a,b]} f(\lambda)dE(\lambda)=f(a)E(a)+\int_{(a,b]} f(\lambda)dE(\lambda)
\end{gather}
\end{df}

\begin{pp}\label{lb282}
The limit on the RHS of \eqref{eq148} converges in the operator norm. Moreover, for each $\xi\in\MH$, we have
\begin{align}\label{eq159}
\Bigbk{\xi\Big|\int_{[a,b]}f(\lambda)dE(\lambda)\xi}=\int_{[a,b]}f(\lambda)d\bk{\xi|E(\lambda)\xi}
\end{align}
where the RHS is the Stieltjes integral of $f$ against the increasing function $\lambda\mapsto\bk{\xi|E(\lambda)\xi}$ on $[a,b]$.
\end{pp}




\begin{proof}
By Cor. \ref{lb39}, $\Ses(\MH)$ is Cauchy-complete (even if $\MH$ is replaced by a general inner product space). Since we have a canonical isomorphism of normed vector spaces $\Ses(\MH)\simeq\fk L(\MH)$ (cf. Thm. \ref{lb136}), we conclude that $\fk L(\MH)$ is complete. \footnote{Of course, since $\MH$ is complete, one can directly invoke Cor. \ref{lb39} to conclude that $\fk L(\MH)$ is complete. The argument provided here is to justify the answer to Question \ref{lb270}, namely, that the isomorphism $\MH\simeq(\MH^\Co)^*$ rather than the Cauchy completeness of $\MH$ is used to prove the Riesz spectral theorem.} Therefore, by Thm. \ref{lb269}, it suffices to show that $(S_E(f,\sigma,\lambda_\blt))_{(\sigma,\lambda_\blt)\in\mc Q([a,b])}$ is a Cauchy net. Eq. \ref{eq159} will follow from the easy fact that
\begin{align}
\bigbk{\xi\big|S_E(f,\sigma,\lambda_\blt)\xi}=S_{\rho_\xi}(f,\sigma,\lambda_\blt)
\end{align}
where $\rho_\xi(\lambda)=\bk{\xi|E(\lambda)\xi}$.



Since $f$ is uniformly continuous, for each $\eps>0$ there is $\delta>0$ such that $|f(s)-f(t)|\leq\eps$ whenever $|s-t|\leq\delta$. Choose any tagged partition $(\sigma,\lambda_\blt)$ with mesh $\leq\delta$. If a tagged partition $(\sigma',\lambda_\blt')$ is finer than $(\sigma,\lambda_\blt)$, then for each $\xi\in\MH$, applying \eqref{eq149} to the increasing function $\rho_\xi$, we get
\begin{align*}
&\Big|\bigbk{\xi\big|(S_E(f,\sigma',\lambda'_\blt)-S_E(f,\sigma,\lambda_\blt))\xi}\Big|=|S_{\rho_\xi}(f,\sigma',\lambda_\blt')-S_{\rho_\xi}(f,\sigma,\lambda_\blt)|\\
\leq& \eps\cdot(\rho_\xi(b)-\rho_\xi(a))\leq\eps\cdot\rho_\xi(b)=\eps\bk{\xi|E(b)\xi}\leq\eps\Vert\xi\Vert^2
\end{align*}
It follows from Prop. \ref{lb238} that
\begin{align*}
\Vert S_E(f,\sgm,\mu_\blt)-S_E(f,\sigma,\lambda_\blt)\Vert\leq 4\eps
\end{align*}
finishing the proof of the Cauchyness.
\end{proof}



\subsubsection{Radon/normal unitary representations}




\begin{comment}
\begin{df}
Let $\scr A$ and $\scr B$ be *-$\Fbb$-algebras. A linear map $\varphi:\scr A\rightarrow\scr B$ is called a \textbf{*-homomorphism} \index{00@*-homomorphism} if it satisfies
\begin{align*}
\varphi(xy)=\varphi(x)\varphi(y)\qquad\varphi(x^*)=\varphi(x)^*
\end{align*}
for all $x,y\in\scr A$. If $\scr A$ and $\scr B$ are both unital, a *-homomorphism $\varphi:\scr A\rightarrow\scr B$ is called \textbf{unital} \index{00@Unital *-homomorphism} if
\begin{align*}
\varphi(1_{\scr A})=1_{\scr B}
\end{align*}
\end{df}
\end{comment}


As noted in the answer to Question \ref{lb271}, proving Riesz's spectral theorem essentially amounts to establishing an operator-valued analogue of the Riesz representation theorem, and is therefore almost equivalent to proving an operator-valued analogue of the Hausdorff moment problem. We will approach this in a slightly more general framework: namely, we shall prove Thm. \ref{lb274}, an operator-valued version of the abstract Hausdorff moment theorem (Cor.\ \ref{lb261}).

In this subsection, we define an operator-valued version of Radon/normal positive linear functionals. Recall that *-algebras refer to *-$\Cbb$-algebras.


\begin{df}\label{lb347}
Let $\scr A$ be a unital *-algebra. A \textbf{pre-unitary representation} of $\scr A$ \index{00@Pre-unitary representation of a unital *-algebra} denotes a pair $(\pi,V)$ where $V$ is an inner product space, and
\begin{align*}
\pi:\scr A\rightarrow\Lin(V)
\end{align*}
is a linear map satisfying
\begin{align*}
\pi(xy)=\pi(x)\pi(y)\qquad\bk{\eta|\pi(x)\xi}=\bk{\pi(x^*)\eta|\xi}\qquad\pi(1_{\scr A})=\id_V
\end{align*}
for all $x,y\in\scr A$ and $\xi,\eta\in V$. If moreover $V$ is a Hilbert space and $\pi(\SA)\subset\fk L(V)$, we say that $(\pi,V)$ is \textbf{unitary representation} of $\scr A$. \index{00@Unitary representation of a unital *-algebra}
\end{df}

%In other words, a unitary representation denotes a pair $(\pi,V)$ where $V$ is a Hilbert space and $\pi:\scr A\rightarrow\fk L(V)$ is a unital *-homomorphism.


\begin{cv}
When the context is clear, a pre-unitary representation $(\pi,V)$ is abbreviated to $V$, and $\pi(x)\xi$ is abbreviated to $x\xi$.
\end{cv}


\begin{df}
Let $X$ be a set, and let $\scr A$ be a unital *-subalgebra of $l^\infty(X)$. A pre-unitary representation $(\pi,V)$ of $\scr A$ is called \textbf{positive} \index{00@Positive pre-unitary representation} if the linear functional $\bk{\xi|\pi(-)\xi}:\scr A\rightarrow\Cbb$ is positive for each $\xi\in V$; in other words,
\begin{align}
\bk{\xi|\pi(f)\xi}\geq0\qquad\text{for all }\xi\in V\text{ and }f\in\scr A\text{ satisfying }f\geq0
\end{align}
\end{df}

\begin{pp}\label{lb272}
Let $X$ be a set, and let $\scr A$ be a unital *-subalgebra of  $l^\infty(X)$. Suppose that any $f\in\scr A$ with $f\geq0$ can be written as $f=g^*g$ for some $g\in\scr A$. Then any pre-unitary representation $(\pi,V)$ is positive.
\end{pp}

For example, if $X$ is a compact Hausdorff (resp. LCH) sapce, any pre-unitary representation of $C(X)$ (resp. $\Borb(X)$) is positive.

\begin{proof}
For each $f\in\scr A$ with $f\geq0$, write $f=g^*g$. Then
\begin{align*}
\bk{\xi|\pi(f)\xi}=\bk{\xi|\pi(g^*)\pi(g)\xi}=\bk{\pi(g)\xi|\pi(g)\xi}\geq0
\end{align*}
\end{proof}








\begin{comment}
\begin{pp}
Let $X$ be a set. Let $\scr A$ be a unital *-subalgebra of $l^\infty(X)$. Let $(\pi,V)$ be a \uwave{positive} pre-unitary representation of $\scr A$. Then the linear map $\pi:\scr A\rightarrow\fk L(V)$ is bounded with operator norm $1$.
\end{pp}


Consequently, if $X$ is a compact Hausdorff space, any pre-unitary representation of $C(X)$ or $\Borb(X)$ has operator norm $\leq 1$.

\begin{proof}
Since $(\pi,V)$ is positive, for each $\xi\in V$, the linear functional
\begin{align*}
\Lambda_\xi:\scr A\rightarrow\Cbb\qquad f\mapsto\bk{\xi|\pi(f)\xi}
\end{align*}
is positive. Therefore, by Prop. \ref{lb204}, for each $f\in\scr A$ we have $|\Lambda_\xi(f)|\leq\Vert f\Vert_{l^\infty}\cdot\Lambda_\xi(1)$, i.e.,
\begin{align*}
|\bk{\xi|\pi(f)\xi}|\leq \Vert f\Vert_{l^\infty}\cdot\Vert\xi\Vert^2
\end{align*}
Since $\Vert f^*f\Vert_{l^\infty}=\Vert f\Vert_{l^\infty}^2$, we obtain
\begin{align*}
\bk{\pi(f)\xi|\pi(f)\xi}=\bk{\xi|\pi(f^*f)\xi}\leq\Vert f\Vert_{l^\infty}^2\cdot\Vert\xi\Vert^2
\end{align*}
and hence $\Vert\pi(f)\Vert\leq\Vert f\Vert_{l^\infty}$. This shows that $\Vert\pi\Vert\leq 1$. Since $\pi(1)=\id$, we 
\end{proof}
\end{comment}


\begin{df}
Let $X$ be an LCH space. A pre-unitary representation $(\pi,V)$ of $\Borb(X)$ (which is automatically positive) is called a \textbf{Radon pre-unitary representation} \index{00@Radon pre-unitary representation of a unital *-algebra} if for each $\xi\in V$, the linear functional
\begin{align}\label{eq151}
\Borb(X)\rightarrow\Cbb\qquad f\mapsto\bk{\xi|\pi(f)\xi}
\end{align}
is Radon in the sense of Rem. \ref{lb275}. 
\end{df}



\begin{df}\label{lb433}
More generally, consider the case where $X$ is a topological space. A pre-unitary representation $(\pi,V)$ of $\Borb(X)$ is called a \textbf{normal pre-unitary representation} \index{00@Normal pre-unitary representation} if for each $\xi\in V$, the linear functional \eqref{eq151} is normal, that is,
\begin{align*}
\lim_n\bk{\xi|\pi(f_n)\xi}=\bk{\xi|\pi(f)\xi}
\end{align*}
for any increasing sequence $(f_n)$ in $\Borb(X)$ converging pointwise to $f\in\Borb(X)$.

By Prop. \ref{lb252} and Thm. \ref{lb64}, when $X$ is a second-countable compact Hausdorff space, a pre-unitary representation of $\Borb(X)$ is Radon iff it is normal.  \hqed
\end{df}


\begin{rem}\label{lb297}
Let $X$ be a topological space, and let $(\pi,V)$ be a normal pre-unitary representation of $\Borb(X)$. By Prop. \ref{lb252}, the normality of $\pi$ is equivalent to the fact that for each $\xi\in V$, there is a unique finite Borel measure $\pmb{\mu_\xi}$ \index{zz@$\mu_\xi,\mu_{\eta,\xi}$} (called the \textbf{measure associated to $\xi$ (and $\pi$)}) \index{00@Measure $\mu_\xi$ associated to a vector $\xi$} such that
\begin{align*}
\bk{\xi|\pi(f)\xi}=\int_X fd\mu_\xi\qquad\text{for each }f\in\Borb(X)
\end{align*}
For each $\xi,\eta\in V$ we define the complex Borel measure
\begin{align*}
\pmb{\mu_{\eta,\xi}}:=\frac 14\sum_{t=0,\frac \pi 2,\pi,\frac{3\pi}2}~ e^{\im t}\cdot \mu_{e^{\im t}\eta+\xi}
\end{align*}
Then, by the polarization identity, $\mu_{\eta,\xi}$ satisfies
\begin{align*}
\bk{\eta|\pi(f)\xi}=\int_X fd\mu_{\eta,\xi}\qquad\text{for each }f\in\Borb(X)
\end{align*}
We call $\mu_{\eta,\xi}$ the \textbf{complex measure associated to $\eta,\xi$ (and $\pi$)}. \index{00@Complex measure $\mu_{\eta,\xi}$ associated to vectors $\eta,\xi$}
\end{rem}



\subsubsection{Operator-valued abstract Hausdorff moment problem}

In this subsection, unless otherwise stated, $X$ denotes an LCH space. Our goal is to prove Thm. \ref{lb274}. We first need some preparation.







\begin{df}
The \textbf{universal $L^2$-topology} \index{00@Universal $L^2$-topology} on $\Borb(X)$ is defined to be the pullback topology of the map
\begin{align*}
\bigvee_\mu \Psi_\mu:\Borb(X)\rightarrow \prod_\mu L^2(X,\mu)
\end{align*}
where the product ranges over all finite Radon measures $\mu$ on $X$, (equivalently, all finite Borel measures when $X$ is second countable, cf. Thm. \ref{lb64}), and where for each such $\mu$, the map $\Psi_\mu:\Borb(X)\rightarrow L^2(X,\mu)$ sends each $f$ to (the equivalence class of) $f$.

Therefore, the universal $L^2$-topology is the unique topology such that a net $(f_\alpha)$ in $\Borb(X)$ converges to $f\in\Borb(X)$ iff
\begin{align*}
\lim_\alpha \int_X|f-f_\alpha|^2d\mu=0
\end{align*}
for each finite Radon measure $\mu$ on $X$, iff
\begin{align*}
\lim_\alpha\Lambda(|f-f_\alpha|^2)=0
\end{align*}
for each Radon positive linear functional $\Lambda$ on $\Borb(X)$. \hqed
\end{df}

\begin{rem}\label{lb277}
Suppose that $(f_\alpha)$ is a net in $\Borb(X)$ converging universally-$L^2$ to $f\in\Borb(X)$. Then for each finite Radon measure $\mu$ and each $g\in\Borb(X)$, we have $\lim_\alpha\int_X f_\alpha g d\mu=\int_Xf gd\mu$ (since $(f_\alpha)$ converges weakly to $f$ in $L^2(X,\mu)$). In other words,
\begin{align}
\lim_\alpha\Lambda(f_\alpha g)=\Lambda(fg)
\end{align}
for each finite Radon positive linear functional on $\Borb(X)$ and $g\in\Borb(X)$. 
\end{rem}


\begin{comment}
The following property is analogous to Thm. \ref{lb155}.

\begin{lm}
Let $(f_\alpha)_{\alpha\in\scr I}$ and $(g_\beta)_{\beta\in\scr J}$ be nets in $\Borb(X)$ converges in the universal $L^2$-topology to $f,g\in\Borb(X)$ respectively. Assume that $\sup_\alpha\Vert f_\alpha\Vert_{l^\infty}<+\infty$. Then $\lim_{(\alpha,\beta)\in\scr I\times\scr J} f_\alpha g_\beta$ converges in the universal $L^2$-topology to $fg$.
\end{lm}

\begin{proof}
Let $M=\Vert g\Vert_{l^\infty}+\sup_\alpha\Vert f_\alpha\Vert_{l^\infty}$. Then for each Radon measure $\mu$ on $X$, we have
\begin{align*}
&\Vert fg-f_\alpha g_\beta\Vert_{L^2(\mu)}\leq \Vert (f-f_\alpha)g\Vert_{L^2(\mu)}+\Vert f_\alpha(g-g_\beta)\Vert_{L^\infty}\\
&\leq M\Vert f-f_\alpha\Vert_{L^2(\mu)}+M\Vert g-g_\beta\Vert_{L^2(\mu)}
\end{align*}
and hence converges to $0$.
\end{proof}
\end{comment}




\begin{lm}\label{lb276}
Let $\scr A$ be a *-$\Fbb$-subalgebra of $C_0(X,\Fbb)$ separating points of $X$ and vanishing nowhere. Then $\ovl B_{\scr A}(0,1)$ is dense in $\ovl B_{\Borb(X,\Fbb)}(0,1)$ in the universal $L^2$-topology, i.e., 
\begin{align*}
\{f\in\scr A:\Vert f\Vert_{l^\infty}\leq1\}\qquad\text{is dense in}\qquad \{f\in\Borb(X,\Fbb):\Vert f\Vert_{l^\infty}\leq1\}
\end{align*}
\end{lm}
Therefore, for any $f\in\Borb(X,\Fbb)$ there exists a net $(f_\alpha)$ in $\scr A$ with $\sup_\alpha\Vert f_\alpha\Vert_{l^\infty}\leq\Vert f\Vert_{l^\infty}$ satisfying $\lim_\alpha\Vert f-f_\alpha\Vert_{L^2(X,\mu)}=0$ for each finite Radon measure $\mu$ on $X$.


\begin{proof}
By the Stone-Weierstrass Thm. \ref{lb360}, $\scr A$ is $l^\infty$-dense in $C_0(X,\Fbb)$. Therefore, for each $f\in C_0(X,\Fbb)$ with $\Vert f\Vert_{l^\infty}\leq 1$ there is a net $(f_\alpha)$ in $\scr A$ converging uniformly to $f$. In particular, $\Vert f_\alpha\Vert_{l^\infty}$ converges to $\Vert f\Vert_{l^\infty}$. Therefore $f_\alpha\cdot \Vert f\Vert_{l^\infty}/\Vert f_\alpha\Vert_{l^\infty}$ converges uniformly to $f$. This proves that the closed unit ball of $\scr A$ is $l^\infty$-dense (and hence universally $L^2$-dense) in the closed unit ball of $C_0(X,\Fbb)$.

It remains to prove that $\ovl B_{C_0(X,\Fbb)}(0,1)$ is universally $L^2$-dense in $\ovl B_{\Borb(X,\Fbb)}(0,1)$. Choose any $f\in \ovl B_{\Borb(X,\Fbb)}(0,1)$. Let $\scr I$ be the set of finite Radon measures on $X$. By Lusin's Thm. \ref{lb82} (together with the Tietze extension Thm. \ref{lb83}), for each finite subset $E\subset\scr I$ and $\eps>0$ there exists $f_{E,\eps}\in C_c(X,\Fbb)$ such that $\Vert f_{E,\eps}\Vert_{l^\infty}\leq 1$ and
\begin{align*}
\mu\{x\in X:f(x)\neq f_{E,\eps}\}\leq\eps
\end{align*}
for each $\mu\in E$. Therefore
\begin{align*}
\int_X|f-f_{E,\eps}|^2d\mu\leq 4\eps\qquad\text{for each }\mu\in E
\end{align*}
Hence, the net $(f_{E,\eps})_{(E,\eps)\in\fin(2^{\scr I})\times\Rbb_{>0}}$ (where $\Rbb_{>0}$ is given by the order $>$ instead of the usual one $\leq$) is a net in $\ovl B_{C_0(X,\Fbb)}(0,1)$ and converges universally-$L^2$ to $f$.
\end{proof}




\begin{thm}[\textbf{Operator-valued abstract Hausdorff moment theorem}]\index{00@Operator-valued abstract Hausdorff moment theorem}\label{lb274}
Let $X$ be a compact Hausdorff space. Let $\scr A$ be a unital *-subalgebra of $C(X)$ separating points of $X$. Then there is a one-to-one correspondence between the following two classes of objects: \footnote{Since these two classes are proper classes rather than sets, we avoid using the term ``bijection''.}
\begin{itemize}
\item[(1)] Radon unitary representations of $\Borb(X)$;
\item[(2)] positive unitary representations of $\scr A$,
\end{itemize}
such that $(\pi,\MH)$ in the first class corresponds to $(\pi|_{\scr A},\MH)$ in the second class.
\end{thm}


Let us repeat that when $X$ is second countable, a unitary representation of $\Borb(X)$ is Radon iff it is normal.

\begin{proof}
Step 1. An object $(\pi,\MH)$ in the first class clearly restricts to an object $(\pi|_{\scr A},\MH)$ in the second class. Moreover, if $(\pi_1,\MH)$ and $(\pi_2,\MH)$ satisfy $\pi_1|_{\scr A}=\pi_2|_{\scr A}$, then for each $\xi\in \MH$, the Radon positive linear functionals $\scr A\rightarrow\Cbb$ defined by $f\mapsto\bk{\xi|\pi_1(f)\xi}$ and by $f\mapsto\bk{\xi|\pi_2(f)\xi}$ are equal on $\scr A$. Therefore, by Cor. \ref{lb261} (and Rem. \ref{lb275}), these two linear functionals are equal. This proves $\pi_1=\pi_2$.

We have thus proved that the correspondence $(\pi,\MH)\mapsto(\pi|_{\scr A},\MH)$ from the first to the second class is injective. To prove that it is surjective, let us prove that any positive unitary representation $(\pi,\MH)$ of $\scr A$ can be extend to a Radon unitary representation $(\wht\pi,\MH)$ of $\Borb(X)$.\\[-1ex]

Step 2. Fix $(\pi,\MH)$ in the second class. By Cor. \ref{lb261}, for each $\xi\in \MH$, the positive linear functional
\begin{align}\label{eq154}
\Lambda_\xi:\scr A\rightarrow\Cbb\qquad f\mapsto\bk{\xi|\pi(f)\xi}
\end{align}
can be extended uniquely to a normal positive linear functional
\begin{align*}
\Lambda_\xi:\Borb(X)\rightarrow\Cbb
\end{align*}
The extension $(\wht\pi,\MH)$ will be constructed from the map
\begin{gather}\label{eq150}
\begin{gathered}
\Phi:\MH^\Co\times \Borb(X)\times \MH\rightarrow\Cbb\\
\Phi(\ovl\eta,f,\xi)=\frac 14\sum_{t=0,\frac \pi 2,\pi,\frac{3\pi}2}\Lambda_{e^{\im t}\eta+\xi}(f)\cdot e^{\im t}
\end{gathered}
\end{gather}
By the polarization identity, we have
\begin{align}\label{eq152}
\Phi(\ovl\eta,f,\xi)=\bk{\eta|\pi(f)\xi}\qquad\text{if }f\in\scr A
\end{align}

From the definition of $\Phi$, and by Rem. \ref{lb277}, for each fixed $\xi,\eta\in\MH$,
\begin{gather}\label{eq153}
\begin{gathered}
\text{if $(f_\alpha)$ is a net in $\Borb(X)$ converging to $f$}\\
\text{in the universal $L^2$-topology, then }\lim_\alpha\Phi(\ovl\eta,f_\alpha,\xi)=\Phi(\ovl\eta,f,\xi)
\end{gathered}
\end{gather}
Therefore, for each $f\in\Borb(X)$, if we choose a net $(f_\alpha)$ in $\Borb(X)$ converging universally-$L^2$ to $f$ (cf. Lem. \ref{lb276}), then the bilinearity of $(\ovl\eta,\xi)\mapsto\Phi(\ovl\eta,f_\alpha,\xi)$ (due to \eqref{eq152}) implies the bilinearity of $(\ovl\eta,\xi)\mapsto\Phi(\ovl\eta,f,\xi)$. Clearly $\Phi$ is also linear on the second variable. We have thus proved that $\Phi$ is a trilinear map.\\[-1ex]


Step 3. In this step, we construct the map $\wht\pi$. Observe that
\begin{align*}
\Phi(\ovl\xi,f,\xi)\xlongequal{\eqref{eq153}}\lim_\alpha\Phi(\ovl\xi,f_\alpha,\xi)\xlongequal{\eqref{eq152}}\lim_\alpha\bk{\xi|\pi(f_\alpha)\xi}\xlongequal{\eqref{eq154}}\lim_\alpha\Lambda_\xi(f_\alpha)
\end{align*}
By Rem. \ref{lb277}, the last term above equals $\Lambda_\xi(f)$. Therefore
\begin{align}\label{eq155}
\Phi(\ovl\xi,f,\xi)=\Lambda_\xi(f)\qquad\text{for all }f\in\Borb(X)
\end{align}
Since $\Lambda_\xi$ is positive, by Prop. \ref{lb204}, we have
\begin{align*}
|\Phi(\ovl\xi,f,\xi)|=|\Lambda_\xi(f)|\leq\Vert f\Vert_{l^\infty}\cdot\Lambda_\xi(1)=\Vert f\Vert_{l^\infty}\cdot\bk{\xi|\pi(1)\xi}=\Vert f\Vert_{l^\infty}\cdot\Vert\xi\Vert^2
\end{align*}
It follows from Prop. \ref{lb238} that the trilinear map $\Phi(-,f,-):\MH^\Co\times\MH\rightarrow\Cbb$ is bounded. In other words, $\Phi(-,f,-)$ is a bounded sesquilinear form. Due to the isomorphism $\Ses(\MH)\simeq\fk L(\MH)$ (cf. Thm. \ref{lb136}), $\Phi$ gives rise to a linear map
\begin{align}\label{eq156}
\wht\pi:\Borb(X)\rightarrow\fk L(\MH)\qquad \bk{\eta|\wht\pi(f)\xi}=\Phi(\ovl\eta,f,\xi)
\end{align}
By \eqref{eq152}, we have $\wht\pi|_{\scr A}=\pi$.\\[-1ex]

Step 4. It remains to check that $(\wht\pi,\MH)$ is a Radon unitary representation of $\Bor(X)$. By \eqref{eq155} and \eqref{eq156}, we have
\begin{align}\label{eq157}
\bk{\xi|\wht\pi(f)\xi}=\Lambda_\xi(f)\qquad\text{for all }f\in\Borb(X)
\end{align}
The Radon property of $\wht\pi$ follows from \eqref{eq157} and the Radon property of $\Lambda$. To check $\wht\pi(f^*)=\wht\pi(f)^*$ for each $f\in\Borb(X)$, by linearity, it suffices to check that $\wht\pi(f)^*=\wht\pi(f)$ for all $f\in\Borb(X,\Rbb_{\geq0})$. In fact, we have $\wht\pi(f)\geq0$ due to \eqref{eq157} and the positivity of $\Lambda_\xi$. Since $\wht\pi$ extends $\scr A$, we have $\wht\pi(1)=\id_\MH$.

It remains to check that $\wht\pi(fg)=\wht\pi(f)\wht\pi(g)$ for all $f,g\in\Borb(X)$. To do this, note that by \eqref{eq156}, the property \eqref{eq153} can be rephrased as follows:
\begin{gather}\label{eq158}
\begin{gathered}
\text{If $(f_\alpha)$ is a net in $\Borb(X)$ converging to $f$}\\
\text{in the universal $L^2$-topology, then $\lim_\alpha\wht\pi(f_\alpha)=\wht\pi(f)$ in WOT.}
\end{gathered}
\end{gather}
Now, choose nets $(f_\alpha)_{\alpha\in\scr I}$ and $(g_\beta)_{\beta\in\scr J}$ in $\Borb(X)$ converging uniformly-$L^2$ to $f$ and $g$, respectively. Since $\pi$ is multiplicative, we have $\wht\pi(f_\alpha g_\beta)=\wht\pi(f_\alpha)\wht\pi(g_\beta)$. Clearly, for each $h\in\Borb(X)$, the nets $(f_\alpha h)$ and $(g_\beta h)$ converge uniformly-$L^2$ to $fh$ and $gh$, respectively. It follows from \eqref{eq158} and the following Lem. \ref{lb279} that
\begin{align*}
\wht\pi(fg_\beta)=\lim_\alpha \wht\pi(f_\alpha g_\beta)=\lim_\alpha\wht\pi(f_\alpha)\wht\pi(g_\beta)=\wht\pi(f)\wht\pi(g_\beta)
\end{align*}
in WOT, and hence
\begin{align*}
\wht\pi(fg)=\lim_\beta\wht\pi(fg_\beta)=\lim_\beta\wht\pi(f)\wht\pi(g_\beta)=\wht\pi(f)\wht\pi(g)
\end{align*}
This finishes the proof.
\end{proof}


\begin{lm}\label{lb279}
Let $\MH,\MK$ be Hilbert spaces. Suppose that $(T_\alpha)$ is a net in $\fk L(\MH,\MK)$ converging in WOT to $T\in\fk L(\MH,\MK)$. Let $A\in\fk L(\MH)$ and $B\in\fk L(\MK)$. Then $(T_\alpha A)$ converges in WOT to $TA$, and $(BT_\alpha)$ converges in WOT to $BT$.
\end{lm}

\begin{proof}
For each $\xi\in\MH$ and $\eta\in\MK$, we have $\lim_\alpha\bk{\eta|T_\alpha A\xi}=\bk{\eta|TA\xi}$ and
\begin{align*}
\lim_\alpha\bk{\eta|BT_\alpha\xi}=\lim_\alpha\bk{B^*\eta|T_\alpha\xi}=\bk{B^*\eta|T\xi}=\bk{\eta|BT\xi}
\end{align*}
\end{proof}


We end this subsection with an easy observation that, thanks to the multiplicativity of $\wht\pi$, the WOT convergence in \eqref{eq158} can in fact be strengthened to SOT convergence:


\begin{pp}\label{lb293}
Let $(\pi,V)$ be a Radon pre-unitary representation of $\Borb(X)$. Suppose that $(f_\alpha)$ is a net in $\Borb(X)$ converging to $f\in\Borb(X)$ in the universal $L^2$-topology. Then $\lim_\alpha\pi(f_\alpha)$ converges in SOT to $\pi(f)$.
\end{pp}

\begin{proof}
Choose any $\xi\in V$. Since $\Lambda_\xi:g\in\Borb(X)\mapsto\bk{\xi|\pi(g)\xi}$ is a Radon positive linear funtional, we have
\begin{align*}
&\Vert \pi(f)\xi-\pi(f_\alpha)\xi\Vert^2=\bk{\pi(f-f_\alpha)\xi|\pi(f-f_\alpha)\xi}=\bk{\xi|\pi(f-f_\alpha)^*\pi(f-f_\alpha)\xi}\\
=&\bk{\xi|\pi(|f-f_\alpha|^2)\xi}=\Lambda_\xi(|f-f_\alpha|^2)\rightarrow0
\end{align*}
\end{proof}


The proof of Thm. \ref{lb274} also indicates that $\wht\pi:\Borb(X)\rightarrow\fk L(\MH)$ is bounded. Therefore, if $(f_\alpha)$ converges uniformly to $f$, then $\lim_\alpha\pi(f_\alpha)$ converges in the operator norm to $\pi(f)$. We record this fact in a more general form, as the operator-valued analogue of Prop. \ref{lb204}.

\begin{pp}\label{lb294}
Let $X$ be a set. Let $\scr A$ be a unital *-subalgebra of $l^\infty(X)$, equipped with the $l^\infty$-norm. Let $(\pi,V)$ be a positive pre-unitary representation of $\scr A$. Then $\pi(\SA)\subset\fk L(V)$, and the linear map $\pi:\SA\rightarrow\fk L(V)$ is bounded with operator norm $\Vert\pi\Vert=1$.
\end{pp}

\begin{proof}
By Prop. \ref{lb204}, for each $f\in\scr A$ and $\xi\in V$ we have
\begin{align*}
|\bk{\xi|\pi(f)\xi}|\leq \Vert f\Vert_{l^\infty}\cdot\bk{\xi|\pi(1)\xi}=\Vert f\Vert_{l^\infty}\cdot \Vert\xi\Vert^2
\end{align*}
Thus
\begin{align*}
\bk{\pi(f)\xi|\pi(f)\xi}=\bk{\xi|\pi(f^*f)\xi}\leq \Vert f^*f\Vert_{l^\infty}\cdot \Vert\xi\Vert^2=\Vert f\Vert_{l^\infty}^2\cdot\Vert\xi\Vert^2
\end{align*}
and hence $\Vert\pi(f)\Vert\leq\Vert f\Vert_{l^\infty}$. This proves that $\pi(\SA)\subset\fk L(V)$, and that the linear map $\pi:\SA\rightarrow\fk L(V)$ satisfies $\Vert\pi\Vert\leq1$. Since $\Vert\pi(1)\Vert=1$, we have $\Vert\pi\Vert=1$.
\end{proof}



\subsubsection{Borel functional calculus for bounded self-adjoint operators}



Let $T\in\fk L(\MH)$ be self-adjoint. Choose $r\in\Rbb_{\geq0}$ such that $\Vert T\Vert\leq r$. In this subsection we establish, in Thm. \ref{lb283}, the Borel functional calculus for $T$, which can be viewed the operator-valued (classical) Hausdorff moment theorem.

As we shall see, Thm. \ref{lb283} follows directly from the operator-valued abstract Hausdorff moment Thm. \ref{lb274}, once a subtle difference has been addressed: namely, the distinction between the abstract Hausdorff moment theorem (Cor. \ref{lb261})---applied in the special case $X=I=[a,b]$ with $-\infty<a<b<+\infty$ and $\scr A$ the polynomial algebra $\Cbb[x]$ (viewed as a unital *-subalgebra of $C([-r,r])$ \footnote{To view $\Cbb[x]$ as a subset of $C([-r,r])$ we must assume that $r>0$. However, the case $r=0$ is trivial since $T$ must be zero.})---and the classical Hausdorff moment Thm. \ref{lb169}.


The solvability condition for the (classical) Hausdorff moment problem $\int_I x^nd\rho=c_n$ is that $H,H',H-H'$ are all positive. Define the linear functional
\begin{align*}
\Lambda:\scr A=\Cbb[x]\rightarrow\Cbb\qquad x^n\mapsto c_n
\end{align*}
Then the positivity of $H,H',H-H'$ means that $\Lambda(f)\geq0$ whenever $f\in\Cbb[x]$ has one of the following three forms:
\begin{align*}
f(x)=p(x)^*p(x)\qquad f(x)=xp(x)^*p(x)\qquad f(x)=(1-x)p(x)^*p(x)
\end{align*}
with $p\in\Cbb[x]$. Recall that is the condition in the special case $I=[0,1]$. In the general case $I=[a,b]$, the corresponding solvability condition is that $\Lambda(f)\geq0$ for all $f$ of one of the following three forms (with $p\in\Cbb[x]$):
\begin{align}\label{eq160}
f(x)=p(x)^*p(x)\qquad f(x)=(x-a)p(x)^*p(x)\qquad f(x)=(b-x)p(x)^*p(x)
\end{align}


By contrast, in the abstract Hausdorff moment theorem (Cor. \ref{lb261}), the condition required of $\Lambda$ is that $\Lambda(f)\geq0$ for all $f$ belonging to the set
\begin{align}\label{eq161}
\{f\in\Cbb[x],f|_I\geq0\}
\end{align}
This condition is indeed equivalent to one above, since the set \eqref{eq161} is $\Rbb_{\geq0}$-spanned by polynomials of the form in \eqref{eq160}; see Pb. \ref{lb284}.


We will not rely on this equivalence to establish the Borel functional calculus, because this method does not extend to the setting of several mutually commuting bounded self-adjoint operators. Instead, following Riesz's original idea in \cite{Rie13}, we will use finite-rank approximations of $T$ (as in Subsec. \ref{lb285} or the proof Hilbert's spectral Thm. \ref{lb239}) to  prove the operator-valued version of this equivalence: the condition $-r\leq T\leq r$ is equivalent to $f(T)\geq0$ for all $f\in\Cbb[x]$ satisfying $f|_{[-r,r]}\geq0$. \footnote{The direction ``$\Leftarrow$'' follows directly by choosing $f(x)=x+r$. Therefore, it suffices to prove ``$\Rightarrow$''.}






\begin{thm}[\textbf{Borel functional calculus}]\label{lb283}
There exists a unique normal unitary representation
\begin{align*}
\pi_T:\Borb([-r,r])\rightarrow\fk L(\MH)
\end{align*}
sending the function $x=\id_{[-r,r]}$ to $T$.
\end{thm}

We call $(\pi_T,\MH)$ the \textbf{Borel functional calculus} \index{00@Borel functional calculus of bounded self-adjoint operators} of $T$. Its restriction to $C([-r,r])$ is called the \textbf{continuous functional calculus}. \index{00@Continuous functional calculus} We write \index{fT@$f(T)$, the Borel functional calculus of $T$}
\begin{align*}
\pmb{f(T)}:=\pi_T(f)
\end{align*}


\begin{proof}
Let $\scr A$ be the set of polynomials on $[-r,r]$ (viewed as functions on $[-r,r]$). Then $\scr A$ is a unital *-subalgebra of $C([-r,r])$ separating points of $[-r,r]$. There is a unique unitary representation $(\pi_T,\MH)$ of $\scr A$ sending $x$ to $T$. If we can prove that this representation is positive, then by Thm. \ref{lb274}, it can be extended uniquely to a normal unitary representation of $\Borb([-r,r])$, finishing the proof.

Let us prove that $\pi_T$ is positive on $\scr A$, that is, for any polynomial $f$ satisfying $f|_{[-r,r]}\geq0$, the operator $f(T):=\pi_T(T)$ is positive. Let $(e_i)_{i\in\scr I}$ be an orthonormal basis of $\MH$. For each $\alpha\in\fin(2^{\scr I})$, let $E_\alpha$ be the projection onto $\Span\{e_i:i\in\alpha\}$. By Exp. \ref{lb157} (or more generally, by Thm. \ref{lb264}), $(E_\alpha)_{\alpha\in\fin(2^{\scr I})}$ is an increasing net of projections converging in SOT to $\id_\MH$. By Exp. \ref{lb397}, the net $(f(E_\alpha TE_\alpha))_{\alpha\in\fin(2^{\scr I})}$ converges in SOT to $f(T)$. Therefore, it suffices to show that each $f(E_\alpha TE_\alpha)$ is positive.


The linear operator
\begin{align*}
T_\alpha=E_\alpha TE_\alpha\big|_{\Rng(E_\alpha)}
\end{align*}
is self-adjoint since $\bk{\xi|E_\alpha TE_\alpha\xi}=\bk{E_\alpha\xi|TE_\alpha\xi}\in\Rbb$. Therefore, by finite-dimensional linear algebra, $T_\alpha$ is diagonalizable. Thus, there exists an orthonormal basis $v_1,\dots,v_n$ of $\Rng(E_\alpha)$ such that $T_\alpha v_i=\lambda_iv_i$ with $\lambda_i\in\Rbb$. 

Extend $\{v_1,\dots,v_n\}$ to an orthonormal basis of $\MH$ (cf. Exe. \ref{lb281}). Then, under this basis, the matrix representation of $E_\alpha TE_\alpha$ (cf. Def. \ref{lb280}) is diagonal, with the first $n$-diagonal terms being $\lambda_1,\dots,\lambda_n$ and the remaining terms being $0$. Since $\Vert E_\alpha TE_\alpha\Vert\leq\Vert T\Vert\leq r$, we must have
\begin{align*}
\lambda_i\in[-r,r]
\end{align*}
Therefore, the condition $f|_{[-r,r]}\geq0$ implies that $f(\lambda_i)\geq0$. 

The matrix representation of $f(E_\alpha TE_\alpha)$ is also diagonal, with the first $n$-diagonal terms being $f(\lambda_1),\dots,f(\lambda_n)$ (all $\geq0$) and the remaining terms being $0$. Thus $f(E_\alpha TE_\alpha)\geq0$.
\end{proof}



\subsubsection{Proof of the Riesz spectral Thm. \ref{lb267}}\label{lb289}


\begin{proof}[\textbf{Proof of Thm. \ref{lb267}}]
Define
\begin{align*}
E(\lambda)=\chi_{[-r,\lambda]}(T)=\pi_T(\chi_{[-r,\lambda]})
\end{align*}
Then, since $\pi_T$ is a unitary representation, and since $\chi_{[-r,\lambda]}=(\chi_{[-r,\lambda]})^*=(\chi_{[-r,\lambda]})^2$, we conclude that $E(\lambda)$ is a projection. Since $\pi_T$ is positive (cf. Prop. \ref{lb272}), whenever $-r\leq\lambda_1\leq\lambda_2\leq b$ we have $\chi_{[-r,\lambda_2]}-\chi_{[-r,\lambda_1]}\geq0$ and hence $E(\lambda_2)-E(\lambda_1)\geq0$. This proves that the net $E:=(E(\lambda))_{\lambda\in[-r,r]}$ is increasing. 

Since $\pi_T$ is normal, the linear functional $\Lambda_\xi:f\mapsto\bk{\xi|f(T)\xi}$ is normal (and positive). Therefore, by MCT or DCT (for first-countable nets, cf. Thm. \ref{lb224} or \ref{lb225}), we have
\begin{align*}
\lim_{\lambda\searrow\lambda_0}\bk{\xi|E(\lambda)\xi}=\bk{\xi|E(\lambda_0)\xi}
\end{align*}
That is, $\lim_{\lambda\searrow\lambda_0 E(\lambda)}$ converges in SOT to $E(\lambda_0)$. We have thus proved that $E$ is right-continuous.


In view of Prop. \ref{lb282} (and the polarization identity), to prove $f(T)=\int_{[-r,r]}f(\lambda)dE(\lambda)$, it suffices to show for each $\xi\in\MH$ and $f\in C([-r,r])$ that
\begin{align*}
\Lambda_\xi(f)=\int_{[-r,r]}f(\lambda)d\bk{\xi|E(\lambda)\xi}
\end{align*}
By Prop. \ref{lb252}, we have
\begin{align*}
\Lambda_\xi(f)=\int_{[-r,r]}fd\mu_\xi\qquad\text{for each }f\in\Borb([-r,r])
\end{align*}
where $\mu_\xi:\fk B_{[-r,r]}\rightarrow\Rbb_{\geq0}$ is given by $\mu_\xi(E)=\Lambda_\xi(\chi_E)$. Recall from Thm. \ref{lb9} that when $f\in C([-r,r])$, the integral $\int_{[-r,r]}fd\mu_\xi$ can be expresses by the Stieltjes integral of $f$ against the increasing function sending each $\lambda\in[-r,r]$ to
\begin{align*}
\mu_\xi([-r,\lambda])=\Lambda_\xi(\chi_{[-r,\lambda]})=\bk{\xi|\chi_{[-r,\lambda]}(T)\xi}=\bk{\xi|E(\lambda)\xi}
\end{align*}
This finishes the proof.
\end{proof}


\subsection{Some concluding remarks on Riesz's spectral theorem}

Let $T\in\fk L(\MH)$ be self-adjoint where $\MH$ is a Hilbert space. Let $r\geq \Vert T\Vert$. 

\begin{rem}\label{lb287}
We proved the Riesz spectral Thm. \ref{lb267} by establishing the Borel functional calculus (Thm. \ref{lb283}). However, as noted in the answer to Question \ref{lb286}, it actually suffices---just as Riesz himself did in \cite{Rie13}---to establish the \textbf{semicontinuous functional calculus}. \index{00@Semicontinuous functional calculus} That is, one proves the existence of a (unique) unitary representation
\begin{align*}
\pi_T:\Span_\Cbb\LSCb([-r,r],\Rbb_{\geq0})\rightarrow\fk L(\MH)
\end{align*}
(where $\LSCb(X,\Rbb_{\geq0})$ denotes the set of bounded lower semicontinuous functions $X\rightarrow\Rbb_{\geq0}$) satisfying
\begin{align*}
\lim_n\bk{\xi|\pi_T(f_n)\xi}=\bk{\xi|\pi_T(f)\xi}
\end{align*}
for each $\xi\in\MH$ and each increasing sequence $(f_n)$ in $\LSCb(X,\Rbb_{\geq0})$ converging pointwise to $f\in\LSCb(X,\Rbb_{\geq0})$.

One reason Riesz did not use the Borel functional calculus in \cite{Rie13} is simply that measure theory had not yet matured at the time. In fact, the spectral theorem itself was a major driving force behind the development of modern measure theory.

For a more faithful presentation of Riesz’s original proof of his spectral theorem in \cite{Rie13}, see Sec. 25.8 and 25.9 of \cite{Gui-A}. We will discuss the origin of the Borel functional calculus in Subsec. \ref{lb345}. \hqed
\end{rem}


\begin{rem}
Although Riesz's treatment of the spectral theorem is framed primarily within the paradigm of linear extension and largely avoids the perspective of finite approximation, the latter is not completely absent: it is used to prove the positivity of the polynomial functional calculus, as seen in the proof of Thm. \ref{lb283}. 

Modern approaches to the spectral theorem often abandon the finite approximation paradigm completely. One motivation is to develop methods that apply equally well to operators on Banach spaces, not just on Hilbert spaces. In these modern treatments, the primary non-trivial step---apart from applying the Riesz(-Markov) representation theorem---is still to prove the positivity of the polynomial functional calculus. The following is a list of mainstream approaches, along with the key theorems used to establish this crucial positivity.
\begin{itemize}
\item The approach using the notion of spectrum
\begin{align*}
\sigma(T)=\{z\in\Cbb:(z-T)\text{ is not invertible in }\fk L(T)\}
\end{align*}
The key theorems are \textbf{Gelfand's spectral radius theorem}
\begin{align*}
\sup\{|\lambda|:\lambda\in\sigma(T)\}=\lim_{n\rightarrow\infty}\Vert T^n\Vert^{1/n}
\end{align*}
(for any $T\in\fk L(\MH)$, not necessarily self-adjoint) and the \textbf{spectral mapping theorem}: $\sigma(f(T))\subset f(\sigma(T))$ for each $f\in\Cbb[x]$. See \cite{Lax,RS-1}.
\item The $C^*$-algebra approach. The key theorem is the (commutative) \textbf{Gelfand-Naimark theorem}, which states that any  commutative normed-closed unital $*$-subalgebra of $\fk L(\MH)$ is isometically isomorphic to $C(X)$ for a compact Hausdorff space $X$. This theorem is applied to the subalgebra generated by $T$, so that $T$ can be viewed as a continuous function on $X$ with range in $[-r,r]$. See \cite{Rud-F}.
\item The approach using \textbf{holomorphic functional calculus}
\begin{align*}
f(T)=\oint_C\frac{f(z)}{z-T}\cdot\frac{dz}{2\pi\im}
\end{align*}
where $C$ is a suitable closed curve in $\Cbb$ surrounding $[-r,r]$. The key theorem is $(fg)(T)=f(T)g(T)$ and $f^\dagger(T)=f(T)^*$ (where $f^\dagger(z)=\ovl{f(\ovl z)}$), and that any holomorphic function $f$, defined and strictly positive on a neighborhood of $[-r,r]$, can be written as $h^\dagger h$ with $h$ holomorphic. This allows the argument of Prop. \ref{lb272} to apply. See \cite{Gui-S}.
\item The approach reducing the spectral theorem for self-adjoint operators to that of unitary operators. The crucial point is that positivity of the polynomial functional calculus is easier to establish for unitary operators, due to the (nontrivial) fact that any strictly positive polynomial polynomial $f$ on $\Sbb^1$ can be written as $g^*g$ for some polynomial $g$. This again allows the argument of Prop. \ref{lb272} to go through. See \cite{Xia}.
\end{itemize}
\hqed 
\end{rem}








\subsection{Borel functional calculus for bounded normal operators}\label{lb259}


In this section, we fix a Hilbert space $\MH$.

\begin{df}
An operator $T\in\fk L(\MH)$ is called \textbf{normal} \index{00@Normal operators, bounded} if it satisfies $T^*T=TT^*$. This is equivalent to its real part $\Real(T)$ \index{00@Real part of an operator} and its imaginary part $\Imag(T)$ \index{00@Imaginary part of an operator} commuting with each other, where
\begin{align*}
\Real(T)=\frac{T+T^*}2\qquad \Imag(T)=\frac{T-T^*}{2\im}
\end{align*}
\end{df}


\begin{eg}\label{lb311}
Let $U\in\fk L(\MH,\MK)$ where $\MH$ and $\MK$ are Hilbert spaces. Then $U$ is unitary iff $U^*U=\idt_\MH$ and $UU^*=\idt_\MK$. Therefore, unitary operators on $\MH$ are normal.
\end{eg}

It follows that $U^{-1}=U^*$ if $U$ is a unitary operator between Hilbert spaces.

\begin{proof}
Suppose that $U$ is unitary, i.e., a linear isometry which is also surjective (and hence bijective). In particular, $U^{-1}\in\fk L(\MK,\MH)$ Then for each $\xi,\eta\in\MH$, we have
\begin{align*}
\bk{\eta|U^{-1}U\xi}=\bk{\eta|\xi}=\bk{U\eta|U\xi}=\bk{\eta|U^*U\xi}
\end{align*}
This shows that $U^{-1}=U^*$, and hence $U^*U=\idt_\MH,UU^*=\idt_\MK$.

Conversely, assume that $U^*U=\idt_\MH$ and $UU^*=\idt_\MK$. Then $U^*$ is the inverse of $U$. In particular, $U$ is bijective. For each $\xi\in\MH$ we have $\bk{U\xi|U\xi}=\bk{\xi|U^*U\xi}=\bk{\xi|\xi}$. Thus $U$ is a linear isometry, and hence unitary.
\end{proof}

\subsubsection{Introduction}


While Riesz's spectral Thm. \ref{lb267} offers important historical context for modern versions of the spectral theorem, it's not the most practical approach for a reader who simply wants to learn how to apply the theorem quickly. The modern versions---specifically, the Borel functional calculus (Thm. \ref{lb283}) and the multiplication operator version---are more useful.

Proving Riesz's spectral theorem requires first establishing the Borel functional calculus, yet the functional calculus alone is sufficient for practical applications. The additional components in Riesz's theorem, such as the operator-valued Stieltjes integral (Subsec. \ref{lb288}) or the integral representation of functional calculus (Subsec. \ref{lb289}), are not essential for applying the theorem. Readers can safely skip these sections on first reading.

Furthermore, given that Riesz's spectral theory marks a transition from the paradigm of finite approximation to one of linear extension (cf. Subsec. \ref{lb290}), a complete paradigm shift entails abandoning the language of integration in favor of linear functionals---or, in the context of spectral theory, fully adopting the language of the Borel functional calculus. This is the path we will follow from this point forward, having fulfilled the historical mission of Riesz's theorem.



The goal of this section is to generalize the Borel functional calculus for a single bounded self-adjoint operator (Thm. \ref{lb283}) to several mutually commuting bounded self-adjoint operators (Thm. \ref{lb331}). There are two main reasons for this generalization. First, in quantum mechanics, two commuting self-adjoint operators---say, $A$ and $B$---represent two observables that can be measured simultaneously without uncertainty. (See Sec. \ref{lb428} for a detailed discussion.) Second, this generalization is necessary to establish a spectral theorem for bounded normal operators. This case includes unitary operators, since every unitary operator is normal. In Ch. \ref{lb292}, we will establish the spectral theorem for unbounded self-adjoint operators by reducing it to the unitary case via the Cayley transform.



\subsubsection{Borel functional calculus for mutually commuting bounded self-adjoint operators}


Let $T_1,\dots,T_N\in\fk L(\MH)$ be bounded self-adjoint operators. Assume that they commute with each other, i.e., $[T_i,T_j]=0$ for each $1\leq i,j\leq N$. Choose $R_i\in\Rbb_{>0}$ such that
\begin{align*}
\Vert T_i\Vert\leq R_i
\end{align*}
Let
\begin{align*}
\Cbb[x_\blt]=\Cbb[x_1,\dots,x_N]=\{\text{complex polynomials of }x_1,\dots,x_N\}
\end{align*}
Then we clearly have a unital *-homomophism
\begin{align*}
\pi_{T_\blt}:\Cbb[x_\blt]\rightarrow\fk L(\MH)\qquad x_i\mapsto T_i
\end{align*}
called the \textbf{polynomial functional calculus}. \index{00@Polynomial functional calculus} This is the map sending each $f\in\Cbb[x_\blt]$ to $f(T_\blt)$, e.g., sending $x_1^3x_3-4x_1x_2x_5^6$ to $T_1^3T_3-4T_1T_2T_5^6$.

We view $=\Cbb[x_\blt]$ as a unital *-subalgebra of $C(X)$ where
\begin{align*}
X=[-R_1,R_1]\times\cdots\times[-R_N,R_N]
\end{align*}
As in the proof of Thm. \ref{lb283}, the main obstacle in applying the operator-valued abstract Hausdorff moment Thm. \ref{lb274} is to prove thatt $\pi_{T_\blt}$ is positive, i.e., that $f(T_\blt)\geq0$ for each $f\in\Cbb[x_\blt]$ satisfying $f|_X\geq0$. 


To overcome this difficulty, we adopt a different type of finite approximation, following von Neumann’s treatment of the spectral theorem for bounded normal operators in \cite[Anhang 2]{vN29a}: The earlier method---approximating $T_i$ by $ET_iE$ where $E$ is the projection onto a finite-dimensional subspace---fails here, since $ET_iE$ and $ET_jE$ need not commute. Instead, we use \textbf{finite-spectrum approximation}\index{00@Finite spectrum approximation} rather than \textbf{finite-rank approximation}. Specifically, we approximate each $T_i$ by $f_i(T_i)$ where $f_i\in\Borb([-R_i,R_i])$ has finite range. In this way, the operators $f_i(T_i)$ and $f_j(T_j)$ commute, as shown below.


\begin{lm}\label{lb295}
Let $A,B\in\fk L(A)$ be self-adjoint. Choose $a,b\in\Rbb_{\geq0}$ such that $\Vert A\Vert\leq a$ and $\Vert B\Vert\leq b$. Then $f(A)$ commutes with $g(B)$ for each $f\in\Borb([-a,a])$ and $g\in\Borb([-b,b])$.
\end{lm}


\begin{proof}
By Lem. \ref{lb276}, there is a net of polynomials $(f_\alpha)$ of $z_\blt$ converging universally-$L^2$ to $f$. By Prop. \ref{lb293}, the net $(f_\alpha(A))$ converges in SOT to $f(A)$. Since each $f_\alpha(A)$ commutes with $B$, $f(A)$ also commutes with $B$. A similar argument shows that $f(A)$ commutes with $g(B)$.
\end{proof}




\begin{thm}[\textbf{Borel functional calculus}]\label{lb296}
Let $T_1,\dots,T_N\in\fk L(\MH)$ be mutually commuting and self-adjoint operators. For each $1\leq i\leq N$, choose $R_i\in\Rbb_{>0}$ such that $\Vert T_i\Vert\leq R_i$. Let 
\begin{align*}
X=[-R_1,R_1]\times\cdots\times[-R_N,R_N]
\end{align*}
Then there exists a unique normal unitary representation
\begin{align*}
\pi_{T_\blt}:\Borb(X)\rightarrow\fk L(\MH)
\end{align*}
sending each $x_i$ to $T_i$, where $x_i$ the $i$-th \textbf{coordinate function}\index{00@Coordinate function} of $\Rbb^N$, i.e., the projection $\Rbb^N\rightarrow\Rbb$ onto the $i$-th component.
\end{thm}

We call $(\pi_{T_\blt},\MH)$ the \textbf{Borel functional calculus} \index{00@Borel functional calculus of bounded self-adjoint operators} of $T_\blt$, and write
\begin{align*}
\pmb{f(T_\blt)}:=\pi_{T_\blt}(f)
\end{align*}

\begin{proof}
Step 1. Let $\scr A$ be the polynomial algebra $\Cbb[x_\blt]$, viewed as a unital *-subalgebra of $\Borb(X)$. Then there exists a unique unital *-homomorphism (namely, the polynomial functional calculus)
\begin{align*}
\pi_{T_\blt}:\scr A\rightarrow\fk L(\MH)
\end{align*}
sending each $x_i$ to $T_i$. We abbreviate $\pi_{T_\blt}$ to $\pi$ for simplicity. With the help of Thm. \ref{lb274}, the proof of the current theorem is reduced to showing that $\pi$ is positive. 

In the following, we prove the positivity of $\pi$ in the case $N=2$; the general case follows from the same idea. We write $A=T_1$ and $B=T_2$.\\[-1ex]

Step 2. Let $R=\max\{R_1,R_2\}$, and let $(g_n)$ be a sequence of simple functions in $\Borb([-R,R],[-R,R])$ converging uniformly to the the identity function. Then, by Prop. \ref{lb294}, $g_n(A)$ and $g_n(B)$ converge in the operator norm to $A$ and $B$ respectively. By Prop. \ref{lb143}, for each $f\in\scr A$, the sequence $f(g_n(A),g_n(B))$ converges in norm to $f(A,B)$. Therefore, to prove the positivity of $\pi$, it remains to prove that $f(g(A),g(B))\geq0$ for each $f\in\scr A$ satisfying $f|_X\geq0$, and for each simple function $g\in\Borb([-R,R],[-R,R])$.\\[-1ex]

Step 3. Since $g$ has finite range, we can write
\begin{align*}
g=c_1\chi_{I_1}+\cdots+c_n\chi_{I_n}
\end{align*}
where $c_i\in[-R,R]$, and $I_1,\dots,I_n\in\fk B([-R,R])$ are mutually disjoint with union $[-R,R]$. Then
\begin{align*}
g(A)=\sum_{i=1}^n c_iE_i\qquad g(B)=\sum_{j=1}^n c_jF_j\qquad \id_\MH=\sum_{i=1}^n E_i=\sum_{j=1}^n F_j
\end{align*}
where
\begin{align*}
E_i:=\chi_{I_i}(A)\qquad F_j:=\chi_{I_j}(B)
\end{align*}
are projections, and
\begin{align*}
E_iE_j=\delta_{i,j}E_i\qquad F_iF_j=\delta_{i,j}F_j\qquad [E_i,F_j]=0
\end{align*}
where the last equality is due to Lem. \ref{lb194}. 

Define a linear map
\begin{align*}
\varpi:\scr A\rightarrow\fk L(\MH)\qquad f\mapsto \sum_{i,j=1}^n f(c_i,c_j)E_iF_j
\end{align*}
Then $\varpi(1)=\sum_{i,j}E_iF_j=\idt$, and
\begin{align*}
\varpi(x_1)=\sum_{i,j}x_1(c_i,c_j)E_iF_j=\sum_{i,j}c_iE_iF_j=\sum_{i,j}c_iE_i=g(A)
\end{align*}
Similarly, we have $\varpi(x_2)=g(B)$. Clearly $\varpi(\ovl f)=\varpi(f)^*$. For each $f,g\in\scr A$, we have
\begin{align*}
&\varpi(f)\varpi(h)=\sum_{i,j,k,l}f(c_i,c_j)h(c_k,c_l)E_iF_jE_kF_l=\sum_{i,j,k,l}\delta_{i,k}\delta_{j,l}f(c_i,c_j)h(c_k,c_l)E_iF_j\\
=&\sum_{i,j}f(c_i,c_j)h(c_i,c_j)E_iF_j=\varpi(fh)
\end{align*}
Thus, $\varpi$ is the unique unital *-homomorphism sending $x_1$ to $g(A)$ and $x_2$ to $g(B)$, that is, $\varpi$ is the polynomial functional calculus of $g(A)$ and $g(B)$. Since $(c_i,c_j)\in X$, for each $f\in\scr A$ satisfying $f|_X\geq0$ we must have $\varpi(f)\geq0$.
\end{proof}


\subsubsection{Borel functional calculus for adjointly-commuting bounded normal operators}


\begin{df}
Let $A,B\in\fk L(\MH)$. We say that $A$ \textbf{commutes adjointly} with $B$ \index{00@Adjoint commutativity} \index{00@Commute adjointly} if
\begin{align*}
[A,B]=[A^*,B]=0
\end{align*}
Note that by taking adjoint, the above equalities are equivalent to
\begin{align*}
[A^*,B^*]=[A,B^*]=0
\end{align*}
\end{df}

\begin{eg}
Let $A\in\fk L(\MH)$. Then $A$ commutes adjointly with $A$ iff $A$ is normal.
\end{eg}

\begin{eg}
Let $A,B\in\fk L(\MH)$. The following are clearly equivalent:
\begin{enumerate}
\item[(1)] $A$ and $B$ are adjointly-commuting bounded normal operators.
\item[(2)] The self-adjoint operators $\Real(A),\Imag(A),\Real(B),\Imag(B)$ commute with each other.
\end{enumerate}
\end{eg}


\begin{eg}
Let $T\in\fk L(\MH)$ be self-adjoint and $R\geq\Vert T\Vert$. Let $f,g\in\Borb([-R,R])$. Then, $f(T)$ and $g(T)$ are adjointly-commuting bounded normal operators. 
\end{eg}

\begin{proof}
The operators $f(T)$ and $g(T)$ commute, since
\begin{align*}
f(T)g(T)=(fg)(T)=(gf)(T)=g(T)f(T)
\end{align*}
Replacing $g$ with $\ovl g$, and noting that $\ovl g(T)=g(T)^*$, we get $[f(T),g(T)^*]=0$. Thus $f(T)$ commutes adjointly with $g(T)$. Replacing $g$ with $f$, we conclude that $f(T)$ is normal. Similarly, $g(T)$ is normal.
\end{proof}


Fuglede's theorem states that two bounded normal operators on $\MH$ commute adjointly whenever they commute. We will not need the full result here and record only the following special case:

\begin{eg}\label{lb429}
Let $U\in\fk L(\MH)$ be unitary, and let $T\in\fk L(\MH)$ be normal. Then $U$ and $T$ commute iff they commute adjointly.
\end{eg}


\begin{proof}
Adjoint commutativity clearly implies commutativity. Conversely, assume that $UT=TU$. Then $UTU^{-1}=T$, and hence $TU^{-1}=U^{-1}T$. Since $U$ is unitary, we have $U^{-1}=U^*$, and hence $TU^*=U^*T$.
\end{proof}




The aim of this subsection---and indeed the final goal of this entire section---is to extend Thm.\ \ref{lb296} to the Borel functional calculus for finitely many adjointly-commuting bounded normal operators. To formulate the result in a way that does not depend on the particular underlying space $X$, we introduce the following notion, which serves as the operator-theoretic analogue of the support of a Borel measure (cf. Def. \ref{lb298}).


\begin{df}\label{lb299}
Let $X$ be a topological space. Let $(\pi,\MH)$ be a unitary representation of $\Borb(X)$. The \textbf{support} $\pmb{\Supp(\pi)}$ of $\pi$ \index{00@Support of a unitary representation of $\Borb(X)$} is defined to be
\begin{align*}
\Supp(\pi)=\{x\in X:\pi(\chi_U)\neq0\text{ for each }U\in\Nbh_X(x)\}
\end{align*}
Then $\Supp(\pi)$ is a closed subset of $X$, because we clearly have
\begin{align*}
X\setminus\Supp(\pi)=\bigcup_{U\in\MT_X,\pi(\chi_U)=0}U
\end{align*}
We also have
\begin{align}\label{eq167}
\Supp(\pi)=\Cl_X\Big(\bigcup_{\xi\in\MH}\Supp(\mu_\xi)\Big)
\end{align}
We say that $\pi$ is \textbf{compactly supported} (or that $\pi$ has \textbf{compact support}) if the closed set $\Supp(\pi)$ is compact.  
\end{df}


\begin{proof}[Proof of \eqref{eq167}]
Let $x\in X$. If $x\notin\Supp(\pi)$, then there exists $U\in\Nbh_X(x)$ such that $\pi(\chi_U)=0$, and hence
\begin{align*}
\mu_\xi(\chi_U)=\bk{\xi|\pi(\chi_U)\xi}=0
\end{align*}
for all $\xi$, where $\mu_\xi$ is defined in Rem. \ref{lb297}. So $U\subset X\setminus\Supp(\mu_\xi)$ for all $\xi$, and hence $x$ does not belong to the RHS of \eqref{eq167}.

Conversely, suppose that $x$ does not belong to the RHS of \eqref{eq167}. There there exists $U\in\Nbh_X(x)$ such that $U\subset X\setminus\Supp(\mu_\xi)$ (and hence $\mu_\xi(\chi_U)=0$) for all $\xi$. By the above computation, we have $\bk{\xi|\pi(\chi_U)\xi}=0$ for all $\xi$, and hence $\pi(\chi_U)=0$. This proves $x\notin\Supp(\pi)$.
\end{proof}




\begin{rem}\label{lb302}
Assume that one of the following conditions is satisfied:
\begin{enumerate}
\item[(1)] $X$ is second countable, and $\pi$ is normal.
\item[(2)] $X$ is LCH, and $\pi$ is Radon.
\end{enumerate}
Then $\pi(X\setminus\Supp(\pi))=0$. Therefore, $\Supp(\pi)$ is the smallest closed subset such that $\pi$ vanished on its complement.
\end{rem}

\begin{proof}
For each $\xi\in V$, we have $\Supp(\mu_\xi)\subset\Supp(\pi)$ due to \eqref{eq167}. By Def. \ref{lb298}, $\mu_\xi$ vanishes on $X\setminus\Supp(\mu_\xi)$, and hence on its subset $X\setminus\Supp(\pi)$. Since $\xi$ is arbitrary, we conclude that $\pi$ vanishes on $X\setminus\Supp(\pi)$.
\end{proof}


\begin{rem}\label{lb301}
Let $(\pi,\MH)$ be a unitary representation of $\Borb(X)$ satisfying either (1) or (2) of Rem. \ref{lb302}. Choose any Borel subset $K\subset X$ containing $\Supp(\pi)$. Then for each $f,g\in\Borb(X)$ we have
\begin{align*}
f|_K=g|_K\qquad\Longrightarrow\qquad\pi(f)=\pi(g)
\end{align*}
\end{rem}



\begin{proof}
By Rem. \ref{lb302}, we have $\pi(\Supp(\pi)^c)=0$. Since $0\leq \chi_{K^c}\leq\chi_{\Supp(\pi)^c}$, by the positivity of $\pi$ (Prop. \ref{lb272}), we have $0\leq \pi(\chi_{K^c})\leq\pi(\chi_{\Supp(\pi)^c})$, and hence $\pi(\chi_{K^c})=0$. It follows that
\begin{align*}
\pi(f)=\pi(f\chi_K)+\pi(f\chi_{K^c})+\pi(f\chi_K)+\pi(f)\pi(\chi_{K^c})=\pi(f\chi_K)
\end{align*}
Thus, if $f|_K=g|_K$, then $f\chi_K=g\chi_K$, and hence $\pi(f)=\pi(g)$.
\end{proof}

\begin{pp}\label{lb303}
Assume that $X$ is second-countable, and let $(\pi,\MH)$ be a normal unitary representation of $\Borb(X)$. Let $K\subset X$ be a Borel set containing $\Supp(\pi)$. Then there is a unique normal unitary representation
\begin{gather}\label{eq163}
\pmb{\pi|_K}:\Borb(K)\rightarrow\fk L(\MH)\qquad \pi|_K(f|_K)=\pi(f)
\end{gather}
(where $f\in\Borb(X)$). We call $\pi|_K$ the \textbf{restriction} \index{00@Restriction representation $\pi\vert_K$} of $\pi$ to $K$.
\end{pp}

\begin{proof}
The uniqueness is obvious. Existence: For each $g\in\Borb(K)$, extend $g$ by zero to $\wtd g:X\rightarrow\Cbb$, and set $\pi|_K(g)=\pi(\wtd g)$. Then for each $f\in\Borb(X)$, we have
\begin{align*}
\pi|_K(f|_K)=\pi(\wtd{f|_K})=\pi(f\chi_K)=\pi(f)
\end{align*}
where the last step is by Rem. \ref{lb301}. In particular, $\pi|_K(1_K)=\pi(1|_X)$. It follows that $\pi|_K$ is a normal unitary representation satisfying \eqref{eq163}.
\end{proof}




\begin{thm}[\textbf{Borel functional calculus}]\label{lb331}
Let $T_1,\dots,T_N\in\fk L(\MH)$ be adjointly-commuting bounded normal operators. Then there exists a unique normal unitary representation
\begin{align*}
\pi_{T_\blt}:\Borb(\Cbb^N)\rightarrow\fk L(\MH)
\end{align*}
with compact support such that $\pi_{T_\blt}$ sends each $z_i$ to $T_i$.
\end{thm}

Here, $z_i$ is the $i$-th \textbf{coordinate function}\index{00@Coordinate function} of $\Rbb^N$, i.e., the projection $\Cbb^N\rightarrow\Cbb$ onto the $i$-th component. We call $(\pi_{T_\blt},\MH)$ the \textbf{Borel functional calculus} of $T_\blt$ \index{00@Borel functional calculus for bounded normal operators} of $T_\blt$, and write
\begin{align*}
\pmb{f(T_\blt)}:=\pi_{T_\blt}(f)
\end{align*}



\begin{proof}
Uniqueness: Suppose that $\pi_1,\pi_2$ both satisfy the requirement for $\pi_{T_\blt}$. Let $K$ be a compact subset of $\Cbb^N$ containing $\Supp(\pi_1)\cup\Supp(\pi_2)$. Let $\scr A$ be the polynoimal algebra $\Cbb[z_\blt,\ovl{z_\blt}]$ (cf. Exp. \ref{lb300}). By enlarging $K$, we assume that $K$ has non-empty interior so that $\scr A$ can be viewed as a unital *-subalgebra of $C(K)$. 

By Prop. \ref{lb303},
\begin{align*}
\pi_1|_K(z_i|_K)=\pi_1(z_i)=T_i
\end{align*}
and similarly $\pi_2|_K(z_i|_K)=T_i$. Thus $\pi_1|_K$ and $\pi_2|_K$ agree on $\scr A$, and hence $\pi_1|_K=\pi_2|_K$ by the uniqueness part of Thm. \ref{lb274}. By Prop. \ref{lb303}, we conclude $\pi_1=\pi_2$.\\[-1ex]

Existence: Let $A_i=\Real(T_i)$ and $B_i=\Imag(T_i)$. Then $A_1,\dots,A_N,B_1,\dots,B_N$ are mutually commuting bounded self-adjoint operators on $\MH$, and hence admit a Borel functional calculus by Thm. \ref{lb296}. We choose $R_i\in\Rbb_{>0}$ such that $\Vert T_i\Vert\leq R$ for each $i$. Let 
\begin{align*}
K=[-R_1,R_1]^2\times\cdots\times[-R_N,R_N]^2
\end{align*}
where each $[-R_i,R_i]^2$ is viewed as a subset of $\Cbb$ via the correspondence $(x_i,y_i)\mapsto x_i+\im y_i$. Then $K$ is a compact subset of $\Cbb^N$. One checks easily that
\begin{align*}
\pi:\Borb(\Cbb^N)\rightarrow\fk L(\MH)\qquad f\mapsto (f|_K)(A_1,B_1,\dots,A_N,B_N)
\end{align*}
is a normal unitary representation of $\Borb(\Cbb^N)$ with support $\Supp(\pi)\subset K$, and
\begin{align*}
&\pi(z_i)=(z_i|_K)(A_1,B_1,\dots,A_N,B_N)\\
=&(x_i|_K)(A_1,B_1,\dots,A_N,B_N)+\im (y_i|_K)(A_1,B_1,\dots,A_N,B_N)=A_i+\im B_i=T_i
\end{align*}
This finishes the proof.
\end{proof}



\subsection{Joint spectrum $\Sp(T_\blt)$ and the basic properties of Borel functional calculus}\label{lb335}


Fix a Hilbert space $\MH$ an adjointly-commuting bounded normal operators $T_1,\dots,T_N\in\fk L(\MH)$. Recall Exp. \ref{lb300} for the meaning of $\Cbb[z_\blt,\ovl{z_\blt}]$. Recall that $\Fbb\in\{\Rbb,\Cbb\}$.

\begin{df}\label{lb358}
The support of the Borel functional calculus $\pi_{T_\blt}:\Borb(\Cbb^N)\rightarrow\fk L(\MH)$ is denoted by $\pmb{\Sp(T_1,\dots,T_N)}$ (abbreviated to $\pmb{\Sp(T_\blt)}$) \index{Sp@$\Sp(T_\blt)$} and called the \textbf{joint spectrum} \index{00@Joint spectrum $\Sp(T_\blt)$ for adjointly commuting bounded normal operators} of $T_1,\dots,T_N$. That is, $\lambda_\blt\in\Cbb^N$ belongs to $\Sp(T_\blt)$ iff $\chi_U(T_\blt)\neq0$ for each $U\in\Nbh_{\Cbb^N}(\lambda_\blt)$.
\end{df}




\begin{rem}\label{lb314}
Let $K\subset\Cbb^N$ be a Borel set containing $\Sp(T_\blt)$. By Rem. \ref{lb301}, for each $f,g\in\Borb(\Cbb^N)$, we have
\begin{align*}
f|_K=g|_K\qquad\Longrightarrow\qquad f(T_\blt)=g(T_\blt)
\end{align*}
By Prop. \ref{lb303}, there is a unique normal unitary representation
\begin{gather}\label{eq164}
\Borb(K)\rightarrow\fk L(\MH)\qquad g\mapsto g(T_\blt)
\end{gather}
satisfying $(f|_K)(T_\blt)=f(T_\blt)$ for each $f\in\Borb(K)$. The map \eqref{eq164} is also called a \textbf{Borel functional calculus} \index{00@Borel functional calculus for bounded normal operators} of $T_\blt$.
\end{rem}


\begin{rem}
If $\MH\neq0$, then $\Sp(T_\blt)$ is non-empty; otherwise, by Rem. \ref{lb314}, we have $\idt=1(T_\blt)=0(T_\blt)=0$, which is impossible.
\end{rem}



\subsubsection{Basic properties of Borel functional calculus}


\begin{pp}\label{lb309}
For each $f\in\Borb(\Cbb^N)$, we have
\begin{align*}
\Vert f(T_\blt)\Vert\leq \Vert f\Vert_{l^\infty(\Sp(T_\blt))}
\end{align*}
Consequently, if $(f_\alpha)$ is a net in $\Borb(\Cbb^N)$ converging uniformly on $\Sp(T_\blt)$ to $f\in\Borb(\Cbb^N)$, then $f_\alpha(T_\blt)$ converges in norm to $f(T_\blt)$.
\end{pp}


\begin{proof}
This is an immediate consequence of Prop. \ref{lb294}. We can also prove it using the language of measure theory: Recall Rem. \ref{lb297} for the meaning of $\mu_\xi$ where $\xi\in\MH$. Then
\begin{subequations}\label{eq166}
\begin{align}\label{eq166a}
\Vert f(T_\blt)\xi\Vert^2=\int_{\Sp(T_\blt)}|f|^2d\mu_\xi
\end{align}
since $\Vert f(T_\blt)\xi\Vert^2=\bk{\xi|f(T_\blt)^*f(T_\blt)\xi}=\bk{\xi|(f^*f)(T_\blt)\xi}=\int_{\Sp(T_\blt)}|f|^2d\mu_\xi$. In particular, since $1(T_\blt)=\id_{\MH}$, we obtain
\begin{align}\label{eq166b}
\Vert\xi\Vert^2=\mu_\xi(\Sp(T_\blt))
\end{align}
\end{subequations}
Thus $\int_{\Sp(T_\blt)}|f|^2d\mu_\xi\leq\Vert f\Vert_{l^\infty(\Sp(T_\blt))}\cdot\Vert\xi\Vert^2$.
\end{proof}



\begin{pp}\label{lb316}
Let $(f_\alpha)$ be a net in $\Borb(\Cbb^N)$. Let $f\in \Borb(\Cbb^N)$. Suppose that $(f_\alpha)$ converges universally-$L^2$ to $f$ when restricted to $\Sp(T_\blt)$, that is,
\begin{align*}
\lim_\alpha\int_{\Sp(T_\blt)}|f-f_\alpha|^2d\mu=0
\end{align*}
for each Radon measure (equivalently, finite Borel measure) $\mu$ on $\Supp(T_\blt)$. Then $f_\alpha(T_\blt)$ converges in SOT to $f(T_\blt)$.
\end{pp}

\begin{proof}
Apply Prop. \ref{lb293} to $\pi_{T_\blt}|_{\Sp(T_\blt)}$. Alternatively, apply \eqref{eq166}.
\end{proof}


\begin{pp}\label{lb304}
For each $f,g\in\Borb(\Cbb^N)$, the operators $f(T_\blt)$ and $g(T_\blt)$ are normal, and they commute adjointly.
\end{pp}

\begin{proof}
We have $[f(T_\blt),g(T_\blt)]=0$ since
\begin{align*}
f(T_\blt)g(T_\blt)=(fg)(T_\blt)=(gf)(T_\blt)=g(T_\blt)f(T_\blt)
\end{align*}
Since $g^*(T_\blt)=g(T_\blt)^*$, we have $[f(T_\blt),g(T_\blt)^*]=0$. Thus $f(T_\blt)$ commutes adjointly with $g(T_\blt)$. Setting $g=f$, we see that $f(T_\blt)$ is normal.
\end{proof}


\begin{thm}\label{lb306}
Let $g_1,\dots,g_L\in\Borb(\Cbb^N)$ and $f\in\Borb(\Cbb^L)$. Then
\begin{align}\label{eq165}
f(g_1(T_\blt),\dots,g_L(T_\blt))=(f\circ(g_1,\dots,g_L))(T_\blt)
\end{align}
\end{thm}

Note that by Prop. \ref{lb304}, $g_1(T_\blt),\dots,g_L(T_\blt)$ are adjointly-commuting bounded normal operators. Therefore, their Borel functional calculus $f(g_1(T_\blt),\dots,g_L(T_\blt))$ can be defined.


\begin{proof}
The map
\begin{align*}
\Borb(\Cbb^L)\longrightarrow\fk L(\MH)\qquad f\mapsto (f\circ(g_1,\dots,g_L))(T_\blt)
\end{align*}
is clearly a normal unitary representation of $\Borb(\Cbb^L)$.
\end{proof}


\begin{co}\label{lb308}
Let $1\leq L\leq N$, and assume that $f\in\Borb(\Cbb^N)$ depends only on the first $L$ variables so that $f$ can also be viewed as a Borel function on $\Cbb^L$. Then
\begin{align*}
f(T_1,\dots,T_L)=f(T_1,\dots,T_N)
\end{align*} 
\end{co}

In particular, if $f$ only depends on the first variable, then $f(T_1)=f(T_1,\dots,T_N)$.

\begin{proof}
Apply Thm. \ref{lb306} to the case that $f\in\Borb(\Cbb^L)$ and $g_1,\dots,g_L$ are the first $L$ coordinate functions of $\Cbb^N$ (i.e., $g_i$ sends $(p_1,\dots,p_N)\in\Cbb^N$ to $p_i$).
\end{proof}



We close this subsection with a functional-calculus description of eigenspaces.

\begin{pp}\label{lb317}
Let $T\in\fk L(\MH)$ be normal, and let $\lambda\in\Cbb$. Then $\chi_{\{\lambda\}}(T)$ is the projection onto $\Ker(T-\lambda)$.
\end{pp}


\begin{proof}
Since $\chi_{\{\lambda\}}=\chi_{\{\lambda\}}^2=\ovl{\chi_{\{\lambda\}}}$, the operator $\chi_{\{\lambda\}}(T)$ is a projection. It remains to prove that $\Ker(T-\lambda)$ equals the range of $\chi_{\{\lambda\}}(T)$.

For each $\xi\in\MH$, we compute that
\begin{align*}
\Vert (T-\lambda)\chi_{\{\lambda\}}(T)\xi\Vert^2=\int_\Cbb |z-\lambda|^2\chi_{\{\lambda\}}^2d\mu_\xi=0
\end{align*}
and hence $(T-\lambda)\chi_{\{\lambda\}}(T)\xi=0$. This proves $\Rng(\chi_{\{\lambda\}}(T))\subset\Ker(T-\lambda)$.


For each $\psi\in\Ker(T-\lambda)$, by \eqref{eq166},
\begin{align*}
0=\Vert (T-\lambda)\psi\Vert^2=\int_\Cbb |z-\lambda|^2d\mu_\psi
\end{align*}
and hence $\Cbb\setminus\lambda$ is $\mu_\psi$-null by Prop. \ref{lb310}. It follows that
\begin{align*}
\Vert \chi_{\{\lambda\}}(T)\psi-\psi\Vert^2=\int_\Cbb |\chi_{\{\lambda\}}-1|^2d\mu_\psi=\int_{\{\lambda\}} |\chi_{\{\lambda\}}-1|^2d\mu_\psi=0
\end{align*}
and hence $\chi_{\{\lambda\}}(T)\psi=\psi$. This proves that $\Ker(T-\lambda)\subset\Rng(\chi_{\{\lambda\}}(T))$.
\end{proof}


\subsubsection{Basic properties of joint spectra}

Determining joint spectra is often highly useful. For instance, knowing that the spectrum of a positive operator is contained in $\Rbb_{\geq0}$ allows us to use the properties of integrals of positive functions. In this subsection, we present some basic methods for characterizing joint spectra and illustrate them with examples.


\begin{pp}\label{lb307}
Let $1\leq L<N$. Then
\begin{align}
\Sp(T_1,\dots,T_N)\subset\Sp(T_1,\dots,T_L)\times\Sp(T_{L+1},\dots,T_N)
\end{align}
\end{pp}

By applying Prop. \ref{lb307} repeatedly, we obtain
\begin{align*}
\Sp(T_1,\dots,T_N)\subset\Sp(T_1)\times\cdots\times\Sp(T_N)
\end{align*}


\begin{proof}
Choose any $p\in\Cbb^L,q\in\Cbb^{N-L}$, and assume that $(p,q)$ is outside $\Sp(T_1,\dots,T_L)\times\Sp(T_{L+1},\dots,T_N)$. Then either $p$ is outside $\Sp(T_1,\dots,T_L)$ or $q$ is outside $\Sp(T_{L+1},\dots,T_N)$. In the previous case, there exists $U\in\Nbh_{\Cbb^L}(p)$ such that $\chi_U(T_1,\dots,T_L)=0$. By Cor. \ref{lb308}, we have
\begin{align*}
\chi_{U\times\Cbb^{N-L}}(T_1,\dots,T_N)=\chi_U(T_1,\dots,T_L)=0
\end{align*}
and hence $(p,q)\notin\Sp(T_1,\dots,T_N)$. The latter case can be addressed in the same way.
\end{proof}



To some extend, Prop. \ref{lb307} reduces the study of joint spectra to that of individual operators. The next proposition gives a particularly useful characterization of the spectrum of a single bounded normal operator.

\begin{df}
Let $T\in\fk L(\MH)$ be normal. The number $\lambda\in\Cbb$ is called an \textbf{approximate eigenvalue} \index{00@Approximate eigenvalue} of $T$ if one of the following (clearly) equivalent conditions holds:
\begin{enumerate}
\item[(1)] For each $\eps>0$ there exists a non-zero vector $\xi\in\MH$ such that
\begin{align*}
\Vert (T-\lambda)\xi\Vert\leq\eps\Vert\xi\Vert
\end{align*}
\item[(2)] There exists a sequence $(\xi_n)_{n\in\Zbb_+}$ of unit vectors in $\MH$ such that
\begin{align*}
\lim_n (T-\lambda)\xi_n=0
\end{align*}
\end{enumerate}
\end{df}


\begin{thm}\label{lb312}
Let $T\in\fk L(\MH)$ be normal. Let $\lambda\in\Cbb$. Then the following are equivalent:
\begin{enumerate}
\item[(1)] $\lambda\in\Sp(T)$.
\item[(2)] $\lambda$ is an approximate eigenvalue of $T$.
\end{enumerate}
\end{thm}


\begin{proof}
(1)$\Rightarrow$(2): Assume (1). Then for each $\eps>0$, we have $\chi_{U_\eps}(T)\neq0$, where $U_\eps=B_\Cbb(\lambda,\eps)$. Choose any non-zero $\xi\in\Rng(\chi_{U_\eps}(T))$, noting that $\xi=\chi_{U_\eps}(T)\xi$ because $\chi_{U_\eps}^2=\chi_{U_\eps}$. Let $f_\eps\in\Borb(\Cbb)$ be defined by $f_\eps(z)=(z-\lambda)\chi_{U_\eps}(z)$. Then $\Vert f_\eps\Vert_{l^\infty}\leq\eps$, and hence
\begin{align*}
\Vert (T-\lambda)\xi\Vert=\Vert (T-\lambda)\chi_{U_\eps}(T)\xi\Vert=\Vert f_\eps(T)\xi\Vert\leq \Vert f_\eps\Vert_{l^\infty}\cdot\Vert\xi\Vert=\eps\Vert\xi\Vert
\end{align*}
due to Prop. \ref{lb309}. This proves (2).

$\neg$(1)$\Rightarrow$$\neg$(2): Assume that $\lambda\notin\Sp(T)$. Since $\Sp(T)$ is compact, there exists $\eps>0$ such that $\Sp(T)\subset\Cbb\setminus U_\eps$ where $U_\eps=B_\Cbb(\lambda,\eps)$. For each $\xi\in\MH$, by \eqref{eq166} we have
\begin{align*}
\Vert(T-\lambda)\xi\Vert^2=\int_{\Sp(T)}|z-\lambda|^2d\mu_\xi=\int_{\Cbb\setminus U_\eps}|z-\lambda|^2d\mu_\xi\geq\eps^2\int_{\Cbb\setminus U_\eps}d\mu_\xi=\eps^2\Vert\xi\Vert^2
\end{align*}
Therefore, (2) is not true.
\end{proof}


\begin{exe}
Let $\lambda_\blt=(\lambda_1,\dots,\lambda_N)\in\Cbb^N$. Prove that $\lambda_\blt\in\Sp(T_\blt)$ iff $\lambda_\blt$ is a \textbf{approximate joint eigenvalue} \index{00@Approximate joint eigenvalue} of $T_\blt$, that is, there exists a sequence of unit vectors $(\xi_n)$ in $\MH$ such that
\begin{align*}
\lim_n (T_i-\lambda_i)\xi_n=0\qquad\text{for all }1\leq i\leq N
\end{align*}
Use this result to give an alternative proof of Prop. \ref{lb307}.
\end{exe}


\begin{eg}
Let $\lambda\in\Cbb$. One easily sees that $\lambda$ is the only approximate eigenvalue of $\lambda\cdot \idt$. Therefore $\Sp(\lambda\cdot\idt)=\lambda$.
\end{eg}

\begin{pp}\label{lb313}
Let $T\in\fk L(\MH)$. Then $T\geq0$ iff $\Sp(T)\subset\Rbb_{\geq0}$.
\end{pp}

\begin{proof}
Suppose that $T\geq0$. Choose any $\lambda\in\Cbb\setminus\Rbb_{\geq0}$. Then for any sequence $(\xi_n)$ of unit vectors we have
\begin{align*}
\bk{\xi_n|(T-\lambda)\xi_n}=\bk{\xi_n|T\xi_n}-\lambda=a_n-\lambda
\end{align*}
where $a_n\in\Rbb_{\geq0}$, and hence $a_n-\lambda\nrightarrow0$. Thus $\lambda$ is not an approximate eigenvalue of $T$. In view of Thm. \ref{lb311}, we conclude that $\Sp(T)\subset\Rbb_{\geq0}$.

Conversely, assume that $\Sp(T)\subset\Rbb_{\geq0}$. Then
\begin{align*}
\bk{\xi|T\xi}=\int_{\Sp(T)}z d\cdot\mu_\xi(z)\geq0
\end{align*}
for all $\xi\in\MH$, where $\mu_\xi$ is defined in Rem. \ref{lb297}. Thus $T\geq0$. 
\end{proof}



\begin{pp}\label{lb440}
Let $T\in\fk L(\MH)$. Then $T$ is self-adjoint iff $\Sp(T)\subset\Rbb$.
\end{pp}

\begin{proof}
This can be proved in a same way as in Thm. \ref{lb313}. Here, we provide a different argument.

Note that $T=T^*$ iff $(z-\ovl z)(T)=0$, iff $(z-\ovl z)(T)\xi=0$ for all $\xi$, iff
\begin{align*}
\int_\Cbb |z-\ovl z|^2d\mu_\xi\xlongequal{\eqref{eq166}}\Vert(z-\ovl z)(T)\xi\Vert^2
\end{align*}
equals zero for all $\xi$, iff (by Prop. \ref{lb310}) the set $\Cbb\setminus\Rbb=\{z-\ovl z\neq0\}$ is $\mu_\xi$-null for each $\xi$. This is equivalent to $\Rbb\subset\Supp(\mu_\xi)$ for all $\xi$, and hence equivalent to $\Sp(T)\subset\Rbb$ due to \eqref{eq167}.
\end{proof}



Recall from Exp. \ref{lb311} that unitary operators on $\MH$ are normal.

\begin{pp}\label{lb315}
Let $U\in\fk L(\MH)$ be normal. Then $U$ is unitary iff $\Sp(U)\subset\Sbb^1$.
\end{pp}

\begin{proof}
Suppose that $U$ is unitary. Choose any $\lambda\in\Cbb$ such that $|\lambda|\neq 1$. Then, for each sequence of unit vectors $(\xi_n)$ in $\MH$ we have
\begin{align*}
\Vert (U-\lambda)\xi_n\Vert\geq \Vert U\xi_n\Vert-\Vert\lambda\xi_n\Vert=1-|\lambda|
\end{align*}
which does not converge to $0$. Therefore, $\lambda$ is not an approximate eigenvalue of $U$. By Thm. \ref{lb312}, we conclude $\Sp(U)\subset\Sbb^1$.

Conversely, assume that $\Sp(U)\subset\Sbb^1$. Then $z^*z|_{\Sp(\Sbb^1)}=1$, and hence $U^*U=z(U)^*z(U)=z^*z(U)=1(U)=\idt$ by Rem. \ref{lb314}. Since $[U,U^*]=0$, we also have $UU^*=\idt$. It follows from Exp. \ref{lb311} that $U$ is unitary.
\end{proof}











\begin{comment}
\begin{df}
Let $V$ is an $\Fbb$-vector space $T\in\Lin(V)$. Let $\lambda\in\Fbb$. We say that $\xi\in V$ is an \textbf{$\pmb\lambda$-eigenvector} of $T$ if $T\xi=\lambda\xi$. If there exists a non-zero $\lambda$-eigenvector of $T$, we say that $\lambda$ is an \textbf{eigenvalue} of $T$. \index{00@Eigenvalues and eigenvectors}
\end{df}
\end{comment}









\subsection{Von Neumann's mean ergodic theorem}

In this section, we present an example that illustrates how the Borel functional calculus can be applied in practice. The results in this section will not be used elsewhere in this course.



\begin{thm}[\textbf{Von Neumann's mean ergodic theorem}]\label{lb321}
Let $U\in\fk L(\MH)$ be an isometry, equivalently, $U^*U=\idt$. Let $P$ be the projection onto $\Ker(\idt-U)$. Then
\begin{align}\label{eq169}
\lim_{n\rightarrow\infty}\frac 1{n}\sum_{k=0}^{n-1}U^k=P\qquad\text{in SOT}
\end{align}
\end{thm}

A particularly important case occurs when $\Ker(\idt-U)$ is one-dimensional, i.e., spanned by a unit vector $e\in\Ker(\idt-U)$. In that case, \eqref{eq169} reads
\begin{align}
\lim_{n\rightarrow\infty}\frac 1{n}\sum_{k=0}^{n-1}U^k\xi=e\cdot\bk{e|\xi}\qquad\text{for each }\xi\in\MH
\end{align}

\begin{proof}
Step 1. Let $X$ be a set whose cardinality, added by the cardinality of an orthonormal basis of $\Rng(U)^\perp$, is equal to the cardinality of $X$. There there exists a unitary map $V:l^2(X)\rightarrow \Rng(U)^\perp\oplus l^2(X)$, which can thus be extended to a unitary map
\begin{align*}
W: \MH\oplus l^2(X)\rightarrow\MH\oplus l^2(X)
\end{align*}
whose restriction to $\MH$ equals $U$. 

By Prop. \ref{lb315}, we have $\Sp(W)\subset\Sbb^1$. On $\Sbb^1$, the sequence of functions
\begin{align*}
f_n:=\frac 1n\sum_{k=0}^{n-1}z^k
\end{align*}
which equals $(1-z^n)/n(1-z)$ outside $\{1\}$, is uniformly bounded and converges pointwise to $\chi_{\{1\}}$. By DCT, for any finite Borel measure $\mu$ on $\Sbb^1$ we have
\begin{align*}
\lim_n\int_{\Sbb^1}|f_n-\chi_{\{1\}}|^2d\mu=0
\end{align*}
Therefore, by Thm. \ref{lb316}, 
\begin{align*}
\lim_n\frac 1{n}\sum_{k=0}^{n-1}W^k=Q\qquad\text{in SOT}
\end{align*}
where $Q:=\chi_{\{1\}}(W)$ is the projection of $\MH\oplus l^2(\Zbb)$ onto $\Ker(\idt-W)$ (cf. Prop. \ref{lb317}).\\[-1ex]

Step 2. According to Step 1, for each $\xi\in\MH$, the limit $\lim_n n^{-1}(1+\cdots +U^{n-1})\xi$ converges in $\MH$. In the case  $\xi\in\Ker(\idt-U)$, then $\xi\in\Ker(\idt-W)$, and hence this limit converges to $\xi$. In the case $\xi\perp\Ker(\idt-U)$, if we can prove that $\xi\perp\Ker(\idt-W)$, then this limit converges to $Q\xi=0$. Combining the two cases together, we obtain \eqref{eq169}.

Let us fix $\xi\in\MH$ orthogonal to $\Ker(\idt-U)$, and prove that $\xi\perp\Ker(\idt-W)$. Choose any $\psi+\eta\in \MH\oplus l^2(X)$ (where $\psi\in\MH$ and $\eta\in l^2(X)$), and assume that $W(\psi+\eta)=\psi+\eta$. Using the notation in Step 1, we have $\psi+\eta=U\psi+V\eta$. Let $E$ be the projection of $\MH\oplus l^2(X)$ onto $\MH$. Then
\begin{align*}
\psi=E(\psi+\eta)=EU\psi+EV\eta=U\psi+EV\eta
\end{align*}
Since $V$ has range in $\Rng(U)^\perp\oplus l^2(X)$, we have $EV\eta\in\Rng(U)^\perp$, and hence $U\psi\perp EV\eta$. It follows from the Pythagorean identity that
\begin{align*}
\Vert\psi\Vert^2=\Vert U\psi\Vert^2+\Vert EV\eta\Vert^2
\end{align*}
Since $U$ is an isometry, we must have $\Vert EV\eta\Vert^2=0$. Thus $\psi=U\psi$, and hence $\psi\in\Ker(\idt-U)$. We conclude that
\begin{align*}
\bk{\xi|\psi+\eta}=\bk{\xi|\eta}\subset\bk{\xi|\Ker(\idt-U)}=\{0\}
\end{align*}
This finishes the proof that $\xi\perp\Ker(\idt-W)$.
\end{proof}




\begin{eg}
Let $(X,\fk M,\mu)$ be a \textbf{probability space}, \index{00@Probability} i.e., a measure space satisfying $\mu(X)=1$. Let $\phi:X\rightarrow X$ be a \textbf{measure preserving transform}. \index{00@Measure preserving transform} This means that $\phi$ is a measurable map satisfying $\phi_*\mu=\mu$, that is, $\mu(\phi^{-1}(A))=\mu(A)$ for each measurable $A\subset X$ (cf. Def. \ref{lb319}). Then
\begin{align}\label{eq170}
U:L^2(X,\mu)\rightarrow L^2(X,\mu)\qquad f\mapsto f\circ\phi
\end{align}
is an isometry, since for all $f\in L^2(X,\mu)$ we have
\begin{align*}
\bk{Uf|Uf}=\int_X |f\circ\phi|^2 d\mu=\int_X|f|^2d\phi_*\mu=\int_X|f|^2d\mu=\bk{f|f}
\end{align*}

Now, assume that the measure preserving $\phi:X\rightarrow X$ is \textbf{ergodic} \index{00@Ergodic transform}, which means that the only measurable set $A\subset X$ satisfying \footnote{For any two sets $A,B$, the symmetric difference $A\triangle B$ is $(A\setminus B)\cup (B\setminus A)$.}
\begin{align*}
\mu(\phi^{-1}(A)\triangle A)=0
\end{align*}
must satisfy either $\mu(A)=0$ or $\mu(X\setminus A)=0$. This implies that $\Ker(\idt-U)=\Span\{1\}$, cf. Exe. \ref{lb320}. Thus, for each $f\in L^2(X,\mu)$, since $\bk{1|f}=\int_Xfd\mu$, it follows from the mean ergodic Thm. \ref{lb321} that
\begin{align*}
\lim_{n\rightarrow\infty}\frac {1}{n}\sum_{k=0}^{n-1}f\circ\underbrace{\phi\circ\cdots\circ\phi}_{k\text{ times}}=\int_Xfd\mu
\end{align*}
where the LHS converges to the RHS in the $L^2$-norm.  \hqed
\end{eg}


\begin{exe}\label{lb320}
Let $(X,\fk M,\mu)$ be a probability space. Let $\phi:X\rightarrow X$ be a measure preserving transform. Prove that $\phi$ is ergodic iff the map $U$ defined in \eqref{eq170} satisfies $\Ker(\idt-U)=\Span\{1\}$ .
\end{exe}

\begin{proof}[Hint]
``$\Leftarrow$'': If $\mu(\phi^{-1}(A)\triangle A)=0$ then $\chi_A\in\Ker(\idt-U)$.

``$\Rightarrow$'': Show that if $f,g:X\rightarrow\Cbb$ are measurable functions satisfying $f=g$ a.e. in $\mu$, then $h\circ f=h\circ g$ a.e. in $\mu$. Let $f\in\Ker(\idt-U)$, that is, $f=f\circ\phi$ a.e.. Assume WLOG that $f$ is real-valued. Use the fact that $\chi_\Omega\circ f=\chi_\Omega\circ f\circ\phi$ a.e. for any open $\Omega\subset\Cbb$ to conclude that the essential range of $f$ (cf. Def. \ref{lb319}) is a single-point set.
\end{proof}



\subsection{The multiplication-operator version of the spectral theorem}\label{lb426}


In this section, we introduce the final version of the Spectral Theorem, the multiplication operator version; see Thm. \ref{lb330}. For students already familiar with measure theory, this version is not only the most accessible but also the one most easily extended to the spectral theory of unbounded operators.

Historically, the multiplication-operator version appeared later for several reasons: First, measure theory was not yet fully developed when the earlier versions of the theorem were established. Second, the spectral decomposition in this setting is not unique. Third, several of the ideas underlying this version grew out of representation theory and operator algebras. Finally, unlike the earlier formulations, this version adopts most completely the perspective of linear operators rather than that of bilinear or sesquilinear forms (cf. the paradigm shift \eqref{eq147b}). One drawback of this approach is that, because of this last reason, the proof by itself does not make clear how the Riesz representation theorem interacts with the rest of the argument, since the bilinear/sesquilinear form framework is more naturally suited to the Riesz representation theorem; cf. Subsec. \ref{lb132}.

Informally, the multiplication-operator version of the Spectral Theorem asserts that every bounded normal operator is unitarily equivalent to a multiplication operator on a direct sum of $L^2$-spaces. A detailed statement and explanation will be given in the following subsections.


\subsubsection{Infinite direct sums of Hilbert spaces}

\begin{df}
Let $(V_\alpha)_{\alpha\in\SI}$ be a family of $\Fbb$-vector space. Then the $\Fbb$-vector space structure on \textbf{direct product} \index{00@Direct product vector space} $\pmb{\prod_{\alpha\in\SI}V_\alpha}$ is defined componentwisely. Namely, for each $(\xi_\alpha)_{\alpha\in\SI},(\eta_\alpha)_{\alpha\in\SI}$ in $\prod_{\alpha\in\SI}\MH_\alpha$ and $\lambda\in\Cbb$ we have
\begin{align*}
(\xi_\alpha)_{\alpha\in\SI}+(\eta_\alpha)_{\alpha\in\SI}=(\xi_\alpha+\eta_\alpha)_{\alpha\in\SI}\qquad 
\end{align*}
\end{df}






\begin{df}
Let $(\MH_\alpha)_{\alpha\in\SI}$ be a family of Hilbert spaces. The \textbf{(orthogonal) Hilbert space direct sum} \index{00@Hilbert space direct sum} of $(\MH_\alpha)_{\alpha\in\SI}$, denoted by $\pmb{\bigoplus_{\alpha\in\SI}\MH_\alpha}$, the subspace consisting of all
\begin{align*}
(\MH_\alpha)_{\alpha\in\SI}=\Big\{(\xi_\alpha)_{\alpha\in\SI}\in\prod_{\alpha\in\SI}\MH_\alpha:\sum_{\alpha\in\SI}\Vert\xi_\alpha\Vert^2<+\infty\Big\}
\end{align*}
We write any $\xi=(\xi_\alpha)_{\alpha\in\SI}$ in $\bigoplus_{\alpha\in\SI}\MH_\alpha$ as $\pmb{\oplus_{\alpha\in\SI}\xi_\alpha}$. Then $(\MH_\alpha)_{\alpha\in\SI}$ is equipped with the inner product
\begin{align}\label{eq171}
\bigbk{\oplus_{\alpha\in\SI}\eta_\alpha\big|\oplus_{\alpha\in\SI}\xi_\alpha }=\sum_{\alpha\in\SI}\bk{\eta_\alpha|\xi_\alpha}
\end{align}
and is a Hilbert space. We view each $\MH_\alpha$ as an inner product subspace of $\bigoplus_{\alpha\in\SI}\MH_\alpha$ by identifying each $\xi_\alpha\in\MH_\alpha$ with the element of $\bigoplus_{\alpha\in\SI}\MH_\alpha$ whose $\alpha$-component is $\eta_\alpha$ and whose other components are zero.
\end{df}

\begin{proof}[Explanation]
For each finite set $I\subset\SI$, 
\begin{align*}
&\sum_{\alpha\in I}|\bk{\eta_\alpha|\xi_\alpha}|\leq\sum_{\alpha\in I}\Vert\eta_\alpha\Vert\cdot\Vert\xi_\alpha\Vert\leq\Big(\sum_{\alpha\in I}\Vert\eta_\alpha\Vert^2\Big)^{\frac 12}\cdot \Big(\sum_{\alpha\in I}\Vert\xi_\alpha\Vert^2\Big)^{\frac 12}\\
\leq&\Big(\sum_{\alpha\in\SI}\Vert\eta_\alpha\Vert^2\Big)^{\frac 12}\cdot \Big(\sum_{\alpha\in\SI}\Vert\xi_\alpha\Vert^2\Big)^{\frac 12}=:C
\end{align*}
Applying $\sup_{I\in\fin(2^\SI)}$, we obtain $\sum_{\alpha\in \SI}|\bk{\eta_\alpha|\xi_\alpha}|\leq C<+\infty$. Therefore, the RHS of \eqref{eq171} converges absolutely (and hence converges, cf. Prop. \ref{lb234}).

To prove that $\MH:=\bigoplus_{\alpha\in\SI}\MH_\alpha$ is a Hilbert space, one can either show that $\MH$ is Cauchy-complete, or show that any bounded linear functional $\Lambda:\MH\rightarrow\Cbb$ is realized by a pairing with some element of $\MH$, cf. Thm. \ref{lb135}. We follow the second approach. The restriction of $\Lambda$ to each $\MH_\alpha$ is a bounded linear functional. Hence, by Thm. \ref{lb135}, there exists $\eta_\alpha\in\MH_\alpha$ such that
\begin{align*}
\Lambda(\xi_\alpha)=\bk{\eta_\alpha|\xi_\alpha}\qquad\text{for any }\xi_\alpha\in\MH_\alpha
\end{align*} 
Moreover, for each $I\in\SI$, noting that $\sum_{\alpha\in I}\eta_\alpha$ equals $\oplus_{\alpha\in I}\eta_\alpha$, we have
\begin{align*}
\sum_{\alpha\in I}\Vert\eta_\alpha\Vert^2=\Lambda\big(\oplus_{\alpha\in I}\eta_\alpha\big)\leq\Vert\Lambda\Vert\cdot \big\Vert\oplus_{\alpha\in I}\eta_\alpha\big\Vert=\Vert\Lambda\Vert\cdot \Big(\sum_{\alpha\in I}\Vert\eta_\alpha\Vert^2\Big)^{\frac 12}
\end{align*}
and hence $\sum_{\alpha\in I}\Vert\eta_\alpha\Vert^2\leq\Vert\Lambda\Vert^2$. Applying $\sup_{I\in\fin(2^\SI)}$, we obtain
\begin{align*}
\sum_{\alpha\in\SI}\Vert\eta_\alpha\Vert^2\leq\Vert\Lambda\Vert^2<+\infty
\end{align*}
This proves that $\eta:=\oplus_{\alpha\in\SI}\eta_\alpha$ belongs to $\MH$. Clearly $\Lambda$ equals the pairing with $\eta$ when restricted to the subspace spanned by all $\MH_\alpha$ where $\alpha\in\SI$. Since this subspace is dense, we conclude from Cor. \ref{lb44} that $\Lambda$ equals the pairing with $\eta$ on the whole space $\MH$.
\end{proof}


\begin{rem}\label{lb333}
Let $(\xi_\alpha)_{\alpha\in\SI}$ be an element of $\bigoplus_{\alpha\in\SI}\MH_\alpha$. Since $\sum_{\alpha\in\SI}\Vert\xi_\alpha\Vert^2<+\infty$, by Prop. \ref{lb325}, we have $\xi_\alpha=0$ for all but countably many $\alpha$.
\end{rem}



\begin{df}
Let $(\MH_\alpha)_{\alpha\in\SI}$ and $(\MK_\alpha)_{\alpha\in\SI}$ be families of Hilbert spaces. Let $(T_\alpha)_{\alpha\in\SI}$ be a family where $T_\alpha\in\fk L(\MH_\alpha,\MK_\alpha)$ for each $\alpha\in\SI$. Assume that
\begin{align*}
\sup_{\alpha\in\SI}\Vert T_\alpha\Vert<+\infty
\end{align*}
Then \index{T@$\oplus_{\alpha\in\SI}T_\alpha$}
\begin{gather*}
\pmb{\oplus_{\alpha\in\SI}T_\alpha}:\bigoplus_{\alpha\in\SI}\MH_\alpha\rightarrow\bigoplus_{\alpha\in\SI}\MK_\alpha\qquad \oplus_{\alpha\in\SI}\xi_\alpha\mapsto\oplus_{\alpha\in\SI}T_\alpha\xi_\alpha
\end{gather*}
is clearly a bounded linear map whose adjoint is $\oplus_{\alpha\in\SI}T_\alpha^*$. 
\end{df}


\subsubsection{Orthogonal decompositions of Hilbert spaces and bounded linear operators}

Let $\MH$ be a Hilbert space. Recall from Exp. \ref{lb148} that a Hilbert subspace of $\MH$ refers to a closed (equivalently, complete) linear subspace of $\MH$.

The following example shows that the direct sum of an orthogonal family of Hilbert subspaces of $\MH$ can be viewed as a Hilbert subspace of $\MH$.

\begin{eg}\label{lb323}
Let $(\MH_\alpha)_{\alpha\in\SI}$ be a family of \textit{mutually-orthogonal} Hilbert subspaces of $\MH$. Then we have a linear isometry
\begin{align}\label{eq173}
U:\bigoplus_{\alpha\in\SI}\MH_\alpha\rightarrow\MH\qquad  \oplus_{\alpha\in\MH}\xi_\alpha\mapsto\sum_{\alpha\in\SI}\xi_\alpha
\end{align}
where $\sum_{\alpha\in\SI}\xi_\alpha$ is an unordered sum of mutually orthogonal vectors, and hence converges in $\MH$ due to Thm. \ref{lb129}-(b). It follows that 
\begin{align}\label{eq174}
\Rng(U)=\Cl_\MH\Big(\sum_{\alpha\in\SI}\MH_\alpha\Big)
\end{align}
since $\Rng(U)$ contains the span $\sum_{\alpha\in\SI}\MH_\alpha$ as dense subspace. 

We can therefore view $\bigoplus_{\alpha\in\SI}\MH_\alpha$ as a complete (equivalently, closed, cf. Prop. \ref{lb324}) linear subspace of $\MH$ by identifying the elements on the two sides via $U$. In that case, we have
\begin{align}\label{eq175}
\bigoplus_{\alpha\in\SI}\MH_\alpha=\Cl_\MH\Big(\sum_{\alpha\in\SI}\MH_\alpha\Big)
\end{align}
due to \eqref{eq174}.   \hqed
\end{eg}


\begin{rem}
In Exp. \ref{lb323}, let $P_\alpha\in\fk L(\MH)$ be the projection of $\MH$ onto $\MH_\alpha$. Note that by Cor. \ref{lb322}, for each $I\in\fin(2^\SI)$, the sum $\sum_{\alpha\in I}P_\alpha$ is the projection onto $\sum_{\alpha\in I}\MH_\alpha$. Therefore, 
\begin{align*}
\Big(\sum_{\alpha\in I}P_\alpha\Big)_{I\in\fin(2^\SI)}
\end{align*}
is an increasing net of projections. It follows from Thm. \ref{lb264} that the \textbf{sum of projections} \index{00@Sum of projections $\sum_\alpha P_\alpha$}
\begin{gather*}
\pmb{\sum_{\alpha\in\SI}P_\alpha}:=\lim_{I\in\fin(2^\SI)}\sum_{\alpha\in I}P_\alpha
\end{gather*}
converges in SOT to the projection onto the range of \eqref{eq173}. In particular,
\begin{align*}
\sum_{\alpha\in\SI}P_\alpha=\id_\MH\qquad\Longleftrightarrow\qquad \bigoplus_{\alpha\in\SI}\MH_\alpha=\MH
\end{align*}
\end{rem}


\begin{df}
Let $\fk S\subset\fk L(\MH)$. Let $V$ be a linear subspace of $\MH$. We say that $V$ is \textbf{$\pmb{\fk S}$-invariant} \index{00@Invariant subspace} if $TV\subset V$ for each $T\in\fk S$. In that case, $T$ restricts to
\begin{align*}
T|_V\in\fk L(V)
\end{align*}
Similarly, if $(\pi,\MH)$ is a unitary representation of a unital *-algebra $\scr A$, we say that a linear subspace $V$ is \textbf{\pmb{$\scr A$}-invariant} if $V$ is $\pi(\scr A)$-invariant, i.e., $\pi(x)V\subset V$ for each $x\in\scr A$.
\end{df}


\begin{eg}\label{lb328}
Let $V\subset\MH$ be a linear subspace. Suppose that $\fk S\subset\fk L(\MH)$ and $V$ is $\fk S$-invariant, then $V^\perp$ is invariant under $\fk S^*=\{T^*:T\in\fk S\}$. Suppose that $(\pi,\MH)$ is a unitary representation of a unital *-algebra $\scr A$ and $V$ is $\scr A$-invariant, then $V^\perp$ is $\scr A$-invariant.
\end{eg}


\begin{proof}
To prove that $V^\perp$ is $\fk S^*$-invariant, we compute that
\begin{align*}
\bk{V|T^*V^\perp}=\bk{TV|V^\perp}\subset\bk{V|V^\perp}=\{0\}
\end{align*}
for each $T\in\fk S$, and hence $\fk S^*V^\perp\subset V^\perp$. Thus, $V^\perp$ is invariant under $\pi(\scr A)^*=\pi(\SA^*)=\pi(\SA)$.
\end{proof}


\begin{eg}\label{lb326}
Let $(\MH_\alpha)_{\alpha\in\SI}$ be a family of mutually-orthogonal Hilbert subspaces of $\MH$. Let $T\in\fk L(\MH)$. Assume that each $\MH_\alpha$ is $T$-invariant. If we view $\bigoplus_{\alpha\in\SI}\MH_\alpha$ as a Hilbert subspace of $\MH$, then $\bigoplus_{\alpha\in\SI}\MH_\alpha$ is $T$-invariant, and
\begin{align}\label{eq176}
T\big|_{\bigoplus_{\alpha\in\SI}\MH_\alpha}=\oplus_{\alpha\in\SI}(T|_{\MH_\alpha})
\end{align}
as bounded linear operators on $\bigoplus_{\alpha\in\SI}\MH_\alpha$.
\end{eg}

\begin{proof}
By Cor. \ref{lb325} and \eqref{eq175}, we have
\begin{align*}
T\Big(\bigoplus_\alpha\MH_\alpha\Big)=T\Big(\ovl{\sum_\alpha\MH_\alpha}\Big)\subset \ovl{T\Big(\sum_\alpha\MH_\alpha\Big)}\subset\ovl{\sum_\alpha\MH_\alpha}=\bigoplus_\alpha\MH_\alpha
\end{align*}
This proves that $\bigoplus_\alpha\MH_\alpha$ is $T$-invariant. Since \eqref{eq176} holds when restricted to $\sum_\alpha\MH_\alpha$, it holds on $\bigoplus_\alpha\MH_\alpha$ due to Thm. \ref{lb31}.
\end{proof}



An especially important case of Exp. \ref{lb326} is when $\sum_\alpha\MH_\alpha$ is dense in $\MH$. In this situation, \eqref{eq176} reads
\begin{align*}
T=\oplus_{\alpha\in\SI}(T|_{\MH_\alpha})
\end{align*}
which can be interpreted as writing $T$ in block-diagonal form.



\subsubsection{Orthogonal decompositions of unitary representations}



Fix a unital $*$-algebra $\SA$. In this subsection, we explain how a unitary representation of $\SA$ can be decomposed into smaller components. 


\begin{df}
Let $(\pi_1,V_1)$ and $(\pi_2,V_2)$ be pre-unitary representations of $\SA$. A bounded linear map $\Phi:V_1\rightarrow V_2$ is called a \textbf{homomorphism} \index{00@Homomorphism of pre-unitary representations} if 
\begin{align*}
\Phi\pi_1(x)=\pi_2(x)\Phi\qquad\text{for each }x\in\SA
\end{align*}
A unitary homomorphism is called a \textbf{unitary equivalence}. \index{00@Unitary equivalence} If a unitary equivalence between $(\pi_1,V_1)$ and $(\pi_2,V_2)$ exists, we say that $(\pi_1,V_1)$ and $(\pi_2,V_2)$ are \textbf{unitarily equivalent}.
\end{df}


To simplify discussions, in the following, we focus on unitary representations.


\begin{df}
Let $(\pi,\MH)$ be a unitary representation of $\SA$. Suppose that $\MK$ is an $\scr A$-invariant Hilbert subspace of $\MH$. Then $(\pi|_\MK,\MK)$ is also a unitary representation of $\SA$, where
\begin{align*}
\pi|_\MK:\SA\rightarrow\fk L(\MK)\qquad x\mapsto \pi(x)|_\MK
\end{align*}
We say that $(\pi|_\MK,\MK)$ is a \textbf{subrepresentation} \index{00@subrepresentation} of $(\pi,\MH)$.
\end{df}




\begin{df}
Let $(\pi_\alpha,\MH_\alpha)_{\alpha\in\SI}$ be a family of unitary representations of $\SA$ satisfying
\begin{align}\label{eq177}
\sup_{\alpha\in\SI}\Vert\pi_\alpha(x)\Vert<+\infty\qquad\text{for all }x\in\SA
\end{align}
Then $(\oplus_{\alpha\in\SI}\pi_\alpha,\bigoplus_{\alpha\in\SI}\MH_\alpha)$ is clearly a unitary representation of $\SA$, where
\begin{align*}
\oplus_{\alpha\in\SI}\pi_\alpha:\SA\rightarrow\fk L\Big(\bigoplus_{\alpha\in\SI}\MH_\alpha\Big)\qquad x\mapsto \oplus_{\alpha\in\SI}\pi_\alpha(x)
\end{align*}
We call $(\oplus_{\alpha\in\SI}\pi_\alpha,\bigoplus_{\alpha\in\SI}\MH_\alpha)$ the \textbf{direct sum representation} \index{00@Direct sum representation} of $(\pi_\alpha,\MH_\alpha)_{\alpha\in\SI}$.
\end{df}

\begin{eg}
Suppose that $\SA$ is a unital *-subalgebra of $l^\infty(X)$ where $X$ is a set, and suppose that each $f\in\SA$ with $f\geq0$ can be written as $f=g^*g$ for some $g\in\SA$. Let $(\pi_\alpha,\MH_\alpha)_{\alpha\in\SI}$ be a family of unitary representations of $\SA$. By Prop. \ref{lb272}, each $(\pi_\alpha,\MH_\alpha)$ is positive. Therefore, by Prop. \ref{lb294}, we have $\Vert\pi_\alpha(f)\Vert\leq \Vert f\Vert_{l^\infty}$ for each $f\in\SA$. Thus \eqref{eq177} is satisfied.
\end{eg}


\begin{eg}\label{lb327}
Let $(\pi,\MH)$ be a unitary representation of $\SA$. Let $(\MH_\alpha)_{\alpha\in\SI}$ be a family of mutually-orthogonal $\SA$-invariant Hilbert subspaces of $\MH$. Viewing $\bigoplus_{\alpha\in\SI}\MH_\alpha$ as a $\SA$-invariant Hilbert subspace of $\MH$ (cf. Exp. \ref{lb326}), the subrepresentation $(\pi|_{\bigoplus_{\alpha\in\SI}\MH_\alpha},\bigoplus_{\alpha\in\SI}\MH_\alpha)$ is equal to the direct sum representation of $(\pi|_{\MH_\alpha},\MH_\alpha)_{\alpha\in\SI}$. 

In the important special case where $\sum_{\alpha\in\SI}\MH_\alpha$ is dense in $\MH$, we therefore have
\begin{align}\label{eq178}
(\pi,\MH)=\bigoplus_{\alpha\in\SI}(\pi|_{\MH_\alpha},\MH_\alpha)
\end{align}
which is abbreviated to $\MH=\bigoplus_{\alpha\in\SI}\MH_\alpha$. In this case, we say that $(\pi,\MH)$ is the \textbf{(orthogonal) direct sum} \index{00@Orthogonal direct sum of subrepresentations} of the family of subrepresentations $(\pi_\alpha,\MH_\alpha)_{\alpha\in\SI}$, or that $(\pi_\alpha,\MH_\alpha)_{\alpha\in\SI}$ is an \textbf{orthogonal decomposition} \index{00@Orthogonal decomposition} of $\MH$.  \hqed
\end{eg}







\begin{df}
Let $(\pi,\MH)$ be a unitary representation. A vector $\xi\in \MH$ is called a \textbf{cyclic vector} \index{00@Cyclic vectors} if the subspace $\scr A\xi$ is dense in $\MH$. A unitary representation admitting a cyclic vector is called a \textbf{cyclic representation}. \index{00@Cyclic unitary representation} A subrepresentation admitting a cyclic vector is called a \textbf{cyclic subrepresentation} \index{00@Cyclic subrepresentation}.
\end{df}


\begin{pp}\label{lb329}
Let $(\pi,\MH)$ be a unitary representation of $\SA$. Then $(\pi,\MH)$ is an orthogonal direct sum of cyclic subrepresentations. 
\end{pp}


In other words, there exists a densely-spanning family $(\MH_\alpha)_{\alpha\in\SI}$ of $\SA$-invariant Hilbert subspaces of $\MH$ such that each $\MH_\alpha$ is cyclic.

\begin{proof}
Assume WLOG that $\MH\neq0$. Let $\SF$ be the set of all $\SI\in 2^\MH$ where $\SI$ is a set of mutually-orthogonal non-zero cyclic subrepresentations of $\MH$. Then $(\SF,\subset)$ is a partially ordered set. Clearly every totally ordered subset of $\SF$ has an upper bound in $\SF$ (defined by taking union). By Zorn's lemma, there exists a maximal element $\SI\in\SF$. 

Let us prove that $(\MK)_{\MK\in\SI}$ is densely-spanning. Suppose not, then by Cor. \ref{lb151}, $\mc L:=\big(\sum_{\MK\in\SI}\MK\big)^\perp$ is a non-zero Hilbert subspace of $\MH$---the non-zeroness follows from the fact that $\mc L^\perp\neq\MH$. Since $\sum_{\MK\in\SI}\MK$ is $\SA$-invariant, by Exp. \ref{lb328}, $\mc L$ is $\SA$-invariant. Choose any non-zero $\xi\in\mc L$. Then $\SI\cup\{\ovl{\SA\xi}\}$ belongs to $\SF$ and is strictly larger than $\SI$, contradicting the maximality of $\SI$.
\end{proof}


\begin{rem}
If $\MH$ is separable, Prop. \ref{lb329} can be proved by induction, avoiding the use of Zorn’s lemma. To see this, choose a countable sequence of vectors $\xi_1,\xi_2,\dots$ spanning a dense subspace of $\MH$. Let $\psi_1=\xi_1$. Suppose that $\psi_n$ has been picked. Let $P_n$ be the projection onto the closure of $\sum_{j=1}^n\SA\psi_j$. Let $\psi_{n+1}=\xi_{n+1}-P_n\xi_{n+1}$. We leave it to the reader to check that $(\pi,\MH)$ has orthogonal decomposition
\begin{align*}
\MH=\bigoplus_n \ovl{\SA\psi_n}
\end{align*}
\end{rem}



\subsubsection{Classification of cyclic normal representations of $\Borb(X)$}

\begin{eg}
Let $(X,\mu)$ be a measure space. Recall from the Riesz-Fischer Thm. \ref{lb26}, $L^2(X,\mu)$ is a Hilbert space. Then
\begin{subequations}\label{eq179}
\begin{gather}\label{eq179a}
\Borb(X)\rightarrow\fk L(L^2(X,\mu))\qquad f\mapsto \Mbf_f
\end{gather}
is a normal unitary representation of $\Borb(X)$, where
\begin{align}\label{eq179b}
\Mbf_f:L^2(X,\mu)\rightarrow L^2(X,\mu)\qquad \xi\mapsto f\xi
\end{align}
\end{subequations}
is called the \textbf{multiplication operator} of $f$. \index{00@Multiplication operator $\Mbf_f$} \index{Mf@$\Mbf_f$, the multiplication operator} The representation $(\Mbf,\Borb(X))$ (abbreviated to $L^2(X,\mu)$) is called the \textbf{multiplication representation} \index{00@Multiplication representation} of $\Borb(X)$ with respect to $\mu$.
\end{eg}

\begin{proof}[Proof of normality]
Let $(f_n)_{n\in\Zbb_+}$ be an increasing sequence in $\Borb(X,\Rbb_{\geq0})$ converging pointwise to $f\in\Borb(X,\Rbb_{\geq0})$. Then for each $\xi\in L^2(X,\mu)$, the sequence $(f_n|\xi|^2)_{n\in\Zbb_+}$ is increasing and converging pointwise fo $f|\xi|^2$, and hence
\begin{align*}
\lim_n\bk{\xi|\Mbf_{f_n}\xi}=\lim_n\int_X f_n|\xi|^2d\mu=\int_Xf|\xi|^2d\mu=\bk{\xi|\Mbf_f\xi}
\end{align*}
due to MCT.
\end{proof}



\begin{pp}\label{lb332}
Let $X$ be a topological space. Let $(\pi,\MH)$ be a normal unitary representation of $\Borb(X)$. Let $\psi\in\MH$. Then the following are equivalent.
\begin{enumerate}
\item[(1)] $\psi$ is a cyclic vector.
\item[(2)] There exists a finite Borel measure $\mu:\fk B_X\rightarrow[0,+\infty]$ together with a unitary equivalence
\begin{align*}
\Phi:(\pi,\MH)\xlongrightarrow{\simeq}(\Mbf,L^2(X,\mu))
\end{align*}
satisfying $\Phi\psi=1$.
\end{enumerate}
\end{pp}


\begin{proof}
(2)$\Rightarrow$(1): Assume (2). Then we may well assume that $(\pi,\MH)=(\Mbf,L^2(X,\mu))$ (where $\mu$ is a finite Borel measure) and $\psi=1$. Then $\pi(\Borb(X))\psi$ equals $L^\infty(X,\mu)$ (viewed as a subspace of $L^2(X,\mu)$). Since simple functions are dense in $L^2(X,\mu)$, the space $L^\infty(X,\mu)$ is also dense in $L^2(X,\mu)$. Therefore $\psi$ is a cyclic vector. This proves (1).

(1)$\Rightarrow$(2): Assume (1). Since $(\pi,\MH)$ is normal, for each $f\in\Borb(X)$ we have
\begin{align*}
\bk{\psi|\pi(f)\psi}=\int_X fd\mu_\psi
\end{align*}
where $\mu$ is the finite Borel measure associated to $\xi$, cf. Rem. \ref{lb297}. Let $\mu=\mu_\psi$. Then for each $f,g\in\Borb(X)$ we have
\begin{align}\label{eq180}
\bk{\pi(f)\psi|\pi(g)\psi}=\bk{\psi|\pi(\ovl fg)\psi}=\int_X\ovl fgd\mu=\bk{1|\Mbf_{\ovl f}\Mbf_g1}=\bk{\Mbf_f1|\Mbf_g1}
\end{align}
It follows from the following Lem. \ref{lb368} that there is a unique unitary map
\begin{align*}
\Phi:\MH=\ovl{\Borb(X)\psi}\longrightarrow L^2(X,\mu)
\end{align*}
sending $\pi(f)\psi$ to $f=\Mbf_f1$; in particular, $\Phi\psi=1$.

For each $f,g\in\Borb(X)$, we compute that
\begin{align*}
\Phi\pi(f)\pi(g)\psi=\Phi\pi(fg)\psi=fg=\Mbf_fg=\Mbf\Phi \pi(g)\psi
\end{align*}
Therefore, the bounded linear operators $\Phi\pi(f)$ and $\Mbf_f\Phi$ agree on $\Borb(X)\psi$, and hence on $\MH$ due to the continuity. Thus $\Phi$ is a homomorphism.
\end{proof}


\begin{lm}\label{lb368}
Let $(\xi_\alpha)_{\alpha\in\SI}$ be a densely spanning family in an inner product space $V$. Let $(\eta_\alpha)_{\alpha\in\SI}$ be a family in a Hilbert space $\MK$. Suppose that
\begin{align}\label{eq189}
\bk{\xi_\alpha|\xi_\beta}=\bk{\eta_\alpha|\eta_\beta}\qquad\text{for each }\alpha,\beta\in\SI
\end{align}
Then there exists a unique linear isometry $\Phi:V\rightarrow \MK$ sending each $\xi_\alpha$ to $\eta_\alpha$. Moreover, if $V$ is a Hilbert space and $(\eta_\alpha)_{\alpha\in\SI}$ spans a dense subspace of $\MK$, then $\Phi$ is unitary.
\end{lm}


\begin{proof}
The uniqueness is obvious. Let us prove the existence. For each finite sum $\sum_\alpha c_\alpha\xi_\alpha$ (where $c_\alpha\in\Cbb$), we have $\Vert\sum_\alpha c_\alpha\xi_\alpha=\Vert\sum_\alpha\eta_\alpha\Vert$ due to \eqref{eq189}. Therefore, if we let $V_0=\Span\{\xi_\alpha:\alpha\in\SI$, then we have a well-defined linear map $\Phi:V_0\rightarrow W$ sending each $\xi_\alpha$ to $\eta_\alpha$. Moreover, by \eqref{eq189}, the map $\Phi$ is a linear isometry; in particular, it is bounded. Since $\MK$ is complete, by Thm. \ref{lb31}, $\Phi$ can be extended to a bounded linear map $\Phi:V\rightarrow\MK$. Since $\Vert\Phi\xi\Vert=\Vert\xi\Vert$ holds for all $\xi\in V_0$, by the continuity of $\Phi$, it follows that $\Vert\Phi\xi\Vert=\Vert\xi\Vert$ holds for all $\xi\in V$. Thus $\Phi:V\rightarrow\MK$ is a linear isometry.

That $\Phi$ is surjective when $V$ is a Hilbert space follows from the following Lem. \ref{lb367}.
\end{proof}


\begin{lm}\label{lb367}
Let $T:V\rightarrow W$ be a bounded linear map between normed vector spaces, where $V$ is complete. Assume that there exists $C\in\Rbb_{>0}$ such that
\begin{align}\label{eq190}
\Vert T\xi\Vert\geq C\Vert\xi\Vert\qquad\text{for all }\xi\in V
\end{align}
Then $T(V)=W$ provided that $T(V)$ is dense in $W$.
\end{lm}


\begin{proof}[First proof]
By \eqref{eq190}, we have $T\xi=0\Rightarrow\xi=0$. Therefore $T$ is injective. Let $S:T(V)\rightarrow V$ be its inverse. Condition \eqref{eq190} implies that $S$ is bounded. Therefore, since $V$ is complete, by Thm. \ref{lb31}, $S$ can be extended to a bounded linear map $\wtd S:W\rightarrow V$. Since $TS=\id_{T(V)}$, we have $T\wtd S|_{T(V)}=\id_{T(V)}$, and hence $TS=\id_W$ by the continuity of $T$ and $S$. This proves that $T$ is surjective.
\end{proof}

This proof makes explicit how the Cauchy completeness is used as a codomain condition (cf. Subsec. \ref{lb141}), although it initially appears to be a domain property. We now present a different argument.

\begin{proof}[Second proof]
Since any Cauchy-complete dense subset of $W$ is $W$ itself (cf. Prop. \ref{lb324}), it suffices to show that $T(V)$ is complete. Let $(\eta_n)$ be a Cauchy sequence in $W$. Write $\eta_n=T\xi_n$ where $\xi_n\in V$. Then \eqref{eq190} indicates that $(\xi_n)$ is a Cauchy sequence in $V$. Since $V$ is complete, the sequence $(\xi_n)$ converges to some $\xi\in V$. It follows that $\lim_n\eta_n=\lim_n T\xi_n$ converges to $T\xi$.
\end{proof}





\subsubsection{The multiplication-operator version of the spectral theorem}

Let $\MH$ be a Hilbert space, and let $T_1\dots,T_N\in\fk L(\MH)$ be adjointly-commuting normal operators.


\begin{thm}[\textbf{Spectral theorem}]\label{lb330}
Let $X\subset\Cbb^N$ be a Borel set containing $\Sp(T_\blt)$. Then there exists a family $(\mu_\alpha)_{\alpha\in \SI}$ of finite Borel measures on $X$, together with a unitary map
\begin{gather*}
\Phi: \MH\xlongrightarrow{\simeq}\bigoplus_{\alpha\in\SI} L^2(X,\mu_\alpha)
\end{gather*}
such that for each $1\leq i\leq N$, we have
\begin{align}\label{eq181}
\Phi T_i\Phi^{-1}=\oplus_{\alpha\in\SI}\Mbf_{z_i}
\end{align}
as bounded linear operators on $\bigoplus_{\alpha\in\SI} L^2(X,\mu_\alpha)$.
\end{thm}

As usual, $z_i$ denotes the $i$-th coordinate function of $\Cbb^N$. Then \eqref{eq181} means that for each $\oplus_\alpha\xi_\alpha\in\bigoplus_\alpha L^2(X,\mu_\alpha)$, we have
\begin{align*}
\Phi T_i\Phi^{-1}(\oplus_\alpha\xi_\alpha)=\oplus_\alpha z_i\xi_\alpha
\end{align*}


\begin{proof}
Let $\pi:\Borb(X)\rightarrow\fk L(\MH)$ be the Borel functional calculus (cf. Thm. \ref{lb331}). More precisely, $\pi$ is the restriction of the Borel functional calculus to $X$ (cf. Prop. \ref{lb303}). Then $(\pi,\MH)$ is a normal unitary representation of $\Borb(X)$. 

By Prop. \ref{lb329}, $(\pi,\MH)$ admits an orthogonal decomposition into (automatically normal) cyclic subrepresentations $\MH=\bigoplus_{\alpha\in\SI}\MH_\alpha$. By Prop. \ref{lb332}, each $(\pi|_{\MH_\alpha},\MH_\alpha)$ is unitarily equivalent to the multiplication representation of $\Borb(X)$ with respect to some finite Borel measure $\mu_\alpha$ on $X$. Therefore, $(\pi,\MH)$ is unitarily equivalent to $(\oplus_\alpha \Mbf,\bigoplus_\alpha L^2(X,\mu_\alpha))$ via a unitary operator $\Phi:\MH\rightarrow \bigoplus_\alpha L^2(X,\mu_\alpha)$. That is,
\begin{align*}
\Phi\pi(f)\Phi^{-1}=\oplus_\alpha \Mbf_f\qquad\text{for each }f\in\Borb(X)
\end{align*}
Since $\pi(z_i)=T_i$, we obtain \eqref{eq181}.
\end{proof}


With the multiplication-operator version of the spectral theorem, one can give an explicit description of the Borel functional calculus:





\begin{thm}\label{lb334}
Let $(X,\fk M)$ be a measurable space. Let $f_1,\dots,f_N:X\rightarrow\Cbb$ be bounded measurable functions. Let $(\mu_\alpha)_{\alpha\in\SI}$ be a family of measures on $\fk M$. Let $\MH=\bigoplus_{\alpha\in\SI}L^2(X,\mu_\alpha)$. For each $1\leq i\leq N$, define $T_i\in\fk L(\MH)$ by 
\begin{align*}
T_i=\oplus_{\alpha\in\SI}\Mbf_{f_i}
\end{align*}
Then $T_1,\dots,T_N$ are adjointly-commuting bounded normal operators. Moreover, for each $g\in\Borb(\Cbb^N)$, the Borel functional calculus satisfies
\begin{align}
g(T_1,\dots,T_N)=\oplus_{\alpha\in\SI}\Mbf_{g\circ f_i}
\end{align}
\end{thm}

Note that since $\sup_\alpha\Vert \Mbf f_i\Vert\leq \Vert f_i\Vert_{l^\infty}$, the direct sum operator $\oplus_{\alpha\in\SI}\Mbf_{f_i}$ can be defined as a bounded linear operator.


\begin{proof}
Note that $(\oplus_{\alpha\in\SI}\Mbf,\MH)$ is a unitary representaiton of $\Borb(X)$, and that the range of any unitary representaiton of a commutative *-algebra consists of adjointly-commuting bounded normal operators. Therefore,  $T_1,\dots,T_N$ are mutually-commuting normal operators. Moreover, the map
\begin{align*}
\pi:\Borb(\Cbb^N)\rightarrow \fk L(\MH)\qquad g\mapsto \Mbf_{g\circ f_i} 
\end{align*}
is clearly a unitary representation supported in $K$ where $K\subset\Cbb^N$ is any compact set containing $\Rng(f_\blt)=\Rng(f_1,\dots,f_N)$. It remains to prove that $(\pi,\MH)$ is normal.

Choose an increasing sequence $(g_n)$ in $\Borb(\Cbb^N,\Rbb_{\geq0})$ converging pointwise to $g\in \Borb(\Cbb^N,\Rbb_{\geq0})$. Let $\xi=\oplus_{\alpha\in\SI}\xi_\alpha$ be an element of $\MH$. MCT implies
\begin{align*}
&\lim_n\bk{\xi|\pi(g_n)\xi}=\lim_n \sum_{\alpha\in\SI}\int_X (g_n\circ f_\blt)|\xi_\alpha|^2d\mu_{\alpha}=\sum_{\alpha\in\SI}\lim_n\int_X (g_n\circ f_\blt)|\xi_\alpha|^2d\mu_{\alpha}\\
=&\sum_{\alpha\in\SI}\int_X (g\circ f)|\xi_\alpha|^2d\mu_{\alpha}=\bk{\xi|\pi(g)\xi}
\end{align*}
recalling that $\sum_{\alpha\in\SI}$ coincides with the integral on $\SI$ with respect to the counting measure (so that MCT applies).
\end{proof}



\begin{exe}
In the setting of Thm. \ref{lb334}, choose an element $\xi=\oplus_{\alpha\in\SI}\xi_\alpha$ of $\MH$. Recall the measure $\mu_\xi$ in Rem. \ref{lb297}. Show that
\begin{align}
d\mu_\xi=\sum_{\alpha\in\SI}(f_\blt)_*\big(\Vert\xi_\alpha\Vert^2d\mu_\alpha\big)
\end{align}
where all but countably many summands are zero due to Prop. \ref{lb235}. Note that in the special case where $X\subset\Cbb^N$ and $f_i=z_i$, the above relation becomes
\begin{align}
d\mu_\xi=\sum_{\alpha\in\SI}\Vert\xi_\alpha\Vert^2d\mu_\alpha
\end{align}
\end{exe}



The joint spectra can also be described explicitly:


\begin{exe}
In the setting of Thm. \ref{lb334}, assume that each $\mu_\alpha$ is $\sigma$-finite. Prove that
\begin{align}
\Sp(T_\blt)= \Cl_{\Cbb^N}\Big(\bigcup_{\alpha\in\SI}\Ess(f_\blt,\mu_\alpha)\Big)
\end{align}
where $\Ess(f_\blt,\mu_\alpha)$ is the essential range (cf. Def. \ref{lb319}) of the map $f_\blt=(f_1,\dots,f_N):X\rightarrow\Cbb^N$ with respect to $\mu_\alpha$. \footnote{Indeed, the relation ``$\subset$'' can be proved without assuming $\sigma$-finiteness.} Note that in the special case where $X\subset\Cbb^N$ and $f_i=z_i$, the above relation becomes
\begin{align}
\Sp(T_\blt)= \Cl_{\Cbb^N}\Big(\bigcup_{\alpha\in\SI}\Supp(\mu_\alpha)\Big)
\end{align}
\end{exe}


We encourage the reader to use the results from this subsection to provide alternative proofs for the basic properties of the Borel functional calculus and joint spectra, namely those in Sec. \ref{lb335}. I must confess, when I was proving certain propositions in Sec. \ref{lb335} (for example, Prop. \ref{lb317}), I often had in mind the concrete case of multiplication operators as in Thm. \ref{lb330}---sometimes even restricting to the situation where the index set $\SI$ consists of a single point---and then figured out the argument. This is my secret method for working with the Borel functional calculus.








\subsection{Problems}

In this section, we fix Hilbert spaces $\MH,\MK$.

\begin{prob}\label{lb284}
Let $-\infty<a<b<+\infty$. Let $f\in\Cbb[x]$. Prove that $f|_{[a,b]}\geq0$ iff $f$ can be written as
\begin{align*}
\ovl{p_1(x)}p_1(x)+(x-a)\ovl{p_2(x)}p_2(x)+(b-x)\ovl{p_3(x)}p_3(x)
\end{align*}
where $p_1,p_2,p_3\in\Cbb[x]$. (Assume for simplicity that $a=0,b=1$.)
\end{prob}

\begin{proof}[Hint]
Show that $f\in\Rbb[x]$. Factor the polynomial $f$ into linear factors. Show that any real root of $f$ with odd multiplicity must be outside the open interval $(a,b)$.
\end{proof}






\begin{df}
The \textbf{strong-* operator topology (SOT*)} \index{00@strong-* operator topology (SOT*)} \index{00@SOT*} on $\fk L(\MH,\MK)$ is defined as the pullback topology along the map
\begin{align*}
\fk L(\MH,\MK)\rightarrow\fk L(\MH,\MK)\times\fk L(\MK,\MH)\qquad T\mapsto (T,T^*)
\end{align*}
where the RHS carries the product topology of SOT on $\fk L(\MH,\MK)$ and on $\fk L(\MK,\MH)$, respectively. Equivalently, a net $(T_\alpha)$ in $\fk L(\MH,\MK)$ converges to $T\in\fk L(\MH,\MK)$ in SOT* iff $(T_\alpha)\rightarrow T$ in SOT and simultaneously $(T_\alpha^*)\rightarrow T^*$ in SOT.
\end{df}




\begin{prob}\label{lb337}
Let $(T_\alpha)$ be a net of normal operators on $\MH$. Let $T\in\fk L(\MH)$. 
\begin{enumerate}
\item Assume that $(T_\alpha)$ converges in WOT to $T$. Prove that $(T_\alpha^*)$ converges in WOT to $T^*$.
\item Assume that each $T_\alpha$ is normal, and that $(T_\alpha)$ converges in SOT* to $T\in\fk L(\MH)$. Prove that $T$ is normal.
\item Assume that $T$ and each $T_\alpha$ are normal, and that $(T_\alpha)$ converges in SOT to $T$. Prove that $(T_\alpha)$ converges in SOT* to $T$.
\end{enumerate}
\end{prob}


\begin{proof}[Note]
Part 2. One cannot conclude that $(T_\alpha^*T_\alpha)$ converges in SOT to $T^*T$, since $\sup_{\alpha\in I}\Vert T_\alpha\Vert$ is not assumed to be finite. (Cf. Cor. \ref{lb159}.) Consider WOT instead.

Part 3. Recall Rem. \ref{lb241}.
\end{proof}






\begin{prob}\label{lb240}
Let $(T_\alpha)$ be a net of bounded normal operators on $\MH$ satisfying $\sup_\alpha\Vert T_\alpha\Vert\leq R$ for some $R\in\Rbb_{\geq0}$. Let $f\in C(\ovl B_\Cbb(0,R))$. Assume that $(T_\alpha)$ converges in SOT* to $T\in\fk L(\MH)$. Note that $T$ is normal by Pb. \ref{lb337}. Prove that
\begin{align}
\lim_\alpha f(T_\alpha)=f(T)\qquad\text{in SOT*}
\end{align}
\end{prob}

\begin{proof}[Hint]
Approximate $f$ uniformly by polynomials of $z$ and $\ovl z$.
\end{proof}

\begin{rem}\label{lb305}
Let $T\in\fk L(\MH)$ be self-adjoint and $R\geq\Vert T\Vert$. For each $z\in\Cbb$ satisfying $|z|>R$, let $f_z(\lambda)=(z-\lambda)^{-1}$. Since the Borel functional calculus preserves the multiplication of functions, we have
\begin{align*}
f_z(T)(z-T)=(z-T)f_z(T)=\idt
\end{align*}
and hence $f_z(T)=(z-T)^{-1}$. 

Now suppose that $\MH$ is separable and infinite-dimensional, and let $e_1,e_2,\dots$ be an orthonormal basis of $\MH$. Let $E_n$ be the projection of $\MH$ onto $\Span\{e_1,\dots,e_n\}$. Then $\Vert E_nTE_n\Vert\leq R$, and hence $f_z(E_nTE_n)=(z-E_nTE_n)^{-1}$. By Pb. \ref{lb240}, we have
\begin{align*}
\lim_n (z-E_nTE_n)^{-1}=(z-T)^{-1}\qquad \text{in SOT*}
\end{align*}
This proves that Hilbert's resolvent is equal to the usual definition of resolvent for bounded linear operators, as discussed in the answer to Question \ref{lb242}.  \hqed
\end{rem}

\begin{prob}
Let $P\in\fk L(\MH)$ be normal. Prove that $P$ is a projection iff $\Sp(P)\subset\{0,1\}$.
\end{prob}


\subsubsection{Application of the spectral theorem to moment problems}


In this chapter, we have used the polynomial moment problem in Sec. \ref{lb188} as a central motivation for the spectral theorem. Conversely, the spectral theorem can in turn be applied to solve moment problems---specifically, to prove Thm. \ref{lb169}. In Exp. \ref{lb351} below, we explain how the spectral theorem for bounded self-adjoint operators immediately establishes Part 3 of Thm. \ref{lb169}, i.e. the solution of the Hausdorff moment problem. In the next chapter, we will see how the spectral theorem for unbounded self-adjoint operators provides alternative proofs for the first two parts of Thm. \ref{lb169}.





\begin{eg}\label{lb351}
Let $(c_n)_{n\in\Nbb}$ be a sequence in $\Rbb$. Define $H$ and $H'$ as in Def. \ref{lb203}. As in the proof of Prop. \ref{lb168}, if there is a finite Borel measure $\mu$ on $[0,1]$ satisfying $\int_{[0,1]}x^nd\mu=c_n$ for all $n$, then necessarily $H,H',H-H'\geq0$.

Conversely, assume that $H,H',H-H'\geq0$. Let $\SA=\Cbb[x]$, and let $\Lambda:\SA\rightarrow\Cbb$ be the unique linear functional such that $\Lambda(x^n)=c_n$ for all $n$. Since $H\geq0$, by Pb. \ref{lb348} and Rem. \ref{lb349}, the space $\SA$ admits a positive sesquilinear form defined by $\bk{f|g}=\Lambda(\ovl fg)$, which descends to an inner product on $V=\SA/\scr N$ where $\scr N=\{g\in\SA:\bk{g|g}=0\}$. Moreover, $\SA$ has a pre-unitary representation $(\pi,V)$ such that $\pi(f)(g+\scr N)=fg+\scr N$. Let $T=\pi(x)$. Then the condition $H',H-H'\geq0$ implies that 
\begin{align*}
0\leq\bk{\xi|T\xi}\leq \bk{\xi|\xi}\qquad\text{for all }\xi\in V
\end{align*}
By Prop. \ref{lb238}, we have $\Vert\omega_T\Vert\leq 4$, and hence (by Prop. \ref{lb133}) $\Vert T\Vert\leq 4$.

Let $\MH$ be the Hilbert space completion of $V$ (cf. Pb. \ref{lb350}). By Thm. \ref{lb31}, $T$ can be extended uniquely to an element of $\fk L(\MH)$, also denoted by $T$. We still have $0\leq T\leq 1$, and hence $\Sp(T)\subset[0,1]$ due to Prop. \ref{lb313}. Let $\Omega=1+\scr N$. By Rem. \ref{lb297}, there is a finite Borel measure $\mu=\mu_\Omega$ on $[0,1]$ such that the Borel functional calculus of $T$ satisfies
\begin{align*}
\bk{\Omega|f(T)\Omega}=\int_{[0,1]}fd\mu
\end{align*}
Taking $f(x)=x^n$, we obtain $c_n=\Lambda(x^n)=\bk{\Omega|T^n\Omega}=\int_{[0,1]}x^nd\mu$. Thus $\mu$ solves the Hausdorff moment problem.   \hqed
\end{eg}


Next, the reader is asked to solve a trigonometric moment problem by a similar method. Let $N\in\Zbb_+$. Recall that $\Tbb=\Sbb^1=\{z\in\Cbb:|z|=1\}$. For each $z=(z_1,\dots,z_N)\in\Tbb^N$ and $n=(n_1,\dots,n_N)\in\Zbb^N$, let
\begin{align}
z^n=z_1^{n_1}\cdots z_N^{n_N}
\end{align}

\begin{df}
For each complex Borel measure $\mu$ on $\Tbb^N$, define the \textbf{Fourier series} $\wht\mu:\Zbb^N\rightarrow\Cbb$ by \index{00@Fourier series of measures} \index{zz@$\wht\mu$, the Fouerier series of $\mu$}
\begin{align*}
\wht\mu(n)=\int_{\Tbb^N}z^{-n}d\mu(z)
\end{align*} 
Note that $|\wht\mu(n)|\leq \Vert\mu\Vert<+\infty$, and hence $\wht\mu\in l^\infty(\Zbb^N)$. Moreover, by Stone-Weierstrass, $\Span\{z^n:n\in\Zbb^N\}$ is dense in $C(\Tbb^N)$. Thus $\mu$ is uniquely determined by its Fourier series $\wht\mu$.
\end{df}

The following result is known as the \textbf{Carath\'eodory-Toeplitz theorem}. \index{00@Carath\'eodory-Toeplitz theorem}

\begin{prob}(\textbf{Trigonometric moment problem}) \index{00@Trigonometric moment problem} 
Let $c_\blt=(c_n)_{n\in\Zbb}$ be a family in $\Cbb$. Prove that the following conditions are equivalent.
\begin{enumerate}
\item[(1)] There exists a finite Borel measure $\mu$ on $\Tbb^N$ such that $\wht\mu=c_\blt$.
\item[(2)] $c_\blt$ is \textbf{positive-definite} in the sense that the matrix $C\in\Cbb^{\Zbb^N\times\Zbb^N}$ defined by $C(m,n)=c_{n-m}$ (where $m,n\in\Zbb^N$) is positive. That is, for each $f:\Zbb^N\rightarrow\Cbb$ with finite support, we have
\begin{align*}
\sum_{m,n\in\Zbb^N}\ovl{f(m)}c_{n-m}f(n)\geq0
\end{align*}
\end{enumerate}
\end{prob}


\begin{proof}[Hint for (2)$\Rightarrow$(1)]
Let $\SA$ be the set of polynomials of $z_1,z_1^{-1},\dots,z_N,z_N^{-1}$, viewed as a unital *-subalgebra of $C(\Tbb^N)$. Show that the linear functional
\begin{align*}
\Lambda:\SA\rightarrow\Cbb\qquad \Lambda(z^{-n})=c_n
\end{align*}
satisfies the condition in Pb. \ref{lb348} so that the GNS construction gives a pre-unitary representation $(\pi,V)$ of $\SA$. Show that $U_j=\pi(z_j)$ (for $1\leq j\leq N$) are unitary and adjointly-commuting, and hence can be extended to adjointly-commuting unitary operators on the Hilbert space completion $\MH$. Apply the spectral theorem to $U_1,\dots,U_N$. 
\end{proof}





\subsubsection{The origin of the Borel functional calculus and the abstract Riesz-Fischer theorem}\label{lb345}

As discussed in Rem. \ref{lb287} and the answer to Question \ref{lb286}, Riesz used the semicontinuous functional calculus to establish his spectral theorem in \cite{Rie13}, rather than the more general Borel functional calculus. The Borel functional calculus was first developed by von Neumann in \cite{vN31} to prove the following theorem.

\begin{thm}\label{lb343}
Assume that $\MH$ is separable, and let $T_1,T_2,\dots\in\fk L(\MH)$ be a possibly finite sequence of mutually-commuting bounded self-adjoint operators. Then there exist a self-adjoint $S\in\fk L(\MH)$ and $f_1,f_2,\dots\in\Borb(\Rbb,\Rbb)$ such that $T_i=f_i(S)$ for each $i$.
\end{thm}

Although von Neumann did not make this explicit, part of his motivation for studying Thm. \ref{lb343} may have been to reduce the study of the functional calculus for several operators to that of a single operator: indeed, in Thm. \ref{lb343} one has $g(T_1,T_2,\dots)=g\circ (f_1,f_2,\dots)(S)$ for $g\in\Borb(\Rbb\times\Rbb\times\cdots)$. See \cite{vN32a} (especially Sec. II.10, III.1, III.3) for von Neumann's use of this result in developing mathematical interpretations of quantum mechanics.

The Borel functional calculus is crucial to this theorem. In fact, as we will see in the proof, the operator $S$ can also be written as $g(T_1,T_2,\dots)$ if the number of the operators $T_1,T_2,\dots$ is finite. This enhanced version of Thm. \ref{lb343} does not hold if the functions $f_i$ and $g$ are only assumed to be semicontinuous---even in the case of just two operators $T_1,T_2$. 

While proving Thm \ref{lb343}, von Neumann also established the abstract Riesz-Fischer theorem: the completeness of $L^2([a,b],\mu)$ where $\mu$ is a finite Borel measure on $[a,b]$. (See Pb. \ref{lb344} for where this theorem is used.) His argument---similar to his proof of completeness in \cite[Anhang 2]{vN27} for $L^2(\Omega,m)$ where $\Omega\subset\Rbb^n$ and $m$ is the Lebesgue measure---is much closer to the modern proof of the Riesz-Fischer Thm. \ref{lb26}, and therefore extends naturally to arbitrary measure spaces. By contrast, the original proofs of Riesz and Fischer for the Lebesgue measure on $[a,b]$ relied heavily on the fundamental theorem of calculus (see \cite[Sec. 27.3]{Gui-A} for a discussion), and thus do not generalize.



The aim of this subsection is to give a proof of Thm. \ref{lb343}, following von Neumann's approach in \cite{vN31}. The only exception is the proof of Thm. \ref{lb339}, where we follow the argument in \cite[Lem.\ II.2.8]{Dav}, which differs from von Neumann's original proof in \cite{vN29b}.






\begin{df}\label{lb336}
Throughout this subsection, we let $\fk S$ be a set of adjointly-commuting bounded normal operators on $\MH$. Let $\pmb{\Cbb[\fk S\cup\fk S^*]}$ be the set of polynomials of elements of $\fk S\cup\fk S^*$, which is clearly a commutative unital *-subalgebra of $\fk L(\MH)$. Let $\pmb {W^*(\fk S)}$ be the closure of $\Cbb[\fk S\cup\fk S^*]$ in SOT*.
\end{df}

In the following, we always let $\SA=\Cbb[\fk S\cup\fk S^*]$. Note that $W^*(\fk S)=W^*(\SA)$.

\begin{eg}\label{lb340}
Let $T_1,\dots,T_N\in\fk S$ and $f\in\Borb(\Cbb^N)$. Then $f(T_\blt)\in W^*(\fk S)$.
\end{eg}


\begin{proof}
By Lem. \ref{lb276}, there is a net $(f_\alpha)$ of polynomials of $z_1,\ovl{z_1},\dots,z_N,\ovl{z_N}$ converging to $f$ in the universal $L^2$-topology on $\Sp(T_\blt)$. By Prop. \ref{lb316}, $f_\alpha(T_\blt)$ converges in SOT $f(T_\blt)$. Since $f(T_\blt)$ is normal (Prop. \ref{lb304}), the convergence is in SOT* due to Pb. \ref{lb337}. Since $f_\alpha(T_\blt)\in\SA$, we have $f(T_\blt)\in W^*(\fk S)$.
\end{proof}


\begin{rem}
By Prop. \ref{lb143}, if $(A_\alpha)_{\alpha\in I}$ and $(B_\beta)_{\beta\in J}$ are nets in $\SA$ converging in norm to $A,B\in\fk L(\MH)$ respectively, then $(A_\alpha B_\beta)_{(\alpha,\beta)\in I\times J}$ converges in norm to $AB$. Thus, the norm closure of $\SA$ is closed under multiplication, and hence is a unital *-subalgebra of $\fk L(\MH)$. The proof that $W^*(\fk S)$ is closed under multiplication is much less straightforward, as we will establish in the following theorem.
\end{rem}


\begin{thm}\label{lb338}
$W^*(\fk S)$ is an (automatically SOT*-closed) unital *-subalgebra of $\fk L(\MH)$.
\end{thm}



\begin{prob}\label{lb341}
The goal of this problem is to prove Thm. \ref{lb338}.
\begin{enumerate}
\item Prove that any two elements of $W^*(\fk S)$ are normal and commute adjointly.
\item Let $S,T\in\fk L(\MH)$ be normal and adjointly-commuting. Assume that $f\in\Bor(\Cbb)$ has Lipschitz constant $C$ when restricted to $K:=\Sp(S)\cup\Sp(T)$. Prove that
\begin{align*}
\Vert f(S)\xi-f(T)\xi\Vert^2\leq C^2\cdot\Vert S\xi-T\xi\Vert^2
\end{align*}
(Note that $f|_K$ is bounded due to the Lipschitz-continuity. Thus $f(S),f(T)$ can be defined as bounded operators.)
\item Let $(T_\alpha)_{\alpha\in\SI}$ be a net in $W^*(\fk S)$ converging in SOT* to $T\in\fk L(\MH)$. (So $T\in W^*(\fk S)$.) Assume that $f\in\Bor(\Cbb)$ is Lipschitz continuous on a compact set $K\subset\Cbb$ containing $\Sp(T)$ and all $\Sp(T_\alpha)$. Prove that 
\begin{align*}
\lim_\alpha f(T_\alpha)=f(T)\qquad\text{in SOT*}
\end{align*}
(Note that Pb. \ref{lb240} is not applicable here, since we do not assume $\sup_\alpha\Vert T_\alpha\Vert<+\infty$.)
\item Prove Thm. \ref{lb338}.
\end{enumerate}
\end{prob}


\begin{proof}[Hint]
2. Use the multiplication-operator version of the spectral theorem. Alternatively, apply the Borel functional calculus to $S,T$ and the function $g(z,w)=f(z)-f(w)$ defined on $K\times K$.

4. Let $S,T\in W^*(\fk S)$. To show $ST\in W^*(\fk S)$, restrict to the case where $S,T$ are self-adjoint. Choose nets $(S_\alpha)_{\alpha \in I}$ and $(T_\beta)_{\beta\in J}$ in $\SA$ converging in SOT to $S,T$. Find a suitable bounded Lipschitz-continuous $f:\Rbb\rightarrow\Rbb$ such that $f(x)=x$ whenever $x\in\Sp(S)\cup \Sp(T)$. Use Cor. \ref{lb159} to show that $\lim_{(\alpha,\beta)\in I\times J}f(S_\alpha)f(T_\beta)$ converges in SOT* to $ST$.
\end{proof}


\begin{rem}
It follows from Thm. \ref{lb338} that $W^*(\fk S)$ is the smallest SOT*-closed unital *-subalgebra of $\fk L(\MH)$ containing $\fk S$. In particular, if $\fk T\subset W^*(\fk S)$, then $W^*(\fk T)\subset W^*(\fk S)$.
\end{rem}


\begin{thm}\label{lb339}
Assume that $\MH$ is separable, and $\fk S=\{T_1,\dots,T_N\}$ is a finite set. Then
\begin{align*}
W^*(\fk S)=\{f(T_\blt):f\in\Borb(\Cbb^N)\}
\end{align*}
\end{thm}


\begin{prob}\label{lb344}
In this problem, we prove Thm. \ref{lb339}. By Exp. \ref{lb340}, it suffices to show that any $S\in W^*(\fk S)$ is a Borel functional calculus of $T_\blt$. By considering $\Real(S)$ and $\Imag(S)$ separately, it suffices to assume that $S=S^*$.
\begin{enumerate}
\item Show that there exists a net of polynomials $(f_\alpha)_{\alpha\in\SI}$ of $z_1,\ovl{z_1},\dots,z_N,\ovl{z_N}$ such that $(f_\alpha(T_\blt))$ converges in SOT* to $S$, and that each $f_\alpha$ is real-valued on $\Cbb^N$.
\item Show that one can assume moreover that the net $(f_\alpha)_{\alpha\in\SI}$ is uniformly bounded on $\Cbb^N$. That is, $\sup_\alpha \Vert f_\alpha\Vert_{l^\infty(\Cbb^N)}<+\infty$.
\item Let $(\psi_n)_{n\in\Zbb_+}$ be a densely-spanning sequence in $\MH$ satisfying $\sum_n\Vert\psi_n\Vert^2<+\infty$. Define a Borel measure on $\Cbb^N$ by
\begin{align*}
\mu=\sum_n \mu_{\psi_n}
\end{align*}
where $\mu_{\psi_n}$ is the finite Borel measure associated to $\psi_n$ and $T_\blt$. (That is, $\bk{\psi_n|g(T_\blt)\psi_n}=\int_{\Cbb^N}gd\mu_{\psi_n}$ for each $g\in\Borb(\Cbb^N)$, cf. Rem. \ref{lb297}.) Show that $(f_\alpha)$ is a Cauchy net in $L^2(\Cbb^N,\mu)$, that is,
\begin{align*}
\lim_{\alpha,\beta\in\SI}\int_{\Cbb^N} |f_\alpha-f_\beta|^2d\mu=0
\end{align*}
\item By the Riesz-Fischer Thm. \ref{lb26} (and Thm. \ref{lb269}), there exists $f\in L^2(\Cbb^N,\mu)$ such that $\lim_\alpha\Vert f-f_\alpha\Vert_{L^2(\Cbb^N,\mu)}=0$. Show that $f$ can be chosen to be a bounded Borel function.
\item Show that $S=f(T_\blt)$.
\end{enumerate}
\end{prob}


\begin{proof}[Hint]
2. Find a suitable bounded Lipschitz-continuous $\varphi:\Rbb\rightarrow\Rbb$ such that $\varphi(x)=x$ whenever $x\in [-\Vert S\Vert,\Vert S\Vert]$. Use Pb. \ref{lb341} and Thm. \ref{lb306} to show that $f_\alpha$ can be replaced with $\varphi\circ f_\alpha$.

4. Choose a sequence $(\alpha_n)_{n\in\Zbb_+}$ in $\SI$ such that $\lim_n \Vert f-f_{\alpha_n}\Vert_{L^2(\mu)}=0$. Apply the second part of Thm. \ref{lb26}.
\end{proof}

\begin{thm}\label{lb342}
Assume that $\fk S$ is countable. Then there exists $S\in \fk L(\MH)$ such that $S\geq0$ and $W^*(\fk S)=W^*(S)$.
\end{thm}

\begin{prob}
In this problem, we prove Thm. \ref{lb342}.
\begin{enumerate}
\item Prove that $W^*(\fk S)$ contains a countable subset $\fk E$ of mutually-commuting projections such that $W^*(\fk S)=W^*(\fk E)$.
\item Suppose that $P,H\in\fk L(\MH)$ commute with each other, $P$ is a projection, and $0\leq H\leq 1/2$. Show that $P=\chi_{[1,+\infty)}(P+H)$.
\item Write $\fk E=\{E_0,E_1,E_2,\dots\}$. For each $n\in\Nbb$, let
\begin{align*}
S_n=\sum_{k=n}^{+\infty} 3^{-k}E_k
\end{align*}
Show that the above limit converges in SOT*; in particular, $S_n\in W^*(\fk S)$.
\item Use Part 2 to prove that $E_n\in W^*(S_n)$. Conclude $E_0,E_1,E_2,\dots\in W^*(S_0)$.
\item Conclude that $W^*(\fk S)=W^*(S_0)$.
\end{enumerate}
\end{prob}

\begin{proof}[Hint]
1. Consider $\chi_{(a,b]}(T)$ where $a,b\in\Qbb$ and $T\in\fk S$.

2. View $P,H$ as $\Mbf_p$ and $\Mbf_h$ where $p,h\in\Borb(\Cbb^2)$. Show that $p,h$ can be chosen so that $p$ is a characteristic function, and $0\leq h\leq 1/2$.
\end{proof}


\begin{proof}[\textbf{Proof of Thm. \ref{lb343}}]
Let $\fk S=\{T_1,T_2,\dots\}$. By Thm. \ref{lb342}, there exists a self-adjoint $S\in\fk L(\MH)$ such that $W^*(\fk S)=W^*(S)$. Since each $T_i$ belongs to $W^*(S)$, by Thm. \ref{lb339}, there exists $f_i\in\Borb(\Rbb)$ such that $T_i=f_i(S)$. Since $T_i=T_i^*$, we have $T_i=\ovl{f_i}(S)$, and hence $T_i=(\Real f_i)(S)$. The proof is finished by replacing $f_i$ with $\Real f_i$.
\end{proof}








\newpage


\section{Unbounded operators and their spectral theorem}\label{lb292}


\subsection{Von Neumann and the mathematical foundation of quantum mechanics}\label{lb291}

In this chapter we study unbounded operators and their spectral theory. Von Neumann was the principal developer of this theory; his chief motivation, beginning in 1927, was to place quantum mechanics on a firm mathematical footing. The aim of this section is to sketch that historical and conceptual background so the reader can appreciate von Neumann's concrete goals and methods.






\subsubsection{The mathematical interpretation of quantum mechanics by physicists}

The mathematical formulation of quantum mechanics, developed around 1925 by physicists such as Heisenberg, Born, Jordan, and Schr\"odinger, can be summarized as follows. A particle (for instance, an atom) may exist in different states, each represented by a vector. These vectors are often concrete objects, such as functions on $\Rbb^3$ (i.e., wave functions). Since waves can superpose, quantum states also admit superposition, which mathematically corresponds to vector addition. Thus, the collection of all possible states of a particle forms a complex vector space $\MV$. This space is in fact equipped with an inner product, which provides a notion of length. A genuine quantum state is then required to have length $1$.

Another fundamental notion is that of observables, i.e., measurable quantities of a quantum system such as energy, momentum, position, and angular momentum. Mathematically, observables are represented by Hermitian operators; in finite dimensions these are simply Hermitian matrices. Actual quantum systems, however, are infinite-dimensional, and in that setting physicists did not initially adopt the same level of rigor as mathematicians in defining what precisely constitutes a ``Hermitian operator''. The need for such rigor, especially in giving a precise mathematical foundation to the notion of observables, became one of the main starting points for von Neumann's investigation of the spectral theory of unbounded operators, beginning with \cite{vN27}.





An observable cannot, in general, be measured with perfect accuracy in all states. If a state (i.e., a vector $\xi\in \MV$) allows the observable $T$ to be measured with perfect accuracy and value $\lambda$, then mathematically this means $T\xi=\lambda\xi$. Thus, the unit eigenvectors of a Hermitian operator correspond exactly to those states in which the observable can be measured precisely. 

In general, at least when $\dim \MV<+\infty$, a vector $\xi$ can be expanded as a finite sum $\sum_i a_ie_i$ where $e_1,e_2,\dots$ are orthonormal eigenvectors of $T$ corresponding to distinct eigenvalues $\lambda_1,\lambda_2,\dots\in\Rbb$, and each $a_i\in\Cbb$. This shows that the value of the observable $I$ measured in state $\xi$ cannot be predicted with certainty; rather, it follows a probability distribution: the probability of measuring the value $\lambda_i$ is $|a_i|^2$. By the Pythagorean identity, the probabilities sum to $\sum_i|a_i|^2=1$, due to the Pythagorean identity. \uwave{The expectation value of measuring $T$ in state $\xi$ is $\bk{\xi|T\xi}$}, since
\begin{align*}
\sum_i |a_i|^2\lambda_i=\bk{\xi|T\xi}
\end{align*}

For example, the multiplication operator $\Mbf_{x_i}$ (abbreviated to $x_i$) for the $i$-th coordinate function of $\Rbb^3$ is the observable measuring the $i$-th component of the position. Thus, for a function $\xi$ on $\Rbb^3$, the quantity $\bk{\xi|x_i\xi}$ gives the expectation value of the $i$-th component of the position of $\xi$. Similarly,
\begin{align*}
p_i:=\frac\partial{\im\partial x_i}
\end{align*}
is the momentum operator for the $i$-th component, and hence $\bk{\xi|p_i\xi}$ gives the expectation value of the $i$-th coordinate of the momentum of $\xi$. The \textbf{energy operator} (or \textbf{Hamiltonian}) $H=H_t$ typically takes the form
\begin{align}\label{eq186}
H_t=-\Delta+V=p_1^2+p_2^2+p_3^2+V(t,x)
\end{align}
where $V$ is the potential function defined on $\Rbb\times\Rbb^3$.



The time evolution of a state $\xi$, denoted $t\in\Rbb\rightarrow \xi(t)\in \MV$, is governed by the \textbf{Schr\"odinger equation} $\im\partial_t\xi(t)=H\xi(t)$ with initial condition $\xi(0)=\xi$, where $H$ is the Hermitian operator for the energy (so that $\bk{\xi|H\xi}$ is the expected energy in state $\xi$.) In the important case where $H$ is time-independent (e.g. the potential function $V(t,x)$ in \eqref{eq186} does not depend on $t$), the formal solution of the Schr\"odinger equation is
\begin{align*}
\xi(t)=e^{-\im tH}\xi
\end{align*}

To compute the RHS explicitly, one may decompose $\xi=\sum_i u_i$ where $u_1,u_2,\dots$ are mutually orthogonal eigenvectors of $H$ with corresponding eigenvalues $\lambda_1,\lambda_2,\dots\in\Rbb$. Then
\begin{align*}
e^{-\im tH}\xi=\sum_i e^{-\im t\lambda_i}u_i
\end{align*}
Of course, this argument relies on the diagonalization of Hermitian operators, which is valid when $\dim \MV<+\infty$. In infinite dimensions, physicists still assume that Hermitian operators admit a kind of diagonalization, though quite different from mathematician's spectral theorems in Ch. \ref{lb181}. Instead, physicists like Dirac assumed that a Hermitian operator $T$ can be ``diagonalized'' as a combination of a discrete sum and a continuous (Riemann) integral, as described below. (See \cite{Dir30}, especially Sec. 10, 16, and 17.)


\subsubsection{Physicists' spectral decomposition}


Let $\delta$ denote the \textbf{delta function} on $\Rbb$, i.e., the idealized function satisfying $\delta(x)=0$ when $x\neq0$, $\delta(0)=+\infty$, and $\int\delta(x)dx=1$. Then there exists a family of vectors $(u_\lambda)$ indexed by real numbers $\lambda$, together with a countable family $v_{\lambda_1},v_{\lambda_2},\dots$ for distinct real numbers $\lambda_1,\lambda_2,\dots$, such that these two collections together form an ``orthonormal basis'' in the sense that
\begin{align}\label{eq187}
\bk{u_{\lambda}|u_{\lambda'}}=\delta(\lambda-\lambda')\qquad \bk{u_{\lambda}|v_{\lambda_i}}=0\qquad \bk{v_{\lambda_i}|v_{\lambda_j}}=\delta_{i,j}
\end{align}
and that for each $\xi,\eta\in \MV$, the ``Parseval identity''
\begin{align*}
\bk{\xi|\eta}=\int \bk{\xi|u_\lambda}\bk{u_\lambda|\eta}d\lambda+\sum_i\bk{\xi|v_{\lambda_i}}\bk{v_{\lambda_i}|\eta}
\end{align*}
holds. These vectors are eigenvectors of $T$, in the sense that for each reasonable real-valued function $f$ on $\Rbb$, the following spectral decomposition holds:
\begin{align*}
\bk{\xi|f(T)\eta}=\int f(\lambda)\bk{\xi|u_\lambda}\bk{u_\lambda|\eta}d\lambda+\sum_if(\lambda_i)\bk{\xi|v_{\lambda_i}}\bk{v_{\lambda_i}|\eta}
\end{align*}
In particular, when $T$ is the time-independent Hamiltonian $H$, setting $f(x)=e^{\im tx}$ gives the solution of the Schr\"odinger equation. Note that the integrals in the above formulas are understood in the classical sense—essentially what mathematicians would call Riemann integrals, rather than the more general Stieltjes integral (which was regarded as too abstract by physicists).


Physicists refer to the vectors $u_\lambda$ as \textbf{scattering states}, since their squared lengths are $\delta(0)=+\infty$, in contrast to the unit vectors $v_{\lambda_i}$, which are called \textbf{bound states}. For example, when $T$ is the Hamiltonion for the hydrogen atom
\begin{align*}
H=-\Delta-e^2/|x|\qquad e>0
\end{align*}
its spectral decomposition contains both continuous and discrete parts (scattering and bound eigenstates), cf. \cite[Sec.\ 39]{Dir30}. As another instance, assuming for simplicity that the space has one dimension (so that the wave functions are defined on $\Rbb$), the eigenstates of the position and momentum operators $x$ and $p=\frac{\partial}{\im\partial x}$ are scattering states: the $\lambda$-eigenstate of $x$ is $\delta(x-\lambda)$, while the $\lambda$-eigenstate of $p$ is $\frac 1{\sqrt{2\pi}}e^{\im\lambda x}$.



\subsubsection{Von Neumann's notion of abstract Hilbert spaces}


Von Neumann rejected the use of vectors of infinite length (i.e., scattering states) such as delta functions in his effort to place quantum mechanics on a rigorous mathematical foundation. He insisted that wave functions must be square-integrable, and hence elements of $L^2(\Rbb^n,m)$. Consequently, he opposed the physicists' practice of interpreting operators in quantum mechanics as continuous (or mixed continuous and discrete) versions of matrices, since that interpretation necessarily relied on ``orthonormal bases'' of the type in \eqref{eq187}, which in turn presupposed scattering states.

For von Neumann, the concept that unifies ordinary matrices and operators on function spaces was the Riesz-Fischer theorem. To him, this theorem asserts that for any subset $\Omega\subset\Rbb^n$, the space $L^2(\Omega,m)$ of Lebesgue square-integrable functions is an abstract, separable Hilbert space. This abstract definition of a Hilbert space was a major departure from the early 20th-century view, where Hilbert spaces were specifically understood as $l^2(\Zbb)$. Introducing this abstract notion of Hilbert space was one of the central contributions of \cite{vN27}, von Neumann's first paper laying down the mathematical foundations of quantum mechanics.


This version of the Riesz-Fischer theorem did not exist before von Neumann's work. Riesz and Fischer had only proved (in 1907) the completeness of $L^2(I,m)$ where $I\subset\Rbb$ is a compact interval. It was in \cite{vN27} (see Anhang 2) that the completeness of $L^2(\Omega,m)$ for any higher-dimensional set $\Omega\subset\Rbb^n$ was first established.\footnote{Unlike the original proofs, which depended heavily on the fundamental theorem of calculus, von Neumann's proof could be extended to general measure spaces and is closer in spirit to modern textbook proofs of the completeness of $L^p$ spaces over abstract measure spaces. See also Subsec. \ref{lb345}.} In addition, \cite{vN27} proved that every separable (abstract) Hilbert space admits an orthonormal basis. Taken together, these results imply a unitary equivalence $L^2(\Omega,m)\simeq l^2(\Zbb)$ (when $m(\Omega)>0$), thus providing the mathematical foundation for unifying discrete matrices with operators on function spaces.



\subsubsection{Von Neumann's spectral decomposition for unbounded operators}\label{lb375}


For von Neumann, another reason for adopting Hilbert spaces as the rigorous framework of quantum mechanics was that, as we have seen in Ch. \ref{lb181}, Hilbert and especially F. Riesz had already established spectral theorems for bounded self-adjoint operators. The only missing piece was that operators arising in quantum mechanics typically involve differential operators. Unlike bounded self-adjoint operators, these are unbounded and are defined only on dense linear subspaces of the Hilbert space.

Despite this, Riesz's spectral Thm. \ref{lb267} provided a clear path forward. It states that any bounded self-adjoint operator $T$ on a Hilbert space $\MH$ admits a decomposition $T=\int_{[-a,a]}\lambda dE(\lambda)$. As von Neumann recognized in \cite{vN27}, this suggests that the spectral decomposition of an unbounded operator representing a quantum observable should have a similar form:
\begin{align}\label{eq188}
T=\int_{-\infty}^{+\infty}\lambda dE(\lambda)
\end{align}
where $E=(E(\lambda))_{\lambda\in\Rbb}$ is a right-continuous increasing family of projections satisfying
\begin{align*}
\lim_{\lambda\rightarrow-\infty}E(\lambda)=0\qquad \lim_{\lambda\rightarrow+\infty}E(\lambda)=\idt_\MH
\end{align*}
with both limits holding in SOT (cf. Thm. \ref{lb264}). More precisely, for each $\xi\in\MH$, one defines
\begin{align*}
T\xi=\int_{-\infty}^{+\infty}\lambda dE(\lambda)\xi=\lim_{a\rightarrow+\infty}\int_{[-a,a]}\lambda dE(\lambda)\xi
\end{align*} 
whenever the limit exists; the domain of $T$ is defined to be the set of all $\xi\in\MH$ such that this limit exists. 


For modern readers familiar with the multiplication-operator version of the spectral theorem (Thm. \ref{lb330}), the most suitable version for unbounded operators is that any such operator $T$ is unitarily equivalent to a multiplication operators $\Mbf_f$ on a direct sum of $L^2$-spaces, where $f$ is a real-valued Borel function that is not necessarily bounded. (See Exp. \ref{lb366} for the precise definition.)


\subsubsection{Measurement with absolute precision vs. measurement with prescribed accuracy}\label{lb427}



Von Neumann's spectral decomposition for observables abandons the notion of scattering states and the idea that one can measure a quantity $T$ with absolute precision, as is the case with bound states. The mathematically rigorous viewpoint is instead that, for $\lambda\in\Rbb$ lying in the continuous spectrum, the quantity $T$ can only be measured to within an arbitrarily prescribed accuracy. 

To see how this rigorous viewpoint arises, one must understand von Neumann's interpretation of projections in \cite{vN27}, later expanded and refined in \cite{vN32a}.\footnote{\cite{vN32a} may be regarded as a greatly expanded version of \cite{vN27}. There, von Neumann develops and clarifies his earlier treatment of the mathematical foundations of quantum mechanics.} A projection $E$ on $\MH$ represents a ``proposition'' (or ``event'') in a quantum system, i.e., an observable that can take only the values $0$ and $1$, interpreted as ``false'' and ``true'', respectively. Thus, $\Rng(E)$ is the subspace of states in which the proposition holds, and $\Ker(E)$ is the subspace of states in which it fails. It follows that for any unit vector $\xi\in \MH$, the value $\bk{\xi|E\xi}$ gives the probability that the proposition is true in the state $\xi$.

Applying this interpretation to the spectral projections $E(\lambda)=\chi_{(-\infty,\lambda]}(T)$ in \eqref{eq188}, one finds that for any unit vector $\xi$, the value $\bk{\xi|E(\lambda)\xi}$ is the probability that the observable $T$ takes a value not exceeding $\lambda$ in the state $\xi$. Therefore, if we define the projection
\begin{align*}
E(\lambda,\lambda')=E(\lambda')-E(\lambda)
\end{align*}
for $\lambda\leq\lambda'$, then $\bk{\xi|E(\lambda,\lambda')\xi}$ is the probability that a measurement of $T$ in the state $\xi$ yields a value in the interval $(\lambda,\lambda']$.

As in Def. \ref{lb358}, a number $\lambda\in\Rbb$ belongs to the spectrum of $T$ precisely when $E(\lambda-\eps,\lambda+\eps)\neq0$ for all $\eps>0$. For such $\lambda$, one can always choose a unit vector $\xi$ in $\Rng(E(\lambda-\eps,\lambda+\eps))$ so that $\bk{\xi|E(\lambda,\lambda')\xi}=1$. Therefore, in the state $\xi$, a measurement of $T$ is not guaranteed to yield exactly $\lambda$, but must lie within the interval $(\lambda-\eps,\lambda+\eps]$. This is the precise meaning of \textbf{measurement with arbitrarily prescribed accuracy}.



\subsubsection{Conclusion}



We can now clarify the true starting point of von Neumann's study of unbounded operators. A common misconception is that his project began with a rigorous definition of unbounded self-adjoint operators, with the goal of proving a spectral theorem for them. In fact, such a rigorous definition was not available at the outset---the notion of the adjoint for unbounded operators is far subtler than in the bounded case. Rather, von Neumann's aim was to find a natural definition of observables under which the spectral decomposition of the form \eqref{eq188} would hold.

Following von Neumann's line of thought, we introduce in Sec. \ref{lb382} the first such definition: the Hermitian operators $T$ on $\MH$ satisfying
\begin{align}\label{eq195}
\Rng(T+\im)=\Rng(T-\im)=\MH
\end{align}
(See the beginning of Subsec. \ref{lb384}.) This is not yet the final definition of unbounded self-adjoint operators; indeed, in modern textbooks it often appears as a criterion for self-adjointness rather than a definition. Nevertheless, we will see that verifying condition \eqref{eq195} is frequently more convenient than checking self-adjointness directly, and that many central ideas in the theory of unbounded operators---such as the Cayley transform and the concept of closed operators---are more naturally understood in terms of this condition.


\subsection{Basic notions about unbounded operators}


Let $\MH,\MK,\ML,\MM$ be Hilbert spaces.


\subsubsection{Definitions and basic properties}

\begin{df}
An \textbf{unbounded operator} \index{00@Unbounded operator} $T$ from $\MH$ to $\MK$ (abbreviated to $T:\MH\rightarrow\MH$) is defined to be a linear map from a linear subspace $\Dom(T)$ of $\MH$ to $\MK$. We call $\Dom(T)$ the \textbf{domain} of $T$. \index{00@Domain of an unbounded operator} If $\MH=\MK$, we say that $T$ is an \textbf{unbounded operator on $\pmb\MH$}. If $\Dom(T)=\MH$, we say that $T$ is \text{everywhere-defined}. \index{00@Everywhere-defined unbounded operator}
\end{df}

\begin{cv}\label{lb385}
Unless otherwise stated, we assume that the domain $\Dom(T)$ of an unbounded operator $T:\MH\rightarrow\MK$ is dense. If this assumption is dropped, we will say that $T$ is an \textbf{n.d.d. unbounded operator}, where ``n.d.d.'' stands for ``non-necessarily densely defined''. \index{zz@n.d.d.=non-necessarily densely defined}
\end{cv}


Note that every bounded linear operator is an unbounded operator in this sense. This is not contradictory: ``unbounded'' here simply means ``not necessarily bounded''.


\begin{df}\label{lb363}
Let $S,T:\MH\rightarrow\MK$ be n.d.d. unbounded operators. The addition $\pmb{S+T}$ \index{00@Addition of unbounded operators} is defined to be
\begin{align*}
S+T:\Dom(S)+\Dom(T)\rightarrow\MK\qquad \xi\mapsto S\xi+T\xi
\end{align*} 
which is an unbounded operator $\MH\rightarrow\MK$ whenever $\Dom(S+T):=\Dom(S)\cap\Dom(T)$ is dense in $\MH$.
\end{df}


\begin{df}\label{lb364}
Let $S:\MK\rightarrow\ML$ and $T:\MH\rightarrow\MK$ be n.d.d. unbounded operators. The composition \index{00@Composition of unbounded operators} $\pmb {ST}$ is defined to be
\begin{gather*}
ST:\Dom(ST)\rightarrow\ML\qquad\xi\mapsto ST\xi
\end{gather*}
where $\Dom(ST)$ is the space of all $\xi\in\Dom(T)$ satisfying $T\xi\in\Dom(S)$. Then $ST$ is an unbounded operator $\MH\rightarrow\ML$ whenever $\Dom(ST)$ is dense in $\MH$. If $\lambda\in\Cbb$, we define the scalar product \index{00@Scalar product of unbounded operators}  $\pmb{\lambda T}$ (with domain $\Dom(\lambda T):=\Dom(T)$) by
\begin{align*}
\lambda T:\Dom(T)\rightarrow\MK\qquad \xi\mapsto \lambda\cdot T\xi
\end{align*}
\end{df}


\begin{pp}
Let $A,B,C$ be n.d.d. unbounded operators $\MH\rightarrow\MK$. Then $(A+B)+C=A+(B+C)$.
\end{pp}


It is therefore legitimate to write $A+B+C$.

\begin{proof}
One checks that both sides have domain $\Dom(A)\cap\Dom(B)\cap\Dom(C)$, and that these two maps agree on this common domain.
\end{proof}



\begin{pp}
Let $A:\ML\rightarrow\MM$, $B:\MK\rightarrow\ML$, and $C:\MH\rightarrow\MK$ be n.d.d. unbounded operators. Then $(AB)C=A(BC)$.
\end{pp}


Due to this proposition, one can write $ABC$ unambiguously.

\begin{proof}
The only non-trivial part is the compare their domains:
\begin{align*}
\Dom((AB)C)=\Dom(A(BC))=\{\xi\in\Dom(C):C\xi\in\Dom(B),BC\xi\in\Dom(A)\}
\end{align*}
\end{proof}


\begin{pp}
Let $A,B:\MK\rightarrow\ML$ and $C,D\in\MH\rightarrow\MK$ be n.d.d. unbounded operators. Then
\begin{gather}
(A+B)C=AC+BC\qquad A(C+D)\supset AC+AD
\end{gather}
where the ``$\supset$'' in the second relation becomes ``$=$'' if $A$ is everywhere-defined.
\end{pp}



\begin{proof}
The only non-trivial part is to compare their domains:
\begin{gather*}
\Dom((A+B)C)=\Dom(AC+BC)=\{\xi\in\Dom(C):C\xi\in\Dom(A)\cap\Dom(B)\}\\
\Dom(A(C+D))=\{\xi\in\Dom(C)\cap\Dom(D):C\xi+D\xi\in\Dom(A)\}\\
\Dom(AC+AD)=\{\xi\in\Dom(C)\cap\Dom(D):C\xi\in\Dom(A),D\xi\in\Dom(A)\}
\end{gather*}
\end{proof}

\begin{eg}
Let $A$ be an unbounded operator on $\MH$ with $\Dom(A)\subsetneq\MH$. Let $C=\idt_\MH$ and $D=-\idt_\MH$. Then $A(C+D)=A0=0$ has domain $\Dom(H)$, while $AC+AD=A+(-A)$ has domain $\Dom(A)$. Thus $A(C+D)\supsetneq AC+AD$.
\end{eg}




\begin{df}
Let $S,T$ be (not necessarily defined) unbounded operators $\MH\rightarrow\MT$. We say that $T$ is an \textbf{extension} \index{00@Extensions of unbounded operators} of $S$ and write $\pmb{S\subset T}$ if $\Dom(S)\subset \Dom(T)$, and if $S\xi=T\xi$ for each $\xi\in\Dom(S)$.
\end{df}


\begin{df}
An unbounded operator $T$ on $\MH$ is called a \textbf{Hermitian operator} \index{00@Hermitian operator, unbounded} if for each $\xi,\eta\in\Dom(T)$ we have
\begin{align*}
\bk{\eta|T\xi}=\bk{T\eta|\xi}
\end{align*} 
In other words, $T$ is Hermitian iff the sesquilinear form $\pmb{\omega_T}$ associated to $T$, \index{zz@$\omega_T$, the unbounded case} \index{00@Sesquilinear forms defined by unbounded operators} as defined by
\begin{align*}
\omega_T:\Dom(T)\times\Dom(T)\rightarrow\Cbb\qquad (\eta,\xi)\mapsto\bk{\eta|T\xi}
\end{align*}
is Hermitian.
\end{df}


\subsubsection{Elementary examples of Hermitian operators}


\begin{eg}\label{lb362}
Let $\Omega\subset\Rbb^N$ be open. By Thm. \ref{lb361}, the space $C_c^\infty(\Omega)$ is dense in the Hilbert space $\MH:=L^2(\Omega,m)$. For each $1\leq j\leq N$, let $\pbf_i$ be the unbounded operator on $\MH$ defined by
\begin{align*}
\pbf_j=\frac{\partial}{\im\partial x_j}\qquad\Dom(\pbf_j)=C_c^\infty(\Omega)
\end{align*}
Then $\pbf_j$ is Hermitian.
\end{eg}



\begin{proof}
We consider for simplicity the case $j=1$. For each $f,g\in C_c^\infty(\Omega)$, using integration by parts, we compute
\begin{align*}
\int_\Rbb \ovl f\partial_1gdx_1=\ovl fg\big|_{x_1=-\infty}^{+\infty}-\int_\Rbb \ovl{\partial_1f}gdx_1=-\int_\Rbb \ovl{\partial_1f}gdx_1
\end{align*}
as functions of $x_2,\dots,x_N$. Hence
\begin{align*}
&\bk{f|\pbf_1g}=\int_{\Rbb^{N-1}}\int_\Rbb -\im \ovl f\partial_1g dx_1\cdot dx_2\cdots dx_N\\
=&\int_{\Rbb^{N-1}}\int_\Rbb \ovl{-\im\partial_1f}g dx_1\cdot dx_2\cdots dx_N=\bk{\pbf_1f|g}
\end{align*}
\end{proof}


\begin{eg}
We work in the setting of Exp. \ref{lb362}. Let $f$ be a real polynomial with $N$ mutually-commuting variables. Define $f(\pbf_\blt)=f(\pbf_1,\dots,\pbf_N)$ in the obvious way, e.g., if $f=x_1x_3^2-2x_4^3x_5$ then $f(\pbf_\blt)=\pbf_1\pbf_3^2-2\pbf_4^3\pbf_5$. According to Def. \ref{lb363} and \ref{lb364}, $f(\pbf_\blt)$ has domain $C_c^\infty(\Omega)$. Using the fact that each $\pbf_j$ is Hermitian, one easily checks that $f(\pbf_\blt)$ is Hermitian. In particular, the \textbf{Laplacian} \index{00@Laplacian $\Delta$}
\begin{align*}
\Delta=-\pbf_1^2-\cdots-\pbf_N^2=\partial_{x_1}^2+\cdots+\partial_{x_N}^2
\end{align*}
(with domain $C_c^\infty(\Omega)$) is Hermitian.
\end{eg}

\begin{df}\label{lb365}
Let $(X,\fk M,\mu)$ be a measure space. Let $f:X\rightarrow\Cbb$ be measurable. The \textbf{multiplication operator} \index{00@Multiplication operator $\Mbf_f$, unbounded} $\pmb{\Mbf_f}$ \index{Mf@$\Mbf_f$, the multiplication operator, unbounded} is an unbounded operator on $L^2(X,\mu)$ defined by
\begin{gather*}
\Mbf_f:\Dom(\Mbf_f)\rightarrow L^2(X,\mu)\qquad \xi\mapsto f\xi\\
\Dom(\Mbf_f)=\{\xi\in L^2(X,\mu):f\xi\in L^2(X,\mu)\}
\end{gather*}
If $f$ is real-valued, then $\Mbf_f$ is clearly Hermitian.
\end{df}


\begin{proof}
We need to prove that $\Dom(\Mbf_f)$ is dense. Let
\begin{align*}
V_n=\{\xi\in L^2(X,\mu):\xi\text{ vanishes outside $X_n$ and }\{x\in X:|f(x)|\leq n\}=0\}
\end{align*}
Then $\sum_{n\in\Zbb_+} V_n$ is dense in $L^2(X,\mu)$ (by DCT), and each $V_n$ is contained in $\Dom(\Mbf_f)$. Thus $\Dom(\Mbf_f)$ is dense because it contains $\sum_{n\in\Zbb_+} V_n$.
\end{proof}



\begin{df}
Let $(\MH_\alpha)_{\alpha\in\SI}$ and $(\MK_\alpha)_{\alpha\in\SI}$ collections of Hilbert spaces. For each $\alpha\in\SI$, let $T_\alpha:\MH_\alpha\rightarrow\MK_\alpha$ be an n.d.d. unbounded operators. Their \textbf{direct sum} \index{00@Direct sum of unbounded operators} $\pmb{\oplus_{\alpha\in\SI}T_\alpha}$ is an n.d.d. unbounded operator $\bigoplus_{\alpha\in\SI}\MH_\alpha\rightarrow \bigoplus_{\alpha\in\SI}\MK_\alpha$ defined by
\begin{gather*}
\oplus_{\alpha\in\SI}T_\alpha:\Dom(\oplus_{\alpha\in\SI}T_\alpha)\rightarrow \bigoplus_{\alpha\in\SI}\MK_\alpha\qquad \oplus_{\alpha\in\SI}\xi_\alpha\mapsto \oplus_{\alpha\in\SI} T_\alpha\xi_\alpha
\end{gather*}
where
\begin{align*}
\Dom(\oplus_{\alpha\in\SI}T_\alpha)=\Big\{\oplus_\alpha\xi_\alpha\in \bigoplus_{\alpha\in\SI}\MH_\alpha:~&\xi_\alpha\in\Dom(T_\alpha)\text{ for all }\alpha\in\SI\\
&\text{and }\sum_{\alpha\in\SI}\Vert T_\alpha\xi_\alpha\Vert^2<+\infty\Big\}
\end{align*}
\end{df}







\begin{eg}\label{lb366}
Let $(X,\fk M)$ be a measurable space. Let $(\mu_\alpha)_{\alpha\in\SI}$ be a family of measures on $\fk M$. Let $f:X\rightarrow\Cbb$ be measurable. Then $\oplus_{\alpha\in\SI}\Mbf_f$ is an unbounded operator on $\bigoplus_{\alpha\in\SI}L^2(X,\mu_\alpha)$ with domain
\begin{align*}
\Dom(\oplus_{\alpha\in\SI}\Mbf_f)=\Big\{\oplus_\alpha\xi_\alpha\in \bigoplus_{\alpha\in\SI}\MH_\alpha: \oplus_\alpha f\xi_\alpha\in\bigoplus_{\alpha\in\SI}\MH_\alpha\Big\}
\end{align*}
When no confusion arises, we
\begin{align}
\boxed{~\text{abbreviate $\oplus_\alpha\Mbf_f$ to $\Mbf_f$}~}
\end{align}
and also call $\Mbf_f$ the \textbf{multiplication operator}.\index{Mf@$\Mbf_f$, the multiplication operator, unbounded} If $f$ is real-valued, then $\Mbf_f$ is clearly Hermitian.
\end{eg}


\begin{proof}
Similar to Def. \ref{lb365}, we need to check that $T:=\oplus_{\alpha\in\SI}\Mbf_f$ has dense domain in $\MH:=\bigoplus_{\alpha\in\SI}L^2(X,\mu_\alpha)$. Let $V$ be the set of all $\oplus_\alpha\xi_\alpha$ in $\MH$ satisfying the following conditions:
\begin{itemize}
\item There exists a finite set $I\subset\SI$ such that $\xi_\alpha=0$ for all $\alpha\notin I$.
\item For each $\alpha\in I$, there exists $n_\alpha\in\Zbb_+$ such that the function $\xi_\alpha$ vanishes outside $\{x\in X:|f(x)|\leq n_\alpha\}$.
\end{itemize}
Then $V$ is clearly a linear subspace of $\MH$.
\end{proof}

\begin{exe}
Complete the above proof by showing that $V$ is dense in $\MH$, and that $V$ is contained in $\Dom(T)$.
\end{exe}





\begin{rem}\label{lb371}
In Exp. \ref{lb366}, if $f,g:X\rightarrow\Cbb$ are both measurable, in general we only have
\begin{align*}
\Mbf_f\Mbf_g\subset\Mbf_{fg}
\end{align*}
However, if $g$ is bounded (or more generally, if $\Vert g\Vert_{L^\infty(X,\mu_\alpha)}<+\infty$ for each $\alpha$), then
\begin{align*}
\Mbf_f\Mbf_g=\Mbf_{fg}
\end{align*}
since both sides have domain consisting of all $\oplus_\alpha\xi_\alpha\in\bigoplus_\alpha L^2(X,\mu_\alpha)$ satisfying $\sum_\alpha\Vert fg\xi_\alpha\Vert_{L^2}^2<+\infty$.
\end{rem}



\subsubsection{Inverses of unbounded operators}


\begin{df}\label{lb377}
Let $T:\MH\rightarrow\MK$ be an n.d.d. unbounded operator. Assume that $T$ is injective, equivalently, that the kernel \index{00@Kernel of an unbounded operator}
\begin{align*}
\pmb{\Ker(T)}:=\{\xi\in\Dom(T):T\xi=0\}
\end{align*}
is zero. The \textbf{inverse} \index{00@Inverse of an unbounded operator} of $T$ is the n.d.d. unbounded operator $\MK\rightarrow\MH$ defined by
\begin{gather*}
\pmb{T^{-1}}:\Rng(T)\rightarrow\MH\qquad T\xi\mapsto \xi
\end{gather*}
with $\Dom(T^{-1})=\Rng(T)$. It is clear that $T^{-1}$ is injective and $(T^{-1})^{-1}=T$. Note that $T$ has dense range iff $T^{-1}$ is a (densely-defined) unbounded operator.
\end{df}

It is useful to keep in mind that
\begin{gather}
\Dom(T^{-1})=\Rng(T)\qquad \Dom(T)=\Rng(T^{-1})
\end{gather}


\begin{pp}
Let $A:\MK\rightarrow\ML$ and $B:\MH\rightarrow\MK$ be injective n.d.d. unbounded operators. Note that $AB$ is clearly injective. We have
\begin{align*}
(AB)^{-1}=B^{-1}A^{-1}
\end{align*}
\end{pp}

\begin{proof}
The only non-trivial part is to compare their domains. The domain of $(AB)^{-1}$ is $\Rng(AB)$. An element $\psi\in\ML$ belongs to $\Dom(B^{-1}A^{-1})$ iff $\psi\in\Dom(A^{-1})=\Rng(A)$ and $A^{-1}\psi\in\Dom(B^{-1})=\Rng(B)$, iff $\psi=A\eta$ and $\eta=B\xi$ for some $\eta\in\Dom(A)$ and $\xi\in\Dom(B)$, iff $\psi\in\Rng(AB)$.
\end{proof}







\begin{eg}\label{lb372}
Let $(X,\fk M)$ be a measurable space. Let $(\mu_\alpha)_{\alpha\in\SI}$ be a family of measures on $\fk M$. Let $f:X\rightarrow\Cbb$ be measurable. Let $\MH=\bigoplus_{\alpha\in\SI}L^2(X,\mu_\alpha)$. Then
\begin{align}\label{eq191}
\Ker(\Mbf_f)=\Big\{\oplus_\alpha\xi_\alpha\in\MH:\text{each }\xi_\alpha\text{ is }\mu_\alpha\text{-a.e. zero outside }f^{-1}(0) \Big\}
\end{align}
Equivalently, $\Ker(\Mbf_f)$ equals the range of $\Mbf_{\chi_{f^{-1}(0)}}$. Consequently, $\Mbf_f$ is injective iff $f^{-1}(0)$ is $\mu_\alpha$-null for each $\alpha$.
\end{eg}

It follows that $\Mbf_f$ is injective iff there exists a measurable $g:X\rightarrow\Cbb$ such that $fg=1$ a.e. in $\mu_\alpha$ for each $\alpha\in\SI$.\footnote{The direction ``$\Leftarrow$'' follows from $f^{-1}(0)\subset\{x\in X:f(x)g(x)\neq1\}$. The direction ``$\Rightarrow$'' follows by defining $g$ to be $g(x)=1/f(x)$ when $f(x)\neq0$ and $g(x)=0$ when $f(x)=0$.}


\begin{proof}[Proof of \eqref{eq191}]
An element $\oplus_\alpha\xi_\alpha\in\MH$ belongs to $\Ker(\Mbf_f)$ iff $f\xi_\alpha=0$ in $L^2(X,\mu_\alpha)$ for each $\alpha$, iff $f\xi_\alpha=0$ a.e. in $\mu_\alpha$, iff $\oplus_\alpha\xi_\alpha$ belongs to the RHS of \eqref{eq191}.
\end{proof}




\begin{eg}\label{lb373}
Let $(X,\fk M)$ be a measurable space. Let $(\mu_\alpha)_{\alpha\in\SI}$ be a family of measures on $\fk M$. Suppose that $f,g:X\rightarrow\Cbb$ are measurable functions satisfying $fg=1$ a.e. in $\mu_\alpha$ for each $\alpha\in\SI$. Then on $\MH:=\bigoplus_{\alpha\in\SI}L^2(X,\mu_\alpha)$, both $\Mbf_f$ and $\Mbf_g$ are injective and have dense ranges. Moreover, we have $\Mbf_g=\Mbf_f^{-1}$, and hence $\Mbf_f=\Mbf_g^{-1}$.
\end{eg}




\begin{proof}
We have
\begin{gather*}
\Dom(\Mbf_f)=\{\oplus_\alpha\xi_\alpha\in\MH:\oplus_\alpha f\xi_\alpha\in\MH\}\\
\Rng(\Mbf_f)=\{\oplus_\alpha \eta_\alpha\in\MH:\oplus_\alpha \eta_\alpha=\oplus_\alpha f\xi_\alpha\text{ for some }\oplus_\alpha\xi_\alpha\in\MH\}\\
\Dom(\Mbf_g)=\{\oplus_\alpha\eta_\alpha\in\MH:\oplus_\alpha g\xi_\alpha\in\MH\}\\
\Rng(\Mbf_g)=\{\oplus_\alpha \xi_\alpha\in\MH:\oplus_\alpha \xi_\alpha=\oplus_\alpha g\eta_\alpha\text{ for some }\oplus_\alpha\eta_\alpha\in\MH\}
\end{gather*}
It follows immediately that 
\begin{align*}
\Dom(\Mbf_g)=\Rng(\Mbf_f)\qquad \Rng(\Mbf_g)=\Dom(\Mbf_f)
\end{align*}
that $\Mbf_f$ sends $\oplus_\alpha\xi_\alpha$ bijectively to $\oplus_\alpha\eta_\alpha$, and that $\Mbf_g$ sends $\oplus_\alpha\eta_\alpha$ bijectively to $\oplus_\alpha\xi_\alpha$. Thus $\Mbf_f:\Dom(\Mbf_f)\rightarrow\Rng(\Mbf_f)$ and $\Mbf_g:\Rng(\Mbf_f)\rightarrow\Dom(\Mbf_f)$ are inverses of each other. In particular, $\Mbf_g$ and $\Mbf_f$ are injective with dense ranges.
\end{proof}


\subsubsection{Inverses of bounded operators}


Exp. \ref{lb373} shows that $\oplus_{\alpha\in\SI}\Mbf_f$ has dense range if it is injective. In the case where $f$ is bounded (and hence $\oplus_{\alpha\in\SI}\Mbf_f$ is a bounded normal operator), this phenomenon can be understood in a more general setting.



\begin{df}
We say that an unbounded operator $T:\MH\rightarrow\MK$ has an \textbf{everywhere-defined bounded inverse} \index{00@Everywhere-defined bounded inverse} if $T=S^{-1}$ for some injective $S\in\fk L(\MK,\MH)$ with dense range. (Note that such $S$ must be unique, since $S=T^{-1}$.)
\end{df}

For bounded linear operators, injectivity and dense range are closely related:



\begin{pp}\label{lb370}
Let $T\in\fk L(\MH,\MK)$. Then
\begin{align*}
\Ker(T)=\Rng(T^*)^\perp\qquad \ovl{\Rng(T)}=\Ker(T^*)^\perp
\end{align*}
\end{pp}

It follows from Cor. \ref{lb369} that $T$ has dense range iff $\Ker(T^*)$ is injective.


\begin{proof}
For each $\xi\in\MH$, we have $\xi\in\Ker(T)$ iff $T\xi=0$ iff $\bk{\MK|T\xi}=0$ iff $\bk{T^*\MK|\xi}=0$ iff $\xi\in\Rng(T^*)$ iff $\xi\in\Rng(T^*)^\perp$. This proves the first identity. Replacing $T$ with $T^*$, we obtain $\Ker(T^*)=\Rng(T)^\perp$, and hence
\begin{align*}
\ovl{\Rng(T)}=\Rng(T)^{\perp\perp}=\Ker(T^*)^\perp
\end{align*}
due to Cor. \ref{lb151}.
\end{proof}


\begin{rem}\label{lb381}
Suppose that $T\in\fk L(\MH)$ is normal. Then 
\begin{align*}
\Ker(T)=\Ker(T^*)
\end{align*}
since $\Vert T\xi\Vert^2=\Vert T^*\xi\Vert^2$ for each $\xi\in\MH$. It follows from Prop. \ref{lb370} that $T$ is injective iff $T$ has dense range.
\end{rem}




\subsection{Extensions of Hermitian operators I: reduction to extensions of unitary maps}\label{lb382}

Let $\MH$ be a Hilbert space.


\subsubsection{Introduction}\label{lb395}


In this section we follow von Neumann's idea in \cite{vN29a} to investigate which Hermitian operators admit spectral decompositions. As noted in Subsec. \ref{lb375}, a spectral decomposition for a Hermitian operator $T$ means that it can be written in the form $\int_{-\infty}^{+\infty}\lambda dE(\lambda)$. We will take a more modern, beginner-friendly viewpoint: we say that $T$ has a spectral decomposition if it is unitarily equivalent to a multiplication operator on a direct sum of $L^2$-spaces (cf. Exp. \ref{lb366}).

Von Neumann's key idea was to use the Cayley transform to connect Hermitian operators and unitary operators. The Cayley transform itself goes back to Cayley, who gave a systematic way to construct (generic) real orthogonal matrices from skew-symmetric matrices via the formula
\begin{align*}
U=\frac{\idt+A}{\idt-A}
\end{align*}
where $A$ is skew-symmetric (so $\idt-A$ is invertible). Here ``generic'' means that $1$ is not an eigenvalue of $U$. 

For von Neumann, the Cayley transform and its inverse
\begin{align*}
U=\frac{T-\im}{T+\im}\qquad T=\frac{U+\idt}{\im(U-\idt)}
\end{align*}
connect ``generic'' unitary operators $U$ with Hermitian operators $T$ that admit spectral decompositions. The meaning of ``generic'' becomes clear if we take $T$ to be a multilication operator $\Mbf_f$ where $f:X\rightarrow\Rbb$ is measurable. Then $U$ is expected to correspond to $\Mbf_u$ where $u=(f+\im)/(f-\im)$. One can easily check that $u$ takes values in $\Sbb^1\setminus\{1\}$, and conversely any measurable function $u:X\rightarrow\Sbb^1\setminus\{1\}$ arises in this way from some measurable $f:X\rightarrow\Rbb$. In light of Exp. \ref{lb372}, it is natural to guess that ``generic'' here should mean that the unitary operator $U$ satisfies $\Ker(U-\idt)=\{0\}$.


Thus, a preliminary answer to the question ``which Hermitian operators admit spectral decompositions?'' is: those Hermitian operators that, via the Cayley transform (to be defined rigorously), correspond to unitary operators $U$ with $\Ker(U-\idt)=\{0\}$. As we will see in the following subsections, it is more convenient to work with the assumption that $\Rng(U-\idt)$ is dense in $\MH$, though this condition is equivalent to $\Ker(U-\idt)=\{0\}$ (for unitary operators $U\in\fk L(\MH)$) due to Rem. \ref{lb381}.

In what follows we will make precise sense of these transforms. In doing so, we will see that the Cayley transform is well defined for any Hermitian operator, though the result need not be unitary on the whole space $\MH$. This more general perspective will help us address the following deeper question: if a Hermitian operator does not admit a spectral decomposition, can it be extended to one that does? And if so, how can such extensions be characterized?



\subsubsection{The Cayley transform}


\begin{lm}\label{lb376}
Let $T$ be a Hermitian operator on $\MH$. Then all eigenvalues of $T$ are real numbers.
\end{lm}



\begin{proof}
Suppose that $a+b\im$ is an eigenvalue of $T$, where $a,b\in\Rbb$ and $b\neq0$. Then there exists a non-zero $\xi\in\Ker(T-a-b\im)$, and hence hence $\bk{\xi|(T-a)\xi}=b\im\bk{\xi|\xi}$. This is impossible, since $\bk{\xi|(T-a)\xi}\in\Rbb$ and $\bk{\xi|\xi}\in\Rbb_{>0}$.
\end{proof}


According to Lem. \ref{lb376}, we have $\Ker(T-\im)=\Ker(T+\im)=\{0\}$. Therefore, by Def. \ref{lb377}, $(T\pm\im)^{-1}$ can be defined as (not necessarily dense-defined) unbounded operators on $\MH$.


\begin{df}\label{lb379}
Let $T$ be a Hermitian operator on $\MH$. The \textbf{Cayley transform} \index{00@Cayley transforms of Hermitian operators} the n.d.d. unbounded operator on $\MH$ defined by
\begin{align*}
(T-\im)(T+\im)^{-1}:\Rng(T+\im)\rightarrow\MH
\end{align*}
and commonly denoted by $\frac{T-\im}{T+\im}$. In other words, the Cayley transform of $T$ is the unique linear map satisfying
\begin{align*}
\dps\frac{T-\im}{T+\im}:\Rng(T+\im)\rightarrow\MH\qquad (T+\im)\xi\mapsto (T-\im)\xi
\end{align*}
for each $\xi\in\Dom(T)$.
\end{df}

\begin{pp}\label{lb380}
Let $T$ be a Hermitian operator on $\MH$. After restricting the codomain, the Cayley transform $U_T$ of $T$ is a unitary map
\begin{align}\label{eq192}
\tcboxmath{\frac{T-\im}{T+\im}:\Rng(T+\im)\xlongrightarrow{\simeq}\Rng(T-\im)\qquad (T+\im)\xi\mapsto (T-\im)\xi}
\end{align}
Moreover, the range of $U_T-\idt$ equals $\Dom(T)$; in particular, it is a dense in $\MH$.
\end{pp}

\begin{proof}
For each $\xi\in\Dom(T)$, we compute that
\begin{align}\label{eq197}
\Vert (T\pm\im)\xi\Vert^2=\bk{T\xi|T\xi}+\bk{\xi|\xi}
\end{align}
since $\bk{\xi|T\xi}=\bk{T\xi|\xi}$ is real. Thus $U_T$ is a linear isometry; its image is clearly $\Rng(T-\im)$.

The map $U_T-\idt$ sends each $(T+\im)\xi$ to $(T-\im)\xi-(T+\im)\xi=-2\xi$ (where $\xi\in\Dom(T)$). Hence $\Rng(U_T-\idt)=\Dom(T)$.
\end{proof}


Our next goal is to determine which unitary maps arise from Hermitian operators via the Cayley transform.


\begin{lm}\label{lb378}
Let $U:\Dom(U)\xlongrightarrow{\simeq}\Rng(U)$ be a unitary map between two linear subspaces of $\MH$. Suppose that $\Rng(U-\idt)$ is dense in $\MH$. Then $\Ker(U-\idt)=\{0\}$.
\end{lm}

More precisely, if $(U-\idt)\Dom(U)$ is dense in $\MH$, then the only vector $\xi\in\Dom(U)$ satisfying $U\xi=\xi$ is the zero vector.


\begin{proof}
Choose any $\xi\in\Dom(U)$ satisfying $U\xi=\xi$. Then for each $\eta\in\Dom(U)$, we have $\bk{\eta|\xi}=\bk{U\eta|U\xi}$, and hence
\begin{align*}
\bk{(U-\idt)\eta|\xi}=\bk{U\eta|\xi}-\bk{\eta|\xi}=\bk{U\eta|\xi}-\bk{U\eta|U\xi}=\bk{U\eta|\xi-U\xi}=0
\end{align*}
Since all such $(U-\idt)\eta$ form the dense linear subspace $\Rng(U-\idt)$, we conclude that $\xi=0$.
\end{proof}


\begin{thm}\label{lb383}
There is a bijection between:
\begin{enumerate}
\item[(1)] A Hermitian operator $T$ on $\MH$.
\item[(2)] A unitary map $U:\Dom(U)\xlongrightarrow{\simeq}\Rng(U)$ where $\Dom(U)$ and $\Rng(U)$ are linear subspaces of $\MH$, and $\Rng(U-\idt)$ is dense in $\MH$.
\end{enumerate}
Viewing each $U$ in (2) as an n.d.d. unbounded operator on $\MH$, the correspondence is given by
\begin{align*}
U=(T-\im)(T+\im)^{-1}\qquad T=-\im(U+\idt)(U-\idt)^{-1}
\end{align*} 
Moreover, if $\wtd T$ and $\wtd U$ are also related by this bijection, then
\begin{align}\label{eq194}
T\subset\wtd T\qquad\Longleftrightarrow\qquad U\subset\wtd U
\end{align}
\end{thm}

Note that $(U-\idt)^{-1}$ is well-defined by Lem. \ref{lb378}. As in Def. \ref{lb379}, it is customary to write $-\im(U+\idt)(U-\idt)^{-1}$ as $\frac{U+\idt}{\im(U-\idt)}$ and call it the \textbf{inverse Cayley transform} of $U$. \index{00@Inverse Cayley transform} It is the unique map satisfying
\begin{align}\label{eq193}
\tcboxmath{\frac{U+\idt}{\im(U-\idt)}:\Rng(U-\idt)\rightarrow\MH\qquad \im(U\eta-\eta)\mapsto U\eta+\eta}
\end{align}
where $\eta\in\Dom(U)$.



\begin{proof}
Step 1. For each Hermitian $T$ on $\MH$, we denote its Cayley transform by $U_T$. Then $U_T$ satisfies condition (2) by Prop. \ref{lb380}. For each $U$ satisfying (2) we denote its inverse Cayley transform by $T_U$. Let us prove that $T_U$ is a Hermitian operator on $\MH$.

By \eqref{eq193}, the domain of $T_U$ is $\Rng(U-\idt)$, which is dense in $\MH$ by assumption. For each $\xi=(U-\idt)\eta$ where $\eta\in\Dom(U)$, we compute that
\begin{align*}
\bk{\xi|T_U\xi}=\bk{U\eta-\eta|T_U(U\eta-\eta)}\xlongequal{\eqref{eq193}}\im\bk{U\eta-\eta|U\eta+\eta}=\im(\bk{U\eta|\eta}-\bk{\eta|U\eta})
\end{align*}
where $\bk{U\eta|U\eta}=\bk{\eta|\eta}$ is used. Since $\bk{U\eta|\eta}=\ovl{\bk{\eta|U\eta}}$, the last term above is a real number. Thus $\bk{\xi|T_U\xi}$ is real, and hence $T_U$ is Hermitian.\\[-1ex]

Step 2. Next we must prove that $T_{U_T}=T$ and $U_{T_U}=U$, and that the equivalence \eqref{eq193} holds. While these facts can be checked directly, the most convenient argument is to use operator graphs. We therefore defer the proof of Step 2 to Rem. \ref{lb394}.
\end{proof}


\subsubsection{From extensions of unitary maps $U:\Dom(U)\rightarrow\Rng(U)$ to extensions of Hermitian operators}\label{lb384}


Thm. \ref{lb383} suggests that the Hermitian operators $T$ admitting spectral decompositions are precisely those whose Cayley transforms $U_T$ are unitary operators on $\MH$.\footnote{If $T=\Mbf_f$ where $f:X\rightarrow\Rbb$ is measurable, one can show that $U_T=\Mbf_u$ where $u=(f-\im)/(f+\im)$, and hence is unitary on $\MH$.} Equivalently, these are the operators for which
\begin{align}\label{eq196}
\Dom(U_T)\equiv\Rng(T+\im)=\MH\qquad \Rng(U_T)\equiv\Rng(T-\im)=\MH
\end{align}
which justifies the condition \eqref{eq195}.


Even if the Hermitian operator $T$ does not satisfy \eqref{eq196} (that is, if the Cayley transform $U_T$ is not a unitary operator on the whole space $\MH$), Thm. \ref{lb383} shows that $T$ can be extended to a Hermitian operator satisfying \eqref{eq196} iff $U_T$ can be extended to a unitary operator on $\MH$. Our next task, therefore, is to extend operators $U$ satisfying condition (2) of Thm. \ref{lb383}, and to analyze how such extensions correspond, via the Cayley transform, to extensions of Hermitian operators.


The natural first step is to extend any such $U$ to a bounded linear operator
\begin{align*}
\ovl U:\ovl{\Dom(U)}\longrightarrow\ovl{\Rng(U)}
\end{align*}
which exists uniquely by Thm. \ref{lb31} (together with the completeness of $\ovl{\Rng(U)}$). This extension remains a linear isometry, and hence is unitary by Thm. \ref{lb367}. The second step is then to extend $\ovl U$ further; however, this extension is no longer unique.



\begin{question}\label{lb390}
Let $T$ be a Hermitian operator on $\MH$. Let $\ovl T$ denote the inverse Cayley transform of $\ovl{U_T}$, the unique bounded linear extension of $U_T$ to $\ovl{\Dom(U_T)}$. Can we give a direct definition of $\ovl T$ without appealing to its Cayley transform $\ovl{U_T}$?
\end{question}

The idea for approaching this question is as follows. Note that $\Dom(\ovl{U_T})$ consists of vectors $\eta\in\MH$ that are limits of elements of $\Dom(U_T)=\Rng(T+\im)$. Thus, $\eta\in\MH$ belongs to $\Dom(\ovl{U_T})$ iff there exists a sequence $(\xi_n)$ in $\Dom(T)$ such that $\eta=\lim_n (T+\im)\xi_n$. In view of \eqref{eq197}, the fact that $(T\xi_n+\im\xi_n)$ is a Cauchy sequence is equivalent to that both $(\xi_n)$ and $(T\xi_n)$ are Cauchy sequences. This suggests that $\xi:=\lim_n\xi_n$ should be in the domain $\Dom(\ovl T)$, and that such $\xi$ form the whole domain $\Dom(\ovl T)$. Moreover, it is easy to guess how $\ovl T$ is defined on such $\xi$: the element $\ovl T\xi$ should equal $\lim_n T\xi_n$. 


Although the above reasoning can be made rigorous, in the next section we prefer to present the argument using the important concept of operator graphs, introduced implicitly by von Neumann in \cite{vN29a} and later further explored in \cite{vN32b}. In particular, as we will see in Def. \ref{lb386}, the approximation $(\xi_n,T\xi_n)\rightarrow(\xi,\ovl T\xi)$ mentioned above can be understood geometrically in terms of operator graphs and their closures.







\subsection{Extensions of Hermitian operators II: the unique part}\label{lb398}


Fix Hilbert spaces $\MH,\MK$. 

In this section, we define closures of n.d.d. unbounded operators and explore their basic properties. Not every unbounded operator admits a closure; those that do are called closable. In Thm. \ref{lb389}, we will prove that every Hermitian operator $T$ is closable, that its closure $\ovl T$ is Hermitian, and that the Cayley transform of $\ovl T$ is exactly the unique bounded linear extension of the Cayley transform $U_T$ of $T$ to $\ovl{\Dom(U_T)}$. This provides a complete answer to Question \ref{lb390}.



\subsubsection{Graphs and closures of unbounded operators}


\begin{df}
For each n.d.d. unbounded operator $T:\MH\rightarrow\MK$, the \textbf{graph} \index{00@Graph of unbounded operators} of $T$ is defined to be
\begin{align*}
\SG(T)=\{\xi\oplus T\xi:\xi\in\Dom(T)\}
\end{align*}
which is clearly a linear subspace of $\MH\oplus\MK$. We equip $\SG(T)$ with the inner product inherited from $\MH\oplus\MK$.
\end{df}

Clearly, for two n.d.d. unbounded operators $T_1,T_2:\MH\rightarrow\MK$, we have $T_1\subset T_2$ iff $\SG(T_1)\subset\SG(T_2)$.


\begin{df}
Let $\fk G$ be a linear subspace of $\MH\oplus\MK$. The \textbf{domain} \index{00@Domain of a subspace of $\MH\oplus\MK$} of $\fk G$ is defined by \index{Dom@$\Dom(\fk G)$, the domain of a subspace of $\MH\oplus\MK$}
\begin{align*}
\pmb{\Dom(\fk G)}=\{\xi\in\MH:\xi\oplus\eta\in\fk G\text{ for some }\eta\in\MK\}
\end{align*}
which is clearly a linear subspace of $\MH$. We say that $\fk G$ is \textbf{densely-defined} \index{00@Densely-defined linear subspace of $\MH\oplus\MK$} if $\Dom(\fk G)$ is dense in $\MH$.
\end{df}


It is helpful to view a linear subspace $\fk G\in\MH\oplus\MK$ as a linear relation between elements of $\MH$ and $\MK$.


\begin{eg}
Let $T:\MH\rightarrow\MK$ be an n.d.d. unbounded operator. Then
\begin{align*}
\Dom(T)=\Dom(\SG(T))
\end{align*}
\end{eg}


\begin{df}\label{lb387}
Let $\fk G$ be a linear subspace of $\MH\oplus\MK$. We say that $\fk G$ is an \textbf{operator graph} \index{00@Operator graph} if one of the following equivalent conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item $\fk G=\SG(T)$ for some n.d.d. unbounded operator $T:\MH\rightarrow\MK$.
\item $\fk G$ is an operator graph if for each $\xi\in\MH$ there exists at most one $\eta\in\MH$ such that $\xi\oplus\eta\in\fk G$.
\item Any element $\eta\in\MK$ satisfying $0\oplus\eta\in\fk G$ must be zero.
\end{enumerate} 
\end{df}

\begin{proof}[Proof of equivalence]
We clearly have (1)$\Leftrightarrow$(2) and (2)$\Rightarrow$(3). Assume (3). If both $\xi\oplus\eta$ and $\xi\oplus\eta'$ belong to $\fk G$, then $0\oplus(\eta-\eta')\in\fk G$, and hence $\eta=\eta'$. This proves (2).
\end{proof}




\begin{df}
Let $T:\MH\rightarrow\MK$ be an n.d.d. unbounded operator. We say that $T$ is \textbf{closed} if $\SG(T)$ is a closed subset of $\MH\oplus\MK$. \index{00@Closed unbounded operators} We say that $T$ is \textbf{closable} if one of the following equivalent conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item $\ovl{\SG(T)}\equiv\Cl_{\MH\oplus\MK}(\SG(T))$ is an operator graph.
\item If $(\xi_n)$ is a sequence in $\Dom(T)$ converging to $0$ such that $(T\xi_n)$ converges, then $\lim_n T\xi_n=0$.
\item If $(\xi_\alpha)$ is a net in $\Dom(T)$ converging to $0$ such that $(T\xi_\alpha)$ converges, then $\lim_\alpha T\xi_\alpha=0$.
\end{enumerate}  

If $T$ is closable, we let $\pmb{\ovl T}$ be the unique n.d.d. unbounded operator $\MH\rightarrow\MK$ extending $T$, and call $\ovl T$ the \textbf{closure} of $T$. \index{00@Closure of unbounded operators}  \hqed
\end{df}

\begin{proof}[Proof of equivalence]
For each $\eta\in\MK$, we have $0\oplus\eta\in\ovl{\SG(T)}$ iff there exists a sequence $(\xi_n\oplus T\xi_n)$ in $\SG(T)$ converging to $0\oplus\eta$, iff there exists a sequence $(\xi_n)$ in $\Dom(T)$ converging to $0$ such that $\lim_n T\xi_n=\eta$. Thus, condition (3) of Def. \ref{lb387} is equivalent to condition (2) of the current definition. This proves (1)$\Leftrightarrow$(2). A similar argument proves (1)$\Leftrightarrow$(3).
\end{proof}



\begin{cv}
As in Convention \ref{lb385}, a closable/closed operator $T$ is automatically understood to be densely-defined. If this assumption is dropped, we will say that $T$ is an \textbf{n.d.d. closable/closed operator}. However, if it has already been stated that an unbounded operator is n.d.d., then ``closable'' and ``closed'' are automatically taken in the n.d.d. sense.
\end{cv}


\begin{pp}
Let $T:\MH\rightarrow\MK$ be an n.d.d. unbounded operator. The following are equivalent.
\begin{enumerate}
\item[(1)] $T$ is closable.
\item[(2)] There is an n.d.d. closed operator $\wtd T:\MH\rightarrow\MK$ extending $T$.
\end{enumerate}
Moreover, if $T$ is closable, then $\ovl T$ is the smallest n.d.d. closed operator extending $T$. 
\end{pp}



\begin{proof}
Assume (1). Then $\ovl T$ is an n.d.d. closed operator extending $T$. This proves (2). If $\wtd T:\MH\rightarrow\MK$ is also closed and extends $T$, then $\SG(\wtd T)$ is a closed set containing the closure $\SG(\ovl T)$ of $\SG(T)$, and hence $\ovl T\subset\wtd T$. This proves that $\ovl T$ is the smallest n.d.d. closed extension.

Assume (2), then each $\eta$ in the second component of $\SG(\wtd T)$ corresponds to at most one element of $\MH$. The same property holds for any linear subspace of $\SG(\wtd T)$. In particular, it holds for $\ovl{\SG(T)}$, since $\SG(\wtd T)$ is closed and contains $\SG(T)$. Therefore, $\ovl{\SG(T)}$ is an operator graph. This proves (1).
\end{proof}

\begin{pp}\label{lb388}
Let $T:\MH\rightarrow\MK$ be an n.d.d. unbounded operator whose restriction $T|_{\Dom(T)}:\Dom(T)\rightarrow\MK$ is bounded. Then $T$ is closable, and the closure $\ovl T$ is the unique bounded linear extension of $T|_{\Dom(T)}$ to $\ovl{\Dom(T)}\rightarrow\MK$. In particular, $T$ is closed iff $\Dom(T)$ is a closed subspace of $\MH$.
\end{pp}

\begin{proof}
Let $\wht T:\ovl{\Dom(T)}\rightarrow\MK$ denote the unique bounded linear extension of $T$, which exists due to Thm. \ref{lb31}. 

Proof of $\SG(\wht T)\subset\ovl{\SG(T)}$: Let $\xi\oplus \wht T\xi\in\SG(\wht T)$. Then there exists a sequence $(\xi_n)$ in $\Dom(T)$ converging to $\xi$. Since $\wht T$ is bounded, the sequence $(T\xi_n)$ converges to $\wht T\xi$. Hence $(\xi_n,T\xi_n)$ is a sequence in $\SG(T)$ converging to $\xi\oplus \wht T\xi$. This proves that $\xi\oplus \wht T\xi\in\ovl{\SG(T)}$.

Proof of $\ovl{\SG(T)}\subset\SG(\wht T)$: Let $\xi\oplus\eta\in\ovl{\SG(T)}$. Then there exists a sequence $(\xi_n\oplus T\xi_n)$ in $\SG(T)$ converging to $\xi\oplus\eta$. In particular, $\xi_n\rightarrow \xi$ and $T\xi_n\rightarrow \eta$. Since $\wht T$ is bounded, we have $T\xi_n\rightarrow\wht T\xi$, and hence $\eta=\wht T\xi$. Thus $\xi\oplus\eta=\xi\oplus\wht T\xi$ belongs to $\SG(\wht T)$.
\end{proof}



\begin{df}\label{lb386}
Let $T:\MH\rightarrow\MK$ be an n.d.d. unbounded operator. A linear subspace $\Dom_0\subset\Dom(T)$ is called a \textbf{core for $\pmb T$} \index{00@Core for an unbounded operator} if one of the following (clearly) equivalent conditions holds: 
\begin{itemize}
\item $\SG(T|_{\Dom_0})$ is dense in $\SG(T)$.
\item For each $\xi\in\Dom(T)$ there exists a sequence $(\xi_n)$ in $\Dom_0$ such that $\xi=\lim_n\xi_n$ and $T\xi=\lim_n T\xi_n$.
\item For each $\xi\in\Dom(T)$ there exists a net $(\xi_\alpha)$ in $\Dom_0$ such that $\xi=\lim_\alpha\xi_\alpha$ and $T\xi=\lim_\alpha T\xi_\alpha$.
\end{itemize}
For example, if $T$ is closable, then $\Dom(T)$ is a core for $\Dom(\ovl T)$.
\end{df}


\begin{df}
If $\fk G\subset\MH\oplus\MK$ is a linear subspace, we call \index{G@$\fk G^{-1}$, the diagonal reflection of $\fk G\subset\MH\oplus\MK$}
\begin{align*}
\fk G^{-1}=\{\eta\oplus\xi:\xi\oplus\eta\in\MK\oplus\MH\}
\end{align*}
the \textbf{diagonal reflection} of $\fk G$. In other words, $\fk G^{-1}$ is the image of $\fk G$ under the (clearly unitary) \textbf{diagonal reflection map} \index{00@Diagonal reflection map}
\begin{align}\label{eq206}
\fk r:\MH\oplus\MK\rightarrow\MK\oplus\MK\qquad \xi\oplus\eta\mapsto\eta\oplus\xi
\end{align}
\end{df}

\begin{comment}
\begin{eg}
Let $T:\MH\rightarrow\MK$ be an n.d.d. injective unbounded operator. Then
\begin{align*}
\SG(T^{-1})=\SG(T)^{-1}
\end{align*}
It follows immediately that $T$ is closed iff $T^{-1}$ is closed. Moreover, if both $T$ and $T^{-1}$ are closable, then $\ovl T$ is injective, and $\ovl T^{-1}=\ovl{T^{-1}}$.
\end{eg}
\end{comment}




\subsubsection{Closures of Hermitian operators and their Cayley transforms}


\begin{df}\label{lb412}
Define the \textbf{Cayley transform}
\begin{align}\label{eq198}
\Cay:\MH\oplus\MH\xlongrightarrow{\simeq}\MH\oplus\MH\qquad \xi\oplus\phi\mapsto \frac{\phi+\im\xi}{\sqrt2}\oplus  \frac{\phi-\im\xi}{\sqrt2}
\end{align}
If $\fk G\subset\MH\oplus\MH$, the set $\Cay(\fk G)$ \index{Cay@$\Cay(\fk G)$, the Cayley transform of a $\fk G\subset\MH\oplus\MH$} is called the \textbf{Cayley transform} of $\fk G$, \index{00@Cayley transforms of linear subspace of $\MH\times\MH$} and $\fk G$ is called the \textbf{inverse Cayley transform} \index{00@Inverse Cayley transforms of linear subspace of $\MH\times\MH$} of $\Cay(\fk G)$. Clearly $\fk G$ is the image of $\Cay(\fk G)$ under
\begin{align}\label{eq199}
\Cay^{-1}:\MH\oplus\MH\xlongrightarrow{\simeq}\MH\oplus\MH\qquad \eta\oplus\psi\mapsto \frac{\im(\psi-\eta)}{\sqrt 2}\oplus\frac{\psi+\eta}{\sqrt 2}
\end{align}
\end{df}


\begin{pp}\label{lb391}
The Cayley transform $\Cay$ (defined in \eqref{eq198}) is a unitary map. Consequently, its inverse $\Cay^{-1}$ is also unitary.
\end{pp}


\begin{proof}
Clearly $\Cay$ is bijective. To show that it is a linear isometry, we compute that
\begin{align*}
\Vert\phi+\im\xi\Vert^2=\Vert\phi\Vert^2+\Vert\xi\Vert^2+\im\bk{\phi|\xi}-\im\bk{\xi|\phi}=\Vert\phi\Vert^2+\Vert\xi\Vert^2+2\im\Real\bk{\phi|\xi}
\end{align*}
and similarly $\Vert\phi-\im\xi\Vert^2=\Vert\phi\Vert^2+\Vert\xi\Vert^2-2\im\Real\bk{\phi|\xi}$.
\end{proof}



\begin{eg}\label{lb392}
Let $T$ be a Hermitian operator on $\MH$. Then $\Cay(\SG(T))$ is the graph of the Cayley transform of $T$.
\end{eg}

\begin{proof}
The Cayley transform $U_T$ of $T$ sends $T\xi+\im\xi$ to $T\xi-\im\xi$ where $\xi\in\Dom(T)$. Replacing $\xi$ with $\xi/\sqrt2$, we see that $\SG(U_T)$ consists of points of the form $(T\xi+\im\xi)/\sqrt2\oplus(T\xi-\im\xi)/\sqrt2$. This is compatible with \eqref{eq198} by setting $\phi=T\xi$.
\end{proof}


\begin{eg}\label{lb393}
Let $U$ satisfy Condition (2) of Thm. \ref{lb383}. Then $\Cay^{-1}(\SG(U))$ is the graph of the inverse Cayley transform of $T$.
\end{eg}

\begin{proof}
The inverse Cayley transform $T_U$ of $U$ sends $\im(U\eta-\eta)$ to $U\eta+\eta$ where $\eta\in\Dom(U)$. Replacing $\eta$ with $\eta/\sqrt2$, we see that $\SG(T_U)$ consists of points of the form $\im(U\eta-\eta)/\sqrt2\oplus(U\eta+\eta)/\sqrt2$. This is compatible with \eqref{eq199} by setting $\psi=U\eta$.
\end{proof}


\begin{rem}\label{lb394}
We are now ready to complete the second step in the proof of Thm. \ref{lb383}.
\end{rem}

\begin{proof}
Let $U_T$ be the Cayley transform of $T$, and let $T_U$ be the inverse Cayley transform of $U$. By Exp. \ref{lb392} and \ref{lb393}, the Cayley transform $\Cay$ maps the graph of $T$ to the graph of $U_T$; the inverse Cayley transform $\Cay^{-1}$ maps the graph of $U$ to the graph of $T_U$, and hence maps the graph of $U_T$ to the graph of $T_{U_T}$. So the graphs of $T$ and $T_{U_T}$ are equal. This proves $T=T_{U_T}$. A similar argument shows $U=U_{T_U}$.

That $T\subset\wtd T$ is equivalent to $U_T\subset U_{\wtd T}$ follows directly from the fact that $\Cay$ maps a larger graph to a larger one.
\end{proof}





\begin{thm}\label{lb389}
Let $T$ be a Hermitian operator on $\MH$ with Cayley transform $U_T$. Then $T$ is closable and $\ovl T$ is Hermitian. Moreover, the Cayley transform of $\ovl T$ is equal to the unique bounded linear extension of $U_T$ to $\ovl{\Dom(U_T)}\rightarrow\MH$.
\end{thm}

It follows that $T$ is closed iff $\Dom(U_T)$ is closed (equivalently, $\Rng(U_T)$ is closed).


\begin{proof}
By Prop. \ref{lb388}, the operator $U_T$ is closable, and its closure $\ovl{U_T}$ is precisely the unique bounded linear extension of $U_T$ to $\ovl{\Dom(U_T)}\rightarrow\MH$. Since $U_T:\Dom(U_T)\rightarrow\MH$ is a linear isometry, the bounded linear extension $\ovl{U_T}:\ovl{\Dom(U_T)}\rightarrow\MH$ remains a linear isometry by continuity. Because $\Rng(U_T-\idt)$ is dense $\MH$, the larger set $\Rng(\ovl{U_T}-\idt)$ is also dense. Thus $\ovl{U_T}$ satisfies Condition (2) of Thm. \ref{lb383}. 

By Thm. \ref{lb383}, there exists a Hermitian operator $\wht T$ on $\MH$ whose Cayley transform $U_{\wht T}$ equals $\ovl{U_T}$. Since the map $\Cay$ is unitary (cf. Prop. \ref{lb391}), the fact that $\ovl{U_T}$ equals the closure of $U_T$ implies that (the graph of) $\wht T$ equals the closure of (the graph of) $T$. This proves that $T$ is closable, and that its closure $\wht T$ is Hermitian with Cayley transform $\ovl{U_T}$.
\end{proof}



\subsection{Extensions of Hermitian operators III: the non-unique part}


Let $\MH$ be a Hilbert space. In Thm. \ref{lb383}, we have related the extensions of a Hermitian operator $T$ to the isometric extensions of its Cayley transform $U_T$. According to Thm. \ref{lb389}, the extension of $T$ to $\ovl T$ corresponds to the unique bounded linear extension of $U_T$ to $\ovl{\Dom(U_T)}$.

In this section, we study closed extensions of a closed Hermitian operator $T$, which corresponds to isometric extensions of $U_T$ to larger closed linear subspaces of $\MH$ containing $\Dom(U_T)$.



\begin{thm}\label{lb396}
Let $T$ be a closed Hermitian operator on $\MH$. Then there exists a bijection between:
\begin{enumerate}
\item[(1)] A closed Hermitian operator $\wht T$ extending $T$.
\item[(2)] A unitary map $V:\Dom(V)\xlongrightarrow{\simeq}\Rng(V)$ where $\Dom(V)$ is a Hilbert subspace of $\Rng(T+\im)^\perp$ and $\Rng(V)$ is a Hilbert subspace of $\Rng(T-\im)^\perp$.
\end{enumerate}
Viewing $V$ as an n.d.d. unbounded operator on $\MH$, the correspondence is given by
\begin{gather}\label{eq200}
\begin{gathered}
\Dom(\wht T)=\Dom(T)+\Rng(V-\idt)\\
\wht T|_{\Rng(V-\idt)}:\im(V\eta-\eta)\mapsto (V\eta+\eta)
\end{gathered}
\end{gather}
for each $\eta\in\Dom(V)$.
\end{thm}

If one does not require that $\wht T$ is closed, then $\Dom(V)$ and $\Rng(V)$ are not necessarily complete.

\begin{proof}
Let $U_T:\Rng(T+\im)\xlongrightarrow{\simeq}\Rng(T+\im)$ be the Cayley transform of $T$. By Thm. \ref{lb383} and \ref{lb389}, the Cayley transform establishes a bijection between $\wht T$ and unitary $\wht U:\Dom(\wht U)\xlongrightarrow{\simeq}\Rng(\wht U)$ extending $U_T$, where $\Dom(\wht U)$ and $\Rng(\wht U)$ are closed linear subspaces of $\MH$.

The bijection between $\wht U$ and $V$ is as follows. Given $\wht U$, then $\Dom(V)$ is chosen to be the orthogonal complement of $\Rng(T+\im)$ in $\Dom(\wht U)$, and $V$ is defined to be $\wht U|_{\Dom(V)}$. Conversely, given $V$, then $\Dom(\wht U)$ is set to be $\Rng(T+\im)+\Dom(V)$, and $\wht U$ is defined to be the unique extension of the Cayley transform $U_T$ whose restriction to $\Dom(V)$ equals $V$. Eq. \ref{eq200} is easy to check.
\end{proof}

\begin{df}
Let $T$ be a Hermitian operator on $\MH$. Let
\begin{align*}
n_+=\dim \Rng(T+\im)^\perp\qquad n_-=\dim\Rng(T-\im)^\perp
\end{align*}
Then $(n_+,n_-)$ is called the (pair of) \textbf{deficiency indices} \index{00@Deficiency index} of $T$. 
\end{df}

By \ref{lb389}, $T$ and its closure $\ovl T$ have the same deficiency indices. Therefore, it suffices to consider deficiency indices of closed Hermitian operators.


\begin{rem}
As discussed in Subsec. \ref{lb384}, the Hermitian operators $T$ that admit spectral decompositions are those satisfying $\Rng(T+\im)=\Rng(T-\im)=\MH$. Later we will show that these operators are precisely the self-adjoint ones. By Thm. \ref{lb396}, this implies that a Hermitian operator $T$ has a self-adjoint extension iff its deficiency indices satisfy $n_+=n_-$. See Cor. \ref{lb424}.
\end{rem} 



\subsection{Adjoints of unbounded operators}


Let $\MH,\MK$ be Hilbert spaces.


In \cite{vN29a}, von Neumann introduced the notion of the adjoint operator $T^*$ for a Hermitian operator $T$.\footnote{However, in \cite{vN29a} von Neumann did not yet regard $T^*$ as the adjoint of $T$. See Subsec. \ref{lb411} for a detailed discussion.} The idea is straightforward: viewing $T$ as a differential operator, the extended operator $T^*$ should have domain $\Dom(T^*)$ consisting of all $\eta\in\MH$ for which the ``weak derivative'' $T^*\eta$ exists. Concretely, these are the vectors $\eta\in\MH$ such that the linear functional
\begin{align}\label{eq203}
\Dom(T)\rightarrow\Cbb\qquad \xi\mapsto\bk{\eta|T\xi}
\end{align}
is bounded. Since $\Dom(T)$ is dense, we have $\Dom(T)^*\simeq\MH^*$ due to Cor. \ref{lb144}. Therefore, by the Riesz-Fr\'echet Thm. \ref{lb135}, there exists a unique element $T^*\eta\in\MH$ such that
\begin{align*}
\bk{\eta|T\xi}=\bk{T^*\eta|\xi}\qquad\text{for all }\xi\in\Dom(T)
\end{align*}


This definition of $T^*$ clearly applies to any unbounded operator $T$ on $\MH$. However, without assuming that $T$ is Hermitian, the adjoint operator $T^*$ need not extend $T$. In fact, $\Dom(T^*)$ is not necessarily densely-defined, so $T^*$ may be only an n.d.d. unbounded operator. The systematic study of adjoints of general (not necessarily Hermitian) unbounded operators was undertaken by von Neumann in \cite{vN32b}. In this course, contrary to the historical order, we will first examine adjoints of general operators before specializing to Hermitian operators. The most surprising result we will see in this section is the equivalence of the closability of $T$ and the density of $\Dom(T^*)$; see Thm. \ref{lb402}.




\subsubsection{Adjoints of graphs}




In Sec. \ref{lb398}, we have seen how the graphs $\SG(T)$ of operators $T$ illuminate both the algebraic and analytic features of the Cayley transform. Operator graphs are also a powerful tool for studying adjoints.


\begin{df}
For each linear subspace $\fk G\subset\MH\oplus\MK$, the \textbf{adjoint} \index{00@Adjoint of a subset of $\MH\oplus\MK$} of $\fk G$ is defined to be \footnote{We avoide the notation $\fk G^*$ for the adjoint, since it is already reserved for dual spaces.} \index{AdG@$\Ad(\fk G)$}
\begin{align*}
\pmb{\Ad(\fk G)}=\{\eta\oplus\psi\in\MK\oplus\MH:\bk{\eta|\phi}=\bk{\psi|\xi}\text{ for all }\xi\oplus\phi\in\fk G\}
\end{align*}
An equivalent description is as follows. Define a (clearly) unitary map \index{J@$\Jbb$}
\begin{align*}
\pmb{\Jbb_{\MH,\MK}}:\MH\oplus\MK\xrightarrow{\simeq}\MK\oplus\MH\qquad \xi\oplus\phi\mapsto\im\phi\oplus(-\im\xi)
\end{align*}
abbreviated to $\Jbb$ when the context is clear. Then
\begin{align*}
\Ad(\fk G)=(\Jbb\fk G)^\perp
\end{align*}
\end{df}

\begin{pp}
The unitary map $\Jbb$ satisfies $\Jbb_{\MK,\MH}\Jbb_{\MH,\MK}=\idt$ and hence
\begin{align}
\Jbb_{\MH,\MK}^*=\Jbb_{\MH,\MK}^{-1}=\Jbb_{\MK,\MH}
\end{align}
\end{pp}

\begin{proof}
This is easy to check.
\end{proof}

\begin{eg}
If $T:\MH\rightarrow\MK$ is an injective n.d.d. unbounded operator, then $\Jbb\SG(T)=\SG(-T^{-1})$.
\end{eg}


\begin{pp}\label{lb399}
For each linear subspace $\fk G\subset\MH\oplus\MK$ we have
\begin{align*}
(\Jbb\fk G)^\perp=\Jbb(\fk G^\perp)\qquad (\Jbb\fk G)^{-1}=\Jbb(\fk G^{-1})\qquad (\fk G^{-1})^\perp=(\fk G^\perp)^{-1}
\end{align*}
Consequently, we have
\begin{align*}
\Ad(\fk G^{-1})=(\Ad\fk G)^{-1}
\end{align*}
\end{pp}

Therefore, it is unambiguous to omit parentheses and write $\Jbb\fk G^\perp$ and $\Jbb\fk G^{-1}$.

\begin{proof}
The first and third relations follow from the fact that any unitary tranform commutes with taking orthogonal complements.  The second one follows from $\Jbb\fk r=-\fk r\Jbb$ and the fact that $-\fk V=\fk V$ for any linear subspace $\fk V$.
\end{proof}








\begin{thm}\label{lb400}
Let $\fk G\subset\MH\oplus\MK$ be a linear subspace. The following are true.
\begin{enumerate}
\item $\ovl{\fk G}=\Ad(\Ad(\fk G))$. In particular, $\fk G\subset\Ad(\Ad(\fk G))$.
\item $\fk G$ is densely defined iff $\Ad(\fk G)$ is an operator graph.
\end{enumerate}
\end{thm}

\begin{proof}
Prop. \ref{lb399} implies that
\begin{align*}
\Jbb(\Jbb\fk G^\perp)^\perp=\Jbb\Jbb(\fk G^{\perp\perp})=\fk G^{\perp\perp}
\end{align*}
where the last term equals $\ovl{\fk G}$ by Cor. \ref{lb151}. This proves part 1.



Recall that $\Dom(\fk G)$ consists of all $\xi\in\MH$ such that $\xi\oplus\phi\in\fk G$. By Cor. \ref{lb369}, $\Dom(\fk G)$ is dense in $\MH$ iff the only vector $\psi\in\MH$ orthogonal to $\xi\in\MH$ (for all $\xi\oplus\phi\in\fk G$) is zero, iff the only vector $\psi\oplus 0\in\MH\oplus \MK$ orthogonal to $\fk G$ is zero, iff the only vector $0\oplus\psi\in\MK\oplus\MH$ orthogonal to $\Jbb\fk G$ is zero, iff the only vector $0\oplus\psi\in\MK\oplus\MH$ belonging to $\Ad(\fk G)$ is zero. This last statement is equivalent to that $\Ad(\fk G)$ is an operator graph, cf. Def. \ref{lb387}-(3). This proves part 2.
\end{proof}


\begin{co}\label{lb401}
Let $\fk G\subset\MH\oplus\MK$ be a linear subspace. Then $\ovl{\fk G}$ is an operator graph iff $\Ad(\fk G)$ is densely defined.
\end{co}

\begin{proof}
Part 2 of Thm. \ref{lb400} implies that $\Ad(\fk G)$ is densely defined iff $\Ad(\Ad(\gk G))$ is an operator graph, and Thm. part 1 says $\Ad(\Ad(\gk G))=\ovl{\fk G}$.
\end{proof}


\begin{comment}
\begin{df}
For each linear subspace $\fk F\subset\MH\oplus\MK$, define
\begin{align*}
\Ker(\fk G)=\{\xi\in\MH:\xi\oplus 0\in \fk G\}\qquad\Rng(\fk G)=\{\eta\in\MK:\xi\oplus\eta\in\fk G\text{ for some }\xi\in\MH\}
\end{align*}
\end{df}

\begin{eg}
If $T:\MH\rightarrow\MK$ be an n.d.d. unbounded operator, then $\Ker(\SG(T))=\Ker(T)$ and $\Rng(\SG(T))=\Rng(T)$.
\end{eg}




\begin{thm}
Let $\fk G\subset\MH\oplus\MK$ be a linear subspace. Then
\begin{align*}
\Ker(\Ad(\fk G))=\Rng(\fk G)^\perp
\end{align*}
In particular, $\Ker(\Ad(\fk G))$ is a closed linear subspace of $\MK$.
\end{thm}

\begin{proof}
Let $\eta\in\MK$. Then $\eta\in\Ker(\Ad(\fk G))$ iff $\eta\oplus0\in\Jbb\fk G^\perp$, iff $0\oplus\eta\in\fk G^\perp$, iff $0\oplus\eta$ is orthogonal to all $\xi\oplus\phi\in\fk G$, iff $\eta\perp\phi$ whenever $\xi\oplus\phi\in\fk G$, iff $\eta\in\Rng(\fk G)$.
\end{proof}

\end{comment}


\subsubsection{Adjoints of unbounded operators}



\begin{df}
Let $T:\MH\rightarrow\MK$ be an unbounded operator. By Thm. \ref{lb400}, there exists a (unique) n.d.d. unbounded operator $T^*:\MH\rightarrow\MK$ such that $\SG(T^*)=\Ad(\SG(T))$. We call $T^*$ the \textbf{adjoint} \index{00@Adjoints of unbounded operators} of $T$.
\end{df}

\begin{rem}
Let $T:\MH\rightarrow\MK$ be an unbounded operator. An equivalent description of $T^*$ is as follows: $\Dom(T)$ is the set of all $\eta\in\MK$ such that there exists an element of $\MH$, denoted by $T^*\eta$, satisfying
\begin{align}\label{eq202}
\bk{\eta|T\xi}=\bk{T^*\eta|\xi}\qquad\text{for all }\xi\in\Dom(T)
\end{align}
As discussed near \eqref{eq203}, $\Dom(T^*)$ can also be described as the set of all $\eta\in\MK$ such that the linear functional $\xi\in\Dom(T)\mapsto\bk{\eta|T\xi}\in\Cbb$ is bounded.
\end{rem}


\begin{rem}
Let $A,B:\MH\rightarrow\MK$ be unbounded operators satisfying $A\subset B$. Then $B^*\supset A^*$. This is due to the more general (obvious) fact that if $\fk G,\fk K$ are linear subspaces of $\MH\oplus\MK$, then
\begin{align*}
\fk G\subset\fk K\qquad\Longrightarrow\qquad\Jbb\fk G^\perp\supset\Jbb\fk K^\perp
\end{align*}
\end{rem}



\begin{eg}\label{lb409}
Let $T$ be an unbounded operator on $\MH$. Then $T$ is Hermitian iff $T\subset T^*$.
\end{eg}


\begin{proof}
If $T$ is Hermitian, then for each $\eta\in\Dom(T)$, we have $\bk{\eta|T\xi}=\bk{T\eta|\xi}$. Comparing this with \eqref{eq202}, we conclude that $\eta\in\Dom(T^*)$ and $T\eta=T^*\eta$. This proves $T\subset T^*$. 

Conversely, assume that $T\subset T^*$. Then for each $\eta\in\Dom(T)$, we have $\eta\in\Dom(T^*)$ and $T^*\eta=T\eta$. It follows from \eqref{eq202} that $\bk{\eta|T\xi}=\bk{T\eta|\xi}$ for all $\xi\in\Dom(T)$. This proves that $T$ is Hermitian.
\end{proof}






\begin{thm}\label{lb402}
Let $T:\MH\rightarrow\MK$ be an unbounded operator. Then the following are equivalent:
\begin{enumerate}
\item[(1)] $T$ is closable.
\item[(2)] $T^*$ is densely-defined (i.e. $T^*$ is an unbounded operator).
\end{enumerate}
Moreover, if either (1) or (2) is true, then $T^*$ is a closed operator, and 
\begin{align}\label{eq205}
\ovl T=T^{**}\qquad (\ovl T)^*=T^*=T^{***}
\end{align}
\end{thm}



\begin{proof}
The equivalence of (1) and (2) is due to Cor. \ref{lb401}. If (1) or (2) is true, then $\ovl T=T^{**}$ by Thm. \ref{lb400}-1, and the closedness of $T^*$ is due to the closedness of $\SG(T^*)=(\Jbb\SG(T))^\perp$. (Note that any orthogonal complement is closed; cf. Rem. \ref{lb150}.) Applying adjoints to both sides of $\ovl T=T^{**}$ gives $(\ovl T)^*=T^{***}$. Replacing $T$ by $T^*$ in the relation $\ovl T=T^{**}$ gives $\ovl{T^*}=T^{***}$, and hence $T^*=T^{***}$ because $T^*$ is closed.\footnote{Alternatively, \eqref{eq205} also follows from the fact that for each linear subspace $V$ of a Hilbert space, the relations $\ovl V=V^{\perp\perp}$ and $\ovl V^\perp=V^\perp=V^{\perp\perp\perp}$ hold due to Rem. \ref{lb150} and Cor. \ref{lb151}.}
\end{proof}


Note that if $T$ is Hermitian, then $T^*$ is densely defined (since $T\subset T^*$), and hence $T$ is closable. This provides an alternative proof of the closability of Hermitian operators, in addition to Thm. \ref{lb389}.



The following proposition generalizes Prop. \ref{lb370}.


\begin{pp}\label{lb403}
Let $T:\MH\rightarrow\MK$ be an unbounded operator. Then
\begin{align}
\Ker(T^*)=\Rng(T)^\perp
\end{align}
Consequently, if $T$ is closed, then
\begin{align}
\Ker(T)=\Rng(T^*)^\perp
\end{align}
\end{pp}


\begin{proof}
Let $\eta\in\MK$. Then $\eta\in\Ker(T^*)$ iff the linear functional $\eta\in\Dom(T)\mapsto \bk{\eta|T\xi}$ is bounded and constantly zero, iff $\eta\in\Rng(T)^\perp$. This proves the first relation. When $T$ is closed, then by Thm. \ref{lb402}, the adjoint $T^*$ is closed, and the first relation gives $\Ker(T^*)=\Rng(T^{***})^\perp=\Rng(T^*)^\perp$.
\end{proof}


Inverses of bounded injective operators with dense ranges provide a large class of examples of closed operators. The following proposition shows that the adjoints of such closed operators can be computed in terms of the adjoints of the original bounded operators.


\begin{pp}\label{lb404}
Let $T:\MH\rightarrow\MK$ be an injective closed operator with dense range. Then $T^{-1},T^*:\MK\rightarrow\MH$ are also injective closed operators with dense ranges, and
\begin{align}\label{eq204}
(T^*)^{-1}=(T^{-1})^*
\end{align}
\end{pp}

\begin{proof}
By Thm. \ref{lb402}, $T^*:\MK\rightarrow\MH$ is a closed operator. By Prop. \ref{lb403}, $\Ker(T^*)=\Rng(T)^\perp=\{0\}$ and $\ovl{\Rng(T^*)}=\Ker(T)^\perp=\MH$. Therefore $T^*$ is injective with dense range. Clearly $T^{-1}$ is injectve with dense range. Since the diagonal reflection map \eqref{eq206} is unitary, the operator $T^{-1}$ is closed.  Eq. \eqref{eq204} follows immediately from Prop. \ref{lb399}.
\end{proof}



\subsubsection{Examples: Sobolev spaces}\label{lb416}



Let $\Omega\subset\Rbb^N$ be open. 

\begin{df}
For each \textbf{multi-index}
\begin{align*}
\alpha=(\alpha_1,\dots,\alpha_n)\in\Nbb^n
\end{align*}
we  define an unbounded operator \index{zz@$\partial^\alpha$}
\begin{align}
\pmb{\partial^\alpha}=\partial_{x_1}^{\alpha_1}\cdots\partial_{x_N}^{\alpha_N}:L^2(\Omega,m)\rightarrow L^2(\Omega,m)\qquad\Dom(\partial^\alpha)=C_c^\infty(\Omega)
\end{align}
The \textbf{order} of $\alpha$ is defined to be \index{zz@$\vert\alpha\vert$, the order of the multi-index $\alpha$}
\begin{align*}
\pmb{|\alpha|}=\alpha_1+\cdots+\alpha_N
\end{align*}
We also define the \textbf{gradient operator} \index{zz@$\nabla$, the gradient operator}
\begin{gather}
\begin{gathered}
\nabla:L^2(\Omega,m)\rightarrow L^2(\Omega,m)^{\oplus N}\qquad f\mapsto \partial_{x_1}f\oplus\cdots\oplus\partial_{x_N}f\\
\Dom(\nabla)=C_c^\infty(\Omega)
\end{gathered}
\end{gather}
and the \textbf{divergence operator}
\begin{gather}
\begin{gathered}
\dive:L^2(\Omega,m)^{\oplus N}\rightarrow L^2(\Omega,m)\qquad f_1\oplus\cdots\oplus f_N\mapsto \partial_{x_1}f_1+\cdots+\partial_{x_N}f\\
\Dom(\dive)=C_c^\infty(\Omega)^{\oplus N}
\end{gathered}
\end{gather}
both understood as unbounded operators.
\end{df}


\begin{pp}\label{lb406}
The unbounded operators $\partial^\alpha,\nabla,\dive$ are closable, and
\begin{align}\label{eq207}
(\partial^\alpha)^*\supset (-1)^{|\alpha|}\partial^\alpha\qquad \nabla^*\supset-\dive\qquad \dive^*\supset-\nabla
\end{align}
\end{pp}


\begin{proof}
As in the proof of Exp. \ref{lb362},  integration by parts gives $\bk{f|\partial_{x_i}g}=-\bk{\partial_{x_i}f|g}$ for each $f,g\in C_c^\infty(\Omega)$. Hence
\begin{align*}
\bk{f|\partial^\alpha g}=(-1)^{|\alpha|}\bk{\partial^\alpha f|g}\qquad \text{for each }f,g\in C_c^\infty(\Omega)
\end{align*}
This is equivalent to the relation $(\partial^\alpha)^*\supset (-1)^{|\alpha|}$. The other two inclusion relations in \eqref{eq207} follow by a similar argument. 

Eq. \eqref{eq207} implies that the adjoints of $\partial^\alpha,\nabla,\dive$ are densely defined. Hence they are closable by Thm. \ref{lb402}.
\end{proof}












\begin{df}\label{lb414}
Let $T:\MH\rightarrow\MK$ be an n.d.d. unbounded operator. The \textbf{graph inner product} (of $T$) \index{00@Graph inner product $\bk{\cdot|\cdot}_T$} on $\Dom(T)$ \index{DomT@$\bk{\cdot\vert\cdot}_T$, the graph inner product} is defined by
\begin{gather*}
\pmb{\bk{\cdot|\cdot}_T}:\Dom(T)\times\Dom(T)\mapsto\Cbb\qquad \bk{\xi|\eta}_T= \bk{\xi|\eta}+\bk{T\xi|T\eta}
\end{gather*}
In other words, $\bk{\cdot|\cdot}_T$ is the pullback of the inner product of $\SG(T)$ to $\Dom(T)$ via the linear bijection
\begin{align}\label{eq213}
\Psi:\Dom(T)\rightarrow\SG(T)\qquad \xi\mapsto\xi\oplus T\xi
\end{align}
It follows that $T$ is closed iff $\Dom(T)$ is complete.
\end{df}


\begin{eg}\label{lb417}
Define the \textbf{Sobolev spaces}  \index{00@$H^1_0(\Omega),H^1(\Omega)$}
\begin{gather*}
H^1_0(\Omega)=\Dom\big(\ovl{\nabla}\big)\qquad H^1(\Omega)=\Dom\big(\dive^*\big)
\end{gather*} 
equipped with the graph inner products of the closed operators $\ovl\nabla$ and $\dive^*$, respectively. Then $H^1_0(\Omega)$ and $H^1(\Omega)$ are Hilbert spaces.
\end{eg}


\begin{eg}
For each $k\in\Nbb$,  define unbounded operators
\begin{gather*}
\nabla^k:L^2(\Omega,m)\rightarrow \bigoplus_{|\alpha|\leq k}L^2(\Omega,m)\qquad f\mapsto\oplus_\alpha \partial^\alpha f\\
\Dom(\nabla^k)=C_c^\infty(\Omega)
\end{gather*}
and
\begin{gather*}
\dive^k:\bigoplus_{|\alpha|\leq k}L^2(\Omega,m)\rightarrow  L^2(\Omega,m)\qquad\oplus_\alpha f_\alpha\mapsto\sum_\alpha \partial^\alpha f_\alpha\\
\Dom(\dive^k)=\bigoplus_{|\alpha|\leq k}C_c^\infty(\Omega)
\end{gather*}
Similar to Prop. \ref{lb406}, one easily checks that
\begin{align}\label{eq208}
(\nabla^k)^*\supset \dive^k\cdot \Ibb_k\qquad (\dive^k)^*\supset \Ibb_k\cdot\nabla^k
\end{align}
where $\Ibb_k\in\fk L\big(\bigoplus_{|\alpha|\leq k}L^2(\Omega,m)\big)$ is the unitary operator defined by $\Ibb_k(\oplus_\alpha f_\alpha)=\oplus_\alpha (-1)^{|\alpha|}f_\alpha$. Hence $\nabla^k$ and $\dive^k$ are closable by Thm. \ref{lb402}. Define the \index{00@Sobolev spaces $H^k_0(\Omega),H^k(\Omega)$} \textbf{Sobolev spaces} \index{Hk@$H_0^k(\Omega),H^k(\Omega)$}
\begin{align*}
H^k_0(\Omega)=\Dom\big(\ovl{\nabla^k}\big)\qquad H^k(\Omega)=\Dom\big((\dive^k)^*\big)
\end{align*}
equipped with the graph inner products of $\ovl{\nabla^k}$ and $(\dive^k)^*$, respectively. Then these two spaces are Hilbert spaces, because $\ovl{\nabla^k}$ and $(\dive^k)^*$ are closed. Moreover, it is easy to check that
\begin{align*}
H^k(\Omega)=\bigcap_{|\alpha|\leq k}\Dom\big((\partial^\alpha)^*\big)
\end{align*}
\end{eg}



\begin{rem}
From the second relation in \eqref{eq208}, we clearly have that $H^k_0(\Omega)\subset H^k(\Omega)$, and that the inner product of $H^k(\Omega)$ restricts to that of $H^k_0(\Omega)$. Moreover, by \eqref{eq208}, the closure of $\SG(\Ibb_k\cdot\nabla^k)$ in $\SG((\dive^k)^*)$ is $\SG(\Ibb_k\cdot\ovl{\nabla^k})$. It follows that $H^k_0(\Omega)$ is the closure of $C_c^\infty(\Omega)$ in $H^k(\Omega)$. 
\end{rem}

Heuristically, $H^k_0(\Omega)$ consists of those functions $f\in H^k(\Omega)$ such that $(\partial^\alpha)^*f$ ``vanishes at the boundary of $\Omega$'' for each $|\alpha|\leq k-1$. 


\subsection{Adjoints of closed Hermitian operators}\label{lb408}


Let $\MH$ be a Hilbert space. 
\begin{df}
Let $T$ be a Hermitian operator on $\MH$. We say that $T$ is \textbf{self-adjoint} if $T=T^*$. \index{00@Self-adjoint unbounded operators} We say that $T$ is \textbf{essentially self-adjoint} \index{00@Essentially self-adjoint operators} if $\ovl T$ is self-adjoint.
\end{df}

Since adjoint operators are closed (Thm. \ref{lb402}), every self-adjoint operator is closed; in particular, it is essentially self-adjoint.

In this section, we show that a Hermitian operator $T$ on $\MH$ satisfies $T=T^*$ iff \begin{align}\label{eq209}
\Rng(T+\im)=\Rng(T-\im)=\MH
\end{align}
that is, iff the Cayley transform of $T$ is a unitary operator on $\MH$. The motivation for establishing this result requires some explanation, which we provide in the following subsection.




\subsubsection{Introduction}\label{lb411}

%As mentioned before, the goal of von Neumann in \cite{vN27,vN29a} was to find a natural characterization of Hermitian operators $T$ on $\MH$ admitting spectral decompositions. As discussed in Subsec. \ref{lb384}, the first such condition he arrived at is $\Rng(T+\im)=\Rng(T-\im)=\MH$. Indeed, in his more systematic (than \cite{vN27}) treatment of the mathematical foundations of quantum mechanics in \cite{vN32a}, von Neumann only mentioned $\Rng(T+\im)=\Rng(T-\im)=\MH$ as the equivalence criterion for the existence of spectral decompositions.


The most fundamental result in the theory of unbounded operators is that Hermitian operators $T$ satisfying $T=T^*$ admit spectral decompositions, as proved by von Neumann in \cite{vN29a}. Today, we call unbounded operators with $T=T^*$ \textbf{self-adjoint} operators. This terminology, however, has often caused confusion about the actual development of the theory of unbounded operators.

The first main confusion is that one might think the notions of adjoint and self-adjointness for unbounded operators are straightforward, and that the real difficulty lies in proving that self-adjoint operators admit spectral decompositions. But this is not how the theory evolved. As emphasized earlier, having a spectral decomposition is not the ultimate goal, but rather the starting point. The true objective is to identify natural conditions on Hermitian operators that are equivalent to the existence of spectral decompositions. The first such condition encountered is \eqref{eq209}, as discussed in Subsec. \ref{lb384}. The final condition is  $T=T^*$. In other words, the condition $T=T^*$ is not the point of departure, but rather the culmination of the development of spectral theory for unbounded operators.

Why, then, did von Neumann in \cite{vN29a} (and most later authors) not regard \eqref{eq209} as the definitive condition for Hermitian operators to admit spectral decompositions? This requires some explanation, especially since in Ch. \ref{lb407} we will see that in many situations it is actually easier to verify \eqref{eq209} than to check $T=T^*$ directly. The reason lies in a second major source of confusion concerning the notion of self-adjoint operators, which I now discuss.



In \cite{vN29a}, von Neumann did not use the term ``self-adjoint'' for Hermitian operators satisfying $T=T^*$. Instead, he called them \textbf{hypermaximal operators}. Correspondingly, in that paper he did not regard $T^*$ as the adjoint of $T$, but rather as an extension of $T$. (Recall that Hermitian operators $T$ satisfy $T\subset T^*$; see Exp. \ref{lb409}.) Of course, for non-Hermitian operators one does not have $T\subset T^*$---but this is precisely why it was only later, in \cite{vN32b}, where von Neumann considered $T^*$ for general operators (not just Hermitian ones), that he began to interpret $T^*$ as the adjoint of $T$. 

There are many clues in \cite{vN29a} that demonstrate von Neumann's original perspective of $T^*$ as an extension of the Hermitian operator $T$, rather than its adjoint:
\begin{itemize}
\item In footnote 46, von Neumann used $\ovl{\ovl T}$ to denote what we now call $T^*$.
\item A key concept in \cite{vN29a} is \textbf{extension elements} (Erweiterungselemente), which are defined as those vectors belonging to the domain of (what we now call) $T^*$.
\item In the second paragraph of Section I, von Neumann used both ``self-adjoint'' (selbstadjungiert) and ``Hermitian'' (Hermitsch) to describe Hermitian operators.
\end{itemize}


To explain why von Neumann regarded the condition $T=T^*$ (in his notation, $T=\ovl{\ovl T}$) rather than \eqref{eq209} as the definitive criterion for Hermitian operators admitting spectral decompositions, let's examine the following result; see \cite[Satz 33]{vN29a}:

\begin{pp}\label{lb410}
Let $T$ be a Hermitian operator on $\MH$. Then $T$ is \textbf{maximal} \index{00@Maximal Hermitian operator} (i.e., any Hermitian operator extending $T$ must be equal to $T$) if and only if
\begin{align}\label{eq210}
\Rng(T+\im)=\MH\qquad\text{or}\qquad\Rng(T-\im)=\MH
\end{align}
\end{pp}

It follows from Thm. \ref{lb389} that a Hermitian operator $T$ is maximal precisely when it is closed and one of its deficiency indices is zero.

\begin{proof}
This follows directly from Thm. \ref{lb383}, since \eqref{eq210} means precisely that the Cayley transform of $T$ has no proper extension satisfying condition (2) of Thm. \ref{lb383}.
\end{proof}


Of course, a maximal Hermitian operator need not satisfy \eqref{eq209}. This naturally raises the following question:

\begin{question}
What is the analogue of Prop. \ref{lb410} for condition \eqref{eq209}? In other words, what is the natural property corresponding to \eqref{eq209}, in the same way that ``maximality'' corresponds to condition \eqref{eq210}?
\end{question}

\begin{proof}[Answer]
The corresponding theorem is that a Hermitian operator $T$ is hypermaximal iff \eqref{eq209} holds. The natural property sought is precisely hypermaximality $T=\ovl{\ovl T}$ (i.e. $T=T^*$). Heuristically, this means not only that $T$ has no proper Hermitian extensions, but also that it has no proper ``hyperextensions'', if we interpret $T^*$ as the \textbf{hyperextension}\footnote{Von Neumann himself did not use the word ``hyperextension'' in his writings.} of $T$. The hyperextension is larger than any Hermitian extension $\wht T$ of $T$, since $T\subset\wht T$ implies $\wht T^*\subset T^*$, and hence (due to $\wht T\subset\wht T^*$)
\begin{align}
T\subset\wht T\subset\wht T^*\subset T^*
\end{align}
\end{proof}


 
\subsubsection{Characterization of adjoints of closed Hermitian operators}

For a Hermitian operator $T$ on $\MH$, to relate the condition $T=T^*$ with \eqref{eq209}, we need a clear understanding of $T^*$ in terms of $\Rng(T\pm\im)$. The goal of this subsection is to present such a characterization of $T^*$, originally due to \cite{vN29a}. However, we will simplify the original technical computations by using the Cayley transform $\Cay:\MH\oplus\MH\rightarrow\MH\oplus\MH$ introduced in Def. \ref{lb412}.


\begin{lm}\label{lb413}
Let $T$ be a Hermitian operator on $\MH$ with Cayley transform $U_T$. Then $\Cay(\SG(T^*))$ consists precisely of elements $\alpha\oplus\beta\in\MH\oplus\MH$ satisfying
\begin{align}\label{eq211}
\bk{\alpha|\eta}=\bk{\beta|U_T\eta}\qquad\text{for each }\eta\in\Dom(U_T)
\end{align}
\end{lm}


\begin{proof}
On $\MH\oplus\MH$, one computes that
\begin{align*}
\Cay\circ\Jbb\circ\Cay^{-1}=\Gamma:\MH\oplus\MH\rightarrow\MH\oplus\MH\qquad \eta\oplus\phi\mapsto(-\eta)\oplus\phi
\end{align*}
Therefore, noting that any unitary transform commutes with taking orthogonal complements, we compute that
\begin{align*}
\Cay(\Jbb\fk G^\perp)=(\Cay\Jbb\fk G)^\perp=(\Gamma\Cay\fk G)^\perp
\end{align*}
and hence
\begin{align}
\Cay(\Ad(\fk G))=\{\alpha\oplus\beta\in\MH\oplus\MH:\bk{\alpha|\eta}=\bk{\beta|\psi}\text{ for each }\eta\oplus\psi\in\Cay(\fk G)\}
\end{align}
Eq. \eqref{eq211} follows by taking $\fk G=\SG(T)$.
\end{proof}


\begin{pp}
Let $T$ be a closed Hermitian operator on $\MH$ with Cayley transform $U_T$. Then
\begin{align}\label{eq212}
\Cay(\SG(T^*))=\SG(U_T)+(\Rng(T+\im)^\perp\oplus 0)+(0\oplus\Rng(T-\im)^\perp)
\end{align}
Moreover, the three spaces $\SG(U_T)$, $(\Rng(T+\im)^\perp\oplus 0)$, $(0\oplus\Rng(T-\im)^\perp)$ are mutually orthogonal closed linear subspaces of $\MH\oplus\MH$. Therefore \eqref{eq212} is an (orthogonal) direct sum of Hilbert spaces.
\end{pp}

\begin{proof}
By \eqref{eq192}, the projections of $\Cay(\SG(T))\equiv\SG(U_T)$ onto the first and second components are $\Dom(U_T)=\Rng(T+\im)$ and $\Rng(U_T)=\Rng(T-\im)$, respectively. Thus, the three subspaces on the RHS of \eqref{eq212} are mutually orthogonal. They are clearly also closed. Moreover, one checks easily that any element in one of these three spaces satisfies the description of $\Cay(\SG(T^*))$ in Lem. \ref{lb413}. This proves the relation ``$\supset$'' in \eqref{eq212}.

To prove the relation ``$\subset$'', we choose any $\alpha\oplus\beta\in\Cay(\SG(T^*))$ and prove that $\alpha\oplus\beta$ belongs to the RHS of \eqref{eq212}. Since $T$ is closed, by Thm. \ref{lb389}, $\Rng(T\pm\im)$ is closed. Let $P_\pm\in\fk L(\MH)$ be the projection of $\MH$ onto $\Rng(T\pm\im)$. Then
\begin{align*}
\alpha\oplus\beta=(P_+\alpha\oplus P_-\beta)+((\idt-P_+)\alpha\oplus0)+(0\oplus (\idt-P_-)\beta)
\end{align*}
where the second and third terms on the RHS belong to $(\Rng(T+\im)^\perp\oplus 0)$ and $(0\oplus\Rng(T-\im)^\perp)$ respectively. Let $\alpha'=P_+\alpha$ and $\beta=P_-\beta$. Then $\alpha'\in\Rng(T+\im)$ and $\beta'\in\Rng(T-\im)$.

Since $\alpha'\oplus\beta'\in\Cay(\SG(T^*))$ (because $\Cay(\SG(T^*))$ is a linear subspace), the elements $\alpha',\beta'$ satisfy the description in Lem. \ref{lb413}. Therefore, noting that $\bk{\alpha'|\eta}=\bk{U_T\alpha'|U_T\eta}$, we have
\begin{align*}
\bk{\beta'-U_T\alpha'|U_T\eta}=0\qquad\text{for each }\eta\in\Dom(U_T)
\end{align*}
Thus, the element $\beta'-U_T\alpha'$ (which belongs to $\Rng(U_T)=\Rng(T-\im)$) is orthogonal to $\Rng(U_T)$. Hence $\beta'=U_T\alpha'$. This proves that $\alpha'\oplus\beta'\in\SG(U_T)$, and hence $\alpha\oplus\beta$ belongs to the RHS of \eqref{eq212}.
\end{proof}


Recall Def. \ref{lb414} for the meaning of graph inner products.

\begin{thm}\label{lb415}
Let $T$ be a closed Hermitian operator on $\MH$. Then, under the graph inner product of $T^*$, the Hilbert space $\Dom(T^*)$ admits an orthogonal decomposition into Hilbert subspaces
\begin{align}\label{eq215}
\Dom(T^*)=\Dom(T)\oplus \Rng(T+\im)^\perp\oplus\Rng(T-\im)^\perp
\end{align}
Moreover, we have
\begin{gather}\label{eq216}
T^*|_{\Dom(T)}=T\qquad T^*|_{\Rng(T+\im)^\perp}=\im\qquad T^*|_{\Rng(T-\im)^\perp}=-\im
\end{gather}
\end{thm}


\begin{proof}
Applying $\Cay^{-1}=\eqref{eq199}$ to Eq. \eqref{eq212} yields an orthogonal decomposition of $\SG(T^*)$ into three Hilbert subspaces:
\begin{align}\label{eq214}
\begin{aligned}
\SG(T^*)=&\SG(T)+\{-\im\eta\oplus\eta\in\MH\oplus\MH:\eta\in\Rng(T+\im)^\perp\}\\
&+\{\im\psi\oplus\psi\in\MH\oplus\MH:\psi\in\Rng(T-\im)^\perp\}
\end{aligned}
\end{align}
The unitary map $\Psi:\Dom(T^*)\rightarrow\SG(T^*),\xi\mapsto\xi\oplus T^*\xi$ (where $\Dom(T^*)$ is equipped with the graph inner product) pulls the three spaces on the RHS of \eqref{eq214} back to those on the RHS of \eqref{eq215} respectively. Therefore, the Hilbert space decomposition \eqref{eq215} holds. Eq. \eqref{eq216} follows immediately from \eqref{eq214}.
\end{proof}


\begin{rem}\label{lb418}
By Prop. \ref{lb403}, we have
\begin{align}
\Ker(T^*-\im)=\Rng(T+\im)^\perp\qquad \Ker(T^*+\im)=\Rng(T-\im)^\perp
\end{align}
This gives another proof of \eqref{eq216}.
\end{rem}



\begin{co}\label{lb420}
Let $T$ be a Hermitian operator on $\MH$. Then $T$ is self-adjoint iff
\begin{align*}
\Rng(T+\im)=\Rng(T-\im)=\MH
\end{align*}
\end{co}

\begin{proof}
Since self-adjoint operators are closed (by Thm. \ref{lb402}), and since Hermitian operators satisfying $\Rng(T+\im)=\Rng(T-\im)=\MH$ are also closed (by Thm. \ref{lb389}), the two conditions can be compared under the assumption that $T$ is a closed Hermitian operator. Then the equivalence follows immediately from Thm. \ref{lb415}.
\end{proof}

\begin{co}
Let $T$ be a Hermitian operator on $\MH$. Then $T$ is essentially self-adjoint iff both $\Rng(T+\im)$ and $\Rng(T-\im)$ are dense in $\MH$.
\end{co}

\begin{proof}
This follows immediately from Cor. \ref{lb420}, together with the fact that $\Rng(\ovl T\pm\im)$ is the closure of $\Rng(T\pm\im)$ (due to Thm. \ref{lb389} or Eq. \eqref{eq197}).
\end{proof}


\begin{co}\label{lb424}
Let $T$ be a Hermitian operator on $\MH$ with deficiency indices $(n_+,n_-)$. Then $T$ has a self-adjoint extension iff $n_+=n_-$.
\end{co}

\begin{proof}
Any self-adjoint extension of $T$ is closed, and hence extends $\ovl T$. Therefore, replacing $T$ with $\ovl T$ (and noting that this procedure does not change the deficiency indices, cf. Thm. \ref{lb389}), it suffices to assume that $T$ is closed.

By Thm. \ref{lb396}, the equality $n_+=n_-$ holds iff $T$ has a closed Hermitian extension $\wht T$ satisfying $\Rng(\wht T+\im)=\Rng(\wht T-\im)=\MH$. By Cor. \ref{lb420}, this later condition is equivalent to that $T$ has a self-adjoint extension.
\end{proof}







\subsubsection{Thm. \ref{lb415} in the context of differential equations}

In this subsection, we sketch an interpretation of Thm. \ref{lb415} in the context of differential equations. First, we make the following observation:
\begin{rem}\label{lb419}
In the setting of Thm. \ref{lb415}, we have
\begin{align}\label{eq218}
\Ker((T^*)^2+1)=\Ker(T^*-\im)+\Ker(T^*+\im)
\end{align}
Therefore, \eqref{eq215} can be written equivalently as
\begin{align}
\Dom(T^*)=\Dom(T)\oplus \Ker((T^*)^2+1)
\end{align}
\end{rem}

\begin{proof}
In view of Rem. \ref{lb418}, we clearly have ``$\supset$'' in \eqref{eq218}. To prove ``$\subset$'', by \eqref{eq215}, it suffices to show
\begin{align*}
\Ker((T^*)^2+1)\cap\Dom(T)=0
\end{align*}
Pick any $\xi$ on the LHS. Then $T^*T\xi+\xi=0$, and hence $\bk{T\xi|T\xi}+\bk{\xi|\xi}=0$. This proves $\xi=0$.
\end{proof}

Now, let $\Omega\subset\Rbb^N$ be bounded and open with sufficiently regular (e.g. smooth) boundary $\partial\Omega$. Consider $T_0$ as a ``Dirac operator'' on $\MH=L^2(\Omega,m)^{\oplus k}$ with domain $C_c^\infty(\Omega)^{\oplus k}$. This mean that $T_0$ is Hermitian and satisfies
\begin{align*}
\Vert T_0\xi\Vert^2=-\bk{\xi|\Delta\xi}\qquad\text{for each }\xi\in C_c^\infty(\Omega)^{\oplus k}
\end{align*}
For instance, when $N=k=1$, the operator $-\im\frac d{dx}$ is a Dirac operator. For general $N$, let $\MH$ be the space of Lebesgue-$L^2$ functions from $\Omega$ to $\oplus_{j\in\Nbb}\bigwedge^j \Rbb^N$, with $\Rbb^N$ interpreted as the cotangent space of $\Omega$. (In this case, $k=2^N$.) The Dirac operator is defined by $T_0=d+\delta$, where $d$ is the exterior differential, and $\delta$ is the restriction of the adjoint $d^*$ to the subspace of compactly supported smooth sections. The corresponding $\Delta=-(d+\delta)^2$ is called the (negative) Hodge-Laplacian. 

In this setting, $T_0$ plays a role analogous to $\nabla$ in Subsec. \ref{lb416}. Thus, as in Exp. \ref{lb417}, one can use the graph inner products of $T:=\ovl{T_0}$ and $T^*$ to define Hilbert spaces
\begin{align*}
H^1_0(\Omega)=\Dom(T)\qquad H^1(\Omega)=\Dom(T^*)
\end{align*}
Then Rem. \ref{lb419} asserts that
\begin{align}
H^1(\Omega)\ominus H^1_0(\Omega)=\Ker((T^*)^2+1)
\end{align}

On the other hand, one can define the Sobolev space $H^{\frac 12}(\partial\Omega)$ in an appropriate way, show that there exists a surjective bounded linear map (the trace map)
\begin{align*}
H^1(\Omega)\rightarrow H^{\frac12}(\partial\Omega)
\end{align*}
defined by ``restriction to the boundary'', and show that this map has kernel $H^1_0(\Omega)$; see e.g. \cite[Sec. 5.5]{Eva} for details. It follows that the trace map induces a bounded linear bijection\footnote{The inverse of the map \eqref{eq217} is also bounded by the inverse mapping theorem. Hence \eqref{eq217} implements an ``equivalence'' of Hilbert spaces, though not necessarily an isomorphism (i.e. unitary equivalence) of Hilbert spaces.}
\begin{align}\label{eq217}
\Ker((T^*)^2+1)\rightarrow H^{\frac 12}(\partial\Omega)
\end{align}
The LHS of \eqref{eq217} can be viewed as the space of $f\in H^1(\Omega)$ satisfying $(-\Delta+1)f=0$. Therefore, \eqref{eq217} establishes a bijection between $g\in H^{\frac 12}(\partial\Omega)$ and the solutions $f\in H^1(\Omega)$ of the Dirichlet problem
\begin{align*}
(-\Delta+1)f=0\qquad f|_{\partial\Omega}=g
\end{align*}



\subsection{Example: self-adjoint extensions and the adjoint of $-\im\frac d{dx}$}\label{lb425}


Let $I=(a,b)$ be an open interval in $\Rbb$ where $-\infty<a<b<+\infty$. Let $T_0$ be the unbounded (Hermitian) operator 
\begin{gather*}
T_0=-\im\frac d{dx}:L^2(I,m)\rightarrow L^2(I,m)\qquad \Dom(T_0)=C_c^\infty(I)
\end{gather*}
Let $T=\ovl{T_0}$. Recall from Subsec. \ref{lb416} that
\begin{align*}
H^1_0(I)=\Dom(T)\qquad H^1(I)=\Dom(T^*)
\end{align*}
Recall from Thm. \ref{lb402} that $T^*=T_0^*$. In this section, we determine $T^*$ in the case that $I$ is bounded.


Due to Thm. \ref{lb415} (and Rem. \ref{lb418}), to characterize $T^*$ it suffices to determine $\Ker(T^*\mp\im)$. For that purpose, let us first characterize $\Ker(T^*)$.

\begin{lm}\label{lb421}
A function $f\in L^2(I,m)$ belongs to $\Ker(T^*)=\Ker(T_0^*)$ iff $f$ is a.e. constant.
\end{lm}



\begin{proof}
If $f$ is a constant $C$ in $L^2(I,m)$, then for each $g\in C_c^\infty(I)$, the obvious identity $\int g'=0$ implies that $\bk{f|T_0g}=0$. Hence $f\in\Dom(T_0^*)$ and $T_0^*f=0$.

Conversely, assume that $f\in\Ker(T_0^*)$. Then for each $g\in C_c^\infty(I)$ we have $\bk{f|g'}=0$. Therefore, for each $h\in C_c^\infty(I)$ satisfying $\int_I h=0$, we have $f\perp h$.

We now prove that $f\perp h$ for each $h\in L^2(I,m)$ satisfying $\int h=0$. By Thm. \ref{lb361}, there exists a sequence $(h_n)$ in $C_c^\infty(I)$ converging in $L^2$ to $h$. By Cauchy-Schwarz, $\lambda_n:=\int h_n$ converges to $\int h=0$. Fix $\varphi\in C_c^\infty(I)$ such that $\int\varphi=1$, and let $\wtd h_n=h_n-\lambda_n\varphi$. Then $\Vert\wtd h_n-h\Vert_{L^2}=|\lambda_n|\cdot \Vert\varphi\Vert_{L^2}$ converges to $0$, and hence $\wtd h_n$ converges in $L^2$ to $h$. Moreover, $\int \wtd h_n=0$. Thus $f\perp h_n$ for each $n$, and hence $f\perp h$.

We have proved that $f$ is orthogonal to any element orthogonal to the constant function $1$. So $f\in \Span\{1\}^{\perp\perp}=\Span\{1\}$. Thus $f$ is a constant.
\end{proof}



\begin{pp}\label{lb422}
We have
\begin{align}\label{eq219}
\Ker(T^*-\im)=\Span\{e^{-x}\}\qquad \Ker(T^*+\im)=\Span\{e^{x}\}
\end{align}
In particular, the Hermitian operator $T$ has deficiency indices $(1,1)$.
\end{pp}

\begin{proof}
Clearly $e^{-x}$ belongs to $\Ker(T^*-\im)$. Conversely, asume that $f\in\Ker(T^*-\im)$. In particular, $f\in\Dom(T^*)$. Let $g(x)=e^xf$. Then for each $h\in C_0^\infty(I)$, we compute
\begin{align*}
&\bk{g|T_0h}=-\im\bk{e^xf|h'}=-\im\bk{f|e^xh'}=-\im\bk{f|(e^xh)'}+\im\bk{f|e^xh}\\
=&\bk{f|T_0(e^xh)}+\im\bk{f|e^xh}=\bk{e^xT_0^*f|h}+\im\bk{e^xf|h}=\bk{e^x(T^*-\im)f|h}
\end{align*}
This shows that $g\in\Dom(T^*)=\Dom(T_0^*)$ and $T^*g=e^x(T^*-\im)f$. Since $f\in\Ker(T^*-\im)$, we conclude $T^*g=0$, and hence $g$ is a constant by Lem. \ref{lb421}. This proves the first identity in \eqref{eq219}. The second identity can be proved in the same way.
\end{proof}


\begin{thm}\label{lb423}
The Hilbert space $H^1(I)$ has an orthogonal decomposition into Hilbert subspaces
\begin{align}\label{eq220}
H^1(I)=H^1_0(I)\oplus \Span\{e^{-x}\}\oplus \Span\{e^x\}
\end{align}
Moreover, we have $T^*e^{-x}=\im e^{-x}$ and $T^*e^x=-\im e^x$, and we have
\begin{align}\label{eq221}
H_0^1(I)\subset C_0(I)\qquad H^1(I)\subset C(\ovl I)
\end{align}
\end{thm}



\begin{proof}
Eq. \ref{eq220} follows immediately from Prop. \ref{lb422} and Thm. \ref{lb415}. Since $e^{\pm x}\in C(\ovl I)$, to prove $H^1(I)\subset C(\ovl I)$, it suffices to prove $H_0^1(I)\subset C_0(I)$.

We view $C_0(I)$ as the space of functions in $C(\ovl I)$ vanishing at $\partial I=\{a,b\}$. Choose any $f\in H_0^1(I)$. Then there exists a sequence $(f_n)$ in $C_c^\infty(I)$ such that $\Vert f-f_n\Vert_2\rightarrow0$ and $\Vert Tf-f_n'\Vert_2\rightarrow0$. Note that $\int_I f_n'=f_n(b)-f_n(a)=0$. That is, each $f_n'$ is orthogonal to $1$. Thus $Tf$ is also orthogonal to $1$. By Cauchy-Schwarz, we have $\Vert Tf-f'_n\Vert_1\rightarrow1$, and hence $f_n$ converges uniformly to $\wtd f\in C(\ovl I)$ defined by $\wtd f(x)=\int_a^xTf$. The fact that $Tf\perp 1$ implies that $\wtd f(b)=0$, and hence $\wtd f\in C_0(I)$. Since the uniform convergence implies $\Vert\wtd f-f_n\Vert_2\rightarrow0$, we conclude that $f=\wtd f$, and hence that $f\in C_0(I)$.
\end{proof}

Note that $e^{-x}$ and $e^x$ are orthogonal in the inner product of $H^1(I)$, rather than in the original one of $L^2(I,m)$.

Readers unfamiliar with absolutely continuous functions can skip the following remark.


\begin{rem}
Eq. \ref{eq221} can be strengthened as follows. Let $AC(\ovl I)$ be the set of absolutely continuous functions $\ovl I\rightarrow\Cbb$. Then
\begin{subequations}\label{eq222}
\begin{gather}
H^1_0(I)=\{f\in AC(\ovl I):f'\in L^2(I,m),f(a)=f(b)=0\}\label{eq222a}\\
H^1(I)=\{f\in AC(\ovl I):f'\in L^2(I,m)\}\label{eq222b}
\end{gather} 
\end{subequations}
Moreover, for each $f\in H^1(I)$ we have $T^*f=f'$.
\end{rem}

\begin{proof}
Let $\mc E$ and $\mc F$ be the RHS of \eqref{eq222a} and \eqref{eq222b} respectively. From the proof of Thm. \ref{lb423}, we see that if $f\in H^1_0(I)$, then $f$ is the antiderivative of $Tf$. Therefore, by the fundamental theorem of calculus, we conclude that $f\in AC(\ovl I)$ and $f'=Tf$. Since $H^1_0(I)\subset C_0(I)$, we obtain $f(a)=f(b)=0$, and hence $f\in\mc E$. This proves $H^1_0(I)\subset\mc E$. By Eq. \eqref{eq220}, we have $H^1(I)\subset\mc F$.

For each $f\in\mc F$, note that if $g\in C_c^\infty(I)$ then $\ovl fg\in AC(\ovl I)$, and $(\ovl fg)'=\ovl f'g+\ovl fg'$. The fundamental theorem of calculus implies $\bk{f|g'}=-\bk{f'|g}$. This shows that $f\in H^1(I)$ and $T^*f=f'$. We have thus proved $H^1(I)\supset \mc F$. Therefore $H^1(I)=\mc F$.

Finally, we need to prove $H^1_0(I)\supset\mc E$. Choose any $f\in\mc E$. Since $f\in H^1(I)$, by Thm. \ref{lb423}, we can write $f=f_1+f_2$ where $f_1\in H^1_0(I)$ and $f_2=c_-e^{-x}+c_+e^x$ for some $c_\pm\in\Cbb$. By the definition of $\mc E$, we have $f(a)=f(b)=0$. By Thm. \ref{lb423}, we have $f_1(a)=f_1(b)=0$. Hence $f_2(a)=f_2(b)=0$, which implies $c_-=c_+=0$. Therefore $f=f_1\in H^1_0(I)$. This finishes the proof of $H^1_0(I)\supset\mc E$.
\end{proof}









\begin{thm}
There is a bijection between:
\begin{enumerate}
\item[(1)] A self-adjoint extension $\wht T$ of $T$.
\item[(2)] A number $\lambda\in\Sbb^1$. 
\end{enumerate}
These two objects are related by $\wht T=T^*|_{\Dom_\lambda}$ where
\begin{align*}
\Dom_\lambda=\{f\in H^1(I):f(b)=\lambda f(a)\}
\end{align*}
\end{thm}

This theorem suggests that different self-adjoint extensions of a Hermitian operator correspond to different (Hermitian) boundary conditions.

\begin{proof}
We assume for simplicity that $I=(-1,1)$ so that $e^{-x}$ and $e^x$ have the same $L^2$-norm. Thm. \ref{lb396} (together wit Prop. \ref{lb422}) implies that the self-adjoint extensions $\wht T$ of $T$ correspond bijectively to $z\in\Sbb^1$ (with the Cayley transform of $\wht T$ sending $e^{-x}$ to $ze^x$), and that
\begin{align*}
\Dom(\wht T)=\Dom(T)+\Span (ze^x-e^{-x})=H^1_0(I)+\Span (ze^x-e^{-x})
\end{align*}
Comparing this with the description of $H^1(I)$ in \eqref{eq220}, it is clear that $\Dom(\wht T)$ equals
\begin{align*}
\Dom_\lambda=\{f\in H^1_0(I)+\Cbb e^{-x}+\Cbb e^x:f(-1)=\lambda f(1)\}
\end{align*}
where $z\in\Sbb^1$ and $\lambda\in\Sbb^1$ are related by
\begin{align*}
\lambda=\frac{ze-e^{-1}}{ze^{-1}-e}\qquad z=\frac{\lambda e-e^{-1}}{\lambda e^{-1}-e}
\end{align*}
Note that if $z\in\Sbb^1$, then $\lambda\in\Sbb^1$ since $\sqrt{z}e-\sqrt{z^{-1}}e^{-1}$ is the negative conjugate of $\sqrt ze^{-1}-\sqrt{z^{-1}}e$. Similarly, if $\lambda\in\Sbb^1$ then $z\in\Sbb^1$.
\end{proof}



\subsection{Spectral theorem for strongly commuting self-adjoint operators}


Let $\MH$ be a Hilbert space.



\subsubsection{Strong commutativity and simultaneous measurement}\label{lb428}


The goal of this section is to prove that an unbounded operator $T$ on $\MH$ is self-adjoint (equivalently, Hermitian and $\Rng(T+\im)=\Rng(T-\im)=\MH$) iff $T$ admits a spectral decomposition, i.e, $T$ is unitarily equivalent to the multiplication operator of a real-valued measurable function. In fact, we will prove a more general result: the spectral theorem for a finite family of strongly commuting self-adjoint operators. The motivation for considering such operators requires some explanation.


The best-known phenomenon in quantum mechanics is the uncertainty principle: two observables (e.g. momentum $-\im\frac d{dx}$ and position $x$) cannot be simultaneously measured exactly. In finite-dimensional linear algebra, the possibility of measuring two observables simultaneously and with perfect precision is captured by the commutativity of Hermitian matrices, since commuting Hermitian matrices can be simultaneously diagonalized.


In infinite dimensions, greater care is needed. The first caveat is that if we restrict to bounded operators, then the spectral theorem in Sec. \ref{lb335} or \ref{lb426} shows that commutativity of two bounded self-adjoint operators does not mean that their observables can be \textbf{simultaneously measured with absolute precision}. Rather, as explained in Subsec. \ref{lb427}, they can only be \textbf{simultaneously measured with arbitrarily prescribed accuracy}.



More precisely, suppose $A,B\in\fk L(\MH)$ are commuting self-adjoint operators. For each $\Omega,O\subset\Rbb$, define spectral projections
\begin{align*}
E(\Omega)=\chi_{\Omega}(A)\qquad F(O)=\chi_O(B)
\end{align*}
Then $E(\Omega)$ commutes with $F(\Omega)$, so
\begin{align*}
P(\Omega,O):=E(\Omega)F(O)
\end{align*}
equals the projection onto $E(\Omega)\MH\cap F(O)\MH$, the space of all states $\xi\in\MH$ in which the measurement of $A$ yields a value in $\Omega$, and the measurement of $B$ yields a value in $O$. Now fix $\eps>0$ (interpreted as a prescribed accuracy), we partition $\Rbb$ into intervals
\begin{align*}
\Rbb=\bigsqcup_{n\in\Zbb}\Omega_n\qquad\text{where }\Omega_n=(n\eps,(n+1)\eps]
\end{align*}
Then for each unit vector $\xi\in\MH$, the quantity $\bk{\xi|P(\Omega_m,\Omega_n)\xi}$ is the probability that the simultaneous measurements of $A$ and $B$ in the state $\xi$ yield outcomes in $\Omega_m$ and $\Omega_n$ respectively---that is, a simultaneous measurement of $A$ and $B$ with prescribed accuracy $\eps$. The identity
\begin{align}\label{eq223}
1=\bk{\xi|\xi}=\sum_{m,n}\bk{\xi|P(\Omega_m,\Omega_n)\xi}
\end{align}
shows that the probabilities of all such $\eps$-accurate simultaneous measurements sum to $1$. By contrast, if $A$ and $B$ do not commute, then $E(\Omega_m)$ and $F(\Omega_n)$ may fail to commute. In that case, \eqref{eq223} may not hold, if we define $P(\Omega_m,\Omega_n)$ to be the projection onto $E(\Omega_m)\MH\cap F(\Omega_n)\MH$.


The second caveat arises when extending this reasoning to unbounded self-adjoint operators $A,B$. In this case, the appropriate mathematical condition for \textbf{simultaneous measurement with arbitrarily prescribed accuracy} is that the spectral projections of $A$ commute with those of $B$. Equivalently, as we will see, the Cayley transforms of $A$ and $B$ must commute. We call this property \textbf{strong commutativity}. 

However, strong commutativity is not equivalent to ordinary commutativity $AB=BA$. For example, any self-adjoint operator $A$ commutes strongly with the zero operator, even though we only have $0A\subset A0$ (where $A0$ equals $0$) but not $0A=A0$ if $\Dom(A)\neq\MH$. Even if one adopts a weaker notion of commutativity---namely, that there exists a common core $\Dom_0$ for $A$ and $B$ such that $A\Dom_0\subset \Dom_0$ and $B\Dom_0\subset \Dom_0$---this still does not guarantee strong commutativity (cf. \cite[Sec. VIII.5]{RS-1}).

Due to this reason, strong commutativity, rather than the ordinary relation $AB=BA$, is the natural condition for the spectral theorem of unbounded self-adjoint operators. For von Neumann's detailed discussion of the connection between strong commutativity and simultaneous measurement with prescribed accuracy, see \cite{vN32a} (especially Sec. III.3).


\subsubsection{Spectral theorem for strongly commuting self-adjoint operators}


\begin{df}
Two self-adjoint operators $A,B$ on $\MH$ are said to \textbf{commute strongly} \index{@Strong commutativity} if their Cayley transforms $U_A,U_B$ commute (and hence commute adjointly by Exp. \ref{lb429}). 
\end{df}


\begin{eg}\label{lb430}
Let $(X,\fk M)$ be a measurable space. Let $(\mu_\alpha)_{\alpha\in\SI}$ be a family of measures on $\fk M$. Let $f_1,\dots,f_N:X\rightarrow\Rbb$ be measurable. Let $\MH=\bigoplus_{\alpha\in\SI}L^2(X,\mu_\alpha)$. Then the multiplication operators $\Mbf_{f_1},\dots,\Mbf_{f_N}$ (cf. Exp. \ref{lb366}) are strongly-commuting self-adjoint operators on $\MH$. Moreover, the Cayley transform of $\Mbf_{f_j}$ is $\Mbf_{(f_j-\im)/(f_j+\im)}$.
\end{eg}

\begin{proof}
If $f=f_j$, then $\Mbf_f$ is Hermitian, because $\bk{\xi|\Mbf_f\xi}=\sum_\alpha \int f|\xi_\alpha|^2d\mu_\alpha\in\Rbb$ for each $\xi=\oplus_\alpha\xi_\alpha\in\Dom(\Mbf_f)$. It is also clear that $\Mbf_f\pm\im=\Mbf_{f\pm\im}$. By Exp. \ref{lb373}, $\Mbf_{f\pm\im}$ is injective with dense range, and $\Mbf_{f\pm\im}^{-1}=\Mbf_{1/(f\pm\im)}$. In particular, $\Rng(\Mbf_{f\pm\im})=\Dom(\Mbf_{1/(f\pm\im)})=\MH$. This proves that $\Rng(\Mbf_f\pm\im)=\MH$. Therefore, by Cor. \ref{lb420}, $\Mbf_f$ is self-adjoint.

By Rem. \ref{lb371}, the Cayley transform of $\Mbf_f$ equals
\begin{align*}
(\Mbf_f-\im)(\Mbf_f+\im)^{-1}=\Mbf_{f-\im}\Mbf_{1/(f+\im)}=\Mbf_u
\end{align*}
where $u=(f-\im)/(f+\im):X\rightarrow\Sbb^1$ is measurable. This proves that the Cayley transforms of $\Mbf_{f_1},\dots,\Mbf_{f_N}$ are multiplication operators of unitary measurable functions, and hence commute. Thus $\Mbf_{f_1},\dots,\Mbf_{f_N}$ commute strongly.
\end{proof}


To prove that any finite family of strongly commuting self-adjoint operators are unitarily equivalent to multiplication operators, we need the following lemma. Recall Def. \ref{lb431} for the meanings of measurable isomorphisms and pullback measures.


\begin{lm}\label{lb432}
Let $(X,\fk M)$ and $(Y,\fk N)$ be measurable spaces. Let $\phi:X\rightarrow Y$ be a measurable isomorphism. Let $(\nu_\alpha)_{\alpha\in\SI}$ be a family of measures on $\fk N$. Then the map
\begin{align*}
\Gamma:\bigoplus_{\alpha\in\SI}L^2(Y,\nu_\alpha)\xlongrightarrow{\simeq}\bigoplus_{\alpha\in\SI}L^2(X,\phi^*\nu_\alpha)\qquad \oplus_\alpha\eta_\alpha\mapsto \oplus_\alpha (\eta_\alpha\circ\phi)
\end{align*}
is unitary. Moreover, if $f\in X\rightarrow\Cbb$ is measurable, then the identity
\begin{align*}
\Gamma\Mbf_f\Gamma^{-1}=\Mbf_{f\circ\phi}
\end{align*}
holds as bounded linear operators on $\bigoplus_{\alpha\in\SI}L^2(X,\phi^*\nu_\alpha)$. In particular, $\Gamma\Dom(\Mbf_f)=\Dom(\Mbf_{f\circ\phi})$.
\end{lm}

\begin{proof}
The fact that $\Gamma$ is an isometry follows from \eqref{eq224}. It is easy to see that $\Gamma$ is a bijection, and that $\Gamma\Mbf_f\Gamma^{-1}=\Mbf_{f\circ\phi}$ holds.
\end{proof}



\begin{thm}\label{lb436}
Let $T_1,\dots,T_N$ be strongly commuting self-adjoint operators on $\MH$. Then there exists a family $(\mu_\alpha)_{\alpha\in\SI}$ of finite Borel measures on $\Rbb$, together with a unitary map
\begin{align*}
\Phi:\MH\xlongrightarrow{\simeq}\bigoplus_{\alpha\in\SI}L^2(\Rbb^N,\mu_\alpha)
\end{align*}
such that for each $1\leq j\leq N$, we have
\begin{align}
\Phi T_j\Phi^{-1}=\Mbf_{x_j}
\end{align}
as unbounded operators on $\bigoplus_{\alpha\in\SI}L^2(\Rbb^N,\mu_\alpha)$.
\end{thm}

Here, $x_i$ denotes the $i$-th coordinate function of $\Rbb^N$, i.e., the map sending $(a_1,\dots,a_N)\in\Rbb^N$ to $a_i$.


\begin{proof}
Step 1. Let $U_j$ be the Cayley transform of $T_j$, which is a unitary operator on $\MH$ by Cor. \ref{lb420}. By Prop. \ref{lb315}, we have $\Sp(T_j)\subset\Tbb\equiv\Sbb^1$. Since $U_1,\dots,U_N$ commute adjointly, by the spectral Thm. \ref{lb330}, there exists a family $(\nu_\alpha)_{\alpha\in\SI}$ of finite Borel measures on $\Tbb^N$, together with a unitary map
\begin{align*}
\Psi:\MH\rightarrow\bigoplus_{\alpha\in\SI}L^2(\Tbb^N,\nu_\alpha)
\end{align*}
such that $\Psi U_j\Psi^{-1}=\Mbf_{z_j}$ where $z_j:\Tbb^N\rightarrow\Tbb$ is the $i$-th coordinate function of $\Tbb^N$.\\[-1ex]


Step 2. In this step, we reduce $\Tbb^N$ to $(\Tbb\setminus\{1\})^N$. Recall from Lem. \ref{lb378} that $1$ is not an eigenvalue of $U_j$. Hence $1$ is not an eigenvalue of $\Mbf_{z_j}$. Therefore, for each $\alpha\in\SI$, we have $\nu_\alpha(z_j^{-1}(1))=0$. (Otherwise, there exists $\alpha$ such that $\chi_{z_j^{-1}(1)}$ is a non-zero vector of $L^2(\Tbb^N,\nu_\alpha)$, but this vector is an eigenvector of $\Mbf_{z_j}$ with eigenvalue $1$.) 

We have thus proved that $\nu_\alpha$ vanishes on $\bigcup_j z_j^{-1}(1)$, the complement of $(\Tbb\setminus\{1\})^N$. Therefore, we can restrict each $\nu_\alpha$ to $(\Tbb\setminus\{1\})^N$ so that the unitary map $\Psi$ in Step 1 becomes
\begin{align*}
\Psi:\MH\xlongrightarrow{\simeq}\bigoplus_{\alpha\in\SI}L^2((\Tbb\setminus\{1\})^N,\nu_\alpha)
\end{align*}
and that
\begin{align}\label{eq226}
\Psi U_j\Psi^{-1}=\Mbf_{z_j}
\end{align}
where 
\begin{align*}
z_j:Y=(\Tbb\setminus\{1\})^N\rightarrow\Tbb
\end{align*}
is the $i$-th coordinate function of $\Tbb\setminus\{1\}$.\\[-1ex]

Step 3. Define a homeomorphism
\begin{align*}
u_j=\frac{x_j-\im}{x_j+\im}:\Rbb\xlongrightarrow{\simeq}\Tbb\setminus\{1\}
\end{align*}
Applying Lem. \ref{lb432} to the homeomorphism
\begin{align*}
(u_1,\dots,u_N):\Rbb^N\rightarrow (\Tbb\setminus\{1\})^N
\end{align*}
gives a unitary map
\begin{align*}
\Gamma:\bigoplus_{\alpha\in\SI}L^2((\Tbb\setminus\{1\})^N,\nu_\alpha)\xlongrightarrow{\simeq}\bigoplus_{\alpha\in\SI}L^2(\Rbb^N,\mu_\alpha)
\end{align*}
where $\mu_\alpha=(u_1,\dots,u_N)^*\nu_\alpha$ is a finite Borel measure on $\Rbb^N$, and
\begin{align*}
\Gamma\Mbf_f \Gamma^{-1}=\Mbf_{f\circ(u_1,\dots,u_N)}\qquad\text{for each Borel function }f:(\Tbb\setminus\{1\})^N\rightarrow\Cbb
\end{align*}
Therefore $\Gamma\Mbf_{z_j}\Gamma^{-1}=\Mbf_{u_j}=\Mbf_{(x_j-\im)/(x_j+\im)}$. This relation, together with \eqref{eq226}, implies
\begin{align}\label{eq225}
\Phi U_j\Phi^{-1}=\Mbf_{(x_j-\im)/(x_j+\im)}
\end{align}
if the unitary map $\Phi$ is defined to be
\begin{align*}
\Phi=\Gamma\circ\Psi:\MH\xlongrightarrow{\simeq}\bigoplus_{\alpha\in\SI}L^2(\Rbb^N,\mu_\alpha)
\end{align*}

Since $U_j$ is the Cayley transform of $T_j$, the LHS of \eqref{eq225} is the Cayley transform of $\Phi T_j\Phi^{-1}$. By Exp. \ref{lb430}, the RHS of \eqref{eq225} is the Cayley transform of $\Mbf_{x_j}$. This proves $\Phi T_j\Phi^{-1}=\Mbf_{x_j}$.
\end{proof}


\subsection{Borel functional calculus and the joint spectrum $\Sp(T_\blt)$}

Let $\MH$ be a Hilbert space.


\subsubsection{Borel functional calculus}


Recall that if $X$ is a topological space, then $\Bor(X)$ (resp. $\Borb(X)$) denotes the space of Borel functions (resp. bounded Borel functions) $X\rightarrow\Cbb$. The main goal of this subsection is to prove the following theorem.

\begin{thm}\label{lb434}
Let $T_1,\dots,T_N$ be strongly commuting self-adjoint operators on $\MH$. Then there exists a unique map
\begin{align*}
\pi_{T_\blt}:\Bor(\Rbb^N)\rightarrow\{\text{unbounded operators on }\MH\}
\end{align*}
satisfying the following properties:
\begin{enumerate}[label=(\arabic*)]
\item The map $\pi_{T_\blt}$ restricts to a normal unitary representation\footnote{Recall from Def. \ref{lb433} that ``normal'' means that if $(f_n)$ is an increasing sequence in $\Borb(\Rbb^N)$ converging to $f\in\Borb(\Rbb^N)$, then $\lim_n\bk{\xi|\pi_{T_\blt}(f_n)\xi}=\bk{\xi|\pi_{T_\blt}(f)\xi}$ for each $\xi\in\MH$.}
\begin{align*}
\pi_{T_\blt}|_{\Borb(\Rbb^N)}:\Borb(\Rbb^N)\rightarrow\fk L(\MH)
\end{align*}
\item For each $1\leq j\leq N$, if $x_j:\Rbb^N\rightarrow\Rbb$ denotes the $j$-th coordinate function of $\Rbb^N$, then
\begin{align*}
\pi_{T_\blt}\Big(\frac{x_j-\im}{x_j+\im}\Big)=\frac{T_j-\im}{T_j+\im}
\end{align*}
\item For each $\xi\in\MH$ and $f\in\Bor(\Rbb^N)$, if $\mu_\xi$ denotes the finite Borel measure associated to $\xi$ and $\pi_{T_\blt}$ (cf. Rem. \ref{lb297}), then
\begin{align}
\xi\in\Dom(\pi_{T_\blt}(f))\qquad\Longleftrightarrow\qquad \int_{\Rbb^N} |f|^2d\mu_\xi<+\infty
\end{align}
Moreover, if $\xi\in\Dom(\pi_{T_\blt}(f))$, then \footnote{Note that if $\int_{\Rbb^N} |f|^2d\mu_\xi<+\infty$, then $\int_{\Rbb^N} |f|d\mu_\xi<+\infty$ by Cauchy-Schwarz and the fact that $\mu_\xi(\Rbb^N)<+\infty$.}
\begin{align}
\bk{\xi|\pi_{T_\blt}(f)\xi}=\int_{\Rbb^N}fd\mu_\xi
\end{align}
\end{enumerate}
\end{thm}


We call $(\pi_{T_\blt},\MH)$ the \textbf{Borel functional calculus} \index{00@Borel functional calculus for unbounded self-adjoint operators} of $T_\blt$, and write
\begin{align*}
\pmb{f(T_\blt)}:=\pi_{T_\blt}(f)
\end{align*}



\begin{proof}
Let us prove the uniqueness. Suppose that $\wtd\pi_{T_\blt}$ satisfies also conditions (1), (2), and (3). We extend $\pi_{T_\blt}$ and $\wtd\pi_{T_\blt}$ by zero to
\begin{align*}
\pi_{T_\blt},\wtd\pi_{T_\blt}:\Borb(\ovl\Rbb^N)\rightarrow\{\text{unbounded operators on }\MH\}
\end{align*}
In other words, if $f\in\Borb(\ovl\Rbb^N)$, then $\pi_{T_\blt}(f)=\pi_{T_\blt}(f|_{\Rbb^N})$, and $\wtd\pi_{T_\blt}$ is defined in a similar way.


By (2), the maps $\pi_{T_\blt}$ and $\wtd\pi_{T_\blt}$ agree on the functions $u_j=(x_j-\im)/(x_j+\im)$. Here, $u_j$ is viewed a continuous function on $\ovl\Rbb^N\simeq\Tbb^N$, where the homeomorphism $\ovl\Rbb\simeq\Tbb$ is defiend by the Cayley transform $x\mapsto \frac{x+\im}{x-\im}$. Since $u_1,\dots,u_N$ are the coordinate functions on $\Tbb^N$, they separate the points of $\ovl\Rbb^N$. By the uniqueness part in Thm. \ref{lb274}, $\pi_{T_\blt}$ and $\wtd\pi_{T_\blt}$ agree on $\Borb(\ovl\Rbb^N)$, and hence on $\Borb(\Rbb^N)$. In particular, for each $\xi\in\MH$, the measures $\mu_\xi,\wtd\mu_\xi$ defined respectively by $\pi_{T_\blt},\wtd\pi_{T_\blt}$ are equal. 

Now choose any $f\in\Bor(\Rbb^N)$. By property (3), the unbounded operators $\pi_{T_\blt}(f)$ and $\wtd\pi_{T_\blt}(f)$ have the same domain $\Dom_0$, and for any $\xi\in\Dom_0$ we have $\bk{\xi|\pi_{T_\blt}\xi}=\bk{\xi|\wtd\pi_{T_\blt}\xi}$. By the polarization identiy, we have $\bk{\eta|\pi_{T_\blt}(f)\xi}=\bk{\eta|\wtd\pi_{T_\blt}(f)\xi}$ for each $\eta,\xi\in\Dom_0$. The density of $\Dom_0$ implies $\pi_{T_\blt}(f)\xi=\wtd\pi_{T_\blt}(f)\xi$. Thus $\pi_{T_\blt}$ equals $\wtd\pi_{T_\blt}$ on the whole space $\Bor(\Rbb^N)$.

To prove the existence, one may assume that $T_1,\dots,T_N$ are equal to the multiplication operators $\Mbf_{x_1},\dots,\Mbf_{x_N}$ as described in the spectral Thm. \ref{lb436}. Then the uniqueness follows immediately by applying the following Thm. \ref{lb435} to $X=\Rbb^N$ and $f_1=x_1,\dots,f_N=x_N$.
\end{proof}





\begin{thm}\label{lb435}
Let $(X,\fk M)$ be a measurable space. Let $f_1,\dots,f_N:X\rightarrow\Rbb$ be measurable functions. Let $(\mu_\alpha)_{\alpha\in\SI}$ be a family of measures on $\fk M$. Let $\MH=\bigoplus_{\alpha\in\SI}L^2(X,\mu_\alpha)$. Then the map
\begin{align}
\pi_{T_\blt}:\Bor(\Rbb^N)\rightarrow\{\text{unbounded operators on }\MH\}\qquad g\mapsto \Mbf_{g\circ f_\blt}
\end{align}
(where $f_\blt=(f_1,\dots,f_N):\Rbb^N\rightarrow\Rbb^N$) is a Borel functional calculus of $\Mbf_{f_1},\dots,\Mbf_{f_N}$.
\end{thm}


Recall from Exp. \ref{lb430} that $\Mbf_{f_1},\dots,\Mbf_{f_N}$ are strongly commuting self-adjoint operators. In short, Thm. \ref{lb435} says that for each $g\in\Bor(\Rbb^N)$, we have
\begin{align*}
g(\Mbf_{f_1},\dots,\Mbf_{f_N})=\Mbf_{g\circ f_\blt}
\end{align*}

\begin{proof}
Step 1. We need to prove that $\pi_{T_\blt}$ satisfies the three properties in Thm. \ref{lb434}.

Property (1) is easy to check. In particular, for each $\xi=\oplus_\alpha\xi_\alpha$ in $\MH$, noting that $\xi_\alpha=0$ for all $\alpha$ outside a countable subset of $\SI$ (Rem. \ref{lb333}), if we define
\begin{align}
d\mu_\xi=\sum_{\alpha\in\SI}(f_\blt)_*(|\xi_\alpha|^2d\mu_\alpha)
\end{align}
then for each $g\in\Bor(\Rbb^N,\ovl{\Rbb}_{\geq0})$ we have (recalling Def. \ref{lb314} for the basic properties of pushforward measures)
\begin{align}\label{eq227}
\sum_{\alpha\in\SI}\int_X(g\circ f_\blt)|\xi_\alpha|^2d\mu_\alpha=\sum_{\alpha\in\SI}\int_{\Rbb^N}g\cdot (f_\blt)_*(|\xi_\alpha|^2d\mu_\alpha)=\int_{\Rbb^N}gd\mu_\xi
\end{align}
The LHS of \eqref{eq227} equals $\bk{\xi|\pi_{T_\blt}(g)\xi}$ when $g\in\Borb(\Rbb^N,\Rbb_{\geq0})$. Thus $\bk{\xi|\pi_{T_\blt}(g)\xi}=\int_{\Rbb^N}gd\mu_\xi$ holds for all $g\in\Borb(\Rbb^N,\Rbb)$, and hence for all $g\in\Borb(\Rbb^N)$ by linearity. Thus $\mu_\xi$ is the finite Borel measure associated to $\xi$.\\[-1ex]

Step 2. Let us check property (2). According to the definition of $\pi_{T_\blt}$,
\begin{align*}
\pi_{T_\blt}\Big(\frac{x_j-\im}{x_j+\im}\Big)=\Mbf_{\frac{x_j-\im}{x_j+\im}\circ f_\blt}=\Mbf_{(f_j-\im)/(f_j+\im)}
\end{align*}
where the last term equals the Cayley transform of $\Mbf_{f_j}$ by Exp. \ref{lb430}.\\[-1ex]

Step 3. We now check property (3). Choose any $g\in\Bor(\Rbb^N)$ and $\xi=\oplus_\alpha\xi_\alpha\in\MH$. From the definition of multiplication operators, we have $\xi\in\Dom(\Mbf_{g\circ f_\blt})$ iff
\begin{align*}
\sum_{\alpha\in\SI}\int_X |g\circ f_\blt|\cdot|\xi_\alpha|d\mu_\alpha<+\infty
\end{align*}
By \eqref{eq227}, this is equivalent to $\int_{\Rbb^N}|g|^2d\mu_\xi<+\infty$. This proves the first half of (3).

By linearity, \eqref{eq227} holds when $g\in\Bor(\Rbb^N,\Rbb)$, and when $g_+=\max\{g,0\},g_-=\max\{-g,0\}$ are $\mu_\xi$-integrable (equivalently, $|g|$ is $\mu_\xi$-integrable). Therefore, \eqref{eq227} holds when $g\in\Bor(\Rbb^N)$, and when $\Real g,\Imag g$ are $\mu_\xi$-integrable (equivalently, $|g|$ is $\mu_\xi$-integrable). Therefore, it holds when $g\in\Bor(\Rbb^N)$ and $|g|^2$ is $\mu_\xi$-integral. This last statement is equivalent to
\begin{align*}
\bk{\xi|\pi_{T_\blt}(g)\xi}=\int_{\Rbb^N}gd\mu_\xi
\end{align*}
whenever $\int_{\Rbb^N}|g|^2d\mu_\xi<+\infty$ (equivalently, $\xi\in\Dom(\Mbf_{g\circ f_\blt})$). This proves the second half of (3).
\end{proof}


\subsubsection{Basic properties of Borel functional Calculus}



\begin{thm}\label{lb437}
Let $T_1,\dots,T_N$ be strongly commuting self-adjoint operators on $\MH$. Let $g_1,\dots,g_L:\Rbb^N\rightarrow\Rbb$ be Borel functions. Then $g_1(T_\blt),\dots,g_L(T_\blt)$ are strongly commuting self-adjoint operator on $\MH$, and
\begin{align}\label{eq228}
f(g_1(T_\blt),\dots,g_L(T_\blt))=(f\circ(g_1,\dots,g_L))(T_\blt)
\end{align}
holds for each $f\in\Bor(\Rbb^L)$.
\end{thm}


\begin{proof}
By Thm. \ref{lb436}, we may assume that $\MH=\bigoplus_\alpha L^2(\Rbb^N,\mu_\alpha)$ where $(\mu_\alpha)$ is a family of finite Borel measures on $\Rbb^N$, and $T_j=\Mbf_{x_j}$. By Thm. \ref{lb435}, we have $g_k(T_\blt)=\Mbf_{g_k}$. Therefore, by Exp. \ref{lb430}, $g_1(T_\blt),\dots,g_L(T_\blt)$ are strongly commuting self-adjoint operators.

Let $f\in\Bor(\Rbb^L)$. By Thm. \ref{lb435}, we have
\begin{align*}
&f(g_1(\Mbf_{x_\blt}),\dots,g_L(\Mbf_{x_\blt}))=f(\Mbf_{g_1},\dots,\Mbf_{g_L})\\
=&\Mbf_{f\circ(g_1,\dots,g_L)}=(f\circ(g_1,\dots,g_L))(\Mbf_{x_\blt})
\end{align*}
This proves \eqref{eq228}.
\end{proof}

\begin{co}\label{lb439}
Let $T_1,\dots,T_N$ be strongly commuting self-adjoint operators on $\MH$. Let $1\leq L\leq N$. Assume that $f\in\Bor(\Rbb^N)$ depends only on the first $L$ variables so that $f$ can also be viewed as a Borel function on $\Rbb^L$. Then
\begin{align*}
f(T_1,\dots,T_L)=f(T_1,\dots,T_N)
\end{align*} 
\end{co}

In particular, if $f$ only depends on the first variable, then $f(T_1)=f(T_1,\dots,T_N)$.

\begin{proof}
Apply Thm. \ref{lb437} to the case that $f\in\Bor(\Rbb^L)$ and $g_1,\dots,g_L$ are the first $L$ coordinate functions of $\Rbb^N$.
\end{proof}

Next, we give some useful criteria for the strong commutativity of self-adjoint operators.

\begin{pp}\label{lb438}
Let $T$ be a self-adjoint operator on $\MH$ with Cayley transform $U_T$. Let $V\in\fk L(\MH)$ be unitary. Then $VT=TV$ iff $V$ commutes with $U_T$.
\end{pp}

We emphasize that the commutativity of a unitary operator and a bounded linear operator implies the adjoint commutativity (cf. Exp. \ref{lb429}).

\begin{proof}
In general, if two self-adjoint operators are unitarily equivalent via a unitary operator $V$, then there Cayley transforms are also unitarily equivalent via $V$. Therefore, if $VTV^{-1}=T$, then $VU_TV^{-1}=U_T$. This proves ``$\Rightarrow$''.

Similarly, if two unitary operators $U_1,U_2$ are unitarily equivalent via a unitary operator $V$, and if $\Rng(U_1-\idt)$ and $\Rng(U_2-\idt)$ are dense in $\MH$, then the inverse Cayley transforms of $U_1,U_2$ are also unitarily equivalent via $V$. This proves ``$\Leftarrow$''.
\end{proof}



\begin{thm}
Let $T_1,T_2$ be self-adjoint operators on $\MH$ with Cayley transforms $U_1,U_2$ respectively. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $T_1$ and $T_2$ commute strongly, that is, $U_1U_2=U_2U_1$.
\item $U_1T_2=T_2U_1$.
\item $U_2T_1=T_1U_2$.
\item For each $f_1,f_2\in\Borb(\Rbb,\Rbb)$, the bounded self-adjoint operators $f_1(T_1),f_2(T_2)$ commute.
\item For each $f_1,f_2\in\Borb(\Rbb)$, the bounded normal operators $f_1(T_1),f_2(T_2)$ commute adjointly.
\end{enumerate}
\end{thm}

\begin{proof}
The equivalence of (1), (2), and (3) follow immediately from Prop. \ref{lb438}. 


(1)$\Rightarrow$(4): Assume (1). By the spectral Thm. \ref{lb436}, we may assume that $T_1,T_2$ are equal to the multiplication operators $\Mbf_{x_1},\Mbf_{x_2}$ on $\MH=\bigoplus_\alpha L^2(\Rbb^N,\mu_\alpha)$ where $(\mu_\alpha)$ is a family of finite Borel measures. By Thm. \ref{lb435}, we have $f_1(T_1)=\Mbf_{f_1}$ and $f_2(T_2)=\Mbf_{f_2}$. These two bounded linear operators clearly commute.



(4)$\Rightarrow$(5): Since $f\in\Borb(\Rbb)\rightarrow f(T_1)\in\fk L(\MH)$ is a unitary representation (and in particular, linear), we have
\begin{align*}
f(T_1)=(\Real f)(T_1)+\im(\Imag f)(T_1)
\end{align*}
A similar relation holds for $f(T_2)$. By (4), the bounded self-adjoint operators $(\Real f_1)(T_1)$ and $(\Imag f_1)(T_1)$ commute with $(\Real f_2)(T_2)$ and $(\Imag f_2)(T_2)$. Therefore $f_1(T_1)$ commutes with $f_2(T_2)$. This proves (5). 



(5)$\Rightarrow$(1): Assume (5). Let $f_1=f_2=f:=\frac{x-\im}{x+\im}$. By property (2) in Thm. \ref{lb434}, $f(T_j)$ is the Cayley transform $U_i$ of $T_j$. Therefore, $U_1$ commutes with $U_2$, and hence (1) holds.
\end{proof}


\begin{pp}
Let $T_1,\dots,T_N\in\fk L(\MH)$ be self-adjoint. Then these operators commute iff they commute strongly. Moreover, in the case that they commute, for each $f\in\Borb(\Rbb)$, the Borel functional calculus $f(T_\blt)$ defined for mutually commuting bounded self-adjoint operators agrees with the one defined for strongly commuting self-adjoint operators.
\end{pp}

\begin{proof}
First, assume that $T_1,\dots,T_N$ commute. Let $R_j=\Vert T_j\Vert$. Then $-R_j\leq T_j\leq T_j$. Thus $\Sp(T_j)\subset[-R_j,R_j]$ (cf. Prop. \ref{lb313}), and hence $\Sp(T_\blt)\subset X:=[-R_1,R_1]\times\cdots\times[-R_N,R_N]$ (cf. Prop. \ref{lb307}). Therefore, by the spectral Thm. \ref{lb330} for adjointly-commuting bounded normal operators, we may assume that $\MH=\oplus_{\alpha\in\SI}L^2(X,\mu_\alpha)$ and $T_j=\Mbf_{x_j}$. By Exp. \ref{lb430}, $\Mbf_{x_1},\dots,\Mbf_{x_N}$ commute strongly. Moreover, by Thm. \ref{lb334} and \ref{lb435}, the two Borel functional calculi coincide.

Conversely, assume that $T_1,\dots,T_N$ commute strongly. By the spectral Thm. \ref{lb436} for strongly commuting self-adjoint operators, we may assume that $\MH=\oplus_{\alpha\in\SI}L^2(\Rbb^N,\mu_\alpha)$ and $T_j=\Mbf_{x_j}$. It is clear that
\begin{align*}
\Mbf_{x_i}\Mbf_{x_j}=\Mbf_{x_j}\Mbf_{x_i}
\end{align*}
holds on $\Dom(\Mbf_{x_i}\Mbf_{x_j})\cap \Dom(\Mbf_{x_j}\Mbf_{x_i})$. Since this subspace equals $\MH$ (because $T_i,T_j\in\fk L(\MH)$), we conclude that $T_iT_j=T_jT_i$.
\end{proof}



\subsubsection{The joint spectrum $\Sp(T_\blt)$}




\begin{df}
Let $T_1,\dots,T_N$ be strongly commuting self-adjoint operators on $\MH$. Let $\pi_{T_\blt}$ be the Borel functional calculus of $T_\blt$ (cf. Thm. \ref{lb434}). The support (cf. Def. \ref{lb299}) of the restriction $\pi_{T_\blt}|_{\Borb(\Rbb^N)}:\Borb(\Rbb^N)\rightarrow\fk L(\MH)$ is denoted by $\pmb{\Sp(T_\blt)}$ \index{Sp@$\Sp(T_\blt)$} and called the \textbf{joint spectrum}  \index{00@Joint spectrum $\Sp(T_\blt)$ for strongly commuting self-adjoint operators} of $T_1,\dots,T_N$. That is,
\begin{align*}
\Sp(T_\blt):=\Supp(\pi_{T_\blt}|_{\Borb(\Rbb^N)})
\end{align*}
In other words, $\lambda_\blt\in\Cbb^N$ belongs to $\Sp(T_\blt)$ iff $\chi_U(T_\blt)\neq0$ for each $U\in\Nbh_{\Cbb^N}(\lambda_\blt)$.
\end{df}

Note that $\Sp(T_\blt)$ is a closed subset of $\Rbb^N$, and hence is LCH.

\begin{thm}\label{lb441}
Let $(X,\fk M)$ be a measurable space. Let $(\mu_\alpha)_{\alpha\in\SI}$ be a family of \uwave{$\sigma$-finite} measures on $\fk M$. Let $f_1,\dots,f_N:X\rightarrow\Rbb$ be measurable. Let $\MH=\bigoplus_{\alpha\in\SI}L^2(X,\mu_\alpha)$. Let $T_1=\Mbf_{f_1},\dots,T_N=\Mbf_{f_N}$, which are strongly commuting self-adjoint operators by Exp. \ref{lb430}. Then
\begin{align}\label{eq230}
\Sp(T_\blt)= \Cl_{\Rbb^N}\Big(\bigcup_{\alpha\in\SI}\Ess(f_\blt,\mu_\alpha)\Big)
\end{align}
where $\Ess(f_\blt,\mu_\alpha)$ is the essential range (cf. Def. \ref{lb319}) of the map $f_\blt=(f_1,\dots,f_N):X\rightarrow\Rbb^N$ with respect to $\mu_\alpha$.
\end{thm}

In the important special case that $X$ is a Borel subset of $\Rbb^N$ and $T_1=\Mbf_{x_1},\dots,T_N=\Mbf_{x_N}$, Eq. \eqref{eq230} becomes
\begin{align}\label{eq231}
\Sp(T_\blt)=\Cl_{\Rbb^N}\Big(\bigcup_{\alpha\in\SI}\Supp(\mu_\alpha)\Big)
\end{align}


\begin{proof}
Denote the RHS of \eqref{eq230} by $Y$. For each open $U\subset\Rbb^N$, we have
\begin{align*}
\chi_U(T_\blt)=\Mbf_{\chi_U\circ f_\blt}
\end{align*}
due to Thm. \ref{lb435}. Therefore, if $U$ does not intersect $Y$, then $U$ does not intersect $\Supp((f_\blt)_*\mu_\alpha)$ for each $\alpha$, and hence
\begin{align*}
\mu_\alpha\{x\in X:\chi_U\circ f_\blt(x)\neq0\}=\mu_\alpha((f_\blt)^{-1}(U))=((f_\blt)_*\mu_\alpha)(U)
\end{align*}
equals zero. From this, it is clear that $\Mbf_{\chi_U\circ f_\blt}=0$. We have thus proves that $\Sp(T_\blt)\subset Y$.

Now choose any $y\in Y$. Then for each $U\in\Nbh_y(\Rbb^N)$, there exists $\alpha$ such that $U$ intersects $\Supp((f_\blt)_*\mu_\alpha)$. From the above derivation, we see that the set $\{x\in X:\chi_U\circ f_\blt(x)\neq0\}$ has nonzero $\mu_\alpha$-value. Since $\mu_\alpha$ is $\sigma$-finite, there exists a Borel subset $E$ of $\{x\in X:\chi_U\circ f_\blt(x)\neq0\}$ such that $0<\mu_\alpha(E)<+\infty$. Let $\xi_\alpha$ be the function $\chi_E$ in $L^2(X,\mu_\alpha)$, viewed also as a vector of $\MH$. Then
\begin{align*}
\bk{\xi_\alpha|\Mbf_{\chi_{U}\circ f_\blt}\xi_\alpha}=\int_E (\chi_U\circ f_\blt) d\mu_\alpha=\mu_\alpha(E)>0
\end{align*}
Thus $\Mbf_{\chi_U\circ f_\blt}\neq0$. This proves $Y\subset\Sp(T_\blt)$.
\end{proof}




\begin{rem}
Let $T_1,\dots,T_N$ be strongly commuting self-adjoint operators on $\MH$. Let $K\subset\Rbb^N$ be a Borel set containing $\Sp(T_\blt)$. Then there is a (clearly unique) map
\begin{align}\label{eq229}
\pi_{T_\blt}:\Bor(K,\Rbb)\rightarrow\{\text{unbounded operators on }\MH\}
\end{align}
satisfying $(f|_K)(T_\blt)=f(T_\blt)$ for each $f\in\Bor(K,\Rbb)$. The map \eqref{eq229} is also called a \textbf{Borel functional calculus} \index{00@Borel functional calculus for unbounded self-adjoint operators} of $T_\blt$.
\end{rem}

\begin{proof}
By the spectral Thm. \ref{lb436}, one may assume that $\MH=\bigoplus_{\alpha\in\SI}L^2(\Rbb^N,\mu_\alpha)$ where each $\mu_\alpha$ is a finite Borel measure on $\Rbb^N$, and $T_1=\Mbf_{x_1},\dots,T_N=\Mbf_{x_N}$. It follows from Thm. \ref{lb435} and the description \eqref{eq231} of $\Sp(T_\blt)$ that the map \eqref{eq229} defined by $\pi_{T_\blt}(f)=\Mbf_{\wtd f}$ (where $\wtd f\in\Bor(\Rbb^N,\Rbb)$ is the zero extension of $f\in\Bor(K,\Rbb)$) satisfies the desired property.
\end{proof}







\subsection{Why the methods of Hilbert and Riesz fail}

Let $\MH$ be a Hilbert space.

\subsubsection{The three paradigm shifts}


In Sec. \ref{lb245}, we mentioned three major paradigm shifts as the central themes of this course. As this chapter illustrates, all three are deeply embodied in von Neumann's treatment of the spectral theory of unbounded operators. In this section, I would like to focus on \eqref{eq147a}, the first of these shifts---the transition from finite approximation to linear extension. The pivotal role of linear extension in von Neumann's theory is most clearly seen in Thm. \ref{lb383}, where the Cayley transform is used to translate the problem of extending a Hermitian operator on $\MH$ into that of extending a unitary map between two linear subspaces of $\MH$.

The other two paradigm shifts follow naturally from this one. The move from the paradigm of bilinear/sesquilinear forms to that of linear operators is unavoidable because, even for bounded sesquilinear forms, defining multiplication necessarily involves finite approximation---as discussed in Subsec. \ref{lb152}---and so does the definition of resolvents, as seen in Hilbert’s treatment of the resolvent in his proof of the spectral theorem in Sec. \ref{lb442}. Accordingly, the shift from the paradigm of duality to that of Cauchy completeness arises as a natural consequence of the focus on linear operators, as previously discussed in Subsec. \ref{lb141}.



\subsubsection{Von Neumann's comments on the finite-approximation paradigm}

In \cite{vN29a}, von Neumann's own comparison between the finite-approximation paradigm and the linear-extension paradigm appears in Section IX of the Introduction, immediately following his brief introduction of the Cayley transform method. The following is an English translation of his discussion:


\begin{displayquote}
All other methods fail: The elegant procedures of Hellinger and of F. Riesz fail, because in them the operator $R$ must be iterated, which is only permissible for everywhere-defined (hence bounded) Hermitian operators; for arbitrary Hermitian operators this is initially doubtful. All maximum-minimum methods, as well as Schmidt's method, are from the beginning restricted to cases without continuous spectrum. The original Hilbert method (approximation by finite-dimensional truncated operators) alone allows the derivation of certain results; but only with very great difficulties, and only a fraction of what we attain (footnote 23).
\end{displayquote}


Von Neumann's objection to (a direct application of) Riesz's method is clear:\footnote{It is not clear whether Riesz himself has applied this method to unbounded operators.} for a Hermitian operator $T$, one cannot simply perform the polynomial functional calculus and then extend to more general functional calculus, since arbitrary compositions of unbounded operators can be problematic. The correct approach---which von Neumann does not state explicitly in this paragraph---is to perform the functional calculus on the Cayley transform of $T$, once $T$ has been extended to a self-adjoint operator.


The most revealing part of this quotation, however, is von Neumann's comment on Hilbert's method of finite-rank approximation. As we saw in Sec. \ref{lb442}, Hilbert derived his spectral theorem for a bounded bilinear (or sesquilinear) form $\omega$ by approximating $\omega$ with finite-rank forms. In the language of linear operators, this means approximating $T\in\fk L(\MH)$ by $E_nTE_n$, where $E_n$ is the projection of $\MH$ (here assumed to be separable) onto $\Span\{e_1,\dots,e_n\}$, with $e_1,e_2,\dots$ an orthonormal basis of $\MH$. The integral representation of the resolvent
\begin{align*}
\bk{\xi|(z-T)^{-1}\xi}=\int\frac{d\rho_\xi(\lambda)}{z-\lambda}
\end{align*}
is then obtained as the limit of the corresponding representation for $\bk{\xi|(z-E_nTE_n)^{-1}\xi}$. In fact, as discussed in the answer to Question \ref{lb242}, in Hilbert's proof the resolvent $(z-T)^{-1}$ itself is defined as the limit of $(z-E_nTE_n)^{-1}$.


The last sentence of von Neumann's quotation can thus be understood as follows: When $T$ is an unbounded Hermitian operator, defining the resolvent $(z-T)^{-1}$ and deriving its integral representation through the limits of $(z-E_nTE_n)^{-1}$ and their corresponding integral representations can yield only partial results compared with von Neumann's method via the Cayley transform---and even these partial results are obtained only with great difficulty.

What von Neumann meant by partial results (i.e., ``a fraction of what we attain'') can be inferred from the first half of Footnote 23 in \cite{vN29a}, where he comments on his earlier attempt to study the spectral theorem for Hermitian operators using Hilbert’s method of finite approximation:


\begin{displayquote}
By this method the author was able to treat the case of real Hermitian operators (cf. footnote 20), where the exceptional case indicated in VII had not yet appeared. However, the extension process for the Hermitian operators could not be as clearly understood as will be the case in Chapter VIII, for example, and the method was so non-constructive that, for instance, the well-ordering theorem had to be invoked (cf. the announcement in Jahresber. d. D. Math.-Ver. 37, 1–4 (1928), pp. 11–15); furthermore, the non-real Hermitian Operators could not be addressed in this way.
\end{displayquote}


By ``exceptional case'' von Neumann meant the situation where exactly one of the two deficiency indices $n_+,n_-$ of a Hermitian operator $T$ is nonzero---or more generally, where $n_+\neq n_-$. Recall from Cor. \ref{lb424} that $T$ admits a self-adjoint extension iff $n_+=n_-$. This corollary appears in Satz 35 of \cite[Chapter VIII]{vN29a}, which, according to the above quotation, provides a much clearer understanding of the extension process for Hermitian operators than Hilbert's finite-rank approximation method.


\subsubsection{Why the linear-extension paradigm is superior to the finite-approximation paradigm}


It might be too harsh to accuse Hilbert’s method of failing to clarify the extension process for Hermitian operators---after all, according to the paradigm shift \eqref{eq147a}, the paradigm of linear extension directly opposes that of finite approximation. What can be said fairly, however, is that the finite-approximation paradigm does not provide a structural understanding of the non-uniqueness of spectral decompositions of Hermitian operators.

Indeed, as seen in Sec. \ref{lb188}, the solution to the Hamburger and Stieltjes moment problems is not always unique, and this non-uniqueness corresponds to the fact that it is often a subsequence of $(z-E_nTE_n)^{-1}$, rather than the full sequence, that converges. (Beyond the polynomial moment problems, even the existence of a convergent subsequence is not guaranteed.) Consequently, the resolvent $(z-T)^{-1}$, defined as the limit of a subsequence $(z-E_{n_k}TE_{n_k})^{-1}$, is not unique and depends on the chosen subsequence; the same holds for the spectral decomposition of $T$, expressed via the integral representation of $T$.

In von Neumann's spectral theory, by contrast, this non-uniqueness appears as the non-uniqueness of the self-adjoint extensions $\wht T$ of $T$. One may therefore interpret the various resolvents $(z-\wht T)^{-1}$ and their spectral decompositions as corresponding to the different possible limits in Hilbert's approach. 

In light of this comparison, the real advantage of von Neumann's theory over Hilbert's finite-approximation method becomes clear: \uwave{Von Neumann's framework characterizes the non-uniqueness (and even the non-existence) of the resolvents and the spectral decompositions of a Hermitian operator $T$ in a structural and conceptual way through the extensions of the Cayley transform of $T$ and the deficiency indices $n_+,n_-$, rather than through the choice of subsequences of $(z-E_nTE_n)^{-1}$.}























\hypertarget{current}{}

\subsection{Problems}


Let $\MH,\MK,\MM$ be Hilbert spaces.


\begin{prob}\label{lb405}
Let $A,B:\MH\rightarrow\MK$ and $C:\MM\rightarrow\MH$ be unbounded operators. Assume that $A+B:\MH\rightarrow\MK$ and $AC:\MM\rightarrow\MK$ are unbounded operators (i.e. they are densely-defined). Prove that as n.d.d. unbounded operators, we have
\begin{align*}
(A+B)^*\supset A^*+B^*\qquad (CA)^*\supset A^*C^*
\end{align*}
Moreover, if $A\in\fk L(\MH,\MK)$, prove that $(A+B)^*=A^*+B^*$, and $(AB)^*=B^*A^*$. 
\end{prob}




\begin{prob}
Let $I=(a,b)$ where $-\infty\leq a<b\leq+\infty$. Let $T_0$ be the unbounded operator $-\im\frac d{dx}$ on $L^2(I,m)$ with domain $C_c^\infty(I)$. Let $T=\ovl {T_0}$.
\begin{enumerate}
\item Prove that 
\begin{gather*}
\Ker(T^*-\im)=\left\{\begin{array}{ll}
\Span\{e^{-x}\}&\text{if }a>-\infty\\[0.5ex]
0&\text{if }a=-\infty
\end{array}
\right.\\[0.5ex]
\Ker(T^*+\im)=\left\{\begin{array}{ll}
\Span\{e^{x}\}&\text{if }b<+\infty\\[0.5ex]
0&\text{if }b=+\infty
\end{array}
\right.
\end{gather*}
\item Conclude that if $I=(0,+\infty)$, the Hermitian operator $T$ has deficiency indices $n_+=1,n_-=0$, and hence has no self-adjoint extensions.
\item Conclude that if $I=\Rbb$, then $H^1(I)=H^1_0(I)$, and $T_0$ is essentially self-adjoint.
\end{enumerate}
\end{prob}

\begin{proof}[Hint]
Restrict $f\in\Dom(T^*)$ to bounded intervals, and apply the results in Sec. \ref{lb425}.
\end{proof}


\begin{prob}
Let $A,B$ be self-adjoint operators on $\MH$. Let $U\in\fk L(\MH)$ be unitary. For each $\lambda\in\Rbb$, let $E(\lambda)=\chi_{(-\infty,\lambda]}(A)$ and $F(\lambda):=\chi_{(-\infty,\lambda]}(B)$.
\begin{enumerate}
\item Prove that $UA=AU$ iff $UE(\lambda)=E(\lambda)U$ for each $\lambda\in\Rbb$.
\item Prove that $A$ commutes strongly with $B$ iff $E(\lambda)F(\mu)=F(\mu)E(\lambda)$ for each $\lambda,\mu\in\Rbb$.
\end{enumerate}
\end{prob}








\newpage


\section{Examples of unbounded self-adjoint operators}\label{lb407}




\subsection{Positive self-adjoint operators}



\begin{df}
An unbounded operator $T$ on $\MH$ is called a \textbf{positive operator} \index{00@Positive (unbounded) operators} if $\bk{\xi|T\xi}\geq0$ for each $\xi\in\MH$. 

More generally, a linear subspace $\fk G\subset\MH\times\MH$ is called a \textbf{positive graph} \index{00@Positive graph} if $\bk{\phi|\xi}\geq0$ for each $(\xi,\phi)\in\fk G$.  \hqed
\end{df}

Positive operators are clearly Hermitian.


\begin{pp}
Let $T$ be an unbounded operator on $\MH$. The following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $T$ is self-adjoint and positive.
\item $T$ is self-adjoint and $\Sp(T)\subset\Rbb_{\geq0}$.
\item $T$ is positive, and $\Rng(\idt+T)=\MH$.
\end{enumerate}
\end{pp}



\begin{proof}
$\neg$(2)$\Rightarrow$$\neg$(1): Assume that $T$ is self-adjoint and $\Sp(T)\nsubset\Rbb_{\geq0}$. By the spectral Thm. \ref{lb436}, one may assume that $\MH=\bigoplus_{\alpha\in\SI}L^2(\Rbb,\mu_\alpha)$ where each $\mu_\alpha$ is a finite Borel measure on $\Rbb$, and $T=\Mbf_x$. By Thm. \ref{lb441}, there exists $\alpha$ such that $\Supp(\mu_\alpha)\nsubset\Rbb_{\geq0}$ and hence $\mu_\alpha(\Rbb_{<0})\geq0$. Thus, viewing $\xi=\chi_{\Rbb_{<0}}$ as an element of $L^2(\Rbb,\mu_\alpha)$ (and hence an element of $\MH$), we have $\bk{\xi|T\xi}=\int_{\Rbb_{<0}}xd\mu_\alpha<0$. So $T$ is not positive.

(2)$\Rightarrow$(3): By the spectral Thm. \ref{lb436} and Thm. \ref{lb441}, we may assume that $\MH=\bigoplus_{\alpha\in\SI}L^2(\Rbb_{\geq0},\mu_\alpha)$ where each $\mu_\alpha$ is a finite Borel measure on $\Rbb_{\geq0}$, and $T=\Mbf_x$. Then $T$ is clearly positive. Since the function $1/(1+x)$ is bounded, by Rem. \ref{lb371}, we have
\begin{align*}
(\idt+T)\Mbf_{1/(1+x)}=\Mbf_{1+x}\Mbf_{1/(1+x)}=\Mbf_1=\idt
\end{align*} 
Thus $\Rng(\idt+T)=\MH$.

(3)$\Rightarrow$(1): Since $T$ is positive, we have
\begin{align*}
\bk{(\idt+T)\xi|(\idt+T)\xi}\geq \bk{\xi|\xi}\qquad\text{for each }\xi\in\Dom(T)
\end{align*}
In particular, if $(\idt+T)\xi=0$ then $\xi=0$. Therefore, the unbounded operator $\idt+T$ is injective and has range $\MH$. Let $S:\MH\rightarrow\MH$ be its inverse, whose domain is $\Dom(S)=\Rng(\idt+T)=\MH$. Then the above inequality becomes
\begin{align*}
\bk{\phi|\phi}\geq\bk{S\phi|S\phi}\qquad\text{for each }\phi\in\MH
\end{align*}
Thus $S\in\fk L(\MH)$. Moreover, since the diagonal reflection of a positive graph is clearly also positive, we conclude that $S\geq0$. In particular, we have $S^*=S$. By Prop. \ref{lb404}, we have $(\idt+T)^*=(S^{-1})^*=(S^*)^{-1}=S^{-1}=\idt+T$, and hence $\idt+T^*=\idt+T$. Therefore $T$ is self-adjoint.
\end{proof}




\newpage



\section{From completely continuous forms to compact operators}\label{lb355}


\newpage

\section{Convexity and bounded linear extensions}





\printindex	






	\begin{thebibliography}{999999}
		\footnotesize	

\bibitem[Apo]{Apo}
Apostol, T. M. (1974). Mathematical analysis. 2nd ed.

\bibitem[Dav]{Dav}
Davidson, K. R. (1996). $C^*$-algebras by example. RI: AMS, American Mathematical Society.


\bibitem[Dir30]{Dir30}
Dirac, P. A. M. (1958). The principles of quantum mechanics. 4th ed. First edition in 1930.

\bibitem[Eva]{Eva}
Evans, L. C. Partial differential equations. 2nd ed. (2010)


\bibitem[Fol-R]{Fol-R}
Folland, G. B. (1999). Real analysis: modern techniques and their applications. 2nd ed.

\bibitem[Fre03]{Fre03}
Fredholm, I. Sur une classe d'{\'e}quations fonctionnelles. Acta Math. 27, 365-390 (1903).


\bibitem[Gray84]{Gray84}
Gray, J. D. (1984). The shaping of the Riesz representation theorem: A chapter in the history of analysis. Archive for History of Exact Sciences, 31, 127-187.

\bibitem[Gud74]{Gud74}
Gudder, S. (1974). Inner product spaces. The American Mathematical Monthly, 81(1), 29-36.

\bibitem[Gui-A]{Gui-A}
Bin Gui, Qiuzhen Lectures on Analysis. See \url{https://binguimath.github.io/Pages/2023_Analysis.html}
%See the ``Notes'' section of \url{https://binguimath.github.io}

\bibitem[Gui-S]{Gui-S}
Bin Gui, Spectral Theory for Strongly Commuting Normal Closed Operators. See the ``Notes'' section of \url{https://binguimath.github.io}
%

\bibitem[Haw-L]{Haw-L}
Hawkins, T. (1979) Lebesgue's theory of integration: Its origins and development. Corrected reprint of the 2nd edition. 

\bibitem[Hil06]{Hil06}
Hilbert, D. (1906) Grundz\"uge einer allgemeinen Theorie der linearen Integralgleichungen. The fourth part (Vierter Abschnitt, Theorie der quadratischen Formen mit unendlich vielen Variablen).

\bibitem[Jah]{Jah}
Jahnke, H. N. (2003). A history of analysis (No. 24). American Mathematical Soc..

\bibitem[Lax]{Lax}
P. D. Lax. Functional analysis. (2002)

\bibitem[vN27]{vN27}
von Neumann, J. Mathematische {Begr{\"u}ndung} der {Quantenmechanik}. Nachr. Ges. Wiss. G{\"o}ttingen, Math.-Phys. Kl. 1927, 1-57 (1927).


\bibitem[vN29a]{vN29a}
von Neumann, J. Allgemeine Eigenwerttheorie Hermitescher Funktionaloperatoren. Math. Ann. 102, 49-131 (1929).


\bibitem[vN29b]{vN29b}
von Neumann, J. Zur Algebra der Funktionaloperationen und Theorie der normalen Operatoren. Math. Ann. 102, 370-427 (1929).



\bibitem[vN31]{vN31}
von Neumann, J. \"Uber Funktionen von Funktionaloperatoren. Annals of Math. (2) 32, 191-226 (1931)


\bibitem[vN32a]{vN32a}
von Neumann, J. (1932). Mathematical foundations of quantum mechanics. English translation of von Neumann's book \textit{Mathematische Grundlagen der Quantenmechanik}.


\bibitem[vN32b]{vN32b}

von Neumann, J. {\"U}ber adjungierte {Funktionaloperatoren}. Ann. Math. (2) 33, 294-310 (1932).



\bibitem[Pes]{Pes}
Pesin, I. N. (1970). Classical and modern integration theories.


\bibitem[RN]{RN}
F. Riesz and B. Sz.-Nagy, Functional analysis. Transl. from the 2nd French ed. by Leo F.
Boron. (1956)

\bibitem[RS-1]{RS-1}
M. Reed and B. Simon, Methods of modern mathematical physics. {I}: {Functional} analysis. {Rev}. and enl. ed. (1982)

\bibitem[Rie07a]{Rie07a}
Riesz, F. (1907). \"Uber orthogonale Funktionensysteme. Nachr. Ges. Wiss. G{\"o}ttingen, Math.-Phys. Kl.  1907, 116-122.


\bibitem[Rie07b]{Rie07b}
Riesz, F. (1907). Sur une esp{\`e}ce de g{\'e}om{\'e}trie analytique des syst{\`e}mes de fonctions sommables. C. R. Acad. Sci., Paris.  144, 1409-1411.



\bibitem[Rie09]{Rie09}
Riesz, F. (1909). Sur les op\'erations functionnelles lin\'eaires. Gauthier-Vllars.

\bibitem[Rie10]{Rie10}
Riesz, F. (1910). Untersuchungen \"uber systeme integrierbarer funktionen. Mathematische Annalen, 69(4), 449-497.


\bibitem[Rie11]{Rie11}
Riesz, F. (1911). Sur certains syst\'emes singuliers d'\'equations int\'egrales. In Annales scientifiques de l'\'Ecole Normale Sup\'erieure (Vol. 28, pp. 33-62).

\bibitem[Rie13]{Rie13}
Riesz, F. (1913). Les syst\`emes d'\'equations lin\'eaires \`a une infinite d'inconnues.


\bibitem[Rie14]{Rie14}
Riesz, F. (1914). D{\'e}monstration nouvelle d'un th{\'e}or{\`e}me concernant les op{\'e}rations fonctionelles lin{\'e}aires. Ann. Sci. {\'E}c. Norm. Sup{\'e}r. (3).

\bibitem[Rie18]{Rie18}
Riesz, F. (1918). \"Uber lineare funktionalgleichungen. Acta math, 41(1), 71-98.

\bibitem[Rud-R]{Rud-R}
Rudin, W. (1987). Real and complex analysis. 3rd ed.

\bibitem[Rud-F]{Rud-F}
W. Rudin, Functional analysis. 2nd ed. (1991)


\bibitem[Sti94]{Sti94}
Stieltjes, T. J. (1894). Recherches sur les fractions continues. Toulouse Ann. VIII, J1-J122.

\bibitem[Sti-C]{Sti-C}
Stieltjes. {\OE}uvres compl{\`e}tes. {Collected} papers. Vol. II contains an English translation of \cite{Sti94}.

\bibitem[Xia]{Xia}

\begin{CJK*}{UTF8}{gkai}
夏道行，吴卓人，严绍宗，舒五昌. 实变函数论与泛函分析，下册，第二版修订本.
\end{CJK*}


\bibitem[You10]{You10}
Young, W. H. On a new method in the theory of integration. Proc. Lond. Math. Soc. (2) 9, 15--50 (1910).

\bibitem[You13]{You13}
Young, W. H. On the new theory of integration.  Proc. R. Soc. Lond., Ser. A 88, 170--178 (1913).


		
\end{thebibliography}

%\noindent {\small \sc Yau Mathematical Sciences Center, Tsinghua University, Beijing, China.}

%\noindent {\textit{E-mail}}: binguimath@gmail.com\qquad bingui@tsinghua.edu.cn
\end{document}