% !TeX spellcheck = en_US
% !TEX program = pdflatex
\documentclass[12pt,b5paper,notitlepage]{article}
\usepackage[b5paper, margin={0.5in,0.65in}]{geometry}
%\usepackage{fullpage}
\usepackage{amsmath,amscd,amssymb,amsthm,mathrsfs,amsfonts,layout,indentfirst,graphicx,caption,mathabx, stmaryrd,appendix,calc,imakeidx,upgreek} % mathabx for \wtidecheck
%\usepackage{ulem} %wave underline
\usepackage[dvipsnames]{xcolor}
\usepackage{palatino}  %template

\usepackage{slashed} % Dirac operator
\usepackage{mathrsfs} % Enable using \mathscr
%\usepackage{eufrak}  another template/font
\usepackage{extarrows} % long equal sign, \xlongequal{blablabla}
\usepackage{enumitem} % enumerate label change e.g. [label=(\alph*)]  shows (a) (b) 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage{fontspec}
%\setmainfont{Palatino Linotype}
%\usepackage{emoji}


% emoji, use lualatex  remove \usepackage{palatino}

%%%%%%%%%%%%%


\usepackage{CJK}   % Chinese package





\usepackage{csquotes} % \begin{displayquote}   \begin{displaycquote}  for quotation
\usepackage{epigraph}   %\epigraph{}{}  for quotation
%\pmb  mandatory math bold 

\usepackage{fancyhdr} % date in footer

%\usepackage{soul}  %\ul underline break line automatically

\usepackage{ulem}  % \uline  underline break line   also    \uwave

\usepackage{relsize} % use \mathlarger \larger \text{\larger[2]$...$} to enlarge the size of math symbols

\usepackage{verbatim}  % comment environment


\usepackage{halloweenmath} % Interesting halloween math symbols

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tcolorbox}
\tcbuselibrary{theorems}
% box around equations   \tcboxmath
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% circled colon and thick colon \hcolondel and \colondel

\usepackage{pdfrender}

\newcommand*{\hollowcolon}{%
	\textpdfrender{
		TextRenderingMode=Stroke,
		LineWidth=.1bp,
	}{:}%
}

\newcommand{\hcolondel}[1]{%
	\mathopen{\hollowcolon}#1\mathclose{\hollowcolon}%
}
\newcommand{\colondel}[1]{%
	\mathopen{:}#1\mathclose{:}%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\usepackage{tikz}
\usetikzlibrary{fadings}
\usetikzlibrary{patterns}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes}

\usepackage{tikz-cd}
\usepackage[nottoc]{tocbibind}   % Add  reference to ToC


\makeindex


% The following set up the line spaces between items in \thebibliography
\usepackage{lipsum}  
\let\OLDthebibliography\thebibliography
\renewcommand\thebibliography[1]{
	\OLDthebibliography{#1}
	\setlength{\parskip}{0pt}
	\setlength{\itemsep}{2pt} 
}


%\hyperref{page.10}{...}

\allowdisplaybreaks  %allow aligns to break between pages
\usepackage{latexsym}
\usepackage{chngcntr}
\usepackage[colorlinks,linkcolor=blue,anchorcolor=blue, linktocpage,
%pagebackref
]{hyperref}
\hypersetup{ urlcolor=cyan,
	citecolor=[rgb]{0,0.5,0}}


\setcounter{tocdepth}{2}	 %hide subsections in the content


\counterwithin{figure}{section}

\counterwithin*{footnote}{section}   % Footnote numbering is recounted from the beginning of each subsection



\pagestyle{plain}

\captionsetup[figure]
{
	labelsep=none	
}













\theoremstyle{definition}
\newtheorem{df}{Definition}[section]
\newtheorem{eg}[df]{Example}
\newtheorem{exe}[df]{Exercise}
\newtheorem{rem}[df]{Remark}
\newtheorem{obs}[df]{Observation}
\newtheorem{ass}[df]{Assumption}
\newtheorem{cv}[df]{Convention}
\newtheorem{prin}[df]{Principle}
\newtheorem{nota}[df]{Notation}
\newtheorem*{axiom}{Axiom}
\newtheorem{coa}[df]{Theorem}
\newtheorem{srem}[df]{$\star$ Remark}
\newtheorem{seg}[df]{$\star$ Example}
\newtheorem{sexe}[df]{$\star$ Exercise}
\newtheorem{sdf}[df]{$\star$ Definition}




\newtheorem{prob}{\color{red}Problem}[section]
%\renewcommand*{\theprob}{{\color{red}\arabic{section}.\arabic{prob}}}
\newtheorem{sprob}[prob]{\color{red}$\star$ Problem}
%\renewcommand*{\thesprob}{{\color{red}\arabic{section}.\arabic{sprob}}}
% \newtheorem{ssprob}[prob]{$\star\star$ Problem}



\theoremstyle{plain}
\newtheorem{thm}[df]{Theorem}
\newtheorem{ccl}[df]{Conclusion}
\newtheorem{thd}[df]{Theorem-Definition}
\newtheorem{pp}[df]{Proposition}
\newtheorem{co}[df]{Corollary}
\newtheorem{lm}[df]{Lemma}
\newtheorem{sthm}[df]{$\star$ Theorem}
\newtheorem{slm}[df]{$\star$ Lemma}
\newtheorem{claim}[df]{Claim}
\newtheorem{spp}[df]{$\star$ Proposition}
\newtheorem{scorollary}[df]{$\star$ Corollary}


\newtheorem{cond}{Condition}
\newtheorem{Mthm}{Main Theorem}
\renewcommand{\thecond}{\Alph{cond}} % "letter-numbered" theorems
\renewcommand{\theMthm}{\Alph{Mthm}} % "letter-numbered" theorems


%\substack   multiple lines under sum
%\underset{b}{a}   b is under a


% Remind: \overline{L_0}



\usepackage{calligra}
\DeclareMathOperator{\shom}{\mathscr{H}\text{\kern -3pt {\calligra\large om}}\,}
\DeclareMathOperator{\sext}{\mathscr{E}\text{\kern -3pt {\calligra\large xt}}\,}
\DeclareMathOperator{\Rel}{\mathscr{R}\text{\kern -3pt {\calligra\large el}~}\,}
\DeclareMathOperator{\sann}{\mathscr{A}\text{\kern -3pt {\calligra\large nn}}\,}
\DeclareMathOperator{\send}{\mathscr{E}\text{\kern -3pt {\calligra\large nd}}\,}
\DeclareMathOperator{\stor}{\mathscr{T}\text{\kern -3pt {\calligra\large or}}\,}


\usepackage{aurical}
\DeclareMathOperator{\VVir}{\text{\Fontlukas V}\text{\kern -0pt {\Fontlukas\large ir}}\,}

\newcommand{\vol}{\text{\Fontlukas V}}
\newcommand{\dvol}{d~\text{\Fontlukas V}}

\usepackage{aurical}
\usepackage[T1]{fontenc}








\newcommand{\fk}{\mathfrak}
\newcommand{\mc}{\mathcal}
\newcommand{\wtd}{\widetilde}
\newcommand{\wht}{\widehat}
\newcommand{\wch}{\widecheck}
\newcommand{\ovl}{\overline}
\newcommand{\udl}{\underline}
\newcommand{\tr}{\mathrm{t}} %transpose
\newcommand{\Tr}{\mathrm{Tr}}
\newcommand{\End}{\mathrm{End}} %endomorphism
\newcommand{\idt}{\mathbf{1}}
\newcommand{\id}{\mathrm{id}}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\Conf}{\mathrm{Conf}}
\newcommand{\Res}{\mathrm{Res}}
\newcommand{\res}{\mathrm{res}}
\newcommand{\KZ}{\mathrm{KZ}}
\newcommand{\ev}{\mathrm{ev}}
\newcommand{\coev}{\mathrm{coev}}
\newcommand{\opp}{\mathrm{opp}}
\newcommand{\Rep}{\mathrm{Rep}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\Dom}{\mathrm{Dom}}
\newcommand{\loc}{\mathrm{loc}}
\newcommand{\con}{\mathrm{c}}
\newcommand{\uni}{\mathrm{u}}
\newcommand{\ssp}{\mathrm{ss}}
\newcommand{\di}{\slashed d}
\newcommand{\Diffp}{\mathrm{Diff}^+}
\newcommand{\Diff}{\mathrm{Diff}}
\newcommand{\PSU}{\mathrm{PSU}(1,1)}
\newcommand{\Vir}{\mathrm{Vir}}
\newcommand{\Witt}{\mathscr W}
\newcommand{\Span}{\mathrm{Span}}
\newcommand{\pri}{\mathrm{p}}
\newcommand{\ER}{E^1(V)_{\mathbb R}}
\newcommand{\prth}[1]{( {#1})}
\newcommand{\bk}[1]{\langle {#1}\rangle}
\newcommand{\bigbk}[1]{\big\langle {#1}\big\rangle}
\newcommand{\Bigbk}[1]{\Big\langle {#1}\Big\rangle}
\newcommand{\biggbk}[1]{\bigg\langle {#1}\bigg\rangle}
\newcommand{\Biggbk}[1]{\Bigg\langle {#1}\Bigg\rangle}
\newcommand{\GA}{\mathscr G_{\mathcal A}}
\newcommand{\vs}{\varsigma}
\newcommand{\Vect}{\mathrm{Vec}}
\newcommand{\Vectc}{\mathrm{Vec}^{\mathbb C}}
\newcommand{\scr}{\mathscr}
\newcommand{\sjs}{\subset\joinrel\subset}
\newcommand{\Jtd}{\widetilde{\mathcal J}}
\newcommand{\gk}{\mathfrak g}
\newcommand{\hk}{\mathfrak h}
\newcommand{\xk}{\mathfrak x}
\newcommand{\yk}{\mathfrak y}
\newcommand{\zk}{\mathfrak z}
\newcommand{\pk}{\mathfrak p}
\newcommand{\hr}{\mathfrak h_{\mathbb R}}
\newcommand{\Ad}{\mathrm{Ad}}
\newcommand{\DHR}{\mathrm{DHR}_{I_0}}
\newcommand{\Repi}{\mathrm{Rep}_{\wtd I_0}}
\newcommand{\im}{\mathbf{i}}
\newcommand{\Co}{\complement}
%\newcommand{\Cu}{\mathcal C^{\mathrm u}}
\newcommand{\RepV}{\mathrm{Rep}^\uni(V)}
\newcommand{\RepA}{\mathrm{Rep}(\mathcal A)}
\newcommand{\RepN}{\mathrm{Rep}(\mathcal N)}
\newcommand{\RepfA}{\mathrm{Rep}^{\mathrm f}(\mathcal A)}
\newcommand{\RepAU}{\mathrm{Rep}^\uni(A_U)}
\newcommand{\RepU}{\mathrm{Rep}^\uni(U)}
\newcommand{\RepL}{\mathrm{Rep}^{\mathrm{L}}}
\newcommand{\HomL}{\mathrm{Hom}^{\mathrm{L}}}
\newcommand{\EndL}{\mathrm{End}^{\mathrm{L}}}
\newcommand{\Bim}{\mathrm{Bim}}
\newcommand{\BimA}{\mathrm{Bim}^\uni(A)}
%\newcommand{\shom}{\scr Hom}
\newcommand{\divi}{\mathrm{div}}
\newcommand{\sgm}{\varsigma}
\newcommand{\SX}{{S_{\fk X}}}
\newcommand{\DX}{D_{\fk X}}
\newcommand{\mbb}{\mathbb}
\newcommand{\mbf}{\mathbf}
\newcommand{\bsb}{\boldsymbol}
\newcommand{\blt}{\bullet}
\newcommand{\Vbb}{\mathbb V}
\newcommand{\Ubb}{\mathbb U}
\newcommand{\Xbb}{\mathbb X}
\newcommand{\Kbb}{\mathbb K}
\newcommand{\Abb}{\mathbb A}
\newcommand{\Wbb}{\mathbb W}
\newcommand{\Mbb}{\mathbb M}
\newcommand{\Gbb}{\mathbb G}
\newcommand{\Cbb}{\mathbb C}
\newcommand{\Nbb}{\mathbb N}
\newcommand{\Zbb}{\mathbb Z}
\newcommand{\Qbb}{\mathbb Q}
\newcommand{\Pbb}{\mathbb P}
\newcommand{\Rbb}{\mathbb R}
\newcommand{\Ebb}{\mathbb E}
\newcommand{\Dbb}{\mathbb D}
\newcommand{\Hbb}{\mathbb H}
\newcommand{\cbf}{\mathbf c}
\newcommand{\Rbf}{\mathbf R}
\newcommand{\wt}{\mathrm{wt}}
\newcommand{\Lie}{\mathrm{Lie}}
\newcommand{\btl}{\blacktriangleleft}
\newcommand{\btr}{\blacktriangleright}
\newcommand{\svir}{\mathcal V\!\mathit{ir}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cok}{\mathrm{Coker}}
\newcommand{\Sbf}{\mathbf{S}}
\newcommand{\low}{\mathrm{low}}
\newcommand{\Sp}{\mathrm{Sp}}
\newcommand{\Rng}{\mathrm{Rng}}
\newcommand{\vN}{\mathrm{vN}}
\newcommand{\Ebf}{\mathbf E}
\newcommand{\Nbf}{\mathbf N}
\newcommand{\Stb}{\mathrm {Stb}}
\newcommand{\SXb}{{S_{\fk X_b}}}
\newcommand{\pr}{\mathrm {pr}}
\newcommand{\SXtd}{S_{\wtd{\fk X}}}
\newcommand{\univ}{\mathrm {univ}}
\newcommand{\vbf}{\mathbf v}
\newcommand{\ubf}{\mathbf u}
\newcommand{\wbf}{\mathbf w}
\newcommand{\CB}{\mathrm{CB}}
\newcommand{\Perm}{\mathrm{Perm}}
\newcommand{\Orb}{\mathrm{Orb}}
\newcommand{\Lss}{{L_{0,\mathrm{s}}}}
\newcommand{\Lni}{{L_{0,\mathrm{n}}}}
\newcommand{\UPSU}{\widetilde{\mathrm{PSU}}(1,1)}
\newcommand{\Sbb}{{\mathbb S}}
\newcommand{\Gc}{\mathscr G_c}
\newcommand{\Obj}{\mathrm{Obj}}
\newcommand{\bpr}{{}^\backprime}
\newcommand{\fin}{\mathrm{fin}}
\newcommand{\Ann}{\mathrm{Ann}}
\newcommand{\Real}{\mathrm{Re}}
\newcommand{\Imag}{\mathrm{Im}}
%\newcommand{\cl}{\mathrm{cl}}
\newcommand{\Ind}{\mathrm{Ind}}
\newcommand{\Supp}{\mathrm{Supp}}
\newcommand{\Specan}{\mathrm{Specan}}
\newcommand{\red}{\mathrm{red}}
\newcommand{\uph}{\upharpoonright}
\newcommand{\Mor}{\mathrm{Mor}}
\newcommand{\pre}{\mathrm{pre}}
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\Jac}{\mathrm{Jac}}
\newcommand{\emb}{\mathrm{emb}}
\newcommand{\Sg}{\mathrm{Sg}}
\newcommand{\Nzd}{\mathrm{Nzd}}
\newcommand{\Owht}{\widehat{\scr O}}
\newcommand{\Ext}{\mathrm{Ext}}
\newcommand{\Tor}{\mathrm{Tor}}
\newcommand{\Com}{\mathrm{Com}}
\newcommand{\Mod}{\mathrm{Mod}}
\newcommand{\nk}{\mathfrak n}
\newcommand{\mk}{\mathfrak m}
\newcommand{\Ass}{\mathrm{Ass}}
\newcommand{\depth}{\mathrm{depth}}
\newcommand{\Coh}{\mathrm{Coh}}
\newcommand{\Gode}{\mathrm{Gode}}
\newcommand{\Fbb}{\mathbb F}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\Modf}{\mathrm{Mod}^{\mathrm f}}
\newcommand{\codim}{\mathrm{codim}}
\newcommand{\card}{\mathrm{card}}
\newcommand{\dps}{\displaystyle}
\newcommand{\Int}{\mathrm{Int}}
\newcommand{\Nbh}{\mathrm{Nbh}}
\newcommand{\Pnbh}{\mathrm{PNbh}}
\newcommand{\Cl}{\mathrm{Cl}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\eps}{\varepsilon}
\newcommand{\Vol}{\mathrm{Vol}}
\newcommand{\LSC}{\mathrm{LSC}}
\newcommand{\USC}{\mathrm{USC}}
\newcommand{\Ess}{\mathrm{Rng}^{\mathrm{ess}}}
\newcommand{\Jbf}{\mathbf{J}}
\newcommand{\SL}{\mathrm{SL}}
\newcommand{\GL}{\mathrm{GL}}
\newcommand{\Lin}{\mathrm{Lin}}
\newcommand{\ALin}{\mathrm{ALin}}
\newcommand{\bwn}{\bigwedge\nolimits}
\newcommand{\nbf}{\mathbf n}
\newcommand{\dive}{\mathrm{div}}









\usepackage{tipa} % wierd symboles e.g. \textturnh
\newcommand{\tipar}{\text{\textrtailr}}
\newcommand{\tipaz}{\text{\textctyogh}}
\newcommand{\tipaomega}{\text{\textcloseomega}}
\newcommand{\tipae}{\text{\textrhookschwa}}
\newcommand{\tipaee}{\text{\textreve}}
\newcommand{\tipak}{\text{\texthtk}}
\newcommand{\mol}{\upmu}
\newcommand{\dmol}{d\upmu}




\usepackage{tipx}
\newcommand{\tipxgamma}{\text{\textfrtailgamma}}
\newcommand{\tipxcc}{\text{\textctstretchc}}
\newcommand{\tipxphi}{\text{\textqplig}}















\numberwithin{equation}{section}




\title{Qiuzhen Lectures on Analysis}
\author{{\sc Bin Gui}
	\\
	{\small \sc Yau Mathematical Sciences Center, Tsinghua University.}\\
	{\small binguimath@gmail.com\qquad bingui@tsinghua.edu.cn}
}
%\date{}

%\definecolor{mycolor}{RGB}{227,237,205} \pagecolor{mycolor}

\begin{document}\sloppy % avoid stretch into margins
	\pagenumbering{arabic}
	%\pagenumbering{gobble}
	\setcounter{page}{1}
	\setcounter{section}{-1}
	%\setcounter{equation}{6}



	






	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



	
	\maketitle
\small   \hyperlink{page.7}{Last page of TOC}\qquad %\hyperlink{current}{current revision}


%\hyperlink{beforeindex}{Last page before index}~~~~~~  
%\hypertarget{beforeindex}{}



%\noindent Sections on history include but are not limited to: 
%\ref{lb55} (point-set topology),  \ref{lb550} (integral theory, Fourier series), \ref{lb543} (Banach-Alaoglu, Hahn-Banach),  \ref{lb548} (quotient Banach spaces, Hahn-Banach), \ref{lb671} and most part of Ch. \ref{lb672} (Hilbert spaces, integral equations), \ref{lb733} (measurable sets), \ref{mc89} (Riesz-Fischer theorem, $L^p$-$L^q$ duality), \ref{lb896} (functional calculus, spectral theory)
%\normalsize
%\thispagestyle{empty}	 %remove page number of this page


%Contents hyperlinks: \hyperlink{page.2}{Page 2}, \hyperlink{page.3}{Page 3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-0.5cm}

%\makeatletter
%\newcommand*{\toccontents}{\@starttoc{toc}}
%\makeatother
%\toccontents



	
% title and table of contents same page, no content title

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\normalsize
\tableofcontents






\newpage

\section{Preface}

\subsection{Forewords}

The content of these lecture notes is based on the analysis courses the author taught to undergraduate students at Qiuzhen College, Tsinghua University, during the period from fall 2022 to summer 2024. The courses assume that students are familiar with the basic concepts and computations in calculus (such as  differentiation and integration, the $\eps$-$\delta$ language), and the basic notions of analysis such as uniform convergence and uniform continuity. 

Some of the sections in the lecture notes were not covered in class and were left for after-class reading. Most of the problems in the notes were assigned as homework. However, some homework problems, especially those related to manifolds or computations, were not included in the notes.


The notes contain a lot of material related to the history of mathematics, especially in chapters \ref{lb909}, \ref{lb665}, \ref{lb672}, \ref{mc237}, \ref{mc238}. %, and in the (Chinese) introductory section \ref{mc239}. 
They are an important part of the notes and the courses. We do not recommend the readers to skip them arbitrarily.

Readers who find mistakes or typos in the notes are welcome to contact the authors. (See the email addresses at the front page.)


\newpage

\subsection{Introduction (in Chinese)}\label{mc239}

\begin{CJK}{UTF8}{gkai}

2022年秋至2024年夏，作者在清华大学给求真书院的本科生教授了两轮基础分析课程，每一轮为两学期，各名为<分析一>和<分析二>。本课程预设学生熟悉微积分中的基本概念和计算（简单的求极限、求导、积分等等）、熟悉如何运用 $\eps$-$\delta$ 语言。事实上，至少三分之二的选课学生预先修过名为<分析零>的预科课程，在单变量分析学的严格理论方面有基本的训练。本讲义在逻辑上从头开始，不假设任何分析学定理已被证明，以实数理论为起点讲授现代分析学的基本框架。然而，读者应当与一致收敛和一致连续等基础分析概念打过交道，对它们的直觉有基本的把握。






本讲义从第一轮教学的课程素材整理而来，同时也是第二轮教学的指定参考资料。这当然不意味着学生应当只阅读本讲义。站在学习者的角度，参考多本教材有助于自己从不同的视角看待同一个主题。而站在作者私心的角度，本讲义在诸多素材的处理上也暗含与其它教材的对话。许多理论的呈现方式有别于经典教科书中常见的模式，这不止是想要给读者提供一些不同的视角，其实也是不同数学观之间的交锋。读者在比较过其它经典教材的论述之后，方能体会作者的写作意图。

这篇导论的目的便是概述作者想在讲义中传达的理念。读者在刚开始学习分析学时未必能完整理解导论中所提及的数学，对此读者无需担忧，因为导论并不是真的需要在阅读正文前就读完并理解的。导论是整本书的线索，是读者在研读正文迷路时的向导，是可以时时返回去再次阅读的文本。甚至读者在读过讲义很久之后，对数学有了很多独到的理解，再次返回阅读文本时倒能产生前所未有的观点碰撞。读者无需把导论所述观点当作过来人的经验之谈和必须认同的建议。导论中部分措辞稍显严肃或针锋相对，其实更多是一种修辞。能够开启和读者的对话，便已完成了本导论的使命。


%导论可以是序言、可以是间奏曲、可以是尾声、也可以是一本书阅读过之后很久再次翻开时和成长了的读者谈心的老朋友。





\subsubsection{\large\pmb{历史视角}}


一门数学基础课不止应当传授课程名所述的知识体系（例如“分析学”），也应当教授如何“理解数学”，如何辨别什么证明是有助于理解数学直观和本质的、什么证明只是机械地验证技术细节。当然，不同的成熟数学工作者对于何为“本质或直观的理解”可以有相异甚至完全相反的标准。但是大体上来说，他们的标准依赖于他们所学习过的其它后续课程、当下的科研前沿、以及自己的研究品味。无论这些标准差得多远，都是一种\pmb{未来视角}。在这种视角下，能够融入后续更加广阔的数学体系的方法便是更本质的方法，能够和更多其它数学相联系和统一的方法便是更直观的方法。与此相对的，更“非本质”和更“不直观”的方法则是更孤立的、更难推广的、更难与后续数学产生联系的方法。


当下已有大量教材出色地在未来视角下教授学生如何理解数学。本讲义关于未来视角方面的特色会留待导论的最后叙述。在本导论中，我想着重谈谈一种和未来视角非常不同的、往往能对理解数学起到很好补充作用的视角，即\pmb{历史视角}。

某种意义上说，未来视角是一种胜者视角，是一套更一般、更全能的理论战胜经典理论之后对数学知识和视角的改述和重构。通过学习未来视角下“更深刻的理论”，我们能更快地用已有知识处理更广阔的数学主题。然而，初学者往往无法透过现代理论的包装来学到伟大数学家推动数学知识发展的智慧。这不只是因为数学前沿的发展规律与现代教科书中建立体系的干练过程截然相反，也是因为现代体系中大量“优美”、“华丽”、“简洁”的证明使人误以为只有这些才是数学家的真正智慧，是人类心智的荣耀。但如果我们对数学有些许的历史意识，就会理解：在一套庞大的数学理论和观念当中，最不平凡的部分是它的核心想法之雏形从无到有诞生的过程，而不是雏形诞生之后通过喂养“推广”的饲料变成宏大观念巨兽的过程。而只有历史视角能告诉我们，以数学发展和创造的眼光看，一套数学理论从诞生到成熟的过程中最不平凡的思想火种是什么。这些火种往往会被未来视角下的现代文本所掩盖甚至丢弃。


由此便形成了一个有趣的悖论，即“未来视角”倒是面向过去的，而“历史视角”却是以数学的未来、以数学的发展和创造作为“何为真正的、本质的、直观的理解”的标准的。在“历史视角”下，判断一个理解和证明是否是“直观和本质”的标准，并不是能否与更多后续数学方法联系来，而是：如果我们把自己带入到数学发展的当下，设想自己作为一个研究者碰到了这个问题，我们是否能“自然地”想到这个证明或理解方式。




\subsubsection{\large\pmb{定义与证明}}


我希望上述“标准”不至于让读者产生如下误解：学习者首先阅读文本中的定义和定理叙述，然后尝试自己给出证明。如果自己能想到证明，或者在阅读了证明之后能感受到证明思路的“自然而然”，那这个证明便是一个符合直觉的、动机充足的、自然的证明。


恰恰相反，这种误解正是缺乏历史意识的体现。当读者阅读了教材所述的定义和基本设定之后，即便读者能自行想出定理的证明，也不意味着这个定理的陈述和思想是自然而然的。这是因为定义和理论的基本设定常常已经包含了思考相应问题的正确视角和\pmb{语言}。有了正确的视角和语言，找到合适的证明往往水到渠成。而正确语言的诞生往往是最不平凡的，最需要解释的。

另一方面，无法自行想出定理证明也不表明读者的无能。现代数学中，定义往往只是严格呈现一套数学理论所依赖的逻辑起点。但逻辑的起点往往是思想的终点。定义可以没有任何数学直观上的内涵，可以不告诉我们一个概念“究竟说了什么”。类似地，数学证明也可以不“解释”任何本质，不展现任何理解，而只是机械地保证概念之间的推导无误而已。这种定义与内涵的分离，证明与解释的分离，是现代数学的典型特征。数学发展的实际过程，往往是人们已经通过各种直接或间接的证据、通过严格或半严格的推理，相信一些例子满足某些重要的性质。在整合例子、完善理论、推广方法等建立严格现代理论的过程中，人们才找到了能够最经济便捷地证明所需结论的定义。定义和以定义为起点的证明只是最后的理论完善和知识传承而已。

一套现代数学理论中，不止定义和定理证明是后期形成的，正确的视角和语言也是后期形成的。正确的语言和视角能帮助人们有机地结合广泛的例子来相互理解。它们给理解带来的便利会让人极大地低估它们的诞生过程有多么的非凡。例如，现代人早已习惯了以“赋范线性空间”（normed vector space）来思考分析问题，习惯了把收敛性问题转化为空间上的拓扑问题。这让人误以为：仿佛只需想到把线性代数推广到函数上去，只需想到用欧氏空间中的拓扑性质类比到函数空间上去，只需动用每个数学家都擅长的“类比”和“推广”技能，就能发明出合适的语言和观念来简化我们对问题的理解。然而事实是，发端于二十世纪初的分析学现代化的过程，即分析学的“几何化”、“拓扑化”、“代数化”过程，是一场极其伟大却又昙花一现、难以复制的运动。


%而剩下的，不过是在这个语言和框架下动用各种手段解决硬核问题而已。

%由此造成了针锋相对的观点：一方认为正确的语言和观念才是伟大的，剩下的不过是技术性细节；另一方认为语言和观念只是对原问题的简化和改述，却不能消解实质困难，后者只有硬核技术才能做到。这相反的两种观点，无论是对“软数学”的神化还是贬低，其实都是软数学没有被足够祛魅的后果。



\begin{comment}
任何一个经历过前沿数学研究的工作者都会有体会：与教科书中一切都显得自然而然的类比相反，面对一个前沿问题犹如处在森林之中，有无数条“类比”和“推广”的岔路可走，而我们却看不清哪一条路才是正确的路，哪一种推广和类比才有助于解决问题。现代分析中的函数空间观念和拓扑观念早已取代了早期的“有限变量逼近无限变量”、“从离散逼近连续”这些更加朴素的观念。然而，在面对一个崭新的无限维问题时，我们第一个想到的不还是从有限逼近无限吗？现代数学的诸多方向从量子场论中汲取营养，然而至今仍未有一套统一的严格化路径积分（path integral）的方法，面对新的数学物理问题时，我们还得发明新的严格数学方法来对应于物理学家的计算结果。为了找到这个方法，我们还得从物理学家那里吸收养分，去读读他们那不严格的处理路径积分的方法——例如，从有限格点上的函数空间的积分过渡到无限维道路空间上的积分。以此观之，读者或许能略微感受到上世纪初期分析学的“几何化”、“拓扑化”、“代数化”过程是一个多么非凡而伟大的事件。
\end{comment}

\subsubsection{\large\pmb{类比与推广：以矩问题为例}}

每一个我们现在已经习以为常的数学类比、每一个已融入数学基本语言的观点，其诞生的内驱力和内在逻辑都有着独属于数学这门学科的特质。简单地把这一诞生过程归结为人类的艺术想象力，无论是把它平凡化为每个人的基本能力，还是神化为数学天才的专有天赋，都是对数学本身的误解。我想通过两个要点、以及相应的案例分析，来尝试纠正这些误解。
\begin{enumerate}
\item 诚然数学发展的过程中有许多“常规推广”阶段，其中人们沿着\pmb{已被承认价值}的推广方向前进，开启类比机器把理论扩展为庞然大物。但伟大观念的真正非凡的诞生过程会经历一个“反常推广”。其中，人们首先解决了若干重要问题。为了将解决这些问题的方法简化和运用到更复杂的问题上，人们不断地调整对已解决问题的理解方式，由此带来的数学观念变革产生了完全预料不到的类比模式和推广方向。
\end{enumerate}

我以 Hahn-Banach 扩张定理 \ref{lb499} 为例。这个定理告诉我们：一个赋范线性空间$V$的线性子空间 $U$ 上的任意有界线性泛函都能够扩张成为 $V$ 上的有界线性泛函。Hahn-Banach 扩张定理原本是为了解决分析学中的\textbf{矩问题}（moment problem）。大致来说，给定了区间 $[a,b]$ 上的一列函数 $f_1,f_2,\dots$ 和一列数字 $c_1,c_2,\dots$，矩问题想要找到一个函数 $g$, 使得对于任意 $n$ 都有
\begin{align*}
\int f_ng=c_n\qquad\text{或}\qquad \int f_ndg=c_n
\end{align*}
见第 \ref{lb543} 节的讨论。

数学家并非突然灵光乍现，决定类比线性代数中的线性扩张，然后系统地发展出一套理论来严格实现这一类比和推广，最终解决矩问题的。在研究矩问题之前，类比线性扩张的做法没有任何先例，因此人们没有任何理由相信投资这套方法是有成效的，人们甚至不会往这个类比思路去想，哪怕这一思路看起来符合直观。一个类比看似自然、合理、符合直觉，绝不意味着它会是一个成功的类比，因为有成百上千种看似合理但其实无效的类比。数学家不会冒然采纳一个实力未经证明的新视角——数学家在观念变革方面比我们以为的要保守得多。

读者在 \ref{lb543} 节会读到：使 Hahn-Banach 扩张定理诞生的矩问题，其早期是由 F. Riesz 研究，通过有限维逼近无限维的过程，然后运用\pmb{弱(-*)紧性}来解决的。脱胎于矩问题的首个泛函分析一般结论并不是关于有界泛函扩张的 Hahn-Banach 定理，而是关于弱(-*)紧性的 Banach-Alaoglu 定理 \ref{lb519}。早期函数空间的研究方法以紧性占据首位，这部分来源于拥有悠久历史的变分法，其求最大值最小值问题自然地导向了欧氏空间上函数的最值问题。（在后一问题中，空间的紧性是占据首位的性质。）实际上，函数空间的第一个紧性定理，即19世纪末期被证明的 Arzel\`a-Ascoli 定理 \ref{lb516}，便深受变分法影响。Riesz 利用紧性来研究矩问题，这不仅是因为紧性方法和从有限维逼近无限维的朴素思想相容，也是因为紧性方法早已在变分法中证明其成功、其价值无需得到更多辩护。

而只有价值未得到事先辩护的类比和推广，才是真正非凡的类比，才是上述的“反常推广”。我们现在熟悉的“有界泛函扩张”视角，其诞生的过程便是这样一个反常推广：它来源于 Helly 在 1912 年和 1921 年的文章 \cite{Hel12,Hel21} 中简化和推广 Riesz 对矩问题的\pmb{已然成功}的处理、把 Riesz 对$L^p$空间上得到的结果搬到$C([a,b])$甚至一般的赋范线性空间上去时所得到的方法。 Riesz 的文章 \cite{Rie10} 中被简化和取代的部分，恰恰是不能被 Riesz 的紧方法所解释的部分，是 Riesz 的证明过程中最技术性、最“硬”、最依赖于特定函数空间的性质的部分。\footnote{见\cite{Die-H}第6.3节对 \cite{Hel21} 的详细讨论。\cite{Hel12} 的原文很难在网上找到。\cite{BNS84} 引用和英译了 \cite{Hel12}中评价自身与 Riesz 工作之关系的部分段落。}  因此，对 Riesz 方法的改进是促使 Helly 发现有界泛函扩张的一个重要动机。

而另一个重要动机便是 Helly 对凸性的关注。在 \cite{Hel21} 中，有一个保障有界泛函扩张得以实施的关键不等式，它也是 Hahn-Banach 定理之现代证明中的关键不等式。然而，和现代证明不同，Helly 对这一不等式的证明不仅运用了他本人证明过的一个凸集相交定理 \footnote{这一定理说的是：若 $\Rbb^n$ 中的一族（至少 $n+1$ 个）紧凸集满足任意 $n+1$ 个成员的交集非空，则这族凸集的交集非空。见 \cite{BNS84} 和 \cite[节6.3]{Die-H} 的详细讨论。}，也更关键地运用了 Minkowski 的一个关于 $\Rbb^n$ 中凸集和超平面的几何性质、以及 Helly 本人对其在 $\Cbb^n$ 中的推广。\footnote{见 Rem. \ref{mc236} 和 \cite[节6.3]{Die-H}。} 这一几何性质几乎是 \textbf{Hahn-Banach} \pmb{凸集分离定理}的特例。如若读者以为有界线性扩张的观念自然而然、天经地义，那么凸性在有界泛函扩张中起到的关键作用一定会让读者重新审视自己的想当然。



在现代教科书中，有界泛函扩张定理和凸集分离定理是 Hahn-Banach 定理的两个不同却紧密联系的形式。但前者的陈述和证明都完全立足于有界泛函扩张的视角，而和凸集的几何性质完全割裂开来。这致使读者把 Hahn-Banach 扩张定理仅仅看作有限维线性代数中关于对偶空间的结论在无限维函数空间上的直接推广。这一轻巧看法消解了数学家（尤其是 Riesz 和 Helly）为达到这一理解方式所做的努力，也割裂了函数空间的各个重要性质—— Banach-Alaoglu 定理、刻画各种函数空间之对偶空间的表示定理、有界泛函扩张定理、函数空间的凸性等等。但真正的数学创造过程却与此相反：只有具备对概念和性质的整体理解，才能孕育出伟大而非凡的数学新观念。

\begin{comment}

\begin{displayquote}
\small 那么，亲爱的读者，在您读到现代教科书中关于Hahn-Banach定理的应用时，为什么没有想过去用紧性来证明相应的结论呢？为什么就不假思索地接受了教材的权威：这个问题就得用有界泛函扩张的观点来看呢？在您了解了 Riesz、Helly、Hahn、Banach 等伟大数学家的艰苦工作之后，是否还觉得把线性代数中的扩张思想类比到函数空间上去是一种自然而然的想法呢？
\end{displayquote}

\end{comment}


\subsubsection{\large\pmb{数学对象的命名：以} Cauchy \pmb{完备性为例}}

现在我们来谈第二个要点。数学概念的命名是数学语言和观念的产物，而语言和观念是后于具体问题的解决的，所以数学概念的命名也是后于对具体例子的研究的。因此：
\begin{enumerate}
\item[2.] 两个数学对象被同一个名字称呼、被归类到同一个集合名词下，这并不意味着人们首先以同样的角度看待两个对象，然后以此视角进行推理、类比、推广。恰恰相反，人们在对已解决问题的理解、已有理论的简化、研究对象的拓展过程中，捕捉到了处理两个截然不同的数学对象所用方法的些许相似性。通过发展和整合这些方法，孕育出新的概念和语言，使得旧有的不同对象得以囊括其中。数学家从而能够用统一的思想和方法来处理与众不同的对象。新的命名非但不是解决实际问题的起点，反而是人们成功解决许多问题后总结出的答案。
\end{enumerate}


我想以 Banach 空间，即完备的赋范线性空间（complete normed vector space）为例。这里我们不谈赋范线性空间这一概念的历史，而是聚焦于\pmb{完备性}这一分析性质。完备性在处理欧式空间中的级数和积分问题，以及在处理连续函数空间 $C([a,b])$ 上的一致收敛问题时获得了巨大成功。这让现代数学的学习者想当然地接受将“完备性”的概念运用于诸如 $L^p$ 空间之类的空间上。毕竟，$\Rbb^n,C([a,b]),L^p([a,b])$ 这三者同属于 Banach 空间，而 Banach 空间又是现代分析学最基本的概念之一。于是，现代教科书的叙述方式让读者在一开始便熟悉了以同一种视角来看待这三类空间。

\subsubsection*{\pmb{弱紧性与自反性}}


然而，对这三类空间的一视同仁并不是天经地义的。教科书的权威迫使我们接受的这个视角，其实是在历史上慢慢演化而来的。人们并非一开始就意识到函数空间上的完备性有多重要。在函数空间研究的早期，有两个比完备性重要得多的性质：
\begin{enumerate}
\item[(a)] 赋范线性空间单位闭球的弱紧性，即它在弱拓扑（定义\ref{lb901}）下是紧的。
\item[(b)] 赋范线性空间 $V$ 的自反性，即它与二次对偶 $V^{**}$ 之间有标准的同构.
\end{enumerate}
Goldstine 定理 \ref{lb568} 告诉我们二者等价。但二者的用法全然不同。并且，二者都能推出完备性。$L^p$ 空间（以下皆要求 $1<p<+\infty$）满足(a)和(b)，并且这两个性质对于 $L^p$ 空间，尤其是对于和积分方程关系密切的 $L^2,l^2$ 空间（即 \textbf{Hilbert} \pmb{空间}）起到了极其关键的作用。

很遗憾，$C([a,b])$ 是不满足(a)和(b)的最典型的一类 Banach 空间。现在都属于“Banach 空间”这个集合名词的这两类空间，曾经是截然不同，在方法上难以互相借鉴的两类空间。与 Hilbert 空间的现代定义（即完备的内积空间）相反，Hilbert 空间的早期研究很少依赖于完备性，而是更多地依赖于(a)和(b)两条性质。以下两例的详细讨论分别见第\ref{lb672}章、以及第\ref{lb896}和\ref{lb1100}节。
\begin{itemize}
\item 我们现在所熟悉的 $l^2$ 空间\footnote{$l^2(\Zbb)$，其中的元素是满足$\sum_{n\in\Zbb}|a_n|^2<+\infty$的实数列或复数列。}上的有界线性算子，在早期 Hilbert 的研究中是以有界二次型/双线性型出现的。1906年，Hilbert 利用 $l^2$ 空间单位闭球 $B$ 的弱紧性来证明 Hilbert-Schmidt 定理 \ref{lb662}，即\pmb{全连续}（completely continuous）对称二次型的对角化定理。这是因为 Hilbert 是通过对限制在 $B$ 上的二次型求极值这一变分思想来找到特征向量和特征值的。而之所以能求极值，是因为全连续二次型/双线性型的定义（见定义 \ref{lb653}）即是：它限制在 $B$ 上是（关于弱拓扑 ）连续的。弱紧性和全连续，这两个概念配合得天衣无缝。
\item F. Riesz 在1913年的文章 \cite{Rie13} 通过引入了 $l^2$ 空间上的有界线性算子概念来给出 $l^2$ 空间上的有界对称二次型的谱分解定理 \ref{lb895}（即连续版本的对角化定理）。这个对 Hilbert 已有结果的新证明不仅结论更强大，而且引入了大量举足轻重的新观念。Riesz 对谱分解定理的证明几乎没有用到完备性，也没有用到弱紧性。他所用到的关键性质是 Riesz-Fr\'echet 定理 \ref{lb898}，即 $l^2$ 和它的对偶空间 $(l^2)^*$ 之间存在标准的（反）同构。 实际上，起关键作用的只是 $l^2\simeq(l^2)^*$ 所推出的自反性 $(l^2)^{**}\simeq l^2$，即上述性质(b).
\end{itemize}



\subsubsection*{\pmb{自反性实现了算子-双线性型的相互转化}}

我想着重谈谈上面第二个例子，谈谈 Riesz 的这篇非常有趣的文章是如何运用自反性却又几乎完全避开了完备性的。

虽然 Riesz 在证明谱分解定理时没有用到完备性（他在同一篇文章证明别的结论时用了），但是 Riesz 对谱定理的证明却大大加速了完备性成为函数空间首要性质的进程。这是因为他对有界自伴算子 $T$ 引入了极为重要的\pmb{连续函数演算}（continuous functional calculus），即一个从实连续函数代数 $C([a,b],\Rbb)$ 到 $l^2$ 上有界线性算子构成的代数\footnote{更准确地说，是它的一个可交换子代数，其中的元素都是自伴的。}的同态 $f\mapsto f(T)$。



对于 $l^2$ 空间来说，有界线性算子 $T:l^2\rightarrow l^2$ 和有界双线性型 $\omega_T:l^2\times l^2\rightarrow \Rbb$ 是等价的。\footnote{此处我们尊重历史，取数域为 $\Rbb$。讲义正文会与现代教科书一样取数域为 $\Cbb$。此时双线性型应当改为半双线性型（sesquilinear form）。} $T$ 和 $\omega_T$ 的对应方式为：令 $\bk{\cdot,\cdot}$ 为 $l^2$ 上的内积，则对任意 $\xi,\eta\in l^2$ 有
\begin{align*}
\bk{T\xi,\eta}=\omega_T(\xi,\eta)
\end{align*}
然而在历史上，Hilbert 空间的研究范式经历了一个从有界双线性型到有界线性算子的转变。而这一转变必然伴随着完备性登上 Hilbert 空间乃至更一般的函数空间的舞台中央，因为{\color{red}\pmb{完备性和算子观点是共生关系}}。算子观点取代双线性型观点并不只是一个潮流转变，而是有其深刻的理由。其中之一便是：\cite{Rie13} 中引入的连续函数演算，只有在算子观点下才能大展拳脚。


让我以一个例子来说明为何完备性只有在算子观点下才能完全显现。我们需要 $l^2$ 的完备性才能证明：$l^2$ 上所有有界线性算子构成的空间 $\fk L(l^2)$ 在算子范数下是完备的（见定理 \ref{lb540}）。然而，证明所有有界双线性型 $l^2\times l^2\rightarrow\Rbb$ 构成的空间在算子范数（即限制在单位闭球上的一致收敛范数）下完备，这不需要 $l^2$ 的完备性，把 $l^2$ 换成一般的内积空间后结论也成立——这就如同对于不完备的开区间 $(0,1)$ 我们也能证明，$(0,1)$ 上所有有界连续函数构成的空间 $C_b(0,1)$ 在一致收敛范数下完备一样。

Riesz 的 \cite{Rie13} 是历史上算子观点被引入函数空间的极重要的一篇文章，是人们的研究范式从早期 Hilbert 学派的双线性型观点在二三十年后彻底转向算子观点的罪魁祸首之一。并且，这篇文章和我之前提到的 Helly 的工作一样表明了：伟大而深刻的数学观点，其雏形被第一次被引入的过程总是异常小心而保守，并且常常发生在对前人工作的重新诠释和改造的过程中。（Riesz 的谱定理是对 Hilbert 已有结论的改造。）与我们在现代教科书中看到的完全基于算子观点和 Hilbert 空间完备性的谱定理证明不同，Riesz 的证明\pmb{几乎不涉及 $l^2$ 的完备性}。相应的，他对算子观点的运用也极其克制，很多时候宁愿退回到双线性型的观点。

不过，Riesz 在算子观点和双线性型观点之间来回摇摆的保守做法，恰恰是保证谱定理得以证明的关键。因为一旦算子观点转换成了双线性型观点，原本必不可少的 $l^2$ 空间完备性便显得多余——换言之，在现代教科书论述中扮演关键地位的完备性，在 Riesz 的证明中被算子视角和双线性型视角的等价性所替代。而它们的等价又依赖于 $l^2$ 的一个重要性质，即上述性质(b)：$l^2$ 的\pmb{自反性}。一般来说，如果 $V$ 是一个实赋范线性空间，则一个有界线性映射 $T:V\rightarrow V$ 对应了一个有界双线性型 $\omega: V\times V^*\rightarrow \Rbb$；而一个有界双线性型 $\omega: V\times V^*\rightarrow \Rbb$ 只能对应一个有界线性映射 $T:V\rightarrow V^{**}$. 只有当 $V$ 和 $V^{**}$ 有标准的同构时（即当 $V$ 自反时），$\omega$ 才能够对应到 $T:V\rightarrow V$.


\subsubsection*{\pmb{完备性如何成为核心概念}}


我们现代人知道，性质(a)和(b)对于任意赋范空间 $V$ 都等价，且能够推出完备性。并且，当 $V$ 是内积空间时，完备性也能推出(a)和(b)。然而，我不希望读者因此而认为，古人研究 $l^2$ 时对性质(a)和(b)的使用“等价于”对完备性的运用，从而为“Hilbert 空间的内涵便是完备的内积空间”这一充满误解的表述辩护。逻辑上等价的性质可以有完全不同的意义和内涵、完全不同的\pmb{用法}、以及由此带来的完全不同的直觉。无论是 Hilbert 对 Hilbert-Schmidt 定理的证明方法，还是 Riesz 对谱定理的证明方法，都无法直接拿来借鉴和辅助对 $C([a,b])$ 的研究。我们如今用 Banach 空间这一术语来统一看待 $l^2$ 和 $C([a,b])$，导致此现象的决定性事件是 Riesz 在1918年的文章 \cite{Rie18}。



在这篇文章中，Riesz 引入了 $C([a,b])$ 上的\pmb{紧算子}（见定义 \ref{lb675}，它是全连续双线性型的推广），并且对任意紧算子 $T:C([a,b])\rightarrow C([a,b])$ 证明 \textbf{Fredholm} \pmb{二择一}定理（Fredholm alternative）: 对于任意非零的 $\lambda\in\Cbb$，则要么 $\lambda$ 是 $T$ 的特征值（即方程 $\lambda f-Tf=0$ 存在非零解 $f$），要么 $\lambda-T$ 是满射，且二者有且只有一个成立。Fredholm 二择一是积分方程理论中最核心的结论之一，因为它保证了对于一个积分算子 $T:f\mapsto \int_a^b K(x,y)f(y)dy$，只要能验证 $1$ 不是它的特征值（这通常容易做到），则对于任意给定的 $g\in C([a,b])$，积分方程
\begin{align*}
f(x)-\int_a^b K(x,y)f(y)dy=g(x)
\end{align*}
必然存在解 $f\in C([a,b])$.

由于 $C([a,b])$ 不满足性质(a)和(b)，$C([a,b])$ 上的算子无法等价转换为双线性型。所以任何依赖于双线性型观点的证明方法，在 \cite{Rie18} 中都被完全摒弃。\cite{Rie18} 彻底发展了在算子观点下研究函数空间的技术、以及相应的依赖于\pmb{完备性}的技术。实际上，这篇文章中的方法可以几乎原封不动地搬到任意 Banach 空间上去，因此能够同时运用于 $C([a,b])$ 和 $l^2$ 上的紧算子.



我们终于能够回答这个问题：为何要以相同的视角（即完备赋范空间的视角）来看待 $C([a,b])$ 和 $l^2$ 这两个曾经在研究方法上截然不同的空间的？答案是：这两个空间在 Riesz 的文章 \cite{Rie18} 中，在对 Fredholm 二择一定理的证明方法中达到统一。名称的统一是方法之统一的后果，是一套成功方法的胜利宣言。

并且，这一统一更是 $C([a,b])$ 与 $l^2$ 所身负之历史的汇合。Hilbert 空间 $l^2$ 之诞生，恰恰源于 Fredholm 的最初成果启发了 Hilbert 对积分方程的进一步研究。在积分方程中，人们想要找到的解是 $C([a,b])$ 中的元素。而 $l^2$ 是函数的 Fourier 级数所处的空间，是 Hilbert 借助于性质(a)寻找积分方程之解的辅助工具。在 Hilbert 之后二十多年对 $l^2$ 和 $L^2$ 空间的研究，包括 Riesz 在 \cite{Rie13} 中对谱定理的证明，全都暗含对积分方程的关注。\footnote{直到20年代末，von Neumann 受到量子力学启发而开启对抽象 Hilbert 空间及其无界自伴算子谱理论的研究，Hilbert 空间才和现实世界产生了新的联结，才被注入了全新的血液。} 如果说相对于抽象概念和理论而言，具体例子和问题是数学的血肉，那么 $C([a,b])$ 和 $l^2$ 在“Banach 空间”这一集合名词下的统一就不只是抽象概念的统一，更是血与肉的交融。




\subsubsection{\large\pmb{形式的统一}}



但愿上面的分析能让读者略微感受到：数学，这门对一切断言都力求给出严格证明的学科，这门最“以理服人”的学科，在知识传承的过程中可以多么“以权威服人”\footnote{权威对于任何一门科学都未必是坏事。只是，思考科学与权威的关系，可以让我们更好地理解：科学究竟是什么？}——定义无需证明，所以，为何如此定义便可以不加解释。


我相信不是所有读者都能理解我在“完备性”、“有界泛函扩张”等现代人觉得容易接受的观念上较真的做法。这种做法太容易被打上“研读经典”和“学习古人智慧”等散发着老派学究气的标签。对此，我想再给出一些理由来作辩护。


我想许多人在阅读现代数学教材时都有这样的体会：一套方法只要能成功地证明定理，那么无论证明的过程多么技术化和机械性，无论证明的思路在整本教材所授之方法体系中显得多么突兀和孤立，读者都必须强行吞下整个证明过程。而当读者无论如何“事后诸葛亮”地给定义和证明赋予“直观理解”，都无法感受到证明思路的水到渠成，便只能通过一再地误解 von Neumann 那句经典名言来安慰自己——\textit{Young man, in mathematics you don't understand things. You just get used to them.} 然而，我们难以给一些概念和证明赋予直观的动机解释，恰恰是因为我们太轻易地放过了看似易懂的概念。只有看出了概念与概念之间的历史联系，只有理解了看似自然的想法有多么深刻的背景，我们才能明白看似突兀的想法实际上是多么的自然而然。


可为什么非得是“历史”联系呢？历史的数学难道不是过时了的数学吗？数学的发展不应该朝前看吗，为什么要朝后看呢？对此，我想请读者思考如下问题：现代数学对于一个对象或问题的表述和理解方式往往不同于历史。那么现代的数学观念为何会取代曾经的观念呢？是否越现代的数学观念便是越进步的观念——或者说，和古典观念相比，现代观念在何种意义上是更先进的？


我想下面这些理由不难想到：和古典的数学观念相比，现代观念往往更加精炼，删去了无关的技术细节，简化了很多繁琐的计算；现代观念更加触及本质；现代观念更有普遍性，能把与众不同的对象、方法、分支都联系和统一起来。


这些理由需要分别讨论。现代数学确实常常简化了曾经的很多繁琐细节，但并非每一个观念的轮替都是由于这个原因。至于说现代观念更加触及本质，这取决于我们怎么理解数学概念的“本质”。以“未来视角”来看，一个更本质的概念、理论、或者理解方式，其实就是一个更普遍、能够统一更多数学的观念和理解方式。

可一个更具普遍性、更加包罗万象的理解方式就必然胜过一个适用范围更窄的理解方式吗？一个能统一更多数学的理论，如同一台更加强大和万能的机械，能够用于更多的场合。初学者通过学习更具普遍性的现代理论，能够花费更少的成本来更快捷地将已有结论运用在广泛的问题中，能够掌握串联起各种数学对象及其直觉的线索。借助这一线索，对诸多数学主题的思考才不会凌乱。

然而，更具普遍性的现代理论虽然提供了联系诸多直觉的线索和桥梁，却并不会把这些直觉整合为一体。数学中的统一是\pmb{形式的统一}，而不是\pmb{直觉的统一}。很多时候，一个适用范围并不那么普遍的定理或是理论呈现方式，反倒能提供一个更为完整的直觉图像。而在形式上追求过于一般性的定理，在直觉上却是缝补拼凑无法构成整体理解。初学者学习数学时最容易陷入的误区，便是过分追求形式上的一般性，以为学习了更强大的理论自己的数学头脑也会变得更强大。殊不知评价数学工作者的数学能力，所依据的不是他们会用多强大的数学，而是他们有多少非凡的数学创造，能给人们带来多少深刻的新观念。





我想借助对两个案例的细致分析来表明：教科书中对许多现代理论的处理，在追求形式普遍性与统一性的时候，由于缺乏对相应历史脉络的澄清，从而牺牲了直觉。我并不企图表明，人们应当抛弃形式统一性。形式统一是数学有别于其它科学的最典型特征之一，也是数学能在诸多自然科学中发挥巨大威力的根本原因之一。我想要表达的是：直觉是数学创造力的最核心的动力，而历史视角是弥合由形式统一所造成的直观分裂的良药。

\begin{comment}
\subsubsection*{\pmb{案例一：紧算子}}


一个赋范线性空间 $V$ 上的线性算子 $T:V\rightarrow V$ 称为\pmb{紧算子}，若 $V$ 的单位球在 $T$ 下的像有紧闭包。紧算子由 Riesz 在 1918 年的文章 \cite{Rie18} 中引入，是对 Hilbert 1906 年定义的全连续双线性型的二次改造，概因全连续的概念无法适用于非自反（等价地，单位闭球非弱紧）的空间，例如 \cite{Rie18} 中主要考虑的 $C([a,b])$. 

紧算子相比之前的概念是一个全新思想。切不可因其定义中只用到了前人熟悉的紧性概念，便以为紧算子只是对紧性概念的“常规推广”。恰恰想反，紧算子的诞生是“反常推广”的典型。关于紧算子的\pmb{用法和直觉}（这两个词是近义词）完全不同于先前对紧性的各种运用，甚至不同于全连续双线性型于弱紧性在 Hilbert-Schmidt 定理证明过程中的完美搭配，因为后者在变分法和函数求极值的传统中有其根源。


事实上，在 1910 年的文章 \cite{Rie10} 中，Riesz 已经尝试用算子而不是双线性型的观点给出 Hilbert-Schmidt 定理的新证明。为此，Riesz 发明了从全连续双线性型过渡到紧算子的中间产物——全连续算子，大致意为该算子把（有界的）弱收敛序列映射到收敛序列。由于此概念仍旧不适用于非自反空间，在 \cite{Rie18} 中它才被替换成了紧算子。而在 \cite{Rie10} 中已经出现了崭新的基于全连续\pmb{算子}的证明技术，在 \cite{Rie18} 中再次被吸收和激进改造为基于紧算子的证明策略。因此，紧算子是对 $l^2$ 等自反空间和 $C([a,b])$ 等非自反空间上源于积分方程的算子的\pmb{形式统一}。在这种统一中，原本基于变分法和求极值的直觉被孤立甚至抹除。而初学者不知历史渊源地接触紧算子概念，必然会茫然于紧算子之概念的不知所云，和紧算子证明技术里

\end{comment}


\subsubsection{\large\pmb{形式的统一：以} Carath\'eodory \pmb{可测性为例}}





教科书中对于可测集的构造通常可归结于两种方法：正则性方法（内测度法）和 Carath\'eodory 方法。正则性方法只能运用于 Hausdorff 拓扑空间 $X$：它先赋予任意开集 $U$ 一个测度 $\mu$，由此定义任意紧集 $K\subset X$ 上的测度 $\mu(K)=\inf \mu(U)$，其中下确界取遍所有包含 $K$ 的开集 $U$. 最后，一个集合
$E\subset X$ 被成为\pmb{正则}的，若它的外测度 $\mu^*(E)$ 和内测度 $\mu_*(E)$ 相等，其中
\begin{align*}
\mu^*(E)=\inf\{\mu(U):\text{开集 }U\supset E\}\qquad \mu_*(E)=\sup\{\mu(K):\text{紧集 }K\subset E\}
\end{align*}
若 $\mu(X)<+\infty$，则可测集被定义为正则集。若 $\mu(X)=+\infty$，可测集被定义为“局部正则集”。见 \ref{lb726} 节的详细讨论。

概括地来说，正则性方法定义的可测集指的是：从外部可由开集的测度逼近、同时从内部可以由紧集的测度逼近的集合。正则性方法一般适用于构造所谓 Radon 测度。Lebesgue 测度、Stieltjes 积分、流形上微分形式的积分、谱分解定理所涉及测度等分析学中的大部分测度都是 Radon 测度。并且历史上，Lebesgue 建立他的测度理论也是用正则性方法。\footnote{我们上面给出的是正则性方法的现代表述，对内测度的定义与 Lebesgue 原本的定义等价但表述不同。二者的关系见 \ref{lb733} 节的讨论。}

最重要的非 Radon 测度当属 Hausdorff 测度。而 Carath\'eodory 方法诞生于正则性方法之后，比前者适用范围更广，能同时涵盖 Radon 测度和 Hausdorff 测度的构造。Carath\'eodory 方法首先对一个给定集合 $X$（不一定是拓扑空间）的任意子集 $E$ 赋予一个抽象外测度 $\mu^*(E)$ 满足适当的条件。一个集合 $E$ 在 Carath\'eodory 意义下可测，指的是对任意 $A\subset X$ 都有
\begin{align*}
\mu^*(A)=\mu^*(A\cap E)+\mu^*(A\setminus E)
\end{align*}


当今教材较多以 Carath\'eodory 方法建立测度理论。这部分是由于 Carath\'eodory 方法的适用范围更广，但也有偶然或是人为的因素。少数采纳正则性方法的现代教科书，或是局限于 Lebesgue 原本对内测度的并不好用的定义、或是没有做到一般性（例如局限于欧氏空间甚至是有界区间 $[a,b]$）、或是没有突出正则性方法的思想核心而流于验证技术性细节。Rudin 的著名教材 \cite{Rud-R} 便是在使用正则性方法的少数教材中，虽然做到了一般性，却没有在对繁琐步骤的机械验证中指明正则性方法之思想核心的典型例子。前人对正则性方法的整理和精简远远比不上 Carath\'eodory 方法，这更加剧了人们对“正则性方法是落后于 Carath\'eodory 方法的过时方法”的偏见。\footnote{本讲义便是精简正则性方法的一个尝试。见 \ref{lb733} 节。}

无论是哪种方法，构造测度的难点都在于证明所有可测集构成了一个 $\sigma$-代数，以及证明测度在可测集上满足可数可加性（countable additivity）。\uwave{正则性方法的思想核心是}：外测度满足可数次可加性（countable subadditivity），内测度满足可数超可加性（countable superadditivity）。由于外测度和内测度在可测集上相等（并且这个相等的值被定义为可测集的测度），因此测度在可测集上满足可数可加性。


一旦指明了正则性方法的这一思想核心，就可以避免许多机械性验证。这一思想核心本身就在历史上有其渊源：Darboux 积分便是利用 Darboux 上积分满足（有限）次可加性、Darboux 下积分满足超可加性，来证明 Darboux 可积（= Riemann 可积）函数的积分满足可加性/线性性。这套把可测/可积定义为外测度/上积分和内测度/下积分相等的做法是非常普遍的。初学者只需意识到这一历史脉络，便可以在阅读证明细节之前就说服自己：用正则性方法定义的可测集，其关于测度是满足可数可加性的。



实际上，最优美和最直观的理论呈现方式，便是能通过精炼的话语勾勒出思想要点的呈现方式，它使读者在阅读证明中的技术细节之前就能相信结论的正确性。（一些数学家甚至会以此作为一个评判前沿数学论文的标准。）在如此的理论构建中，数学证明接近了它的古典形态——证明真的是“解释”、是“呈现”、是充满修辞力的说服，如同小正方形内接大正方形的勾股定理证明一样直截了当。



Carath\'eodory 理论和正则性方法相反，其关于可测性的直观没有直接的历史传承。Carath\'eodory 条件中最不直观的地方便是等式 $\mu^*(A)=\mu^*(A\cap E)+\mu^*(A\setminus E)$ 对于\pmb{任意}集合 $A$ 成立，而不只是对于好的集合（例如立方体、开集、紧集、Borel集等等）成立。我们无法通过合适的类比或联系，在阅读证明细节之前就相信 Carath\'eodory 可测性是正确的可测性。部分教材通过在 $E\subset A$ 的时候把 $\mu(A)-\mu^*(A\setminus E)$ 类比内测度 $\mu_*(E)$ 来解释 Carath\'eodory 条件的直观，则更是有失重点。其一，即使是对于 Lebesgue 测度而言，当 $A$ 本身不是可测集时 $\mu(A)-\mu^*(A\setminus E)$ 可以不等于 $\mu_*(E)$.（见例 \ref{lb742}. ）其二，Carath\'eodory 方法的强大正是在于它可以处理 Hausdorff 测度等不满足正则性的测度。借助正则性赋予 Carath\'eodory 条件以直观，可谓啼笑皆非。

而 Carath\'eodory 方法的证明过程无补于定义本身的直观缺失，因为它的证明细节恰恰是机械性地验证集合关系，是一种知道答案后的寻找过程。初学者阅读证明过程之后只能慑于逻辑强制力而被迫承认证明的有效，却难以穿透证明细节直达思想核心。Carath\'eodory 方法之突兀来源于它是对正则性方法的激进改造：我们首先意识到正则性方法中的某个推论（即 Carath\'eodory 可测性条件）在诸如 Lebesgue 测度的时候和正则性等价。然而，该推论本身却可以在更一般的设定下陈述。因此，如果我们把这一推论作为推理的起点，便极有希望建立起一个涵盖更广泛例子的理论。

Carath\'eodory 方法是对具有正则性的测度（比如 Radon 测度）和不具有正则性的测度（比如 Haudsdorff 测度）的\pmb{形式统一}。在这个统一中，关于正则性的直觉和历史脉络被抹除。然而正则性又是诸如 Lebesgue 测度的极其关键的性质，联系到了 Lusin定理、连续函数在 $L^p$ 空间中的稠密性、$L^p$ 空间的可分性、Fubini 定理、积分换元公式等一系列测度论中的主要性质。利用 Carath\'eodory 方法获得了测度构造的形式统一，反倒造成和其它大定理之间的直觉断裂。甚至有只谈论 Lebesgue 测度等满足正则性的测度却运用 Carath\'eodory 构造的做法，岂非得不偿失？


\subsubsection{\large\pmb{形式的统一：以} Riesz-Markov \pmb{定理为例}}


\subsubsection*{\pmb{测度论中的两种观念}}


令 $\Rbb_+=[0,+\infty)$. 在测度和积分理论中有两套针锋相对的观念：
\begin{itemize}
\item \pmb{测度}观念：我们首先给一大类集合（即可测集）赋予 $[0,+\infty]$ 中的值，称为该集合的测度。然后我们用测度来定义积分。
\item {\color{red}\pmb{正泛函扩张}}观念\footnote{讲义正文中也把正泛函扩张称为单调收敛扩张（monotone convergence extension）。}：我们以定义在一类函数上的积分为起点。例如，以定义在 $C([a,b],\Rbb_+)$ 上的 Riemann 积分为起点，并把 Riemann 积分抽象地看作\pmb{正}线性泛函 $\Lambda:C([a,b],\Rbb_+)\rightarrow\Rbb_+$. （一般来说，一个线性映射称为“正”的，只要它把一个 $\geq0$ 的函数映射到 $\geq0$ 的元素。） 然后把 $\Lambda$ 扩张到更大的一类函数空间 $\scr L$ 上去。我们把这个扩张后的 $\Lambda$ 看作积分，把特征函数 $\chi_E$ 属于 $\scr L$ 的集合 $E$ 称为可测，并把其测度定义为 $\Lambda(\chi_E)$.
\end{itemize}

关于正（线性）泛函扩张还有两点需要说明。第一，正泛函扩张法对于起始函数空间的选取比较灵活，不必是连续函数空间，也可以是例如 $[a,b]$ 上的阶梯函数（step function）空间（即 $[a,b]$ 的子区间的特征函数所张成的线性空间）。第二，正泛函扩张与之前讨论矩问题和 Hahn-Banach 定理时所提及的有界泛函扩张完全不同。正泛函扩张预先假定的是正性 （positivity），而不假设函数空间上的任何范数。Hahn-Banach 型扩张不仅依赖于范数，而且和函数空间的凸性有紧密联系。在正泛函扩张中起核心作用的不是凸性，而是——如我过会儿会解释的——\pmb{单调收敛定理}。



历史上，测度观念诞生在先，正泛函扩张在后。现今大部分教材会选取二者之一来构建测度理论，且主流教材中以选择测度观念者居多（例如 \cite{Fol-R,Rud-R} 等）。为方便读者对接主流教材，本讲义所选方法以测度观念为主，但不回避必要的正泛函扩张观念，因为它与许多重要的问题联系在一起。测度理论离不开这两个观念中的任意一方。任何只用二者之一来构建测度理论的尝试都会导致直观的分裂。\footnote{另有做法是通过将 $L^1$ 范数下的空间 $C([a,b])$ 完备化来构建测度理论。本导论已对完备性做过详尽的历史分析，故不再对本讲义所持的批判立场做更多解释。} 而这一分裂的重灾区便是 Riesz-Markov 定理的证明。


\subsubsection*{\pmb{被误解的横切函数法}}

彻底贯彻测度观念的做法会导致哪些问题？许多人都听说过 Lebesgue 关于其理论的一个著名的描述：与 Riemann 积分是对函数图像竖着切割相反，Lebesgue 积分是对函数图像横着切。这个方法体现的是纯纯正正的测度观念。与此相反，主流教材（例如 \cite{Fol-R,Rud-R}）对积分的定义方法是\uwave{取正简单函数之积分的上确界，这本质上是正泛函扩张法，而和 Lebesgue 的横切函数法有根本差异}。


很遗憾，许多教材采纳了这一简单函数积分取上确界的方法，却没有意识到它和横切函数法的本质区别，要么强行解释二者如何得以统一，要么干脆不解释二者关联。此乃当今测度论教学之一大未解之谜。教材无论如何无法避开正泛函扩张法，却不能给此方法以名分。于是，这一定义积分的方法便成为了教材中昙花一现的孤立方法。读者无法领会这个方法在数学整体中处于什么位置，可以置入哪个大背景来理解。


通过考察这两个方法如何证明积分的线性性，我们能明显感受出二者的差异。我们假设 Lebesgue 可测集和 Lebesgue 测度 $\mu$ 已然构造。

横切函数法定义积分和证明线性性的步骤如下。取一个有界的 Lebesgue 可测函数 $f:[a,b]\rightarrow\Rbb$. 假设 $-M<f<M$. 我们取 $(-M,M]$ 的一个分划 $\sigma$，即把它写成区间 $I_1=(c_0,c_1],\dots,I_n=(c_{n-1},c_n]$ 的不交并，其中 $-M=c_0<c_1<\cdots<c_n=M$. 则可以定义
\begin{align*}
\ovl S(f,\sigma)=\sum_{i=1}^n c_i\cdot \mu(f^{-1}(I_i))\qquad \udl S(f,\sigma)=\sum_{i=1}^n c_{i-1}\cdot \mu(f^{-1}(I_i))
\end{align*}
当 $\sigma$ 越来越密时，则可用极限定义\pmb{上积分} $\ovl\int fd\mu=\lim_\sigma \ovl S(f,\sigma)$ 与\pmb{下积分} $\udl\int fd\mu=\lim_\sigma \udl S(f,\sigma)$. 易证上下积分相等，这一相等的值称为 $f$ 的积分 $\int fd\mu$. 上积分满足次可加性，而下积分满足超可加性。因此， $f\mapsto \int fd\mu$ 满足可加性，从而（不难验证）满足线性性。

现在我们来描述用正泛函扩张证明积分线性性的步骤。我们先讨论正泛函扩张法的一般流程的\pmb{现代形式}。 取 $X$ 为一空间（例如 $X=[a,b]$）。起始设定如下：假设 $\scr L$ 是一类 $X\rightarrow [0,+\infty]$ 的函数构成的 $\Rbb_+$-线性空间，且 $\scr C$ 是 $\scr L$ 的一个 $\Rbb_+$-线性子空间。假设 $\Lambda:\scr C\rightarrow [0,+\infty]$ 是一个给定的 $\Rbb_+$-线性映射。
\begin{enumerate}
\item 对任意 $f\in\scr L$，定义 $\dps\Lambda(f)=\sup\big\{\Lambda (h):h\in\scr C,h\leq f\big\}$. 
\item 证明\pmb{单调收敛定理}：若 $\scr L$ 中递增序列 $(f_n)$ 逐点收敛到 $f$, 则 $f\in\scr L$，且 $\dps \Lambda(f)=\lim_n\Lambda (f_n)$. \footnote{某些时候，递增序列需要改成递增网。}
\item 证明 $\scr L$ 中的每个函数都能被 $\scr C$ 中的一个递增序列逐点逼近。
\item 利用步骤 2 和 3 以及 $\Lambda$ 在 $\scr C$ 上的 $\Rbb_+$-线性性，证明 $\Lambda$ 在 $\scr L$ 上也是 $\Rbb_+$-线性的。
%\item 利用标准的代数操作，把 $\Lambda$ 扩张成 $\scr C_2:=\Span_\Rbb \scr L$ 上的 $\Rbb$-线性映射 $\Lambda:\scr C_2\rightarrow\Rbb$.
\end{enumerate}
若要用此方法定义 Lebesgue 积分，则 $\scr C$ 取为所有 $[a,b]$ 上的简单函数，即形如 $f=\sum_{i=1}^n a_i\chi_{E_i}$ 的函数，其中 $a_i\geq0$ 且 $E_i\subset [a,b]$ 可测。令 $\scr L$ 为所有可测函数 $[a,b]\rightarrow[0,+\infty]$. 则由公式 $\int f=\sum a_i\mu(E_i)$ 定义的 $\Rbb_+$-线性泛函 $\int:\scr C\rightarrow[0,+\infty]$ 可以按上述方法扩张为 $\Rbb_+$-线性映射 $\int:\scr L\rightarrow[0,+\infty]$. 通过简单的代数处理，便可把积分算子 $\int$ 线性地定义到 Lebesgue 可积函数上去。

这一利用正泛函扩张证明线性性的方法，已然是主流教科书中的通用方法。这是因为，和横切函数法相比，正泛函扩张法不受函数是否有界的限制，也不受大空间之测度是否有限的制约。这一方法看似新奇，其实是以下\pmb{经典形式}的改良版：
\begin{enumerate}[label=(\alph*)]
\item 对任意 $f\in\scr L$，任取 $\scr C$ 中递增序列\footnote{同样，某些情况下需要换成递增网。} $(h_n)$ 逐点收敛到 $f$. 
\item 定义 $\Lambda(f)=\lim_n\Lambda (h_n)$.
\item 证明 $\Lambda(f)$ 的定义与 $(h_n)$ 的选取无关。由此定义的 $\Lambda:\scr L\rightarrow[0,+\infty]$ 显然满足 $\Rbb_+$-线性性。
\end{enumerate}
现代形式中的单调收敛定理，在经典形式中变成了步骤 (c). 


\subsubsection*{\pmb{正泛函扩张法的渊源}}

通过考察历史渊源，我们也能发现这两种方法的巨大差异。横切函数法仍然继承自 Darboux 积分理论中的上积分和下积分思想，借助于次可加和超可加的同时成立来证明线性性。而正泛函扩张法最早于 1910 年由 Young 提出，意在将阶梯函数的 Riemann 积分扩张为一般可积函数上的积分，并且通过避开测度和可测集的概念来说服不容易接受 Lebesgue 理论的老派数学家。\footnote{见 \cite{Pes} 6.6 节，第 98-101 页。} 不久，正泛函扩张法被 Riesz 发扬光大。1913 年， Riesz 在 \cite{Rie13} 中通过将连续函数演算扩张为半连续函数演算（semicontinuous functional calculus）来证明谱定理。1914 年，Riesz 在 \cite{Rie14} 中利用正泛函扩张法给出了 Riesz 表示定理的新证明，大大简化了他于 1911 年在 \cite{Rie11} 中给出的首次详尽证明。

\pmb{Riesz 表示定理}\footnote{实际上，Riesz 原本证明的表示定理是将有界线性泛函 $C([a,b],\Rbb)\rightarrow\Rbb$ 表示为关于有界变差函数的 Stieltjes 积分。我们这里为了便于解释思想，给出的是 Riesz 定理的“正泛函”版本，但它的证明思路的与 Riesz 对原本定理的证明思路基本相同。见 Riesz 和 Sz.-Nagy 的著名教材 \cite{RN} 第 50 节对原定理的讨论。} 说的是：我们能将任意 $\Rbb_+$-线性泛函 $\Lambda:C([a,b],\Rbb_+)\rightarrow\Rbb_+$ 表示为 Stieltjes 积分 $\Lambda(f)=\int fd\rho$，这里 $\rho:[a,b]\rightarrow\Rbb$ 是一个递增函数。证明的关键想法是利用正泛函扩张法，将原本的 $\Lambda$ 扩张到半连续函数以及它们的线性组合上去。特别地，$\Lambda$ 在特征函数 $\chi_{[a,x]}$ 上有定义，故可将单调函数 $\rho$ 定义为
\begin{align*}
\rho(x)=\Lambda(\chi_{[a,x]})
\end{align*}
见 \ref{lb923} 节的讨论。Riesz 的谱定理不过是 Riesz 表示定理的算子/二次型版本。

Riesz 表示定理之所以能成为施展正泛函扩张法的绝佳舞台，是因为该方法的核心——即单调收敛定理——在 Riesz 表示定理的证明中极为具体。不同于 Lebesgue 理论所关注的 Fourier 级数问题涉及复杂的逐点收敛：Riesz 表示定理涉及的逐点收敛，不过是读者可按自身喜好选取的一列连续函数——甚至是一列分段线性函数——逐点递增收敛到给定的阶梯函数。

如果我们把基于正则性构造 Lebesgue 测度、以横切函数法构造积分的这一测度-积分构建法称为经典 Lebesgue 理论，那么可以说：经典 Lebesgue 理论和 Riesz 表示定理分属测度论的两极：
\begin{itemize}
\item 在经典 Lebesgue 理论中，测度本身是基本的，符合人们对长度、面积、体积的直观想象。而函数的逐点收敛模式极为复杂，Fourier 级数为此提供了大量例子。
\item 在 Riesz 表示定理中，测度是抽象的，是对某个抽象泛函的表示。而函数的逐点收敛模式是简单的。
\end{itemize}
所关切之基本例子和问题极为不同，造成了两套理论之内在核心观念的显著差异。\uwave{经典 Lebesgue 理论是本节开头所述之测度观念的典型代表，而 Riesz 表示定理是正泛函扩张观念的典型代表。}它们各自所侧重的视角，恰恰是它们的典型例子中容易为人类直观所企及的部分。\footnote{需要指出的是，虽然以单调收敛定理为核心的正泛函扩张法以 Riesz 表示定理为渊源，但单调收敛定理（Beppo-Levi 定理）的发现本身早于正泛函扩张法和 Riesz 表示定理。} 常见于主流教科书中的现代测度论体系，是对这两种相反取向的整合与\pmb{形式统一}。


\subsubsection*{Riesz-Markov \pmb{定理是形式地统一了两种观念的典型}}


然而，在测度论的教学中，若是没有意识到这两种观念及其历史渊源的根本差异，而是将一方观念之下才可自然解释的例子和定理，强行纳入到基于另一方观念的叙事之中，则必然造成观念的混乱和动机的丧失。\textbf{Riesz-Markov} \pmb{定理}的教学便是这一混乱的典型。该定理一般讨论局部紧 Hausdorff 空间（例如 $\Rbb^n$）。这里我们以紧 Hausdorff 空间 $X$ 为例。该定理说的是：任意 $\Rbb_+$-线性映射 $\Lambda:C(X,\Rbb_+)\rightarrow\Rbb_+$ 可表示为关于某个 Radon 测度 $\mu$ 的积分 $\Lambda (f)=\int_Xfd\mu$.


在定理陈述上，Riesz-Markov 定理对 Riesz 表示定理的推广一目了然。然而，Riesz-Markov 定理的证明思想如何传承了 Riesz 表示定理，对此有所澄清者极少。该定理既推广了 Lebesgue 测度之构造，同时也继承了 Riesz 表示定理的证明中所运用的正泛函扩张法。具体来说：
\begin{enumerate}[label=(\roman*)]
\item 从 $\Lambda$ 出发构造 Radon 测度 $\mu$，此为对 Lebesgue 测度之构造的推广。
\item 对于 $f\in C(X,\Rbb_+)$ 验证 $\Lambda(f)=\int fd\mu$，此乃对 Riesz 表示定理的推广。
\end{enumerate}
二者分别对应了测度观念和正泛函扩张观念。

而一种常见的误解便是：将 Riesz-Markov 定理的证明仅仅理解为对 Lebesgue 测度构造的推广，以为该定理只是一个为我们提供更多测度的工具箱，而正线性泛函 $\Lambda$ 只不过是使用此工具箱的钥匙和线索而已。与此相伴的便是将 $\Lambda(f)=\int fd\mu$ 误解为对“欧氏空间上连续函数的 Riemann 积分等于 Lebesgue 积分”这一命题的推广，却无法解释前者的证明为何会比后者复杂很多。


实际上，对 Riesz-Markov 定理中 $\Lambda(f)=\int fd\mu$ 的验证之所以远远难于对“欧氏空间上连续函数的 Riemann 积分等于 Lebesgue 积分”的证明，是因为 Riemann 积分原本就不止能定义在连续函数上，更能轻而易举地定义在阶梯函数上。此乃 Riemann 积分不能直接与 $\Lambda$ 类比的根本原因。而正是借助于正泛函扩张法把 Riesz-Markov定理中的 $\Lambda$ 扩张到半连续函数上去之后，我们才能得到阶梯函数的对应物。有了此一扩张，验证 $\Lambda(f)=\int fd\mu$ 才能水到渠成。\footnote{详尽的证明可见 \ref{lb833} 和 \ref{mc235} 节。} 

与此相呼应，Riesz 表示定理的证明难点不在于构造递增函数 $\rho$,\footnote{至少对于正泛函版本的 Riesz 表示定理是如此。对于 $C([a,b],\Rbb)$ 上的 Riesz 表示定理，对有界变差函数 $\rho$ 的直接构造（例如 \cite{Rie11} 中的构造）会更麻烦，但也能通过正泛函扩张法得到简化。见 \cite{RN} 第 50 节。}  而是在于验证 $\Lambda(f)=\int fd\rho$. 借助正泛函扩张法，这一验证才会变得流畅自然。正是因为没有意识到这一点，人们才会在验证 Riesz-Markov 定理的公式 $\Lambda(f)=\int fd\mu$ 时身陷强行构造辅助函数和机械验证不等式的局面。证明一旦丧失对思想渊源的合理呈现，读者便会陷入对证明动机的牵强附会。

%Riesz-Markov 表示定理的证明中对 $\Lambda(f)=\int fd\mu$ 的验证与此相对应。当然，在Riesz-Markov 表示定理的证明中，测度 $\mu$ 的构造并不容易。也正是测度构造这一部分，对应的不是经典的 Riesz 表示定理。





\subsubsection{\large\pmb{未来视角}}



我想以本讲义在未来视角方面的些许特色或原则来结束本导论。尽管对历史视角的叙述占据了导论的绝大部分，讲义的正文在绝对篇幅上仍然以未来视角占大多数。这是任何以教学而非历史研究为主要目的的文本所无法避免的。


本讲义在证明的选取上尽量避免采纳孤立思想。一个思想一旦运用于证明中，我们会尽量尝试展现它和其它思想的联系，展现该思想可以运用在哪些别的问题上。例如，本讲义对测度理论的构建，以正则性贯穿各大结论及其证明始终。其它方面的特色，读者通过翻阅目录或概览正文便能体会。这里我仅想讲两点。

其一是对网的使用。网（或者滤子）因其相比序列可以处理不可度量的拓扑空间而闻名。本讲义或许是少数彻底以网的语言建立基础分析体系的教材。实际上，网的优势远超过其在处理不可度量空间上的便捷。下面举出的若干例子皆会在正文中详细展开。
\begin{itemize}
\item 不收敛的序列存在收敛到不同值的子列。不绝对收敛的级数在存在收敛到不同值的重排。这两个现象可以被网的语言统一起来。
\item 有界实数序列收敛当且仅当其上下极限相等。有界函数 Riemann 可积当且仅当它的上下 Darboux 积分相等。网的语言能够统一这两个现象。
\item 在序列的语言下，一致收敛和等度连续是不对称的。一致收敛的连续函数列必然等度连续，而逐点收敛的等度连续函数列只有在底空间是紧致的时候才是一致收敛的。只有在网的语言下，一致收敛和等度连续才是对称概念。
\item 可分 Hilbert 空间可以通过 Gram-Schmidt 正交化来证明关于闭子空间的正交分解。利用网，我们能够对不一定可分的 Hilbert 空间也做到这一点，而无需采用关于子空间取最短距离、结合平行四边形法则的几何方法。
\item 在运用正泛函扩张法证明 Riesz-Markov 定理甚至是 Riesz 表示定理时，网会比序列更容易使用。这部分是因为对于任意下半连续函数 $f$，构造逐点递增收敛到 $f$ 的网要比构造逐点递增收敛的序列来得简单自然。在 Riesz-Markov 定理的证明中，网的方法也给出了从泛函 $\Lambda$ 构造开集测度的自然解释。
\item 对于非下半连续的函数而言，单调收敛定理关于网不成立。类似地，对于非下半连续函数而言， Fubini-Tonelli 定理关于不满足 $\sigma$-有限的测度空间不成立。并且存在例子可以同时被二者解释。网的语言建立了 Fubini-Tonelli 定理中的 $\sigma$-有限条件与其它概念的联系，从而不再是孤立条件。
\end{itemize}


第二点是对等度连续的强调。首先，上面已经提到，借助网的语言，等度连续和一致收敛构成一组对称概念。但更重要的是，人们多以为等度连续这一概念仅出现在 Arzel\`a-Ascoli 定理周围，却不太意识到等度连续与算子范数之间的联系。算子范数概念之强大，很多时候在于它保证了等度连续性。我们有 Banach-Alaoglu 定理这一关于弱-*紧性的定理，本质上便是因为算子范数的条件暗含等度连续。甚至，Riesz 在 \cite{Rie10} 中关于空间 $L^p([a,b])$ 单位闭球之弱紧性（这是 Banach-Alaoglu 定理在 $L^p$ 空间上的情形）的证明竟然是运用 Arzel\`a-Ascoli 定理。对 Riesz 的证明和 Banach-Alaoglu 定理的一般证明稍加对比和澄清，便能意识到等度连续在两者之间同时扮演的关键作用。\\[2ex]


\hfill 2024 年 6 月于北京


\subsubsection*{\large\pmb{致谢}}
本讲义脱胎于作者给清华大学求真书院的本科生教授的两学年分析课程，感谢丘成桐先生创立的求真书院给作者提供的这一教学机会。感谢求真书院的二字班和三字班参与本课程的同学。感谢何会萱、胡致远、秦楷、赵梓博同学，他们的助教工作给作者的教学减轻了很多负担。感谢李颐和欧阳张腾同学在第一学年的 notes taker 工作，他们整理的中文讲义是本讲义的重要参考。感谢陈靖宇、连梓涵、田佳怡、周睿哲同学，以及杨志鹏老师指出的讲义中的错误。读者若有发现讲义中的错误，欢迎联系作者。








\end{CJK}

















\newpage


\subsection{Notations}\label{mc74}
Note: Topics marked with $\star\star$ are technical and/or their methods are rarely used in later studies. Topics marked with $\star$ are interesting, but not necessarily technical or difficult. They are not essential for understanding the rest of the notes. You can skim or skip the starred topics on first reading. When a chapter/section/subsection is starred, it means that all of the material in that chapter/section/subsection is starred.

We use frequently the abbreviations:
\begin{gather*}
\text{iff=if and only if}\\
\text{LHS=left hand side}\qquad
\text{RHS=reft hand side}\\
\text{$\exists$=there exists}\qquad \text{$\forall$=for all}\\
\text{i.e.=id est=that is=namely}\qquad\text{e.g.=for example}\\
\text{cf.=compare/check/see/you are referred to}\\
\text{resp.=respectively}\qquad 
\text{WLOG=without loss of generality}\\
\end{gather*}
If $P,Q$ are properties, then
\begin{align*}
P\land Q=P\text{ and }Q\qquad P\lor Q=P\text{ or }Q\qquad \neg P=\text{ Not }P
\end{align*}
When we write $A:=B$ or $A\xlongequal{\mathrm{def}}B$, we mean that $A$ is defined by the expression $B$. When we write $A\equiv B$, we mean that $A$ are $B$ are different symbols of the same object.

If $\Fbb$ is any field (e.g. $\Qbb,\Rbb,\Cbb$), we let $\Fbb^\times=\Fbb\setminus\{0\}$. \index{F@$\Fbb^\times=\Fbb\setminus\{0\}$} If $\alpha$ is a complex number and $n\in\Nbb$, we define the \textbf{binomial coefficient}\index{zz@$\alpha\choose n$}  \index{00@Binomial coefficient}
\begin{align}
{\alpha\choose n}=\left\{
\begin{array}{ll}
\dps\frac{\alpha\cdot(\alpha-1)\cdots (\alpha-n+1)}{n!} &\text{ if }n\geq 1\\[1ex]
1&\text{ if }n=0
\end{array}
\right.
\end{align}
where $n!=n(n-1)(n-2)\cdots 2\cdot 1$ and $0!=1$. The bold letter $\im$ means \index{i@$\im=\sqrt{-1}$}
\begin{align*}
\im=\sqrt{-1}
\end{align*}
If $z=a+b\im$ where $a,b\in\Rbb$, we let
\begin{align*}
\Real(z)=a\qquad \Imag(z)=b
\end{align*}
If $x,y$ are two elements, we let \index{zz@$\delta_{x,y}$, $\delta_x^y$}
\begin{align}\label{eq154}
\delta_{x,y}=\left\{
\begin{array}{ll}
1&\text{if }x=y\\
0&\text{if }x\neq y
\end{array}
\right.
\end{align}
When studying manifolds, we also write $\delta_{x,y}$ as $\delta_x^y$.

We let $\ovl\Rbb=[-\infty,+\infty]$, $\ovl\Rbb_{\geq0}=[0,+\infty]$, \index{R@$\ovl\Rbb_{\geq0}=[0,+\infty]$} and $\Rbb_{\geq0}=[0,+\infty)$. \index{R@$\Rbb_{\geq0}=[0,+\infty)$} Additions and multiplications in $\ovl\Rbb$ and $\ovl\Rbb_{\geq0}$ are described in Def. \ref{lb114}.

If $f,g:X\rightarrow Y$ where $X$ is a set and $Y$ is a preordered set, we write
\begin{align*}
f\leq g
\end{align*}
whenever $f(x)\leq g(x)$ for all $x\in X$. If $Y$ is a totally ordered set where $a<b$ in $Y$ means $a\leq b$ and $a\neq b$, we write
\begin{align*}
f<g
\end{align*}
whenever $f(x)<g(x)$ for all $x\in X$.

%Topics in the ``Problems" section (or the whole ``Problems" sections) marked with $\heartsuit$ are important problems that will be used later in this course.

If $X$ is a topological space, then $\mc T_X$ denotes the topology of $X$, i.e., the set of open subsets of $X$. \index{TX@$\mc T_X=$ the topology of $X$}

If $f:X\rightarrow V$ where $V$ is a normed vector space, $|f|:X\rightarrow\Rbb_{\geq0}$ denotes its \textbf{absolute value function}, i.e., the one sending each $x\in X$ to $\Vert f(x)\Vert$.

If $A$ is a precompact subset of $B$ (cf. Def. \ref{lb930}), we write
\begin{align*}
A\Subset B
\end{align*}

If $V,W$ are vector spaces over a field $\Fbb$, we \index{V@$V^\vee$} let \index{Lin@$\Lin(V,W),\Lin(V)$} 
\begin{gather*}
\Lin_\Fbb(V,W)\equiv\Lin(V,W)=\{\text{linear maps }V\rightarrow W\}\\
\Lin(V)=\Lin(V,V)\\
V^\vee=\Lin(V,\Fbb)
\end{gather*}
On the other hand, if $\Fbb\in\{\Rbb,\Cbb\}$ and $V,W$ are normed vector spaces over $\Fbb$, we let
\begin{gather*}
\fk L(V,W)=\{\text{bounded linear maps }V\rightarrow W\}\\
\fk L(V)=\fk L(V,V)\qquad
V^*=\fk L(V,\Fbb)
\end{gather*}
Note that $V^\vee=V^*$ if $V$ is a finite dimensional normed vector space over $\Rbb$ or $\Cbb$. Therefore, we also let $V^*$ denote $V^\vee$ if $V$ is a finite dimensional vector space over any field $\Fbb$.

\newpage

\section{Basic set theory and numbers}





In this chapter, we discuss informally some of the basic notions in set theory and basic properties about numbers. A more thorough treatment can be found in \cite[Ch. 1]{Mun} (for set theory) and \cite[Ch. 1]{Rud-P} (for numbers). 





\subsection{Basic operations and axioms}
Intuitively, a set denotes a collection of elements. For instance:\index{N@$\Nbb=\{0,1,2,\dots\}$} \index{Z@$\Zbb_+=\{1,2,\dots\}$}
\begin{gather*}
\Zbb=\{\text{all integers}\}\qquad \Nbb=\Zbb_{\geq0}=\{n\in\Zbb:n\geq0\}\qquad \Zbb_+=\{n\in\Zbb:n>0\}
\end{gather*}
have infinitely many elements. (In this course, we will not be concerned with the rigorous construction of natural numbers and integers from Peano axioms.) We also let
\begin{align*}
\Qbb=\{\text{all rational numbers}\}\qquad\Rbb=\{\text{all real numbers}\}
\end{align*}
if we assume that rational and real numbers exist and satisfy the properties we are familiar with in high school mathematics. (We will construct $\Qbb$ and $\Rbb$ rigorously, by the way.)


Set theory is the foundation of modern mathematics. It consists of several Axioms telling us what we can do about the sets. For example, the following way of describing sets
\begin{align}
\{x: x\text{ satisfies property...}\}  \label{eq1}
\end{align}
is illegal, since it gives \textbf{Russell's paradox}: Consider
\begin{align}
S=\{A: A\text{ is a set and }A\notin A\}\label{eq12}
\end{align}
If $S$ were a set, then $S\in S\Rightarrow S\notin S$ and $S\notin S\Rightarrow S\in S$. This is something every mathematician doesn't want to happen.

Instead, the following way of defining sets is legitimate:
\begin{align}
\{x\in X:x\text{ satisfies property}\dots\}  \label{eq2}
\end{align}
where \textit{$X$ is a given set}.  For instance, we can define the \textbf{difference} of two sets:\index{AB@$A\backslash B$}
\begin{align*}
A\setminus B=A-B=\{x\in A:x\notin B\}
\end{align*}




So let us figure out the legal way of defining unions and intersections of sets. The crucial point is that we assume the following axiom:
\begin{axiom}
If $\scr A$ is a set of sets, then there exists a set $X$ such that $A\subset X$ for all $A\in\scr A$.
\end{axiom}

Thus, if $\scr A$ is a set of sets, let $X$ satisfy $A\subset X$ for all $A\in\scr A$, then we can define the \textbf{union} and the \textbf{intersection} 
\begin{subequations}\label{eq3}
\begin{gather}
\bigcup_{A\in\scr A}A=\{x\in X:\text{there exists $A\in\scr A$ such that $x\in A$}\}\\
\bigcap_{A\in\scr A}A=\{x\in X:\text{for all $A\in\scr A$ we have $x\in A$}\}
\end{gather}
\end{subequations}
It is clear that this definition does not rely on the particular choice of $X$.

\begin{rem}
In many textbooks, it is not uncommon that sets are defined as in \eqref{eq1}. You should interpret such definition as \eqref{eq2}, where the set $X$ is omitted because it is clear from the context. For instance, if the context is clear, the set $\{x\in\Rbb:x\geq 0\}$ could be simply written as $\{x:x\geq0\}$ or even $\{x\geq0\}$. By the same token, the phrase ``$\in X$" in \eqref{eq3} could be omitted. So we can also write
\begin{gather*}
A\cup B=\{x: x\in A\text{ or }x\in B\} \qquad  A\cap B=\{x: x\in A\text{ and }x\in B\}
\end{gather*}
which are special cases of \eqref{eq3}.
\end{rem}


\begin{rem}
In the same spirit, when discussing subsets of a given ``large" set $X$, and if $X$ is clear from the context, we shall write $X\setminus A$ (where $A\subset X$) as $A^c$ \index{Ax@$A^c$, the complement of $A$} and call it the \textbf{complement} of $A$.
\end{rem}


\begin{eg}
We have
\begin{gather*}
\bigcup_{x\in(1,+\infty)}[0,x)=[0,+\infty)\qquad\bigcap_{n\in\Zbb_+}(0,1+1/n)=(0,1]\qquad \bigcup_{n\in\Nbb}(0,1-1/n]=(0,1)
\end{gather*}
The readers may notice that these examples are not exactly in the form \eqref{eq3}. They are actually unions and intersections of indexed families of sets. (See Def. \ref{lb1}.) We need some preparation before discussing this notion.
\end{eg}




\begin{axiom}
If $A_1,\dots,A_n$ are sets, their \textbf{Cartesian product} exists:
\begin{align*}
A_1\times\cdots\times A_n=\{(a_1,\dots,a_n): a_i\in A_i\text{ for all }1\leq i\leq n\}
\end{align*}
where two elements $(a_1,\dots,a_n)$ and $(b_1,\dots,b_n)$ of the Cartesian product are regarded equal iff $a_1=b_1,\dots,a_n=b_n$. We also write
\begin{align*}
(a_1,\dots,a_n)=a_1\times\cdots\times a_n
\end{align*}
especially when $a,b$ are real numbers and $(a,b)$ can mean an open interval. We understand $A_1\times\cdots\times A_n$ as $\emptyset$ if some $A_i$ is $\emptyset$.

If $A_1=\cdots=A_n=A$, we write the Cartesian product as $A^n$. \hfill\qedsymbol
\end{axiom}

\begin{eg}
Assume that the set of real numbers $\Rbb$ exists. Then the set of complex numbers $\Cbb$ \index{C@$\Cbb$, the set of complex numbers} is defined to be $\Rbb^2=\Rbb\times\Rbb$ as a set. We write $(a,b)\in\Cbb$ as $a+b\im$ where $a,b\in\Rbb$. Define
\begin{gather*}
(a+b\im)+(c+d\im)=(a+c)+(b+d)\im\\
(a+b\im)\cdot (c+d\im)=(ac-bd)+(ad+bc)\im
\end{gather*}
Define the zero element $0$ of $\Cbb$ to be $0+0\im$. More generally, we consider $\Rbb$ as a subset of $\Cbb$ by viewing $a\in\Rbb$ as $a+0\im\in\Cbb$. This defines the usual arithmetic of complex numbers. 

If $z=a+b\im$, we define its \textbf{absolute value} $|z|=\sqrt{a^2+b^2}$. Then $z=0$ iff $|z|=0$. We define the \textbf{(complex) conjugate} of $z$ to be $\ovl z=a-b\im$. Then $|z|^2=z\ovl z$.

If $z\neq 0$, then there clearly exists a unique $z^{-1}\in\Cbb$ such that $zz^{-1}=z^{-1}z=1$:  $z^{-1}=|z|^{-2}\cdot \ovl z$. Thus, using the language of modern algebra, $\Cbb$ is a  \textbf{field}.\footnote{See Rem. \ref{lb166} or  \cite[Def. 1.12]{Rud-P} for the definition of fields. Rather than memorizing the full definition of fields, it is more important to keep in mind some typical (counter)examples: $\Qbb,\Rbb,\Cbb$ are fields. $\Zbb$ is not a field, because not every non-zero element of $\Zbb$ has an inverse. The set of quaternions $\{a+b\im+c\mathbf{j}+d\mathbf{k}: a,b,c,d\in\Rbb\}$ is not a field because it is not commutative ($\im\mathbf{j}=-\mathbf{j}\im=\mathbf{k}$). The set of rational functions $P(x)/Q(x)$, where $P,Q$ are polynomials with coefficients in $\Rbb$ and $Q\neq 0$, is a field.}  \hfill\qedsymbol
\end{eg}


The axiom of Cartesian product allows us to define relations and functions:

\begin{df}
If $A,B$ are sets, a subset $R$ of $A\times B$ is called a \textbf{relation}. For $(a,b)\in A\times B$, we write $aRb$ iff $(a,b)\in R$. We understand ``$aRb$" as ``$a$ is related to $b$ through the relation $R$".
\end{df}


\begin{df}\label{lb39}
A relation $f$ of $A,B$  is called a \textbf{function} or a \textbf{map} (or a \textbf{mapping}), if for every $a\in A$ there is a unique $b\in B$ such that $afb$. In this case, we write $b=f(a)$. 

When we write $f:A\rightarrow B$, we always mean that $A,B$ are sets and $f$ is a function from $A$ to $B$. $A$ and $B$ are called respectively the \textbf{domain} and the \textbf{codomain} of $f$. (Sometimes people also use the words ``source" and ``target" to denote $A$ and $B$.) 

If $E\subset A$ and $F\subset B$, we define the \textbf{image under $f$} of $E$  and the \textbf{preimage under $f$} of $F$ to be
\begin{gather*}
f(E)=\{b\in B:\exists a\in E\text{ such that }b=f(a)\}\\
f^{-1}(F)=\{a\in A: f(a)\in F\}.
\end{gather*}
$f(A)$ is simply called the \textbf{image} of $f$, or the \textbf{range} of $f$. If $b\in B$, $f^{-1}(\{b\})$ is often abbreviated to $f^{-1}(b)$. The function \index{f@$f\lvert_E$, the restriction of $f$ to $E$}
\begin{align*}
f|_E:E\rightarrow B\qquad x\mapsto f(x)
\end{align*}
is called the \textbf{restriction}  of $f$ to $E$. \hfill\qedsymbol
\end{df}


The intuition behind the definition of functions is clear: we understand functions as the same as their graphs. So a subset $f$ of the ``coordinate plane" $A\times B$ is the graph of a function iff it ``intersects every vertical line precisely once".


\begin{rem}\label{lb40}
According to our definition, $\emptyset$ (as a subset of $\emptyset\times B$) is the only function from $\emptyset$ to $B$. (A false assumption implies any statement.) If $A\neq\emptyset$, there are no functions $A\rightarrow\emptyset$.
\end{rem}


\begin{df}\label{lb13}
A function $x:\Zbb_+\rightarrow A$ is called a \textbf{sequence in $A$}. We write $x(n)$ as $x_n$, and write this sequence as $(x_n)_{n\in\Zbb_+}$ (or simply $(x_n)_n$ or $(x_n)$).
\end{df}

Many people write such a sequence as $\{x_n\}_{n\in\Zbb_+}$. We do not use this notation, since it can be confused with $\{x_n: n\in\Zbb_+\}$ (the range of the function $x$).



\begin{axiom}
If $X$ is a set, then the \textbf{power set} \index{00@Power set $2^X$} $2^X$ exists, where
\begin{align*}
2^X=\{\text{Subsets of }X\}
\end{align*}
\end{axiom}

\begin{eg}
The set $2^{\{1,2,3\}}$ has $8$ elements: $\emptyset$, $\{1\}$, $\{2\}$, $\{3\}$, $\{1,2\}$, $\{1,3\}$, $\{2,3\}$, $\{1,2,3\}$. Surprisingly, $8=2^3$. As we shall see in Exp. \ref{lb11} and Cor. \ref{lb12}, this relationship holds more generally, which explains the terminology $2^X$.  
\end{eg}

Now we are ready to define indexed families of sets.
\begin{df}\label{lb1}
An \textbf{indexed family of sets} \index{00@Indexed family of sets}  $(S_i)_{i\in I}$ is defined to be a function $S:I\rightarrow 2^X$ for some sets $I,X$. We write $S(i)$ as $S_i$. (So $S_i$ is a subset of $X$.) $I$ is called the \textbf{index set}. Define
\begin{align*}
\bigcup_{i\in I}S_i= \bigcup_{T\in S(I)}T\qquad \bigcap_{i\in I}S_i= \bigcap_{T\in S(I)}T
\end{align*}
Note that $S(I)$ is the image of the function $S$.
\end{df}


\begin{eg}
In the union $\bigcup_{x\in(1,+\infty)}[0,x)$, the index set is $I=(1,+\infty)$, and $X$ can be the set of real numbers $\Rbb$. Then $S:I\rightarrow 2^X$ is defined to be $S_i=S(i)=[0,i)$.
\end{eg}




\begin{exe}\label{lb5}
Let $f:A\rightarrow B$ be a function. We say that $f$ is \textbf{injective} if for all $a_1,a_2\in A$ satisfying $a_1\neq a_2$ we have $f(a_1)\neq f(a_2)$. We say that $f$ is \textbf{surjective} if for each $b\in B$ we have $f^{-1}(b)\neq\emptyset$. $f$ is called \textbf{bijective} if it is both surjective and bijective. Define the \textbf{identity maps} $\id_A:A\rightarrow A,a\mapsto a$ \index{id@$\id_A$} and $\id_B$ in a similar way. Prove that
\begin{subequations}
\begin{gather}
\text{$f$ is injective $\Longleftrightarrow$ there is $g:B\rightarrow A$ such that $g\circ f=\id_A$}\label{eq4}\\
\text{$f$ is surjective $\Longleftrightarrow$ there is $g:B\rightarrow A$ such that $f\circ g=\id_B$}\label{eq5}\\
\text{$f$ is bijective $\Longleftrightarrow$ there is $g:B\rightarrow A$ such that $g\circ f=\id_A$ and $f\circ g=\id_B$}\label{eq6}
\end{gather}
\end{subequations}
Show that the $g$ in \eqref{eq4} (resp. \eqref{eq5}, \eqref{eq6}) is surjective (resp. injective, bijective).
\end{exe}


The equivalence \eqref{eq5} is subtler, since its proof requires Axiom of Choice.


\begin{axiom}
Let $(S_i)_{i\in I}$ be an indexed family of sets. The \textbf{Axiom of Choice} asserts that if $S_i\neq\emptyset$ for all $i\in I$, then there exists a function (the \textbf{choice function})
\begin{align*}
f:I\rightarrow \bigcup_{i\in I}S_i
\end{align*}
such that $f(i)\in S_i$ for each $i\in I$.
\end{axiom}


Intuitively, the axiom of choice says that for each $i\in I$ we can choose an element $f(i)$ of $S_i$. And such choice gives a function $f$.


\begin{eg}
Let $f:A\rightarrow B$ be surjective. Then each member of the family $(f^{-1}(b))_{b\in B}$ is nonempty. Thus, by axiom of choice, there is a choice function $g$ defined on the index set $B$ such that $g(b)\in f^{-1}(b)$ for each $b$. Clearly $f\circ g=\id_B$.
\end{eg}



\begin{rem}
Suppose that each member $S_i$ of the family $(S_i)_{i\in I}$ has exactly one element. Then the existence of a choice function does not require Axiom of Choice: Let $X=\bigcup_{i\in I}S_i$ and define relation
\begin{align*}
f=\{(i,x)\in I\times X: x\in S_i\}
\end{align*}
Then one checks easily that this relation between $I$ and $X$ is a function, and that it is the (necessarily unique) choice function of $(S_i)_{i\in I}$.
\end{rem}

According to the above remark, one does not need Axiom of Choice to prove \eqref{eq4} and \eqref{eq6}. Can you see why?


\subsection{Partial and total orders, equivalence relations}\label{lb299}

\begin{df}
Let $A$ be a set. A \textbf{partial order} (or simply an \textbf{order}) $\leq$ on $A$ is a relation on $A\times A$ satisfying for all $a,b,c\in A$ that:
\begin{itemize}
\item (Reflexivity) $a\leq a$.
\item (Antisymmetry) If $a\leq b$ and $b\leq a$ then $a=b$.
\item (Transitivity) If $a\leq b$ and $b\leq c$ then $a\leq c$.
\end{itemize}
We write $b\geq a$ iff $a\leq b$. Write $a>b$ iff $a\geq b$ and $a\neq b$. Write $a<b$ iff $b>a$. So $\geq$ is also an order on $A$. The pair $(A,\leq)$ is called a \textbf{partially ordered set}, or simply a \textbf{poset}. \index{00@Poset=partially ordered set} A partial order $\leq$ on $A$ is called a \textbf{total order}, if for every $a,b\in A$ we have either $a\leq b$ or $b\leq a$.
\end{df}


\begin{eg}
The following are examples of orders.
\begin{itemize}
\item Assume that $\Rbb$ exists. Then $\Rbb$ has the canonical total order, which restricts to the total order of $\Zbb$. This is the total order that everyone is familiar with.
\item Let $X$ be a set. Then $(2^X,\subset)$ is a poset.
\item $\Rbb^2$ is a poset, if we define $(a,b)\leq (c,d)$ to be $a\leq c$ and $b\leq d$. 
\end{itemize}
\end{eg}


\begin{df}\label{lb156}
A relation $\sim$ on a set $A$ is called an \textbf{equivalence relation}, \index{00@Equivalence relation} if for all $a,b,c\in A$ we have
\begin{itemize}
\item (Reflexivity) $a\sim a$.
\item (Symmetry) $a\sim b$ iff $b\sim a$.
\item (Transitivity) If $a\sim b$ and $b\sim c$ then $a\sim c$.
\end{itemize}
\end{df}

Later, we will use the notions of partial orders and equivalence relation not just for a set, but for a collection of objects ``larger" than a set. See Sec. \ref{lb4}.

\begin{df}\label{lb157}
Let $A$ be a set, together with an equivalence relation $\sim$. Define a new set
\begin{align*}
{A/\sim}=\{[a]: a\in A\}
\end{align*}
where the notion $[a]$ can be understood in the following two equivalent ways (we leave it to the readers to check the equivalence):
\begin{itemize}
\item[(1)] $[a]$ is a new symbol. We understand $[a]$ and $[b]$ as equal iff $a\sim b$.
\item[(2)] $[a]=\{x\in A: x\sim a \}$
\end{itemize}
We call $[a]$ the \textbf{equivalence class} (or the \textbf{residue class}) of $a$, and call $A/\sim$ the \textbf{quotient set} \index{00@Quotient sets} of $A$ under $\sim$. The surjective map $\pi:a\in A\mapsto [a]\in {A/\sim}$ is called the \textbf{quotient map}.
\end{df}


\begin{exe}
Prove that every surjective map  is equivalent to a quotient map. More precisely, prove that for every surjection $f:A\rightarrow B$, there is an equivalence relation $\sim$ on $A$ and a bijective map $\Phi:{A/\sim}\rightarrow B$ such that the following diagram commutes (i.e. $f=\Phi\circ\pi$):
\begin{equation}\label{eq7}
\begin{tikzcd}[column sep=small]
                          & A \arrow[rd, "f"] \arrow[ld, "\pi"'] &   \\
{A/\sim} \arrow[rr, "\Phi"] &                                      & B
\end{tikzcd}
\end{equation}
\end{exe}


This is the first time we see commutative diagrams. Commutative diagrams are very useful for indicating that certain maps between sets are ``equivalent" or are satisfying some more general relations. For example, \eqref{eq7} shows that the maps $f$ and $\pi$ are equivalent, and that this equivalence is implemented by the bijection $\Phi$. The formal definition of commutative diagrams is the following:


\begin{df}
A diagram (i.e. some sets denoted by symbols, and some maps denoted by arrows) is called a \textbf{commutative diagram}, \index{00@Commutative diagram} if all directed paths in the diagram with the same start and endpoints lead to the same result.
\end{df}


Here is an example of commutative diagram in linear algebra. This example assumes some familiarity with the basic properties of vector spaces \index{00@Vector spaces} and linear maps.\footnote{Again, we refer the readers to Internet or any Linear Algebra textbook (e.g. \cite{Axl}) for the definition of vector spaces and linear maps.}


\begin{eg}\label{lb67}
Let $V,W$ be vector spaces over a field $\Fbb$ with finite dimensions $m,n$ respectively. Let $e_1,\dots,e_m$ be a basis of $V$, and let $\eps_1,\dots,\eps_n$ be a basis of $W$. We know that there are unique linear isomorphisms $\Phi:\Fbb^m\xrightarrow{\simeq} V$ and $\Psi:\Fbb^n\xrightarrow{\simeq} W$ such that
\begin{align*}
\Phi(a_1,\dots,a_m)=a_1e_1+\cdots+a_me_m\qquad \Psi(b_1,\dots,b_n)=b_1\eps_1+\cdots+b_n\eps_n
\end{align*}
Let $T:V\rightarrow W$ be a \index{00@Linear maps} \textbf{linear map}, i.e., a map satisfying $T(a\xi+b\eta)=aT\xi+bT\eta$ for all $a,b\in\Fbb,\xi,\eta\in V$. Then there is a unique $n\times m$ matrix $A\in\Fbb^{n\times m}$ \index{Fnm@$\Fbb^{n\times m}$, the set of $n\times m$ matrices} (viewed as a linear map $\Fbb^m\rightarrow\Fbb^n$ defined by matrix multiplication) such that the following diagram commutes:
\begin{equation}
\begin{tikzcd}
\Fbb^m \arrow[r,"\Phi","\simeq"'] \arrow[d,"A"'] & V \arrow[d,"T"] \\
\Fbb^n \arrow[r,"\Psi","\simeq"']           & W          
\end{tikzcd}
\end{equation} 
namely, $T\Phi=\Psi A$. This commutative diagram tells us that $T$ is equivalent to its \textbf{matrix representation} \index{00@Matrix representation} $A$ under the bases $e_\blt,\eps_\star$, and that this equivalence is implemented by the linear isomorphisms $\Phi$ (on the sources) and $\Psi$ (on the targets). 
\end{eg}

Commutative diagrams are ubiquitous in mathematics. You should learn how to read commutative diagrams and understand their intuitive meanings. We will see more examples in the future of this course.



\subsection{$\Qbb$, $\Rbb$, and $\overline{\mathbb R}=[-\infty,+\infty]$}



Using equivalence classes, one can construct rational numbers from integers, and real numbers from rationals. We leave the latter construction to the future, and discuss the construction of rationals here.

\begin{eg}[Construction of $\Qbb$ from $\Zbb$]\label{lb17}
Define a relation on $\Zbb\times\Zbb^\times$ (where $\Zbb^\times=\Zbb\setminus\{0\}$) as follows. If $(a,b),(a',b')\in\Zbb\times\Zbb^\times$, we say $(a,b)\sim(a',b')$ iff $ab'=a'b$. It is a routine check that $\sim$ is an equivalence relation. Let \index{Q@$\Qbb$, the field of rational numbers}  $\Qbb=(\Zbb\times\Zbb^\times)/\sim$, and write the equivalence class of $(a,b)$ as $a/b$ or $\frac ab$. Define additions and multiplications in $\Qbb$ to be
\begin{align*}
\frac ab+\frac cd=\frac{ad+bc}{bd}\qquad \frac ab\cdot\frac cd=\frac{ac}{bd}
\end{align*}
We leave it to the readers to check that this definition is \index{00@Well defined} \textbf{well-defined}: If $(a,b)\sim(a',b')$ and $(c,d)\sim(c',d')$ then $(ad+bc,bd)\sim(a'd'+b'c',b'd')$ and $(ac,bd)\sim(a'c',b'd')$.

We regard $\Zbb$ as a subset of $\Qbb$ by identifying $n\in\Zbb$ with $\frac n1$. (This is possible since the map $n\in\Zbb\mapsto \frac n1\in\Qbb$ is injective.) Each $a/b\in\Qbb$ has additive inverse $\frac{-a}b$. If $a/b\in\Qbb$ is not zero (i.e. $(a,b)\nsim (0,1)$), then $a/b$ has multiplicative inverse $b/a$. This makes $\Qbb$ a field: the field of \textbf{rational numbers}.

If $a/b\in\Qbb$, we say $a/b\geq 0$ if $ab\geq0$. Check that this is well-defined (i.e., if $(a,b)\sim(a',b')$, then $ab\geq0$ iff $a'b'\geq0$). More generally, if $a/b,c/d\in\Qbb$, we say $\frac ab\geq \frac cd$ if $\frac ab-\frac cd\geq0$. Check that $\geq$ is a total order on $\Qbb$.  Check that $\Qbb$ is an Archimedean ordered field, defined below.\hfill\qedsymbol
\end{eg}


\begin{df}\label{lb161}
A field $\Fbb$, together with a total order $\leq$, is called an \index{00@Ordered field} \textbf{ordered field}, if for every $a,b,c\in\Fbb$ we have
\begin{itemize}
\item (Addition preserves $\leq$) If $a\leq b$ then $a+c\leq b+c$.
\item (Multiplication by $\Fbb_{\geq0}$ preserves $\geq0$) If $a,b\geq 0$ then $ab\geq0$.
\end{itemize}
These two properties relate $\leq$ to $+$ and $\cdot$ respectively.
\end{df}

\begin{rem}
Many familiar properties about inequalities in $\Qbb$ hold for an ordered field. For instance: 
\begin{gather*}
a\geq b~\wedge~ c\geq d \qquad\Longrightarrow\qquad a+c\geq b+d\\
a\geq0\qquad\Longleftrightarrow\qquad -a\leq0\\
a\geq0~\wedge~b\geq c\qquad\Longleftrightarrow\qquad ab\geq ac\\
a\leq0~\wedge~b\geq c\qquad\Longleftrightarrow\qquad ab\leq a\\
a^2\geq0\\
0<a\leq b\qquad\Longrightarrow\qquad 0< b^{-1}\leq a^{-1}
\end{gather*}
Check them yourself, or see \cite[Prop. 1.18]{Rud-P}.
\end{rem}


\begin{df}
We say that an ordered field $\Fbb$ satisfies \index{00@Archimedean property} \textbf{Archimedean property} if for each $a,b\in\Fbb$ we have
\begin{align*}
a> 0\qquad\Longrightarrow \qquad\exists n\in\Nbb\text{ such that }na>b
\end{align*}
where $na$ means $\underbrace{a+\cdots+a}_{n}$.
\end{df}

\begin{eg}
$\Qbb$ satisfies Archimedean property. Indeed, let $a,b\in\Qbb$ and $a>0$. Then $a=p/q$ and $b=r/s$ where $p,q,s\in\Zbb_+$ and $r\in\Zbb$. So $na>b$ where $n=q|r|+q$.
\end{eg}



Prop. \ref{lb2} gives an important application of Archimedian property. We will use this in the construction of $\Rbb$ from $\Qbb$, and in the proof that $\Qbb$ is dense in $\Rbb$. 

\begin{df}
Let $\Fbb$ be a field. A subset $\Ebb\subset\Fbb$ is called a  \textbf{subfield} \index{00@Subfield} of $\Fbb$, if $\Ebb$ contains the $1$ of $\Fbb$, and if $\Ebb$ is closed under the operations of addition, multiplication, taking negative, and taking inverse in $\Fbb$ (i.e. if $a,b\in\Ebb$ then $a+b,ab,-a\in\Ebb$, and $a^{-1}\in\Ebb$ whenever $a\neq 0$). We also call $\Fbb$ a \index{00@Field extension} \textbf{field extension} of $\Ebb$, since $\Ebb$ is clearly a field.
\end{df}

Note that if $\Ebb$ is a subfield of $\Fbb$, the $0$ of $\Fbb$ is in $\Ebb$ since $0=1+(-1)\in\Ebb$.

\begin{df}
Let $\Ebb$ be an ordered field. A field extension $\Fbb$ of $\Ebb$ is called an \index{00@Ordered field extension=ordered subfield} \textbf{ordered field extension}, if $\Fbb$ is equipped with a total order $\leq$ such that $\Fbb$ is an ordered field, and if the order $\leq$ of $\Fbb$ restricts to that of $\Ebb$. We also call $\Ebb$ an \textbf{ordered subfield} of $\Fbb$.
\end{df}

Our typical example of ordered field extension will be $\Qbb\subset\Rbb$.

\begin{pp}\label{lb2}
Let $\Fbb$ be an ordered field extension  of $\Qbb$. Assume that $\Fbb$ is Archimedean. Then for every $x,y\in\Fbb$ satisfying $x<y$, there exists $p\in\Qbb$ such that $x<p<y$.
\end{pp}

\begin{proof}
Assume $x,y\in\Fbb$ and $x<y$. Then $y-x>0$ (since $y-x\neq 0$ and $-x+x\leq -x+y$). By Archimedean property, there exists $n\in\Zbb_+$ such that $n(y-x)>1$. So $\displaystyle y-x>\frac 1n$ and hence $\displaystyle x+\frac 1n<y$.

Let us prove that the subset
\begin{equation*}
A=\big\{k\in\Zbb: \frac {~k~}{n}\leq x\big\}
\end{equation*}
is nonempty and bounded from above in $\Zbb$. By Archimedean property, there is $m\in\Zbb_+$ such that $m>nx$, i.e. $\displaystyle \frac mn>x$. So for each $k\in\Zbb_+$ satisfying $k\geq m$, we have $\displaystyle \frac kn=\frac mn+\frac{k-m}n>x$. Therefore, for each $k\in A$ we have $k<m$. So $A$ is bounded above. By Archimedean property again, there is $l\in\Zbb_+$ such that $\displaystyle \frac ln>-x$. So $\displaystyle -\frac ln<x$, and hence $A$ is nonempty.

We now use the fact that \textit{every nonempty subset of $\Zbb$ bounded above has a maximal element}. Let $k=\max A$. Since $k+1\notin A$, we have $\displaystyle x<\frac{k+1}n$. Since $\displaystyle \frac kn\leq x$, we have
\begin{align*}
\frac{k+1}n=\frac kn+\frac 1n\leq x+\frac 1n<y
\end{align*}
This proves $x<p<y$ with $\displaystyle p=\frac{k+1}n$.
\end{proof}

To introduce $\Rbb$ formally, we need more definitions:

\begin{df}
Let $(X,\leq)$ be a poset and $E\subset X$. An \textbf{upper bound of $E$ in $X$} \index{00@Upper bound} is an element $x\in X$ satisfying $e\leq x$ for all $e\in E$. An upper bound $x\in X$ of $E$ is called a \textbf{least upper bound} or a \textbf{supremum} \index{00@Supremum}  if $x\leq y$ for every upper bound $y\in Y$ of $E$. In this case, we write the supremum as \index{sup@$\sup E$} $\sup E$. It is not hard to check that supremums are unique if they exist.

We leave it to the readers to define \textbf{lower bounds} and the \textbf{greatest lower bound} (if exists) of $E$, also called the \textbf{infimum} \index{00@Infimum} and is denoted by \index{inf@$\inf E$} $\inf E$. \hfill\qedsymbol
\end{df}


\begin{df}
Let $(X,\leq)$ be a poset. We say that $X$ satisfies the \textbf{least-upper-bound property}, if every every nonempty subset $E\subset X$ which is bounded above (i.e. $E$ has an upper bound) has a supremum in $X$. The \textbf{greatest-lower-bound property} is defined in the opposite way.
\end{df}

\begin{eg}
$\Zbb$ satisfies the least-upper-bound and the greatest-lower-bound property: Let $A\subset \Zbb$. If $A$ is bounded above (resp. below), then the maximum $\max A$ (resp. minimum $\min A$) exists and is the supremum (resp. infimum) of $A$.
\end{eg}

\begin{eg}
Let $X$ be a set. Then $(2^X,\subset)$ satisfies the least-upper-bound and the greatest-lower-bound property: Let $\scr A\subset 2^X$, i.e., $\scr A$ is a set of subsets of $X$. Then $\scr A$ is bounded from above by $X$, and is bounded from below by $\emptyset$. Moreover,
\begin{align*}
\sup\scr A=\bigcup_{A\in\scr A}A\qquad \inf\scr A=\bigcap_{A\in\scr A}A
\end{align*}
\end{eg}





\begin{thm}\label{lb3}
There is an ordered field extension of $\Qbb$ which is Archimedian and satisfies the least-upper-bound property. This field is denoted by  $\Rbb$. Its elements are called \index{00@Real number} \textbf{real numbers}.
\end{thm}

Thm. \ref{lb3} will be proved in Ch. \ref{lb167}. Note that by taking negative, we see that $\Rbb$ also satisfies the greatest-lower-bound property.


\begin{rem}
The ordered field extensions satisfying the conditions in Thm. \ref{lb3} are unique ``up to isomorphisms". (The words ``\textbf{isomorphism}"\index{00@Isomorphism}  and ``equivalence" are often interchangeable, though ``isomorphism" is more often used in the algebraic setting, whereas ``equivalence" can be used in almost every context. For example, in point-set topology, ``equivalence" means ``homeomorphism".) We leave it to the readers to give the precise statement. We will not use this uniqueness in this course. 

Note that to compare two extensions $\Fbb,\Rbb$ of $\Qbb$, it is very confusing to regard $\Qbb$ as a subset of both $\Fbb$ and $\Rbb$. You'd better consider two different injective maps $\tau:\Qbb\rightarrow \Fbb$ and $\iota:\Qbb\rightarrow\Rbb$ preserving the algebraic operations and the order of $\Qbb$, and use a commutative diagram to indicate that $\tau$ and $\iota$ are equivalent. (Thus, what's happening here is that we have an equivalence of maps, not just an equivalence of the fields $\Fbb$ and $\Rbb$.) \hfill\qedsymbol
\end{rem}


\begin{df}\label{lb114}
Let $-\infty,+\infty$ be two different symbols, and extend the total order $\leq$ of $\Rbb$ to the \textbf{extended real line}\index{R@$\ovl\Rbb=[-\infty,+\infty]=\Rbb\cup\{-\infty,+\infty\}$}
\begin{align*}
\ovl\Rbb=\Rbb\cup\{-\infty,+\infty\}
\end{align*}
by letting $-\infty<x<+\infty$ for all $x\in\Rbb$. Define for each $x\in\Rbb$ that
\begin{gather*}
x\pm\infty=\pm\infty+x=\pm\infty\qquad +\infty-(-\infty)=+\infty\\
x\cdot(\pm\infty)=\pm\infty\cdot x=\left\{
\begin{array}{cc}
\pm\infty&\text{if }x>0\\
0&\text{if }x=0\\
\mp\infty&\text{if }x<0
\end{array}
\right.\\
\frac x{\pm\infty}=0\\
\frac{\pm\infty}{x}=x^{-1}\cdot(\pm\infty)\qquad \text{if }x\neq0
\end{gather*}
If $a,b\in\ovl\Rbb$ and $a\leq b$, we define \textbf{intervals} \index{00@Interval} with endpoints \index{00@Endpoints of an interval} $a,b$:
\begin{gather}\label{eq8}
\begin{gathered}
[a,b]=\{x\in\ovl\Rbb:a\leq x\leq b\}\qquad (a,b)=\{x\in\ovl\Rbb:a< x< b\}\\
(a,b]=\{x\in\ovl\Rbb:a< x\leq b\}\qquad [a,b)=\{x\in\ovl\Rbb:a\leq x< b\}
\end{gathered}
\end{gather}
So $\Rbb=(-\infty,+\infty)$ and $\ovl\Rbb=[-\infty,+\infty]$. If $a,b$ are in $\Rbb$, we say that the corresponding interval is \textbf{bounded}. \index{00@Bounded interval}
\end{df}

In this course, unless otherwise stated, an interval always means one of the four sets in \eqref{eq8}. The first two intervals are called respectively a \textbf{closed interval} and an \textbf{open interval}.


\begin{rem}
Clearly, every subset $E$ of $\ovl\Rbb$ is bounded and has a supremum and an infimum. We have that $\sup E=+\infty$ iff $E$ is not bounded above in $\Rbb$, and that $\inf E=-\infty$ iff $E$ is not bounded below in $\Rbb$. 
\end{rem}


\subsection{Cardinalities, countable sets, and product spaces $Y^X$}\label{lb4}


\begin{df}
Let $A$ and $B$ be sets. We say that $A$ and $B$ have the same \textbf{cardinality} \index{00@Cardinality $\card(A)$} and write $\card(A)=\card(B)$ (or simply $A\approx B$), if there is a bijection $f:A\rightarrow B$. We write $\card(A)\leq\card(B)$ (or simply $A\precsim B$) if $A$ and a subset of $B$ have the same cardinality. 
\end{df}



\begin{exe}\label{lb9}
Show that $\card(A)\leq\card(B)$ iff there is an injection $f:A\rightarrow B$, iff there is a surjection $g:B\rightarrow A$. (You need either Axiom of Choice or its consequence \eqref{eq5} to prove the last equivalence.)
\end{exe}

It is clear that $\approx$ is an equivalence relation on the collection of sets. It is also true that $\precsim$ is a partial order: Reflexivity and transitivity are easy to show. The proof of antisymmetry is more involved:



\begin{thm}[Schr\"oder-Bernstein]\label{lb8}\index{00@Schr\"oder-Bernstein theorem}
Let $A,B$ be two sets. If $A\precsim B$ and $B\precsim A$, then $A\approx B$.
\end{thm}

\begin{proof}[$\star\star$ Proof]
Assume WLOG that $A\subset B$. Let $f:B\rightarrow A$ be an injection. Let $A_n=f^n(A)$ defined inductively by $f^0(A)=A$, $f^n(A)=f(f^{n-1}(A))$. Let $B_n=f^n(B)$. Then
\begin{align*}
B_0\supset A_0\supset \cdots\supset B_n\supset A_n\supset B_{n+1}\supset\cdots
\end{align*}
In particular, $C=\bigcap_{n\in\Nbb}A_n$ equals $\bigcap_{n\in\Nbb}B_n$. Note that $f$ gives a bijection $B_n\setminus A_n\rightarrow B_{n+1}\setminus A_{n+1}$ (since $f$ gives bijections $B_n\rightarrow B_{n+1}$ and $A_n\rightarrow A_{n+1}$). Therefore, we have a bijection $g:B\rightarrow A$ defined by
\begin{gather*}
g(x)=\left\{
{\begin{array}{ll}
f(x)&\text{if $x\in B_n\setminus A_n$ for some $n\in\Nbb$}\\[0.5ex]
x&\text{otherwise}
\end{array}}
\right.
\end{gather*}
where ``otherwise" means either $x\in C$ or $x\in A_n\setminus B_{n+1}$ for some $n$.
\end{proof}

Intuition about the above proof: View $B$ as an onion. The layers of $B$ are $B_n\setminus A_n$ (the odd layers) and $A_n\setminus B_{n+1}$ (the even layers). The bijection $g$ maps each odder layer to the subsequent odd one, and fixes the even layers and the core $C$.


\begin{eg}\label{lb6}
If $-\infty<a<b<+\infty$, then $(0,1)\approx (a,b)$.
\end{eg}
\begin{proof}
$f:(0,1)\rightarrow (a,b)$ sending $x$ to $(b-a)x+a$ is a bijection.
\end{proof}

\begin{eg}\label{lb7}
If $-\infty<a<b<+\infty$, then $\Rbb\approx (a,b)$
\end{eg}

\begin{proof}
By the previous example, it suffices to prove $\Rbb\approx(-1,1)$. The function
\begin{gather}\label{eq20}
f:\Rbb\rightarrow(-1,1)\qquad f(x)=\left\{
\begin{array}{ll}
\frac x{1+x}&\text{ if $x\geq0$}\\[0.5ex]
-f(-x)&\text{ if $x<0$}
\end{array}
\right.
\end{gather}
is bijective.
\end{proof}


Alternatively, one may use the tangent function to give a bijection between $(-\pi/2,\pi/2)$ and $\Rbb$. I have avoided this method, since \eqref{eq20} is more elementary than trigonometric functions. The mathematically rigorous definition of trigonometric functions and the verification of their well-known properties are far from easy tasks. 



\begin{pp}
Let $I$ be an interval with endpoints $a<b$ in $\ovl\Rbb$. Then $I\approx\Rbb$.
\end{pp}

\begin{proof}
Let $A=(0,1)\cup\{-\infty,+\infty\}$. By Exp.  \ref{lb7}, we have
\begin{align*}
(a,b)\subset I\precsim \ovl\Rbb\approx A\approx[0,1]\subset (-2,2)\approx (a,b)
\end{align*}
So $I\approx\ovl\Rbb$ by Schr\"oder-Bernstein Thm. \ref{lb8}. In particular, $\Rbb=(-\infty,+\infty)\approx\ovl\Rbb$.
\end{proof}


\begin{df}
A set $A$ is called \textbf{finite} if $A\precsim\{1,\dots,n\}$ for some $n\in\Zbb_+$. $A$ is called  \textbf{countable} if $A\precsim\Nbb$. \index{00@Countable}
\end{df}

Clearly, a set $A$ is finite iff either $A\approx\emptyset$ or $A\approx\{1,\dots,n\}$ for some $n\in\Zbb_+$.

\begin{rem}
Let $A\subset\Nbb$. If $A$ is bounded above, then $A\subset\{0,\dots,n\}$ and hence $A$ is finite. If $A$ is not bounded above, then we can construct a strictly increasing sequence $(x_n)_{n\in\Nbb}$ in $A$. (Pick any $x_0\in A$. Suppose we have $x_n\in A$. Since $x_n$ is not an upper bounded of $A$, there is $x_{n+1}\in A$ larger than $x_n$. So $(x_n)_{n\in\Nbb}$ can be constructed inductively.) This gives an injection $\Nbb\rightarrow A$. Therefore $A\succsim \Nbb$, and hence $A\approx \Nbb$ by Schr\"oder-Bernstein.

It follows that if $B\precsim\Nbb$, then either $B$ is a finite set, or $B\approx\Nbb$. Therefore, ``a set $B$ is \textbf{countably infinite}" \index{00@Countably infinite} means the same as ``$B\approx\Nbb$".  \hfill\qedsymbol 
\end{rem}


\begin{thm}\label{lb15}
A countable union of countable sets is countable. In particular, $\Nbb\times\Nbb\approx\Nbb$.
\end{thm}

\begin{proof}
Recall Exe. \ref{lb9}. Let $A_1,A_2,\dots$ be countable sets. Since each $A_i$ is countable, there is a surjection $f_i:\Nbb\rightarrow A_i$. Thus, the map $f:\Nbb\times\Nbb\rightarrow \bigcup_i A_i$ defined by $f(i,j)=f_i(j)$ is surjective. Therefore, it suffices to show that there is a surjection $\Nbb\rightarrow\Nbb\times\Nbb$. This is true, since we have a bijection $g:\Nbb\rightarrow\Nbb\times\Nbb$ where $g(0),g(1),g(2),\dots$ are $(0,0)$, $(1,0)$, $(0,1)$, $(2,0)$, $(1,1)$, $(0,2)$, $(3,0)$, $(2,1)$, $(1,2)$, $(0,3)$, etc., as shown by the figure
\begin{align*}
\vcenter{\hbox{{
			\includegraphics[width=3.5cm]{fig1.png}}}}
\end{align*}
\end{proof}

As an application, we prove the extremely important fact that $\Qbb$ is countable.
\begin{co}
We have $\Nbb\approx\Zbb_+\approx\Zbb\approx \Qbb$.
\end{co}



\begin{proof}
Clearly $\Zbb_{<0}\approx\Nbb\approx \Zbb_+$. By Thm. \ref{lb15}, $\Zbb=\Zbb_{<0}\cup\Nbb$ is countably infinite, and hence $\Zbb\approx\Nbb$. It remains to prove $\Zbb\approx\Qbb$. By Schr\"oder-Bernstein, it suffices to prove $\Qbb\precsim\Zbb$.  By Thm. \ref{lb15} again, $\Zbb\times\Zbb\approx\Zbb$. By Exp. \ref{lb17}, there is a surjection from a subset of $\Zbb\times\Zbb$ to $\Qbb$. So $\Qbb\precsim\Zbb\times\Zbb\approx\Zbb$.
\end{proof}



Later, when we have learned Zorn's Lemma (an equivalent form of Axiom of Choice), we will be able to prove the following generalization of $\Nbb\times\Nbb\approx\Nbb$. So we defer the proof of the following theorem to a later section.

\begin{thm}\label{lb16}
Let $X$ be a infinite set. Then $X\times\Nbb\approx X$.
\end{thm}

\begin{proof}
See Thm. \ref{lb497}.
\end{proof}



Our next goal is to prove an exponential law $a^{b+c}=a^b\cdot a^c$ for cardinalities. For that purpose, we first need to define the set-theoretic operations that correspond to the summation $b+c$ and the exponential $a^b$.


\begin{df}
We write $X=\bigsqcup_{\alpha\in\scr A}A_\alpha$ \index{zz@$\bigsqcup_{\alpha\in\scr A}A_\alpha$, the disjoint union} and call $X$ the \textbf{disjoint union} \index{00@Disjoint union} of $(A_\alpha)_{\alpha\in\scr A}$,  if $X=\bigcup_{\alpha\in\scr A}A_\alpha$ and $(A_\alpha)_{\alpha\in\scr A}$ is a family of pairwise disjoint sets (i.e. $A_\alpha\cap A_\beta=\emptyset$ if $\alpha\neq\beta$). If moreover $\scr A=\{1,\dots,n\}$, we write $X=A_1\sqcup\cdots\sqcup A_n$.
\end{df}

\begin{df}
Let $X,Y$ be sets. Then \index{YX@$Y^X$, the set of functions $X\rightarrow Y$}
\begin{align}
Y^X=\{\text{functions }f:X\rightarrow Y\}
\end{align}
A more precise definition of $Y^X$ (in the spirit of \eqref{eq2}) is $\{f\in X\times Y \mid f:X\rightarrow Y\text{ is a function}\}$. Note that by Rem. \ref{lb40},
\begin{align}
Y^\emptyset=\{\emptyset\}  \label{eq10}
\end{align}
\end{df}

This new notation is compatible with the old one $Y^n=Y\times\cdots\times Y$:
\begin{eg}
Let $n\in\Zbb_+$. We have $Y^{\{1,\dots,n\}}\approx Y^n$ due to the bijection
\begin{align*}
Y^{\{1,\dots,n\}}\rightarrow Y^n\qquad f\mapsto (f(1),\dots,f(n))
\end{align*}
\end{eg}

\begin{rem}\label{lb18}
The above example suggests that in the general case that $X$ is not necessarily finite, we can view each function $f:X\rightarrow Y$ as $(f(x))_{x\in X}$, an \textbf{indexed family of elements} of $Y$ with index set $X$. Thus, intuitively and hence not quite rigorously, 
\begin{align}
Y^X=\underbrace{Y\times Y\times\cdots}_{\card(X)\text{ pieces}} \label{eq11}
\end{align}
This generalizes the intuition in Def. \ref{lb13} that a function $f:\Zbb_+\rightarrow Y$ is equivalently a sequence $(f(1),f(2),f(3),\dots)$.

The viewpoint that $Y^X$ is a \textbf{product space} with index set $X$ is very important and will be adopted frequently in this course. More generally, we can define:\hfill\qedsymbol
\end{rem}

\begin{df}
Let $(X_i)_{i\in I}$ be a family of sets with index set $I$. Their \textbf{product space} \index{00@Product space} \index{zz@$\prod_{i\in I}X_i$} is defined by
\begin{align*}
\prod_{i\in I}X_i =\{f\in \fk X^I:f(i)\in X_i\text{ for all }i\in I \}
\end{align*}
where $\fk X=\bigcup_{i\in I}X_i$. If each $X_i$ is nonempty, then $\prod_{i\in I}X_i$ is nonempty by Axiom of Choice. An element of $\prod_{i\in I}X_i$ is also written as $(f_i)_{i\in I}$ when the $i$-th component of it is $f_i\in X_i$.
\end{df}

In particular, if all $X_i$ are equal to $X$, then $X^I=\prod_{i\in I}X$.



\begin{eg}\label{lb11}
Let $X$ be a set. For each $A\subset X$, define the \textbf{characteristic function} \index{00@Characteristic function} \index{zz@$\chi_A$, the characteristic function of $A$} $\chi_A:X\rightarrow\{0,1\}$ to be
\begin{align*}
\chi_A(x)=\left\{
\begin{array}{ll}
1&\text{if }x\in A\\
0&\text{if }x\notin A
\end{array}
\right.
\end{align*}
Then we have
\begin{align*}
2^X\approx \{0,1\}^X
\end{align*}
since the following map is bijective:
\begin{gather*}
2^X\rightarrow\{0,1\}^X\qquad A\mapsto\chi_A
\end{gather*}
Its inverse is $f\in\{0,1\}^X\mapsto f^{-1}(1)\in 2^X$.
\end{eg}

\begin{pp}[Exponential Law]\label{lb10}
Suppose that $X=A_1\sqcup\cdots\sqcup A_n$. Then
\begin{align*}
Y^X\approx Y^{A_1}\times \cdots\times Y^{A_n}
\end{align*}
\end{pp}

\begin{proof}
We have a bijection
\begin{gather}\label{eq9}
\begin{gathered}
\Phi:Y^X\rightarrow Y^{A_1}\times \cdots\times Y^{A_n}\\
f\mapsto (f|_{A_1},\dots,f|_{A_n})
\end{gathered}
\end{gather}
where we recall that $f|_{A_i}$ is the restriction of $f$ to $A_i$. 
\end{proof}

\begin{exe}
Assume that $A_1,\dots,A_n$ are subsets of $X$. Define $\Phi$ by \eqref{eq9}. Prove that $\Phi$ is injective iff $X=A_1\cup\cdots\cup A_n$. Prove that $\Phi$ is surjective iff $A_1,\dots, A_n$ are pairwise disjoint. 
\end{exe}

\begin{co}\label{lb12}
Let $X,Y$ be finite sets with cardinalities $m,n\in\Nbb$ respectively. Assume that $Y\neq\emptyset$. Then $Y^X$ is a finite set with cardinality $n^m$.
\end{co}

\begin{proof}
The special case that $m=0$ (i.e. $X=\emptyset$, cf. \eqref{eq10}) and $m=1$ is clear. When $m>1$, assume WLOG that $X=\{1,\dots,m\}$. Then $X=\{1\}\sqcup\cdots\sqcup\{m\}$. Apply Prop. \ref{lb10} to this disjoint union. We see that $Y^X\simeq Y\times \cdots\times Y\simeq\{1,\dots,n\}^m$ has $n^m$ elements.
\end{proof}



We end this section with some (in)equalities about the cardinalities of product spaces. To begin with, we write $X\precnsim Y$ (or $\card(X)<\card(Y)$) if $X\precsim Y$ and $X\napprox Y$.

\begin{pp}\label{lb14}
Let $X,Y$ be sets with $\card(Y)\geq 2$ (i.e. $Y$ has at least two elements). Then $X\precnsim Y^X$. In particular, $X\precnsim 2^X$.
\end{pp}

\begin{proof}
The case $X=\emptyset$ is obvious since $0<1$. So we assume $Y\neq\emptyset$. Clearly $2^X\simeq\{0,1\}^X$ is $\precsim Y^X$. So it suffices to prove $X\precnsim 2^X$. Since the map $X\rightarrow 2^X$ sending $x$ to $\{x\}$ is injective, $X\precsim 2^X$. Let us prove $X\napprox 2^X$.

Assume that $X\approx 2^X$. So there is a bijection $\Phi:X\rightarrow 2^X$ sending each $x\in X$ to a subset $\Phi(x)$ of $X$. Motivated by Russell's Paradox \eqref{eq12}, we define
\begin{align*}
S=\{x\in X:x\notin \Phi(x)\}
\end{align*}
Since $\Phi$ is surjective, there exists $y\in X$ such that $S=\Phi(y)$. If $y\in\Phi(y)$, then $y\in S$, and hence $y\notin \Phi(y)$ by the definition of $S$. If $y\notin\Phi(y)$, then $y\notin S$, and hence $y\in\Phi(y)$ by the definition of $S$. This gives a contradiction.
\end{proof}


\begin{rem}
Write $\{1,\dots,n\}^X$ as $n^X$ for short. \index{nX@$n^X=\{1,\dots,n\}^X$} Assuming that real numbers have decimal, binary, or (more generally) base-$n$ representations where $n\in\Zbb_{\geq 2}$, then  $\Rbb\approx n^{\Nbb}$. So by Prop. \ref{lb14}, $\Nbb\precnsim\Rbb$, i.e. \textit{$\Rbb$ is uncountable}. The base-$n$ representations of real numbers suggest that $\card(n^\Nbb)$ is independent of $n$. This fact can be proved by elementary methods without  resorting to the analysis of real numbers:
\end{rem}

\begin{thm}
Let $X$ be an infinite set. Then
\begin{align*}
2^X\approx 3^X\approx 4^X\approx\cdots\approx \Nbb^X
\end{align*}
\end{thm}

\begin{proof}
First, we assume that $X=\Nbb$. Clearly, for each $n\in\Zbb_{\geq 2}$ we have $2^X\precsim n^X\precsim \Nbb^X$. Since elements of $\Nbb^X$ are subsets of $X\times\Nbb$ (i.e. elements of $2^{X\times\Nbb}$), we have
\begin{align*}
\Nbb^X\subset 2^{X\times\Nbb}\simeq 2^X
\end{align*}
since $X\times\Nbb\approx X$ by Thm. \ref{lb15}. So $2^X\approx n^X\approx \Nbb^X$ by Schr\"oder-Bernstein.

As pointed out earlier (cf. Thm. \ref{lb16}), it can be proved by Zorn's Lemma that $X\times\Nbb\approx X$ for every infinite set $X$. So the same conclusion holds for such $X$.
\end{proof}

\newpage

\section{Metric spaces}


We first give an informal introduction to metric spaces, hoping to motivate the readers from a (relatively) historical perspective. It is okay if you do not understand all of the concepts mentioned in the introduction on the first read. Simply return to this section when you feel unmotivated while formally studying these concepts in later sections. (The same suggestion applies to all the introductory sections and historical comments in our notes.)









\subsection{Introduction: what is point-set topology?}\label{lb55}


\begin{displayquote}
\small The method which has been used with success by Volterra and Hilbert consists in observing that a function (for instance a continuous one) can be replaced by a countable infinity of parameters. One treats the problem first as though one had only a finite number of parameters and then one goes to the limit... We believe that this method has played a useful role because it followed intuition, but that its time has passed... The most fruitful method in functional analysis seems to us to treat the element of which the functional depends directly as a variable and in the form in which it presents itself naturally.

\hfill ---- Fr\'echet, 1925 ~~(cf. \cite[Sec. 13.8]{Jah})
\end{displayquote}




In this chapter, we begin the study of point-set topology by learning one of its most important notions: metric spaces. Similar to \cite{Rud-P}, we prefer to introduce metric spaces and basic point-set topology at the early stage of our study. An obvious reason for doing so is that metric spaces provide a uniform language for the study of basic analysis problems in $\Rbb,\Rbb^n,\Cbb^n$, and more generally in function spaces such as the space of continuous functions $C([a,b])$ on the interval $[a,b]\subset\Rbb$. With the help of such a language, for example, many useful criteria for the convergence of series in $\Rbb$ and $\Cbb$ (e.g. root test, ratio test) are generalized straightforwardly to criteria for the \textit{uniform} convergence of series of functions in $C([a,b])$.

Point-set topology was born in 1906 when Fr\'echet defined metric spaces, motivated mainly by the study of function spaces in analysis (i.e. \textit{functional analysis}). Indeed, point-set topology and functional analysis are the two sides of the same coin: they both originated from the study of \textbf{functionals}, \index{00@Functionals} i.e., functions of functions. See for example \eqref{eq24}. The core ideas of point-set topology are as follows:
\begin{enumerate}[label=(\arabic*)]
\item Take $X$ to be a set of functions defined on a ``classical space" (e.g. the set of all continuous functions $f:[a,b]\rightarrow\Cbb$). Then a functional is a function  $S:X\rightarrow \Cbb$. This is a generalization of functions on $\Rbb,\Cbb,\Rbb^n,\Cbb^n$ or on their subsets.
\item Unlike $\Rbb^n$, a function space $X$ is usually ``infinite dimensional". Thus, one may think that a functional $S$ is a function with infinite variables. In point-set topology, this viewpoint is abandoned; the philosophy of point-set topology is diametrically opposed to that of multivariable calculus.\footnote{Very often, the formula of $S(f)$ involves an integral. See e.g. \eqref{eq24}. Mathematicians (e.g. Volterra, L\'evy, Fredholm, and early Hilbert) used to study $S(f)$ by discretizing $S(f)$, i.e., by approximating integrals by finite sums. Thus, $S$ is approximated by a sequence of functions with $n$ variables where $n\rightarrow\infty$. This viewpoint is abandoned in point-set topology.} Instead, \uline{one should view a functional $S$ as a function with one variable $x$}, where $x$ denotes a general point of the function space $X$.
\item Rather than looking at each variable/component and doing explicit muti-variable calculations, one uses geometric intuitions to study the analytic properties of functionals.\footnote{This is similar to linear algebra where one prefers vectors, linear subspaces, and linear operators to $n$-tuples, sets of solutions, and matrices.} \uline{These geometric intuitions (e.g. distances, open balls, convergence) are borrowed from  $\Rbb$ and $\Rbb^n$}  and are mostly irrelevant to dimensions or numbers of variables.
\end{enumerate}



(Sequential) \textbf{compactness}, \textbf{completeness}, and \textbf{separability} are prominent geometric properties that are useful in the study of the analytic properties of functionals. The importance of these three notions  was  already recognized by Fr\'echet by the time he defined metric spaces. The study of these three properties will be a main theme of our course.


Consider sequential compactness for example. The application of compactness to function spaces originated from the problems in calculus of variations. For instance, let $L(x,y,z)$ be a polynomial or (more generally) a continuous function in $3$ variables. We want to find a ``good" (e.g. differentiable) function $f:[0,1]\rightarrow \Rbb$ minimizing or maximizing the expression
\begin{subequations}\label{eq24}
\begin{align}
S(f)=\int_0^1 L(t,f(t),f'(t))dt
\end{align}
This is the general setting of Lagrangian mechanics. In the theory of integral equations, one considers the extreme values and points of the functional
\begin{align}
S(f)=\int_0^1\int_0^1 f(x)K(x,y)\ovl{f(y)}dxdy  \label{eq206}
\end{align}
\end{subequations}
where $K:[0,1]^2\rightarrow\Rbb$ is continuous and $f:[0,1]\rightarrow\Cbb$ is subject to the condition $\int_0^1 |f(x)|^2dx\leq 1$. Any $f$ maximizing (resp. minimizing) $S(f)$ is an eigenvector of the linear operator $g\mapsto \int_0^1 K(x,y)g(y)dy$ with maximal (resp. minimal) eigenvalue.


As we shall learn, (sequential) compactness is closely related to the problem of finding (or proving the existence of) maximal/minimal values of a continuous function and the points at which the function attains its maximum/minimum. So, in 19th century, when people were already familiar with sequential compactness in $\Rbb^n$ (e.g. Bolzano-Weierstrass theorem, Heine-Borel theorem), they applied compactness to function spaces and functionals. The idea is simple: Suppose we are given $X$, a set of functions (say continuous and differentiable) from $[a,b]$ to $\Rbb$. We want to find $f\in X$ maximizing $S(f)$. Here is an explicit process (see also the proof of Lem. \ref{lb56}):
\begin{itemize}
\item[(A)] Find a sequence $(f_n)_{n\in\Zbb_+}$ in $X$ such that $S(f_n)$ increases to $M=\sup S(X)$. 
\item[(B)] Define convergence in $X$ in a suitable way, and verify that $S:X\rightarrow\Rbb$ is continuous (i.e. if $f_n$ converges to $f$ in the way we define, then $S(f_n)\rightarrow S(f)$). 
\item[(C)] Suppose we can find a subsequence $(f_{n_k})_{k\in\Zbb_+}$ converging to some $f\in X$, then $S$ attains its maximum at $f$. In particular, $S(f)=M$ and hence $M<+\infty$. 
\end{itemize}


To carry out step (B), we need to define suitable geometric structures for a function space $X$ so that the convergence of sequences in $X$ and the continuity of functions $S:X\rightarrow\Rbb$ can be defined and studied in a similar pattern as that for $\Rbb^n$. \textbf{Metric} (of a metric space) and \textbf{topology} (of a topological space) are such geometric structures. As we shall learn, the topology of a metric space is uniquely determined by the convergence of sequences in this space. 

Step (C) can be carried out if every sequence in $X$ has a convergent subsequent, i.e., if $X$ is sequentially compact. Thus, we need a good criterion for sequential compactness for subsets of a function space.  Arzel\`a-Ascoli theorem, the  $C([a,b])$-version of Heine-Borel theorem, is such a criterion. This famous theorem was proved in late 19th century (and hence before the birth of point-set topology), and it gave an important motivation for Fr\'echet to consider  metric spaces in general. We will learn this theorem at the end of the first semester.


To summarize: Metric spaces are defined not just for fun. We introduce such geometric objects because we want to study the convergence of sequences and the analytic properties of continuous functions using geometric intuitions. And moreover, the examples we are interested in are not just subsets of $\Rbb^n$, but also subsets of function spaces. With this in mind, we now begin our journey into point-set topology.


\subsection{Basic definitions and examples}



\begin{df}
Let $X$ be a set. A function $d:X\times X\rightarrow\Rbb_{\geq0}$ is called a \textbf{metric} if for all $x,y,z\in X$ we have
\begin{enumerate}[label=(\arabic*)]
\item $d(x,y)=d(y,x)$.
\item $d(x,y)=0$ iff $x=y$.
\item (Triangle inequality) \index{00@Triangle inequality} $d(x,z)\leq d(x,y)+d(y,z)$.
\end{enumerate}
The pair $(X,d)$, or simply $X$, is called \index{00@Metric space} a \textbf{metric space}. If $x\in X$ and $r\in(0,+\infty]$,\footnote{We want open and closed balls to be nonempty. So we assume $r\neq0$ only for open balls.} the set \index{Br@$B_X(x,r)=B(x,r)$ and $\ovl B_X(x,r)=\ovl B(x,r)$}
\begin{align*}
B_X(x,r)=\{y\in X:d(x,y)<r\}
\end{align*}
often abbreviated to $B(x,r)$, is called the \textbf{open ball} with center $x$ and radius $r$. If $r\in[0,+\infty)$,
\begin{align*}
\ovl B_X(x,r)=\{y\in X:d(x,y)\leq r\}
\end{align*}
also abbreviated to $\ovl B(x,r)$, is called the \textbf{closed ball} with center $x$ and radius $r$.
\end{df}


We make some comments on this definition.


\begin{rem}
That ``$d(x,y)=0$ iff $x=y$" is very useful. Think about $X$ as a set of functions $[0,1]\rightarrow\Rbb$ and $d$ is a metric on $X$. To show that $f,g\in X$ are equal, instead of checking that infinitely many values are equal (i.e. $f(t)=g(t)$ for all $t\in\Rbb$), it suffices to check that one value (i.e. $d(f,g)$) is zero.
\end{rem}

\begin{rem}
Triangle inequality clearly implies ``polygon inequality":
\begin{align}
d(x_0,x_n)\leq\sum_{j=1}^n d(x_{j-1},x_j)
\end{align}
\end{rem}

\begin{rem}\label{lb20}
Choose distinct points $x,y\in X$. Then $x,y$ are separated by two open balls centered at them: there exists $r,\rho>0$ such that $B(x,r)\cap B(y,\rho)=\emptyset$. This is called the \textbf{Hausdorff property}. 

To see this fact, note that $d(x,y)>0$. Choose $r,\rho$ such that $r+\rho\leq d(x,y)$. If $z\in B(x,r)\cap B(y,\rho)$, then $d(x,z)+d(y,z)<r+\rho\leq d(x,y)$, contradicting triangle inequality.

We will see (cf. Prop. \ref{lb21}) that Hausdorff property guarantees that any sequence in a metric space cannot converge to two different points. Intuition: one cannot find a point which is very close to $x$ and $y$ at the same time.  \hfill\qedsymbol
\end{rem}



We give some examples, and leave it to the readers to check that they satisfy the definition of metric spaces. We assume that square roots of positive real numbers can be defined. (We will rigorously define square roots after we define $e^x$ using the series $\sum_{n\in\Nbb}x^n/n!$.)


\begin{eg}
$\Rbb$ is a metric space if we define $d(x,y)=|x-y|$
\end{eg}


\begin{eg}
On $\Rbb^n$, we can define \textbf{Euclidean metric} \index{00@Euclidean metric}
\begin{align*}
d(x,y)=\sqrt{(x_1-y_1)^2+\cdots+(x_n-y_n)^2}
\end{align*}
if $x_\blt,y_\blt$ are the components of $x,y$. The following are also metrics:
\begin{gather*}
d_1(x,y)=|x_1-y_1|+\cdot+|x_n-y_n|\\
d_\infty(x,y)=\max\{|x_1-y_1|,\dots,|x_n-y_n|\}
\end{gather*}
\end{eg}

\begin{eg}
The \textbf{Euclidean metric} on $\Cbb^n$ is
\begin{align*}
d(z,w)=\sqrt{|z_1-w_1|^2+\cdots+|z_n-w_n|^2}
\end{align*}
which agrees with the Euclidean metric on $\Rbb^{2n}$. The following are also metrics:
\begin{gather*}
d_1(z,w)=|z_1-w_1|+\cdot+|z_n-w_n|\\
d_\infty(z,w)=\max\{|z_1-w_1|,\dots,|z_n-w_n|\}
\end{gather*}
\end{eg}

\begin{cv}\label{lb33}
Unless otherwise stated, the metrics on $\Rbb^n$ and $\Cbb^n$ (and their subsets) are assumed to be the Euclidean metrics.
\end{cv}


\begin{rem}
One may wonder what the subscripts $1,\infty$ mean. This notation is actually due to the general fact that
\begin{equation*}
d_p(z,w)=\sqrt[p]{|z_1-w_1|^p+\cdots+|z_n-w_n|^p}
\end{equation*}
is a metric where $1\leq p< +\infty$, and $d_\infty=\lim_{q\rightarrow +\infty}d_q$. It is not easy to prove that $d_p$ satisfies triangle inequality: one needs Minkowski inequality. For now, we will not use such general $d_p$. And we will discuss Minkowski inequality in later sections.
\end{rem}


\begin{eg}\label{lb19}
Let $X=X_1\times\cdots\times X_N$ where each $X_i$ is a metric space with metric $d_i$. Write $x=(x_1,\dots,x_N)\in X$ and $y=(y_1,\dots,y_N)\in Y$. Then the following are metrics on $X$:
\begin{gather*}
d(x,y)=d_1(x_1,y_1)+\cdots+d_N(x_N,y_N)\\
\delta(x,y)=\max\{d_1(x_1,y_1),\dots,d_N(x_N,y_N)\}\\
\rho(x,y)=\sqrt{d_1(x_1,y_1)^2+\cdots+d_N(x_N,y_N)^2}
\end{gather*}
With respect to the metric $\delta$, the open balls of $X$ are ``polydisks"
\begin{align*}
B_X(x,r)=B_{X_1}(x_1,r)\times\cdots\times B_{X_N}(x_N,r)
\end{align*}
\end{eg}


There is no standard choice of metric on the product of metric spaces. $d,\delta,\rho$ are all good, and they are equivalent in the following sense:

\begin{df}
We say that two metrics $d_1,d_2$ on a set $X$ are \index{00@Equivalent metrics} \textbf{equivalent} and write $d_1\approx d_2$, if there exist $\alpha,\beta>0$ such that  for any $x,y\in X$ we have
\begin{gather*}
d_1(x,y)\leq\alpha d_2(x,y)\qquad d_2(x,y)\leq\beta d_1(x,y)
\end{gather*}  
This is an equivalence relation. More generally, we may write $d_1\precsim d_2$ if $d_1\leq \alpha d_2$ for some $\alpha>0$. Then $d_1\approx d_2$ iff $d_1\precsim d_2$ and $d_2\precsim d_1$.
\end{df}



\begin{eg}
In Exp. \ref{lb19}, we have $\delta\leq \rho\leq d\leq N\delta$. So $\delta\approx\rho\approx d$.
\end{eg}

\begin{cv}\label{lb32}
Given finitely many metric spaces $X_1,\dots,X_N$, the metric on their product space $X=X_1\times\cdots\times X_N$ is chosen to be any one that is equivalent to the ones defined in Exp. \ref{lb19}. In the case that each $X_i$ is a subset of $\Rbb$ or $\Cbb$, we follow Convention \ref{lb33} and choose the metric on $X$ to be the Euclidean metric (unless otherwise stated).
\end{cv}


\begin{df}\label{lb43}
Let $(X,d)$ be a metric space. Then a \textbf{metric subspace} \index{00@Metric subspace} denotes an object $(Y,d|_Y)$ where $Y\subset X$ and $d|_Y$ is the restriction of $d$ to $Y$, namely, for all $y_1,y_2\in Y$ we set
\begin{align*}
d|_Y(y_1,y_2)=d(y_1,y_2)
\end{align*}
\end{df}

\begin{cv}\label{lb76}
Suppose $Y$ is a subset of a given metric space $(X,d)$. Unless otherwise stated, the metric of $Y$ is chosen to be $d|_Y$ whenever $Y$ is viewed as a metric space. For example, the metric of any subset of $\Rbb^n$ is assumed to be the Euclidean metric, unless otherwise stated.
\end{cv}



\subsection{Convergence of sequences} \label{lb73}

\begin{df}
Let $(x_n)_{n\in\Zbb_+}$ be a sequence in a metric space $X$. Let $x\in X$. We say that $x$ is the \textbf{limit} of $x_n$ and write $\displaystyle\lim_{n\rightarrow\infty}x_n=x$ (or $x_n\rightarrow x$), if:
\begin{itemize}
\item For every real number $\varepsilon>0$ there exists $N\in\Zbb_+$ such that for every $n\geq N$ we have $d(x_n,x)<\varepsilon$. 
\end{itemize}
Equivalently, this means that every (nonempty) open ball centered at $x$ contains \textbf{all but finitely many} \index{00@All but finitely many $x_n$} $x_n$.\footnote{``All but finitely many $x_n$ satisfies..." means ``for all but finitely many $n$, $x_n$ satisfies...". It does NOT mean that ``all but finitely many elements of the set $\{x_n:n\in\Zbb_+\}$ satisfies...".} 
\end{df}

\begin{rem}\label{lb100}
The negation of $x_n\rightarrow x$ is clear: 
\begin{itemize}
\item There exists $\eps>0$ such that for all $N\in\Zbb_+$ there exists $n\geq N$ such that $d(x_n,x)\geq\eps$.
\end{itemize}
Namely, one changes each ``for all" to ``there exists", changes each ``there exists" to ``for all", and negate the last sentence.
\end{rem}


\begin{exe}
Show that in the above definition of limits,  it suffices to consider rational numbers $\varepsilon>0$. (Note: You need to use Prop. \ref{lb2}.) 
\end{exe}
This exercise implies that the definition of limits does not require the existence of real numbers, i.e., does not assume Thm. \ref{lb3}. Indeed, we will use limits of sequences (and ``double sequences") to prove Thm. \ref{lb3}.


In many textbooks and research papers, you will see phrases such as \index{00@Sufficiently large}
\begin{gather}
\text{$x_n$ satisfies property $P$ for } \textbf{sufficiently large} \text{ $n$}
\end{gather}
This means that ``there exists $N\in\Zbb_+$ such that $P$ holds for all $n\geq N$". (We also say that $x_n$ \textbf{eventually} satisfies $P$.) Then $\lim_{n\rightarrow\infty} x_n=x$ means that ``for every $\varepsilon>0$, we have $d(x_n,x)<\varepsilon$ for sufficiently large $n$". 

\begin{pp}\label{lb21}
Any sequence $(x_n)_{n\in\Zbb_+}$ in a metric space $X$ has at most one limit.
\end{pp}

\begin{proof}
Suppose $(x_n)_{n\in\Zbb_+}$ converges to $x,y\in X$ where $x\neq y$. By Hausdorff property (Rem. \ref{lb20}), there exist $r,\rho>0$ such that $B(x,r)\cap B(y,\rho)=\emptyset$. By the definition of $x_n\rightarrow x$, there exists $N_1\in\Zbb_+$ such that $x_n\in B(x,r)$ for all $n\geq N_1$. Similarly, $x_n\rightarrow y$ means that there is $N_2\in\Zbb_+$ such that $x_n\in B(y,\rho)$ for all $n\geq N_2$. Choose any $n\geq N_1,N_2$ (e.g. $n=\max\{N_1,N_2\}$). Then $x_n\in B(x,r)\cap B(y,\rho)=\emptyset$, impossible.
\end{proof}


\subsubsection{Methods for proving convergence and computing limits}



\begin{eg}
$\dps \lim_{n\rightarrow\infty}\frac 1n=0$.
\end{eg}


\begin{proof}
Choose any $\varepsilon\in\Qbb_{>0}$. By Archimedean property, there exists $N\in\Zbb_+$ such that $N\varepsilon>1$, i.e. $1/N<\varepsilon$. Thus, for all $n\geq N$ we have $1/n<\varepsilon$.
\end{proof}

\begin{pp}
Let $\Fbb\in\{\Qbb,\Rbb\}$ and $(x_n),(y_n)$ be sequences in $\Fbb$ converging to $x,y\in\Rbb$. If $x_n\leq y_n$ for all $n$, then $x\leq y$.
\end{pp}

\begin{proof}
If $y<x$, let $\varepsilon=x-y$. Then all but finitely many members of $(x_n)$ are in $(x-\varepsilon/2,x+\varepsilon/2)$, and all but finitely many members of $(y_n)$ are in $(y-\varepsilon/2,y+\varepsilon/2)$. Since $y+\eps/2<x-\eps/2$, there must exist $n$ such that $y_n<x_n$.
\end{proof}


\begin{df}
If $A$ and $B$ are posets (or more generally, preordered sets, see Def. \ref{lb116}), we say a function $f:A\rightarrow B$ is \textbf{increasing} \index{00@Increasing and decreasing} \index{00@Strictly increasing and strictly decreasing} (resp. \textbf{strictly increasing}), if for each $x,y\in A$ we have
\begin{gather*}
x\leq y\qquad\Longrightarrow\qquad f(x)\leq f(y)\\
\text{resp.}\\
x<y\qquad\Longrightarrow \qquad f(x)<f(y)
\end{gather*}
We leave the definitions of \textbf{decreasing} and \textbf{strictly decreasing} to the readers. We say that $f$ is \index{00@Monotonic} \index{00@Strictly monotonic} \textbf{monotonic} (resp. \textbf{strictly monotonic}), if $f$ is either increasing or decreasing (resp. either strictly increasing or strictly decreasing).
\end{df}


\begin{pp}\label{lb57}
Let $(x_n)_{n\in\Zbb}$ be a sequence in $[a,b]\subset\Rbb$. If $(x_n)$ is increasing (resp. decreasing), then $\dps\lim_{n\rightarrow \infty}x_n$ equals $\dps\sup\{x_n:n\in\Zbb_+\}$ (resp. $\dps\inf\{x_n:n\in\Zbb_+\}$).
\end{pp}

\begin{proof}
Assume $(x_n)$ increases. (The case of decreasing is similar and hence its proof is omitted.) Let $A=\sup\{x_n:n\in\Zbb_+\}<+\infty$. Then for each $\eps>0$ there is $N$ such that $x_N>A-\eps$ (since $A-\eps$ is not an upper bound). Since $(x_n)$ is increasing, for all $n\in\Nbb$ we have $A-\eps<x_n\leq A$ and so $|x_n-A|<\eps$.
\end{proof}



\begin{eg}\label{lb27}
Let $(x_n)_{n\in\Zbb_+}$ be a sequence in a metric space $X$, and let $x\in X$. It is easy to see that
\begin{align*}
\lim_{n\rightarrow\infty} x_n=x\qquad\Longleftrightarrow \qquad \lim_{n\rightarrow\infty} d(x_n,x)=0
\end{align*}
\end{eg}

\begin{eg}\label{lb28}
Suppose that $(a_n)$ and $(b_n)$ are sequences in $\Rbb_{\geq 0}$, that $a_n\leq b_n$ for all $n$, and that $b_n\rightarrow 0$. Then  $a_n\rightarrow 0$. 
\end{eg}
\begin{proof}
For each $\varepsilon>0$, $[0,\varepsilon)$ contains all but finitely many $b_n$, and hence all but finitely many $a_n$.
\end{proof}


More generally, we have:

\begin{pp}[\textbf{Squeeze theorem}]\label{lb29}\index{00@Squeeze theorem}
Suppose that $(x_n)$ is a sequence in a metric space $X$. Let $x\in X$. Suppose that there is a sequence $(a_n)$ in $\Rbb_{\geq 0}$ such that $\dps\lim_{n\rightarrow\infty}a_n=0$ and that $d(x_n,x)\leq a_n$ for all $n$. Then $\dps\lim_{n\rightarrow\infty} x_n=x$.
\end{pp}

\begin{proof}
This follows immediately from Exp. \ref{lb27} and \ref{lb28}.
\end{proof}

The above proposition explains why many people say that ``analysis is the art of inequalities": It transforms the problem of convergence to the problem of finding a sequence $(a_n)\in\Rbb_{\geq 0}$ converging to $0$ such that the inequality $d(x_n,x)\leq a_n$ holds. And very often, a good (hard) analyst is one who knows how to find such good sequences!






\begin{pp}\label{lb38}
Let $X=X_1\times\cdots\times X_N$ be a product of metric spaces $(X_i,d_i)$. Let $d$ be any of the three metrics of $X$ in Exp. \ref{lb19}. Let $\mbf x_n=(x_{1,n},\dots,x_{N,n})$ be a sequence in $X$. Let $\mbf y=(y_1,\dots,y_N)$. Then 
\begin{align*}
\lim_{n\rightarrow\infty} \mbf x_n=\mbf y\qquad\Longleftrightarrow \qquad \lim_{n\rightarrow\infty} x_{i,n}=y_i~~(\forall 1\leq i\leq N)
\end{align*}
\end{pp}

\begin{proof}
We let $d$ be the metric $\delta$ in Exp. \ref{lb19}, i.e. defined by $\max_j d_j(x_j,y_j)$. Now choose a sequence $(\mbf x_n)$ and an element $\mbf y$ in $X$. Then
\begin{align}
\mbf x_n\rightarrow \mbf y~~\Longleftrightarrow~~ d_X(\mbf x_n,\mbf y)\rightarrow 0 ~~\Longleftrightarrow~~ \max_{1\leq j\leq N} d_j(x_{j,n},y_j)\rightarrow 0  \label{eq13}
\end{align}


Suppose that the RHS of \eqref{eq13} is true. Fix any $1\leq i\leq N$. Then $d_i(x_{i,n},y_i)\leq \max_j d_j(x_{j,n},y_j)$. So $x_{i,n}\rightarrow y_i$ by Prop. \ref{lb29}.

Conversely, assume that for every $i$ we have $x_{i,n}\rightarrow y_i$. Then for every $\eps>0$ there is $K_i\in\Zbb_+$ such that $d_i(x_{i,n},y_i)<\varepsilon$ for every $n\geq K_i$. Let $K=\max\{K_1,\dots,K_N\}$. Then for all $n\geq K$ we have $\max_j d_j(x_{j,n},y_j)<\eps$. This proves the RHS of \eqref{eq13}.

If $d$ is one of the other two metrics in Exp. \ref{lb19}, one can either use a similar argument, or use the following important (but easy) fact.
\end{proof}





\begin{pp}
Let $d,\delta$ be two equivalent metrics on a set $X$. Let $(x_n)_{n\in\Zbb_+}$ and $x$ be in $X$. Then $(x_n)$ converges to $x$ under the metric $d$ iff  $(x_n)$ converges to $x$ under $\delta$. Namely, $d(x_n,x)\rightarrow 0$ iff $\delta(x_n,x)\rightarrow 0$.
\end{pp}

\begin{proof}
Prove it yourself. (Or see Prop. \ref{lb48}.)
\end{proof}

More useful formulas about limit will be given in Exp. \ref{lb111}.







\subsubsection{Criteria for divergence}\label{lb119}

\begin{df}
A subset $E$ of a metric space $(X,d)$ is called \index{00@Bounded subset} \textbf{bounded} if either $E=\emptyset$ or there exist $p\in X$ and $R\in\Rbb_{>0}$ such that $E\subset B_X(p,R)$. If $X$ is bounded, we also say that $d$ is a \textbf{bounded metric}. \index{00@Bounded metric}
\end{df}

\begin{rem}
Note that if $E$ is bounded, then  for \textit{any} $q\in X$ there exists $\wtd R\in\Rbb_{>0}$ such that $E\subset B_X(q,\wtd R)$. (Indeed, choose $\wtd R=R+d(p,q)$, then by triangle inequality, $B(p,R)\subset B(q,\wtd R)$.)
\end{rem}

Some easy examples are as follows.
\begin{eg}
In a metric space $X$, if $x\in X$ and $0<r<+\infty$, then $B(x,r)$ is bounded. Hence $\ovl B(x,r)$ is bounded (since it is inside $B(x,2r)$).
\end{eg}


%% Record #1 2023/09/18 two lectures  2

Also, it is easy to see:
\begin{eg}\label{lb22}
A finite union of bounded subsets is bounded.
\end{eg}

\begin{pp}\label{lb24}
Let $(x_n)_{n\in\Zbb_+}$ be a convergent sequence in a metric space $X$. Then $(x_n)_{n\in\Zbb_+}$ is bounded.
\end{pp}

By saying that a sequence \index{00@Bounded sequence} $(x_n)_{n\in\Zbb_+}$ in $X$ is \textbf{bounded}, we mean that its range in $X$ (namely $\{x_n:n\in\Zbb_+\}$) is bounded.

\begin{proof}
Suppose that $x_n\rightarrow x$. Then for each $\varepsilon>0$, say $\varepsilon=1$, all but finitely many elements of $x_n$ (say $x_1,\dots,x_N$) are in $B(x,1)$. So this whole sequence is in $A=\{x_1\}\cup\cdots\{x_N\}\cup B(x,1)$. Since each $\{x_i\}$ is bounded, and since $B(x,1)$ is bounded, $A$ is bounded by Exp. \ref{lb22}.
\end{proof}


\begin{rem}\label{lb26}
Prop. \ref{lb24} gives our first criterion on divergence: If a sequence is unbounded (e.g. $x_n=n^2$), then it does not converge. But there are many bounded and divergent sequences. (See Exp. \ref{lb25}.) In this case, we need the second criterion: If a sequence has two subsequences converging to two different points, then this sequence diverge. (See Prop. \ref{lb23})
\end{rem}




\begin{df}
Let $(x_n)_{n\in\Zbb_+}$ be a sequence in a set $X$. If $(n_k)_{k\in\Zbb_+}$ is a strictly increasing sequence in $\Zbb_+$, we say that $(x_{n_k})_{k\in\Zbb_+}$ is a \textbf{subsequence} of $(x_n)_{n\in\Zbb_+}$. \index{00@Subsequence}
\end{df}



Thus, a subsequence of $(x_n)_{n\in\Zbb_+}$ is equivalently the restriction of the function $x:\Zbb_+\rightarrow X$ to an infinite subset of $\Zbb_+$.

\begin{pp}\label{lb23}
Let $(x_n)_{n\in\Zbb_+}$ be a sequence in a metric space $X$ converging to $x\in X$. Then every subsequence $(x_{n_k})_{k\in\Zbb_+}$ converges to $x$.
\end{pp}

\begin{proof}
For every $\varepsilon>0$, $B(x,\varepsilon)$ contains all but finitely many $\{x_n:n\in\Zbb_+\}$, and hence all but finitely many $\{x_{n_k}:k\in\Zbb_+\}$.
\end{proof}

\begin{eg}\label{lb25}
The sequence $x_n=(-1)^n$ in $\Rbb$ is divergent, because the subsequence $(x_{2k})_{k\in\Zbb_+}$ converges to $1$, whereas $(x_{2k-1})_{k\in\Zbb_+}$ converges to $-1$. 
\end{eg}




One may wonder if the two criteria in Rem. \ref{lb26} are complete in order to determine whether a sequence diverges. This is true for sequences in $\Rbb^n$. We will discuss this topic later. (See Cor. \ref{lb75}.)



\subsection{Continuous maps of metric spaces}\label{lb185}

Continuous maps are a powerful tool for showing that a sequence converges.


\begin{df}\label{lb31}
Let $f:X\rightarrow Y$ be a map of metric spaces. Let $x\in X$. We say that $f$ is \textbf{continuous at $x$} if one of the following equivalent conditions hold:
\begin{itemize}[align=left]
\item [(1)] For every sequence $(x_n)_{n\in\Zbb_+}$ in $X$, we have
\begin{align*}
\lim_{n\rightarrow\infty} x_n=x\qquad\Longrightarrow\qquad \lim_{n\rightarrow\infty} f(x_n)=f(x)
\end{align*}
\item[(2)] For every $\varepsilon>0$, there exists $\delta>0$ such that for every $p\in X$ satisfying $d(p,x)<\delta$, we have $d(f(p),f(x))<\varepsilon$.
\item[(2')] For every $\varepsilon>0$, there exists $\delta>0$ such that $B_X(x,\delta)\subset f^{-1}(B_Y(f(x),\varepsilon)))$.
\end{itemize}
We say that $f$ is a \textbf{continuous map/function}, if $f$ is continuous at every point of $X$.
\end{df}

\begin{proof}[Proof of the equivalence]
(2)$\Leftrightarrow$(2'): Obvious.

(2)$\Rightarrow$(1): Assume (2). Assume $x_n\rightarrow x$. For every $\varepsilon>0$, let $\delta>0$ be as in (2). Then since $x_n\rightarrow x$, there is $N\in\Zbb_+$ such that for all $n\geq N$ we have $d(x_n,x)<\delta$. By (2), we have $d(f(x_n),f(x))<\varepsilon$ for all $n\geq N$. This proves $f(x_n)\rightarrow f(x)$.

$\neg$(2)$\Rightarrow$ $\neg$(1): Assume that (2) is not true. Then there exists $\varepsilon>0$ such that for every $\delta>0$, there exists $p\in X$ such that $d(p,x)<\delta$ and $d(f(p),f(x))\geq\varepsilon$. Thus, for every $n\in\Zbb_+$, by taking $\delta=1/n$, we see that there exists $x_n\in X$ such that $d(x_n,x)<1/n$ and $d(f(x_n),f(x))\geq\varepsilon$. By Squeeze theorem (Prop. \ref{lb29}), $x_n\rightarrow x$. But $f(x_n)\nrightarrow f(x)$ (i.e. $d(f(x_n),f(x))\nrightarrow 0$). So (1) is not true.
\end{proof}

\begin{rem}
One can compare Def. \ref{lb31}-(1) to the definition of linear maps. A map is continuous iff it \textit{preserves the convergence of sequences}, i.e., iff it maps convergent sequences to convergent ones. A map (between vector spaces) is linear iff it perserves the addition and the scalar multiplication of vectors. In general, a good map between two sets with ``structures" is a map which preserves the structures. (Thus, linear combinations encode the linear structures of vector spaces. Similarly, the convergence of sequences remembers the ``topological" structures of metric spaces.) As another example, we will define an isometry of metric spaces to be one that preserves the metrics (the structures of metric spaces), see Exe. \ref{lb46}.
\end{rem}

\begin{rem}\label{lb115}
In this section, we mainly use Def. \ref{lb31}-(1) to study continuity. But in later sections we will also use Def. \ref{lb31}-(2'). An advantage of (2') is that it is more geometric. Indeed, if $X$ is a metric space and $E\subset X$, we say that $x\in E$ is an \textbf{interior point of $E$ in $X$} \index{00@Interior point} if there exists $\delta>0$ such that $B_X(x,\delta)\subset E$. For example, a point  $z\in\Cbb$ is an interior point of the closed unit disk $\ovl B_\Cbb(0,1)=\{w\in\Cbb:|w|\leq 1\}$ iff $|z|<1$. 

Thus, Def. \ref{lb31}-(2') says that for any map of metric spaces $f:X\rightarrow Y$ and $x\in X$, the following are equivalent:
\begin{itemize}
\item[(a)] $f$ is continuous at $x$.
\item[(b)] For each $\eps>0$, every $x\in X$ is an interior point of $f^{-1}\big(B_Y(f(x),\varepsilon)\big)$.
\end{itemize}
We say that a subset $U\subset X$ is \textbf{open} \index{00@Open set} if each point of $U$ is an interior point. For example, by triangle inequality, every open ball in a metric space is an open set. Thus, we have:
\begin{itemize}
\item A map of metric spaces $f:X\rightarrow Y$ is continuous iff the preimage under $f$ of every open ball of $Y$ is an open subset of $X$.
\end{itemize}

In the study of point-set topology, we will see that many properties can be studied in two approaches: using sequences (or using nets, the natural generalizations of sequences) and their convergence, and using open sets. The first example of such property is continuity, as we have seen in Def. \ref{lb31}. Another prominent example is sequential compactness vs. compactness. These two approaches represent two (very) different intuitions: one is dynamic, while the other is static and more geometric. (So it is surprising that these two very things are actually equivalent!) Sometimes both approaches work for a problem, but sometimes only one of them works, or one of them is much simpler. If you are a beginner in analysis and point-set topology, I suggest that whenever you see one approach applied to a problem, try to think about whether the other approach also works and which one is better.   \hfill\qedsymbol
\end{rem}


\subsubsection{Methods for proving continuity}


\begin{lm}\label{lb30}
Let $f:X\rightarrow Y$ be a map of metric spaces.  Let $(B_i)_{i\in I}$ be a collection of open balls in $X$ such that $X=\bigcup_{i\in I}B_i$. Suppose that for each $i$, the restriction $f|_{B_i}:B_i\rightarrow Y$ is continuous. Then $f$ is continuous. 
\end{lm}

This lemma shows that if we can prove that $f$ is ``locally" continuous, then $f$ is globally continuous. 

\begin{proof}
Choose $(x_n)$ in $X$ converging to $x\in X$. We shall show $f(x_n)\rightarrow f(x)$. Choose $i$ such that $x\in B_i$. Then one can find $\delta>0$ such that $B(x,\delta)\subset B_i$. (In the language of point-set topology: $x$ is an interior point of $B_i$.) To see this, write $B_i=B(y,r)$. Since $x\in B(y,r)$, we have $r-d(x,y)>0$. Choose $0<\delta\leq r-d(x,y)$. Then triangle inequality implies $B(x,\delta)\subset B(y,r)$. 

Since $x_n\rightarrow x$, there is $N\in\Zbb_+$ such that $x_n\in B(x,\delta)$ for all $n\geq N$. Thus, $(x_{k+N})_{k\in\Zbb_+}$ converges in $B_i$ to $x$. Since $f|_{B_i}$ is continuous, $\lim_{k\rightarrow\infty} f(x_{k+N})=f(x)$. So $f(x_n)\rightarrow f(x)$.
\end{proof}







\begin{df}
A map of metric spaces $f:X\rightarrow Y$ is called \index{00@Lipschitz continuous} \textbf{Lipschitz continuous} if there exists $L\in\Rbb_{>0}$ (called \textbf{Lipschitz constant}) \index{00@Lipschitz constant} such that for all $x_1,x_2\in X$,
\begin{align}
d_Y\big(f(x_1),f(x_2) \big)\leq L\cdot d_X(x_1,x_2) \label{eq14}
\end{align}
\end{df}

\begin{lm}\label{lb34}
Lipschitz continuous maps are continuous. 
\end{lm}

\begin{proof}
Suppose that $f:X\rightarrow Y$ is Lipschitz continuous with Lipschitz constant $L$. Suppose $x_n\rightarrow x$ in $X$. Then $L\cdot d(x_n,x)\rightarrow 0$. By \eqref{eq14} and Squeeze theorem (Prop. \ref{lb29}), $f(x_n)\rightarrow f(x)$. (You can also use Def. \ref{lb31}-(2) to prove this lemma.)
\end{proof}

\begin{eg}\label{lb35}
Let $\Fbb\in\{\Qbb,\Rbb,\Cbb\}$. The map $z\in\Fbb\setminus \{0\}\mapsto z^{-1}\in\Fbb$ is continuous.
\end{eg}



\begin{proof}
Let this map be $f$. Since $\Fbb$ is covered by open balls $B(z,\delta)$ where $z\in\Fbb\setminus\{0\}$ and $0<\delta<|z|$, by Lem. \ref{lb30}, it suffices to prove that $f$ is continuous when restricted to every such $B(z,\delta)$. Let $\eps=|z|-\delta>0$. Choose $x,y\in B(z,\delta)$. Then $|x|=|x-z+z|\geq |z|-|z-x|>\eps$ by triangle inequality. Similarly, $|y|>\eps$. So
\begin{align*}
|f(x)-f(y)|=|x^{-1}-y^{-1}|=|x-y|/|xy|\leq \eps^{-2}|x-y|
\end{align*}
So $f|_{B(z,\delta)}$ has Lipschitz constant $\eps^{-2}$, and hence is continuous.
\end{proof}

(Question: in the above proof, is the map $f:\Fbb\setminus\{0\}\rightarrow\Fbb$ Lipschitz continuous?)

We have given a fancy way of proving that  if $(z_n)$ is a sequence in $\Fbb\setminus\{0\}$ converging to $z\in\Fbb\setminus\{0\}$, then $z_n^{-1}\rightarrow z^{-1}$. You should think about how to prove this fact directly using $\eps-N$ language, and compare your proof with the above proof to find the similarities!




\begin{pp}\label{lb41}
Let $\Fbb\in\{\Qbb,\Rbb,\Cbb\}$. Then the following maps are continuous:
\begin{gather*}
+:\Fbb\times\Fbb\rightarrow\Fbb\qquad (x,y)\mapsto x+y\\
-:\Fbb\times\Fbb\rightarrow\Fbb\qquad  (x,y)\mapsto x-y\\
\times: \Fbb\times\Fbb\rightarrow\Fbb\qquad  (x,y)\mapsto xy\\
\div:\Fbb\times\Fbb^\times\rightarrow\Fbb\qquad  (x,y)\mapsto x/y
\end{gather*}
\end{pp}


Recall our Convention \ref{lb32} on the metrics of finite product spaces. 


\begin{proof}
We only prove that the last two are continuous: the first two can be treated in a similar (and easier) way.

Denote the multiplication map by $\mu$. We choose the metric on $\Fbb^2$ to be $d(\mbf x,\mbf x')=\max\{|x_1-x_1'|,|x_2-x_2'|\}$. Since $\Fbb\times\Fbb$ is covered by open balls of the form $B(0,r)=\{(x,y)\in\Fbb^2:|x|<r,|y|<r\}$ where $0<r<+\infty$, by Lem. \ref{lb30} and \ref{lb34}, it suffices to show that $\mu|_{B(0,r)}$ is Lipschitz continuous. This is true, since for each $(x,y),(x',y')\in B(0,r)$, we have
\begin{align}\label{eq22}
\begin{aligned}
&|\mu(x,y)-\mu(x',y')|=|xy-x'y'|\leq |(x-x')y|+|x'(y-y')|\\
<&2r\cdot \max\{|x-x'|,|y-y'|\}=2r \cdot d((x,y),(x',y'))  
\end{aligned}
\end{align}

By Exp. \ref{lb35} and Prop. \ref{lb37}, the map $(x,y)\in\Fbb\times\Fbb^\times\mapsto (x,y^{-1})\in\Fbb\times\Fbb$ is continuous. So its composition with the continuous map $\mu$ is continuous, thanks to Prop. \ref{lb36}. So $\div$ is continuous. 
\end{proof}

\begin{pp}\label{lb36}
Suppose that $f:X\rightarrow Y$ and $g:Y\rightarrow Z$ are continuous maps of metric spaces. Then $g\circ f:X\rightarrow Z$ is continuous.
\end{pp}

\begin{pp}\label{lb37}
Suppose that $f_i:X_i\rightarrow Y_i$ is a map of metric spaces, where $1\leq i\leq N$. Then the product map \index{00@Product map}
\begin{gather*}
f_1\times\cdots\times f_N:X_1\times\cdots\times X_N\rightarrow Y_1\times\cdots\times Y_N\\
(x_1,\dots,x_N)\mapsto (f_1(x_1),\dots,f_N(x_N))
\end{gather*}
is continuous if and only if $f_1,\dots,f_N$ are continuous.
\end{pp}

\begin{proof}[Proof of Prop. \ref{lb36} and \ref{lb37}]
Immediate from Def. \ref{lb31}-(1) and Prop. \ref{lb38}.
\end{proof}


\begin{co}[\textbf{Squeeze theorem}]\index{00@Squeeze theorem}\label{lb61}
Let $\Fbb\in\{\Qbb,\Rbb\}$ and $(x_n),(y_n),(z_n)$ be sequences in $\Rbb$. Assume that $x_n\leq y_n\leq z_n$ for all $n$. Assume that $x_n$ and $z_n$ both converge to $A\in\Rbb$. Then $\lim_{n\rightarrow\infty}y_n=A$. 
\end{co}

\begin{proof}
Let $a_n=y_n-x_n$ and $b_n=z_n-x_n$. Then $0\leq a_n\leq b_n$, and $\lim_n b_n=\lim_n z_n-\lim_n x_n= 0$ because the subtraction map is continuous (Prop. \ref{lb41}). By Exp. \ref{lb28}, $a_n\rightarrow 0$. Since $x_n\rightarrow A$, $y_n=x_n+a_n$ converges to $A$, since the addition map is continuous by Prop. \ref{lb41}.
\end{proof}

Again, this is a fancy way of proving Squeeze theorem. The readers should know how to prove it directly from the definition of limits of sequences.

We give some more examples of continuous maps.

\begin{eg}
By Prop. \ref{lb41}, $f(x,y,z)=x^2y+5y^4z^7-3xyz^2$ is a continuous function on $\Cbb^3$. Clearly $z\in\Cbb\mapsto \ovl z\in\Cbb$ is continuous. So $g(x,y,z)=f(\ovl x,\ovl y,z)+2\ovl{f(z,x^2,xy^{-9})}-5xy^{-2}\ovl{z^{-3}}$ is a continuous function on $\Cbb\times\Cbb^\times\times\Cbb^\times$.
\end{eg}


\begin{eg}\label{lb44}
Let $f,g:X\rightarrow \Fbb$ be continuous functions where $\Fbb\in\{\Qbb,\Rbb,\Cbb\}$. Then by Prop. \ref{lb41} and \ref{lb36}, $f\pm g$ and $fg$ are continuous, and $f/g$ is continuous when $0\notin g(X)$. Here
\begin{align}
(f\pm g)(x)=f(x)\pm g(x)\qquad (fg)(x)=f(x)g(x)\qquad (f/g)(x)=f(x)/g(x)
\end{align} 
\end{eg}


\begin{eg}\label{lb54}
Let $f:X\rightarrow Y$ be a map of metric spaces. Let $E,F$ be subsets of $X,Y$ respectively. (Recall that the metrics of subsets are chosen as in Def. \ref{lb43}.) 
\begin{itemize}
\item The inclusion map $\iota_E:E\rightarrow X,x\mapsto x$ is clearly continuous. Thus, if $f$ is continuous, then $f|_E:E\rightarrow Y$ is continuous, since $f|_E=f\circ\iota_E$.
\item If $f(X)\subset F$, then we can restrict the codomain of $f$ from $Y$ to $F$: let $\wtd f:X\rightarrow F$ be $\wtd f(x)=f(x)$. Then it is clear that $f$ is continuous iff $\wtd f$ is continuous.
\end{itemize}
\end{eg}




\begin{pp}
Let $X_1,\dots,X_N$ be metric spaces. The following  projection is clearly continuous:
\begin{gather*}
\pi_{X_i}:X_1\times\cdots\times X_N\rightarrow X_i\qquad(x_1,\dots,x_N)\mapsto x_i
\end{gather*}
\end{pp}

\begin{pp}
Let $f_i:X\rightarrow Y_i$ be maps where $X,Y_1,\dots,Y_N$ are continuous. Then 
\begin{gather*}
f_1\vee \cdots\vee f_N:X\rightarrow Y_1\times\cdots\times Y_N\qquad x\mapsto (f_1(x),\dots,f_N(x))
\end{gather*}
is continuous iff $f_1,\dots,f_N$ are continuous.
\end{pp}


\begin{eg}
Let $X$ be a metric space. Then $d:X\times X\rightarrow\Rbb,(x,y)\mapsto d(x,y)$ is Lipschiz continuous with Lipschitz constant $1$ (by triangle inequality). So $d$ is continuous.
\end{eg}

\begin{pp}\label{lb42}
Let $X$ be a metric space and $E\subset X$ is nonempty. Define \textbf{distance function} \index{00@Distance function $d(\cdot,E)$} \index{dE@$d(x,E)$} 
\begin{gather*}
d(\cdot,E):X\rightarrow\Rbb_{\geq0}\qquad
d(x,E)=\inf_{e\in E}d(x,e)
\end{gather*}
Then $d(\cdot,E)$ is has Lipschitz constant $1$. So $d(\cdot,E)$ is continuous.
\end{pp}


\begin{proof}
Choose any $x,y\in X$. By triangle inequality, for each $e\in E$ we have $d(x,e)\leq d(x,y)+d(y,e)$. Since $d(x,E)\leq d(x,e)$, we get  $d(x,E)\leq d(x,y)+d(y,e)$. Applying $\inf_{e\in E}$ to the RHS gives $d(x,E)\leq d(x,y)+d(y,E)$. Hence $d(x,E)-d(y,E)\leq d(x,y)$. Exchanging $x$ and $y$ gives
\begin{align}
\big|d(x,E)-d(y,E)\big|\leq d(x,y)
\end{align}
This proves that $d(\cdot,E)$ has Lipschitz constant $1$.
\end{proof}

\begin{df}
More generally, if $E,F$ are subsets of a metric space $E$, we can define \index{DEF@$d(E,F)$}
\begin{align}
d(E,F)=\inf_{e\in E,f\in F}d(e,f)
\end{align}
to be the \textbf{distance between $E$ and $F$}.
\end{df}

\begin{exe}
Let $E,F\subset X$. Prove that
\begin{align}
d(E,F)=\inf_{f\in F}d(E,f)
\end{align}
\end{exe}

\begin{eg}\label{lb45}
If $X$ is a metric space and $p\in X$, then by Prop. \ref{lb42} (or simply by triangle inequality), the function $d_p:x\in X\mapsto d(x,p)\in\Rbb$ has Lipschitz constant $1$ and hence is continuous. In particular, if $\Fbb\in\{\Rbb,\Cbb\}$,  the function $z\in\Fbb\mapsto |z|$ is continuous (since $|z|=d_\Fbb(z,0)$). Thus, if $f:X\rightarrow\Fbb$ is continuous, then $|f|:X\rightarrow\Rbb_{\geq0}$ is continuous where
\begin{align}
|f|(x)=|f(x)|
\end{align}
\end{eg}


\begin{eg}
Let $N\in\Zbb_+$. Then the following function is continuous:
\begin{align*}
\max:\Rbb^N\rightarrow \Rbb\qquad (x_1,\dots,x_N)\mapsto\max\{x_1,\dots,x_N\}\in\Rbb
\end{align*}
Similarly, the minimum function is continuous.
\end{eg}

\begin{proof}
To avoid confusion, we write $\max$ as $\max_N$. The case $N=1$ is obvious. When $N=2$, we have
\begin{align}
\max(x_1,x_2)=\frac{x_1+x_2+|x_1-x_2|}2
\end{align}
So $\max_2$ is continuous by Exp. \ref{lb44} and \ref{lb45}.

We use induction. Suppose we have proved that $\max_N$ is continuous. Then $\max_N\times\id_\Rbb:\Rbb^N\times \Rbb\rightarrow\Rbb\times\Rbb$ is continuous. So $\max_{N+1}=\max_2\circ(\max_N\times\id_\Rbb)$ is continuous.
\end{proof}


\subsection{Homeomorphisms and isometric isomorphisms; convergence in $\ovl{\Rbb}$}

\subsubsection{General theory}



\begin{df}\label{lb189}
A bijection of metric spaces $f:X\rightarrow Y$ is called a \textbf{homeomorphism} if one of the following equivalent (cf. Def. \ref{lb31}) statements holds:
\begin{itemize}
\item[(1)] $f:X\rightarrow Y$ and its inverse map $f^{-1}:Y\rightarrow X$ are continuous.
\item[(2)] For each sequence $(x_n)$ in $X$ and each $x\in X$, we have $\dps \lim_{n\rightarrow\infty}x_n=x$ iff $\dps\lim_{n\rightarrow\infty}f(x_n)=f(x)$.
\end{itemize}
If such $f$ exists, we say that $X,Y$ are \textbf{homeomorphic}.
\end{df}

A special case of the above definition is:
\begin{df}\label{lb144}
Let $X$ be a set with metrics $d,\delta$. We say that $d$ and $\delta$ induce the \textbf{same topology} on $X$ (or that $d,\delta$ are \index{00@Topologically equivalent metrics} \textbf{topologically equivalent}) if one of the following clearly equivalent statements holds:
\begin{itemize}
\item[(1)] The map $(X,d)\rightarrow (X,\delta),x\mapsto x$ is a homeomorphism.\footnote{We prefer not to call this map the identity map, because the metrics on the source and on the target are different.}
\item[(2)] For each sequence $(x_n)$ in $X$ and each $x\in X$, $(x_n)$ converges to $x$ under the metric $d$ iff $(x_n)$ converges to $x$ under $\delta$.
\end{itemize}
\end{df}


\begin{pp}\label{lb48}
Suppose that $d,\delta$ are equivalent metrics on a set $X$. Then $d,\delta$ are topologically equivalent.
\end{pp}

\begin{proof}
Suppose $\delta\leq\alpha d$ and $d\leq\beta\delta$ for some $\alpha,\beta>0$. Then the map $f:(X,d)\rightarrow (X,\delta),x\mapsto x$ and its inverse $f^{-1}$ have Lipschitz constants $\alpha$ and $\beta$ respectively. So $f,f^{-1}$ are continuous.
\end{proof}






\begin{exe}\label{lb46}
Let $f:X\rightarrow Y$ be a map of metric spaces. We say that $f:X\rightarrow Y$ is an \textbf{isometry} (or is \textbf{isometric}) \index{00@Isometry and isometric isomorphism} if for all $x_1,x_2\in X$ we have
\begin{align}
d_Y(f(x_1),f(x_2))=d_X(x_1,x_2) \label{eq15}
\end{align}
Show that an isometry is injective and continuous.

We say that $f$ is an \textbf{isometric isomorphism} if $f$ is a surjective isometry. If an isometric isomorphism between two metric spaces $X,Y$ exists, we say that $X$ and $Y$ are \textbf{isometric metric spaces}.\index{00@Isometric metric spaces} Show that an isometric isomorphism is a homeomorphism.   \hfill\qedsymbol
\end{exe}

\begin{rem}
Isometric isomorphisms are important examples of homeomorphisms. That $f:X\rightarrow Y$ is an isometric isomorphism means that $X$ and $Y$ are equivalent as metric spaces, and that this equivalence can be implemented by the bijection $f$. 

We now look at isometric isomorphisms in a different direction. Suppose that $f:X\rightarrow Y$ is a bijection of sets. Suppose that $Y$ is a metric space. Then there is unique metric $d_X$ on $X$ such that $f$ is an isometric isomorphism: one defines $d_X$ using \eqref{eq15}. We write such $d_X$ as $f^*d_Y$, \index{fdY@$f^*d_Y$: pullback metric}  i.e.,
\begin{align*}
f^*d_Y(x_1,x_2)=d_Y(f(x_1),f(x_2))
\end{align*}
and call $f^*d_Y$ the \textbf{pullback metric} \index{00@Pullback metrics} of $d_Y$ by $f$. \hfill\qedsymbol
\end{rem}

Pullback metrics are a very useful way of constructing metrics on a set. We consider some examples below. 


\begin{exe}\label{lb49}
Two metrics inducing the same topology are not necessarily equivalent metrics. For example, let $f:[0,1]\rightarrow [0,1]$ be $f(x)=x^2$. Let $X=[0,1]$, and let $d_X$ be the  Euclidean metric: $d_X(x,y)=|x-y|$. So
\begin{align*}
f^*d_X(x,y)=|x^2-y^2|
\end{align*}
is a metric on $X$. It is not hard to check that $f:(X,d_X)\rightarrow (X,d_X)$ is a homeomorphism.  So $d_X$ and $f^*d_X$ give the same topology on $[0,1]$ (cf. Exe. \ref{lb50}). Show that $f^*d_X$ and $d_X$ are not equivalent metrics.
\end{exe}

\begin{exe}\label{lb50}
Let $f:X\rightarrow Y$ be a bijection of sets with metrics $d_X,d_Y$. Show that $d_X$ and $f^*d_Y$ give the same topology on $X$ iff $f:(X,d_X)\rightarrow(Y,d_Y)$ is a homeomorphism. 

In particular, if $f:X\rightarrow X$ is a bijection, and $d_X$ is a metric on $X$. Then $d_X$ and $f^*d_X$ give the same topology on $X$ iff $f:(X,d_X)\rightarrow (X,d_X)$ is a homeomorphism. 
\end{exe}


\subsubsection{Convergence in $\ovl\Rbb$}


Our second application of pullback metrics is the convergence in $\ovl\Rbb$.




\begin{df}\label{lb47}
We say that a sequence $(x_n)$ in $\ovl\Rbb$ \textbf{converges to} \index{00@Convergence in $\ovl{\Rbb}$} $+\infty$ (resp. $-\infty$), if for every $A\in\Rbb$ there is $N\in\Zbb_+$ such that for all $n\geq N$ we have $x_n>A$ (resp. $x_n<A$). 

Suppose $x\in\Rbb$. We say that a sequence $(x_n)$ in $\ovl\Rbb$ \textbf{converges to} $x$, if there is $N\in\Zbb_+$ such that $x_n\in\Rbb$ for all $n\geq N$, and that the subsequence $(x_{k+N})_{k\in\Zbb_+}$ converges in $\Rbb$ to $x$.  \hfill\qedsymbol
\end{df}



This notion of convergence is weird: it is not defined by a metric. So one wonders if there is a metric $d$ on $\ovl\Rbb$ such that convergence of sequences under $d$ agrees with that in Def. \ref{lb47}. We shall now find such a metric.

\begin{lm}\label{lb59}
Let $-\infty\leq a<b\leq +\infty$ and $-\infty\leq c<d\leq +\infty$. Then there is a strictly increasing bijective map $[a,b]\rightarrow[c,d]$.
\end{lm}
Note that this map clearly sends $a$ to $c$ and $b$ to $d$. So it restricts to strictly increasing bijections $(a,b)\rightarrow(c,d)$, $(a,b]\rightarrow(c,d]$, $[a,b)\rightarrow[c,d)$.

\begin{proof}
We have a strictly increasing bijection $f:\Rbb\rightarrow(-1,1)$ defined by \eqref{eq20}.  $f$ can be extended to a strictly increasing bijective map $\ovl\Rbb\rightarrow[-1,1]$ if we set $f(\pm\infty)=\pm1$. Thus, $f$ restricts to a strictly increasing bijection $[a,b]\rightarrow [f(a),f(b)]$. Choose a linear function $g(x)=\alpha x+\beta$ (where $\alpha>0$) giving an increasing bijection $[f(a),f(b)]\rightarrow[0,1]$. Then $h=g\circ f:[a,b]\rightarrow[0,1]$ is a strictly increasing bijection. Similarly, we have a strictly increasing bijection $k:[c,d]\rightarrow[0,1]$. Then $k^{-1}\circ h:[a,b]\rightarrow[c,d]$ is a strictly increasing bijection.
\end{proof}


\begin{thm}\label{lb51}
Let $\varphi:\ovl\Rbb\rightarrow[a,b]$ be a strictly increasing bijective map where $[a,b]\subset\Rbb$ is equipped with the Euclidean metric $d_{[a,b]}$. Then a sequence $(x_n)$ in $\ovl\Rbb$ converges to $x\in\ovl\Rbb$ in the sense of Def. \ref{lb47} iff $\varphi(x_n)$ converges to $\varphi(x)$ under the metric $d_{[a,b]}$. In other words, the convergence in $\ovl\Rbb$ is given by the metric $\varphi^*d_{[a,b]}$.
\end{thm}

\begin{proof}
Let $y=\varphi(x)$ and $y_n=\varphi(x_n)$. We need to prove that $x_n\rightarrow x$ (in the sense of Def. \ref{lb47}) iff $y_n\rightarrow y$ (under the Euclidean metric). Write $\psi=\varphi^{-1}$, which is a strictly increasing map $[a,b]\rightarrow\ovl\Rbb$. Note that $\varphi(+\infty)=b$ and $\varphi(-\infty)=a$. 

Case 1: $x\in\Rbb$. By discarding the first several terms, we may assume that $(x_n)$ is always in $\Rbb$. If $x_n\rightarrow x$, then for every $\eps>0$, all but finitely many $x_n$ are inside the open interval $(\psi(y-\varepsilon),\psi(y+\varepsilon))$. So all but finitely many $y_n$ are inside $(y-\varepsilon,y+\varepsilon)$. So $y_n\rightarrow y$. That $y_n\rightarrow y$ implies $x_n\rightarrow x$ is proved in a similar way.

Case 2: $x=\pm\infty$. We consider $x=+\infty$ only; the other case is similar. Note that if $0<\eps<b-a$, then $B_{[a,b]}(b,\varepsilon)=(b-\varepsilon,b]$.  If $x_n\rightarrow+\infty$, then for each  $0<\eps<b-a$, all but finitely many $x_n$ are $>\psi(b-\eps)$. So all but finitely many $y_n$ are inside $(b-\eps,b]$. This proves $y_n\rightarrow b$. Conversely, if $y_n\rightarrow b$, then for each $A\in\Rbb$, all but finitely many $y_n$ are inside $(\varphi(A),b]$ and hence $>\varphi(A)$. So all but finitely many $x_n$ are $>A$.
\end{proof}


\begin{cv}\label{lb77}
Unless otherwise stated, a metric on $\ovl\Rbb$ is one that makes Def. \ref{lb47} true, for instance $\varphi^*d_{[a,b]}$ in Thm. \ref{lb51}. Unless otherwise stated, we do NOT view $\Rbb$ (or any subset of $\Rbb$) as a metric subspace of $\ovl\Rbb$. Namely, we do not follow Convention \ref{lb76} for $\Rbb\subset\ovl\Rbb$, or more generally for $\Rbb^N\subset\ovl\Rbb^N$. Instead, we choose Euclidean metrics on $\Rbb^N$, following Convention \ref{lb33}. 
\end{cv}




The main reason for not following Convention \ref{lb76} here is that metrics on $\ovl\Rbb$ are all bounded (by Prop. \ref{lb71}). Thus, every subset of $\Rbb$ is bounded if we view $\Rbb$ as a metric subspace of $\ovl\Rbb$. However, we want a subset of $\Rbb$ to be bounded precisely when it is contained in $[a,b]$ for some $-\infty<a<b<+\infty$. (Recall also Def. \ref{lb114}.)



After learning topological spaces, we shall forget about the metrics on $\ovl\Rbb$ and only care about its topology. (See Conv. \ref{lb173}.)






\begin{rem}\label{lb58}
By Thm. \ref{lb51}, the properties of $[a,b]$ about convergence of sequences and inequalities can be transported to $\ovl\Rbb$, for example:
\begin{enumerate}
\item If $(x_n),(y_n)$ are sequences in $\ovl\Rbb$ converging to $A,B\in\ovl\Rbb$, and if $x_n\leq y_n$ for all $n$, then $A\leq B$.
\item \textbf{Squeeze theorem}: \index{00@Squeeze theorem} Suppose that $(x_n),(y_n),(z_n)$ are sequences in $\ovl\Rbb$, $x_n\leq y_n\leq z_n$ for all $n$, and $x_n$ and $z_n$ both converge to $A\in\ovl\Rbb$. Then $y_n\rightarrow A$.
\item Prop. \ref{lb57} also holds for $[-\infty,+\infty]=\ovl\Rbb$: if $(x_n)$ is an increasing resp. decreasing sequence in $\ovl\Rbb$, then $\lim_n x_n$ exists in $\ovl\Rbb$ and equals $\sup_n x_n$ resp. $\inf_n x_n$.
\end{enumerate}
We will see more examples when studying $\limsup$ and $\liminf$ in the future.
\end{rem}


We have shown that there is a metric on $\ovl\Rbb$ which defines the convergence in Def. \ref{lb47}. However, there is no standard choice of such a metric on $\ovl\Rbb$. Even worse, two possible choices of metrics might not be equivalent: Let $\varphi,\psi:\ovl\Rbb\rightarrow[0,1]$ be a strictly increasing bijections where $\psi\circ\varphi^{-1}:[0,1]\rightarrow[0,1]$ is $x\mapsto x^2$. Then by Exe. \ref{lb49}, $\varphi^*d_{[0,1]}$ and $\psi^*d_{[0,1]}$ are non-equivalent but topologically equivalent metrics on $\ovl\Rbb$. This is the first example that metrics are not convenient for the description of convergence. When studying the convergence in $\ovl\Rbb$, thinking about metrics is distracting. In the future, we will see a better notion for the study of convergence: the notion of topological spaces.

We end this section with a generalization of Thm. \ref{lb51}.

\begin{thm}\label{lb65}
Let $\varphi$ be a strictly increasing bijection in one of the following forms
\begin{gather*}
[a,b]\rightarrow [c,d]\qquad (a,b)\rightarrow(c,d)\\
(a,b]\rightarrow (c,d]\qquad [a,b)\rightarrow [c,d)
\end{gather*}
where $-\infty\leq a\leq b\leq +\infty$ and $-\infty\leq c\leq d\leq +\infty$. Then $\varphi$ is a homeomorphism, i.e., if $(x_n)$ and $x$ are in the domain, then $x_n\rightarrow x$ iff $\varphi(x_n)\rightarrow \varphi(x)$ (in the sense of Def. \ref{lb47}).
\end{thm}

\begin{proof}
The case $a=b$ is obvious. So we consider $a<b$, and hence $c<d$. We consider the left-open-right-closed case for example. The other cases are treated in a similar way. If the theorem can be proved for $(-\infty,+\infty]\rightarrow(c,d]$, then it can also be proved $(-\infty,+\infty]\rightarrow(a,b]$. By composing the inverse of the second map with the first map, we see that the theorem holds for $(a,b]\rightarrow (c,d]$. 

Let us consider $\varphi:(-\infty,+\infty]\rightarrow(c,d]$. $\varphi$ can be extended to a strictly increasing bijection $\varphi:\ovl\Rbb\rightarrow[c,d]$ by letting $\varphi(-\infty)=c$. It suffices to prove that this $\varphi$ is a homeomorphism. When $-\infty<c<d<+\infty$, then the theorem holds by Thm. \ref{lb51}. If one of $c,d$ is $\pm\infty$, the same argument as in the proof of Thm. \ref{lb51} proves that $\varphi$ is a homeomorphism. We leave it to the readers to fill in the details.
\end{proof}



%% Record  #2  2023/9/20   three lectures  5


\subsection{Problems and supplementary material}

\begin{df}
Let $A$ be a subset of $\Rbb$  satisfying $x+y\in A$ for all $x,y\in A$. (Or more generally, let $A$ be an abelian semigroup.) We say that a function $f:A\rightarrow \Rbb$ is \textbf{subadditive} \index{00@Subadditivity} if for every $x,y\in A$ we have $f(x+y)\leq f(x)+f(y)$.
\end{df}

\begin{prob}\label{lb52}
Consider the following increasing functions:
\begin{gather*}
f_1:\Rbb_{\geq 0}\rightarrow[0,1)\qquad f_1(x)=\frac{x}{1+x}\\
f_2:\Rbb_{\geq 0}\rightarrow[0,1]\qquad f_2(x)=\min\{x,1\}
\end{gather*}
Prove that they are subadditive functions. 
\end{prob}

\begin{prob}\label{lb53}
Let $f:\Rbb_{\geq0}\rightarrow \Rbb_{\geq0}$ be an increasing subadditive function satisfying the following conditions:
\begin{itemize}
\item[(1)] $f^{-1}(0)=\{0\}$.
\item[(2)] For any $(x_n)_{n\in\Zbb_+}$ in $\Rbb_{\geq0}$ we have $x_n\rightarrow 0$ iff $f(x_n)\rightarrow 0$.
\end{itemize}
Let $(X,d)$ be a metric space. Define
\begin{align*}
\delta:X\times X\rightarrow [0,A)\qquad \delta(x,y)=f\circ d(x,y)
\end{align*}  
Prove that $\delta$ is a metric, and that $\delta$ and $d$ are topologically equivalent.
\end{prob}


\begin{pp}\label{lb195}
Let $(X,d)$ be a metric space. Then there is a bounded metric $\delta$ on $X$ such that $d$ and $\delta$ are topologically equivalent.
\end{pp}
\begin{proof}
Let $f$ be either $f_1$ or $f_2$ defined in Pb. \ref{lb52}. Then $f$ satisfies the assumptions in Pb. \ref{lb53}. So $\delta=f\circ d$ is a desired metric due to Pb. \ref{lb53}. We write down the formulas explicitly:
\begin{align*}
\delta_1(x,y)=\frac{d(x,y)}{1+d(x,y)}\qquad \delta_2(x,y)=\min\{d(x,y),1\}
\end{align*}
\end{proof}

\begin{prob}\label{lb78}
Let $(X_i,d_i)_{i\in\Zbb_+}$ be a sequence of metric spaces. Assume that $d_i\leq 1$ for each $i$. Let $\dps S=\prod_{i\in\Zbb_+} X_i$. For each elements $f=(f(i))_{i\in\Zbb_+}$ and $g=(g(i))_{i\in\Zbb_+}$ of $S$, define
\begin{align}
d(f,g)=\sup_{i\in\Zbb_+} \frac {d_i(f(i),g(i))}{i}  \label{eq16}
\end{align} 
Prove that $d$ is a metric on $S$. Let $f_n=(f_n(i))_{i\in\Zbb_+}$ be a sequence in $S$. Let $g\in S$. Prove that the following are equivalent:
\begin{enumerate}[label=(\alph*)]
\item $\dps \lim_{n\rightarrow\infty} f_n=g$ under the metric $d$.
\item $f_n$ \textbf{converges pointwise} to $g$, namely, $\dps\lim_{n\rightarrow\infty} f_n(i)=g(i)$ for every $i\in\Zbb_+$.
\end{enumerate}
\end{prob}

\begin{rem}
The above problem gives our first non-trivial example of function spaces  as metric spaces, where the domain of functions is a countable set. After learning series, the readers can check that 
\begin{align}
\delta(f,g)=\sum_{i\in\Zbb_+}2^{-i} d_i(f(i),g(i))   \label{eq61}
\end{align}
also defines a metric, and that (a) (with $d$ replaced by $\delta$) and (b) are equivalent. So $\delta$ and $d$ (defined by \eqref{eq16}) induce the same topology on $X$, called the \textbf{pointwise convergence topology} or simply \textbf{product topology}. Unfortunately, if the index set $\Zbb_+$ is replaced by an uncountable set, there is in general no metric inducing the product topology. We will prove this in Pb. \ref{lb203}.
\end{rem}













\begin{sprob}\label{lb194}
Let $X=\bigsqcup_{\alpha\in \scr A}X_\alpha$ be a disjoint union of metric spaces $(X_\alpha,d_\alpha)$. Assume that $d_\alpha\leq 1$ for all $i$. For each $x,y\in X$, define
\begin{gather*}
d(x,y)=\left\{
\begin{array}{ll}
d_\alpha(x,y)&\text{ if $x,y\in X_\alpha$ for some $\alpha\in\scr A$}\\[0.5ex]
\frac 12&\text{ otherwise}
\end{array}
\right.
\end{gather*}
\begin{enumerate}
\item Prove that $d$ defines a metric on $X$. 
\item Choose $(x_n)_{n\in\Zbb_+}$ in $X$ and $x\in X$. What does $\dps\lim_{n\rightarrow\infty}x_n=x$ mean in terms of the convergence in each $X_\alpha$?
\end{enumerate}
\end{sprob}

Think about the question: Let $X$ be a set. For each $x,y\in X$ define $d(x,y)=0$ if $x=y$, and $d(x,y)=1$ if $x\neq y$. What does convergence in $(X,d)$ mean?



\newpage



\section{Sequential compactness and completeness}



\subsection{Sequential compactness}


\subsubsection{Basic properties of sequentially compact spaces}

\begin{df}
Let $X$ be a metric space. We say that $X$ is \textbf{sequentially compact} \index{00@Sequentially compact} if every sequence in $X$ has a subsequence converging to some point of $X$.
\end{df}





The notion of sequential compactness is extremely useful for finding solutions in an analysis problem. In general, suppose we want to find a point $x\in X$ which makes a property $P(x)$ to be true. Suppose that we can find an ``approximate solution", i.e. an $y\in X$ such that $P(y)$ is close to being true. Thus, we can find a sequence $(x_n)$ in $X$ such that $P(x_n)$ is closer and closer to being true when $n\rightarrow\infty$. Now, if $X$ is sequentially compact, then $(x_n)$ has a subsequence $(x_{n_k})$ converging to $x\in X$. Then $P(x)$ is true, and hence $x$ is a solution for the problem. (See also Sec. \ref{lb55}.) Let us see an explicit example:

\begin{lm}[\textbf{Extreme value theorem}]\label{lb56} \index{00@EVT=Extreme value theorem}
Let $X$ be a sequentially compact metric space. Let $f:X\rightarrow\Rbb$ be a continuous function. Then $f$ attains its maximum and minimum at points of $X$. In particular, $f(X)$ is a bounded subset of $\Rbb$.
\end{lm}

This extremely important result is the main reason for introducing sequentially compact spaces. We call this a lemma, since we will substantially generalize this result later. (See Exe. \ref{lb63}.)

Note that the \textbf{boundedness} of subsets of $\Rbb$ (or more generally, of $\Rbb^N$) is always understood under the Euclidean metric of $\Rbb$, not under any metric of $\ovl\Rbb$ or $\ovl\Rbb^N$. (Recall Convention \ref{lb77}.)

\begin{proof}
We show that $f$ attains its maximum on $X$. The proof for minimum is similar. Let $A=\sup f(X)$. Then $A\in (-\infty,+\infty]$. If $A<+\infty$, then for each $n\in\Zbb_+$ there is $x_n\in X$ such that $A-1/n<f(x_n)\leq A$ (since $A-1/n$ is not an upper bound of $f(X)$). If $A=+\infty$, then for each $n$ there is $x_n\in X$ such that $f(x_n)>n$. In either case, we have a sequence $(x_n)$ in $X$ such that $f(x_n)\rightarrow A$ in $\ovl \Rbb$.

Since $X$ is sequentially compact, $(x_n)$ has a subsequence $(x_{n_k})_{k\in\Zbb_+}$ converging to some $x\in X$. Now, consider $f$ as a map $f:X\rightarrow\ovl\Rbb$, which is continuous (cf. Exp. \ref{lb54}). Since $f(x_n)\rightarrow A$, its subsequence $f(x_{n_k})$ also converges to $A$. But since $x_{n_k}\rightarrow x$ and $f$ is continuous at $x$, we have $A=f(x)$. So $f$ attains its maximum at $x$. Since $f(X)\subset\Rbb$, we have $A\in\Rbb$.
\end{proof}

The following are some elementary examples of sequential compactness:


\begin{exe}
Show that finite unions of sequentially compact spaces is sequentially compact. (In particular, a finite set is sequentially compact.) 

More precisely, let $X$ be a metric space. Assume $X=A_1\cup\cdots\cup A_N$ where each metric subspace $A_i$ is sequentially compact. Show that $X$ is sequentially compact.  
\end{exe}

\begin{pp}\label{lb72}
Let $X_1,\dots,X_N$ be sequentially compact metric spaces. Then $X=X_1\times\cdots\times X_N$ is sequentially compact.
\end{pp}

\begin{proof}
Since $X=(X_1\times\cdots\times X_{N-1})\times X_N$, by induction, it suffices to assume $N=2$. So we write $X=A\times B$ where $A,B$ are sequentially compact. Let $(a_n,b_n)$ be a sequence in $X$. Since $A$ is sequentially compact, $(a_n)$ has a convergent subsequence $(a_{n_k})$. Since $B$ is sequentially compact, $(b_{n_k})$ has a convergent subsequence $(b_{n_{k_l}})$. So $(a_{n_{k_l}},b_{n_{k_l}})$ is a convergent subsequence of $(a_n,b_n)$.
\end{proof}


\begin{pp}\label{lb62}
Let $f:X\rightarrow Y$ be a continuous  map of metric spaces. Assume that $X$ is sequentially compact. Then $f(X)$, as a metric subspace of $Y$, is sequentially compact.
\end{pp}

\begin{proof}
Choose any sequence $(y_n)$ in $f(X)$. We can write $y_n=f(x_n)$ where $x_n\in X$. Since $X$ is sequentially compact, $(x_n)$ has a subsequence $(x_{n_k})$ converging to some $x\in X$. Since $f$ is continuous, $y_{n_k}=f(x_{n_k})$ converges to $f(x)$.
\end{proof}


\begin{exe}\label{lb63}
Prove that if $Y$ is a sequentially compact subset of $\Rbb$, then $\sup Y\in Y$ and $\inf Y\in Y$. Therefore, Prop. \ref{lb62} generalizes Lem. \ref{lb56}.
\end{exe}

\begin{pp}\label{lb71}
Let $X$ be a sequentially compact metric space. Then $X$ is bounded under its metric $d$.
\end{pp}

\begin{proof}
Choose any $p\in X$. The function $d_p:x\in X\mapsto d(x,p)\in\Rbb_{\geq 0}$ is continuous by Exp. \ref{lb45}. So, by Lem. \ref{lb56}, $d_p$ is bounded by some $0<R<+\infty$. So $X=\ovl B_X(p,R)\subset B_X(p,2R)$.
\end{proof} 






\subsubsection{Limits inferior and superior, and Bolzano-Weierstrass}\label{lb69}

The goal of this subsection is to prove that closed intervals are sequentially compact. 


\begin{df}\label{lb266}
Let $(x_n)$ be a sequence in a metric space $X$. We say that $x\in X$ is a \textbf{cluster point} \index{00@Cluster point of a sequence in a metric space} of $(x_n)$, if $(x_n)$ has a subsequence $(x_{n_k})$ converging to $x$.
\end{df}

Warning: In a general topological space, the cluster points of a sequence will be defined in a different way. (See Pb. \ref{lb223} and Rem. \ref{lb267}.)





\begin{df}\label{lb60}
Let $(x_n)$ be a sequence in $\ovl\Rbb$. Define
\begin{gather}
\alpha_n=\inf\{x_k:k\geq n \}\qquad \beta_n=\sup\{x_k:k\geq  n \}
\end{gather}
It is clear that $\alpha_n\leq x_n\leq \beta_n$, that $(\alpha_n)$ is increasing and $(\beta_n)$ is decreasing. Define \index{liminfsup@$\liminf,\limsup$}
\begin{subequations}
\begin{gather}
\liminf_{n\rightarrow\infty}x_n=\sup\{\alpha_n:n\in\Zbb_+\}=\lim_{n\rightarrow\infty} \alpha_n \label{eq18}\\
\limsup_{n\rightarrow\infty}x_n=\inf\{\beta_n:n\in\Zbb_+\}=\lim_{n\rightarrow\infty} \beta_n\label{eq19}
\end{gather}
\end{subequations}
(cf. Rem. \ref{lb58}), called respectively the \textbf{limit inferior} and the \textbf{limit superior} \index{00@Limit inferior and superior} of $(x_n)$.
\end{df}

\begin{rem}
Let $(x_n),(y_n)$ be sequences in $\ovl\Rbb$. Suppose that $x_n\leq y_n$ for every $n$. It is clear that
\begin{gather*}
\liminf_{n\rightarrow\infty}x_n\leq\limsup_{n\rightarrow\infty} x_n\qquad \liminf_{n\rightarrow\infty}x_n\leq \liminf_{n\rightarrow\infty}y_n\qquad \limsup_{n\rightarrow\infty} x_n\leq \limsup_{n\rightarrow\infty} y_n
\end{gather*}
\end{rem}


\begin{thm}\label{lb68}
Let $(x_n)$ be a sequence in $\ovl\Rbb$, and let $S$ be the set of cluster points of $(x_n)$. Then $\dps\liminf_{n\rightarrow\infty}x_n$ and $\dps\limsup_{n\rightarrow\infty}x_n$ belong to $S$. They are respectively the minimum and the maximum of $S$.
\end{thm}

In particular, every sequence in $\ovl\Rbb$ has at least one cluster point.

\begin{proof}
We use the notations in Def. \ref{lb60}. Let $A=\eqref{eq18}$ and $B=\eqref{eq19}$. If $x\in S$, pick a subsequence $(x_{n_k})$ converging to $x$. Since $\alpha_{n_k}\leq x_{n_k}\leq \beta_{n_k}$, we have $A\leq x\leq B$ by Rem. \ref{lb58}. It remains to show that $A,B\in S$. We prove $B\in S$ by constructing a subsequence $(x_{n_k})$ converging to $B$; the proof of $A\in S$ is similar. 

Consider first of all the special case that $(x_n)$ is bounded, i.e., is inside $[a,b]\subset\Rbb$. Choose an arbitrary $n_1\in\Zbb_+$. Suppose $n_1<\dots<n_k$ have been constructed. By the definition of $\beta_{1+n_k}$, there is $n_{k+1}\geq 1+n_k$ such that $x_{n_{k+1}}$ is close to $\beta_{1+n_k}$, say
\begin{align}
\beta_{1+n_k}-\frac 1k<x_{n_{k+1}}\leq \beta_{1+n_k}  \label{eq17}
\end{align}
Since the left most and the right most of \eqref{eq17} both converge to $B$ as $k\rightarrow\infty$, by Squeeze theorem (Cor. \ref{lb61}) we conclude $\lim_k x_{n_k}=B$. 

In general, by Lem. \ref{lb59} and Thm. \ref{lb65}, there is an increasing (i.e. order-preserving) homeomorphism (i.e. topopogy-preserving map) $\varphi:\ovl\Rbb\rightarrow[0,1]$. Then $\varphi(\beta_n)=\sup\{\varphi(x_k):k\geq n\}$ (cf. Exe. \ref{lb66}) and $\varphi(B)=\lim_n\varphi(\beta_n)$. So $\varphi(B)=\limsup_n \varphi(x_n)$. By the above special case, $(\varphi(x_n))$ has a subsequence $(\varphi(x_{n_k}))$ converging to $\varphi(B)$. So $(x_{n_k})$ converges to $B$. 
\end{proof}

\begin{rem}
One can also prove the above general case directly using a similar idea as in the special case. And you are encouraged to do so! (Pay attention to the case $B=\pm\infty$.) 

The proof given above belongs to a classical proof pattern: To prove that a space $X$ satisfies some property, one first prove it in a convenient case. Then, in the general case, one finds an ``isomorphism" (i.e. ``equivalence" in a suitable sense) $\varphi:X\rightarrow Y$ where $Y$ is in the convenient case. Then the result on $Y$ can be translated via $\varphi^{-1}$ to $X$, finishing the proof. 

For example, to solve a linear algebra problem about linear maps between finite-dimensional vector spaces $V,W$, one first proves it in the special case that $V=\Fbb^m$ and $W=\Fbb^n$. Then, the general case can be translated to the special case via an equivalence as in Exp. \ref{lb67}.  \hfill\qedsymbol
\end{rem}


\begin{exe}\label{lb66}
Let $X,Y$ be posets. Let $\varphi:X\rightarrow Y$ be an increasing bijection whose inverse is also increasing. (Namely, $\varphi$ induces an equivalence of posets). Suppose $E\subset X$ has supremum $\sup E$. Explain why $\varphi(E)$ has supremum $\varphi(\sup E)$.
\end{exe}


It is now fairly easy to prove the famous

\begin{thm}[Bolzano-Weierstrass]\index{00@Bolzano-Weierstrass theorem}
Let $[a_1,b_1],\dots,[a_N,b_N]$ be closed intervals in $\ovl\Rbb$. Then $[a_1,b_1]\times\cdots\times [a_N,b_N]$ is sequentially compact. 
\end{thm}

\begin{proof}
By Prop. \ref{lb72}, it suffices to assume $N=1$. Write $a_1=a,b_1=b$. Let $(x_n)$ be a sequence in $[a,b]$. By Thm. \ref{lb68}, $(x_n)$ has a subsequence $(x_{n_k})$ converging to some $x\in\ovl\Rbb$. (E.g. $x=\limsup_n x_n$.) Since $a\leq x_{n_k}\leq b$, we have $a\leq x\leq b$ by Rem. \ref{lb58}.
\end{proof}

Bolzano-Weierstrass theorem illustrates why we sometimes prefer to work with $\ovl\Rbb$ instead of $\Rbb$: $\ovl\Rbb$ is sequentially compact, while $\Rbb$ is not. That every sequence has limits superior and inferior in $\ovl\Rbb$ but not necessarily in $\Rbb$ is closely related to this fact. In the language of point-set topology, $\ovl\Rbb$ is a \textbf{compactification} of $\Rbb$.


Bolzano-Weierstrass theorem (restricted to $\Rbb^N$) will be generalized to \textbf{Heine-Borel theorem}, which says that a subset of $\Rbb^N$ is sequentially compact iff it is bounded and closed (cf. Def. \ref{lb99} for the definition of closed subsets). See Thm. \ref{lb98}.





\subsubsection{A criterion for convergence in sequentially compact spaces}

At the end of Sec. \ref{lb73}, we have raised the following question: Suppose that $(x_n)$ is a bounded sequence in a metric space $X$ such that any two convergent subsequences converge to the same point. Does $(x_n)$ converge?

When $X$ is sequentially compact, $(x_n)$ is automatically bounded due to Prop. \ref{lb71}. The answer to the above question is yes:

\begin{thm}\label{lb74}
Let $X$ be a sequentially compact metric space. Let $(x_n)$ be a sequence in $X$. Then the following are equivalent.
\begin{itemize}
\item[(1)] The sequence $(x_n)$ converges in $X$.
\item[(2)] Any two convergent subsequences of $(x_n)$ converge to the same point. In other words, $(x_n)$ has only one cluster point. 
\end{itemize}
\end{thm}


\begin{proof}
(1)$\Rightarrow$(2): By Prop. \ref{lb23}.

(2)$\Rightarrow$(1): Assume that $(x_n)$ has at most one cluster point. Since $X$ is sequentially compact, $(x_n)$ has at least one cluster point $x\in X$. We want to prove $\lim_{n\rightarrow\infty} x_n=x$. Suppose not. Then there exists $\eps>0$ such that for every $N\in\Zbb_+$ there is $n\geq N$ such that $d(x_n,x)\geq \eps$. Thus, one can inductively construct a subsequence $(x_{n_k})$ of $(x_n)$ such that $d(x_{n_k},x)\geq\eps$ for all $k$. Since $X$ is sequentially compact, $(x_{n_k})$ has a subsequence $x'_n$ converging to $x'\in X$. So $d(x'_n,x)\geq\eps$ for all $n$. Since the function $y\in X\mapsto d(y,x)$ is continuous (Exp. \ref{lb45}), we have $\lim_{n\rightarrow\infty}d(x_n',x)=d(x',x)$. This proves that $d(x',x)\geq\eps>0$. However, $x',x$ are both cluster points of $(x_n)$, and so $x=x'$. This gives a contradiction. 
\end{proof}

\begin{rem}
Thm. \ref{lb74} can be used in the following way. Suppose that we want to prove that a given sequence $(x_n)$ in a sequentially compact space $X$ converges to $x$. Then it suffices to prove that if $(x_n')$ is a subsequence of $(x_n)$ converging to some $y\in X$, then $y=x$. This is sometimes easier to prove than directly proving the convergence of $(x_n)$. We will use this strategy in the proof of L'H\^opital's rule, for example. (See Subsec. \ref{lb349}.)
\end{rem}





\begin{co}\label{lb75}
Let $(x_n)$ be a sequence in $\Rbb^N$. The following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item The sequence $(x_n)$ converges in $\Rbb^N$.
\item The sequence $(x_n)$ is bounded. Moreover, any two convergent subsequences of $(x_n)$ converge to the same point of $\Rbb^N$.
\end{enumerate}
\end{co}

\begin{proof}
(1)$\Rightarrow$(2): By Prop. \ref{lb24} and \ref{lb23}. 

(2)$\Rightarrow$(1): Assume (2). Since $(x_n)$ is bounded, it can be contained in $X=I_1\times\cdots\times I_N$ where each $I_i$ is a closed interval in $\Rbb$. Clearly, any two cluster points of $(x_n)$ are inside $X$, and are equal by (2). By Bolzano-Weierstrass, $X$ is sequentially compact. Thus, by Thm. \ref{lb74}, $(x_n)$ converges in $X$ and hence in $\Rbb^N$.
\end{proof}

\begin{co}\label{lb113}
The following are true.
\begin{itemize}
\item[1.] Let $(x_n)$ be a sequence in $\ovl\Rbb$. Then $(x_n)$ converges in $\ovl\Rbb$ iff $\dps\limsup_{n\rightarrow\infty} x_n$ equals $\dps\liminf_{n\rightarrow\infty} x_n$. 
\item[2.] Let $(x_n)$ be a sequence in $\Rbb$. Then $(x_n)$ converges in $\Rbb$ iff $\dps\limsup_{n\rightarrow\infty} x_n$ equals $\dps\liminf_{n\rightarrow\infty} x_n$ and $(x_n)$ is bounded.
\end{itemize}
\end{co}

Note that if $(x_n)$ converges in $\ovl\Rbb$, we must have $\lim x_n=\limsup x_n=\liminf x_n$ by Thm. \ref{lb68}.

\begin{proof}
1. Let $A=\liminf x_n$ and $B=\limsup x_n$. Let $S$ be the set of cluster points of $(x_n)$.  By Thm. \ref{lb68}, $A=\min S,B=\max S $. So $A=B$ iff $S$ has only one element. This is equivalent to the convergence of $(x_n)$ in $\ovl\Rbb$ due to Thm. \ref{lb74} (since $\ovl\Rbb$ is sequentially compact by Bolzano-Weierstrass.)

2. If $(x_n)$ converges, then $A=B$ by part 1. And $(x_n)$ is bounded due to Prop. \ref{lb24}. Conversely, if $A=B$ and if $(x_n)$ is bounded, say $\alpha\leq x_n\leq \beta$ for all $n$ where $-\infty<\alpha<\beta<+\infty$. Then $\alpha\leq A\leq B\leq\beta$. So $A,B\in\Rbb$. By part 1, $(x_n)$ converges to $A\in\Rbb$.
\end{proof}



\subsection{Outlook: sequentially compact function spaces}


In Sec. \ref{lb55}, we mentioned that metric spaces and (more generally) point-set topology were introduced by mathematicians in order to study (typically infinite dimensional) function spaces with the help of the geometric intuition of $\Rbb^N$.  Now we have learned a couple of important results about sequentially compact spaces. But we have not met any example arising from function spaces. So let me show one example to the curious readers: The product space $[0,1]^{\Zbb_+}$, equipped with the metric defined in Pb. \ref{lb78}, is sequentially compact. We will prove this result at the end of this chapter. (Indeed, we will prove a slightly more general version. See  Thm. \ref{lb89}.) This is a famous result, not only because it has many important applications (some of which will be hinted at in this section), but also because its proof uses the clever  ``diagonal method".  

Moreover, we will later prove an even more surprising fact: every sequentially compact metric space is homeomorphic to a closed subset of $[0,1]^{\Zbb_+}$. (See Thm. \ref{lb261}.) Thus, all sequentially compact metric spaces can be constructed explicitly, in some sense.

The readers may still complain that functions on $\Zbb_+$ are very different from those we often see and use in analysis and (especially) in differential equations: We are ultimately interested in functions on $\Rbb$ or on $[a,b]$, but not on countable sets. This is correct. But $[0,1]^{\Zbb_+}$ (and its closed subsets) are in fact very helpful for the study of spaces of functions on $\Rbb$ and on $[a,b]$. In this course, we shall learn two major examples that the sequential compactness of $[0,1]^{\Zbb_+}$ helps with:
\begin{enumerate}
\item $A=\Qbb\cap[a,b]$ is a countable dense subset of $[a,b]$. Thus, if we let $C([a,b])$ denote the set of continuous $\Rbb$-functions on $[a,b]$, then the restriction map $f\in C([a,b])\mapsto f|_A\in\Rbb^A$ is injective. In many applications, we are interested in a subset $\mc X\subset C([a,b])$ of uniformly bounded functions, say all $f\in\mc X$ take values in $[-1,1]$. Then we have an injective map
\begin{align*}
\Phi:\mc X\rightarrow [-1,1]^A\qquad f\mapsto f|_A
\end{align*}
If $\mc X$ satisfies a condition called ``\textbf{equicontinuous}", then  a sequence $f_n$ in $\mc X$ converges \textit{uniformly} to $f\in C([a,b])$ iff $f_n|_A$ converges \textit{pointwise} to $f|_A$. (See Rem. \ref{lb145}.) Thus, from the sequential compactness of $[-1,1]^A$ under pointwise convergence topology, one concludes that every sequence in $\mc X$ has a subsequence converging uniformly in $C([a,b])$. This remarkable sequential compactness result on (the closure of) $\mc X$ is called \textbf{Arzel\`a-Ascoli theorem}, and will be used to prove the fundamental Peano existence theorem in ordinary differential equations. We also see that the fact that $[a,b]$ has a countable dense subset $A$ plays a crucial role. This property of metric spaces is called ``\textbf{separable}" and will be studied later.

\item \textbf{Fourier series} are powerful for the study of partial differential equations. A continuous function $f:[-\pi,\pi]\rightarrow\Cbb$ satisfying $f(-\pi)=f(\pi)$ has Fourier series expansion $f(x)=\sum_{n\in\Zbb}a_n e^{\im nx}$ where $a_n\in\Cbb$. However, for the sake of studying differential equations, one needs to consider series $\sum_{n\in\Zbb}a_n e^{\im nx}$ converging to a function much worse than a continuous function. For example, in the study of integral equations (which are closely related to certain partial differential equations), Hilbert and Schmidt discovered that one has to consider all $f(x)=\sum_{n\in\Zbb}a_n e^{\im nx}$ satisfying $\sum_n |a_n|^2\leq 1$. Therefore, one lets $\ovl B=\{z\in\Cbb:|z|\leq 1\}$ and considers $\wht f:n\in\Zbb\mapsto a_n\in\Cbb$ as an element of $\ovl B^\Zbb$. The sequential compactness of $\ovl B^\Zbb$ helps one find the $\wht f$ such that the corresponding $f(x)=\sum_n \wht f(n)\cdot e^{\im nx}$ is a desired solution of the integral equation. 
\end{enumerate}




\subsection{Complete metric spaces and Banach spaces}

In this section, we let $\Fbb\in\{\Rbb,\Cbb\}$, and assume that all vector spaces are over $\Fbb$.


\subsubsection{Cauchy sequences and complete metric spaces}

\begin{df}
A sequence $(x_n)$ in a metric space $X$ is called a \textbf{Cauchy sequence}, \index{00@Cauchy sequence}if:
\begin{itemize}
\item For every $\eps>0$  there exists $N\in\Zbb_+$ such that for all $m,n\geq N$ we have $d(x_m,x_n)<\eps$.
\end{itemize}
\end{df}

Here, ``$\eps>0$" can mean either ``$\eps\in\Rbb_{>0}$" or ``$\eps\in\Qbb_{>0}$". The choice of this meaning does not affect the definition. The above definition can be abbreviated to ``for every $\eps>0$, we have $d(x_m,x_n)<\eps$ for sufficiently large $m,n$". 

\begin{rem}
It is an easy consequence of triangle inequality that $(x_n)$ is a Cauchy sequence iff
\begin{itemize}
\item For every $\eps>0$ there exists $N\in\Zbb_+$ such that for all $n\geq N$ we have $d(x_n,x_N)<\eps$.
\end{itemize}
Also, it is clear that every Cauchy sequence is bounded.
\end{rem}


\begin{pp}\label{lb83}
Every convergent sequence in a metric space $X$ is a Cauchy sequence.
\end{pp}

\begin{proof}
Assume $(x_n)$ converges to $x$ in $X$. Then for every $\eps>0$ there is $N\in\Zbb_+$ such that $d(x,x_n)<\eps/2$ for all $n\geq N$. Since this is true for every $m\geq N$, we have $d(x_m,x_n)\leq d(x,x_n)+d(x,x_m)<\eps/2+\eps/2=\eps$.
\end{proof}


\begin{df}
A metric space $X$ is called \textbf{complete} \index{00@Complete metric space} if every Cauchy sequence in $X$ converges.
\end{df}




We have many examples of complete metric spaces:

\begin{thm}\label{lb79}
If $(x_n)$ is a Cauchy sequence in a metric space $X$ with at least one cluster point $x$, then $(x_n)$ converges in $X$ to $x$. Consequently, every sequentially compact metric space is complete.
\end{thm}

\begin{proof}
Let $(x_n)$ be a Cauchy sequence in $X$ with subsequence $(x_{n_k})$ converging to $x\in X$. Let us show that $x_n\rightarrow x$. 

Since $(x_n)$ is Cauchy, for every $\eps>0$ there is $N\in\Zbb_+$ such that $d(x_n,x_m)<\eps/2$ for all $m,n\geq N$. Since $x_{n_k}\rightarrow x$, there is $k\geq N$ such that $d(x_{n_k},x)<\eps/2$. Since $n_k$ is strictly increasing over $k$, we have $n_k\geq k$. So $n_k\geq N$. So we can let $m=n_k$. This gives $d(x_n,x_{n_k})<\eps/2$. Therefore $d(x_n,x)\leq d(x_n,x_{n_k})+d(x_{n_k},x)<\eps$ for all $n\geq N$.
\end{proof}

\begin{eg}\label{lb84}
Let  $X=[a_1,b_1]\times\cdots\times [a_N,b_N]$  where each $[a_i,b_i]$ is a closed interval in $\Rbb$, then $X$ is  sequentially compact by Bolzano-Weierstrass. Thus, by Thm. \ref{lb79}. $X$ is complete.
\end{eg}


\begin{co}\label{lb80}
$\Rbb^N$ and $\Cbb^N$ are complete (under the Euclidean metrics).
\end{co}

\begin{proof}
Since $\Cbb^N$ is isometrically isomorphic to $\Rbb^{2N}$, it suffices to prove that $\Rbb^N$ is complete. Choose a Cauchy sequence $(x_n)$ in $\Rbb^N$. Since $(x_n)$ is bounded, $(x_n)$ is contained inside $X=I_1\times\cdots\times I_N$ where each $I_i=[a,b]$ is in $\Rbb$. By Exp. \ref{lb84}, $X$ is complete. So $(x_n)$ converges to some $x\in X$.
\end{proof}





\begin{df}\label{lb99}
We say that a subset $A$ of a metric space $X$ is \textbf{closed} \index{00@Closed subset} if the following condition is true: For every sequence $(x_n)$ in $A$ converging to a point $x\in X$, we have $x\in A$.
\end{df}


Thus, the word ``closed" here means ``closed under taking limits".


\begin{pp}\label{lb86}
Let $A$ be a metric subspace of a metric space $X$. Recall  that the metric of $A$ inherits from that of $X$ (cf. Def. \ref{lb43}). Consider the statements:
\begin{enumerate}[label=(\arabic*)]
\item $A$ is complete.
\item $A$ is a closed subset of $X$.
\end{enumerate}
Then (1)$\Rightarrow$(2). If $X$ is complete, then (2)$\Rightarrow$(1).
\end{pp}


\begin{proof}
First, assume that $X$ is complete and (2) is true. Let $(x_n)$ be a Cauchy sequence in $A$. Then it is a Cauchy sequence in $X$. So $x_n\rightarrow x\in X$ because $X$ is complete. So $x\in A$ by the definition of closedness. This proves (1).

Next, we assume (1). Choose a sequence $(x_n)$ in $A$ converging to a point $x\in X$. By Prop. \ref{lb83}, $(x_n)$ is a Cauchy sequence in $X$, and hence a Cauchy sequence in $A$. Since $A$ is complete, there is $a\in A$ such that $x_n\rightarrow a$. So we must have $x=a$ because any sequence has at most one limit in a metric space. This proves $x\in A$. So (2) is proved.
\end{proof}

A similar result holds for sequential compactness. See Pb. \ref{lb90}.

\begin{eg}
Let $-\infty<a<b<+\infty$. Then $(a,b)$ is not complete (under the Euclidean metric), because $(a,b)$ is not closed in the metric space $\Rbb$. (For sufficiently large $n$, $b-1/n$ is in $(a,b)$, but $\lim_{n\rightarrow\infty} (b-1/n)=b$ is not in $b$.) 
\end{eg}

\begin{eg}
By Prop. \ref{lb2}, for each $x\in\Rbb\setminus\Qbb$, we can choose an increasing sequence in $\Qbb$ converging to $x$. So $\Qbb$ is not closed in $\Rbb$. So $\Qbb$ is not complete under the Euclidean topology.
\end{eg}


\begin{eg}\label{lb97}
Let $X$ be a metric space. Let $p\in X$ and $0\leq R<+\infty$. Then $\ovl B_X(x,R)$ is a closed subset of $X$. Therefore, if $X$ is complete, then $\ovl B_X(p,R)$ is complete by Prop. \ref{lb86}.
\end{eg}

\begin{proof}[Proof of closedness]
Let $(x_n)$ be a sequence in $\ovl B(p,R)$ converging to $x\in X$. Then $d(p,x_n)\leq R$. Since the function $y\in X\mapsto d(p,y)\in\Rbb$ is continuous (Exp. \ref{lb45}),  we have $d(p,x)=\lim_{n\rightarrow\infty}d(p,x_n)\leq R$. So $x\in\ovl B(p,R)$.
\end{proof}



\begin{exe}
Let $d,\delta$ be two equivalent metrics on a set $X$. Show that a sequence $(x_n)$ in $X$ is Cauchy under $d$ iff $(x_n)$ is Cauchy under $\delta$. 

Note that if, instead of assuming $d,\delta$ are equivalent, we only assume that $d,\delta$ are topologically equivalent. Then the above conclusion is not necessarily true:
\end{exe}


\begin{exe}
Find a non-complete metric $\delta$ on $\Rbb$ topologically equivalent to the Euclidean metric.
\end{exe}



%% Record  #3  2023/9/25  two lectures  7





\subsubsection{Normed vector spaces and Banach spaces}



A major application of complete metric spaces is to show that many series converge without knowing to what exact values these series converge. A typical example is the convergence of $\sum_{n\in\Zbb_+}\sin(\sqrt 2n)/n^2$ in $\Rbb$. We are also interested in the convergence of series in function spaces, for instance: the uniform convergence of $f(x)=\sum_{n\in\Zbb_+}\sin(\sqrt 2nx^3)/n^2$ on $\Rbb$; a suitable convergence of the Fourier series $\sum_{n\in\Zbb}a_ne^{\im n x}$. But we cannot take sum in a general metric space since it has no vector space structures. Therefore, we need a notion which combines complete metric spaces with vector spaces. Banach spaces are such a notion. 



\begin{df}\label{lb91}
Let $V$ be a vector space over $\Fbb$ with zero vector $0_V$. A function $\Vert\cdot\Vert:V\rightarrow\Rbb_{\geq 0}$ is called a \textbf{norm} \index{00@Norm} if for every $u,v\in V$ and $\lambda\in\Fbb$, the following hold:
\begin{itemize}
\item (Subadditivity) $\Vert u+v\Vert\leq \Vert u\Vert+\Vert v\Vert$. \index{00@Subadditivity}
\item (Absolute homogeneity) $\Vert\lambda v\Vert=|\lambda|\cdot \Vert v\Vert$. In particular, (by taking $\lambda=0$) we have $\Vert 0_V\Vert=0$.
\item If $\Vert v\Vert=0$ then $v=0_V$.
\end{itemize}
We call $(V,\Vert\cdot\Vert)$ (often abbreviated to $V$) a \textbf{normed vector space}. \index{00@Normed vector space}
\end{df}


\begin{rem}\label{lb367}
Assuming $\Vert 0_V\Vert=0$, to check the absolute homogeneity, it suffices to check
\begin{align*}
\Vert\lambda v\Vert\leq |\lambda|\cdot\Vert v\Vert
\end{align*}
for all $\lambda$ and $v$. Then clearly $\Vert\lambda v\Vert=|\lambda|\cdot\Vert v\Vert$ when $\lambda=0$. Suppose $\lambda\neq 0$. Then
\begin{align*}
\Vert v\Vert=\Vert \lambda^{-1}\lambda v\Vert\leq |\lambda|^{-1}\Vert\lambda v\Vert
\end{align*}
which implies $\Vert\lambda v\Vert=|\lambda|\cdot\Vert v\Vert$.
\end{rem}

\begin{rem}
Let $V$ be a vector space. If $V$ is a normed vector space, then
\begin{align}
d(u,v)=\Vert u-v\Vert  \label{eq21}
\end{align} 
clearly defines a metric. (Note that triangle inequality follows from subadditivity.) Unless otherwise stated, we always assume that the metric of a normed vector space is defined by \eqref{eq21}.
\end{rem}






\begin{df}
Let $V$ be a normed vector space. We say that $V$ is a \textbf{Banach space} \index{00@Banach space} if $V$ is a complete metric space where the metric is the canonical one \eqref{eq21}. If $V$ is over the field $\Cbb$ (resp. $\Rbb$), we call $V$ a \textbf{complex} (resp. \textbf{real}) \textbf{Banach space}.
\end{df}




\begin{eg}
We always assume that the norm on $\Fbb^N$ is the \textbf{Euclidean norm} \index{00@Euclidean norm}
\begin{align}
\Vert (a_1,\dots,a_N)\Vert=\sqrt{|a_1|^2+\cdots+|a_N|^2}
\end{align}
The canonical metric it gives is the Euclidean metric. Thus, by Cor. \ref{lb80}, $\Fbb^N$ is a Banach space.
\end{eg}



If $(\lambda_n)$ is a sequence in $\Fbb$ converging to $\lambda$, and if $(x_n)$ is a sequence in $\Fbb^N$ converging to $x$, then one can show that $\lambda_nx_n$ converges to $\lambda x$ by checking that each component of $\lambda_nx_n$ converges to the corresponding component of $\lambda x$. This is due to Prop. \ref{lb38}. However, if $(x_n)$ is in general a sequence in a normed vector space, this method fails. So we need a different argument:

\begin{pp}\label{lb82}
Let $V$ be a normed vector space. The following maps are continuous
\begin{gather*}
+: V\times V\rightarrow V\qquad (u,v)\mapsto u+v\\
-: V\times V\rightarrow V\qquad (u,v)\mapsto u-v\\
\times_\Fbb: \Fbb\times V\rightarrow V\qquad (\lambda,v)\mapsto \lambda v\\
\Vert\cdot\Vert:V\rightarrow\Rbb_{\geq 0}\qquad v\mapsto \Vert v\Vert
\end{gather*}
\end{pp}

We didn't mention the continuity of the division map $(\lambda,v)\in\Fbb^\times\times V\mapsto\lambda^{-1}v$ since it follows from that of $\times_\Fbb$ and of the inversion map $\lambda\mapsto\lambda^{-1}$ by Exp. \ref{lb35}.

\begin{proof}
One can check that the addition map, the subtraction map, and the last map $\Vert\cdot\Vert$ are Lipschitz continuous. 

Define metric $d((\lambda,v),(\lambda',v'))=\max\{|\lambda-\lambda'|,\Vert v-v'\Vert \}$ on $\Fbb\times V$. Then $\Fbb\times V$ is covered by open balls of the form $B(0,r)=\{(\lambda,v)\in\Fbb\times V:|\lambda|<r,\Vert v\Vert<r\}$. Similar to the argument in \eqref{eq22}, one uses subadditivity (i.e. triangle inequality) and absolute homogeneity to show that $\times_\Fbb$ has Lipschitz constant $2r$ on $B(0,r)$. So $\times_\Fbb$ is continuous by Lem. \ref{lb30} and \ref{lb34}.
\end{proof}








\subsection{The Banach spaces $l^\infty(X,V)$ and $C(X,V)$}


In this section, we let $\Fbb\in\{\Rbb,\Cbb\}$ and assume that the vector spaces $V$ are over $\Fbb$. As the title suggests, in this section we shall introduce two important examples of Banach spaces: the space of bounded functions $l^\infty(X,V)$ and its  subspace of continuous functions $C(X,V)$ (when $X$ is a sequentially compact metric space).  In order for these two spaces to be Banach spaces, we must assume that $V$ is also Banach. 

In application, the main examples are $V=\Rbb,\Cbb,\Rbb^N,\Cbb^N$. Indeed, $C([a,b],\Rbb^N)$ is one of the main examples of function spaces considered by Fr\'echet when he defined metric spaces. Therefore, the readers can assume that $V$ is one of such spaces if they want to make life easier. Just keep in mind that we sometimes also consider the case where $V$ itself is a function space.

\begin{df}\label{lb150}
Let $X$ be a set and let $V$ be a vector space. The set $V^X$ \index{VX@$V^X$ as a vector space} is a vector space if we define for each $f,g\in V^X$ and $\lambda\in\Fbb$:
\begin{gather*}
f+g:X\rightarrow V\qquad (f+g)(x)=f(x)+g(x)\\
\lambda f:X\rightarrow V\qquad (\lambda f)(x)=\lambda f(x)
\end{gather*}
We also define the \textbf{absolute value function}\index{00@Absolute function $\lvert f\lvert$} \index{f@$\lvert f\lvert$}
\begin{align}
|f|:X\rightarrow\Rbb_{\geq 0}\qquad x\in X\mapsto \Vert f(x)\Vert
\end{align}
The symbol $|f|$ is sometimes also written as $\Vert f\Vert$ when it will not be confused with $\Vert f\Vert_{\infty}$ or other norms of $f$.
\end{df}



\begin{df}
Let $X$ be a set and let $V$ be a normed vector space. For each $f\in V^X$, define the \index{l@$l^\infty$} \pmb{$l^\infty$}\textbf{-norm}
\begin{align}
\Vert f\Vert_{l^\infty(X,V)}\equiv\Vert f\Vert_{l^\infty}\equiv \Vert f\Vert_\infty=\sup_{x\in X}\Vert f(x)\Vert
\end{align}
where $\Vert f(x)\Vert$ is defined by the norm of $V$. Define the \pmb{$l^\infty$}\textbf{-space} \index{l@$l^\infty(X,V)$} 
\begin{align}
l^\infty(X,V)=\{f\in V^X:\Vert f\Vert_\infty<+\infty\}
\end{align}
which is a vector subspace of $V^X$. Then $l^\infty(X,V)$ is a normed vector space under the $l^\infty$-norm. A function $f:X\rightarrow V$ is called \textbf{bounded} \index{00@Bounded function} if $f\in l^\infty(X,V)$.
\end{df}





\begin{exe}\label{lb143}
Prove that for every $f,g\in V^X$ and $\lambda\in\Fbb$ we have
\begin{gather}\label{eq23}
\begin{gathered}
\Vert f+g\Vert_\infty\leq \Vert f\Vert_\infty+\Vert g\Vert_\infty\\
\Vert \lambda f\Vert_\infty=|\lambda|\cdot \Vert f\Vert_\infty
\end{gathered}
\end{gather}
(Note that clearly we have that $\Vert f\Vert_\infty=0$ implies $f=0$.) Here, we understand $0\cdot (+\infty)=0$. Use these relations to verify that $l^\infty(X,V)$ is a linear subspace of $V^X$ (i.e. it is closed under addition and scalar multiplication) and that $\Vert\cdot\Vert_\infty$ is a norm on $l^\infty(X,V)$.  \hfill\qedsymbol
\end{exe}

\begin{df}\label{lb148}
Let $V$ be a normed vector space. We say that a sequence $(f_n)$ in $V^X$ \textbf{converges uniformly} \index{00@Uniform convergence} to $f\in V^X$ if $\lim_{n\rightarrow\infty}\Vert f-f_n\Vert_\infty=0$. In this case, we write ${f_n}\rightrightarrows f$. \index{fnf@$f_n\rightrightarrows f$}

We say that $(f_n)$ \textbf{converges pointwise} \index{00@Pointwise convergence} to $f\in V^X$ if for every $x\in X$ we have $\lim_{n\rightarrow\infty} f_n(x)=f(x)$, i.e. $\lim_{n\rightarrow\infty} \Vert f_n(x)-f(x)\Vert=0$. 

The same definition will be applied to nets $(f_\alpha)_{\alpha\in I}$ in $V^X$ after learning net convergence in Sec. \ref{lb147}. \hfill\qedsymbol
\end{df}


In more details, the uniform convergence of $f_n$ to $f$ means that ``for every $\eps>0$ there is $N\in\Zbb_+$ such that for all $n\geq N$ and  \textit{for all $x\in X$}, we have $\Vert f_n(x)-f(x)\Vert<\eps$". If we place the words ``for all $x\in X$" at the very beginning of the sentence, we get pointwise convergence.


Uniform convergence implies pointwise convergence: If $\Vert f-f_n\Vert_\infty\rightarrow 0$, then for each $x\in X$ we have $\Vert f_n(x)-f(x)\Vert\rightarrow 0$ since $\Vert f(x)-f_n(x)\Vert\leq\Vert f-f_n\Vert_\infty$. 



\begin{eg}
Let $f_n:(0,1)\rightarrow\Rbb$ be $f_n(x)=x^n$. Then $f_n$ converges pointwise to $0$ (cf. Exp. \ref{lb110}). But $\sup_{x\in(0,1)}|x^n-0|=1$ does not converge to $0$. So $f_n$ does not converge uniformly to $0$.
\end{eg}



\begin{rem}
The uniform convergence of sequences in $l^\infty(X,V)$ is induced by the $l^\infty$-norm, and hence is induced by the metric $d(f,g)=\Vert f-g\Vert_\infty$. However, this formula cannot be extended to a metric on $V^X$, since for arbitrary $f,g\in V^X$, $\Vert f-g\Vert_\infty$ is possibly $+\infty$. 



In fact, it is true that the uniform convergence of sequences in $V^X$ is induced by a metric, see Pb. \ref{lb81}. When $X$ is countable, we have seen in Pb. \ref{lb78} that the pointwise convergence in $V^X$ is also given by a metric. \hfill\qedsymbol
\end{rem}












\begin{thm}\label{lb85}
Let $X$ be a set, and let $V$ be a Banach space (over $\Fbb$). Then $l^\infty(X,V)$ is a Banach space (over $\Fbb$).
\end{thm}


\begin{proof}
Let $(f_n)$ be a Cauchy sequence in $l^\infty(X,V)$. Then for every $\eps>0$ there is $N\in\Zbb_+$ such that for all $m,n\geq N$ we have that $\sup_{x\in X}\Vert f_n(x)-f_m(x)\Vert <\eps$, and hence $\Vert f_n(x)-f_m(x)\Vert <\eps$ for each $x\in X$. This shows that for each $x\in X$, $(f_n(x))$ is a Cauchy sequence in $V$, which converges to some element $f(x)\in V$ because $V$ is complete.

We come back to the statement that for each $\eps>0$, there exists $N\in\Zbb_+$ such that for all $n\geq N$ and all $x$,
\begin{align*}
\Vert f_n(x)-f_m(x)\Vert <\eps  
\end{align*}
for every $m\geq N$. Let $m\rightarrow\infty$. Then by the continuity of subtraction and taking norm (cf. Prop. \ref{lb82}.), we obtain $\Vert f_n(x)-f(x)\Vert\leq \eps$ for all $n\geq N$ and $x\in X$. In other words, $\Vert f_n-f\Vert_\infty\leq\eps$ for all $n\geq N$. In particular, $\Vert f\Vert_\infty\leq\Vert f_N\Vert_\infty +\Vert f_N-f\Vert_\infty<+\infty$ by \eqref{eq23}. This proves $f\in l^\infty(X,V)$ and $f_n\rightrightarrows f$.
\end{proof}


Mathematicians used to believe that ``if a sequence of continuous functions $f_n:[0,1]\rightarrow\Rbb$ converges pointwise to a function $f:[0,1]\rightarrow\Rbb$, then $f$ is continuous". Cauchy, one of the main figures in 19th century working on putting analysis on a rigorous ground, has given a problematic proof of this wrong statement. Counterexamples were later found in the study of Fourier series: Let $f:\Rbb\rightarrow\Rbb$ be a function with period $2\pi$ such that $f(x)=x$ when $-\pi<x<\pi$, and $f(x)=0$ when $x=\pm \pi$. Then the Fourier series  of this noncontinuous function $f$ converges pointwise to $f$, yet the partial sums of this series are clearly continuous functions. Later, it was realized that uniform convergence is needed to show the continuity of the limit function. (See Thm. \ref{lb87}.) This was the first time the importance of uniform convergence was realized.



The following discussions about (resp. sequentially compact) metric spaces also apply to general (resp. compact) topological spaces. The reader can come back and check the proofs for these more general spaces after studying them in the future.

\begin{df}
Let $X,Y$ be  metric spaces (resp. topological spaces). Then $C(X,Y)$ \index{CXY@$C(X,Y)$, the set of continuous functions $X\rightarrow Y$. See Conv. \ref{lb85} also} denotes the set of continuous functions from $X$ to $Y$. 
\end{df}


\begin{lm}
Let $X$ be a metric space (resp. a topological space), and let $V$ be a normed vector space. Then $C(X,V)$ is a linear subspace of $V^X$. If $X$ is sequentially compact (resp. compact), then $C(X,V)$ is a linear subspace of $l^\infty(X,V)$.
\end{lm}

\begin{proof}
Using Prop. \ref{lb82}, one checks easily that $C(X,V)$ is a linear subspace of $V^X$.  For any $f\in C(X,V)$, the absolute value function $|f|:x\in X\mapsto\Vert f(x)\Vert$ is continuous. Thus, assuming that $X$ is sequentially compact, then by Lem. \ref{lb56}, $|f|$ is bounded on $X$. This proves that $\Vert f\Vert_\infty<+\infty$. Thus $C(X,V)$ is a subset (and hence a linear subspace) of $l^\infty(X,V)$. 
\end{proof}



\begin{thm}\label{lb87}
Let $X$ be a metric space (resp. a topological space), and let $V$ be a normed vector space. Then $C(X,V)\cap l^\infty(X,V)$ is a closed linear subspace of $l^\infty(X,V)$. In particular, if $X$ is sequentially compact (resp. compact), then $C(X,V)$ is a closed linear subspace of $l^\infty(X,V)$.
\end{thm}



\begin{proof}
Choose a sequence $(f_n)$ in $C(X,V)\cap l^\infty(X,V)$ converging in $l^\infty(X,V)$ to $f$. Namely, $f_n\rightrightarrows f$. We want to prove that $f$ is continuous. We check that $f$ satisfies Def. \ref{lb31}-(2'). (One can also use Def. \ref{lb31}-(1). The proofs using these two definitions are not substantially different.)

Fix $p\in X$. Choose any $\eps>0$. Since $f_n\rightrightarrows f$, there exists $N\in\Zbb_+$ such that for all $n\geq N$ and we have $\Vert f-f_n\Vert_\infty<\eps$. Since $f_N$ is continuous, there exists $r>0$ such that for each $x\in B_X(p,r)$ we have $\Vert f_N(x)-f_N(p)\Vert<\eps$. Thus, for each $x\in B_X(p,r)$ we have
\begin{align*}
\Vert f(x)-f(p)\Vert\leq \Vert f(x)-f_N(x)\Vert +\Vert f_N(x)-f_N(p)\Vert+\Vert f_N(p)-f(p)\Vert<3\eps
\end{align*}
This finishes the proof.
\end{proof}





\begin{cv}\label{lb88}
Unless otherwise stated, if $X$ is sequentially compact metric space (or more generally, a compact topological space to be defined latter), and if $V$ is a normed vector space, the norm on $C(X,V)$ is chosen to be the $l^\infty$-norm.
\end{cv}


\begin{co}\label{lb101}
Let $X$ be a metric space  (resp. a topological space), and let $V$ be a Banach space. Then  $C(X,V)\cap l^\infty(X,V)$ is a Banach space under the $l^\infty$-norm. In particular, if $X$ is sequentially compact (resp. compact), then $C(X,V)$ is a Banach space.
\end{co}

\begin{proof}
This follows immediately from Prop. \ref{lb86}, Thm. \ref{lb87}, and the fact that $l^\infty(X,V)$ is complete (Thm. \ref{lb85}).
\end{proof}










\subsection{Problems and supplementary material}



\begin{prob}\label{lb64}
Let $(x_n)$ be a sequence in a metric space $X$. Let $x\in X$. Prove that the following are equivalent.
\begin{itemize}
\item[(1)] $x$ is the limit of a convergent subsequence of $(x_n)$.
\item[(2)] For each $\eps>0$ and each $N\in\Zbb_+$, there exists $n\geq N$ such that $d(x_n,x)<\eps$.
\end{itemize}
Any $x$ satisfying one of the above two statements is called a \textbf{cluster point}\index{00@Cluster point of a sequence in a metric space} of $(x_n)$.
\end{prob}

\begin{rem}
In a general topological space $X$, we say that $x$ is a cluster point of the sequence $(x_n)$ if it satisfies condition (2) of Pb. \ref{lb64}. This is equivalent to saying that $(x_n)$ has a \textit{subnet} converging to $x$. (See Pb. \ref{lb223} for details.) 

Therefore, if $X$ is metrizable, then $(x_n)$ has a subsequence converging to $x$ iff $(x_n)$ has a subnet converging to $x$. However, when $X$ is not metrizable,  the latter does not necessarily imply the former; in other words, we only have (1)$\Rightarrow$(2) but not necessarily (2)$\Rightarrow$(1) in Pb. \ref{lb64}.  \hfill\qedsymbol
\end{rem}

\begin{rem}
Condition (2) is often abbreviated to ``for each $\eps>0$, the sequence $(x_n)$ is frequently in $B(x,\eps)$". In general, we say ``$(x_n)$ \textbf{frequently} satisfies P" if for each $N\in\Zbb_+$ there is $n\geq N$ such that $x_n$ satisfies P. We say that ``$(x_n)$ \textbf{eventually} satisfies P" if there exists $N\in\Zbb_+$ such that for every $n\geq N$, $x_n$ satisfies P. \index{00@Eventually} \index{00@Frequently}  

Thus ``$(x_n)$ eventually satisfies P" means the same as ``all but finitely many $x_n$ satisfies P". Its negation is ``$(x_n)$ frequently satisfies $\neg$P".   \hfill\qedsymbol
\end{rem}

\begin{rem}
Condition (2) of Pb. \ref{lb64} is sometimes easier to use than (1). For example, compared to the original definition of cluster points, it is much easier to find an explicit negation of (2) by using the rule suggested in Rem. \ref{lb100}: There exist $\eps>0$ and $N\in\Zbb_+$ such that $d(x_n,x)\geq\eps$ for all $n\geq N$. (Or simply: there exists $\eps>0$ such that $x_n$ is eventually not in $B(x,\eps)$.) 
\end{rem}



\begin{prob}\label{lb70}
Use Pb. \ref{lb64}-(2) to prove that if $(x_n)$ is a sequence in $\ovl\Rbb$, then $\dps\limsup_{n\rightarrow\infty} x_n$ is a cluster point of $(x_n)$.
\end{prob}

\begin{rem}
You will notice that your proof of Pb. \ref{lb70} is slightly simpler than the proof we gave for Thm. \ref{lb68}. This is because our construction of subsequence as in \eqref{eq17} has been incorporated into your proof of (2)$\Rightarrow$(1) in Pb. \ref{lb64}.
\end{rem}

\begin{prob}\label{lb235}
Let $f:X\rightarrow Y$ be a continuous map of metric spaces. Assume that $f$ is bijective and $X$ is sequentially compact.  Prove that $f$ is a homeomorphism using the following hint.
\end{prob}

\begin{proof}[Hint]
You need to prove that if $(y_n)$ is a sequence in $Y$ converging to $y\in Y$, then $x_n=f^{-1}(y_n)$ converges to $x=f^{-1}(y)$. Prove that $(x_n)$ has only one cluster point, and hence converges to some point $x'\in X$ (why?). Then prove $x'=x$. (In the future, we will use the language of open sets and closed sets to prove this result again. Do not use this language in your solution.)
\end{proof}




\begin{thm}[\textbf{Tychonoff theorem, countable version}]\index{00@Tychonoff theorem, countable version}  \label{lb89}
Let $(X_n)_{n\in\Zbb_+}$ be a sequence of sequentially compact metric spaces. Then the product space $\dps S=\prod_{n\in\Zbb_+} X_n$ is sequentially compact under the metric defined  as in Pb. \ref{lb78}.
\end{thm}

The method of choosing subsequence in the following proof is the reknowned \textbf{diagonal method}. \index{00@Diagonal method} A different method will be given in Pb. \ref{lb241}.

\begin{proof}
Let $(x_m)_{m\in\Zbb_+}$ be a sequence in $S$. Since $(x_m(1))_{m\in\Zbb_+}$ is a sequence in the sequentially compact space $X_1$, $(x_m)_{m\in\Zbb_+}$ has a subsequence $x_{1,1},x_{1,2},x_{1,3}\dots$ whose value at $n=1$ converges in $X_1$. Since $X_2$ is sequentially compact, we can choose a subsequence $x_{2,1},x_{2,2},x_{2,3},\dots$ of the previous subsequence such that its values at $n=2$ converge in $X_2$. Then pick a subsequence from the previous one whose values at $3$ converge in $X_3$. 

By repeating this process, we get an $\infty\times\infty$ matrix $(x_{i,j})_{i,j\in\Zbb_+}$:
\begin{equation}
\begin{tikzcd}[sep=0cm]
{x_{1,1}} & {x_{1,2}} & {x_{1,3}} & \cdots \\
{x_{2,1}} & {x_{2,2}} & {x_{2,3}} & \cdots \\
{x_{3,1}} & {x_{3,2}} & {x_{3,3}} & \cdots \\
\vdots    & \vdots    & \vdots    & \ddots
\end{tikzcd}
\end{equation}
such that the following hold:
\begin{itemize}
\item The $1$-st line is a subsequence of the original sequence $(x_m)_{m\in\Zbb_+}$.
\item The $(i+1)$-th line is a subsequence of the $i$-th line.
\item For each $n$, $\lim_{j\rightarrow\infty} x_{n,j}(n)$ converges in $X_n$.
\end{itemize}
Then the diagonal line $(x_{i,i})_{i\in\Zbb_+}$ is a subsequence of the original sequence $(x_m)_{m\in\Zbb_+}$. Moreover, for each $n$, $(x_{i,i})_{i\geq n}$ is a subsequence of the $n$-th line, whose value at $n$ therefore converges in $X_n$. Thus $\lim_{i\rightarrow\infty} x_{i,i}(n)$ converges in $X_n$. Thus, by Pb. \ref{lb78}, $(x_{i,i})_{i\in\Zbb_+}$ converges under any metric inducing the product topology.
\end{proof}




\begin{prob}\label{lb90}
Let $X$ be a sequentially compact metric space. Let $A\subset X$ be a metric subspace.  Consider the statements:
\begin{enumerate}[label=(\arabic*)]
\item $A$ is sequentially compact.
\item $A$ is a closed subset of $X$.
\end{enumerate}
Prove that (1)$\Rightarrow$(2). Prove that if $X$ is sequentially compact, then (2)$\Rightarrow$(1).
\end{prob}


The above problem implies immediately:

\begin{thm}[\textbf{Heine-Borel theorem}]\label{lb98}  \index{00@Heine-Borel theorem} 
Let $A$ be a subset of $\Rbb^N$. Then $A$ is sequentially compact iff $A$ is a bounded closed subset of $\Rbb^N$.
\end{thm}

\begin{proof}
Suppose that $A$ is sequentially compact. Then $A$ is bounded under the Euclidean metric by Prop. \ref{lb71}. By Pb. \ref{lb90}, $A$ is a closed subset of $\Rbb^N$.

Conversely, assume that $A$ is a bounded and closed subset of $\Rbb^N$. Then $A\subset B$ where $B$ is the product of $N$ pieces of closed intervals in $\Rbb$. Then $B$ is sequentially compact by Bolzano-Weierstrass. Since $A$ is closed in $\Rbb^N$, it is not hard to check that $A$ is closed in $B$.\footnote{If $Z$ is a metric space, if $X\subset Y\subset Z$, and if $X$ is closed in $Z$, then it is easy to check that $X$ is closed in $Y$.} Thus $A$ is sequentially compact by Pb. \ref{lb90}.
\end{proof}




\begin{eg}
Choose any $p\in \Rbb^N$ and $0\leq R<+\infty$. Then $\ovl B_{\Rbb^N}(p,R)$ is a bounded closed subset of $\Rbb^N$ (Exp. \ref{lb97}), and hence is sequentially compact by Heine-Borel.
\end{eg}

\begin{rem}
Think about the question: Equip $\Rbb^{\Zbb_+}$ with metric
\begin{align*}
d(x,y)=\sup_{n\in\Zbb_+}\frac {\min\{|x(n),y(n)|,1\}}{n}
\end{align*} 
What are the sequentially compact subsets of $\Rbb^{\Zbb_+}$? (Namely, think about how to generalize Heine-Borel theorem to $\Rbb^{\Zbb_+}$.)
\end{rem}



\begin{prob}
Do Exercise \ref{lb143}.
\end{prob}




\begin{prob}\label{lb81}
Let $V$ be a normed vector space. For every $f,g\in V^X$ define
\begin{align}
d(f,g)=\min\{1,\Vert f-g\Vert_\infty \}\label{eq55}
\end{align}
\begin{enumerate}
\item Show that $d$ defines a metric on $V^X$. 
\item Show that for every sequence $(f_n)$ in $V^X$ and every $g\in V^X$, we have $f_n\rightarrow g$ under the metric $d$ iff $f_n\rightrightarrows g$.
\end{enumerate}
\end{prob}

\begin{df}\label{lb146}
Let $X$ be a set, and let $V$ be a normed vector space. A metric on $V^X$ is called a \textbf{uniform convergence metric} \index{00@Uniform convergence metric} if it is equivalent to \eqref{eq55}. Thus, by Def. \ref{lb144}, a uniform convergence metric is one such that a sequence $(f_n)$ in $V^X$ converges to $f$ under this metric iff $f_n\rightrightarrows f$.
\end{df}




\begin{prob}\label{lb103}
Let $X,Y$ be metric spaces, and assume that $Y$ is sequentially compact. Let $V$ be a normed vector space. Choose $f\in C(X\times Y,V)$, i.e., $f:X\times Y\rightarrow V$ is continuous. For each $x\in X$, let
\begin{align*}
f_x:Y\rightarrow V\qquad y\mapsto f(x,y)
\end{align*}
Namely $f_x(y)=f(x,y)$. It is easy to check that $f_x\in C(Y,V)$. Define a new function
\begin{gather}
\begin{gathered}
\Phi(f):X\rightarrow C(Y,V)\qquad x\mapsto f_x
\end{gathered}
\end{gather}
Recall that $C(Y,V)$ is equipped with the $l^\infty$-norm. 
\begin{enumerate}
\item Prove that $\Phi(f)$ is continuous. In other words, prove that if $(x_n)$ is a sequence in $X$ converging to  $x\in X$, then $f_{x_n}\rightrightarrows f_x$ on $Y$, i.e.
\begin{align*}
\lim_{n\rightarrow\infty}\Vert f_{x_n}-f_x\Vert_{l^\infty(Y,V)}=0
\end{align*}
\item[$\star$ 2.]  Give an example of $f\in C(X\times Y,\Rbb)$ where $Y$ is not sequentially compact, $(x_n)$ converges to $x$ in $X$, and $f_{x_n}$ does not converge uniformly to $f_x$. (Note: you may consider $X=Y=\Rbb$.)
\end{enumerate}

\end{prob}

\begin{proof}[Hint]
In part 1, to prove that $\Phi(f)$ is continuous,   one can  prove the equivalent fact that for every fixed $x\in X$ the following is true:
\begin{itemize}
\item For every $\eps>0$ there exists $\delta>0$ such that for all $p\in B_X(x,\delta)$, we have $\sup_{y\in Y}\Vert f(p,y)-f(x,y)\Vert<\eps$. 
\end{itemize}
(Cf. Def. \ref{lb31}.) Prove this by contradiction and by using the sequential compactness of $Y$ appropriately.
\end{proof}


\begin{rem}\label{lb102}
Let $X=\Zbb_+\cup\{\infty\}$, equipped with the metric
\begin{align*}
d(m,n)=|m^{-1}-n^{-1}|
\end{align*} 
In other words, the metric on $X$ is $\tau^*d_\Rbb$ where $d_\Rbb$ is the Euclidean metric on $\Rbb$, and $\tau:X\rightarrow \Rbb,n\mapsto n^{-1}$. It is not hard to show that $X$ is sequentially compact: either prove it directly, or apply Heine-Borel to $\tau(X)$.

Let $Y$ be a metric space. Let $(y_n)_{n\in\Zbb_+}$ be a sequence in $Y$, and let $y_\infty\in Y$. It is not hard to see that the following two statements are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item The function $F:X\rightarrow Y,n\mapsto y_n$ is continuous.
\item The sequence $(y_n)_{n\in\Zbb_+}$ converges to $y_\infty$.
\end{enumerate}
The following problem is a generalization of this equivalence.  \hfill\qedsymbol
\end{rem}



\begin{sprob}\label{lb104}
Let $V$ be a normed vector space. Let $Y$ be a metric space. Let $X=\Zbb_+\cup\{\infty\}$ with metric defined as in Rem. \ref{lb102}. Let $(f_n)_{n\in\Zbb_+}$ be a sequence in $C(Y,V)$. Let $f_\infty\in V^Y$. Prove that the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item The following function is continuous:
\begin{align}
F:X\times Y\rightarrow V\qquad (n,y)\mapsto f_n(y)
\end{align}
In particular, by restricting $F$ to $\infty\times Y$, we see that $f_\infty\in C(Y,V)$.
\item $(f_n)_{n\in\Zbb_+}$ converges pointwise to $f_\infty$. Moreover, $(f_n)_{n\in\Zbb_+}$ is \textbf{pointwise equicontinuous}, \index{00@Pointwise equicontinuous} which means the following:
\begin{itemize}
\item For every $y\in Y$ and every $\eps>0$, there exists $\delta>0$ such that for all $p\in B_Y(y,\delta)$ we have
\begin{align*}
\sup_{n\in\Zbb_+}\Vert f_n(p)-f_n(y)\Vert<\eps
\end{align*}
\end{itemize}
\end{enumerate}
\end{sprob}

\begin{proof}[Note]\renewcommand{\qedsymbol}{}
In part (1), the only nontrivial thing to prove  is that $F$ is continuous at $(\infty,y)$ for every $y\in Y$.
\end{proof}





\begin{rem}
There is a concise way to define pointwise equicontinuity: a sequence $(f_n)_{n\in\Zbb_+}$ in $V^Y$ is pointwise equicontinuous iff the function
\begin{gather}
Y\mapsto V^{\Zbb_+}\qquad y\mapsto (f_1(y),f_2(y),\dots)
\end{gather}
is continuous, where $V^{\Zbb_+}$ is equipped with any uniform convergence metric (cf. Def. \ref{lb146}). 
\end{rem}

\begin{srem}
In Pb. \ref{lb104}, there is a quick and tricky way to conclude (1)$\Rightarrow$(2): Use Pb. \ref{lb103} and the sequential compactness of $X$. (Do not use this method in your solution. Prove (1)$\Rightarrow$(2) directly; it is a good exercise and is not difficult.)
\end{srem}



\begin{srem}\label{lb145}
Pb. \ref{lb103} and \ref{lb104}, together with Thm. \ref{lb87}, imply the following fact (can you see why?): 
\begin{itemize}
\item Let $Y$ be a sequentially compact metric space. Let $V$ be a normed vector space. Let $(f_n)_{n\in\Zbb_+}$ be a pointwise equicontinuous sequence of functions $Y\rightarrow V$ converging pointwise to some $f:Y\rightarrow V$. Then $f_n\rightrightarrows f$ on $Y$. 
\end{itemize}
You can also try to give a straightforward proof of this fact without using Pb. \ref{lb103} and \ref{lb104}.
\end{srem}








\newpage




\section{Series}

In this chapter, we assume that vector spaces are over $\Fbb\in\{\Rbb,\Cbb\}$ unless otherwise stated.





\subsection{Definitions and basic properties}


\begin{df}
Let $V$ be a Banach space (over $\Fbb$). A \textbf{series} \index{00@Series in a Banach space} in $V$ is an expression of the form
\begin{align}
\sum_{i=1}^\infty v_i  \label{eq25}
\end{align}
where $(v_i)_{i\in\Zbb_+}$ is a sequence in $V$. If $s\in V$, we say that the series \eqref{eq25} \textbf{converges to $s$} if
\begin{align*}
s=\lim_{n\rightarrow\infty} \sum_{i=1}^n v_i
\end{align*}
namely, $s_n\rightarrow s$ where $s_n$ is the \textbf{partial sum} \index{00@Partial sum} $s_n=\sum_{i=1}^n v_i$. In this case, we write
\begin{align*}
s=\sum_{i=1}^\infty v_i
\end{align*}
\end{df}


\begin{rem}\label{lb93}
Since $V$ is complete, the series \eqref{eq25} converges iff the sequence of partial sum $(s_n)$ is a Cauchy sequence: for every $\eps>0$ there exists $N\in\Zbb_+$ such that for all $n> m\geq N$ we have $\Vert s_n-s_m\Vert<\eps$, i.e.,
\begin{align}
\Big\Vert \sum_{i=m+1}^n v_i\Big\Vert<\eps  \label{eq28}
\end{align}
\end{rem}


\begin{pp}\label{lb92}
Suppose that $\sum_{i=1}^\infty v_i$ is a convergent series in a Banach space $V$. Then $\dps\lim_{n\rightarrow\infty} v_n=0$.
\end{pp}

\begin{proof}
Let $s_n=v_1+\cdots+v_n$, which converges to $s\in V$. Then $\lim_{n\rightarrow\infty} s_{n+1}=s$. So $v_n=s_{n+1}-s_n\rightarrow s-s=0$ since subtraction in continuous (Prop. \ref{lb82}).
\end{proof}

Thus, for example, $\sum_{n=1}^\infty (-1)^n$ diverges in the Banach space $\Rbb$ since $\lim_{n\rightarrow\infty} (-1)^n$ does not converge to $0$.





\begin{df}
Consider a \textbf{series} in $\ovl\Rbb_{\geq0}$: \index{00@Series in $\ovl\Rbb_{\geq0}$}
\begin{align}
\sum_{i=1}^\infty a_i \label{eq26}
\end{align}
namely, each $a_i$ is in $\ovl\Rbb_{\geq 0}$. Note that the partial sum $s_n=\sum_{i=1}^n a_i$ is increasing. We say that $\lim_{n\rightarrow\infty} s_n$ (which exists in $\ovl\Rbb_{\geq0}$ and equals $\sup\{s_n:n\in\Zbb_+\}$, cf. Rem. \ref{lb58}) is the value of the series \eqref{eq26} and write
\begin{align*}
\sum_{i=1}^\infty a_i=\lim_{n\rightarrow\infty} s_n
\end{align*}
\end{df}


\begin{df}
We say that a series $\sum_{i=1}^\infty a_i$ in $\Rbb_{\geq 0}$ \textbf{converges} if it converges in $\Rbb$ (but not just converges in $\ovl\Rbb_{\geq 0}$, which is always true). Clearly, $\sum_{i=1}^\infty a_i$ converges iff
\begin{align*}
\sum_{i=1}^\infty a_i<+\infty
\end{align*}
More generally, we say that a series $\sum_{i=1}^\infty v_i$ in a Banach space $V$ \textbf{converges absolutely}, \index{00@Absolute convergent series} if
\begin{align*}
\sum_{i=1}^\infty~ \Vert v_i\Vert <+\infty
\end{align*}
\end{df}

\begin{rem}
By the Cauchy condition of convergence, $\sum_{i=1}^\infty v_i$ converges absolutely iff for every $\eps>0$ there exists $N\in\Zbb_+$ such that for all $n> m\geq N$ we have 
\begin{align}
\sum_{i=m+1}^n~\Vert v_i\Vert<\eps \label{eq27}
\end{align}
By comparing \eqref{eq27} with \eqref{eq28} and using the subadditivity of the norm (recall Def. \ref{lb91}), we immediately see:
\end{rem}

\begin{pp}\label{lb94}
Let $\sum_{i=1}^\infty v_i$ be a series in a Banach space. The following are true.
\begin{enumerate}
\item If $\sum_{i=1}^\infty v_i$ converges absolutely, then it converges.
\item For each $i$ we choose $a_i\in\Rbb_{\geq0}$ satisfying $\Vert v_i\Vert\leq a_i$. Suppose that $\sum_{i=1}^\infty a_i<+\infty$. Then $\sum_{i=1}^\infty v_i$ converges absolutely.
\end{enumerate}
\end{pp}

\begin{proof}
Part 1 has been explained above. In part 2, we have $\sum\Vert v_i\Vert \leq \sum a_i<+\infty$. So $\sum v_i$ converges absolutely.
\end{proof}


\begin{exe}
Suppose that $\sum_{i=1}^\infty u_i$ and $\sum_{i=1}^\infty v_i$ are convergent (resp. absolutely convergent) series in a Banach space $V$. Let $\lambda\in\Fbb$. Show that the LHS of the following equations converges (resp. converges absolutely) in $V$, and that the following equations hold:
\begin{gather*}
\sum_{i=1}^\infty (u_i+v_i)=\sum_{i=1}^\infty u_i+\sum_{i=1}^\infty v_i\\
\sum_{i=1}^\infty \lambda v_i=\lambda\cdot\sum_{i=1}^\infty v_i
\end{gather*}
\end{exe}


\begin{rem}
We have seen that absolute convergence implies convergence. In fact, at least when $V=\Fbb^N$, absolute convergence is in many ways more natural than convergence. For example, we will learn that if a series $\sum_i v_i$ in $\Fbb^N$ converges absolutely, then the value of $\sum_i v_i$ is invariant under rearrangement of the series: for every bijection $\varphi:\Zbb_+\rightarrow\Zbb_+$ we have $\sum_i v_i=\sum_i v_{\varphi(i)}$. In the next semester, we shall learn Lebesgue integral theory and, more generally, measure theory. When applying measure theory to infinite sums over the countable set $\Zbb_+$, many good results (e.g. dominated convergence theorem, Fubini's theorem)  hold only for absolute convergence series, but not for arbitrary convergent series in general. In fact, there is no analog of convergent (but not absolutely convergent) series in measure theory at all!

When $V$ is not necessarily finite-dimensional, the situation is subtler: there is a version of convergence which lies between the usual convergence and absolute convergence, and which coincides with absolute convergence when $V=\Fbb^N$. This version of convergence is defined using nets instead of sequences. Moreover, many good properties (as mentioned above) hold for this convergence, and these properties can be proved in a very conceptual way (rather than using brute-force computation). We will learn this convergence in the next chapter.   \hfill\qedsymbol
\end{rem}



\subsection{Basic examples}


Let us study the \textbf{geometric series} $\sum_{n=0}^\infty z^n$ where $z\in\Cbb$. We first note the famous \textbf{binomial formula}: \index{00@Binomial formula} for each $z,w\in\Cbb$ and $n\in\Nbb$,
\begin{align}
(z+w)^n=\sum_{k0}^n{n\choose k}z^kw^{n-k}  \label{eq60}
\end{align}
In particular,
\begin{align}
(1+z)^n=1+nz+\frac{n(n-1)}{2}z^2+\frac{n(n-1)(n-2)}6 z^3+\cdots+nz^{n-1}+z^n \label{eq29}
\end{align}


\begin{eg}\label{lb110}
Assume $z\in\Cbb$ and $|z|<1$. Then $\lim_{n\rightarrow\infty}z^n=0$. 
\end{eg}

\begin{proof}
If $z=0$ then it is obvious. Assume that $0<|z|<1$. Choose $\delta>0$ such that $|z|=1/(1+\delta)$. By \eqref{eq29}, $(1+\delta)^n\geq 1+n\delta$. So
\begin{align*}
0\leq |z^n|\leq (1+n\delta)^{-1}
\end{align*}
Since $\dps\lim_{n\rightarrow\infty} (1+n\delta)^{-1}=0$, we have $|z^n|\rightarrow0$ by squeeze theorem. Hence $z^n\rightarrow0$.
\end{proof}

\begin{eg}\label{lb106}
Let $z\in\Cbb$. If $|z|<1$, then $\dps\sum_{n=0}^\infty z^n$ converges absolutely, and
\begin{align}
\sum_{n=0}^\infty z^n=\frac 1{1-z}
\end{align}
where $0^0$ is understood as $1$. If $|z|\geq 1$, then $\dps\sum_{n=0}^\infty z_n$ diverges in $\Cbb$.
\end{eg}


\begin{proof}
The partial sum $s_n=1+z+z^2+\cdots +z^n$ equals $(1-z^{n+1})/(1-z)$ when $z\neq 1$. Therefore, when $|z|<1$, $s_n\rightarrow 1/(1-z)$. When $|z|\geq 1$, we have $|z^n|\geq 1$ and hence $z^n\nrightarrow 0$. So $\sum_{n=0}^\infty z^n$ diverges by Prop. \ref{lb92}.
\end{proof}


\begin{eg}\label{lb95}
The \textbf{harmonic series} $\dps\sum_{n=1}^\infty \frac 1n$ diverges (in $\Rbb$).
\end{eg}


\begin{proof}
We want to show that the Cauchy condition (cf. Rem. \ref{lb93}) does not hold. Thus, we want to prove that there exists $\eps>0$ such that for every $N\in\Zbb_+$ there exist $n>m\geq N$ such that $|(m+1)^{-1}+(m+2)^{-1}+\cdots+n^{-1}|\geq\eps$.

To see this, for each $N$ we choose  $m=2^N$ and $n=2^{N+1}$. Then $n>m>N$, and
\begin{align*}
&\Big|\sum_{i=m+1}^n i^{-1}\Big|=\Big|\frac 1{2^N+1}+\frac 1{2^N+2}+\cdots +\frac 1{2^N+2^N}  \Big|\\
\geq&\underbrace{\Big|\frac 1{2^{N+1}}+\frac 1{2^{N+1}}+\cdots +\frac 1{2^{N+1}}  \Big|}_{2^N\text{ terms}}=\eps
\end{align*}
where $\eps=\frac 12$.
\end{proof}

\begin{comment}
\begin{rem}
For every $p\in\Rbb$, assume that $n^p$ (where $n\in\Zbb_+$) is defined and that the properties we learned in high school mathematics are satisfied. If $p\leq 1$, then clearly $\sum_{n=1}^\infty n^{-p}=+\infty$ since $1/n^p\geq 1/n$. It is in fact true that for every $p>1$ we have $\sum_{n=1}^\infty n^{-p}<+\infty$. The easiest (but not the most elementary) way to see this is by using integrals: This series equals $1+\int_{x=1}^{+\infty}f(x)dx$ where $f:[1,+\infty)\rightarrow\Rbb_{\geq0}$ equals $(n+1)^{-p}$ when restricted to $[n,n+1)$. So $f(x)\leq x^{-p}$ on $[1,+\infty)$. Hence $\int_{x=1}^{+\infty}f(x)dx\leq \int_{x=1}^{+\infty}x^{-p}dx=(1-p)^{-1}x^{1-p}|_{x=1}^{+\infty}=(p-1)^{-1}<+\infty$.
\end{rem}
\end{comment}


\begin{exe}\label{lb96}
Choose any $p\in\Zbb$. Prove that $\dps\sum_{n=1}^\infty n^{-p}$ converges iff $p\geq 2$.
\end{exe}

\begin{proof}[Hint]
Use Prop. \ref{lb94} and Exp. \ref{lb95} to reduce the problem to the case $p=2$. Prove this case by proving $\sum_{n=1}^\infty 1/n(n+1)=1<+\infty$.
\end{proof}



\begin{df}
Let $V$ be a Banach space, let $X$ be a set, and let $(f_n)$ be a sequence in $l^\infty(X,V)$, and let $g\in l^\infty(X,V)$. We say that the series of functions $\dps\sum_{i=1}^\infty f_i$ \textbf{converges uniformly to $g$} \index{00@Uniform convergence of series of functions} (on $X$) if it converges to $g$ as a series in the Banach space $l^\infty(X,V)$ and under the $l^\infty$-norm. Equivalently, this means that the partial sum function $s_n=f_1+\cdots+f_n$ converges uniformly to $g$ as $n\rightarrow\infty$.
\end{df}


\begin{eg}
The series of functions $\dps\sum_{n=1}^\infty \frac{\sin|nz^3|}{n^2}$ converges uniformly on $\Cbb$ to a continuous function $g:\Cbb\rightarrow\Rbb$ which is bounded (i.e. $\dps\sup_{z\in\Cbb}|g(z)|<+\infty$).
\end{eg}

\begin{proof}
Let $f_n(z)=\sin|nz^3|/n^2$. Then each $f_n$ is in $\fk X=C(\Cbb,\Rbb)\cap l^\infty(\Cbb,\Rbb)$ where $\fk X$ is a real Banach space under the $l^\infty$-norm by Cor. \ref{lb101}. Note that $\Vert f_n\Vert_\infty\leq n^{-2}$. By Exe. \ref{lb96}, $\sum_{n=1}^\infty n^{-2}<+\infty$. Therefore, by Prop. \ref{lb94}, the series $\sum_n f_n$ converges in $\fk X$, i.e., it converges uniformly to an element $g\in \fk X$. (In particular, $\sum_n f_n(z)=g(z)$ for all $z\in\Cbb$.)
\end{proof}


\subsection{Root test and ratio test; power series; construction of $e^z$}\label{lb218}


Root test and ratio test are useful criteria for proving the convergence or divergence of series, especially  power series. In addition, the method of power series provides a unified and elegant proof for many useful formulas about limit (see Prop. \ref{lb109} and Exp. \ref{lb111}). We begin our discussion with the following easy observation:

\begin{rem}\label{lb105}
Let $(x_n)$ be a sequence in $\ovl\Rbb$, and let $A\in\ovl\Rbb$. The following are true.
\begin{enumerate}
\item If $\dps\limsup_{n\rightarrow\infty} x_n<A$, then $x_n<A$ is eventually true.
\item If $\dps\limsup_{n\rightarrow\infty} x_n>A$, then $x_n>A$ is frequently true.
\end{enumerate}
By taking negative, we obtain similar statements for $\liminf$.
\end{rem}


\begin{proof}
Recall that $\limsup x_n=\inf_{n\in\Zbb_+}\alpha_n$ where where $\alpha_n=\sup\{x_n,x_{n+1},\dots\}$. 



Assume that  $\inf_{n\in\Zbb_+}\alpha_n<A$. Then $A$ is not a lower bound of $\{\alpha_n:n\in\Zbb_+\}$. Thus, there exists $N\in\Zbb_+$ such that $\alpha_N<A$. Then $x_n<A$ for all $n\geq N$.

Assume that $\inf_{n\in\Zbb_+}\alpha_n>A$. Then for each $N\in\Zbb_+$ we have $\alpha_N>A$. So $A$ is not an upper bound of $\{x_n,x_{n+1},\dots\}$.  So there is $n\geq N$ such that $x_n>A$.
\end{proof}


We will heavily use $\sqrt[n]{x}$ (where $x\geq0$ and $n\in\Zbb_+$) in the following discussions. $\sqrt[n]{x}$ will be rigorously constructed in Exp. \ref{lb216}, whose proof does not rely on the results of this section.


\begin{pp}[\textbf{Root test}]\index{00@Root test} 
Let $\dps\sum_{n=1}^\infty v_n$ be a series in a Banach space $V$. Let $\dps\beta=\limsup_{n\rightarrow\infty}\sqrt[n]{\Vert v_n\Vert}$. Then:
\begin{enumerate}
\item If $\beta<1$, then $\sum v_n$ converges absolutely, and hence converges in $V$.
\item If $\beta>1$, then $\sum v_n$ diverges in $V$.
\end{enumerate}
\end{pp}


\begin{proof}
Suppose $\beta<1$. Then we can choose $\gamma$ such that $\beta<\gamma<1$. So $\limsup \sqrt[n]{\Vert v_n\Vert}<\gamma$. By Rem. \ref{lb104}, there exists $N\in\Zbb_+$ such that for all $n\geq N$, we have $\sqrt[n]{\Vert v_n\Vert}<\gamma$, and hence $\Vert v_n\Vert <\gamma^n$. Since $\sum_{n=0}^\infty \gamma^n=(1-\gamma)^{-1}<+\infty$ (Exp. \ref{lb106}), the series $\sum_{n=N}^\infty v_n$ converges absolutely by Prop. \ref{lb94}. So the original series converges absolutely.

Assume that $\beta>1$. Then by Rem. \ref{lb105}, for each $N$ there is $n\geq N$ such that $\sqrt[n]{\Vert v_n\Vert}>1$ and hence $\Vert v_n-0\Vert>1$. So $v_n\nrightarrow 0$. So $\sum v_n$ diverges by Prop. \ref{lb92}.
\end{proof}

\begin{eg}
Let $V=\Rbb$ and $v_n=1/n$ resp. $v_n=1/n^2$. Then $\beta=1$, and $\sum v_n$ diverges resp. converges absolutely due to Exe. \ref{lb96}. So Root test gives no information on the convergence of series when $\beta=1$. The same can be said about ratio test.
\end{eg}




\begin{pp}[\textbf{Ratio test}]\index{00@Ratio test}  
Let $\dps\sum_{n=1}^\infty v_n$ be a series in a Banach space $V$ such that $v_n\neq 0$ for all $n$. Let $\dps\alpha=\liminf_{n\rightarrow\infty}\frac{\Vert v_{n+1}\Vert}{\Vert v_n\Vert}$ and $\dps\beta=\limsup_{n\rightarrow\infty}\frac{\Vert v_{n+1}\Vert}{\Vert v_n\Vert}$. Then:
\begin{enumerate}
\item If $\beta<1$, then $\sum v_n$ converges absolutely, and hence converges in $V$.
\item If $\alpha>1$, then $\sum v_n$ diverges in $V$.
\end{enumerate}
\end{pp}

\begin{proof}
Suppose $\beta<1$. Choose $\gamma$ such that $\beta<\gamma<1$. Then by Rem. \ref{lb105}, there is $N$ such that for all $n\geq N$ we have $\Vert v_{n+1}\Vert/\Vert v_n\Vert<\gamma$. So $\Vert v_n\Vert <\gamma^{n-N}\Vert v_N\Vert$. So $\sum_{n\geq N}\Vert v_n\Vert \leq \Vert v_N\Vert \cdot\sum_{n\geq N}\gamma^{n-N}=\Vert v_N\Vert\cdot (1-\gamma)^{-1}<+\infty$. So $\sum v_n$ converges absolutely.

Suppose $\alpha>1$. Then by Rem. \ref{lb105}, there is $N$ such that for all $n\geq N$ we have $\Vert v_{n+1}\Vert/\Vert v_n\Vert>1$. So $\Vert v_n\Vert\geq\Vert v_N\Vert>0$ for all $n\geq N$. So $v_n\nrightarrow 0$ and hence $\sum v_n$ diverges, as in the proof of root test.
\end{proof}









\begin{df}
A \textbf{power series} in a complex Banach space $V$ \index{00@Power series} is an expression of the form $\dps\sum_{n=0}^\infty v_nz^n$ where the \textbf{coefficients} $v_0,v_1,v_2,\dots$ are elements of $V$, and $z$ is a \textbf{complex variable},\index{00@Complex variable} i.e., a symbol which can take arbitrary values in $\Cbb$. If the power series $\sum v_nz^n$ converges at $z_0\in\Cbb$, we often let $\sum v_n z_0^n$ denote this limit.
\end{df}


\begin{pp}\label{lb108}
Let $\sum v_n z^n$ be a power series in a complex Banach space $V$. Then there is a unique $0\leq R\leq+\infty$ satisfying the following properties:
\begin{enumerate}[label=(\alph*)]
\item If $z\in\Cbb$ and $|z|<R$, then $\sum v_n z^n$ converges absolutely in $V$.
\item If $z\in\Cbb$ and $|z|>R$, then $\sum v_n z^n$ diverges in $V$.
\end{enumerate}
Such $R$ is called the \textbf{radius of convergence} \index{00@Radius of convergence} of $\sum v_nz^n$. Moreover, we have
\begin{align}
R=\frac 1{\dps\limsup_{n\rightarrow\infty}\sqrt[n]{\Vert v_n\Vert}}=\liminf_{n\rightarrow\infty}\frac 1{\sqrt[n]{\Vert v_n\Vert}}  \label{eq30}
\end{align}
\end{pp}



\begin{proof}
Clearly, there are at most one $R$ satisfying (a) and (b). Let us define $R$ using \eqref{eq30} (note that the second and the third terms of \eqref{eq30} are clearly equal), and prove that $R$ satisfies (a) and (b). Let
\begin{gather*}
\beta(z)=\limsup_{n\rightarrow\infty} \sqrt[n]{\Vert v_n z^n\Vert}
\end{gather*}
Then $\beta(z)=|z|/R$. So (a) and (b) follow immediately from root test.
\end{proof}


\begin{rem}
Note that if one can find $0\leq r\leq R$ such that $\sum v_nz^n$ converges whenever $|z|<r$, then $r\leq R$ where $R$ is the radius of convergence: otherwise, the series diverges for any positive $z$ satisfying $R<z<r$, impossible.

It follows that if  $\sum v_nz^n$ converges for all $|z|<r$, then $\sum v_nz^n$ converges \textit{absolutely} for all $|z|<r$.  \hfill\qedsymbol
\end{rem}


Prop. \ref{lb108} provides a useful method for computing limits of a positive sequence:

\begin{pp}\label{lb109}
Let $(\lambda_n)$ be a sequence in $\Rbb_{>0}$. Then
\begin{align}
\liminf_{n\rightarrow\infty}\frac{\lambda_{n+1}}{\lambda_n}\leq \liminf_{n\rightarrow\infty}\sqrt[n]{\lambda_n}\leq \limsup_{n\rightarrow\infty}\sqrt[n]{\lambda_n}\leq \limsup_{n\rightarrow\infty} \frac{\lambda_{n+1}}{\lambda_n}  \label{eq35}
\end{align}
In particular, (by Cor. \ref{lb113}) we have
\begin{align}
\lim_{n\rightarrow\infty}\sqrt[n]{\lambda_n}=\lim_{n\rightarrow\infty} \frac{\lambda_{n+1}}{\lambda_n}\label{eq31}
\end{align}
provided that the limit on the RHS of \eqref{eq31} exists in $\ovl\Rbb$.
\end{pp}

The four numbers in \eqref{eq35} can be completely different. See \cite[Exp. 3.35]{Rud-P}.

\begin{proof}
Let $R$ be the radius of convergence of $\sum \lambda_n z^n$. Then $R=1/\limsup\sqrt[n]{\lambda_n}$ by \eqref{eq31}. Thus, by Prop. \ref{lb108}, if $|z|>R$ then $\sum \lambda_n z^n$ diverges, and hence $\limsup|\lambda_{n+1}z^{n+1}|/|\lambda_n z^n|\geq 1$ by ratio test. Therefore, 
\begin{align*}
|z|>\frac 1{\dps\limsup\sqrt[n]{\lambda_n}}\qquad\Longrightarrow \qquad |z|\cdot\limsup\frac{\lambda_{n+1}}{\lambda_n}\geq 1
\end{align*}
This proves
\begin{align*}
\limsup\sqrt[n]{\lambda_n}\leq \limsup \frac{\lambda_{n+1}}{\lambda_n}
\end{align*}
Replacing $\lambda_n$ by $\lambda_n^{-1}$, we get
\begin{align*}
\frac 1{\dps\liminf \sqrt[n]{\lambda_n}}=\limsup\sqrt[n]{\lambda_n^{-1}}\leq \limsup \frac{\lambda_n}{\lambda_{n+1}}=\frac 1{\dps \liminf\frac{\lambda_{n+1}}{\lambda_n}}
\end{align*}
This proves \eqref{eq35}.
\end{proof}

\begin{eg}\label{lb111}
Let $a\in\Rbb_{>0}$ and $p\in\Zbb$. The following formulas follow immediately from Prop. \ref{lb109} (especially, from \eqref{eq31}):
\begin{subequations}
\begin{gather}
\lim_{n\rightarrow\infty} \sqrt[n]{a}=1 \label{eq32}\\
\lim_{n\rightarrow\infty}\sqrt[n]{n!}=+\infty  \label{eq33}\\
\lim_{n\rightarrow\infty}\sqrt[n]{n^p}=1  \label{eq34}
\end{gather}
Note that \eqref{eq34} follows from 
\begin{align}
\lim_{n\rightarrow\infty}\Big(\frac n{n+1}\Big)^p=1 
\end{align}
(This is clearly true when $p=\pm1$, and hence is true for any $p$ by induction.) By \eqref{eq34}, the radius of convergence of $\sum_n n^p z^n$ is $1$. Therefore, by Prop. \ref{lb108},  $\sum n^pA^{-n}$ converges absolutely when $A>1$. Thus, by Prop. \ref{lb92},
\begin{align}
\lim_{n\rightarrow\infty} \frac{n^p}{A^n}=0 \qquad(\text{if }A>1)
\end{align}
This means that ``polynomials grow slower than exponentials".
\end{subequations}

The same conclusions hold for arbitrary $p\in\Rbb$ once we know how to define $x^p$ and prove the continuity of $x\in\Rbb_{>0}\mapsto x^p$. (See Sec. \ref{lb219}.) \hfill\qedsymbol
\end{eg}


\begin{sexe}
Prove \eqref{eq32} directly. Then use \eqref{eq32} to give a direct proof of Prop. \ref{lb109}. Do not use root test, ratio test, or any results about power series.
\end{sexe}


%% Record #4 2023/09/27   three lectures  10





\begin{df}\label{lb107}
By \eqref{eq33}, the power series \index{exp@$e^z=\exp(z)$}
\begin{align*}
\exp(z)\equiv e^z=\sum_{n=0}^\infty \frac{z^n}{n!}
\end{align*}
has radius of convergence $+\infty$, and hence converges absolutely on $\Cbb$. (In particular, $\lim_{n\rightarrow\infty} z^n/n!=0$ for all $z\in\Cbb$.) This gives a function $\exp:\Cbb\rightarrow\Cbb$, called the \textbf{exponential function}. \index{00@Exponential function} 
\end{df}















Part (a) of Prop. \ref{lb108} can be strengthened in the following way.

\begin{thm}\label{lb112}
Let $\sum v_n z^n$ be a power series with coefficients in a complex Banach space $V$. Let $R$ be its radius of convergence, and assume that $0<R\leq+\infty$. For each $z\in B_\Cbb(0,R)$, let $f(z)$  denote the value of this series at $z$ (which is an element of $V$). Then $f:B_\Cbb(0,R)\rightarrow V$ is continuous. Moreover,  for each $0<\rho<R$, the series of functions $\sum v_n z^n$ converges uniformly on $\ovl B_\Cbb(0,\rho)$ to $f$. 
\end{thm}

Note that by calling $\sum v_n z^n$ a series of functions, we understand each term $v_nz^n$ as a function $\Cbb\rightarrow V$.

\begin{proof}
For each $0<\rho<R$, let $X_\rho=\ovl B_\Cbb(0,\rho)$. Then $X_\rho$ is clearly a bounded closed subset of $\Cbb$, and hence is sequentially compact by Heine-Borel Thm. \ref{lb98}. Let $g_n=v_nz^n$, which is a continuous function $X_\rho\rightarrow V$. We view $g_n$ as an element of the Banach space (cf. Cor. \ref{lb101}) $C(X_\rho,V)$. Then $\Vert g_n\Vert_\infty=\rho^n\Vert v_n\Vert$. Thus
\begin{align*}
\limsup_{n\rightarrow\infty}\sqrt[n]{\Vert g_n\Vert_\infty}=\limsup_{n\rightarrow\infty}\rho\sqrt[n]{\Vert v_n\Vert}=\rho/R<1
\end{align*}
Therefore, by root test, the series $\sum g_n$ converges in the Banach space $C(X_\rho,V)$ to some $f_\rho\in C(X_\rho,V)$.

We have proved that for each $0<\rho<R$, the series of functions $\sum v_nz^n$ converges uniformly on $X_\rho$ to a continuous function $f_\rho$. Let $f:B_\Cbb(0,R)\rightarrow V$ whose value at each $z$ is the value of the original series at $z$. Thus, if $|z|\leq\rho$, then $f_\rho(z)=f(z)$. Namely, $f|_{X_\rho}=f_\rho$. This shows that $\sum v_nz^n$ converges uniformly on $X_\rho$ to $f$. It also shows that $f|_{B_\Cbb(0,\rho)}$ is continuous (because $f_\rho$ is continuous). Therefore, since $B_\Cbb(0,R)$ is covered by all open disks $B_\Cbb(0,\rho)$ (where $0<\rho<R$), we conclude from Lem. \ref{lb30} that $f$ is continuous on $B_\Cbb(0,R)$.
\end{proof}

\begin{eg}\label{lb214}
By Thm. \ref{lb112}, the exponential function $\exp:\Cbb\rightarrow\Cbb$ is continuous; moreover, $\sum_{n=0}^\infty z^n/n!$ converges uniformly to $e^z$ on $\ovl B_{\Cbb}(0,R)$ for every $0<R<+\infty$, and hence on every bounded subset of $\Cbb$.
\end{eg}



\subsection{Problems and supplementary material}


Let $V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$. 

\begin{prob}\label{lb566}
Let $W$ be a normed vector space. 
\begin{enumerate}
\item Prove that if $(w_n)_{n\in\Zbb_+}$ is a Cauchy sequence in $W$, then $(w_n)$ has a subsequence $(w_{n_k})_{k\in\Zbb_+}$ such that $\sum_{n=1}^\infty\Vert w_{n+1}-w_n\Vert<+\infty$.
\item Use part 1 to prove that $W$ is complete iff every absolutely convergent series in $W$ is convergent.
\end{enumerate}
\end{prob}



\begin{prob}\label{lb845}
Use the formula of \textbf{summation by parts} \index{00@Summation by parts}
\begin{align}
\sum_{k=m+1}^n f_kg_k=F_ng_n-F_mg_m-\sum_{k=m}^{n-1}F_k (g_{k+1}-g_k)
\end{align}
(where $F_n=\sum_{j=0}^n f_j$) to prove the following Dirichlet's test.
\end{prob}


\begin{thm}[\textbf{Dirichlet's test}]\index{00@Dirichlet's test}\label{lb481}
Let $X$ be a set. Assume that $(f_n)$ is a sequence in $l^\infty(X,V)$ such that $\sup_{n\in\Zbb_+}\Vert F_n\Vert_{l^\infty}<+\infty$ (where $F_n=\sum_{j=1}^n f_j$). Assume that $(g_n)$ is a decreasing sequence (i.e. $g_1\geq g_2\geq g_3\geq\cdots$) in $l^\infty(X,\Rbb_{\geq0})$ converging uniformly to $0$. Then $\sum_{n=1}^\infty f_ng_n$ converges uniformly on $X$.
\end{thm}


\begin{prob}\label{lb394}
Let $e_n:\Rbb\rightarrow\Cbb$ be $e_n(x)=e^{\im nx}=\cos(nx)+\im\sin(nx)$. Show that for each $x\in\Rbb$, $\sum_{n=1}^\infty e_n(x)/n$ does not converge absolutely. Use Dirichlet's test to show that the series of functions $\sum_{n=1}^\infty e_n/n$ converges pointwise on $\Rbb\setminus\{2k\pi:k\in\Zbb\}$, and uniformly on $[\delta,2\pi-\delta]$ for every $0<\delta<\pi$.
\end{prob}











\begin{comment}

\subsection{Problems and supplementary material}

\begin{sprob}
Consider a power series $\sum a_nz^n$ where $a_n\in\Rbb_{\geq 0}$ for each $n$. Let $R$ be its radius of convergence. Prove that the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $\sum a_n<+\infty$.
\item $\sum a_nz^n$ converges uniformly on $\ovl B_\Cbb(0,R)$ to a continuous function.
\item $\sum a_nz^n$ converges uniformly on $B_\Cbb(0,R)$.
\end{enumerate}
\end{sprob}
\end{comment}


\newpage


\section{Nets and unordered sums}


\subsection{Introduction: why do we need nets?}



Nets were introduced by Moore and Smith in 1922 as a generalization of sequences. The most well-known motivation for introducing nets is that sequences are not enough for the study of non-metrizable topological spaces (i.e. topological spaces whose topologies are not induced by metrics). Here are two examples:
\begin{itemize}
\item In a general topological space, the definition of continuous maps using sequential convergence (as in Def. \ref{lb31}-(1)) is weaker than the definition using interior points and open sets (as in Def. \ref{lb31}-(2'), see also Rem. \ref{lb109}). Therefore, the dynamic intuition of sequences is not equivalent to the static intuition of open sets. 
\item Some important  topological spaces are compact (i.e. every open cover has a finite subcover) but not sequentially compact. $[0,1]^I$ (where $I$ is uncountable), equipped with the ``product topology" (i.e. ``pointwise convergence topology"), is such an example. 
\end{itemize}
As we shall see, nets provide a remedy for these issues: For a general topological space, the definition of continuity using net convergence is equivalent to that using open sets; compactness is equivalent to ``net-compactness", where the latter means that every net has a convergent subset. Thus, by generalizing sequences to nets, the dynamic intuition and the static and geometric intuition are unified again.


Nevertheless, the most common topological spaces appearing in analysis are metrizable. This raises the question: Why should we care about nets, given that our primary interest is in metrizable topological spaces? Here is my answer: Even though we are mainly interested in metrizable spaces, we can still find nets helpful in the following aspects. 

First of all, many convergence processes cannot be described by sequential convergence, but can be described by net convergence. For example, the following limits can be formulated and understood in the language of net convergence:
\begin{enumerate}[label=(\arabic*)]
\item The limit of a function $\lim_{x\rightarrow x_0}f(x)$ where $f:X\rightarrow Y$ is a map of metric spaces and $x_0\in X$.
\item The limit $\dps\lim_{m,n\rightarrow\infty}a_{m,n}$ where $(a_{m,n})_{m,n\in\Zbb_+}$ is a \textbf{double sequence} in a metric space $X$. Note that this is not the same as (but is more natural than) the \textbf{iterated limit} $\dps\lim_{n\rightarrow\infty}\lim_{m\rightarrow\infty} a_{m,n}$. Moreover, the limit $\dps\lim_{m,n\rightarrow\infty}a_{m,n}$ is the key to understanding the problem of commutativity of iterated integrals:
\begin{align*}
\lim_{n\rightarrow\infty}\lim_{m\rightarrow\infty} a_{m,n}\xlongequal{?}\lim_{m\rightarrow\infty}\lim_{n\rightarrow\infty} a_{m,n}
\end{align*}
\item The Riemann integral $\int_a^b f(x)dx$. This is the limit of the Riemann sum $\lim\sum f(\xi_i)(a_i-a_{i-1})$  as the partition of the interval $[a,b]$ is getting finer and finer.
\end{enumerate} 
Moreover, as for (3), we shall see that the net version of Cor. \ref{lb113} provides a quick and conceptual proof of the following fact: If the upper and lower Darboux integrals are equal, then the Riemann integral exists and are equal to the two Darboux integrals. Indeed, the upper and lower Darboux integrals are respectively the $\limsup$ and $\liminf$ of a net in $\Rbb$.

Second, nets provide a conceptual solution to many problems about \textbf{double series}. Let $(a_{m,n})_{m,n\in\Zbb_+}$ be a double sequence in $\Rbb$. Think about the following questions, which arise naturally when one is trying to prove $e^ze^w=e^{z+w}$.
\begin{enumerate}[label=(\alph*)]
\item When is it true that $\dps \sum_{n=1}^\infty\sum_{m=1}^\infty a_{m,n}=\sum_{m=1}^\infty\sum_{n=1}^\infty a_{m,n}$ ?
\item Since $\card(\Zbb_+\times\Zbb_+)=\card(\Zbb_+)$, why not use an ordinary series to study a double series? So let us \textbf{parametrize} $\Zbb_+\times\Zbb_+$ by $\Zbb_+$: choose a bijection $\varphi:\Zbb_+\rightarrow \Zbb_+\times\Zbb_+$. When is it true that $\dps  \sum_{k=1}^\infty a_{\varphi(k)}=\sum_{n=1}^\infty\sum_{m=1}^\infty a_{m,n}$ ?
\item Choose another parametrization (i.e. bijection) $\psi:\Zbb_+\rightarrow\Zbb_+\times\Zbb_+$. When is it true that $\dps  \sum_{k=1}^\infty a_{\varphi(k)}=\sum_{k=1}^\infty a_{\psi(k)}$ ?
\item More generally, let $X$ be a countably infinite set, and let $f:X\rightarrow\Rbb$. Intuitively, we can take an infinite sum $\dps\sum_{x\in X}f(x)$. How to define it rigorously? One may think about choosing a parametrization, i.e., a bijection $\varphi:\Zbb_+\rightarrow X$. Then one defines the infinite sum by $\sum_{k=1}^\infty f(\varphi(k))$. Is this definition independent of the choice of parametrization?
\item As a special case of (d), when is a series invariant under \textbf{rearrangement}? Namely, choose a bijection $\varphi:\Zbb_+\rightarrow\Zbb_+$, and choose a sequence $(a_n)$ in $\Rbb$, when is it true that $\dps\sum_{n=1}^\infty a_n=\sum_{n=1}^\infty a_{\varphi(n)}$ ?
\end{enumerate}

Modern differential geometry (whose ``intrinsic" spirit stems from Gauss's Theorema Egregium) teaches us that in order to answer these questions, one should first define the infinite sum $\sum_{x\in X}f(x)$ in a parametrization-independent way. (The reason we call a bijection $\varphi:\Zbb_+\rightarrow X$ a parametrization is that we want the readers to compare it with the parametrizations of curves, surfaces, and more generally manifolds.)  We will call this sum an \textbf{unordered sum}. Then, one tries to answer when this definition agrees with those that depend on parametrizations (such as the sums in (a)-(e) above). These goals can be achieved with the help of nets.



\subsection{Nets}\label{lb147}


\subsubsection{Directed sets and nets}

\begin{df}\label{lb116}
A relation $\leq$ on a set $I$ is called a \textbf{preorder} \index{00@Preorder, and preordered set} if for all $\alpha,\beta,\gamma\in I$, the following are satisfied:
\begin{itemize}
\item (Reflexivity) $\alpha\leq \alpha$.
\item (Transitivity) If $\alpha\leq \beta$ and $\beta\leq \gamma$ then $a\leq \gamma$.
\end{itemize}
The pair $(I,\leq)$ (or simply $I$) is called a \textbf{preordered set}.
\end{df}

Therefore, a partial order is a preorder satisfying antisymmetry: $(\alpha\leq \beta)\land(\beta\leq\alpha)\Rightarrow (\alpha=\beta)$.

\begin{df}
A preordered set $(I,\leq)$ is called a \textbf{directed set} \index{00@Direct set} if 
\begin{align}
\forall\alpha,\beta\in I~~~\exists\gamma\in I~~\text{ such that }\alpha\leq \gamma,\beta\leq\gamma  \label{eq37}
\end{align}
If $I$ is a directed set and $X$ is a set, then a function $x:I\rightarrow X$ is called a \textbf{net} \index{00@Net $(x_\alpha)_{\alpha\in I}$} with directed set/index set $I$. We often write $x(\alpha)$ as $x_\alpha$ if $\alpha\in I$, and write $x$ as $(x_\alpha)_{\alpha\in I}$.

Unless otherwise stated, for any net $(x_\alpha)_{\alpha\in I}$ we assume that $I\neq\emptyset$.  \hfill\qedsymbol
\end{df}


\begin{eg}
$(\Zbb_+,\leq)$ is a directed set. A net with index set $\Zbb_+$ in a set $X$ is precisely a sequence in $X$.
\end{eg}

\begin{df}\label{lb117}
Suppose that $(I,\leq_I )$ and $(J,\leq_J)$ are preordered set (resp. directed set), then the \textbf{product} \index{00@Product preordered/directed set} $(I\times J,\leq)$ is a preordered set (resp. directed set) if for every $\alpha,\alpha'\in I,\beta,\beta'\in J$ we define
\begin{align}\label{eq36}
(\alpha,\beta)\leq (\alpha',\beta')\qquad\Longleftrightarrow\qquad \alpha\leq_I \alpha'~~\text{and}~~\beta\leq_J\beta'
\end{align}
Unless otherwise stated, the preorder on $I\times J$ is assumed to be defined by \eqref{eq36}.
\end{df}


\begin{eg}
$\Zbb_+\times\Zbb_+$ (or similarly, $\Nbb\times\Nbb$) is naturally a directed set whose preorder is defined by \eqref{eq36}. A net $(x_{m,n})_{(m,n)\in\Zbb_+\times\Zbb_+}$ with index set $\Zbb_+\times\Zbb_+$ is called a \textbf{double sequence} \index{00@Double sequence} and is written as $(x_{m,n})_{m,n\in\Zbb_+}$ or simply $(x_{m,n})$. (We will even write it as $(x_{mn})$ when no confusion arises.)

More generally, we call $(x_{\alpha,\beta})_{(\alpha,\beta)\in I\times J}=(x_{\alpha,\beta})_{\alpha\in I,\beta\in J}$ a \textbf{double net} \index{00@Double net} if its index set is $I\times J$ for some directed sets $I,J$. \hfill\qedsymbol
\end{eg}




\begin{eg}\label{lb130}
If $X$ is a set, then $(2^X,\subset)$ and $(\fin(2^X),\subset)$ \index{fin@$\fin(2^X)$} are directed sets where
\begin{align}
\fin(2^X)=\{A\subset X:A\text{ is a finite set}\}
\end{align}
We will use nets with index set $\fin(2^X)$ to study infinite sums.
\end{eg}


\begin{eg}
Let $X$ be a metric space and $x\in X$. Then $X_x=(X,\leq)$ is a directed set if for each $p_1,p_2\in X$ we define
\begin{align}
p_1\leq p_2~~\text{in }X_x\qquad\Longleftrightarrow\qquad d(p_1,x)\geq d(p_2,x)
\end{align}
(Namely, a larger element of $X_x$ is one closer to $x$.) Nets with this directed set can be used to study the limits of functions (cf. Rem. \ref{lb269}). Note that $X_x$ is our first example of directed set which is not a poset! ($d(p_1,x)=d(p_2,x)$ does not imply $p_1=p_2$.)
\end{eg}


\subsubsection{Limits of nets}

If $I$ is an preordered set and $\beta\in I$, we write \index{I@$I_{\geq\beta}$}
\begin{gather}
I_{\geq\beta}=\{\alpha\in I:\alpha\geq\beta\}
\end{gather}
\begin{df}
Let $P$ be a property about elements of a set $X$, i.e., $P$ is a function $X\rightarrow\{\text{true, false}\}$. Let $(x_\alpha)_{\alpha\in I}$ be a net in $X$. 

We say that $x_\alpha$ \textbf{eventually} \index{00@Eventually} satisfies $P$ (equivalently, we say that $x_\alpha$ satisfies $P$ for \textbf{sufficiently large} \index{00@Sufficiently large} $\alpha$) if:
\begin{itemize}
\item There exists $\beta\in I$ such that for every $\alpha\in I_{\geq\beta}$, the element $x_\alpha$ satisfies $P$.
\end{itemize}
``Sufficiently large" is also called ``\textbf{large enough}". \index{00@Large enough=sufficiently large}

We say that $x_\alpha$ \textbf{frequently} \index{00@Frequently} satisfies $P$ if:
\begin{itemize}
\item For every $\beta\in I$ there exists $\alpha\in I_{\geq\beta}$ such that $x_\alpha$ satisfies $P$.
\end{itemize}
\hfill\qedsymbol
\end{df}


\begin{rem}
Note that unlike sequences, for a general net, ``$x_\alpha$ eventually satisfies $P$" does not imply ``all but finitely many $x_\alpha$ satisfy $P$" because the complement of $I_{\geq\beta}$ is not necessarily a finite set.  
\end{rem}


\begin{rem}
Let $P$ and $Q$ be two properties about elements of $X$. Then
\begin{subequations}
\begin{gather}
\neg(\text{$x_\alpha$ eventually satisfies $P$})~~=~~(\text{$x_\alpha$ frequently satisfies $\neg P$})
\end{gather}
By the crucial condition \eqref{eq37} for directed sets, we have
\begin{gather}\label{eq38}
\begin{gathered}
(x_\alpha\text{ eventually satisfies }P)\land(x_\alpha\text{ eventually satisfies }Q)\\
\Downarrow \\
x_\alpha\text{ eventually satisfies }P\land Q
\end{gathered}
\end{gather}
By taking contraposition and replacing $P,Q$ by $\neg P,\neg Q$, we have
\begin{gather}\label{eq103}
\begin{gathered}
x_\alpha\text{ frequently satisfies }P\lor Q\\
\Downarrow\\
(x_\alpha\text{ frequently satisfies }P)\lor(x_\alpha\text{ frequently satisfies }Q)
\end{gathered}
\end{gather}
\end{subequations}
\end{rem}

\begin{df}\label{lb174}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a metric space $X$. Let $x\in X$. We say that $(x_\alpha)$ \textbf{converges to} $x$ and write \index{lim@$\lim_{\alpha\in I}x_\alpha\equiv \lim_\alpha x_\alpha$}
\begin{align*}
\lim_{\alpha\in I}x_\alpha\equiv \lim_\alpha x_\alpha=x
\end{align*}
or simply $x_\alpha\rightarrow x$ if the following statement holds:
\begin{itemize}
\item For every $\eps>0$, $x_\alpha$ is eventually in $B_X(x,\eps)$.
\end{itemize}
Clearly, $x_\alpha\rightarrow x$ iff $d(x_\alpha,x)\rightarrow 0$.
\end{df}

\begin{df}
Let $(x_{m,n})_{m,n\in\Zbb_+}$ be a double sequence in a metric space. Then we write
\begin{align}
\lim_{(m,n)\in\Zbb_+\times\Zbb_+} x_{m,n}\equiv \lim_{m,n\rightarrow\infty} x_{m,n}
\end{align}
and call it the \textbf{(double) limit} \index{00@Double limit} of $(x_{m,n})$.
\end{df}

\begin{rem}
Let us spell out the meaning of $\lim_{m,n\rightarrow\infty} x_{m,n}=x$: For each $\eps>0$ there exists $M,N\in\Zbb_+$ such that $d(x_{m,n},x)<\eps$ for all $m\geq M$ and $n\geq N$. Clearly, this is equivalent to the statement:
\begin{itemize}
\item For each $\eps>0$ there exists $N\in\Zbb_+$ such that $d(x_{m,n},x)<\eps$ for all $m,n\geq N$.
\end{itemize}
Therefore, if $(x_n)$ is a sequence in $X$, then
\begin{align}
\text{$(x_n)$ is a Cauchy sequence}\qquad\Longleftrightarrow\qquad \lim_{m,n\rightarrow\infty} d(x_m,x_n)=0
\end{align}
Thus, the Cauchyness of sequences can be studied in terms of double limits, and hence in terms of nets.
\end{rem}




\begin{pp}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a metric space $X$ converging to $x,y$. Then $x=y$.
\end{pp}

\begin{proof}
Suppose that $x\neq y$. Then there are $r,\rho>0$ such that $B(x,r)\cap B(y,\rho)=\emptyset$, say $r=\rho=d(x,y)/2$. Since $x_\alpha\rightarrow x$, the point $x_\alpha$ is eventually in $B(x,r)$. Since $x_\alpha\rightarrow y$, the point $x_\alpha$ is eventually in $B(y,\rho)$. Therefore, by the logic \eqref{eq38}, $x_\alpha$ is eventually in $B(x,r)\cap B(y,\rho)$, impossible.
\end{proof}

\begin{thm}\label{lb121}
Let $f:X\rightarrow Y$ be map of metric spaces continuous at $x\in X$. Let $(x_\alpha)_{\alpha\in I}$ be a net in $X$ converging to $x$. Then  $\dps\lim_\alpha f(x_\alpha)=f(x)$.
\end{thm}

\begin{proof}
Choose any $\eps>0$. By Def. \ref{lb31}-(2) and the continuity of $f$ at $x$, there exists $\delta>0$ such that for all $p\in B(x,\delta)$ we have $f(p)\in B(f(x),\eps)$. Since $x_\alpha\rightarrow x$, $x_\alpha$ is eventually in $B(x,\delta)$. Therefore $f(x_\alpha)$ is eventually in $B(f(x),\eps)$.
\end{proof}


This theorem implies, for example, that if $(v_\alpha)$ is a net in a complex normed vector space converging to $v$, and if $(\lambda_\alpha)$ is a net in $\Cbb$ converging to $\lambda$, then $\lambda_\alpha v_\alpha$ converges to $\lambda v$ because the scalar multiplication map is continuous (Prop. \ref{lb82}).



\begin{exe}\label{lb123}
Prove the generalization of Rem. \ref{lb58}:
\begin{enumerate}
\item If $(x_\alpha)_{\alpha\in I},(y_\alpha)_{\alpha\in I}$ are nets in $\ovl\Rbb$ converging to $A,B\in\ovl\Rbb$, and if $x_\alpha\leq y_\alpha$ for all $\alpha$, then $A\leq B$.
\item \textbf{Squeeze theorem}: \index{00@Squeeze theorem} Suppose that $(x_\alpha)_{\alpha\in I},(y_\alpha)_{\alpha\in I},(z_\alpha)_{\alpha\in I}$ are nets in $\ovl\Rbb$, $x_\alpha\leq y_\alpha\leq z_\alpha$ for all $\alpha$, and $x_\alpha$ and $z_\alpha$ both converge to $A\in\ovl\Rbb$. Then $y_\alpha\rightarrow A$.
\item If $(x_\alpha)$ is an increasing resp. decreasing net in $\ovl\Rbb$, then $\lim_\alpha x_\alpha$ exists in $\ovl\Rbb$ and equals $\sup_\alpha x_\alpha$ resp. $\inf_\alpha x_\alpha$.
\end{enumerate}
\end{exe}








\subsubsection{Subnets (in the sense of Willard)}




\begin{df}
A subset $E$ of a directed set $I$ is called \textbf{cofinal} \index{00@Cofinal subset} if:
\begin{align*}
\forall\alpha\in I~~~\exists\beta\in E~~~\text{such that }\alpha\leq\beta
\end{align*}
By the transitivity in Def. \ref{lb116} and property \eqref{eq37}, we clearly have
\begin{align*}
\forall\alpha_1,\dots,\alpha_n\in I~~~\exists\beta\in E~~~\text{such that }\alpha_1\leq\beta,\dots,\alpha_n\leq\beta
\end{align*}
\end{df}



\begin{df}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a set $X$. A \textbf{subnet} \index{00@Subnet} of $(x_\alpha)_{\alpha\in I}$ is, by definition, of the form $(x_{\alpha_s})_{s\in S}$ where $S$ is a directed set, and
\begin{align*}
(\alpha_s)_{s\in S}:S\rightarrow I\qquad s\mapsto \alpha_s
\end{align*}
is an increasing function whose range $\{\alpha_s:s\in S\}$ is cofinal in $I$.
\end{df}



\begin{rem}
There are several different definitions of subnets that are equivalent for proving the main results in point-set topology. Unfortunately, there is no common agreement on the standard definition of subnets. The definition we gave is due to Willard \cite{Wil}, and is also the one given in the famous textbook of Munkres \cite{Mun}. Some famous analysis and topology textbooks (e.g. \cite{Fol-R,Kel,RS}) use a weaker definition, which does not assume that the map $S\rightarrow I$ is increasing.
\end{rem}




\begin{eg}
A subsequence of a sequence is a subnet of that sequence.
\end{eg}

\begin{eg}\label{lb118}
Let $(x_{m,n})_{m,n\in\Zbb_+}$ be a net with index set $\Zbb_+\times\Zbb_+$. Then $(x_{k,k})_{k\in\Zbb_+}$ and $(x_{2k,k})_{k\in\Zbb_+}$ are subnets. $(x_{k,1})_{k\in\Zbb_+}$ is not a subnet, because the cofinal condition is not satisfied. More generally, it is not hard to show that for every function $\varphi,\psi:\Zbb_+\rightarrow\Zbb_+$, $(x_{\varphi(k),\psi(k)})_{k\in\Zbb_+}$ is a subnet iff $\varphi,\psi$ are increasing and $\lim_{k\rightarrow\infty}\varphi(k)=\lim_{k\rightarrow\infty}\psi(k)=+\infty$.
\end{eg}

\begin{exe}
Prove the following facts:
\begin{itemize}
\item The cofinal subset of a cofinal subset of a directed set $I$ is a cofinal subset of $I$.
\item  The subnet of a subnet of a net $(x_\alpha)$ is a subnet of $(x_\alpha)$. 
\end{itemize}
Note that in your proof you need to use the transitivity in Def. \ref{lb116}.
\end{exe}


The biggest difference between subnets and subsequences is that the index set of a subnet is not necessarily a subset of the index set of the original net. Indeed, subnets are defined in this way mainly because we want to have a net version of Pb. \ref{lb64} in any topological space. (This will be achieved in Pb. \ref{lb223}.) Let us see an elementary example of subnet whose index set is larger than that of the original net. Its importance is justified by the proofs of Exp. \ref{lb125} and Prop. \ref{lb126}.


\begin{eg}\label{lb124}
Let $J$ be a directed set. Then every net $(x_\alpha)_{\alpha\in I}$ has subnet $(x_\alpha)_{(\alpha,\beta)\in I\times J}$. The corresponding increasing map of directed sets is the projection $I\times J\rightarrow I$ onto the first component. 
\end{eg}






To appreciate the importance of cofinalness (as well as transitivity), we prove the following generalization of Prop. \ref{lb23}. This result has a wide range of surprising applications that are unavailable when one only considers sequences. (We will see them soon in this chapter. For instance, this result explains why the values of absolutely convergent series are invariant under rearrangement.) So I call this result a theorem, even though its proof is simple.


\begin{thm}\label{lb120}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a metric space (or more generally, a topological space) $X$ converging to $x\in X$. Then every subnet $(x_{\alpha_s})_{s\in S}$ converges to $x$.
\end{thm}

The following proof for metric spaces can be generalized straightforwardly to topological spaces. The readers can come back and check the details after learning topological spaces.

\begin{proof}
Choose any $\eps>0$. Since $x_\alpha\rightarrow x$, there exists $\beta\in I$ such that for all $\alpha\geq\beta$ we have $d(x_\alpha,x)<\eps$. By the cofinalness, there exists $t\in S$ such that $\alpha_t\geq\beta$. Thus, since $s\in S\mapsto \alpha_s\in I$ is increasing, for every $s\geq t$, we have $\alpha_s\geq\alpha_t\geq\beta$ and hence $\alpha_s\geq\beta$ by the transitivity in Def. \ref{lb116}. So $d(x_{\alpha_s},x)<\eps$ for all $s\geq t$. This finishes the proof.
\end{proof}

This proposition does not hold if one does not assume cofinalness in the definition of subnets:

\begin{eg}
Let $(x_n)$ be a sequence in $\Rbb$ converging to $x\in\Rbb$. Since $(x_n)$ is a Cauchy sequence, we know that $\lim_{m,n\rightarrow\infty}x_m-x_n=0$. We have seen in Exp. \ref{lb118} that $(x_{2k}-x_k)_{k\in\Zbb_+}$ is a subnet of $(x_{m,n})$. Therefore, $\lim_{k\rightarrow\infty} x_{2k}-x_k=0$. But $(x_k-x_1)_{k\in\Zbb_+}$ is not a subnet since the cofinal condition is not satisfied. And if $x\neq x_1$, then $\lim_k (x_k-x_1)=x-x_1\neq 0$, i.e.,
\begin{align*}
\lim_{k\rightarrow\infty}(x_k-x_1)\neq \lim_{m,n\rightarrow\infty} (x_m-x_n)
\end{align*}
\end{eg}


In Subsec. \ref{lb119}, we have seen two criteria for the divergence of sequence: a sequence diverges if it is unbounded, or if it has two subsequences converging to different points. By Thm. \ref{lb120}, the second criterion can be generalized to nets. However, the following example shows that the first criterion does not has its net version:


%% Record #5 2023/10/7 two lectures  12



\begin{eg}
A convergent net $(x_\alpha)_{\alpha\in I}$ in a metric space $X$ is not necessarily \textbf{bounded}. Namely, it is not necessarily true that $\{x_\alpha:\alpha\in I\}$ is a bounded subset of $X$. Let $f:\Rbb_{>0}\rightarrow\Rbb$ be $f(x)=1/x$. Then $f$ is net in $\Rbb$ with directed set $(\Rbb_{> 0},\leq)$. This net is not bounded, although $\lim f(x)=0$.
\end{eg}





\begin{eg}
The double sequence $x_{m,n}=n/(m+n)$ in $\Rbb$ has subnets $x_{n,n}=n/(n+n)=1/2$ and $x_{2n,n}=1/3$. Since these two subnets converge to different values, Thm. \ref{lb120} implies that $\lim_{m,n}x_{m,n}$ does not exist. However, the \textbf{iterated limits}\index{00@Iterated limit} exist and take different values:
\begin{gather*}
\lim_{m\rightarrow\infty}\lim_{n\rightarrow\infty}\frac{n}{m+n}=1\qquad \lim_{n\rightarrow\infty}\lim_{m\rightarrow\infty}\frac{n}{m+n}=0
\end{gather*}
As we shall see, this gives another criterion for the divergence of double series: If the two iterated limits exist and are different, then the double series diverge.
\end{eg}


Finally, we do an example of convergent double sequence:

\begin{eg}\label{lb125}
Let $\dps x_{m,n}=(m^{-2}-n^{-1})\sin\frac{\pi(m+\sqrt n)}{4}$. Then $\dps\lim_{m,n\rightarrow\infty}x_{m,n}=0$.
\end{eg}

\begin{proof}
The sequence $(m^{-2})_{m\in\Zbb_+}$ converges to $0$. By Exp. \ref{lb124}, the double sequence $(m^{-2})_{m,n\in\Zbb_+}$ is its subnet, and hence converges to $0$ by Thm. \ref{lb120}. Similarly, the double sequence $(n^{-1})_{m,n\in\Zbb_+}$ converges to $0$. Therefore, $m^{-2}+n^{-1}$ converges to $0$ due to Thm. \ref{lb121} and the continuity of the addition map $(x,y)\in\Rbb^\mapsto x+y\in\Rbb$ (Prop. \ref{lb41}). Since $0\leq |x_{m,n}|\leq m^{-2}+n^{-1}$, we conclude $|x_{m,n}|\rightarrow 0$ (and hence $x_{m,n}\rightarrow0$) by squeeze theorem (Exe. \ref{lb123}).
\end{proof}







\subsubsection{Double limits and iterated limits}

\begin{thm}\label{lb122}
Let $(x_{\alpha,\beta})_{\alpha\in I,\beta\in J}$ be a double net in a metric space $X$. Assume that the following are true:
\begin{enumerate}[label=(\arabic*)]
\item The limit $\dps\lim_{(\alpha,\beta)\in I\times J}x_{\alpha,\beta}$ exists in $X$.
\item For each $\alpha\in I$, the limit $\dps\lim_{\beta\in J}x_{\alpha,\beta}$ exists in $X$.
\end{enumerate}
Then the LHS limit in the following equation exists and equals the RHS:
\begin{align}
\lim_{\alpha\in I}\lim_{\beta\in J}x_{\alpha,\beta}=\lim_{(\alpha,\beta)\in I\times J}x_{\alpha,\beta}
\end{align}
In particular, suppose that the following is also true:
\begin{itemize}
\item[(3)] For each $\beta\in J$, the limit $\dps\lim_{\alpha\in J}x_{\alpha,\beta}$ exists in $X$. 
\end{itemize}
Then the following limits exist and are equal:
\begin{align}
\lim_{\alpha\in I}\lim_{\beta\in J}x_{\alpha,\beta}=\lim_{\beta\in J}\lim_{\alpha\in I}x_{\alpha,\beta}
\end{align}
\end{thm}


\begin{proof}
Let $\dps x_\alpha=\lim_\beta x_{\alpha,\beta}$ and $\dps x=\lim_{\alpha,\beta}x_{\alpha,\beta}$. We want to show that $\dps\lim_\alpha x_\alpha=x$. Choose any $\eps>0$. Then there exist $A\in I,B\in J$ such that for every $\alpha\geq A$ and $\beta\geq B$ we have $d(x_{\alpha,\beta},x)<\eps/3$. In particular,  $d(x_{\alpha,\beta},x)\leq \eps/2$. Using Thm. \ref{lb121} and the fact that $p\in X\mapsto d(p,x)\in\Rbb$ is continuous (Exp. \ref{lb45}), we see that for every $\alpha\geq A$ we have $\dps d(x_\alpha,x)=\lim_{\beta\in J_{\geq B}} d(x_{\alpha,\beta},x)\leq \eps/2<\eps$.
\end{proof}

The readers may skip the next remark and proof and come back to them when they have learned about topological spaces.

\begin{srem}
Thm. \ref{lb122} can be generalized to the case that $X$ is a regular topological space. By saying that the topological space $X$ is \textbf{regular}, \index{00@Regular topological space} we mean that for every $x\in X$ and every open set $U$ containing $x$, there is a smaller open set $V$ containing $x$ such that the closure $\ovl V$  (cf. Def. \ref{lb183}) is contained in $U$.
\end{srem}

\begin{proof}[$\star$ Proof]
Let $\dps x_\alpha=\lim_\beta x_{\alpha,\beta}$ and $\dps x=\lim_{\alpha,\beta}x_{\alpha,\beta}$. Choose any open set $U$ containing $x$. We want to prove that $x_\alpha$ is eventually in $U$. Choose an open set $V$ containing $x$ such that $\ovl V\subset U$. Then there are $A\in I,B\in J$ such that for all $\alpha\geq A$ and $\beta\geq B$ we have $x_{\alpha,\beta}\in V$. Thus, for each $\alpha\geq A$, since $x_{\alpha,\beta}$ approaches $x_\alpha$, we have $x_\alpha\in \ovl V$ and hence $x_\alpha\in U$.
\end{proof}


\begin{co}
Let  $(x_{\alpha,\beta})_{\alpha\in I,\beta\in J}$ be a double net in $\ovl\Rbb$. Assume that $x_{\blt,\blt}$ is increasing, i.e., $x_{\alpha,\beta}\leq x_{\alpha',\beta'}$ if $\alpha\leq\alpha'$ and $\beta\leq \beta'$. Then the following equation \eqref{eq39} hold, where all the limits \eqref{eq39} exist in $\ovl\Rbb$:
\begin{align}
\lim_{\alpha\in I}\lim_{\beta\in J}x_{\alpha,\beta}=\lim_{\beta\in J}\lim_{\alpha\in I}x_{\alpha,\beta}=\lim_{(\alpha,\beta)\in I\times J}x_{\alpha,\beta}=\sup\{x_{\alpha,\beta}:\alpha\in I,\beta\in J\}  \label{eq39}
\end{align}
\end{co}

Clearly, a similar result holds for decreasing double nets in $\ovl\Rbb$.

\begin{proof}
By Exe. \ref{lb123}, the three limits $\dps\lim_\alpha x_{\alpha,\beta}$, $\dps\lim_\beta x_{\alpha,\beta}$, and $\dps\lim_{\alpha,\beta}x_{\alpha,\beta}$ exist in $\ovl\Rbb$. Therefore, by Thm. \ref{lb122}, the three limits in \eqref{eq39} exist and are equal. The last equality in \eqref{eq39} is also due to Exe. \ref{lb123}.
\end{proof}


\subsubsection{Cauchy nets}

\begin{df}
A net $(x_\alpha)_{\alpha\in I}$ in a metric space $X$ is called a Cauchy net \index{00@Cauchy net} if
\begin{align*}
\lim_{\alpha,\beta\in I}d(x_\alpha,x_\beta)=0
\end{align*}
Equivalently, this means that 
\begin{align}
\forall\eps>0~~~\exists \gamma\in I~~~\text{such that }\forall\alpha,\beta\geq\gamma~~~\text{we have }d(x_\alpha,x_\beta)<\eps
\end{align}
\end{df}

\begin{exe}
Show that the subnet of a Cauchy net is Cauchy.
\end{exe}


\begin{pp}\label{lb126}
A convergent net in a metric space is a Cauchy net.
\end{pp}

\begin{proof}
Let $(x_\alpha)_{\alpha\in I}$ converge to $x$ in a metric space $X$. Then $\lim_\alpha d(x_\alpha,x)=0$. Since $(d(x_\alpha,x))_{\alpha,\beta\in I}$ is a subnet (cf. Exp. \ref{lb124}), we have $\lim_{\alpha,\beta} d(x_\alpha,x)=0$ by Thm. \ref{lb120}. Similarly, we have $\lim_{\alpha,\beta}d(x,x_\beta)=0$. Since $0\leq d(x_\alpha,x_\beta)\leq d(x_\alpha,x)+d(x,x_\beta)$, by Squeeze theorem (Exe. \ref{lb123}) we have $\lim_{\alpha,\beta}d(x_\alpha,x_\beta)=0$.
\end{proof}

\begin{comment}
\begin{exe}
Prove Prop. \ref{lb126} directly using the definitions of convergent nets and Cauchy nets.
\end{exe}
\end{comment}


\begin{pp}\label{lb127}
Let $(x_\alpha)_{\alpha\in I}$ be a Cauchy net in a metric space $X$. Suppose that $(x_\alpha)_{\alpha\in I}$ has a convergent subnet $(x_{\alpha_s})_{s\in S}$ converging to $x\in X$. Then $(x_\alpha)_{\alpha\in I}$ converges to $x$.
\end{pp}

\begin{proof}
Choose any $\eps>0$. Since $(x_\alpha)$ is a Cauchy net, there exists $\gamma\in I$ such that $d(x_\alpha,x_\beta)\leq \eps$ for all $\alpha,\beta\geq \gamma$. Since $(\alpha_s)_{s\in S}$ has cofinal range, $\alpha_{s_0}\geq \gamma$ for some $s_0\in S$. Thus $\alpha_s\geq \gamma$ for all $s\geq s_0$ because $(\alpha_s)_{s\in S}$ is increasing and because of the transitivity in Def. \ref{lb116}. Thus, for every $\beta\geq\gamma$, $d(x_{\alpha_s},x_{\beta})\leq\eps$ for sufficiently large $s$. By taking limit over $s$ and using the continuity of $y\in X\mapsto d(y,x_\beta)$ as well as Thm. \ref{lb121}, we get $d(x,x_\beta)\leq \eps$ for all $\beta\geq\gamma$.
\end{proof}

\begin{df}\label{lb155}
Two nets $(x_\alpha)_{\alpha\in I}$ and $(y_\alpha)_{\alpha\in I}$ in a metric space $X$ are called \textbf{Cauchy-equivalent} \index{00@Cauchy-equivalent} if
\begin{align*}
\lim_{\alpha\in I}d(x_\alpha,y_\alpha)=0
\end{align*}
Two Cauchy nets are simply called \textbf{equivalent} if they are Cauchy-equivalent. It is not hard to see that Cauchy-equivalence is an equivalence relation (recall Def. \ref{lb156}) on $X^I$.
\end{df}


\begin{exe}\label{lb128}
Let $(x_\alpha)_{\alpha\in I}$ and $(y_\alpha)_{\alpha\in I}$ be nets in a metric space $X$. 
\begin{enumerate}
\item Assume that $(x_\alpha)_{\alpha\in I}$ and $(y_\alpha)_{\alpha\in I}$ are Cauchy-equivalent. Prove that $(x_\alpha)$ is a Cauchy net iff $(y_\alpha)$ is a Cauchy net.
\item Assume that $(x_\alpha)_{\alpha\in I}$ converges to $x$. Prove that $(y_\alpha)_{\alpha\in I}$ converges to $x$ iff $(x_\alpha)_{\alpha\in I}$ and $(y_\alpha)_{\alpha\in I}$ are Cauchy-equivalent.
\end{enumerate}
\end{exe}



\begin{thm}\label{lb129}
Every Cauchy net $(x_\alpha)_{\alpha\in I}$ in a complete metric space $X$ is convergent.
\end{thm}

We give a hint of the proof and leave the details to the readers as an exercise.

\begin{proof}[Hint]
Construct an increasing sequence $(\alpha_n)_{n\in\Zbb_+}$ in $I$ such that for every $\beta,\gamma\geq\alpha_n$ we have $d(x_\beta,x_\gamma)<1/n$. Prove that $(x_{\alpha_n})_{n\in\Zbb_+}$ is a Cauchy sequence, and hence converges to some $x\in X$. Prove that $(x_\alpha)_{\alpha\in I}$ converges to $x$. (Warning: $(x_{\alpha_n})_{n\in\Zbb_+}$ is not necessarily a subnet of $(x_\alpha)_{\alpha\in I}$.)
\end{proof}

\begin{comment}
\begin{proof}
Let $(x_\alpha)_{\alpha\in I}$ be a Cauchy net in a complete metric space $X$. Then $I\times \Nbb$ is a directed set. Define
\begin{align*}
S=\{(\alpha,n)\in I\times\Nbb:\forall \beta,\gamma\geq\alpha\text{ we have }d(x_\beta,x_\gamma)<1/n\}
\end{align*}
Then $(x_\alpha)_{(\alpha,n)\in S}$ is a subnet of $X$. Recall that every subnet of a Cauchy net is Cauchy. By Prop. \ref{lb127}, it suffices to show that the Cauchy net $(x_\alpha)_{(\alpha,n)\in S}$ converges.

For each $n\in\Zbb_+$, choose $\beta_n$ such that $(\beta_n,n)\in S$: the existence of $\beta_n$ is due to the Cauchyness of $(x_\alpha)_{\alpha\in I}$. Thus, if $(\alpha,n)\in S$, we have $d(x_\alpha,x_{\beta_n})<1/n$, and hence
\begin{align*}
\lim_{(\alpha,n)\in S}d(x_\alpha,x_{\beta_n})=0
\end{align*}
Therefore, by Exe. \ref{lb128}, it suffices to prove that the equivalent Cauchy net $(x_{\beta_n})_{(\alpha,n)\in S}$ is convergent. But this is a subnet of the sequence $(x_{\beta_n})_{n\in\Nbb}$. And clearly, the Cauchyness of $(x_{\beta_n})_{(\alpha,n)\in S}$ implies that of $(x_{\beta_n})_{n\in\Nbb}$. So the Cauchy sequence $(x_{\beta_n})_{n\in\Nbb}$ converges because $X$ is complete. So its subnet $(x_{\beta_n})_{(\alpha,n)\in S}$ converges.
\end{proof}
\end{comment}



\subsection{Unordered sums $\sum_{x\in X}f(x)$}

In this section, we fix $V$ to be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$. We fix a (non-necessarily countable) set $X$. Note that if $f:X\rightarrow V$ is a function and $X$ is finite, then $\sum_{x\in X}f(x)$ can be understood in its most obvious way.



\begin{df}\label{lb131}
Let $f:X\rightarrow V$ be a map. The expression
\begin{align*}
\sum_{x\in X}f(x)
\end{align*}
(or simply $\sum_X f$) is called an \textbf{unordered sum}.\index{00@Unordered sum} If $v\in V$, we say that $\sum_{x\in X}f(x)$ equals (or \text{converges} to) $v$, if
\begin{align}
\lim_{A\in\fin(2^X)}\sum_{x\in A}f(x)=v
\end{align}
In this case, we write
\begin{align}
\sum_{x\in X}f(x)=v \label{eq40}
\end{align}
\end{df}

\begin{rem}
Recall from Exp. \ref{lb130} that $\fin(2^X)$ is the directed set of finite subsets of $2^X$. Its preorder is ``$\subset$". So \eqref{eq40} means more precisely that:
\begin{itemize}
\item For every $\eps>0$, there exists a finite set $B\subset X$ such that for every finite set $A$ satisfying $B\subset A\subset X$, we have $\Vert v-\sum_{x\in A}f(x)\Vert<\eps$.
\end{itemize}
\end{rem}


\begin{rem}
Unordered sums are one of the most important and representative examples in Moore and Smith's original paper on nets (cf. \cite{MS22}), explaining why nets are called nets: Imagine an infinitely large \textit{fishing net} whose vertices form the set $X=\Zbb^2$. You grab the net with your hands and pull it up. As you pull it up, the lifted part $A\in\fin(2^X)$ becomes larger and larger.
\end{rem}


\begin{rem}\label{lb141}
One of the advantages of unordered sums over series is that  unordered sums are clearly invariant under rearrangement: For every bijection $\varphi:X\rightarrow X$, if one side of the following equation converges in $V$, then the other side converges, and the equation holds true:
\begin{align}
\sum_{x\in X}f(x)=\sum_{x\in X}f(\varphi(x))
\end{align} 
or simply $\sum_Xf=\sum_Xf\circ\varphi$.
\end{rem}


\begin{rem}\label{lb133}
Let us spell out what Cauchyness means for the net $(\sum_A f)_{A\in\fin(2^X)}$:
\begin{itemize}
\item[(1)] For every $\eps>0$, there exists a finite set $B\subset X$ such that for any finite sets $A_1,A_2$ satisfying $B\subset A_1\subset X,B\subset A_2\subset X$, we have
\begin{align*}
\Big\Vert \sum_{A_1\setminus A_2}f-\sum_{A_2\setminus A_1}f \Big\Vert<\eps
\end{align*} 
\end{itemize}
Note that the term inside the norm is $\sum_{A_1}f-\sum_{A_2}f$. This is also equivalent to:
\begin{itemize}
\item[(2)] For every $\eps>0$, there exists a finite set $B\subset X$ such that for any finite set $E\subset X\setminus B$, we have 
\begin{align*}
\Big\Vert \sum_Ef\Big\Vert<\eps
\end{align*}
\end{itemize}
We shall mainly use (2) as the Cauchy criterion for the convergence of $\sum_Xf$.
\end{rem}

\begin{proof}[Proof of the equivalence]
(2) follows from (1) by taking $A_1=B$ and $A_2=B\cup E$. (1) follows from (2) by taking $E_1=A_1\setminus A_2$ and $E_2=A_2\backslash A_1$ and then concluding $\Vert \sum_{E_1}f-\sum_{E_2}f\Vert<2\eps$.
\end{proof}





\begin{df}\label{lb132}
Let $g:X\rightarrow\ovl\Rbb_{\geq0}$ be a map. Note that the net $(\sum_A g)_{A\in\fin(2^X)}$ is increasing. Hence, its limit exists in $\ovl\Rbb$ and equals $\sup_{A\in\fin(2^X)}\sum_Ag$ (by Exe. \ref{lb123}). We write this as $\sum_Xg$, or more precisely:
\begin{align}
\sum_Xg\equiv\sum_{x\in X}g(x)\xlongequal{\mathrm{def}} \lim_{A\in \fin(2^X)}\sum_A g=\sup_{A\in \fin(2^X)}\sum_A g
\end{align}
We say that $\sum_Xg$ \textbf{converges} or \textbf{converges absolutely}, if $\sum_Xg<+\infty$. 
\end{df}

It is clear that $\sum_Xg<+\infty$ iff there exists $C\in\Rbb_{\geq0}$ such that $\sum_Ag<C$ for all $A\in\fin(2^X)$.


\begin{rem}
Note that when $g:X\rightarrow\Rbb_{\geq0}$, the convergence in Def. \ref{lb132} agrees with that in Def. \ref{lb131}. Therefore, Rem. \ref{lb133} still gives a Cauchy criterion for convergence.
\end{rem}






\begin{df}
Let $f:X\rightarrow V$. We say that $\sum_Xf$ \textbf{converges absolutely} \index{00@Absolutely convergent unordered sum} if 
\begin{align*}
\sum_{x\in X}\Vert f(x)\Vert<+\infty
\end{align*}
\end{df}



\begin{pp}\label{lb142}
Let $f:X\rightarrow V$. If $\sum_Xf$ converges absolutely, then it converges, and
\begin{align}
\Big\Vert \sum_{x\in X} f(x) \Big\Vert\leq\sum_{x\in X} \Vert f(x)\Vert \label{eq41}
\end{align}
We write this simply as $\Vert\sum_X f\Vert\leq\sum_X |f|$. (Recall Def. \ref{lb150}.)
\end{pp}

\begin{proof}
\eqref{eq41} clearly holds when $X$ is finite. In the general case, assume that $\sum_Xf $ converges absolutely. Then by Cauchy criterion (Rem. \ref{lb133}-(2)), for every $\eps>0$ there is $A\in \fin(2^X)$ such that for each finite $E\subset X\setminus A$ we have $\sum_E|f|<\eps$, and hence $\Vert \sum_E f\Vert<\eps$. Therefore $\sum_Xf$ converges by Cauchy criterion again.

By the continuity of the norm function $v\in V\mapsto \Vert v\Vert\in\Rbb_{\geq0}$, and by Thm. \ref{lb121}, we have
\begin{align*}
\Big\Vert \sum_X f \Big\Vert=\Big\Vert \lim_A \sum_Af \Big\Vert=\lim_A \Big\Vert \sum_Af \Big\Vert
\end{align*}
Since $\Vert \sum_A f\Vert\leq\sum_A|f|$, by Exe. \ref{lb123}, the above expression is no less than
\begin{align*}
\lim_A\sum_A|f|=\sum_X|f|
\end{align*}
\end{proof}

The following proposition gives another demonstration that unordered sums are more natural than series. We leave the proof to the readers.

\begin{pp}\label{lb134}
Let $f:X\rightarrow\Rbb^N$ where $N\in\Zbb_+$. Then
\begin{align*}
\sum_{x\in X}f(x)~~\textrm{converges}\qquad\Longleftrightarrow\qquad \sum_{x\in X}f(x)~~\text{converges absolutely}
\end{align*}

\end{pp}

\begin{proof}[Hint]
Reduce to the case $N=1$. Consider $A=\{x\in X:f(x)\geq 0\}$ and $B=X\setminus A$. 
\end{proof}

When $\Rbb^N$ is replaced by an infinite-dimensional Banach space, the convergence of a unordered sum may not imply absolute convergence. See Pb. \ref{lb149}.







\subsection{Fubini's theorem for unordered sums}\index{00@Fubini's theorem for unordered sums}\label{lb138}

Fix a Banach space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$. Let $X,Y$ be sets.

\begin{thm}[\textbf{Fubini's theorem-A}]\label{lb135} 
Let $f:X\times Y\rightarrow V$. Assume that $\sum_{X\times Y}f$ converges. Then $\sum_Y f(x,\cdot)$ converges for each $x\in X$, and $\sum_X f(\cdot,y)$ converges for each $y\in Y$, and 
\begin{align}\label{eq45}
\sum_{x\in X}\sum_{y\in Y}f(x,y)=\sum_{y\in Y}\sum_{x\in X}f(x,y)=\sum_{(x,y)\in X\times Y}f(x,y)
\end{align}
where all unordered sums converge in $V$.
\end{thm}

We abbreviate \eqref{eq45} to $\sum_X\sum_Yf=\sum_Y\sum_Xf=\sum_{X\times Y}f$.

\begin{proof}
For each $x\in X$, let $f_x(y)=f(x,y)$. Let us prove that $\sum_Y f_x$ converges.
Choose any $\eps>0$. Since $\sum_{X\times Y}f$ converges, by Cauchy criterion (Rem. \ref{lb133}-(2)), there exists a finite $S\subset X\times Y$ such that the sum of $f$ over any finite subset outside $S$ has norm $<\eps$. The projection $X\times Y\rightarrow Y$ maps $S$ to a finite set $B\subset Y$. Thus, for each finite $E\subset Y\setminus B$, we have $\Vert\sum_E f_x\Vert<\eps$ since $x\times E$ is outside $S$. Therefore $\sum_Y f_x$ converges. By the same reasoning, $\sum_Xf(\cdot,y)$ converges for all $y$.

Recall that $\sum_{X\times Y}f$ is the limit of the net $(\sum_S f)_{S\in\fin(2^{X\times Y})}$. This net has subnet
\begin{align*}
\Big(\sum_{(x,y)\in A\times B} f(x,y)\Big)_{A\in \mc I,B\in \mc J}\qquad \text{ where }\mc I=\fin(2^X)~~\mc J=\fin(2^Y)
\end{align*}
(Its index set is $\mc I\times\mc J$.) Thus, by Thm. \ref{lb120},
\begin{align}
\sum_{(x,y)\in X\times Y}f(x,y)=\lim_{A\in\mc I,B\in\mc J} \sum_{(x,y)\in A\times B} f(x,y) \label{eq43}
\end{align}
We are now going to use Thm. \ref{lb122} to show that
\begin{align}
\lim_{A\in\mc I,B\in\mc J} \sum_{(x,y)\in A\times B} f(x,y)=\lim_{A\in\mc I}\lim_{B\in\mc J} \sum_{(x,y)\in A\times B} f(x,y) \label{eq42}
\end{align}
where the RHS limit exists. For that purpose, we need to check for each $A\in\mc I$ the convergence of $\lim_B\sum_{(x,y)\in A\times B}f(x,y)$. Since $\sum_Yf_x$ converges, we have
\begin{align}
&\lim_{B\in\mc J}\sum_{(x,y)\in A\times B}f(x,y)=\lim_{B\in\mc J}\sum_{x\in A}\sum_{y\in B}f(x,y)\nonumber\\
=&\sum_{x\in A}\lim_{B\in\mc J}\sum_{y\in B}f(x,y)=\sum_{x\in A}\sum_{y\in Y}f(x,y)\label{eq44}
\end{align}
(Note that $\sum_A$ is a finite sum and hence commutes with $\lim_B$.) Thus, the assumption in Thm. \ref{lb122} ensuring \eqref{eq42} has now been proved true. So \eqref{eq42} is true. Moreover, combining \eqref{eq43}, \eqref{eq42}, \eqref{eq44}  together, we get
\begin{align*}
\sum_{(x,y)\in X\times Y}f(x,y)=\lim_{A\in\mc I}\sum_{x\in A}\sum_{y\in Y}f(x,y)=\sum_{x\in X}\sum_{y\in Y}f(x,y)
\end{align*}
where the second and the third limits exist. This proves a half of \eqref{eq45}. The other half can be proved in the same way.
\end{proof}








\begin{thm}[\textbf{Fubini's theorem-B}]\label{lb137}
Let $g:X\times Y\rightarrow\ovl\Rbb_{\geq0}$. Then the five unordered sums in \eqref{eq46} exist in $\ovl\Rbb_{\geq0}$, and equations \eqref{eq46} hold in $\ovl\Rbb_{\geq0}$:
\begin{align}\label{eq46}
\sum_{x\in X}\sum_{y\in Y}f(x,y)=\sum_{y\in Y}\sum_{x\in X}f(x,y)=\sum_{(x,y)\in X\times Y}f(x,y)
\end{align}
\end{thm}

\begin{proof}
The existence in $\ovl\Rbb_{\geq0}$ of the five unordered sums is clear. (Recall Def. \ref{lb132}.) Formula \eqref{eq46} can be proved in the same way as \eqref{eq45}. Note that when applying Thm. \ref{lb122} to prove \eqref{eq46}, the assumption in Thm. \ref{lb122} on the existence of limits is satisfied because all nets involved are increasing in $\ovl\Rbb$. (Recall Exe. \ref{lb123}.)
\end{proof}

\begin{co}[\textbf{Fubini's theorem-C}]
Let $f:X\times Y\rightarrow V$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $\sum_{X\times Y}f$ converges absolutely.
\item $\sum_{x\in X}\sum_{y\in Y}\Vert f(x,y)\Vert<+\infty$.
\item $\sum_{y\in Y}\sum_{x\in X} \Vert f(x,y)\Vert<+\infty$.
\end{enumerate}
\end{co}

\begin{proof}
Immediate from Thm. \ref{lb137}. It is also not hard to prove it directly.
\end{proof}

%% Record #6 2023/10/9 two lectures  14



\subsection{Parametrization theorem for unordered sums}

We fix a Banach space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$. In the following sections, we shall apply the results about unordered sums to the study of series and double series. For the convenience of applications (e.g. the proof of  $e^ze^w=e^{z+w}$), we enlarge the concept of series a little:

\subsubsection{Series over $\Zbb$}\label{lb151}


\begin{df}
A \textbf{series over $\Zbb$} \index{00@Series over $\Zbb$} is an expression
\begin{align*}
\sum_{n=-\infty}^{+\infty} f(n)
\end{align*}
where $f$ is a function from $\Zbb$ to either $V$ or $\ovl\Rbb_{\geq0}$. We say that this series \textbf{converges to}  (or equals) $\mu\in V$ resp.  equals $\mu\in\ovl\Rbb_{\geq0}$, if
\begin{align}
\lim_{m,n\rightarrow+\infty} \sum_{i=-m}^n f(i)=\mu \label{eq47}
\end{align}
In this case, we write
\begin{align*}
\sum_{n=-\infty}^{+\infty} f(n)=\mu
\end{align*}
We say that $\sum_{n=-\infty}^{+\infty}f(n)$ \textbf{converges absolutely} \index{00@Absolute convergent series over $\Zbb$} if $\sum_{n=-\infty}^{+\infty}\Vert f(n)\Vert<+\infty$.
\end{df}

\begin{rem}
Note that in the case of $\ovl\Rbb_{\geq0}$, the limit on the LHS of \eqref{eq47} must exist in $\ovl\Rbb_{\geq0}$. Again, this is due to the fact that the involved net is increasing, and so one can use Exe. \ref{lb123}.
\end{rem}



\begin{exe}\label{lb152}
Let $\sum_{n=-\infty}^{+\infty} f(n)$ be a series in either $V$ or $\ovl\Rbb_{\geq0}$.
\begin{enumerate}
\item Fix $k\in\Zbb$. Prove that $\sum_{n=-\infty}^{+\infty} f(n)$ converges iff the following limits converge:
\begin{subequations}
\begin{gather}
\sum_{n=k}^{+\infty} f(n)=\lim_{n\rightarrow+\infty} \sum_{i=k}^nf(i)\\
\sum_{n=-\infty}^{k-1} f(n)=\lim_{m\rightarrow+\infty} \sum_{i=-m}^{k-1}f(i)
\end{gather}
\end{subequations}
Moreover, if these limits converge, then
\begin{align}
\sum_{n=-\infty}^{+\infty}f(n)=\sum_{n=k}^{+\infty} f(n)+\sum_{n=-\infty}^{k-1} f(n)
\end{align}
\item In the case that $f$ has codomain $V$, prove that $\sum_{n=-\infty}^{+\infty} f(n)$ converges if it converges absolutely.
\item Prove that if $f$ is zero outside $\Zbb_+$, then
\begin{align}
\sum_{n=-\infty}^{+\infty}f(n)=\sum_{n=1}^{+\infty}f(n)  \label{eq48}
\end{align}
\end{enumerate}
\end{exe}

Thus, by \eqref{eq48}, our following results about series over $\Zbb$ can be directly applied to series over $\Zbb_+$ (or over $\Zbb_{\geq k}$ where $k\in\Zbb$).



\subsubsection{Parametrization theorem}

The following theorem relates series and unordered sums. The structure of this theorem is similar to that of Fubini's theorem-A,B,C in Sec. \ref{lb138}.

\begin{thm}[\textbf{Parametrization theorem}]\label{lb136}
Let $X$ be an infinite countable set. Let $\varphi:\Zbb\rightarrow X$ be a bijection (called a \textbf{parametrization} of $X$). \index{00@Parametrization (in unordered sums)} The following are true.
\begin{enumerate}
\item Let $f:X\rightarrow V$. If the RHS of \eqref{eq49} converges in $V$, then the LHS converges, and \eqref{eq49} holds:
\begin{align}
\sum_{n=-\infty}^{+\infty}f\circ\varphi(n)=\sum_{x\in X}f(x)\label{eq49}
\end{align}
\item Let $f:X\rightarrow\ovl\Rbb_{\geq0}$. Then \eqref{eq49} holds in $\ovl\Rbb_{\geq0}$.
\item Let $f:X\rightarrow V$. Then the unordered sum $\dps\sum_{x\in X} f(x)$ converges absolutely iff the series $\dps\sum_{n=-\infty}^{+\infty} f\circ\varphi(n)$ converges absolutely.
\end{enumerate}
The same conclusions hold if we assume that $\varphi:\Zbb_+\rightarrow X$ is a bijection.
\end{thm}



\begin{proof}
We prove the case $\varphi:\Zbb\rightarrow X$; the other case is similar. 

Assume that $\sum_Xf$ converges, which means that the limit of the net $(\sum_Af)_{A\in\fin(2^X)}$ converges to some $v\in V$. Therefore, by Thm. \ref{lb120}, the subnet
\begin{align*}
\Big(\sum_{x\in A_{m,n}}f(x)\Big)_{m,n\in\Zbb_+}=\Big(\sum_{i=-m}^n f\circ\varphi(i)\Big)_{m,n\in\Zbb_+}
\end{align*}
converges to $v$, where $A_{m,n}=\{\varphi(i):i\in\Zbb,-m\leq i\leq n\}$. This proves part 1. The same method proves part 2. Part 3 follows directly from part 2.
\end{proof}

\subsection{Application to (double) series and power series; $e^ze^w=e^{z+w}$}

Fix a Banach space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$.

\subsubsection{General results about series and double series}

\begin{co}\label{lb140}
Let $f:\Zbb\rightarrow V$, and let $\psi:\Zbb\rightarrow\Zbb$ be a bijection. Suppose that
\begin{align}
\sum_{n=-\infty}^{+\infty}\Vert f(n)\Vert<+\infty \label{eq54}
\end{align}
Then \eqref{eq50} holds true, where the RHS of \eqref{eq50} converges absolutely:
\begin{align}
\sum_{n=-\infty}^{+\infty} f(n)=\sum_{n=-\infty}^{+\infty}f\circ\psi(n) \label{eq50}
\end{align}
\end{co}
The same conclusion clearly holds if $\Zbb$ is replaced by $\Zbb_+$.

\begin{proof}
By \eqref{eq54} and Thm. \ref{lb136}-3, the unordered sum $\sum_\Zbb f$ converges absolutely, and hence converges. By Thm. \ref{lb136}-1, the LHS resp. RHS of \eqref{eq50} converges to the value of $\sum_\Zbb f$ if we choose the parametrization to be $\id_\Zbb$ resp. $\psi$. This proves \eqref{eq50} and the convergence of the RHS of \eqref{eq50}. Applying the same conclusion to $\Vert f(\cdot)\Vert$ proves the absolute convergence of the RHS of \eqref{eq50}.
\end{proof}


\begin{co}\label{lb139}
Let $f:\Zbb^2\rightarrow V$. Let $\Phi:\Zbb^2\rightarrow\Zbb^2$ be a bijection. Suppose that
\begin{align}\label{eq51}
\sum_{m=-\infty}^{+\infty}\sum_{n=-\infty}^{+\infty}\Vert f(m,n)\Vert<+\infty
\end{align}
Then \eqref{eq52} holds true, where the six series involved in \eqref{eq52} converge absolutely.
\begin{align}\label{eq52}
\sum_{m=-\infty}^{+\infty}\sum_{n=-\infty}^{+\infty} f(m,n)=\sum_{n=-\infty}^{+\infty}\sum_{m=-\infty}^{+\infty}f(m,n)=\sum_{k=-\infty}^{+\infty}\sum_{l=-\infty}^{+\infty} f\circ\Phi(k,l)
\end{align}
\end{co}

Similar results clearly hold if $\Zbb^2$ is replaced by $\Zbb_+^2$: One extends the domain of $f$ and the domain and codomain of $\Phi$ from $\Zbb_+^2$ to $\Zbb^2$. Then one apply Cor. \ref{lb139}. 

Also, note that the second term of \eqref{eq52} is redundant: it follows from the equality of the first and the third terms of \eqref{eq52} if we choose $\Phi(k,l)=(l,k)$.


\begin{proof}
By Thm. \ref{lb136}-2 and Thm. \ref{lb137}, we have
\begin{align}
\sum_{m=-\infty}^{+\infty}\sum_{n=-\infty}^{+\infty}\Vert f(m,n)\Vert=\sum_{x\in\Zbb}\sum_{y\in \Zbb}\Vert f(x,y)\Vert=\sum_{(x,y)\in\Zbb^2}\Vert f(x,y)\Vert\label{eq53}
\end{align}
where all the limits exist in $\ovl\Rbb_{\geq0}$. Therefore, by \eqref{eq51}, the unordered sum $\sum_{\Zbb^2}f$ is absolutely convergent and hence convergent. 

Similar to the argument for \eqref{eq53}, Thm. \ref{lb136}-1 and Thm. \ref{lb135} imply that the first two terms of \eqref{eq52}  exist and are both equal to the unordered sum $\sum_{\Zbb^2}f$. Since $\sum_{\Zbb^2}f=\sum_{\Zbb^2}f\circ\Phi$ (recall Rem. \ref{lb141}), by Thm. \ref{lb136}-1 and Thm. \ref{lb135} again, the last term of \eqref{eq52} converges to $\sum_{\Zbb^2}f\circ\Phi$.

We have proved that the six series in \eqref{eq52} converge, and \eqref{eq52} holds. Replacing $f(\cdot,\cdot)$ with $\Vert f(\cdot,\cdot)\Vert$ and applying a similar argument, we see that the six series in \eqref{eq52} converge absolutely. %(Note that one needs Prop. \ref{lb142} to show that $\sum\Vert \sum(\cdots)\Vert\leq\sum\sum\Vert(\cdots)\Vert<+\infty$.)
\end{proof}


\begin{rem}
Using the same method as in the above proof, one can easily prove a more general version of Cor. \ref{lb139}: Let $N\in\Zbb_+$. Let $f:\Zbb^2\rightarrow V$ such that \eqref{eq51} holds true. Let $\Psi:\Zbb^N\rightarrow\Zbb^2$ be a bijection. Then the $N$ series involved in the expression of \eqref{eq58} (from innermost to outermost) converge absolutely:
\begin{align}\label{eq58}
\sum_{n_1=-\infty}^{+\infty}\cdots \sum_{n_N=-\infty}^{+\infty}f\circ\Psi(n_1,\dots,n_N)
\end{align}
Moverover, the outermost series of \eqref{eq58} converges to \eqref{eq52}. And of course, a similar result holds if $\Zbb^2$ is replaced by $\Zbb^M$ for every $M\in\Zbb_+$. We leave it to the readers to fill in the details.
\end{rem}



%We remark that \eqref{eq52} is the most important reason we introduced series over $\Zbb$: If we restrict to series over $\Zbb_+$, the proof of \eqref{eq52} will involve more technical discussions.

\begin{co}\label{lb153}
Assume that
\begin{align*}
A=\sum_{n=-\infty}^{+\infty} a_n\qquad B=\sum_{n=-\infty}^{+\infty}b_n
\end{align*}
are absolutely convergent series in $\Cbb$. Then for each $k\in\Zbb$, the series
\begin{align*}
c_k=\sum_{l=-\infty}^{+\infty}a_{k-l}b_l
\end{align*}
converges absolutely. Moreover, the LHS of the \eqref{eq59} converges absolutely to the RHS:
\begin{align}\label{eq59}
\sum_{k=-\infty}^{+\infty}c_k=AB
\end{align}
\end{co}


\begin{proof}
Apply Cor. \ref{lb139} to the case that $f(m,n)=a_mb_n$ and $\Phi(k,l)=(k-l,l)$.
\end{proof}


\subsubsection{Application to power series}


\begin{co}\label{lb362}
Let $\dps f(z)=\sum_{n=0}^{+\infty}a_nz^n$ and $\dps g(z)=\sum_{n=0}^{+\infty}b_nz^n$ be power series in $\Cbb$ with radii of convergence $R_1,R_2$ respectively. Let $R=\min\{R_1,R_2\}$. For each $k\in\Zbb_+$, let
\begin{align*}
c_k=\sum_{l=0}^k a_{k-l}b_l
\end{align*}
Then the power series $\dps h(z)=\sum_{k=0}^{+\infty}c_kz^k$ has radius of convergence $\geq R$. Moreover, for each $z\in\Cbb$ satisfying $0\leq |z|<R$, we have
\begin{align*}
h(z)=f(z)\cdot g(z)
\end{align*}
\end{co}

\begin{proof}
For each $0\leq |z|<R$, apply Cor. \ref{lb153} by replacing the $a_n,b_n,c_k$ of Cor. \ref{lb153} with $a_nz^n,b_nz^n,c_kz^k$. This shows that $h(z)$ converges absolutely to $f(z)\cdot g(z)$. Since this is true for all $|z|<R$, $h(z)$ must have radius of convergence at least $R$ by Rem. \ref{lb108}.
\end{proof}

The above result also holds more generally for Laurent series. See Exe. \ref{lb154}.

\begin{co}\label{lb215}
For each $z,w\in\Cbb$ we have 
\begin{align*}
e^ze^w=e^{z+w}
\end{align*}
\end{co}

\begin{proof}
Apply Cor. \ref{lb153} to the case $a_n=z^n/n!$ and $b_n=w^n/n!$. (We set $a_n=b_n=0$ if $n<0$.) Then
\begin{align*}
c_k=\sum_{l=0}^{k} \frac{z^{k-l}}{(k-l)!}\cdot\frac{w^l}{l!}=\sum_{l=0}^k {k\choose l}\frac{z^{k-l}w^l}{k!}=\frac{(z+w)^k}{k!}
\end{align*}
by \eqref{eq60}.
\end{proof}




\subsection{Summary}


The following are some fundamental questions about series and double series:
\begin{itemize}
\item[(a)] Are they invariant under rearrangement? (Cf. \eqref{eq50}.) 
\item[(b)] Does the value of an interated double series remain unchanged if the order of the two infinite sums is changed? (Cf. the first equality in \eqref{eq52}.)
\item[(c)] A mixture of the above two questions. (Cf. the last term of \eqref{eq52}.)
\end{itemize}
We address these questions by relating them to unordered sum, a version of infinite sums which is parametrization-independent. The following are some key features of this theory.
\begin{enumerate}
\item (General principle)  A unordered sum is to a series (defined by parametrization) as a net to a subnet.
\item (Net $\Rightarrow$ Subnet) All subnets of a convergent net converge to the same value: the limit of the original net.
\item (Unordered sum $\Rightarrow$ Series) Therefore, different series converge to the same value if they are different parametrizations of the same convergent unordered sum.
\item (Unordered sums $\Rightarrow$ Series) Fubini-type theorems (any theorems about exchanging the orders of iterated sums/integrals) hold for convergent double unordered sums. Therefore, they hold when passing to subnets, in particular, when passing to double series.
\item (Subnet $\Rightarrow$ Net) Every increasing net in $\ovl\Rbb_{\geq0}$  has a limit in $\ovl\Rbb_{\geq0}$. Therefore, if an increasing net in $\Rbb_{\geq0}$ has a subnet converging to a number $<+\infty$, then the original net converges in $\Rbb_{\geq 0}$ (to a finite number).
\item (General principle) The unordered sum $\sum_{x\in X}\Vert f(x)\Vert$ is defined by the limit of an increasing net in $\ovl\Rbb_{\geq0}$.
\item (Series $\Rightarrow$ Unordered sum) Therefore, if any series or double series corresponds in a reasonable way to a unordered sum, then the absolute convergence of this (double) series (more specifically: \eqref{eq54} or \eqref{eq51}) implies the absolute convergence (and hence convergence) of the original unordered sum. This implies the absolute convergence of any other (double) series arising from that unordered sum.
\item (Conclusion) Thus, when a (double) series converges absolutely (in the form of \eqref{eq54} or \eqref{eq51}), the three problems (a), (b), (c) have satisfying answers. The reason absolutely convergent (double) series are so good is because increasing nets in $\ovl\Rbb_{\geq0}$ are very good!
\item (Counterexamples) Non-absolutely convergent series in $\Rbb$ have rearrangements converging to different values. This is because non-convergent nets may have two subnets converging to different values, cf. Pb. \ref{lb204}. (Recall from Prop. \ref{lb134} that for unordered sums in $\Rbb$, absolute convergence is equivalent to convergence.)
\end{enumerate}











\subsection{Problems and supplementary material}


Let $X$ be a set, and let $V$ be a Banach space over $\Rbb\in\{\Rbb,\Cbb\}$.





\begin{comment}
\begin{prob}
Prove Thm. \ref{lb129}, namely, prove that every Cauchy net $(x_\alpha)_{\alpha\in I}$ in a complete metric space $X$ is convergent.
\end{prob}


\begin{sprob}\label{lb266}
Let $f:X\rightarrow\Rbb$ be a function. Recall that $\fin(2^X)$ is the set of finite subsets of $X$. For each $A\in\fin(2^X)$, define
\begin{align*}
s_A=\sum_{x\in A}f(x)
\end{align*}
We say that $s\in\Rbb$ is a cluster point of the net $(s_A)_{A\in\fin(2^X)}$ if the following condition holds: 
\begin{itemize}
\item[($\varstar$)] For every $\eps>0$, $s_A$ is frequently in $B_\Rbb(s,\eps)$. (Namely, for every $\eps>0$ and $A\in\fin(2^X)$ there exists $B\in\fin(2^X)$ such that $A\subset B$ and $|s-s_B|<\eps$.) 
\end{itemize}
Answer the following questions.
\begin{enumerate}
\item Prove that if there is a bijection $\varphi:\Zbb_+\rightarrow X$ such that the series $\sum_{n=1}^\infty f\circ\varphi(n)$ converges to $s$, then $s$ is a cluster point of the net $(s_A)_{A\in\fin(2^X)}$.
\item Suppose that $s$ is a cluster point of $(s_A)_{A\in\fin(2^X)}$. Define $(I,\leq)$ to be
\begin{gather*}
I=\big\{(A,\eps)\in\fin(2^X)\times\Rbb_{>0}:|s-s_A|<\eps \big\}\\[0.5ex]
(A,\eps)\leq (A',\eps')\qquad\Longleftrightarrow\qquad A\subset A'\text{ and }\eps\geq\eps'
\end{gather*}
For each $\alpha=(A,\eps)\in I$, let $s_\alpha=s_A$. Prove that $I$ is a directed set. Prove that $(s_\alpha)_{\alpha\in I}$ is a subnet of $(s_A)_{A\in\fin(2^X)}$ if the increasing map $I\rightarrow \fin(2^X)$ is defined to be $(A,\eps)\mapsto A$. Prove that $(s_\alpha)_{\alpha\in I}$ converges to $s$.
\end{enumerate}
\end{sprob}
\end{comment}


\begin{prob}
Compute $\lim_{p,q\rightarrow+\infty}a_{p,q}$ where $(a_{p,q})_{p,q\in\Zbb_+}$ are given below. Or explain why the limit does not exist.
\begin{gather*}
a_{p,q}=\frac{(-1)^p\cdot p}{p+q} \qquad 
a_{p,q}=\frac{(-1)^p}{p}\qquad
a_{p,q}=\frac{\cos(p\pi/4)}{p+q}
\end{gather*}
\end{prob}


\begin{prob}
Prove Thm. \ref{lb129}. (Every Cauchy net in a complete metric space converges.)
\end{prob}



\begin{prob}\label{lb413}
Let $f:X\rightarrow V$. Define the \textbf{support} \index{00@Support $\Supp(f)$} \index{Supp@$\Supp(f)$} of $f$ to be
\begin{align}
\Supp(f)=\{x\in X:f(x)\neq 0\}
\end{align}
Prove that if $\sum_Xf$ converges absolutely, then $\Supp(f)$ is a countable set.
\end{prob}

\begin{proof}[Hint]
Consider $\{x\in X:|f(x)|\geq\eps\}$ where $\eps>0$.
\end{proof}




\begin{prob}
Prove Prop. \ref{lb134}. 
\end{prob}


\begin{sprob}\label{lb204}
Prove \textbf{Riemann rearrangement theorem}, which says the following: Let $\sum_{n=1}^{+\infty} x_n$ be a series in $\Rbb$ which converges and which does not converge absolutely. Choose any  $A\in\ovl\Rbb$. Then $\sum_{n=1}^{+\infty} x_n$ has a rearrangement converging to $A$ (i.e., there is bijection $\varphi:\Zbb_+\rightarrow\Zbb_+$ such that $\sum_{n=1}^{+\infty} f\circ\varphi(n)=A$).
\end{sprob}


\begin{rem}
By Riemann rearrangement theorem, it is clear that every convergent series in $\Rbb^N$ which is not absolutely convergent must have two  rearrangements converging to two different points. However, when $\Rbb^N$ is replaced by an infinite dimensional Banach space, one may find a series $\sum_{n=1}^{+\infty} v_n$ which does not converge absolutely but converge to some $v$, and every rearrangement of $\sum_{n=1}^{+\infty} v_n$ converges to $v$. See Pb. \ref{lb149}.
\end{rem}


\begin{prob}\label{lb149}
Consider the case that $V$ is the real Banach space $V=l^\infty(\Zbb_+,\Rbb)$. For each $n\in\Zbb_+$, let $e_n\in V$ be the characteristic function $\chi_{\{n\}}$. Namey, $e_n$ takes value $1$ at $n$, and takes $0$ at the other points. Prove that the unordered sum
\begin{align}
\sum_{n\in\Zbb_+}\frac 1{n}e_n \label{eq57}
\end{align}
converges in $V$, and find the limit. Prove that \eqref{eq57} does not converge absolutely.
\end{prob}


\begin{rem}
A more important example that will be considered later is $V=l^2(\Zbb_+,\Cbb)$, the set of all functions $f:\Zbb_+\rightarrow\Cbb$ satisfying that the \pmb{$l^2$}\textbf{-norm} $\Vert f\Vert_{l^2}=\sqrt{\sum_{n\in\Zbb_+} |f(n)|^2}$ is finite. Then $V$ is in fact a Banach space. (Actually, it is a so-called \textbf{Hilbert space}.) Again, let $e_n=\chi_{\{n\}}$. (These $e_n$ will be called an \textbf{orthonormal basis} of $V$.) Then for each $f\in V$, the unordered sum $\sum_{n\in\Zbb_+}f(n)\cdot e_n$ converges to $f$. But it does not converge absolutely if $\sum_{n\in\Zbb_+}|f(n)|=+\infty$. Take for example $f(n)=n^{-1}$. We will study these objects in the second semester.
\end{rem}


\begin{prob}
Define $(x_{j,k})_{(j,k)\in\Zbb_+\times\Zbb_+}$ to be
\begin{align*}
x_{j,k}=\left\{
\begin{array}{ll}
\dps\frac 1{j^2-k^2}
 & \text{if }j\neq k\\[2ex]
0&\text{if }j=k
\end{array}\right.
\end{align*}
Prove that the unordered sum $\dps\sum_{(j,k)\in\Zbb_+^2}x_{j,k}$ does not converge in $\Rbb$.
\end{prob}

\begin{proof}[Hint]
Consider $(x_{j,k})$ as a net over $\Zbb^2$. Find a good bijection $\Phi:\Zbb^2\rightarrow\Zbb^2$.
\end{proof}




\begin{df}
For each $f\in V^X$, define the \pmb{$l^1$}\textbf{-norm} \index{l1@$\Vert\cdot\Vert_{l^1}=\Vert\cdot\Vert_{1}$}
\begin{align*}
\Vert f\Vert_{l^1(X,V)}\equiv\Vert f\Vert_{l^1}\equiv\Vert f\Vert_1=\sum_{x\in X}\Vert f(x)\Vert
\end{align*}
Define the $l^1$-space \index{l1XV@$l^1(X,V)$}
\begin{gather*}
l^1(X,V)=\{f\in V^X:\Vert f\Vert_{l^1}<+\infty \}
\end{gather*}
Namely, $l^1(X,V)$ is the set of all $f\in V^X$ where $\sum_Xf$ converges absolutely. In particular, $\sum_Xf$ converges for such $f$. 
\end{df}


\begin{exe}
Prove that for each $f,g\in V^X$ and $\lambda\in\Fbb$, we have
\begin{gather}
\Vert f+g\Vert_1\leq \Vert f\Vert_1+\Vert g\Vert_1\qquad \Vert\lambda f\Vert_1=|\lambda|\cdot\Vert f\Vert_1
\end{gather}
Show that $l^1(X,V)$ is a linear subspace of $l^\infty(X,V)$, and that $\Vert\cdot\Vert_{l^1}$ is a norm on $l^1(X,V)$
\end{exe}

\begin{prob}
Prove that $l^1(X,V)$ is a Banach space. Namely, prove that the metric on $l^1(X,V)$ defined by the $l^1$-norm is complete.
\end{prob}


\begin{prob}\label{lb759}
Prove the \textbf{dominated convergence theorem} for unordered sums: Let $(f_\alpha)_{\alpha\in I}$ be a net in $V^X$ satisfying the following conditions:
\begin{enumerate}[label=(\arabic*)]
\item There exists $g\in l^1(X,\Rbb)$ satisfying $g\geq0$ (i.e. $g(x)\geq0$ for all $x\in X$) such that for every $\alpha\in I,x\in X$ we have
\begin{align*}
\Vert f_\alpha(x)\Vert\leq g(x)
\end{align*}
We simply write the above condition as $|f_\alpha|\leq g$.
\item $(f_\alpha)_{\alpha\in I}$ converges pointwise some $f\in V^X$. Namely, $\lim_\alpha f_\alpha(x)=f(x)$ for every $x\in X$.
\end{enumerate}
Prove that $f\in l^1(X,V)$. Prove that the LHS of \eqref{eq56} exists and equals the RHS: 
\begin{align}\label{eq56}
\lim_{\alpha\in I}\sum_{x\in X}f_\alpha(x)=\sum_{x\in X}f(x)
\end{align}
\end{prob}


\begin{sprob}
Assume $v_n\in V$ for each $n$. Let $z$ be a complex variable. Then the expression
\begin{align*}
f(z)=\sum_{n=-\infty}^{+\infty}v_nz^n
\end{align*}
is called a \textbf{Laurent series} \index{00@Laurent series} in $V$.

Prove that there exist unique $r,R\in\ovl\Rbb_{\geq0}$ such that $f(z)$ converges absolutely when $|r|<z<|R|$, and that $f(z)$ diverges when $|z|<r$ or $|z|>R$. Prove that
\begin{align}
r=\limsup_{n\rightarrow+\infty} \sqrt[n]{\Vert v_{-n}\Vert}\qquad R=\frac{1}{\dps\limsup_{n\rightarrow+\infty} \sqrt[n]{\Vert v_n\Vert}}
\end{align}
(Recall that by Exe. \ref{lb152}, $f(z)$ diverges iff either $\sum_{n=0}^\infty v_nz^n$ or $\sum_{n=-\infty}^{-1} v_nz^n$ diverges.) We call $r$ and $R$ the \textbf{radii of convergence} of $f(z)$. \hfill\qedsymbol
\end{sprob}

\begin{sexe}\label{lb154}
Consider Laurent series $f(z)=\sum_{n=-\infty}^{+\infty}a_nz^n$ (with radii of convergence $r_1<R_1$) and $g(z)=\sum_{n=-\infty}^{+\infty}b_nz^n$ (with radii of convergence $r_2<R_2$) in $\Cbb$. Let
\begin{align*}
r=\max\{r_1,r_2\}\qquad R=\min\{R_1,R_2\}
\end{align*}
Assume that $r<R$. Prove that for each $k\in\Zbb$, the series
\begin{align*}
c_k=\sum_{l=-\infty}^{+\infty}a_{k-l}b_l
\end{align*}
converges absolutely. Prove that for each $z\in\Cbb$ satisfying $r<|z|<R$, the LHS of the following equation converges absolutely to the RHS:
\begin{align}
\sum_{k=-\infty}^{+\infty}c_kz^k= f(z)g(z)
\end{align}
\end{sexe}





\newpage


\section{$\star$ Construction of $\Rbb$ from $\Qbb$}  \label{lb167}


The goal of this chapter is to construct real numbers from rationals. More precisely, our goal is to prove Thm. \ref{lb3}. We use the method of Cantor to construct real numbers using equivalence classes of Cauchy sequences in $\Qbb$. The idea is quite simple: If we admit the existence of $\Rbb$ satisfying Thm. \ref{lb3}, then by Prop. \ref{lb2}, each $x\in\Rbb$ is the limit of a sequence $(x_n)$ in $\Qbb$, which must be a Cauchy sequence. Moreover, if $(y_n)$ is a sequence in $\Qbb$ converging to $y\in\Rbb$, then by Exe. \ref{lb128} we have $x=y$ iff $(x_n)$ and $(y_n)$ are Cauchy equivalent. Motivated by this, we now do not assume the existence of $\Rbb$, and make the following definition:

\begin{df}
We let $\scr R$ be the set of Cauchy sequences in $\Qbb$, \footnote{Only in this chapter do we use $\scr R$ for this meaning.} namely, the set of $(x_n)_{n\in\Zbb_+}\in\Qbb^{\Zbb_+}$ satisfying 
\begin{align*}
\lim_{m,n\rightarrow+\infty} (x_m-x_n)=0
\end{align*}
We say that two elements $(x_n),(y_n)$ of $\scr R$ are Cauchy-equivalent and write $(x_n)\sim(y_n)$ if $\lim_{n\rightarrow\infty}(x_n-y_n)=0$.
\end{df}


Note that the above definition does not rely on the existence of $\Rbb$, because the limit of nets in $\Qbb$ can be defined using only rational numbers: a net $(\xi_\alpha)_{\alpha\in I}$ converges to $\xi$ iff for every $\eps\in\Qbb_{>0}$, $\xi_\alpha$ is eventually satisfies $|\xi_\alpha-\xi|<\eps$. The readers can check that all the properties about limit used in this chapter does not rely on the existence of $\Rbb$.

Cauchy-equivalence is clearly an equivalence condition on $\scr R$: For example, if $\lim (x_n-y_n)=\lim(y_n-z_n)=0$ then $|x_n-z_n|\leq |x_n-y_n|+|y_n-z_n|\rightarrow 0$. So $|x_n-z_n|\rightarrow0$. This proves the transitivity. The other two conditions are obvious. Therefore, we can define:

\begin{df}
We let $\Rbb=\scr R/\sim$ where $\sim$ is the Cauchy-equivalence relation. (Recall Def. \ref{lb157}). The equivalence class of $(x_n)_{n\in\Zbb_+}$ is denoted by $[x_n]_{n\in\Zbb_+}=[x_1,x_2,\dots]$, simply written as $[x_n]$. The zero element $0$ of $\Rbb$ is defined to be $[0,0,\dots]$. 
\end{df}




\begin{exe}\label{lb160}
Choose $[x_n]\in\Rbb$ (i.e. $(x_n)\in\scr R$) . The following are equivalent:
\begin{itemize}
\item[(1)] $[x_n]\neq 0$. Namely, $\lim_n x_n$ does not converge to $0$.
\item[(2)] There exists $\eps\in\Qbb_{>0}$ such that either $x_n>\eps$ eventually, or $x_n<-\eps$ eventually. In particular, $x_n\neq 0$ eventually.
\end{itemize}
Consequently, the map $a\in\Qbb\mapsto [a,a,\dots]\in\Rbb$ is injective. With the help of this injective map, $\Qbb$ can be viewed as a subset of $\Rbb$.
\end{exe}


\begin{exe}\label{lb159}
Let $[x_n]\in\Rbb$ and $a\in\Qbb$. Suppose that $x_n\geq a$ (resp. $x_n\leq a$) frequently.  Then for every $\eps\in\Qbb_{>0}$, we have that $x_n\geq a-\eps$ (resp. $x_n\leq a+\eps$) eventually.
\end{exe}





\begin{df}\label{lb158}
If $\xi,\eta\in\Rbb$, write $\xi=[x_n]$ and $\eta=[y_n]$. In the case that $\eta\neq0$, we assume $y_n\neq 0$ for all $n$, which is possible by Exe. \ref{lb160}. Define
\begin{gather*}
[x_n]+ [y_n]=[x_n+ y_n]\\
-[x_n]=[-x_n]\\
[x_n]\cdot [y_n]=[x_ny_n]\\
1/[y_n]=[1/y_n]\qquad(\text{if }[y_n]\neq0)
\end{gather*}
\end{df}


\begin{exe}
Prove that the above formulas are well-defined: For example, if $(x_n)\sim(x_n')$ in $\scr R$, then $(x_ny_n)\sim (x_n'y_n)$. (You may need the easy fact that every Cauchy sequence is bounded.)
\end{exe}

\begin{rem}\label{lb166}
It is clear that Def. \ref{lb158} makes $\Rbb$ a \textbf{field}, \index{00@Field} which means that for every $\alpha,\beta,\gamma\in\Rbb$, the following are satisfied:
\begin{gather*}
\alpha+\beta=\beta+\alpha\qquad  (\alpha+\beta)+\gamma=\alpha+(\beta+\gamma)\qquad 0+\alpha=\alpha\qquad \alpha+(-\alpha)=0\\
\alpha\beta=\beta\alpha\qquad (\alpha\beta)\gamma=\alpha(\beta\gamma)\qquad 1\cdot\alpha=\alpha\qquad(\alpha+\beta)\gamma=\alpha\gamma+\beta\gamma\\
\alpha\cdot \frac 1\alpha=1\qquad(\text{if }\alpha\neq0)
\end{gather*}
Moreover, $\Qbb$ is a subfield of $\Rbb$ where the addition, taking negative, multiplication, and inverse of $\Rbb$ restrict to those of $\Qbb$.
\end{rem}

\begin{df}\label{lb164}
Let $[x_n],[y_n]\in\Rbb$. We write $[x_n]<[y_n]$ if one of the following equivalent (due to Exe. \ref{lb159}) statements hold:
\begin{itemize}
\item There exists $\eps\in\Qbb_{>0}$ such that $y_n-x_n>\eps$ eventually. 
\item There exists $\eps\in\Qbb_{>0}$ such that $y_n-x_n>\eps$ frequently. 
\end{itemize}
It is not hard show that $``<"$ is well-defined, and that (by Exe. \ref{lb160}) if $[x_n]<[y_n]$ then $[x_n]\neq [y_n]$. We write $[x_n]\leq [y_n]$ if $[x_n]<[y_n]$ or $x_n=y_n$.
\end{df}

\begin{lm}
$(\Rbb,\leq)$ is a totally ordered set.
\end{lm}

\begin{proof}
Choose $[x_n],[y_n],[z_n]\in\Rbb$. If $[x_n]<[y_n]$ and $[y_n]<[z_n]$, then clearly $[x_n]<[z_n]$. This proves that $\leq$ is a preorder. 

Suppose $[x_n]\leq[y_n]$ and $[y_n]\leq[x_n]$. Let us prove $[x_n]=[y_n]$. Suppose not. Then $[x_n]<[y_n]$ and $[y_n]<[x_n]$ by the definition of ``$\leq$". So there is $\eps>0$ such that $y_n-x_n>\eps$ eventually, and $x_n-y_n>\eps$ eventually. Impossible. So $\leq$ is a partial order.

Suppose $[x_n]\neq [y_n]$. Then $(x_n-y_n)\nsim 0$. So Exe. \ref{lb160} implies that either $[x_n]<[y_n]$ or $[y_n]<[x_n]$. So $\leq$ is a total order.
\end{proof}

\begin{lm}\label{lb165}
Let $[x_n],[y_n]\in\Rbb$. Then the following are equivalent.
\begin{itemize}
\item $[x_n]\geq[y_n]$.
\item For every $\eps\in\Qbb_{>0}$, $x_n-y_n\geq-\eps$ frequently.
\item For every $\eps\in\Qbb_{>0}$, $x_n-y_n\geq-\eps$ eventually.
\end{itemize}
\end{lm}

\begin{proof}
Since $\leq$ is a total order, the negation of $>$ is $\leq$. So the statements follow immediately by negating Def. \ref{lb164}.
\end{proof}



\begin{lm}
$\Rbb$ is an ordered field extension of $\Qbb$, and $\Rbb$ is Archimedean.
\end{lm}

\begin{proof}
The order of $\Rbb$ clearly restricts to that of $\Qbb$. We want to prove that $\Rbb$ is an ordered field. (Recall Def. \ref{lb161}). Clearly, if $[x_n]<[y_n]$ and $[z_n]\in\Rbb$, then $[x_n]+[z_n]=[x_n+z_n]<[y_n+z_n]=[y_n]+[z_n]$. If $[x_n]>0$ and $[y_n]>0$, then there are $\eps>0$ such that $x_n>\eps$ eventually and $y_n>\eps$ eventually. So $x_ny_n>\eps^2$ eventually. So $[x_n][y_n]>0$. This proves that $\Rbb$ is an ordered field.

Now let $[x_n]>0$ and $[y_n]\in\Rbb$. So there exist $\eps\in\Qbb_{>0}$ such that $x_n>\eps$ eventually. Since $(y_n)$ is Cauchy, one checks easily that $(y_n)$ is bounded. So there is $M\in\Qbb_{>0}$ such that $|y_n|\leq M$ for all $n$. Since $\Qbb$ is Archimedean, there exists $k\in\Zbb_+$ such that $k\eps>M+1$. So $kx_n>M+1$ eventually. So $k[x_n]>M$. This proves that $\Rbb$ is Archimedean.
\end{proof}




To finish the proof of Thm. \ref{lb3}, it remains to prove that $\Rbb$ satisfies the least-upper-bound property.


\begin{lm}\label{lb162}
Thm. \ref{lb3} holds if every bounded increasing sequence in $\Rbb$ converges.
\end{lm}

\begin{proof}
Suppose that every bounded increasing sequence in $\Rbb$ converges. Choose any nonempty $E\subset \Rbb$ bounded from above. We shall show that $E$ has a least upper bound.

Let $F$ be the set of upper bounds of $E$. Namely, $F=\{\eta\in\Rbb:\eta\geq\xi,\forall\xi\in E\}$. So $F\neq\emptyset$. We construct an increasing sequence $(\xi_k)$ in $E$ and an decreasing sequence $(\eta_k)$ in $F$ as follows. Since $E,F$ are nonempty, we choose arbitrary $\xi_1\in E$ and $\eta_1\in F$. Then $\xi_1\leq \eta_1$. Suppose $\xi_1\leq\cdots\leq\xi_k\in E$ and $\eta_1\geq\cdots\geq\eta_k\in F$ have been constructed. Let $\psi_k=(\xi_k+\eta_k)/2$. Let
\begin{gather*}
\left\{
\begin{array}{ll}
\xi_{k+1}=\psi_k,\eta_{k+1}=\eta_k &\text{ if }\psi_k\in E\\
\xi_{k+1}=\xi_k,\eta_{k+1}=\psi_k &\text{ if }\psi_k\in F
\end{array}
\right.
\end{gather*}
Then the sequences we have constructed satisfy $\lim_{k\rightarrow\infty}(\eta_k-\psi_k)=0$.

By assumption, $\alpha=\lim_{k\rightarrow\infty}\xi_k$ exists, and it equals $\lim_k \eta_k$.  So $\alpha$ is an upper bound of $E$. (If $\lambda\in E$, then $\lambda\leq \eta_k$ for all $k$ since $\eta_k\in F$. So $\lambda\leq\lim_k\eta_k=\alpha$.) We now show that $\alpha$ is the least upper bound. Let $\eps>0$. Since $\xi_k\rightarrow\alpha$, there is $k$ such that $\alpha-\xi_k<\eps$. So $\xi_k>\alpha-\eps$, and hence $\alpha-\eps$ is not an upper bound of $E$.
\end{proof}


\begin{lm}\label{lb163}
Thm. \ref{lb3} holds if every bounded increasing sequence in $\Qbb$ converges to an element of $\Rbb$.
\end{lm}

\begin{proof}
Suppose that every increasing sequence in $\Qbb$ converges in $\Rbb$. By Lem. \ref{lb162}, it suffices to prove that every increasing sequence $(\xi_k)$ in $\Rbb$ converges. If $\{\xi_{k}:k\in\Zbb_+\}$ is a finite subset of $\Rbb$, then $(\xi_k)$ clearly converges. If $\{\xi_{k}:k\in\Zbb_+\}$ is infinite, then $(\xi_k)$ clearly has a strictly increasing subsequence $(\xi_{k_l})$. If we can prove that $(\xi_{k_l})$ converges to some $\psi\in\Rbb$, then $(\xi_k)$ converges to $\psi$. (Choose any $\eps>0$. Choose $L\in\Zbb_+$ such that $|\psi-\xi_{k_L}|<\eps$ and hence $0\leq \psi-\xi_{k_L}<\eps$. Then for all $k\geq k_L$ we have $0\leq\psi-\xi_k<\eps$.)

Thus, it remains to prove that every strictly increasing sequence $(\eta_k)$ in $\Rbb$ converges. Since we have proved that $\Rbb$ is an Archimedean ordered field extension of $\Qbb$, by Prop. \ref{lb2}, for each $k$, there exists $a_k\in\Qbb$ such that $\xi_k< a_k< \xi_{k+1}$. By assumption, $(a_k)$ converges to some $\alpha\in\Rbb$. Since $a_{k-1}<\xi_k< a_k$, by squeeze theorem, $(\xi_k)$ converges to $\alpha$.
\end{proof}




\begin{proof}[\textbf{Proof of Thm. \ref{lb3}}]
By Lem. \ref{lb163}, it suffices to show that every bounded increasing sequence $(a_k)$ in $\Qbb$ converges in $\Rbb$. Let $M\in\Qbb$ such that $a_k\leq M$ for all $k$.

We first prove that $(a_k)$ is a Cauchy sequence. If not, then there exists $\eps\in\Qbb_{>0}$ such that for every $K\in\Zbb_+$ there is $k>K$ such that $|a_k-a_K|>\eps$, and hence $a_k-a_K>\eps$. Thus, we can find a subsequence $(a_{k_l})$ such that $a_{k_{l+1}}-a_{k_l}>\eps$. By the Archimedean property for $\Qbb$, there is $l\in\Zbb_+$ such that $a_{k_1}+l\cdot\eps>M$. So $a_{k_{l+1}}>M$, impossible.



Note that each $a_k$ is identified with $\xi_k=[a_k,a_k,\dots]$. Let $\psi=[a_1,a_2,a_3,\dots]$, which is an element of $\Rbb$ since we just proved that $(a_n)\in\scr R$. Then for each $k$, $\psi-\xi_k=[a_1-a_k,a_2-a_k,\dots]$, where the terms are eventually $\geq0$. So $\xi_k\leq\psi$ by Lem. \ref{lb165}. We have proved that $\psi$ is an upper bound for the sequence $(\xi_k)$.

Let us prove that $\lim_k\xi_k=\psi$. Choose any $\eps\in\Qbb_{>0}$. Let us prove that there exists $k$ such that $\psi-\eps<\xi_k$. Then for every $k'\geq k$ we have $\psi-\eps<\xi_{k'}\leq\psi$, finishing the proof of $\lim_k\xi_k=\psi$.

We have proved that $a_1,a_2,\dots$ is a Cauchy sequence in $\Qbb$. So there exists $k$ such that $a_l-a_k<\eps/2$ for all $l\geq k$. Thus, for all $l\geq k$ we have $a_k-(a_l-\eps)>\eps/2$. Thus, the $l$-th term of $\xi_k=[a_k,a_k,\dots]$ minus that of $\psi-\eps=[a_1-\eps,a_2-\eps,\dots]$ is $>\eps/2$ for sufficiently large $l$. By Def. \ref{lb164}, we have that $\psi-\eps<\xi_k$.
\end{proof}

\newpage

\section{Topological spaces}\label{lb350}


\subsection{The topologies of metric spaces}\label{lb169}

In this chapter, we begin our study of topological spaces, which were introduced by Hausdorff in 1914 \cite{Hau14} as a generalization of metric spaces. As we have seen, focusing on metrics in order to study convergence and continuity is often distracting. For example, in $\ovl\Rbb$, we only care about how the convergence of sequences look like, but not about the particular metrics. The same is true about the countable product of metric spaces $S=\prod_{i\in\Zbb_+}X_i$: the metrics \eqref{eq16} and \eqref{eq61} give the same topology, although they look very different. Moreover, the shapes of the open balls defined by these two metrics are not very simple. This makes it more difficult to study the continuity of functions on $S$ by using (2) or (2') of Def. \ref{lb31}.




Topological spaces generalize metric spaces by giving a set of axioms satisfied by the open sets of the spaces.

\begin{df}\label{lb168}
Let $X$ be a metric space, and let $E\subset X$. A point $x\in E$ is called an \textbf{interior point} of $E$ if $B_X(x,r)\subset E$ for some $r>0$. We say that $E$ is an \textbf{open (sub)set} of $X$, \index{00@Open set of a metric spaces} if every point of $E$ is an interior point.
\end{df}

\begin{df}
Let $\mc T$ be the set of open sets of $X$. We call $\mc T$ the \textbf{topology of the metric space} $X$. \index{00@Topology of a metric space}
\end{df}

\begin{eg}
By triangle inequality, every open ball of a metric space $X$ is open. $\emptyset$ and $X$ are open subsets of $X$. If $p,q\in\Rbb^N$ and $d(p,x)=r$ (where $0\leq r<+\infty$), then $p$ is not an interior point of $\ovl B_{\Rbb^N}(x,r)$. So the closed balls of $\Rbb^N$ are not open sets. In particular, $[a,b]$ are not open subsets of $\Rbb$ since $a,b$ are not interior points.
\end{eg}

\begin{eg}
It is not hard to see that a finite intersection of open sets is open.
\end{eg}



In topological spaces, open sets play the role of open balls in metric spaces due to the following facts:

\begin{exe}
Let $(x_n)$ be a sequence in a metric space $X$. Let $x\in X$. Show that the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $(x_n)$ converges to $x$.
\item For every \textbf{neighborhood $U$ of $x$} (i.e. every open set containing $x$) there is $N\in\Zbb_+$ such that for every $n\geq N$ we have $x_n\in U$.
\end{enumerate}
\end{exe}
\begin{exe}
Let $f:X\rightarrow Y$ be a map of metric spaces. Let $x\in X$ and $y=f(x)$. Prove that the following are equivalent. 
\begin{enumerate}[label=(\arabic*)]
\item $f$ is continuous at $x$.
\item For every neighborhood $V$ of $y$ there is a neighborhood $U$ of $x$ such that $f(U)\subset V$ (equivalently, $U\subset f^{-1}(V)$.)
\end{enumerate}
\end{exe}


But there is an important difference between the intuitions of open sets and open balls: We want the open balls at a point $x$ to be small so that they can be used to describe the approximation to $x$. However, an arbitrary open set can be very large. For example, when studying convergence and continuity in $\Rbb$, we really want a neighborhood of $1$ to be $(1-\eps,1+\eps)$ but not the more complicated and bigger one $(-\infty,-2)\cup (0,100-\eps)$. Indeed, open sets can be very big:


\begin{lm}
Let $X$ be a metric space. If $(U_\alpha)_{\alpha\in I}$ is a family of open subsets of $X$, then $W=\bigcup_{\alpha\in I}U_\alpha$ is open in $X$.
\end{lm}

\begin{proof}
Choose $x\in W$. Then $x\in U_\alpha$ for some $\alpha$. So $B_X(x,r)\subset U_\alpha$ for some $r>0$. So $x$ is an interior point of $W$.
\end{proof}



Thus, people very often choose a class $\mc B$ of smaller open sets (such as the set of open balls) to study the analytic properties of a topological space. 
\begin{df}\label{lb170}
Let $\mc B$ be a set of open sets of a metric space (or more generally, a topological space) $X$. We say that $\mc B$ is a \textbf{basis for the topology} \index{00@Basis for topology} $\mc T$ of $X$ if one of the following (clearly) equivalent statements holds:
\begin{itemize}
\item For every point $x\in X$ and every neighborhood $W$ of $x$ there exists $U\in\mc B$ such that $x\in U$ and $U\subset W$.
\item Every open subset of $X$ is a union of some members of $\mc B$.
\end{itemize}
\end{df}

Thus, according to Def. \ref{lb168}, the set of open balls of a metric space $X$ form a basis for the topology of $X$. Nevertheless, even in the case of metric spaces, we sometimes consider more convenient bases than the set of open balls. We will see this when we study the topologies of infinite product spaces.


\subsection{Topological spaces}


\subsubsection{Definitions and basic examples}

\begin{df}\label{lb178}
We say that a pair $(X,\mc T)$ (or simply $X$) is a \textbf{topological space} \index{00@Topological space} if $X$ is a set, and if $\mc T$ (called the \textbf{topology} of $X$) is a set of subsets of $X$ satisfying the following conditions
\begin{itemize}
\item $\emptyset\in\mc T$ and $X\in \mc T$.
\item (Union property) If $(U_\alpha)_{\alpha\in I}$ is a family of elements of $\mc T$, then $\bigcup_{\alpha\in I}U_\alpha$ is an element of $\mc T$.
\item (Finite intersection property) If $n\in\Zbb_+$ and $U_1,\dots,U_n\in\mc T$, then $U_1\cap\cdots\cap U_n$ is an element of $\mc T$.
\end{itemize}
Elements of $\mc T$ are called \textbf{open (sub)sets} \index{00@Open set} of $X$.
\end{df}


\begin{df}
Let $X$ be a topological space, and $x\in X$. A subset $U\subset X$ is called  a \index{00@Neighborhood=open set containing the point} \textbf{neighborhood} of $x$, if $U$ is an open subset of $X$ containing $x$.\footnote{We are following the convention in \cite{Mun,Rud-R}. But many people refer to the word "neighborhood" with slightly different meaning: a subset $A$ is called a neighborhood of $x$ if there is an open set $U$ such that $x\in U\subset A$. And our neighborhoods are called ``open neighborhoods" by them.} We define $(\Nbh_X(x),\leq)$, \index{Nbh@$\Nbh_X(x)=\Nbh(x)$}  the \textbf{directed set of neighborhoods of $x$}, \index{00@Directed set of neighborhoods of a point} to be 
\begin{gather}
\begin{gathered}
\Nbh_X(x)=\{\text{neighborhoods of }x\text{ in }X\}\\
U\leq U'\qquad\Longleftrightarrow \qquad U\supset U'
\end{gathered}
\end{gather} 
(Note that one needs the finite intersection property to show that $\Nbh_X(x)$ is a directed set.) We abbreviate this set to $\Nbh_X(x)$ or simply $\Nbh(x)$.
\end{df}


\begin{eg}\label{lb529}
In Subsec. \ref{lb169}, we have proved that the topology of a metric space satisfies the above axioms of a topological space. 

In particular,   if $X$ is a normed vector space, the topology induced by the metric $d(x,x')=\Vert x-x'\Vert$ is called the \textbf{norm topology}. \index{00@Norm topology} If $X$ is a subset of $\Rbb^N$ or $\Cbb^N$, the topology on $X$ induced by the Euclidean metric is called the \textbf{Euclidean topology}. \index{00@Euclidean topology}  \hfill\qedsymbol
\end{eg}

\begin{df}
A topological space $(X,\mc T)$ is called \textbf{metrizable}, \index{00@Metrizable topological space} if there is a metric on $X$ inducing the topology $\mc T$. 
\end{df}


We have seen that the open balls of a metric space generate a topology. In general, one may ask what possible subsets of $2^X$ generate a topology on a set $X$. Here is a description, whose proof is left to the readers as an exercise.

\begin{pp}\label{lb171}
Let $X$ be a set, and let $\mc B\subset 2^X$. Define
\begin{align}
\mc T=\{\text{Unions of elements of }\mc B\}
\end{align}
The following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $(X,\mc T)$ is a topological space.
\item The following are satisfied:
\begin{itemize}
\item[(2-a)] $X=\bigcup_{U\in\mc B}U$.
\item[(2-b)] If $U_1,U_2\in\mc B$, then $U_1\cap U_2\in\mc T$ (i.e., for each $x\in U_1\cap U_2$ there exists $V\in\mc B$ such that $x\in V$ and $V\subset U_1\cap U_2$).
\end{itemize} 
\end{enumerate}
\end{pp}

When (1) or (2) holds, we call $\mc T$ the \textbf{topology generated by $\mc B$}. \index{00@Topology generated by the basis} Clearly, $\mc B$ is a basis for $\mc T$ (cf. Def. \ref{lb170}).





\begin{exe}\label{lb172}
Let $X$ be a set. Let $\mc B,\mc B'$ be subsets of $2^X$ generating topologies $\mc T,\mc T'$ respectively. Prove that the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $\mc T=\mc T'$.
\item Each $U\in\mc B$ is a union of elements of $\mc B'$. Each $U'\in\mc B'$ is a union of elements of $\mc B$.
\item For each $U\in\mc B$ and $x\in U$, there exists $U'\in\mc B'$ such that $x\in U'\subset U$. For each $U'\in\mc B$ and $x\in U'$, there exists $U\in\mc B$ such that $x\in U\subset U'$.
\end{enumerate} 
\end{exe}

\begin{eg}
If $(X,\mc T)$ is a topological space, then $\mc T$ is a basis for $\mc T$.
\end{eg}

\begin{eg}
Let $(X,d)$ be a metric space with topology $\mc T$. Let $\mc B=\{B_X(x,r):x\in X,0<r<+\infty\}$. Then $\mc B$ is a basis for $\mc T$. For each $\eps>0$, the set $\mc B'=\{B_X(x,r):x\in X,0<r<\eps\}$ is also a basis for $\mc T$.
\end{eg}

\begin{eg}\label{lb691}
Let $\mc B\subset 2^{\ovl\Rbb}$ be defined by
\begin{gather}
\mc B=\{(a,b),(c,+\infty],[-\infty,d):a,b,c,d\in\Rbb \}  \label{eq62}
\end{gather}
Using Prop. \ref{lb171}, one easily checks that $\mc B$ is a basis for a topology $\mc T$. We call this the \textbf{standard topology} of $\ovl\Rbb$. \index{00@Topology of $\ovl\Rbb$}

Let $\varphi:\ovl\Rbb\rightarrow[u,v]$ be a strictly increasing bijection where $-\infty<u<v<+\infty$. Let $d_{[u,v]}$ be the Euclidean metric, and let $\mc T'$ be the topology on $\ovl\Rbb$ defined by $d_{\ovl\Rbb}=\varphi^*d_{[u,v]}$. Then the set of open balls under $\mc T'$ is
\begin{align*}
\mc B'=\{&(\varphi^{-1}(y-\eps),\varphi^{-1}(y+\eps)), (\varphi^{-1}(v-\eps'),+\infty],[-\infty,\varphi^{-1}(u+\eps'')):\\
&y\in(u,v)\text{ and } \eps,\eps',\eps''\in\Rbb_{>0} \}
\end{align*}
(Note that the three types of intervals in the definition of $\mc B'$ are open balls centered at $\varphi^{-1}(y),+\infty,-\infty$ respectively.) Using Exe. \ref{lb172}, one easily checks $\mc T=\mc T'$. \hfill\qedsymbol 
\end{eg}

\begin{cv}\label{lb173}
Unless otherwise stated, the topology on $\ovl\Rbb$ is defined to be the standard one, i.e., the one generated by \eqref{eq62}. We shall forget about the metric on $\ovl\Rbb$, and view $\ovl\Rbb$ only as a (metrizable) topological space.
\end{cv}



\begin{df}\label{lb180}
Let $A$ be a subset of a topological space $(X,\mc T_X)$. Then
\begin{align*}
\mc T_A=\{U\cap A:U\in \mc T_X\}
\end{align*} 
is clearly a topology on $A$, called the \textbf{subspace topology}. \index{00@Subspace topology} Unless otherwise stated, when viewing a subset as a topological subspace, we always choose the subspace topology for the subset.
\end{df}




\begin{exe}
Let $(X,d_X)$ be a metric space, inducing a topology $\mc T_X$. Let $A$ be a metric subspace of $X$. (So $A\subset X$, and $d_X$ restricts to $d_A$.) Prove that the topology on $A$ induced by $d_A$ is the subspace topology.
\end{exe}


According to the above exercise, if $X$ is a metric space, then viewing a subset $A$ as a topological subspace is compatible with viewing $A$ as a metric subspace.

\begin{exe}\label{lb209}
Let $A$ be a subset of a topological space $X$. Let $\mc B$ be a basis for the topology of $X$. Show that $\{U\cap A:U\in\mc B\}$ is a basis for the subspace topology of $A$.
\end{exe}




\subsubsection{Convergence of nets}



\begin{df}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a topological space $X$. Let $x\in X$. We say that $(x_\alpha)$ \textbf{converges to} $x$ and write \index{lim@$\lim_{\alpha\in I}x_\alpha\equiv \lim_\alpha x_\alpha$}
\begin{align*}
\lim_{\alpha\in I}x_\alpha\equiv \lim_\alpha x_\alpha=x
\end{align*}
or simply write $x_\alpha\rightarrow x$, if the following statement holds:
\begin{itemize}
\item For every $U\in\Nbh_X(x)$, we have that $x_\alpha$ is eventually in $U$.
\end{itemize}
Clearly, if $\mc B$ is a basis for the topology, then $x_\alpha\rightarrow x$ iff:
\begin{itemize}
\item For every $U\in\mc B$ containing $x$, we have that $x_\alpha$ is eventually in $U$.
\end{itemize}
In the case that $X$ is a metric space (and the topology of $X$ is induced by the metric), the definition here agrees with Def. \ref{lb174}.
\end{df}

\begin{exe}
Let $(x_\alpha)$ be a net in $X$ converging to $x\in X$. Prove that every subnet of $(x_\alpha)$ converges to $x$.
\end{exe}

\begin{exe}
Let $A$ be a subset of a topological space $X$, equipped with the subspace topology. Let $(x_\alpha)$ be a net in $A$, and let $x\in A$. Show that $x_\alpha\rightarrow x$ in $A$ iff $x_\alpha\rightarrow x$ in $X$.
\end{exe}




\begin{eg}
Let $X$ be a set. Let $\mc T=\{\emptyset,X\}$. Then every net in $X$ converges to every point of $X$. Thus, if $X$ has at least two elements, then the limit of a net in $X$ is not unique. Therefore, a general topological space might be very pathological. To avoid this uniqueness issue, we introduce the following notion:
\end{eg}



\begin{df}\label{lb268}
Let $X$ be a topological space with a basis for the topology $\mc B$. We say that $X$ is a \textbf{Hausdorff space} if the following equivalent conditions are satisfied:
\begin{itemize}
\item[(1)] (Hausdorff condition) If $x,y\in X$ and $x\neq y$, then there exist neighborhoods $U$ of $x$ and $V$ of $y$ such that $U\cap V=\emptyset$.
\item[(1')] If $x,y\in X$ and $x\neq y$, then there exist $U\in\mc B$ containing $x$ and $V\in\mc B$ containing $y$ such that $U\cap V=\emptyset$.
\item[(2)] If $(x_\alpha)_{\alpha\in I}$ is a net in $X$ converging to both $x$ and $y$, then $x=y$.
\end{itemize}
\end{df}

\begin{proof}[Proof of the equivalence]
(1)$\Leftrightarrow$(1'): Obvious.

(1)$\Rightarrow$(2): Suppose that $(x_\alpha)$ converges to $x$ and $y$. Suppose $x\neq y$. By (1),  we have disjoint neighborhoods $U\ni x$ and $V\ni y$. Since $x_\alpha\rightarrow x$, $x_\alpha$ is eventually in $U$. Similarly, $x_\alpha$ is eventually in $V$. Therefore, by the logic \eqref{eq38}, $x_\alpha$ is eventually in $U\cap V=\emptyset$, impossible.

$\neg$(1)$\Rightarrow$ $\neg$(2): Suppose that (1) is not true. Then there exist $x\neq y$ such that every neighborhood of $x$ intersects every neighborhood of $y$. Let $I=\Nbh_X(x)\times\Nbh_X(y)$. For each $\alpha=(U,V)\in I$, by assumption, there exists $x_\alpha\in U\cap V$. Then $(x_\alpha)_{\alpha\in I}$ is a net in $X$. We leave it to the readers to check that $x_\alpha\rightarrow x$ and $x_\alpha\rightarrow y$.
\end{proof}


\begin{rem}
In Hausdorff's 1914 paper introducing topological spaces, the Hausdorff condition is one of the axioms of topological spaces. Non-Hausdorff topological spaces were studied much later. The reason that Hausdorff spaces appeared first may be as follows: The original motivation for topological spaces lies in the study of analysis (especially functional analysis). But in analysis, most spaces are Hausdorff, because we want the limits of sequences or nets to be unique. 

In differential geometry and in topology\footnote{Here, I mean genuine topology, such as algebraic topology, differential topology, geometric topology, etc., but not point-set topology, which is analysis under the guise of topology.}, people are also mainly concerned with topological spaces that are Hausdorff. This is related to the fact that in these areas people often use tools from analysis. But in algebraic geometry, the main examples of topological spaces (e.g. varieties and schemes, whose topologies are called \textbf{Zariski topology}) are not Hausdorff.  As a related fact, sequences and nets are not effective tools in the study of algebraic geometry.  \hfill\qedsymbol
\end{rem}

\subsection{Closures, interiors, and closed sets}


In this section, we fix a topological space $X$.


\subsubsection{Closure points; dense subsets}





\begin{df}\label{lb183}
Let $A$ be a subset of $X$. We say that $x\in X$ is a \textbf{closure point} \index{00@Closure, closure point} of $A$, if the following equivalent conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item There is a net $(x_\alpha)_{\alpha\in I}$ in $A$ converging to $x$.
\item Each $U\in \Nbh_X(x)$ intersects $A$. 
\end{enumerate}
The \textbf{closure} of $A$ is defined to be \index{Acl@$\ovl A=\Cl_X(A)$, closure}
\begin{align*}
\ovl A\equiv\Cl(A)\equiv\Cl_X(A)=\{\text{closure points of }A\}
\end{align*}
Clearly $A\subset \ovl A$. Clearly, if $A\subset B\subset X$, then $\ovl A\subset\ovl B$.
\end{df}

Unless otherwise stated, if several subsets are involved, we always understand $\ovl A$ as $\Cl_X(A)$ where $X$ is the ambient topological space.

\begin{proof}[Proof of equivalence]
(1)$\Rightarrow$(2): Assume (1). Choose any $U\in\Nbh_X(x)$. Since $x_\alpha\rightarrow x$, we have that $x_\alpha$ is eventually in $U$. So $U$ must contain some $x_\alpha$. But $x_\alpha\in A$. So $U\cap A\neq\emptyset$.

(2)$\Rightarrow$(1):  By (2), for each $U\in\Nbh_X(x)$ we can choose $x_U\in U\cap A$. Then $(x_U)_{U\in\Nbh_X(x)}$ is a net in $A$ converging to $x$. 
\end{proof}







\begin{exe}
Let $\mc B$ be a basis for the topology of $X$. Show that $x\in X$ is a closure point of $A$ iff every $U\in\mc B$ containing $x$ must intersect $A$.
\end{exe}

\begin{exe}
Let $A$ be a subset of a metric space. Show that $x\in X$ is a closure point of $A$ iff there is a sequence $(x_n)_{n\in\Zbb_+}$ in $A$ converging to $x$.
\end{exe}

\begin{exe}
Recall that if $X$ is a metric space, then $\ovl B_X(x,r)=\{y\in X:d(x,y)\leq r\}$. Show that 
\begin{align}
\ovl{B_X(x,r)}\subset \ovl B_X(x,r)
\end{align}
and that these two sets are not necessarily equal.
\end{exe}



\begin{rem}\label{lb270}
Our proof of (2)$\Rightarrow$(1) in Def. \ref{lb183} is an indirect proof, because it uses axiom of choice. (Given $U\in\Nbh_X(x)$, the choice of $x_U\in U\cap A$ is highly arbitrary.) Here is a direct proof: Assume (2). Define  a direct set $(I,\leq)$ where
\begin{gather*}
I=\{(p,U):U\in\Nbh_X(x),p\in U\cap A\}\\[0.5ex]
(p,U)\leq(p',U')\qquad\Longleftrightarrow\qquad U\supset U'
\end{gather*} 
The fact that $I$ is a directed set is due to (2). Then $(p)_{(p,U)\in I}$ is a net in $A$ converging to $x$.

We will often prove results about nets in topological spaces using axiom of choice, not only because it is simpler than direct proofs (as above), but also because it is parallel to our use of sequences in metric spaces. (For example, see the proof of (1)$\Rightarrow$(2) in Def. \ref{lb31}.) However, it is important to know how to give a direct proof. This is because the studies of topological spaces using nets and using open sets are often equivalent, and direct proofs using nets can be more easily translated into proofs using open sets and vice versa.   \hfill \qedsymbol
\end{rem}


\begin{exe}
Prove $\neg$(1)$\Rightarrow$ $\neg$(2) of Def. \ref{lb268} without using axiom of choice.
\end{exe}



\begin{rem}\label{lb176}
There is a notion closely related to closure points, called accumulation points. Let $A$ be a subset of $X$. A point $x\in X$ is called a \textbf{accumulation point} \index{00@Accumulation point of a subset}  (or \textbf{limit point} or \textbf{cluster point}) of $A$, if $x$ is a closure point of $A\setminus\{x\}$.

We will not use the notion of accumulation points, although this concept is widely used in many textbooks on analysis or point-set topology. We use closure points instead. (But note that if $x\notin A$, then $x$ is a closure point iff $x$ is an accumulation point.) On the other hand, the following opposite notion of accumulation points is important and has a clear geometric picture:   \hfill\qedsymbol
\end{rem}

\begin{df}
We say that $x\in X$ is an \textbf{isolated point} of $X$, if the following (clearly) equivalent conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item $x\notin\ovl {X\setminus\{x\}}$.
\item There is no net in $X\setminus\{x\}$ converging to $x$.
\item There is a neighborhood of $x$ disjoint from $X\setminus\{x\}$.
\end{enumerate}
If $X$ is a metric space, then $x$ is an isolated point iff there is no sequence in $X\setminus\{x\}$ converging to $x$.
\end{df}


We return to the study of closures.

\begin{pp}\label{lb177}
Let $A$ be a subset of $X$. Then $\ovl{\ovl A}=\ovl A$.
\end{pp}

\begin{proof}
Choose any $x\in \ovl{\ovl A}$. To prove $x\in \ovl A$, we choose any  $U\in\Nbh_X(x)$, and try to prove $U\cap A\neq\emptyset$. Since $x$ is a closure point of $\ovl A$, $U$ intersects $\ovl A$. Pick $y\in U\cap\ovl A$. Then $y$ is a closure point of $A$, and $U\in\Nbh_X(y)$. So $U$ intersects $A$. 
\end{proof}


One should think of $\ovl{\ovl A}=\ovl A$ not only as a ``geometric" fact about closures. Instead, one should also understand its analytic content: A closure point of $A$ is a point which can be approximated by elements of $A$. Thus, $\ovl{\ovl A}=\ovl A$ says that ``approximation is transitive": If $x$ can be approximated by some elements which can be approximated by elements of $A$, then $x$ can be approximated by elements of $A$. Alternatively, one can use the language of density:

\begin{df}
A subset $A$ of $X$ is called \textbf{dense} (in $X$) \index{00@Dense subset} if $\ovl A= X$.
\end{df}

\begin{exe}
Show that $A$ is dense in $X$ iff every nonempty open subset of $X$ intersects $A$.
\end{exe}



\begin{rem}\label{lb182}
Let $A\subset B\subset X$.  From Def. \ref{lb183}-(1), it is clear that
\begin{align}
\Cl_B(A)=\Cl_X(A)\cap B \label{eq64}
\end{align}
Thus, $A$ is dense in $B$ iff $B\subset \Cl_X(A)$.
\end{rem}

Thus, the following property has the same meaning as $\ovl{\ovl A}=A$.
\begin{co}
Let $A\subset B\subset X$. Assume that $A$ is dense in $B$, and $B$ is dense in $X$, then $A$ is dense in $X$.
\end{co}
\begin{proof}
Choose any $x\in X$. Then $x\in\Cl_X(B)$ since $B$ is dense in $X$. Since $A$ is dense in $B$, we have $B\subset \Cl_X(A)$. Therefore $x\in\Cl_X(\Cl_X(A))$, and hence $x\in\Cl_X(A)$ by Prop. \ref{lb177}.
\end{proof}

\begin{eg}
Let $X=C([0,1],\Rbb)$, equipped with the $l^\infty$-norm. Let $B$ be the set of polynomials with real coefficients, regarded as continuous functions on $[0,1]$. By Weierstrass approximation theorem (which will be studied in the future), $B$ is a dense subset of $X$. Then the set $A$ of polynomials with rational coefficients is clearly a dense subset of $B$ under the $l^\infty$-norm. (Proof: Let $f(x)=a_0+a_1x+\cdots+a_{k}x^k$. For each $0\leq i\leq k$, choose a sequence $(a_{i,n})_{n\in\Zbb_+}$ in $\Qbb$ converging to $a_i$. Let $f_n(x)=a_{0,n}+a_{1,n}x+\cdots+a_{k,n}x^k$. Then $f_n\rightrightarrows f$ on $[0,1]$.) Therefore, $A$ is dense in $X$. To summarize:
\begin{itemize}
\item Since each continuous function on $[0,1]$ can be uniformly approximated by polynomials with $\Rbb$-coefficients, and since each polynomial can be uniformly approximated polynomials with $\Qbb$-coefficients, therefore each continuous function on $[0,1]$ can be uniformly approximated by polynomials with $\Qbb$-coefficients.
\end{itemize}
\end{eg}


%% Record #7 2023/10/11 three lectures  17



\subsubsection{Interior points}

Interior points are dual to closure points:

\begin{df}\label{lb187}
Let $A$ be a subset of $X$. A point $x\in X$ is called an \textbf{interior point} \index{00@Interior point} of $A$ if the following equivalent conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item There exists $U\in \Nbh_X(x)$ such that $U\subset A$.
\item $x$ is not a closure point of $X\setminus A$. 
\end{enumerate}
The set of interior points of $A$ is called the \textbf{interior} \index{00@Interior} of $A$ and is denoted by $\Int_X(A)$ or simply $\Int(A)$. \index{Int@$\Int_X(A)=\Int(A)$} So
\begin{align}
X\setminus\Int(A)=\ovl{X\setminus A}\qquad(\text{or simply }\Int(A)^c=\ovl{A^c})
\end{align}
according to (2). In particular, $\Int(A)\subset A$.
\end{df}

\begin{proof}[Proof of equivalence]
$A$ contains no neighborhoods of $x$ with respect to $X$ iff $A^c$ intersects every neighborhood of $x$ iff $x$ is a closure point of $A^c$.
\end{proof}

It is clear that if $\mc B$ is a basis for the topology, then $x\in\Int(A)$ iff there exists $U\in\mc B$ such that $x\in U\subset A$.

In analysis, interior points are not as commonly used as closure points. The following property is an important situation where interior points are used:

\begin{pp}\label{lb179}
Let $U$ be a subset of $X$. Then $U$ is open iff every point of $U$ is an interior point.
\end{pp}

In other words, $U$ is open iff $U=\Int_X(U)$.

\begin{proof}
If $U$ is open and $x\in U$, then $U\in \Nbh_X(x)$. So $x$ is an interior point of $U$.

Conversely, suppose that each $x\in U$ is interior. Choose $V_x\in\Nbh_X(x)$. Then $U=\bigcup_{x\in U}V_x$. So $U$ is open by the union property in Def. \ref{lb178}.
\end{proof}

Note that this is the first time we seriously use the fact that a union of open sets is open. 




\subsubsection{Closed sets and open sets}\label{lb228}


\begin{df}
We say that $A\subset X$ is a \textbf{closed (sub)set} \index{00@Closed subset} of $X$ if $\ovl A=A$.
\end{df}

\begin{exe}
Show that the above definition of closed subsets agrees with Def. \ref{lb99} when $X$ is a metric space.
\end{exe}

\begin{exe}
Show that a finite subset of a Hausdorff space is closed. Give an example of non-closed finite subset of a non-Hausdorff topological space.
\end{exe}


\begin{rem}\label{lb242}
The closure $\ovl A$ is the smallest closed set containing $A$. (Proof: By Prop. \ref{lb177},  $\ovl A$ is closed. If $B$ is closed and contains $A$, then $\ovl A\subset\ovl B=B$.)
\end{rem}



\begin{thm}\label{lb181}
Let $A$ be a subset of $X$. Then $A$ is closed iff $X\setminus A$ is open.
\end{thm}

\begin{proof}
Let $B=X\setminus A$. Then $A$ is closed iff every closure point of $A$ is in $A$, iff every non-interior point of $B$ is not in $B$, iff every point in $B$ is an interior point of $B$. By Prop. \ref{lb179}, this is equivalent to that $B$ is open.
\end{proof}

\begin{co}\label{lb186}
$\emptyset$ and $X$ are closed subsets of $X$. An intersection of closed subsets is closed. A finite union of closed subsets is closed. 
\end{co}

\begin{proof}
Take the complement of Def. \ref{lb178}, and apply Thm. \ref{lb181}. (Of course, they can also be proved directly using the condition $A=\ovl A$ for closedness.)
\end{proof}


\begin{co}\label{lb243}
$X$ is Hausdorff iff for every distinct $x,y\in X$ there exists $U\in\Nbh_X(x)$ such that $y\notin \ovl U$.
\end{co}

\begin{proof}
``$\Leftarrow$": Let $x\neq y$. Choose $U\in\Nbh(x)$ such that $y\notin\ovl U$. Then $X\setminus \ovl U\in\Nbh(y)$ by Thm. \ref{lb181}. So $x$ and $y$ are separated by neighborhoods $U,X\setminus\ovl U$.

``$\Rightarrow$": Let $x\neq y$. Choose disjoint $U\in\Nbh(x)$ and $V\in\Nbh(y)$. Then $X\setminus V$ is closed by Thm. \ref{lb181}. So $\ovl U\subset X\setminus V$ by Rem. \ref{lb242}. So $y\notin\ovl U$.
\end{proof}

\begin{co}\label{lb190}
Let $Y$ be a subset of $X$, and let $A\subset Y$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $A$ is a closed subset of $Y$.
\item $A=B\cap Y$ for some closed subset $B$ of $X$.
\end{enumerate}
\end{co}

Note that the ``open subset" version of this corollary is true due to the definition of the subspace topology of $Y$ (cf. Def. \ref{lb180}).

\begin{proof}[First proof]
$A$ is closed in $Y$ iff $Y\setminus A=Y\cap A^c$ is open in $Y$, iff $Y\cap A^c$ equals $Y\cap U$ for some open subset $U\subset X$, iff $Y\cap A$ (which is $A$) equals $Y\cap U^c$ for some open subset $U\subset X$. This finishes the proof, thanks to Thm. \ref{lb181}.
\end{proof}

\begin{proof}[Second proof]
Recall by \eqref{eq64} that $\ovl A\cap Y$ is the closure of $A$ in $Y$. Then $A$ is closed in $Y$ iff $A=\ovl A\cap Y$. This proves (1)$\Rightarrow$(2) since $\ovl A$ is closed by Prop. \ref{lb177}. Assume (2). Then $A=B\cap Y$ where $B=\ovl B$. So $\ovl A\cap Y=\ovl{B\cap Y}\cap Y\subset \ovl B\cap Y=B\cap Y=A$. This proves (1).
\end{proof}


As an immediate consequence of Def. \ref{lb178} and Cor. \ref{lb190}, we have:

\begin{exe}\label{lb341}
Let $A\subset B\subset X$. 
\begin{enumerate}
\item Prove that if $B$ is open in $X$, then $A$ is open in $B$ iff $A$ is open in $X$.
\item Prove that if $B$ is closed in $X$, then $A$ is closed in $B$ iff $A$ is closed in $X$.
\end{enumerate}
\end{exe}







\begin{rem}
Many people define a closed set to be the complement of an open set, and then proves that a set $A$ is closed iff $A=\ovl A$. I went the other way because I believe that $A=\ovl A$ is more essential for understanding of closedness from the viewpoint of analysis. In Thm. \ref{lb87}, we have already seen a classical example of closed set in analysis: $C([0,1],\Rbb)$ is a closed subset of $l^\infty([0,1],\Rbb)$, which has the clear analytic meaning that the uniform limit of a sequence/net of continuous functions $[0,1]\rightarrow\Rbb$ is continuous. And we will see many more examples of this type in the future.
\end{rem}

\begin{rem}\label{lb229}
I defined closedness using $A=\ovl A$, and hence using the limits of nets. This is because the intuition of closed sets is very closely related to the intuition of limits of nets/sequences. On the other hand, the intuition of open sets is very different. Let me say a few words about this.

Without a doubt, the keyword I give for the intuition of limits of nets is ``\uline{approximation}": Limit is not only a dynamic process, but also gives an impression of "getting smaller and smaller". When dealing with closed sets, we often do the same thing! We take an intersection of possibly infinitely many closed subsets, and the result we get is still a closed set (cf. Cor. \ref{lb185}). 

The keyword I give for open sets is ``local", or more precisely, ``\uline{local-to-global}" (as opposed to ``getting smaller and smaller"!). This is not only because a union of open sets is open, but also because open sets are very often used to prove a global result by reducing to local problems. One easy example is Exe. \ref{lb184}, which says that in order to prove that a function is continuous on the whole space $X$, it suffices to prove this locally. (We have already used this strategy in Sec. \ref{lb185}.) Here is a more advanced example: to define the integral for a function on a large set, one can first define it locally (i.e. on small enough open subsets), and then patch these local values together. We will see many examples in the future, for example, in the following chapter about compactness.
\end{rem}

\begin{rem}
Very often, a theorem is an important result establishing two seemingly different (systems of) intuitions, and hence two different ways of mathematical thinking. This is why I call ``closed sets are the complements of open sets" a theorem. The term ``complement" implies that this theorem often manifests itself in the following way: If solving a problem using open sets is a direct proof, then solving the problem using limits of sequences/nets is a proof by contradiction/contrapositive. And vise versa.
\end{rem}


\subsection{Continuous maps and homeomorphisms}



Unless otherwise stated,  $X$ and $Y$ are topological spaces.


\subsubsection{Continuous maps}



\begin{df}\label{lb188}
Let $f:X\rightarrow Y$ be a map. Let $x\in X$. We say that $f$ is \textbf{continuous at} \index{00@Continuity} $x$ if the following equivalent conditions hold:
\begin{enumerate}
\item[(1)] For every net $(x_\alpha)_{\alpha\in I}$ in $X$ converging to $x$, we have $\lim_{\alpha\in I}f(x_\alpha)=f(x)$.
\item[(2)] For every $V\in \Nbh_Y(f(x))$, there exists $U\in\Nbh_X(x)$ such that for every $p\in U$ we have $f(p)\in V$.
\item[(2')] For every $V\in \Nbh_Y(f(x))$, the point $x$ is an interior point of $f^{-1}(V)$.
\end{enumerate}
We say that $f$ is a \textbf{continuous} function/map, if $f$ is continuous at every point of $X$. 
\end{df}

It is clear that ``for every $V\in\Nbh_{Y}(f(x))$" in (2) and (2') can be replaced by ``for every $V\in\mc B$ containing $f(x)$" if $\mc B$ is a basis for the topology of $Y$. 

Note that in the case that $(x_\alpha)$ or $(f(x_\alpha))$ has more than one limits (which could happen when $X$ or $Y$ is not Hausdorff), condition (1) means that $f(x)$ is one of the limits of $(f(x_\alpha))_{\alpha\in I}$ if $x$ is one of the limits of $(x_\alpha)$.


\begin{proof}[Proof of equivalence]
Clearly (2) is equivalent to (2'). The proof of (2)$\Rightarrow$(1) is similar to the case of sequences in metric spaces. (See Def. \ref{lb31}.) We leave the details to the reader.

$\neg$(2)$\Rightarrow$ $\neg$(1): Assume that (2) is not true. Then there is a neighborhood $V$ of $f(x)$ such that for every neighborhood $U$ of $x$ there exists $x_U\in U$ such that $f(x_U)\notin V$. Then $(x_U)_{U\in\Nbh_X(x)}$ is a net in $X$, and $\lim_Ux_U=x$ since $x_U\in U$. However, for each $U$ we have $f(x_U)\in Y\setminus V$. So $\lim_U f(x_U)$ cannot converge to $f(x)$.
\end{proof}

\begin{exe}
Show that when $X,Y$ are metric spaces, Def. \ref{lb188} agrees with Def. \ref{lb31}.
\end{exe}

\begin{exe}\label{lb321}
Let $f:X\rightarrow Y$ and $g:Y\rightarrow Z$ be maps of topological spaces. Assume that $f$ is continuous at $x\in X$, and $g$ is continuous at $f(x)$. Prove that $g\circ f:X\rightarrow Z$ is continuous at $x$.
\end{exe}








The proof of (1)$\Rightarrow$(2) in Def. \ref{lb188} is indirect, since it uses the axiom of choice. (The merit of this proof is that it is parallel to the proof for metric spaces in Sec. \ref{lb185}.) One can also give a direct proof. Indeed, there is a particular net $(x_\alpha)$ converging to $x$ such that  $\lim f(x_\alpha)=f(x)$ iff (2) is true:

\begin{exe}\label{lb198}
Define $(\Pnbh_X(x),\leq)$, \index{PNbh@$\Pnbh_X(x)$} the \textbf{directed set of pointed neighborhoods} of $x$,  to be
\begin{gather}
\begin{gathered}
\Pnbh_X(x)=\big\{(p,U):U\in\Nbh_X(x),p\in U  \big\}\\
(p,U)\leq(p',U')\qquad\Longleftrightarrow\qquad U\supset U'
\end{gathered}
\end{gather}
For each $\alpha=(p,U)\in\Pnbh_X(x)$, let $x_\alpha=p$. Then $(x_\alpha)_{\alpha\in\Pnbh_X(x)}$ is a net in $X$ converging to $x$. Prove that $f$ is continuous at $x$ iff $\lim_\alpha f(x_\alpha)=f(x)$.
\end{exe}



\begin{pp}\label{lb191}
Let $f:X\rightarrow Y$ be a map. The following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $f$ is continuous.
\item If $V\subset Y$ is open in $Y$, then $f^{-1}(V)$ is open in $X$.
\item If $F\subset Y$ is closed in $Y$, then $f^{-1}(F)$ is closed in $Y$.
\end{enumerate}
\end{pp}

\begin{proof}
(1)$\Leftrightarrow$(2): By Def. \ref{lb188}-(2') and Prop. \ref{lb179}. (2)$\Leftrightarrow$(3): By Thm. \ref{lb181} and the fact that $f^{-1}(B^c)=f^{-1}(B)^c$ for every $B\subset Y$.
\end{proof}



\begin{rem}
We first defined the continuity of $f$ at a point, and then used this to define a continuous function $f$ to be one continuous at every point. However, it seems that the notion of continuity at a point is used only in analysis. In geometry and in topology, only continuous maps (but not a map continuous at a point) are used, and they are defined by Prop. \ref{lb191}-(2).

One might think that continuous functions are special cases of functions  which are continuous at given points. But in fact, the latter notion can also be derived from the former: \hfill\qedsymbol
\end{rem}

\begin{exe}\label{lb308}
Let $f:(X,\mc T)\rightarrow (Y,\mc T')$ be a map of topological spaces. Let $x\in X$. Define a new topological space $(X_x,\mc T_x)$ as follows. $X_x$ equals $X$ as a set. The topology $\mc T_x$ of $X_x$ is generated by the basis
\begin{align}
\mc B_x=\Nbh_X(x)\cup\big\{\{p\}:p\neq x\big\}
\end{align}
Prove that if $X$ is Hausdorff, then $X_x$ is Hausdorff. Prove that the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $f:X\rightarrow Y$ is continuous at $x$.
\item $f:X_x\rightarrow Y$ is continuous.
\end{enumerate}
\end{exe}

Continuous functions are determined by their values on a dense subset: 

\begin{pp}\label{lb196}
Let $A$ be a subset of $X$, and let $f,g:\ovl A\rightarrow Y$ be continuous. Then
\begin{subequations}
\begin{gather}
f(\ovl A)\subset\ovl{f(A)}  \label{eq80}
\end{gather}
If $Y$ is moreover Hausdorff, then
\begin{gather}
f=g\qquad\Longleftrightarrow\qquad f|_A=g|_A
\end{gather}
\end{subequations}
\end{pp}
\begin{proof}
If $y\in f(\ovl A)$, then $y=f(x)$ for some $x\in\ovl A$. Choose a net $(x_\alpha)$ in $A$ converging to $x$. Then $\lim_\alpha f(x_\alpha)=f(x)$, and hence $f(x)\in\ovl {f(A)}$.

Assume that $Y$ is Hausdorff. If $f=g$ then clearly $f|_A=g|_A$. Assume that $f|_A=g|_A$. For each $x\in\ovl A$, choose a net $(x_\alpha)$ in $A$ converging to $x$. Then $f(x)=\lim f(x_\alpha)=\lim g(x_\alpha)=g(x)$. So $f=g$.
\end{proof}


You are encouraged to prove Prop. \ref{lb196} using open sets instead of using nets.



\subsubsection{Homeomorphisms}

\begin{df}
A map $f:X\rightarrow Y$ is called \textbf{open} (resp. \textbf{closed}) \index{00@Open map} \index{00@Closed map} if for every open (resp. closed) subset $A\subset X$, the image $f(A)$ is open (resp. closed) in $Y$.
\end{df}


\begin{df}
A bijection $f:X\rightarrow Y$ is called a \textbf{homeomorphism} \index{00@Homeomorphism} if the following clearly equivalent conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item $f$ and $f^{-1}$ are continuous.
\item For every net $(x_\alpha)$ in $X$ and each $x\in X$, we have that  $\lim_\alpha x_\alpha=x$ iff $\lim_\alpha f(x_\alpha)=f(x)$.
\item $f$ is continuous and open.
\item $f$ is continuous and closed.
\end{enumerate}
If a homeomorphism $f:X\rightarrow Y$ exists, we say that $X,Y$ are \textbf{homeomorphic}.
\end{df}

Recall from Def. \ref{lb189} that when $X,Y$ are metric spaces, the sequential version of (2) holds. 

\begin{rem}
Let $\mc T_1,\mc T_2$ be two topologies on a set $X$. Clearly, we have $\mc T_1=\mc T_2$ iff
\begin{gather}
\varphi:(X,\mc T_1)\rightarrow(X,\mc T_2)\qquad x\mapsto x
\end{gather}
is a homeomorphism. Thus, the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $\mc T_1=\mc T_2$.
\item For every net $(x_\alpha)$ in $X$ and $x\in X$, we have that $\lim_\alpha x_\alpha=x$ under $\mc T_1$ iff $\lim_\alpha x_\alpha=x$ under $\mc T_2$.
\end{enumerate}
This equivalence implies that
\begin{align*}
\boxed{\text{ topologies are determined by net convergence }}
\end{align*}
Therefore, instead of using open sets or bases of topologies to describe a topology, one can also describe a topology $\mc T$ on a set $X$ in the following way:
\begin{gather}\label{eq65}
\begin{gathered}
\text{$\mc T$ is the unique topology on $X$ such that}\\
\text{a net $(x_\alpha)$ in $X$ converges to $x\in X$ iff ...}
\end{gathered}
\end{gather}
Similarly, by Def. \ref{lb189}, metrizable topologies are determined by sequential convergence. Therefore, metrizable topologies can be described in the following way:
\begin{gather}
\begin{gathered}
\text{$\mc T$ is the unique metrizable topology on $X$ such that}\\
\text{a sequence $(x_n)$ in $X$ converges to $x\in X$ iff ...}
\end{gathered}
\end{gather}
\end{rem}


%% Record #8 2023/10/16 two lectures  19



\subsection{Examples of topological spaces described by net convergence}

\begin{eg}
Let $A$ be a subset of a topological space $(X,\mc T_X)$. Then the subspace topology $\mc T_A$ of $A$ is the unique topology such that a net $(x_\alpha)$ in $A$ converges to $x\in A$ under $\mc T_A$ iff it converges to $x$ under $\mc T_X$.
\end{eg}

\begin{seg}\label{lb193}
Let $X=\bigsqcup_{\alpha\in \scr A}X_\alpha$ be a disjoint union where each $(X_\alpha,\mc T_\alpha)$ is a topology space. Then
\begin{align*}
\mc B=\bigcup_{\alpha\in\scr A}\mc T_\alpha
\end{align*}
is clearly a basis generating a topology $\mc T$ on $X$, called \textbf{disjoint union topology}. \index{00@Disjoint union of topological spaces}   $\mc T$ is the unique topology on $X$ such that for every net $(x_\mu)_{\mu\in I}$ in $X$ and any $x\in X$, the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $(x_\mu)_{\mu\in I}$ converges to $x$ under $\mc T$.
\item There exists $\nu\in I$ such that for every $\mu\geq\nu$, the element $x_\mu$ belongs to the unique $X_\alpha$ containing $x$. Moreover, $\lim_{\mu\in I_{\geq\nu}}x_\mu=x$ in $X_\alpha$.
\end{enumerate}
We call $(X,\mc T)$ the \textbf{disjoint union topological space} \index{00@Disjoint union topological space} of $(X_\alpha)_{\alpha\in\scr A}$.
\end{seg}

The following exercise says that ``disjoint union of topological spaces" is synonymous with ``disjoint union of open subsets".

\begin{sexe}
Assume that $X=\bigsqcup_{\alpha\in\scr A}X_\alpha$. Assume that $X$ has a topology $\mc T$, and equip each $X_\alpha$ with the subspace topology. Show that $(X,\mc T)$ is the disjoint union topological space of $(X_\alpha)_{\alpha\in\scr A}$ iff each $X_\alpha$ is an open subset of $(X,\mc T)$.
\end{sexe}

Thus, for example, $\bigcup_{n\in\Nbb} [2n,2n+1)$ (under the Euclidean topology) is the disjoint union topological space of the family $\big([2n,2n+1)\big)_{n\in\Nbb}$.


\begin{sexe}
In Exp. \ref{lb193}, assume that each $(X_\alpha,\mc T_\alpha)$ is metrizable. Prove that $(X,\mc T)$ is metrizable. More precisely: Choose a metric $d_\alpha$ inducing $\mc T_\alpha$, and assume that $d_\alpha\leq 1$ (cf. Prop. \ref{lb195}). Define a metric $d$ on $X$ as in Pb. \ref{lb194}. Solve \textit{the net version} of part 2 of Pb. \ref{lb194}. Conclude from this that $d$ induces the topology $\mc T$. (Warning: we cannot conclude this from the original sequential version of Pb. \ref{lb194}-2.)
\end{sexe}


\begin{df}\label{lb454}
Let $(X_\alpha)_{\alpha\in\mc A}$ be a family of topological spaces. Elements of the product space
\begin{align*}
S=\prod_{\alpha\in\scr A}X_\alpha
\end{align*}
are denoted by $x=(x(\alpha))_{\alpha\in\scr A}$. One checks easily that
\begin{align}
\begin{aligned}
\mc B=\Big\{&\prod_{\alpha\in\scr A} U_\alpha: \text{each $U_\alpha$ is open in $X_\alpha$},\\
& \text{$U_\alpha=X_\alpha$ for all but finitely many $\alpha$}\Big\}
\end{aligned}
\end{align}
is a basis for a topology $\mc T$, called the \textbf{product topology} \index{00@Product topology} or \textbf{pointwise convergence topology} \index{00@Pointwise convergence topology} of $S$. We call $(S,\mc T)$ the \textbf{product topological space}. \index{00@Product topological space} 

Equivalently, let
\begin{gather}
\pi_\alpha:S\rightarrow X_\alpha \qquad x\mapsto x(\alpha)
\end{gather}
be the \textbf{projection map onto the $X_\alpha$ component}. Then
\begin{align}
\mc B=\Big\{\bigcap_{\alpha\in E} \pi_\alpha^{-1}(U_\alpha):E\in\fin(2^{\scr A}), \text{ $U_\alpha$ is open in $X_\alpha$ for each $\alpha\in E$}    \Big\}
\end{align}
Unless otherwise stated, a product of topological spaces is equipped with the product topology.  \hfill\qedsymbol
\end{df}



\begin{eg}\label{lb226}
Let $S=X_1\times\cdots\times X_N$ be a finite product of topological spaces. Then the product topology has a basis
\begin{align}
\mc B=\{ U_1\times\cdots \times U_N:\text{ each $U_i$ is open in $X_i$}\}
\end{align}
\end{eg}


\begin{thm}\label{lb192}
Let $S=\prod_{\alpha\in\scr A}X_\alpha$ be a product of topological spaces, equipped with the product topology. Then each projection map $\pi_\alpha$ is continuous. Moreover, for every net $(x_\mu)_{\mu\in I}$ in $S$ and every $x\in S$, the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $\dps\lim_{\mu\in I}x_\mu=x$ in $S$.
\item For every $\alpha\in\scr A$, we have $\dps\lim_{\mu\in I}x_\mu(\alpha)=x(\alpha)$ in $X_\alpha$.
\end{enumerate}
\end{thm}

If $(x_\mu)$ satisfies (1) or (2), we say that $x_\mu$ \textbf{converges pointwise} \index{00@Pointwise convergence} to $x$ if we view $(x_\mu)$ as a net of functions with domain $\scr A$. 

\begin{proof}
We leave the proof to the readers. Note that the continuity of $\pi_\alpha$ follows easily from the basis-for-topology version of Prop. \ref{lb191}-(2). And from the continuity of $\pi_\alpha$ one easily deduce (1)$\Rightarrow$(2).
\end{proof}

\begin{rem}
In the spirit of \eqref{eq65}, one says that:
\begin{itemize}
\item The product topology $\mc T$ on $S=\prod_{\alpha\in\scr A}X_\alpha$ is the unique topology such that a net $(x_\mu)$ converges to $x$ under $\mc T$ iff $x_\mu$ converges pointwise to $x$ as a net of functions on $\scr A$.
\end{itemize}
\end{rem}


\begin{co}
If each $X_\alpha$ is a Hausdorff space, then $S=\prod_{\alpha\in\scr A}X_\alpha$ is Hausdorff.
\end{co}

\begin{proof}
Either prove this directly using the basis for the topology, or prove that any net cannot converge to two different values using Thm. \ref{lb192}.
\end{proof}

\begin{co}\label{lb260}
Let $X_1,X_2,\dots$ be a possibly finite sequence of metric spaces. Then $S=\prod_i X_i$ is metrizable. More precisely, for each $i$, choose a metric $d_i$ on $X_i$ topologically equivalent to the original one such that $d_i\leq 1$ (cf. Prop. \ref{lb195}). Then the metric $d$ on $S$ defined by
\begin{align}
d(f,g)=\sup_{i} \frac {d_i(f(i),g(i))}{i} 
\end{align}
induces the product topology.
\end{co}

We note that the product topology is also induced by
\begin{align}
\delta(f,g)=\sum_{i}2^{-i} d_i(f(i),g(i))
\end{align}

\begin{proof}
The same method for solving Pb. \ref{lb78} also applies to its net version: One shows that a net $(f_\alpha)$ in $S$ converges to $f$ under $d$ (or under $\delta$) iff $(f_\alpha)$ converges pointwise to $f$. Thus, by Thm. \ref{lb192}, $d$ and $\delta$ induce the product topology.
\end{proof}

The next example discusses the topologies induced by uniform convergence metrics. (Recall Def. \ref{lb146}.) In this example, $Y$ is usually a normed vector space.

\begin{eg}\label{lb272}
Let $X$ be a set, and let $(Y,d_Y)$ be a metric space. Then there is a unique topology $\mc T$ on $Y^X$ such that for every net $(f_\alpha)_{\alpha\in I}$ in $Y^X$ and every $f\in Y^X$, the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item The net $(f_\alpha)$ converges to $f$ under $\mc T$.
\item We have $\dps\lim_{\alpha\in I}~\sup_{x\in X} d_Y(f_\alpha(x),f(x))=0$.
\end{enumerate}
(If $(f_\alpha)$ satisfies (2), we say that $f_\alpha$  \textbf{converges uniformly} \index{00@Uniform convergence} to $f$.) For example, one checks easily that $\mc T$ is induced by any \textbf{uniform convergence metric}, \index{00@Uniform convergence metric} i.e., any metric on $Y^X$ equivalent to $d$ where
\begin{align}\label{eq78}
d(f,g)=\min\Big\{1,\sup_{x\in X} d_Y(f(x),g(x))\Big\}
\end{align}
So $\mc T$ is metrizable. We call $\mc T$ the \textbf{uniform convergence topology} \index{00@Uniform convergence topology} on $Y^X$. 
\end{eg}

\begin{comment}
According to \eqref{eq78}, $\mc T$ has a basis
\begin{gather}\label{lb275}
\begin{gathered}
\mc B=\{U_{f,\eps}:f\in Y^X,\eps\in\Rbb_{>0}\}\quad\text{where}\\
U_{f,\eps}=\Big\{g\in Y^X:\sup_{x\in X}d_Y(f(x),g(x))<\eps   \Big\}
\end{gathered}
\end{gather}
\end{comment}

\begin{thm}\label{lb339}
Let $Y$ be a complete metric space. Let $X$ be a set. Then $Y^X$, equipped with the metric \eqref{eq78}, is complete.
\end{thm}

\begin{proof}
It can be proved in a similar way to Thm. \ref{lb85}. We leave the details to the readers.
\end{proof}



\begin{thm}\label{lb279}
Let $V$ be a normed vector space over $\Rbb$ or $\Cbb$. Let $X$ be a topological space. Equip $V^X$ with the uniform convergence topology. Then $C(X,V)$ is a closed subset of $V^X$.
\end{thm}

\begin{proof}
This is similar to the proof of Thm. \ref{lb87}. Let $(f_\alpha)$ be a net $C(X,V)$ converging uniformly to $f:X\rightarrow V$. Choose any $x\in X$ and $\eps>0$. Then there is $\alpha\in I$ such that $\sup_{p\in X}\Vert f(x)-f_\alpha(x)\Vert<\eps$. Since $f_\alpha$ is continuous, there is $U\in\Nbh_X(x)$ such that for each $p\in U$ we have $\Vert f_\alpha(x)-f_\alpha(p)\Vert<\eps$. Thus, for each $p\in U$ we have 
\begin{align*}
\Vert f(x)-f(p)\Vert\leq \Vert f(x)-f_\alpha(x)\Vert +\Vert f_\alpha(x)-f_\alpha(p)\Vert+\Vert f_\alpha(p)-f(p)\Vert<3\eps
\end{align*}
So $f$ is continuous.
\end{proof}


\begin{rem}
Note that the uniform convergence topology depends on the equivalence class (not just the topological equivalence class) of $d_Y$. Thus, one needs metrics when talking about uniform convergence. On the other hand, the study of pointwise convergence does not require metrics.
\end{rem}

\subsection{Limits of functions}\label{lb290}




By Prop. \ref{lb196}, if $A\subset X$,  and if $f:\ovl A\rightarrow Y$ is continuous, then the value of $f$ is uniquely determined by $f|_A$ provided that $Y$ is Hausdorff (cf. Prop. \ref{lb196}). We now consider the opposite question of \uwave{extension of continuous functions}: Suppose that $f:A\rightarrow Y$ is continuous. Can we extend $f$ to a continuous function $f:\ovl A\rightarrow Y$? (We know that such extension must be unique if it exists.) The classical concept of the limits of functions can be understood in this light.



\begin{df}\label{lb197}
Let $A$ be a subset of $X$. Let $f:A\rightarrow Y$ be a map. Let $x\in\ovl A\setminus A$. Let $y\in Y$. We say that the \textbf{limit of the function} \index{00@Limit of a function} $f$ at $x$ is $y$ and write \index{lim@$\lim_{p\rightarrow x}f(p)$}
\begin{align*}
\lim_{
\begin{subarray}{c}
p\in A\\
p\rightarrow x
\end{subarray}
} f(p)\equiv\lim_{p\rightarrow x}f(p)=y
\end{align*}
if the following equivalent conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item If we extend $f$ to a function $A\cup\{x\}\rightarrow Y$ satisfying $f(x)=y$, then $f:A\cup\{x\}\rightarrow Y$ is continuous at $x$.
\item For every $V\in\Nbh_Y(y)$, there exists $U\in\Nbh_X(x)$ such that for every $p\in U\cap A$, we have $f(p)\in V$.
\item For every net $(x_\alpha)_{\alpha\in I}$ in $A$ converging to $x$, we have $\lim_{\alpha\in I} f(x_\alpha)=y$.
\end{enumerate}
When $X,Y$ are metric spaces, the above three conditions and the following two are equivalent:
\begin{itemize}
\item[(2m)] For every $\eps>0$, there exists $\delta>0$ such that for every $p\in A$, if $d(p,x)<\delta$ then $d(f(p),y)<\eps$.
\item[(3m)] For every sequence $(x_n)_{n\in\Zbb_+}$ in $A$ converging to $x$, we have $\lim_{n\rightarrow\infty}f(x_n)=y$.
\end{itemize}
\end{df}


Recall that by the definition of subspace topology, we have
\begin{align}
\Nbh_A(x)=\{U\cap A:U\in\Nbh_X(x)\}  \label{eq104}
\end{align}

\begin{proof}[\textbf{Proof of equivalence}]
Extend $f$ to $\wtd f:A\cup\{x\}\rightarrow Y$ by setting $\wtd f(x)=y$. Then by Def. \ref{lb188}-(2), condition (1) of Def. \ref{lb197} means that for every $V\in\Nbh_Y(y)$ there is a neighborhood of $x$ in $A\cup\{x\}$ (which, by \eqref{eq104}, must be of the form $U\cap (A\cup\{x\})$ where $U\in\Nbh_X(x)$) such that for every $p\in U\cap (A\cup\{x\})$ we have $\wtd f(p)\in V$. This is clearly equivalent to (2), since $\wtd f(x)=y\in V$. The equivalence (2)$\Leftrightarrow$(3) can be proved in a similar way as the equivalence of (1) and (2) in Def. \ref{lb188}. We leave the details to the readers. When $X,Y$ are metric spaces, (2) is clearly equivalent to (2m). The equivalence (2m)$\Leftrightarrow$(3m) can be proved in a similar way as the equivalence of (1) and (2) in Def. \ref{lb31}.
\end{proof}






The following remarks show that the limit of a function at a point is the limit of a single net, rather than the limit of many nets (as in Def. \ref{lb197}-(3)).

\begin{rem}\label{lb275}
Assume the setting of Def. \ref{lb197}. In the same spirit of Exe. \ref{lb198}, define a directed set $(\Pnbh_A(x),\leq)$ where
\begin{gather}
\begin{gathered}
\Pnbh_A(x)=\big\{(p,U):U\in\Nbh_X(x),p\in U\cap A  \big\}\\[0.5ex]
(p,U)\leq(p',U')\qquad\Longleftrightarrow\qquad U\supset U'
\end{gathered}
\end{gather}
(That it is a directed set is due to $x\in \ovl A$.) We have seen this directed set in Rem. \ref{lb270}. Then $(p)_{(p,U)\in\Pnbh_A(x)}$ is a net converging to $x$, and
\begin{align}
\lim_{p\rightarrow x} f(p)=\lim_{(p,U)\in\Pnbh_A(x)}f(p)
\end{align}
where the convergence of the LHS is equivalent to that of the RHS.
\end{rem}

\begin{rem}\label{lb269}
In the setting of Def. \ref{lb197}, assume moreover that $X$ is a metric space, then $\lim_{p\rightarrow x}f(p)$ can be described by the limit of a simpler net. Define a directed set $(A_x,\leq)$ where
\begin{gather}
\begin{gathered}
A_x=A\text{ as sets}\\[0.5ex]
p\leq p'\qquad\Longleftrightarrow \qquad d(p',x)\geq d(p,x)
\end{gathered}
\end{gather}
Then $(p)_{p\in A_x}$ is a net in $A$ converging to $x$, and
\begin{align}
\lim_{p\rightarrow x} f(p)=\lim_{p\in A_x}f(p)
\end{align}
where the convergence of the LHS is equivalent to that of the RHS.
\end{rem}


\begin{rem}\label{lb318}
Thanks to the above two remarks, limits of functions enjoy all the properties that limits of nets enjoy. For example, they satisfy Squeeze theorem; if $f:A\rightarrow \Fbb$ and $g:A\rightarrow V$ (where $V$ is a normed vector space over $\Fbb\in\{\Rbb,\Cbb\}$), if $x\in\ovl A\setminus A$,  and if $\lambda=\lim_{p\rightarrow x}f(p)$ and $v=\lim_{p\rightarrow x}g(p)$ exist, then $\lim_{p\rightarrow x}f(p)g(p)$ converges to $\lambda v$. 

Of course, you can also conclude them by using Def. \ref{lb197}-(3) instead of Rem. \ref{lb275}. In practice, it makes no difference whether you view $\lim_{p\rightarrow x}f(p)$ as the limit of $f(x_\alpha)$ for an arbitrary net $x_\alpha$ in $A$ converging to $x$, or whether you view  $\lim_{p\rightarrow x}f(p)$ as the limit of the particular net in Rem. \ref{lb275} or Rem. \ref{lb269}. The explicit constructions of nets in these two remarks are not important for proving results about limits of functions.   \hfill\qedsymbol
\end{rem}




\begin{rem}\label{lb202}
Let $f:A\rightarrow Y$, and let $x\in\ovl A\setminus A$. Suppose that $Y$ is Hausdorff. Assume that there exist two nets $(x_\alpha)_{\alpha\in I}$ and $(y_\beta)_{\beta\in J}$ in $A$ converging to $x$ such that $(f(x_\alpha))$ and $(f(y_\beta))$ converge to two different values. Then by Def. \ref{lb197}-(2), the limit $\lim_{p\rightarrow x}f(p)$ does not exist.
\end{rem}


The above remark gives a useful criterion for the non-convergence of limits of functions. The following proposition, on the other hand, gives a method of computing limits of functions by decomposing the domain into (non-necessarily mutually disjoint) subsets.


\begin{pp}\label{lb199}
Assume the setting of Def. \ref{lb197}. Assume that $A=A_1\cup\cdots\cup A_N$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item We have $\dps \lim_{p\rightarrow x} f(p)=y$.
\item For every $1\leq i\leq N$ such that $x\in\ovl {A_i}$, we have $\dps\lim_{p\rightarrow x} f|_{A_i}(p)=y$
\end{enumerate}
\end{pp}

\begin{proof}
(1)$\Rightarrow$(2): Assume (1). Extend $f:A\rightarrow Y$ to a function $\wtd f:A\cup\{x\}\rightarrow Y$ by setting $\wtd f(x)=y$. Then $\wtd f$ is continuous by (1). Thus, if $x\in\ovl{A_i}$, then $\wtd f|_{A_i\cup\{x\}}$ is continuous. This proves (2).

(2)$\Rightarrow$(1): Assume (2). Choose any $V\in\Nbh_Y(y)$. By (2), for each $i$, either $x\in\ovl{A_i}$ so that there is $U_i\in\Nbh_X(x)$ satisfying $U_i\cap A_i\subset f^{-1}(V)$ (recall \eqref{eq104}), or that $x\notin\ovl{A_i}$ so that there is $U_i\in\Nbh_X(x)$ disjoint from $A_i$. In either case, we have $U_i\cap A_i\subset f^{-1}(V)$. Let $U=U_1\cap\cdots\cap U_N$. Then
\begin{align*}
U\cap A=U\cap(A_1\cup\cdots\cup A_N)=\bigcup_i U\cap A_i\subset\bigcup_i U_i\cap A_i
\end{align*}
which is therefore a subset of $f^{-1}(V)$.

Another proof of $\neg$(1)$\Rightarrow$ $\neg$(2): Assume (1) is not true. Then there is a net $(x_\alpha)_{\alpha\in I}$ in $A$ converging to $x$ such that $f(x_\alpha)$ does not converge to $y$. So there exists $V\in\Nbh_Y(y)$ such that $f(x_\alpha)$ is not eventually in $V$, i.e., $f(x_\alpha)$ is frequently in $V^c$. Then $(f(x_\alpha))$ has a subnet $(f(x_{\beta}))_{\beta\in J}$ which is always in $V^c$. For example, take
\begin{align*}
J=\{\beta\in I:f(x_\beta)\in V^c\}
\end{align*}
Since $(x_\beta)_{\beta\in J}$ is always in $A$, by the logic \eqref{eq103}, there is $1\leq i\leq N$ such that $(x_\beta)$ is frequently in $A_i$. Thus, by the same argument as above, $(x_\beta)$ has a subnet $(x_\gamma)_{\gamma\in K}$ which is always in $A_i$. Since $x_\alpha\rightarrow x$, we have $x_\gamma\rightarrow x$, and hence $x\in\ovl{A_i}$. But $f(x_\gamma)\in V^c$. So we have found a net $(x_\gamma)$ in $A_i$ converging to $x$ such that $(f(x_\gamma))$ does not converge to $y$. This disproves (2).
\end{proof}








\begin{rem}
In many textbooks, $\lim_{p\rightarrow x}f(x)$ is also defined more generally when $x$ is an accumulation point of $A$, i.e., when $x\in\ovl{A\setminus\{x\}}$. In this case, the limit of $f$ at $x$ simply means \index{lim@$\lim_{p\rightarrow x}f(p)$}
\begin{align}\label{eq66}
\lim_{p\rightarrow x}f(p)
\xlongequal{\mathrm{def}} \lim_{p\rightarrow x}f|_{A\setminus\{x\}}(p)
\end{align}
This more general case is important in classical analysis, but is less useful in abstract analysis. (As a matter of fact, accumulation points are less convenient than closure points.) In order not to deviate too far from the traditional analysis textbooks, let's take a look at some examples.
\end{rem}


\begin{df}\label{lb200}
Let $A\subset\Rbb$ and $x\in\Rbb$. Let $f:A\rightarrow Y$ be a function. If $x$ is a closure point of $A\cap\Rbb_{<x}$ resp. $A\cap \Rbb_{>x}$, we define the \textbf{left limit} resp. \textbf{right limit} \index{00@Left and right limit} \index{lim@$\lim_{t\rightarrow x^-}$ and $\lim_{t\rightarrow x^+}$} to be
\begin{subequations}
\begin{gather}
\lim_{t\rightarrow x^-}f(t)=\lim_{t\rightarrow x}f|_{A\cap \Rbb_{<x}}(t)\\
\lim_{t\rightarrow x^+}f(t)=\lim_{t\rightarrow x}f|_{A\cap \Rbb_{>x}}(t)
\end{gather}
\end{subequations}
If $x\in\ovl\Rbb$ and $x$ is a closure point of $A\setminus \{x\}$, then $\lim_{t\rightarrow x}f(t)$ is understood by \eqref{eq66}.
\end{df}

\begin{rem}\label{lb201}
In Def. \ref{lb200}, if $x\in\Rbb$ is a closure point of $A\setminus\{x\}$, then by Prop. \ref{lb199},
\begin{align}
\lim_{p\rightarrow x}f(p)=y\qquad\Longleftrightarrow\qquad \lim_{p\rightarrow x^-}f(p)=\lim_{p\rightarrow x^+}f(p)=y
\end{align}
In particular, the existence of the limit on the LHS is equivalent to the existence and the equality of the two limits on the RHS.
\end{rem}



\begin{eg}
Let $g,h:\Rbb\rightarrow \Rbb$ be continuous functions. Let $c\in\Rbb$. Define $f:\Rbb\rightarrow\Rbb$ to be
\begin{align*}
f(x)=\left\{
\begin{array}{ll}
g(x)&\text{ if }x<0\\
c&\text{ if }x=0\\
h(x)&\text{ if }x>0\\
\end{array}
\right.
\end{align*}
Since $g|_{(-\infty,0]}$ is continuous, by Def. \ref{lb197}-(1) we have that $\lim_{x\rightarrow 0^-}f(x)=\lim_{x\rightarrow 0,t<0}g(t)=g(0)$. Similarly, $\lim_{x\rightarrow 0^+}f(x)=h(0)$. Therefore, by Rem. \ref{lb201}, $\lim_{x\rightarrow0}f(x)$ exists iff $g(0)=h(0)$, and it converges to $g(0)$ if $g(0)=h(0)$. The value $c$ is irrelevant to the limits.
\end{eg}


\begin{eg}
Let $f:X=\Rbb^2\setminus\{(0,0)\}\rightarrow \Rbb$ be $f(x,y)=\frac{x}{x+y}$. Then $(1/n,0)$ and $(0,1/n)$ are sequences in $X$ converging to $0$. But $f(1/n,0)=1$ and $f(0,1/n)=0$. So $\lim_{(x,y)\rightarrow(0,0)}f(x,y)$ does not exist by Rem. \ref{lb202}.
\end{eg}
















\subsection{Connected spaces}

Let $X$ be a topological space. In this section, we shall define a notion of connected space. Based on our usual geometric intuition, one might attempt to define a connected space as one satisfying that any two points can be linked by a path. Such spaces are actually called \textbf{path-connected spaces} and is stronger than connected spaces. In fact, connected spaces arise from the study of intermediate value problem.

\subsubsection{Connected $\Leftrightarrow$ IVP}

\begin{df}\label{lb212}
We say that the topological space $X$ is \textbf{connected} \index{00@Connected topological space} if $X$ can not be written as the disjoint of two nonempty open sets. Namely, if $X=U\sqcup V$ where $U,V$ are open subsets of $X$, then either $U=\emptyset$ (and hence $V=X$) or $V=\emptyset$ (and hence $U=X$).
\end{df}

Equivalently (by Thm. \ref{lb181}), $X$ is connected iff every $U\subset X$ which is both closed and open must be $\emptyset$ or $X$.


\begin{df}
We say that $X$ satisfies the \textbf{intermediate value property} (abbreviated to \textbf{IVP}) \index{00@IVP=Intermediate value property} if for every continuous function $f:X\rightarrow\Rbb$ and every $x,y\in X$ we have
\begin{align}
f(x)<f(y)\qquad\Longrightarrow\qquad [f(x),f(y)]\subset f(X)  \label{eq67}
\end{align}
\end{df}


\begin{thm}\label{lb206}
$X$ is connected iff $X$ satisfies IVP. Moreover, if $X$ is not connected, then there is a continuous $f:X\rightarrow\Rbb$ such that $f(X)=\{0,1\}$.
\end{thm}

\begin{proof}
First, assume that $X$ does not satisfy IVP. Choose a continuous $f:X\rightarrow\Rbb$ with real numbers $a<b<c$ such that $a,c\in f(X)$ but $b\notin f(X)$. So $U=f^{-1}(-\infty,b)$ and $V=f^{-1}(b,+\infty)$ are disjoint non-empty open subsets of $X$, and $X=U\sqcup V$. They are open, because $f$ is continuous (cf. Prop. \ref{lb191}). So $X$ is not connected.

Next, assume that $X$ is not connected. Then $X=U\sqcup V$ where $U,V$ are open subsets of $X$. Define $f:X\rightarrow\Rbb$ to be constantly $0$ on $U$ and constantly $1$ on $V$. It is easy to check that $f$ is continuous. (See also Rem. \ref{lb205}.) That $f(X)=\{0,1\}$ means that $X$ does not satisfy IVP.
\end{proof}



We now give a couple of elementary examples.


\subsubsection{Connected subsets of $\ovl\Rbb$ are precisely intervals}


\begin{pp}\label{lb207}
Let $A$ be a dense subset of $X$. Assume that $A$ is connected. Then $X$ is connected.
\end{pp}

\begin{proof}
If $X=\ovl A$ is not connected, then by Thm. \ref{lb206}, there exists a continuous surjection $f:\ovl A\rightarrow\{0,1\}$. By Prop. \ref{lb196}, $\ovl{f(A)}$ contains $f(\ovl A)$. So $f(A)$ has closure $\{0,1\}$. So $f(A)=\{0,1\}$. $A$ does not satisfy IVP, and hence is not connected.
\end{proof}









\begin{thm}\label{lb211}
Let $A$ be a nonempty subset of $\ovl\Rbb$. Then $A$ is connected iff $A$ is an interval.
\end{thm}

\begin{proof}
Step 1. Suppose that $A$ is connected. Let $a=\inf A$ and $b=\sup B$. To show that $A$ is one of $(a,b)$, $(a,b]$, $[a,b)$, $[a,b]$, it suffices to show that every $c\in (a,b)$ belongs to $A$. Suppose that some $c\in (a,b)$ does not belong to $A$. Then $A$ is the disjoint union of two nonempty open subsets $A\cap[-\infty,c)$ and $A\cap (c,+\infty]$, impossible.\\[-1ex]


Step 2. Every single point is clearly connected. Since every interval containing at least two points is homeomorphic to one of $[0,1]$, $(0,1]$, $[0,1)$, $(0,1)$, it suffices to prove that these four intervals are connected. Since $(0,1)$ is dense in the other three intervals, by Prop. \ref{lb207}, it suffices to prove that $(0,1)$ is connected.

Suppose that $(0,1)$ is not connected. Then $(0,1)=U\sqcup V$ where $U,V$ are disjoint open nonempty subsets. Choose $x_1\in U$ and $y_1\in V$, and assume WLOG that $x_1<y_1$. In the following, we construct an increasing sequence $(x_n)$ in $U$ and a decreasing one $(y_n)$ in $V$ satisfying $x_n<y_n$ for all $n$ by induction.  Suppose $x_n,y_n$ has been constructed. Let $z_n=(x_n+y_n)/2$. 
\begin{itemize}
\item If $z_n\in U$, then let $x_{n+1}=z_n$ and $y_{n+1}=y_n$.
\item If $z_n\in V$, then let $x_{n+1}=x_n$ and $y_{n+1}=z_n$.
\end{itemize}
Then $y_n-x_n$ converges to $0$. So $x_n$ and $y_n$ converge to the same point $\xi\in\Rbb$. We have $\xi\in(0,1)$ since $x_1<\xi<y_1$. Since $V$ is open, $U=(0,1)\setminus V$ is closed in $(0,1)$ by Thm. \ref{lb181}. So $\xi\in\Cl_{(0,1)}(U)=U$. Similarly, $\xi\in\Cl_{(0,1)}(V)=V$. This is impossible.
\end{proof}







\subsubsection{More examples of connected spaces}


\begin{df}
Let $x,y\in X$. A \textbf{path} \index{00@Path in a topological space} in $X$ from $x$ to $y$ is defined to be a continuous map $\gamma:[a,b]\rightarrow X$ where $-\infty<a<b<+\infty$, such that $\gamma(a)=x$ and $\gamma(b)=y$. Unless otherwise stated, we take $[a,b]$ to be $[0,1]$. We call $x$ and $y$ respectively the \textbf{initial point} and the \textbf{terminal point} of $\gamma$. 
\end{df}

\begin{df}
We say that $X$ is \textbf{path-connected} \index{00@Path-connected space} if for every $x,y\in X$ there is a path in $X$ from $x$ to $y$.
\end{df}


\begin{eg}
$\Rbb^N$ is path-connected. $B_{\Rbb^N}(0,R)$ and $\ovl B_{\Rbb^N}(0,R)$ (where $R<+\infty$) are path connected. $\{x\in \Rbb^N:r<x<R\}$ (where $0\leq r<R<+\infty$) are path connected. The region enclosed by a triangle is a connected subset of $\Rbb^2$. $[0,1]^N$ is connected.
\end{eg}

\begin{thm}\label{lb220}
Assume that $X$ is path-connected. Then $X$ is connected.
\end{thm}

\begin{proof}
If $X$ is not connected, then $X=U\sqcup V$ where $U,V$ are nonempty open subsets of $X$. Since $X$ is path-connected, there is a path $\gamma$ from a point of $U$ to a point of $V$. So $[0,1]=\gamma^{-1}(U)\sqcup\gamma^{-1}(V)$ where $\gamma^{-1}(U),\gamma^{-1}(V)$ are open (by Prop. \ref{lb191}) and nonempty. This contradicts the fact that $[0,1]$ is connected (cf. Thm. \ref{lb211}).
\end{proof}



\begin{pp}\label{lb210}
Let $f:X\rightarrow Y$ be a continuous map of topological spaces. Suppose that $X$ is connected. Then $f(X)$ is connected.
\end{pp}

\begin{proof}
By replacing $f:X\rightarrow Y$ by the restricted continuous map $f:X\rightarrow f(X)$, it suffices to assume $Y=f(X)$. If $Y$ is not connected, then $Y=U\sqcup V$ where $U,V$ are open and nonempty. Then $X=f^{-1}(U)\sqcup f^{-1}(V)$ are open (by Prop. \ref{lb191}) and nonempty subsets of $X$. So $X$ is not connected, impossible. (One can also use Thm. \ref{lb206} to prove that $f(X)$ is connected.)
\end{proof}

\begin{rem}
When $Y=\Rbb$, Prop. \ref{lb210} and Thm. \ref{lb211} imply that $f(X)$ is an interval. So $f$ satisfies \eqref{eq67}. Therefore, Prop. \ref{lb210} can be viewed as a generalization of IVP for connected spaces.
\end{rem}



\begin{co}\label{lb213}
Let $I$ be an interval, and let $f:I\rightarrow\ovl\Rbb$ be a strictly increasing continuous map. Then $J=f(I)$ is an interval, and the restriction $f:I\rightarrow J$ is a homeomorphism.
\end{co}


\begin{proof}
By Thm. \ref{lb211} and Prop. \ref{lb210}, $J$ is connected and hence is an interval. Therefore, by Thm. \ref{lb65}, $f$ is a homeomorphism.
\end{proof}


\begin{seg}
Not all connected spaces are path-connected. Let $f:(0,1]\rightarrow\Rbb^2$ be defined by $f(x)=(x,\sin(x^{-1}))$. Then the range $f((0,1])$ is connected by Prop. \ref{lb210}. Since $f((0,1])$ is a dense subset of $X=f((0,1])\cup\{(0,0)\}$, by Prop. \ref{lb207}, $X$ is connected. However, it can be checked that $X$ is not path-connected. (Prove it yourself, or see \cite[Sec. 24]{Mun}.) $X$ is called the \textbf{topologist's sine curve}.
\end{seg}




The following proposition can be used to decompose (for example) an open subset of $\Rbb^N$ into open connected subsets. (See Pb. \ref{lb221}.)


\begin{pp}\label{lb208}
Assume that $X=\bigcup_{\alpha\in\scr A}X_\alpha$ where each $X_\alpha$ is connected. Assume that $\bigcap_{\alpha\in\scr A}X_\alpha\neq\emptyset$. Then $X$ is connected.
\end{pp}

\begin{proof}
Suppose that $X$ is not connected. By Thm. \ref{lb206}, there is a continuous surjection $f:X\rightarrow\{0,1\}$. Let $p\in\bigcap_\alpha X_\alpha$. Then $f(p)$ is $0$ or $1$. Assume WLOG that $f(p)=0$. Choose $x\in X$ such that $f(x)=1$. Choose $\alpha$ such that $x\in X_\alpha$. Then $f|_{X_\alpha}:X_\alpha\rightarrow\{0,1\}$ is a continuous surjection. So $X_\alpha$ does not satisfy IVP, and hence is not connected.
\end{proof}

\begin{exe}
Prove a path-connected version of Prop. \ref{lb208}.
\end{exe}

\begin{exe}
Prove Prop. \ref{lb207} and \ref{lb208} directly using Def. \ref{lb212} (but not using IVP).
\end{exe}



%% Record #9 2023/10/18 three lectures  22





\subsection{Rigorous constructions of $\sqrt[n]{x}$, $\log x$, and $a^x$}\label{lb219}


With the help of Cor. \ref{lb213}, one can construct a lot of well-known functions rigorously. 

%Our first construction is $\sqrt[n]{x}$. This expression was used in Sec. \ref{lb218} to prove root test and hence to construct $e^x$. Therefore, $\sqrt[n]{x}$ will also be needed in the construction of its generalization $a^x=e^{x\log a}$. Thus, we shall construct $\sqrt[n]{x}$ before we construct $a^x$.


\begin{eg}\label{lb216}
Let $f:\Rbb_{\geq0}\rightarrow\Rbb_{\geq0}$ be $f(x)=x^n$ where $n\in\Zbb_+$. Then by Cor. \ref{lb213}, $J=f(\Rbb_{\geq 0})$ is an interval. Clearly $J\subset[0,+\infty)$. Since $0\in J$ and $\sup J=+\infty$, we have $J=[0,+\infty)$. Therefore $f$ is a homeomorphism. Its inverse function is a homeomorphism: the \textbf{$n$-th root} function
\begin{gather*}
\sqrt[n]{~}:\Rbb_{\geq0}\rightarrow\Rbb_{\geq0} \qquad x\mapsto\sqrt[n]x
\end{gather*}
This gives the rigorous construction of $\sqrt[n]{x}$.
\end{eg}

A similar method gives the rigorous construction of $\log$. 
\begin{eg}\label{lb217}
By Exp. \ref{lb214}, the exponential function $\exp:\Rbb\rightarrow\Rbb$ is continuous. We claim that $\exp$ is a strictly increasing homeomorphism from $\Rbb$ to $\Rbb_{>0}$. Its inverse function is called the \textbf{logarithmic function} \index{log@$\log$} 
\begin{align*}
\log:\Rbb_{>0}\rightarrow\Rbb \qquad x\mapsto \log x
\end{align*}
\end{eg}

\begin{proof}
From $e^x=\sum_{n=0}^\infty x^n/n!$ we clearly have $e^0=1$ and $e^x>1$ if $x>0$. From $e^{x+y}=e^xe^y$ proved in Cor. \ref{lb215}, we have $e^xe^{-x}=e^0=1$, which shows that $e^x\in\Rbb_{>0}$ for all $x\in\Rbb$. If $x<y$, then $e^y>e^x>0$ since $e^y=e^{y-x}e^x$ and $e^{y-x}>1$. So $\exp$ is strictly increasing. Thus, by Cor. \ref{lb213}, $\exp$ is a homeomorphism from $\Rbb$ to $J=\exp(\Rbb)$, and $J$ is an interval. 

When $x\geq 0$, we have $e^x\geq x$ from the definition of $e^x$. So $\sup_{x\geq 0}e^x=+\infty$. When $x\leq 0$, since $e^xe^{-x}=1$, we have $\inf_{x\leq 0}e^x=1/\sup_{x\geq 0}e^x=0$. So $\sup J=+\infty$ and $\inf J=0$. Since $0\notin\exp(\Rbb)$ (if $e^x=0$, then $1=e^xe^{-x}=0$, impossible), we have $J=\Rbb_{>0}$.
\end{proof}

\begin{eg}
Let $a\in\Rbb_{>0}$. For each $z\in\Cbb$, define
\begin{align}
a^z=e^{z\log a}
\end{align}
By Exp. \ref{lb217}, if $a>1$ (resp. $0<a<1$), the map
\begin{align}
\Rbb\rightarrow\Rbb_{>0}\qquad x\mapsto a^x
\end{align}
is an increasing (resp. decreasing) homeomorphism, since it is the composition of the increasing (resp. decreasing) homeomorphism $x\in\Rbb\mapsto x\log a\in\Rbb$ and the increasing one $\exp:\Rbb\rightarrow\Rbb_{>0}$. By the proof of Exp. \ref{lb217}, we have 
\begin{align}
a^0=1\qquad a^xa^{-x}=1\qquad a^xa^y=a^{x+y}
\end{align}
And clearly
\begin{align}
a^1=a.
\end{align}
It follows that for every $n\in\Zbb_+$, $a^n=a^{1+\cdots+1}=a\cdots a$. Namely, $a^n=e^{n\log a}$ agrees with the usual understanding of $a^n$. Thus, since $(a^{1/n})^n$ equals $a^{1/n}\cdots a^{1/n}=a^{1/n+\cdots+1/n}=a^1=a$, we conclude
\begin{align*}
a^{\frac 1n}=\sqrt[n]{a}
\end{align*}
\end{eg}



\begin{eg}
By Exp. \ref{lb217}, if $p>0$ (resp. $p<0$), then
\begin{align}
\Rbb_{>0}\rightarrow\Rbb_{> 0} \qquad x\mapsto x^p=e^{p\log x}\label{eq102}
\end{align}
is an increasing (resp. decreasing) homeomorphism, since it is the composition of the increasing (resp. decreasing)  homeomorphism $x\in\Rbb_{>0}\rightarrow p\log x\in\Rbb$ and the increasing homeomorphism $\exp:\Rbb\rightarrow\Rbb_{>0}$. 
\end{eg}







\subsection{Problems and supplementary material}


Let $X$ and $Y$ be topological spaces.

\subsubsection{Open sets, closed sets, closures}



\begin{prob}
Let $A,B\in X$. Let $(A_\alpha)_{\alpha\in \scr A}$ be a family of subsets of $X$. Prove that
\begin{subequations}
\begin{gather}
\ovl{A\cup B}=\ovl A\cup \ovl B\label{eq73}\\
\ovl{\bigcap_{\alpha\in \scr A}A_\alpha}\subset\bigcap_{\alpha\in\scr A}\ovl{A_\alpha}\label{eq74}
\end{gather}
\end{subequations}
\end{prob}

The following problem is crucial to the study of compactness. (See Sec. \ref{lb254} for instance.)

\begin{prob}\label{lb223}
Let $(x_\alpha)_{\alpha\in I}$ be a net in $X$. Let $x\in X$. Prove that the following statements are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $(x_\alpha)_{\alpha\in I}$ has a subnet converging to $x$.
\item For every neighborhood $U$ of $x$, we have that $x_\alpha$ is frequently in $U$.
\item $x$ belongs to $\dps\bigcap_{\alpha\in I}\ovl{\{x_\beta:\beta\geq\alpha\}}$.
\end{enumerate}
Any $x\in X$ satisfying one of these three conditions is called a \textbf{cluster point} \index{00@Cluster point of a net in a topological space} of $(x_\alpha)_{\alpha\in I}$. (Compare Pb. \ref{lb64}.)
\end{prob}

\begin{proof}[Hint]
(2)$\Leftrightarrow$(3) is a direct translation. Assume (2). To prove (1), show that the preordered set $(J,\leq)$ is a directed set, where
\begin{subequations}
\begin{gather}
\begin{gathered}
J=\{(\alpha,U)\in I\times\Nbh_X(x):x_\alpha\in U \}\\[0.5ex]
(\alpha,U)\leq (\alpha',U')\qquad\Longleftrightarrow\qquad \alpha\leq \alpha'\text{ and }U\supset U'
\end{gathered}
\end{gather}
(Important: \uwave{The only place you need condition (2) is in the proof that $J$ is directed}.) Prove that $(x_\mu)_{\mu\in J}$ is a subnet of $(x_\alpha)_{\alpha\in I}$ if for each $(\alpha,U)\in J$ we set
\begin{align}
x_{(\alpha,U)}=x_\alpha
\end{align}
\end{subequations}
(Namely, the increasing map $J\rightarrow I$ is defined to be $(\alpha,U)\mapsto \alpha$.) Prove that $(x_\mu)_{\mu\in J}$ converges to $x$. 
\end{proof}





\begin{rem}\label{lb238}
By Pb. \ref{lb223}-(3), the set of cluster points of $(x_\alpha)$ is a closed subset, since intersections of closed subsets are closed (cf. Cor. \ref{lb186}, or by \eqref{eq74}).
\end{rem}

For the reader's convenience, we present below the sequential version of Pb. \ref{lb223}. ``(1)$\Leftrightarrow$(2)" is due to Pb. \ref{lb64}. ``(2)$\Leftrightarrow$(3)" is due to Pb. \ref{lb223}.

\begin{pp}\label{lb256}
Assume that $X$ is a metric space. Let $(x_n)_{n\in\Zbb_+}$ be a sequence in $X$. Let $x\in X$. The following statements are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $(x_n)_{n\in\Zbb_+}$ has a subsequence converging to $x$.
\item For every neighborhood $U$ of $x$, we have that $x_n$ is frequently in $U$.
\item $x$ belongs to $\dps\bigcap_{n\in\Zbb_+}\ovl{\{x_k:k\geq n\}}$.
\end{enumerate}
Any $x\in X$ satisfying one of these three conditions is called a \textbf{cluster point} of  $(x_n)_{n\in\Zbb_+}$.
\end{pp} 

Prop. \ref{lb256}-(3) should remind you of the definitions of $\limsup$ and $\liminf$.



\begin{srem}\label{lb263}
It is not hard to show that \textit{the (1,2,3) of Prop. \ref{lb256} are equivalent in the more general case that $X$ is a first countable topological space} (see below for the definition). The proof is similar to that for metric spaces, and is left to the readers as an exercise.
\end{srem}

\begin{df}\label{lb262}
Let $X$ be a topological space. A subset $\mc B_x$ of $\Nbh_X(x)$ is called a \textbf{neighborhood basis} \index{00@Neighborhood basis} of $x$, if for every $U\in\Nbh_X(x)$ there exists $V\in\mc B_x$ such that $V\subset U$. We say that $X$ \textbf{first countable} \index{00@First countable} if every point $x$ has a neighborhood basis $\mc B_x$ which is a countable set.  
\end{df}


\begin{eg}
If $X$ is a metric space, then $X$ is first countable, since for every $x\in X$, $\{B_X(x,1/n):n\in\Zbb_+\}$ is a neighborhood basis of $x$.
\end{eg}

\begin{rem}\label{lb267}
By Pb. \ref{lb223}-(2) and Prop. \ref{lb256}-(2), if $(x_n)$ is a sequence in a metric space $X$, then $(x_n)$ has a subsequence converging to $x\in X$ iff $(x_n)$ has a subnet converging to $x$. This is not necessarily true when $X$ is a general topological space. Note that in the general case, cluster points of a sequence $(x_n)$ mean cluster points of $(x_n)$ as a net. Thus, they are not the limits of convergent \textit{subsequences} of $(x_n)$. 
\end{rem}


\begin{comment}
\begin{rem}
Although the word ``cluster point" is also used for a subset $A$ of $X$ (cf. Rem. \ref{lb176}), it is not parallel to the notion of cluster points of net. The true analogous concept of ``cluster points of a net" is ``closure points of a subset".
\end{rem}
\end{comment}



\begin{prob}\label{lb251}
Assume that $X$ is a metric space. Let $E\subset X$. Recall that $d(x,E)=d(E,x)=\inf_{e\in E}d(e,x)$. Prove that
\begin{align}
\{x\in X:d(x,E)=0\}=\ovl E
\end{align}
\end{prob}





\begin{rem}\label{lb257}
If $E,F$ are disjoint subsets of a metric space $X$, a continuous function $f:X\rightarrow[0,1]$ is called an \textbf{Urysohn function} \index{00@Urysohn functions for metric spaces} with respect to $E,F$, if
\begin{align*}
f^{-1}(1)=E\qquad f^{-1}(0)=F
\end{align*} 
For example, it is easy to check that
\begin{gather}
f:X\rightarrow[0,1]\qquad f(x)=\frac{d(x,F)}{d(x,E)+d(x,F)}
\end{gather}
is an Urysohn function.
\end{rem}


\begin{sprob}
A topological space $X$ is called \textbf{normal} \index{00@Normal topological space} if for every closed disjoint $E,F\subset X$, there exist disjoint open subsets $U,V\subset X$ such that $E\subset U$ and $F\subset V$. 
\begin{enumerate}
\item Prove that $X$ is normal iff for each $E\subset W\subset X$ where $E$ is closed and $W$ is open, there exists an open subset $U\subset X$ such that $E\subset U\subset \ovl U\subset W$.
\item Prove that if $X$ is metrizable, then $X$ is normal.
\end{enumerate}
\end{sprob}








\subsubsection{Continuous maps}


\begin{exe}\label{lb184}
Let $f:X\rightarrow Y$ be a map.
\begin{enumerate}
\item Suppose that $F$ is a subset of $Y$ containing $f(X)$. Show that $f:X\rightarrow Y$ is continuous iff $f:X\rightarrow F$ is continuous.
\item (Local to global principle) Suppose that $X=\bigcup_{\alpha\in I}U_\alpha$ where each $U_\alpha$ is an open subset of $X$, Prove that $f$ is continuous iff $f|_{U_\alpha}:U_\alpha\rightarrow Y$ is continuous for every $\alpha$. 
\end{enumerate}
\end{exe}

\begin{rem}\label{lb205}
The above local-to-global principle for continuous functions can be rephrased in the following way. Suppose that $X=\bigcup_{\alpha\in I}U_\alpha$ where each $U_\alpha$ is an open subset of $X$. Suppose that for each $\alpha$ we have a continuous map $f_\alpha:U_\alpha\rightarrow Y$. Assume that for each $\alpha,\beta\in I$ we have
\begin{align*}
f_\alpha|_{U_\alpha\cap U_\beta}=f_\beta|_{U_\alpha\cap U_\beta}
\end{align*}
Then there is a (necessarily unique) continuous function $f:X\rightarrow Y$ such that $f|_{U_\alpha}=f_\alpha$ for every $\alpha$.
\end{rem}



\begin{prob}
Let $f:X\rightarrow Y$ be a map. Suppose that $X=A_1\cup\cdots \cup A_N$ where $N\in\Zbb_+$ and $A_1,\dots,A_N$ are closed subsets of $X$. Suppose that $f|_{A_i}:A_i\rightarrow Y$ is continuous for each $1\leq i\leq N$. Prove that $f$ is continuous. 

Does the conclusion remain true if $A_1,\dots,A_N$ are not assumed closed? If no, find a counterexample.  \hfill\qedsymbol
\end{prob}

\begin{proof}[Note]
Do not use Prop. \ref{lb199} in your proof. But you can think about how this problem is related to Prop. \ref{lb199}.
\end{proof}




\begin{df}\label{lb175}
Let $(I,\leq)$ be a directed set. Let $\infty_I$ (often abbreviated to $\infty$) be a new symbol not in $I$. Then
\begin{align*}
I^*=I\cup\{\infty_I\}
\end{align*}
is also a directed set if we extend the preorder $\leq$ of $I$ to $I^*$ by setting
\begin{align*}
\alpha\leq\infty_I\qquad(\forall\alpha\in I^*)
\end{align*}
For each $\alpha\in I$, let
\begin{align*}
I^*_{\geq\alpha}=\{\beta\in I^*:\beta\geq\alpha\}
\end{align*}
The \textbf{standard topology} \index{00@Topology of $\mc I^*=I\cup\{\infty_I\}$ where $I$ is an index set} on $I^*$ is defined to be the one induced by the basis
\begin{align}\label{eq63}
\mc B=\big\{\{\alpha\}:\alpha\in I \big\}\cup \big\{I^*_{\geq\alpha}:\alpha\in I \big\}
\end{align}
\end{df}



\begin{prob}\label{lb278}
Let $(I,\leq)$ be a directed set. Let $I^*$ be as in Def. \ref{lb175}.
\begin{enumerate}
\item Check that $\mc B$ (defined by \eqref{eq63}) is a basis for a topology. (Therefore, $\mc B$ generates a topology $\mc T$ on $I^*$.) 
\item Let $(x_\alpha)_{\alpha\in I}$ be a net in a topological space $X$. Let $x_\infty\in X$. (So we have a function $x:I^*\rightarrow X$.) Prove that 
\begin{align}
x\text{ is a continuous function}\qquad\Longleftrightarrow\qquad \lim_{\alpha\in I} x_\alpha=x_\infty
\end{align}
\item Is $I^*$ Hausdorff? Prove it, or find a counterexample.
\end{enumerate} 
\end{prob}




\subsubsection{Product spaces}













\begin{prob}
Prove Thm. \ref{lb192}.
\end{prob}


\begin{prob}\label{lb258}
Let $(X_\alpha)_{\alpha\in\scr A}$ and $(Y_\alpha)_{\alpha\in\scr A}$ be families of nonempty topological spaces. Let $Z$ be a nonempty topological space. For each $\alpha\in\scr A$, choose maps $f_\alpha:X_\alpha\rightarrow Y_\alpha$ and $g_\alpha:Z\rightarrow X_\alpha$. 
\begin{enumerate}
\item Use Thm. \ref{lb192} to prove that  \index{zz@$\prod_{\alpha\in\scr A} f_\alpha$}
\begin{align}
\prod_{\alpha\in\scr A}f_\alpha:\prod_\alpha X_\alpha\rightarrow\prod_\alpha Y_\alpha\qquad (x(\alpha))_{\alpha\in\scr A}\mapsto (f_\alpha(x(\alpha)))_{\alpha\in\scr A}
\end{align}
is continuous iff each $f_\alpha$ is continuous.
\item Use Thm. \ref{lb192} to prove that \index{zz@$\bigvee_{\alpha\in\scr A} f_\alpha$}
\begin{align}
\bigvee_{\alpha\in\scr A}g_\alpha:Z\rightarrow \prod_\alpha X_\alpha \qquad z\mapsto (g_\alpha(z))_{\alpha\in\scr A}
\end{align}
is continuous iff each $g_\alpha$ is continuous.
\end{enumerate}
\end{prob}







\begin{prob}\label{lb203}
Let $(X_\alpha)_{\alpha\in\scr A}$ be an uncountable family of metric spaces, where each $X_\alpha$ has at least two elements. Let $S=\prod_{\alpha\in\scr A}X_\alpha$ be the product space, equipped with the product topology. Prove that $S$ is not first countable (recall Def. \ref{lb262}), and hence not metrizable.
\end{prob}

\subsubsection{Limits of functions}

\begin{prob}
Prove the equivalence of (2) and (3) in Def. \ref{lb197}.
\end{prob}


\begin{prob}
Find $\dps\lim_{(x,y)\rightarrow(0,0)}f(x,y)$, or explain why it does not exist:
\begin{gather*}
f(x,y)=\frac{x^2-y^2}{x^2+y^2}\\
f(x,y)=\frac{(xy)^2}{(xy)^2+(x-y)^2}\\
f(x,y)=\frac{x^6y^2}{(x^4+y^2)^2}
\end{gather*}
\end{prob}








\subsubsection{Connectedness}

\begin{prob}
Assume that $X,Y$ are not empty. Prove that $X$ and $Y$ are connected iff $X\times Y$ is connected.
\end{prob}

\begin{proof}[Hint]
Write $X\times Y$ as a union of sets of the form $(X\times\{y\})\cup (\{x\}\times Y)$.
\end{proof}


\begin{df}
A topological space $X$ is called \textbf{locally connected} \index{00@Locally connected} if every $x\in X$ has a neighborhood basis $\mc B_x$ (recall Def. \ref{lb262}) whose members are all connected.
\end{df}

\begin{eg}
Every open subset of a locally connected space is clearly locally connected.
\end{eg}

\begin{eg}
$\Rbb^N$ is locally connected, since open balls are path-connected and hence connected (by Thm. \ref{lb220}). Therefore, every open subset of $\Rbb^N$ is locally connected.
\end{eg}


\begin{prob}\label{lb221}
Suppose that $X$ is locally connected. Prove that $X$ has a unique (disjoint) decomposition $X=\bigsqcup_{\alpha\in\scr A}X_\alpha$ where each $X_\alpha$ is a nonempty connected open subset of $X$. (Each $X_\alpha$ is called a \textbf{connected component} of $X$.) \index{00@Connected component}
\end{prob}

\begin{proof}[Hint]
For each $x\in X$, consider the union of all connected neighborhoods containing $x$.
\end{proof}




\newpage

\section{Compactness}\label{lb351}


\subsection{Overture: two flavors of compactness}

Let $X$ be a topological space.



\begin{df}
An \textbf{open cover} \index{00@Open cover} of $X$ means a family $\fk U=(U_\alpha)_{\alpha\in\scr A}$ of open subsets of $X$ such that $X=\bigcup_{\alpha\in\scr A} U_\alpha$. $\fk U$ is called \textbf{finite} resp. \textbf{countable} if $\scr A$ is finite resp. countable. A \textbf{subcover} \index{00@Subcover} of $\fk U$ means an open cover $\fk V=(V_\beta)_{\beta\in\scr B}$ of $X$ such that each $V_\beta$ equals $U_\alpha$ for some $\alpha\in\scr A$.
\end{df}

\begin{df}
We say that $X$ is a \textbf{compact space} \index{00@Compact space} if every open cover of $X$ has a finite subcover.  We say that $X$ is a \textbf{Lindel\"of space} \index{00@Lindel\"of space} if every open cover of $X$ has a countable subcover.
\end{df}

\begin{rem}
For the purpose of this chapter, it suffices to consider open covers $\fk U=(U_\alpha)_{\alpha\in\scr A}$ such that $\alpha\in\scr A\mapsto U_\alpha\in 2^X$ is injective. (Namely, one can throw away repeated open sets.) In this case, we write
\begin{align*}
\fk U\subset 2^X
\end{align*}
and view $\fk U$ as a subset of $2^X$. A \textbf{subcover} of such $\fk U$ is an open cover $\fk V$ such that $\fk V\subset\fk U$. The readers can check that this assumption does not affect the definition of compact spaces and Lindel\"of spaces.
\end{rem}

\begin{rem}\label{lb244}
Compactness can also be formulated in a relevant version: If $A$ is a compact subset of $X$, and if $\fk U$ is a set of open subsets of $X$ such that $A\subset\bigcup_{U\in\fk U}U$, then since $\{U\cap A:U\in\fk U\}$ gives an open cover of $A$, we know that
\begin{align*}
A\subset U_1\cup\cdots\cup U_n
\end{align*}
some $U_1,\dots,U_n\in\fk U$. Conversely, any $A$ satisfying such property is a compact subspace of $X$.
\end{rem}


\begin{exe}
Show that a finite union of compact spaces is compact. Show that a finite set is compact.
\end{exe}

\begin{exe}
Show that $X$ is compact iff $X$ satisfies the \textbf{finite intersection property}: \index{00@Finite intersection property} The intersection of a family of non-empty closed subsets is nonempty.
\end{exe}



A main goal of this chapter is to prove the following theorem. Its proof will be finished at \hyperlink{target1}{the end} of Sec. \ref{lb253}. In fact, the formal proof will only be in Sec. \ref{lb254} and Sec. \ref{lb253}. 

\begin{thm}\label{lb222}
Let $X$ be a metric space. Then $X$ is sequentially compact iff $X$ is compact.
\end{thm}
This is the first fundamental theorem we prove in this course. Its significance lies in the fact that it connects two seemingly very different notions of compactness, and hence two strikingly different intuitions. We hope that the reader can not only follow the logical chains of the proofs, but also understand the pictures behind the proof. More precisely, we hope that the readers can have an intuitive understanding of the following questions:
\begin{itemize}
\item Why are these two compactness both powerful in solving certain problems? What roles do they play in the proof? How are the roles played by these two compactness related? (This is more important than just knowing why these notions are \textit{logically} equivalent.)
\item Why is one version of compactness more powerful than the other one in solving certain problems?
\end{itemize}




Thus, I feel that it is better to look at some applications of compactness before we prove Thm. \ref{lb222} rigorously. For pedagogical purposes, we also introduce two related notions of compactness:

\begin{df}
We say that $X$ is \textbf{net-compact}, \index{00@Net-compact} if every net $(x_\alpha)_{\alpha\in I}$ in $X$ has at least one cluster point (recall Pb. \ref{lb223}), equivalently, at least one convergent subnet. We say that $X$ is \textbf{countably compact}, \index{00@Countably compact} if every countable open cover of $X$ has a finite subcover.
\end{df}



Sequential compactness and net-compactness clearly share the same intuition. Countable compactness is intuitively similar to compactness. Also, compactness clearly implies countable compactness. But net-compactness does not imply sequential compactness in general: In a net-compact space, every sequence has a convergent subnet, but not necessarily a convergent subsequence. 

The relationship between these four versions of compactness is as follows. (We will prove this in the course of proving Thm. \ref{lb222}.)
\begin{subequations}\label{eq68}
\begin{align}
&\text{Metric spaces:} & \text{all the four versions}&\text{ of compactness are equivalent}\\
&\text{Topological spaces:} & \text{net-compact}&\Longleftrightarrow\text{compact}
\end{align}
\end{subequations}
After proving \eqref{eq68}, we will not use the notions of countable compactness and net-compactness. This is because net-compactness is equivalent to compactness, and countable compactness is more difficult to use than compactness. (Nevertheless, proving/using compactness by proving/using the existence of cluster points is often helpful.)




\subsection{Act 1: case studies}\label{lb293}



\subsubsection{Extreme value theorem (EVT)}

\begin{lm}[\textbf{Extreme value theorem}]\label{lb224} \index{00@EVT=Extreme value theorem}
Let $X$ be a compact topological space. Let $f:X\rightarrow\Rbb$ be a continuous function. Then $f$ attains its maximum and minimum at points of $X$. In particular, $f(X)$ is a bounded subset of $\Rbb$.
\end{lm}



We have seen the sequential compactness version of \textbf{EVT} (extreme value theorem) in Lem. \ref{lb56}. There, we find the point $x\in X$ at which $f$ attains its maximum by first finding a sequence $(x_n)$ such that $f(x_n)$ converges to $\sup f(X)$. Then we choose any convergent subsequence $(x_{n_k})$, which converges to the desired point $x$. The same method can be used to prove EVT for net-compact spaces if we replace sequences by nets.


For compact spaces, EVT is proved in a completely different way. In fact, without the tools of sequences and nets, one can not easily find $x$ at which $f$ attains it maximum. The argument is rather indirect:

\begin{proof}[Proof of Lem. \ref{lb224}]
It suffices to prove that $f(X)$ is bounded for all continuous maps $f:X\rightarrow\Rbb$. Then $a=\sup f(X)$ is in $\Rbb$. If $a\notin f(X)$, we choose a homeomorphism $\varphi:(-\infty,a)\rightarrow\Rbb$. So $\varphi\circ f:X\rightarrow\Rbb$ is  continuous but has no upper bound. This is impossible.
\end{proof}

Thus, to prove EVT, it remains to prove:
\begin{eg}\label{lb227}
Assume that $X$ is compact and $f:X\rightarrow\Rbb$ is continuous. Then $f(X)$ is a bounded subset of $\Rbb$.
\end{eg}

\begin{proof}
For each $x\in X$, since $f$ is continuous at $x$, there exists $U_x\in\Nbh(x)$ such that $|f(p)-f(x)|<1$ for all $p\in U_x$. In particular, $f(U_x)$ is bounded. Since $X=\bigcup_{x\in X}U_x$ is an open cover of $X$, by compactness, $X=U_{x_1}\cup\cdots\cup U_{x_n}$ for some $x_1,\dots,x_n\in X$. Thus $f(X)= f(U_{x_1})\cup\cdots\cup f(U_{x_n})$ is bounded.
\end{proof}



The above proof is typical. It suggests that compactness is powerful for \uline{proving finiteness properties} rather than finding solutions of functions satisfying certain requirements. Thus, if you want to prove a finiteness property using sequential or net-compactness, you have to prove it indirectly. For example, you need to prove it by contradiction:

\begin{eg}
Assume that $X$ is net-compact or sequentially compact. Assume that $f:X\rightarrow\Rbb$ is continuous. Then $f(X)$ is a bounded subset of $\Rbb$.
\end{eg}


\begin{proof}
Assume that $X$ is net-compact. If $f(X)$ is not bounded above, then there is a sequence $(x_\alpha)$ in $X$ (viewed as a net)  such that $\lim_\alpha f(x_\alpha)=+\infty$. By net-compactness, $(x_\alpha)$ has a subnet $(x'_\beta)$ converging to $x\in X$. So $f(x)=\lim_\beta f(x'_\beta)=+\infty$, impossible. So $f$ is bounded above, and hence bounded below by a similar argument. The case where $X$ is sequentially compact can be proved by a similar method.
\end{proof}




Let us look at a more complicated example.













\subsubsection{Uniform convergence in multivariable functions}\label{lb271}


\begin{eg}\label{lb225}
Let $X,Y$ be topological spaces. Assume that $Y$ is compact. Let $V$ be a normed vector space. Choose $f\in C(X\times Y,V)$. For each $x\in X$, let
\begin{align*}
f_x:Y\rightarrow V\qquad y\mapsto f(x,y)
\end{align*}
Equip $C(Y,V)$ with the $l^\infty$-norm. Then the following map is continuous:
\begin{align}
\Phi(f):X\rightarrow C(Y,V)\qquad x\mapsto f_x
\end{align}
\end{eg}



\begin{rem}
Note that since $Y$ is compact, each $g\in C(Y,V)$ is bounded by EVT (applied to $|g|$). So $C(Y,V)\subset l^\infty(Y,V)$.
\end{rem}


The continuity of $\Phi(f)$ means that for each $x\in X$, the following statement holds:
\begin{itemize}
\item[\textleaf] For every $\eps>0$ there exists $U\in\Nbh_X(x)$ such that for all $p\in U$ and all $y\in Y$ we have $\Vert f(p,y)-f(x,y)\Vert<\eps$.
\end{itemize}
This is clearly a finiteness property. Thus, its sequentially compact version or net-compact version should be proved indirectly. Indeed, when $X,Y$ are metric spaces and $Y$ is sequentially compact, we have proved this in Pb. \ref{lb103} by contradiction. The same method (with sequences replaced by nets) also works for the net-compact case:

\begin{eg}
Example \ref{lb225} is true, assuming that $Y$ is net-compact rather than compact.
\end{eg}


\begin{proof}
Suppose ``\textleaf" is not true. Then there is $\eps>0$ such that for every $U\in\Nbh_X(x)$ there is $x_U\in U$ and $y_U\in Y$ such that $\Vert f(x_U,y_U)-f(x,y_U)\Vert\geq\eps$. Then $(x_\alpha)_{\alpha\in\Nbh_X(x)}$ is a net converging to $x$, where $x_\alpha=x_U$ if $\alpha=U$. Since $Y$ is net-compact, $(y_\alpha)$ has a subnet $(y_\beta)$ converging to  some $y\in Y$. Since the subnet $(x_\beta)$ also converges to $x$, we have $\lim_\beta f(x_\beta,y_\beta)=f(x,y)$ and $\lim_\beta f(x,y_\beta)=f(x,y)$ by the continuity of $f$. This contradicts the fact that $\Vert f(x_\beta,y_\beta)-f(x,y_\beta)\Vert\geq\eps$ for all $\beta$.
\end{proof}



On the other hand, the solution of Exp. \ref{lb225} using open covers is a direct proof:

\begin{proof}[\textbf{Proof of Exp. \ref{lb225}}]
``\textleaf" is a finiteness property global over $Y$. We prove ``\textleaf" by first proving it locally, and then passing to the global space $Y$ using the compactness of $Y$.

Fix $x\in X$. Choose any $\eps>0$. For each $y\in Y$, since $f$ is continuous at $(x,y)$, there is a neighborhood $W$ of $(x,y)$ such that for every $(p,q)\in W$ we have $\Vert f(p,q)-f(x,y)\Vert<\eps/2$. By Exp. \ref{lb226}, we can shrink $W$ to a smaller neighborhood of the form $U_y\times V_y$ where $U_y\in\Nbh_X(x)$ and $V_y\in\Nbh_Y(y)$. Then for each $p\in U_y$ and $q\in U_y$ we have $\Vert f(p,q)-f(x,y)\Vert<\eps/2$, and hence $\Vert f(p,q)-f(x,q)\Vert<\eps$. This proves the special case of ``\textleaf" where $Y$ is replaced by $U_y$.

Now we pass from local to global in the same way as in the proof of Exp. \ref{lb227}. Since $Y=\bigcup_{y\in Y}V_y$ is an open cover of $Y$, by the compactness of $Y$, there is a finite subset $F\subset Y$ such that $Y=\bigcup_{y\in F}V_y$. Then ``\textleaf" is true if we let $U=\bigcap_{y\in F}U_y$.
\end{proof}


\subsubsection{Conclusions}

\begin{enumerate}%[label=(\arabic*)]
\item Sequential compactness and net-compactness are useful for finding solutions of a function satisfying some given conditions. 
\item Compactness is useful for proving finiteness properties. The proof is usually a  local-to-global argument. It is usually a direct argument (rather than proof by contradiction).
\item If one uses sequential/net-compactness to prove a finiteness property, one usually proves it by contradiction: Assume that this finiteness is not true. Find a sequence/net $(x_\alpha)$ that violates this finiteness property, and pass to a convergent subsequence/subnet to find a contradiction.
\item Therefore, for sequential/net-compact spaces, the argument is in the direction of ``getting smaller and smaller", opposite to the argument for compact spaces.
\end{enumerate}

Let me emphasize that the proof for sequentially/net-compact spaces is opposite to the one for compact spaces in two aspects: (1) If one argument is direct, the other is a proof by contradiction for the same problem. (2) The former has the intuition of ``getting smaller", while the latter local-to-global argument has the intuition of ``getting larger". 

I have already touched on this phenomenon in Rem. \ref{lb229}: \textit{The reason that sequences and nets run in the opposite direction to that of open sets is because closed sets are opposite to open sets}, as proved in Thm. \ref{lb181}.  Thus, you can expect that the transition between closed and open sets plays a crucial role in the following proof of Thm. \ref{lb222}. 

\begin{comment}

Now, we have a more vivid sense of the following sentence: 
\begin{itemize}
\item[$\Sun/\Moon$] The seemingly simple fact that ``closed sets are the complements of open sets" is the golden key that allows you to walk between the worlds of dark and light.
\end{itemize}



Let me close this section with a final remark.

\begin{rem}
Logically equivalent concepts are usually not intuitively equivalent. Proving directly is sometimes more transparent and intuitive than proving by contradiction, and sometime vice versa. For example: You will never prove a property by contradiction unless you already know what should be proved, and what statement is expected true. However, a direct argument can be more helpful in finding an unknown property and setting the goal.
\end{rem}
\end{comment}


\subsection{Act 2: ``sequentially compact $\Leftrightarrow$ countably compact'' for metric spaces, just as ``net-compact $\Leftrightarrow$ compact''}\label{lb254}

\epigraph{The road up and the road down is one and the same.}{Heraclitus}


As mentioned before, our goal of this chapter is to prove ``sequentially compact $\Leftrightarrow$ compact" for metric spaces. Our strategy is as follows: We reformulate the sequential compactness condition in terms of decreasing chains of closed sets, and reformulate the compactness condition in terms of increasing chains of open sets. Then we relate these two pictures easily using Thm. \ref{lb181}.

The following difficulty arises when carrying out this strategy. Sequences are countable by nature, whereas open covers can have arbitrarily large cardinality. Thus, sequences are related to countable decreasing chains, and hence countable open covers. Therefore, the above idea only implies the equivalence
\begin{subequations}\label{eq69}
\begin{align}\label{eq70}
\text{sequentially compact}\quad\Longleftrightarrow\quad \text{countably compact}\qquad(\text{for metric spaces})
\end{align}
Accordingly, it will only imply
\begin{align}\label{eq71}
\text{net-compact}\qquad\Longleftrightarrow\qquad \text{compact}
\end{align}
\end{subequations}
since there are no constraints on the cardinalities of indexed sets of nets. We will prove \eqref{eq69} in this section, and leave the proof of ``countably compact $\Leftrightarrow$ compact" for metric spaces to Sec. \ref{lb253}.


Since the proofs of \eqref{eq70} and \eqref{eq71} are similar, we first discuss \eqref{eq71}.


\begin{pp}\label{lb230}
Let $X$ be a topological space. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $X$ is compact.
\item (\textbf{Increasing chain property}) If $(U_\mu)_{\mu\in I}$ is an increasing net of open subsets of $X$ satisfying $\bigcup_{\mu\in I}U_\mu=X$, then $U_\mu=X$ for some $\mu$.
\item (\textbf{Decreasing chain property}) If $(E_\mu)_{\mu\in I}$ is a decreasing net of nonempty closed subsets of $X$, then $\bigcap_{\mu\in I}E_\mu\neq\emptyset$.
\end{enumerate}
\end{pp}

Here, ``increasing net" means $U_\mu\subset U_\nu$ if $\mu\leq \nu$, and ``decreasing net" means the opposite.

\begin{proof}
(1)$\Rightarrow$(2): Assume (1). Then $X=\bigcup_\mu U_\mu$ is an open cover of $X$. So, by the compactness of $X$, we have $X=U_{\mu_1}\cup\cdots\cup U_{\mu_n}$ for some $\mu_1,\dots,\mu_n\in I$. Choose $\mu\in I$ which is $\geq \mu_1,\dots,\mu_n$. Then $X=U_\mu$.

(2)$\Rightarrow$(1): Assume (2). Let $X=\bigcup_{\alpha\in\scr A} W_\alpha$ be an open cover of $X$. Let $I=\fin(2^{\scr A})$. For each $\mu=\{\alpha_1,\dots,\alpha_n\}\in I$, let $U_\mu=W_{\alpha_1}\cup\cdots\cup W_{\alpha_n}$. Then $(U_\mu)_{\mu\in I}$ is an increasing net of open sets covering $X$. Thus, by (2), we have $U_\mu=X$ for some $\mu$. This proves (1).

(2)$\Leftrightarrow$(3): If we let $E_\mu=X\setminus U_\mu$, then (2) says that if $(E_\mu)$ is a decreasing net of closed sets whose intersection is $\emptyset$, then $E_\mu=\emptyset$ for some $\mu$. This is the contraposition of (3).
\end{proof}


We now relate decreasing chain property and cluster points of nets using \eqref{eq76}.




%% Record #10 2023/10/23 two lectures  24


\begin{thm}\label{lb232}
Let $X$ be a topological space. Then $X$ is net-compact iff $X$ is compact. 
\end{thm}


\begin{proof}
Assume that $X$ is net-compact. By Prop. \ref{lb230}, it suffices to prove that $X$ satisfies the decreasing chain property. Let $(E_\mu)_{\mu\in I}$ be a decreasing net of nonempty closed subsets of $X$. For each $\mu$ we choose $x_\mu\in E_\mu$, which gives a net $(x_\mu)_{\mu\in I}$ in $X$. The fact that $(E_\mu)$ is decreasing implies that $F_\mu\subset E_\mu$ if we set
\begin{subequations}\label{eq76}
\begin{align}
F_\mu=\{x_\nu:\nu\in I,\nu\geq\mu \}\label{eq72}
\end{align}
Thus, the closure $\ovl F_\mu$ is a subset of $E_\mu$ since $E_\mu$ is closed. It suffices to prove that $\bigcap_{\mu\in I}\ovl F_\mu\neq\emptyset$. By Pb. \ref{lb223}, 
\begin{align}
\bigcap_\mu \ovl F_\mu=\big\{\text{the cluster points of the net $(x_\mu)_{\mu\in I}$}\big\}
\end{align}
\end{subequations}
which is nonempty because $X$ is net-compact. This finishes the proof that $X$ is compact.

Now we assume that $X$ is compact. Let $(x_\mu)_{\mu\in I}$ be a net in $X$. Define $F_\mu$ by \eqref{eq72}. Then $(\ovl F_\mu)_{\mu\in I}$ is a decreasing net of nonempty closed subsets. So $\bigcap_\mu\ovl F_\mu$, the set of cluster points of $(x_\mu)_{\mu\in I}$, is nonempty by the decreasing chain property (cf. Prop. \ref{lb230}). So $X$ is net-compact.
\end{proof}



\begin{pp}\label{lb231}
Let $X$ be a topological space. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $X$ is countably compact.
\item (\textbf{Increasing chain property}) If $(U_n)_{n\in\Zbb_+}$ is an increasing sequence of open subsets of $X$ satisfying $\bigcup_{n\in\Zbb_+}U_n=X$, then $U_n=X$ for some $n$.
\item (\textbf{Decreasing chain property}) If $(E_n)_{n\in\Zbb_+}$ is a decreasing sequence of nonempty closed subsets of $X$, then $\bigcap_{n\in\Zbb_+}E_n\neq\emptyset$.
\end{enumerate}
\end{pp}

\begin{proof}
Similar to the proof of Prop. \ref{lb230}.
\end{proof}

\begin{exe}
Fill in the details of the proof of Prop. \ref{lb231}.
\end{exe}



\begin{lm}\label{lb247}
Let $X$ be a metric space. Then $X$ is sequentially compact iff $X$ is countably compact. 
\end{lm}

\begin{proof}
This lemma can be proved in a similar way to Thm. \ref{lb231}. The only difference is that one should use the sequential version of Pb. \ref{lb223}, namely, Prop. \ref{lb256}. Note that the ``(1)$\Leftrightarrow$(2)" of Prop. \ref{lb256} does not hold for general topological spaces. Thus, sequential compactness is not equivalent to countable compactness for general topological spaces. 
\end{proof}

\begin{srem}\label{lb264}
As pointed out in Rem. \ref{lb263}, Prop. \ref{lb256} holds more generally for first countable topological spaces (Def. \ref{lb262}). Therefore, Lem. \ref{lb247} also holds for such spaces:
\begin{gather}
\begin{gathered}
\text{sequentially compact}\quad\Longleftrightarrow\quad \text{countably compact}\\
(\text{for first countable spaces})
\end{gathered}
\end{gather}
\end{srem}



\subsection{Intermezzo: elementary properties about compactness}






\begin{pp}\label{lb233}
Suppose that $X\subset Y$ where $Y$ is a topological space. The following are true.
\begin{enumerate}
\item Assume that $Y$ is compact and $X$ is closed in $Y$. Then $X$ is compact.
\item Assume that $Y$ is Hausdorff and $X$ is compact, then $X$ is a closed subset of $Y$. 
\end{enumerate} 
\end{pp}

\begin{proof}
Part 1. Let $(x_\alpha)$ be a net in $X$. Since $Y$ is compact, $(x_\alpha)$ has a subnet $(x'_\beta)$ converging to some $p\in Y$. Since $(x'_\beta)$ is in $X$, we have $p\in \ovl X=X$. So $X$ is compact.

Part 2. To prove $\ovl X=X$, we choose any net $(x_\alpha)$ in $X$ converging to $p\in Y$ and show that $p\in X$. Indeed, since $X$ is compact, $(x_\alpha)$ has a subnet $(x_\beta')$ converging to some $x\in X$. Since $(x_\beta')$ also converges to $p$, we have $p=x$ because $Y$ is Hausdorff. So $p\in X$.
\end{proof}

I have mentioned that non-Hausdorff spaces are not often used in analysis. Thus, we mainly use the following special case of Prop. \ref{lb233}:


\begin{co}\label{lb234}
Let $Y$ be a Hausdorff space and $X\subset Y$. If $X$ is compact, then $X$ is closed in $Y$. If $X$ is closed in $Y$ and if $Y$ is compact, then $X$ is compact.
\end{co}

Recall that a similar property holds for complete metric spaces, cf. Prop. \ref{lb86}.







\begin{thm}\label{lb236}
Suppose that $f:X\rightarrow Y$ is a continuous map of topological spaces where $X$ is compact. Then $f(X)$ is compact. Moreover, if $f$ is injective and $X,Y$ are Hausdorff, then $f$ restricts to a homeomorphism $f:X\rightarrow f(X)$.
\end{thm}

\begin{proof}
Choose any net $(f(x_\alpha))$ in $f(X)$ where $x_\alpha\in X$. Since $X$ is compact, $(x_\alpha)$ has a subnet $(x'_\beta)$ converging to some $x\in X$. Then $f(x'_\beta)$ converges to $f(x)$. So $f(X)$ is compact.

Now assume that $f$ is injective and $Y$ is Hausdorff. Then the subspace $f(X)$ is also Hausdorff. By replacing $Y$ by $f(X)$, we assume that $f$ is bijective. To show that $f^{-1}$ is continuous, by Prop. \ref{lb191}, it suffices to prove that $f$ is a closed map, i.e., $f$ sends every closed $E\subset X$ to a closed subset $f(E)$. Indeed, since $X$ is compact, $E$ is also compact by Cor. \ref{lb234}. So $f(E)$ is compact by the first paragraph. So $f(E)$ is closed in $X$ by Cor. \ref{lb234}.
\end{proof}

The second part of Thm. \ref{lb236} can also be proved in a similar way to Pb. \ref{lb235} by replacing sequences with nets. But that argument relies on the fact that every net in a compact Hausdorff space with only one cluster point is convergent. We leave the proof of this fact to the readers (cf. Pb. \ref{lb237}).


\begin{exe}
The first part of Thm. \ref{lb236} can be viewed as a generalization of extreme value theorem. Why?
\end{exe}



\begin{pp}\label{lb239}
Suppose that $X,Y$ are compact topological spaces. Then $X\times Y$ is compact.
\end{pp}

\begin{proof}
Take a net $(x_\alpha,y_\alpha)$ in $X\times Y$. Since $X$ is compact, $(x_\alpha)$ has a convergent subnet $(x_{\alpha_\beta})$. Since $Y$ is compact,  $(y_{\alpha_\beta})$ has a convergent subnet $(y_{\alpha_{\beta_\gamma}})$. So $(x_{\alpha_{\beta_\gamma}},y_{\alpha_{\beta_\gamma}})$ is a convergent subnet of $(x_\alpha,y_\alpha)$.
\end{proof}

\begin{rem}
Note that if $X\times Y$ is compact, then $X$, as the image of $X\times Y$ under the projection map, is compact by Thm. \ref{lb236}. Therefore, we conclude that $X\times Y$ is compact iff $X$ and $Y$ are compact.
\end{rem}

The following proposition will be used in Prop. \ref{lb245} and Lem. \ref{lb716}.

\begin{pp}\label{lb1000}
Let $K_1,K_2$ be mutually disjoint compact subsets of a Hausdorff space $X$. Then there exist mutually disjoint open subsets $U,V\subset X$ such that $K_1\subset U$ and $K_2\subset V$.
\end{pp}

Equivalently, there is an open $U\subset X$ containing $K_1$ such that $\ovl U\cap K_2=\emptyset$.

\begin{proof}
We first treat the special case that $K_1=\{x\}$. Then for each $y\in K_2$ there exist mutually disjoint $U_y\in\Nbh_X(x)$ and $V_y\in\Nbh_X(y)$. Since $K_2$ is compact, there exist $y_1,\dots,y_n\in K_2$ such that $V:=V_{y_1}\cup\cdots \cup V_{y_n}$ covers $K_2$. The proof is finished by setting $U=U_{y_1}\cap\cdots\cap U_{y_n}$.

Now consider the general case. By the above special case, for each $x\in K_1$ there exist mutually disjoint open sets $U_x,V_x$ such that $x\in U_x$ and $K_2\subset V_x$. Since $K_1$ is compact, we can find $x_1,\dots,x_n\in K_1$ such that $U=U_{x_1}\cup\cdots\cup U_{x_n}$ covers $K_1$. Let $V=V_{x_1}\cap\cdots\cap V_{x_n}$, finishing the proof. 
\end{proof}





\subsection{Act 3: ``countably compact $\Leftrightarrow$ compact" for Lindel\"of spaces}\label{lb253}


Assume in this section that $X$ is a topological space. Recall that $X$ is Lindel\"of iff every open cover has a countable subcover. Thus, it is obvious that
\begin{align}
\text{countably compact}\quad\Longleftrightarrow\quad \text{compact}\qquad(\text{for Lindel\"of spaces})
\end{align}
Thus, by Lem. \ref{lb247}, to prove that sequentially/countably compact metric spaces are compact, it suffices to prove that they are Lindel\"of.

We introduce two related concepts that are more useful than Lindel\"of spaces:
\begin{df}
We say that a topological space $X$ is \textbf{separable} \index{00@Separable} if $X$ has a countable dense subset. We say that $X$ is \textbf{second countable} \index{00@Second countable} if the topology of $X$ has a countable basis (i.e., a basis $\mc B$ with countably many elements).
\end{df}

\begin{eg}\label{lb248}
$\Rbb^N$ is separable, since $\Qbb^N$ is a dense subset. 
\end{eg}


As we shall immediately see, these two notions are equivalent for metric spaces. It is often easier to visualize and prove separability for concrete examples (such as Exp. \ref{lb248}). Indeed, Exp. \ref{lb248} is the typical example that helps us imagine more general separable spaces. However, for general topological spaces, second countability behaves better than separability.  The following property gives one reason.

\begin{pp}\label{lb475}
If $Y$ is a subset of a second countable space $X$, then $Y$ is second countable.
\end{pp}

\begin{proof}
Let $\mc B$ be a countable basis for the topology of $X$. Then $\{Y\cap U:U\in\mc B\}$ is a countable basis for the topology of $Y$.
\end{proof}
Another reason that second countability is better is because it implies Lindel\"of property. This is mainly due to the following fact:

\begin{pp}\label{lb249}
Let $\mc B$ be a basis for the topology of $X$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $X$ is Lindel\"of (resp. compact).
\item If $X$ has open cover $\fk U$ where each member of $\fk U$ is an element of $\mc B$, then $\fk U$ has a countable (resp. finite) subcover.
\end{enumerate}
\end{pp}

\begin{proof}
``(1)$\Rightarrow$(2)" is obvious.  Assume (2). Let $\fk W$ be an open cover of $X$. Let
\begin{align*}
\fk U=\{U\in \mc B:U\subset W\text{ for some }W\in\fk W\}
\end{align*} 
For each $x\in X$, since there is $W\in\fk W$ containing $x$, and since $\mc B$ is a basis, there is $U\in\mc B$ such that $x\in U\subset W$. This proves that $\fk U$ is an open cover of $X$. So $\fk U$ has a countable (resp. finite) subcover $\fk U_0$. For each $U\in\fk U_0$, choose $W_U\in\fk W$ containing $U$. Then $\{W_U:U\in\fk U_0\}$ is a countable (resp. finite) subcover of $\fk W$.
\end{proof}

\begin{co}\label{lb265}
Every second countable topological space $X$ is Lindel\"of.
\end{co}

\begin{proof}
Let $\mc B$ be a countable basis for the topology of $X$. Let $\fk U$ be an open cover of $X$ such that each member of $\fk U$ is in $\mc B$. Then by discarding duplicated terms, $\fk U$ becomes countable. This verifies (2) of Prop. \ref{lb249}.
\end{proof}


\begin{thm}\label{lb250}
Consider the following statements:
\begin{enumerate}[label=(\arabic*)]
\item $X$ is second countable.
\item $X$ is separable.
\end{enumerate}
Then (1)$\Rightarrow$(2). If $X$ is metrizable, then (1)$\Leftrightarrow$(2).
\end{thm}



\begin{proof}
Assume that $X$ is second countable with countable basis $\mc B$. Assume WLOG that $\emptyset\notin\mc B$. For each $U\in\mc B$, choose $x_U\in U$. Then one checks easily that $\{x_U:U\in\mc B\}$ is dense by checking that it intersects every nonempty open subset of $X$. This proves (1)$\Rightarrow$(2).

Assume that $X$ is a metric space with countable dense subset $E$. Let us prove that the countable set
\begin{align*}
\mc B=\{B_X(e,1/n):e\in E,n\in\Zbb_+\}
\end{align*}
is a basis for the topology of $X$. Choose any open $W\subset X$ with $x\in W$. We want to show that some member of $\mc B$ contains $x$ and is in $W$. By shrinking $W$, we may assume that $W=B_X(x,1/n)$ for some $n\in\Zbb_+$. Since $E$ is dense, $B(x,1/2n)$ contains some $e\in E$. So $d(x,e)<1/2n$. Therefore,  $B(e,1/2n)$ contains $x$  and is inside $W$ by triangle inequality.
\end{proof}


It can be proved that Lindel\"of metric spaces are separable. (Therefore, the three notions agree for metric spaces.) We will not use this fact. So we leave its proof to the readers as an exercise (cf. Pb. \ref{lb255}). The following chart is a summary of the relationships between the various topological properties about countability.





\begin{align}
\begin{aligned}
&\text{Topological spaces:} &  \text{second countable }&\Longrightarrow \left\{
{\begin{array}{l}
\text{subset is second countable}\\
\text{separable}\\
\text{Lindel\"of}
\end{array}}
\right.\\[0.5ex]
&\text{Metric spaces:}  & \text{second countabl}&\text{e }\Longleftrightarrow\text{ separable}\Longleftrightarrow \text{ Lindel\"of} 
\end{aligned}
\end{align}

\begin{eg}
Since $\Rbb^N$ is separable and hence second countable, every subset of $\Rbb^N$ is second countable, and hence is separable.
\end{eg}



\begin{thm}\label{lb252}
Let $X$ be a sequentially compact metric space. Then $X$ is separable, and hence second countable and Lindel\"of.
\end{thm}

\begin{proof}
We claim that for every $\delta>0$, there is a finite set $E\subset X$ such that for every $x\in E$, the distance $d(x,E)<\delta$. Suppose that there is no such a finite set for some given number $\delta>0$. Pick any $x_1\in X$. Suppose $x_1,\dots,x_k\in X$ have been constructed. Then there is a point $x_{k+1}\in X$ whose distance to $\{x_1,\dots,x_k\}$ is $\geq \delta$. This defines inductively a sequence $(x_k)_{k\in\Zbb_+}$ in $X$ such that any two elements have distance $\geq \delta$. So $(x_k)$ has no convergent subsequence, contradicting the sequential compactness of $X$.

Thus, for each $n\in\Zbb_+$, we can choose a finite  $E_n\subset X$ satisfying  $d(x,E_n)<1/n$ for all $x\in X$. Let $E=\bigcup_{n\in\Zbb_+}E_n$, which is countable. Then for each $x\in X$, $d(x,E)\leq d(x,E_n)<1/n$ for every $n$, which implies $d(x,E)=0$ and hence $x\in\ovl E$ by Pb. \ref{lb251}. So $E$ is dense in $X$.
\end{proof}


\begin{rem}\label{lb483}
The above proof is indirect because it proves the existence of $E_n$ by contradiction but not by explicit construction. However, if $X$ is a bounded closed subset of $\Rbb^N$, one can find an explicit countable basis for the topology of $X$:
\begin{align*}
\mc B=\{X\cap B(x,1/n):n\in\Zbb_+,x\in\Qbb^N\}
\end{align*}
and hence has an explicit countable dense subset $\{x_U:U\in\mc B,U\neq\emptyset\}$ where for each $U$ we choose some $x_U\in U$. More generally, if $X$ is a closed subset of the sequentially compact space $[0,1]^{\Zbb_+}$, one can find a countable basis for the topology of $X$ and hence a countable dense subset of $X$ in a similar way. (You will be asked to construct them in Pb. \ref{lb305}.) 


We shall see in Thm. \ref{lb261} that every sequentially compact metric space is homeomorphic to a closed subset of $[0,1]^{\Zbb_+}$. Therefore, for any sequentially compact metric space $X$ you will see in the real (mathematical) life, you don't need the indirect construction in the proof of Thm. \ref{lb252} to prove the separability of $X$. So what is the point of giving an indirect proof of Thm. \ref{lb252}? Well, you need Thm. \ref{lb252} to prove Thm. \ref{lb261}.  \hfill\qedsymbol
\end{rem}





\begin{proof}[\textbf{Proof of Thm. \ref{lb222}}] \hypertarget{target1}{}
Let $X$ be a metric space. Assume that $X$ is compact. Then $X$ is clearly countably compact, and hence sequentially compact by Lem. \ref{lb247}. Conversely, assume that $X$ is sequentially compact. Then by Lem. \ref{lb247} and Thm. \ref{lb252}, $X$ is countably compact and Lindel\"of, and hence compact.
\end{proof}




\begin{srem}
Since second countable spaces are first countable, by Rem. \ref{lb264} and Cor. \ref{lb265}, we have
\begin{gather}\label{eq75}
\begin{gathered}
\text{sequentially compact}\quad\Longleftrightarrow\quad \text{countably compact}\quad\Longleftrightarrow\quad \text{compact}\\[0.5ex]
(\text{for second countable topological spaces})
\end{gathered}
\end{gather}
Relation \eqref{eq75} not only generalizes Thm. \ref{lb222}, but also tells us what are the crucial properties that ensure the equivalence of compactness and sequential compactness for metric spaces. 
\end{srem}






















\subsection{Problems and supplementary material}


Let $X,Y$ be topological spaces.


\subsubsection{Compactness}

\begin{prob}\label{lb237}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a compact Hausdorff space $X$. Prove that $(x_\alpha)$ is convergent iff $(x_\alpha)$ has exactly one cluster point.
\end{prob}


\begin{prob}\label{lb346}
Let $(x_\alpha)_{\alpha\in I}$ be a net in the compact space $\ovl\Rbb$. Let $S$ be the (automatically nonempty) set of cluster points of $(x_\alpha)$ in $\ovl\Rbb$. Recall that $S$ is a closed subset by Rem. \ref{lb238}. For each $\alpha\in I$, define  \index{00@Limit inferior and superior}
\begin{gather}
A_\alpha=\inf\{x_\beta:\beta\geq \alpha \}\qquad  B_\alpha=\sup\{x_\beta:\beta\geq  \alpha \}
\end{gather}
Then $(A_\alpha)$ is increasing and $(B_\alpha)$ is decreasing. So they converge in $\ovl\Rbb$. Define \index{liminfsup@$\liminf,\limsup$}
\begin{subequations}
\begin{gather}
\liminf_{\alpha\in I}x_\alpha=\sup\{A_\alpha:\alpha\in I\}=\lim_{\alpha\in I} A_\alpha \\
\limsup_{\alpha\in I}x_\alpha=\inf\{B_\alpha:\alpha\in I\}=\lim_{\alpha\in I} B_\alpha
\end{gather}
\end{subequations}
Prove that
\begin{align}
\liminf_{\alpha\in I}x_\alpha=\inf S\qquad \limsup_{\alpha\in I}x_\alpha=\sup S
\end{align}
\end{prob}

\begin{proof}[Note]
You will get a quick proof by choosing the right one of the three equivalent definitions of cluster points in Pb. \ref{lb223}. A wrong choice will take you much more effort.
\end{proof}


\begin{co}\label{lb385}
Let $(x_\alpha)$ be a net in $\ovl\Rbb$. Then $(x_\alpha)$ converges in $\ovl\Rbb$ iff $\limsup_\alpha x_\alpha=\liminf_\alpha x_\alpha$. 
\end{co}


\begin{proof}
$\ovl\Rbb$ is compact. Therefore, $\limsup_\alpha x_\alpha=\liminf_\alpha x_\alpha$ iff $(x_\alpha)$ has only one cluster point (by Pb. \ref{lb346}), iff $(x_\alpha)$ converges (by Pb. \ref{lb237}).
\end{proof}




\begin{prob}
Given a general topological space $X$, which one implies the other between the conditions of ``sequential compactness" and ``countable compactness"? Prove your conclusion with details.
\end{prob}

\begin{proof}[Hint]
Check the proof of Thm. \ref{lb232}, and think about the question: If $(x_n)$ is a sequence in $X$, what is the inclusion relation between $\bigcap_n\ovl{\{x_k:k\geq n\}}$ and the set of limits of the convergent subsequences (rather than subnets) of $(x_n)$?
\end{proof}







\begin{prob}\label{lb246}
Prove Prop. \ref{lb233} using the original definition of compact spaces (i.e. every open cover has a finite subcover) instead of using nets.
\end{prob}

\begin{sprob}
Prove Prop. \ref{lb239} using the original definition of compact spaces instead of using nets.
\end{sprob}

\begin{prob}\label{lb240}
Assume that $Y$ is compact. Let $(x_\alpha,y_\alpha)_{\alpha\in I}$ be a net in $X\times Y$. Assume that $x\in X$ is a cluster point of $(x_\alpha)$. Prove that there exists $y\in Y$ such that $(x,y)$ is a cluster point of $(x_\alpha,y_\alpha)$.
\end{prob}

\begin{prob}\index{00@Tychonoff theorem, countable version} \label{lb241}
(\textbf{Tychonoff theorem, countable version}) Let $(X_n)_{n\in\in\Zbb_+}$ be a sequence of compact topological spaces. Prove that the product space $S=\prod_{n\in\Zbb_+}X_n$ (equipped with the product topology) is compact using the following hint.
\end{prob}

\begin{proof}[Hint]
Let $(f_\alpha)_{\alpha\in I}$ be a net in $S$ where $f_\alpha=(f_\alpha(1),f_\alpha(2),\dots)$. Use Pb. \ref{lb240} to construct inductively an element $x=(x(1),x(2),\dots)\in S$ such that for every $n\in\Zbb_+$, the element $(x(1),\dots,x(n))$ is a cluster point of $(f_\alpha(1),\dots,f_\alpha(n))_{\alpha\in I}$ in $X_1\times\cdots\times X_n$. Prove that $x$ is a cluster point of $(f_\alpha)_{\alpha\in I}$ in $S$.
\end{proof}


\begin{rem}
The same idea as above can be used to prove the general Tychonoff theorem (the version where the index set $\Zbb_+$ in Pb. \ref{lb241} is replaced by an arbitrary set) by replacing mathematical induction by Zorn's lemma. 
\end{rem}



\begin{sprob}
Let $X$ be the set of two elements: $X=\{0,1\}$, viewed as a metric subspace of $\Rbb$. Let $S=X^{[0,1]}$, the product space of uncountably many $X$, where the index set is the  interval $[0,1]$. $S$ is equipped with the product topology. According to Tychonoff theorem (to be proved in the future), $S$ is compact. Prove that $S$ is not sequentially compact.
\end{sprob}


\begin{proof}[Hint]
Use binary representations in $[0,1]$.
\end{proof}




\subsubsection{LCH spaces}


\begin{df}\label{lb458}
A subset $A$ of a Hausdorff space $X$ is called \textbf{precompact} \index{00@Precompact subset} if its closure $\ovl A$ is compact. This is equivalent to saying that $A$ is contained in a compact subset of $X$.   
\end{df}

\begin{proof}[Proof of equivalence]
If $\ovl A$ is compact, then $\ovl A$ is a compact subset of $X$ (cf. Cor. \ref{lb234}) containing $A$. Conversely, if $A\subset K$ where $K$ is a compact subset of $X$, then $K$ is closed by Cor. \ref{lb234}. Since $\ovl A$ is the smallest closed subset of $X$ containing $A$, we have $\ovl A\subset K$. By Exe. \ref{lb341}, $\ovl A$ is closed in $K$. By Cor. \ref{lb234}, $\ovl A$ is compact.
\end{proof}



It is clear that a subset of a precompact set is precompact.

\begin{prob}\label{lb287}
Suppose that $X$ is metric space. Let $A\subset X$. Prove that the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $A$ is precompact, i.e., $\ovl A$ is compact.
\item Every sequence in $A$ has a subsequence converging to some point of $X$.
\end{enumerate}
\end{prob}



\begin{df}
A Hausdorff space $X$ is called a \textbf{locally compact Hausdorff (LCH) space} \index{00@LCH=Locally compact Hausdorff} if every point has a precompact neighborhood.
\end{df}






\begin{pp}\label{lb245}
Let $X$ be an LCH space. Then the closed subsets and the open subsets of $X$ are LCH. 
\end{pp}

\begin{proof}
Let $E\subset X$ be closed. Let $x\in E$. Then there is $U\in\Nbh_X(x)$ with compact closure $\Cl_X(U)$. So $\Cl_X(U)\cap E$ is compact by Cor. \ref{lb234}. We have thus proved that $x$ is contained in a neighborhood $U\cap E\in \Nbh_E(x)$, and that this neighborhood is contained in a compact subset of $E$ (namely, $\Cl_X(U)\cap E$). This proves that $E$ is LCH.

Next, we let $W$ be an open subset of $X$. We want to prove that $W$ is LCH. Choose any $x\in W$. Since $X$ is LCH, there exists $\Omega\in\Nbh_X(x)$ whose closure $\ovl\Omega\equiv\Cl_X(\Omega)$ is compact. Thus, its closed subset $\ovl\Omega\setminus W$ is also compact (Cor. \ref{lb234}). Since $x\notin\ovl\Omega\setminus W$, by Prop. \ref{lb1000}, there exists $U\in\Nbh_X(x)$ such that $\Cl_X(U)\cap (\ovl\Omega\setminus W)=\emptyset$. So
\begin{align*}
\Cl_X(U\cap \Omega)\cap(\ovl\Omega\setminus W)=\emptyset
\end{align*}
Noting that $\Cl_X(U\cap\Omega)\subset\ovl\Omega$, we have $\Cl_X(U\cap\Omega)\setminus W=\emptyset$, i.e., $\Cl_X(U\cap\Omega)\subset W$.

Note that $\Cl_X(U\cap\Omega)$ is a closed subset of the compact set $\ovl\Omega$ and hence is compact (Cor. \ref{lb234}). We have thus proved that $x$ is contained in a neighborhood $U\cap\Omega\in\Nbh_W(x)$, and that this neighborhood is contained in a compact subset of $W$ (namely, $\Cl_X(U\cap\Omega)$). This proves that $W$ is LCH.
\end{proof}


\begin{comment}


Case 1: Assume that $X$ is compact Hausdorff.  Then $B=X\setminus W$ is compact by Cor. \ref{lb234}. Since $X$ is Hausdorff, for each $y\in B$ there exists $V_y\in\Nbh_X(y)$ such that $x\notin \ovl V_y$. (Recall Cor. \ref{lb243}.) Since $B$ is compact, there are $y_1,\dots,y_n\in B$ such that $B\subset V$ where $V=V_{y_1}\cup\cdots\cup V_{y_n}$. By \eqref{eq73}, $\ovl V=\ovl V_{y_1}\cup\cdots\cup \ovl V_{y_n}$. So $x\notin\ovl V$. Now $X\setminus V$ is a closed subset of $X$, and hence 

Let $U=X\setminus \ovl V$. Then $x\in U$. Since $U\subset X\setminus V$ and $X\setminus V$ is closed, $\ovl U\subset X\setminus V$, and hence $\ovl U\subset W$. Since $X$ is compact, $U$ is precompact.


Case 2: $X$ is LCH. Choose a precompact $\Omega\in\Nbh_X(x)$. By case 1 (applied to $\ovl\Omega$), and by the definition of subspace topology, there exists $V\in\Nbh_X(x)$ such that $x\in V\cap \ovl\Omega\subset\Cl_{\ovl\Omega}(V\cap \ovl\Omega)\subset W\cap\ovl\Omega$. By Rem. \ref{lb182}, we have $\Cl_{\ovl\Omega}(V\cap \ovl\Omega)= \ovl{V\cap\ovl\Omega}\cap\ovl\Omega$, which contains $\ovl{V\cap\Omega}$ since both $\ovl{V\cap\ovl\Omega}$ and $\ovl\Omega$ do. So $x\in U\subset\ovl U\subset W$ where $U=V\cap\Omega$. Since $\Omega$ is precompact, $U$ is precompact.
\end{comment}



\begin{df}\label{lb334}
Let $X$ be LCH. Let $Y$ be a metric space. Let $(f_\alpha)_{\alpha\in I}$ be a net in $Y^X$. Let $f\in Y^X$.  We say that $(f_\alpha)$  \textbf{converges locally uniformly} \index{00@Locally uniform convergence} to $f$ if the following equivalent conditions are satisfied:
\begin{enumerate}[label=(\arabic*)]
\item For each $x\in X$, there exists $U\in\Nbh_X(x)$ such that $(f_\alpha|_U)$ converges uniformly to $f|_U$.
\item For each precompact open subset $W\subset X$, the net $(f_\alpha|_W)$ converges uniformly to $f|_W$.
\end{enumerate}
\end{df}

\begin{prob}
Prove that in Def. \ref{lb334}, conditions (1) and (2) are equivalent. 
\end{prob}


\begin{exe}
Let $X$ be LCH. Let $\mc V$ be a normed vector space. Let $(f_\alpha)_{\alpha\in I}$ be a net in $C(X,\mc V)$ converging pointwise to $f:X\rightarrow 
\mc V$. Assume that the net $(f_\alpha)$ converges locally uniformly on $X$ (clearly to $f$). Prove that $f$ is continuous. 
\end{exe}






An example of locally uniform convergence was given in Thm. \ref{lb112}.



\subsubsection{Countability in topological spaces}



\begin{prob}
Let $(X,\mc T)$ be a second countable LCH space. Prove that the topology $\mc T$ has a countable basis $\mc B$ whose members are all precompact.
\end{prob}

\begin{proof}[Hint]
Use Lindel\"of property for open subsets of $X$.
\end{proof}

\begin{sprob}\label{lb255}
Let $X$ be a Lindel\"of metric space. Prove that $X$ is separable. 
\end{sprob}


\begin{prob}\label{lb305}
Let $(X_n)_{n\in\Zbb_+}$ be a sequence of topological spaces. Equip $S=\prod_{n\in\Zbb_+}X_n$ with the product topology. 
\begin{enumerate}
\item Prove that $S$ is second countable if each $X_n$ is second countable.
\item Prove that $S$ is separable if each $X_n$ is separable
\end{enumerate}
\end{prob}


Recall from Pb. \ref{lb221} the basic facts about connected components.

\begin{prob}\label{lb679}
Let $X$ be a locally connected topological space. Prove that if $X$ is second countable, then $X$ has countably many connected components. Use this result to show that every open subset of $\Rbb$ is a countable disjoint union of open intervals.
\end{prob}



\subsubsection{The problem of embedding}


\begin{df}\label{lb327}
Let $\scr F$ be a set of functions $X\rightarrow Y$. We say that $\scr F$ \textbf{separates points} \index{00@Separates points} of $X$, if for every distinct $x_1,x_2\in X$ there exists $f\in\scr F$ such that $f(x_1)\neq f(x_2)$. 
\end{df}

\begin{prob}\label{lb259}
Let $X$ be a nonempty compact metric space.
\begin{enumerate}
\item Prove that there is a sequence of continuous functions $(f_n)_{n\in\Zbb_+}$ from $X$ to $[0,1]$ separating points of $X$. 
\item Prove that 
\begin{gather*}
\Phi:X\rightarrow [0,1]^{\Zbb_+} \qquad x\mapsto (f_1(x),f_2(x),\dots)
\end{gather*}
gives a homeomorphism $\Phi:X\rightarrow\Phi(X)$ where $\Phi(X)$ is a closed subspace of $[0,1]^{\Zbb_+}$ (equipped with the subspace topology).
\end{enumerate}
\end{prob}

The topological space $[0,1]^{\Zbb_+}$, equipped with the product topology, is called the \textbf{Hilbert cube}. \index{00@Hilbert cube}




\begin{proof}[Hint]
Part 1: Choose an infinite countable basis $\mc B=(U_1,U_2,\dots)$ for the topology of $X$ where each $U_n$ is nonempty. (Why can you do so?) Use Urysohn functions (Rem. \ref{lb257}) to construct $f_n:X\rightarrow [0,1]$ such that $f^{-1}(0)=X\setminus U_n$.

Part 2: Notice Pb. \ref{lb258}.
\end{proof}


\begin{thm}\label{lb261}
Let $X$ be a topological space. The following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $X$ is a compact metrizable space.
\item $X$ is homeomorphic to a closed subset of the Hilbert cube $[0,1]^{\Zbb_+}$.
\end{enumerate}
\end{thm}

\begin{proof}
(1)$\Rightarrow$(2): By Pb. \ref{lb259}. (2)$\Rightarrow$(1): By Cor. \ref{lb260}, $[0,1]^{\Zbb_+}$ is metrizable. By countable Tychonoff theorem (Thm. \ref{lb89} or Pb. \ref{lb241}), $[0,1]^{\Zbb_+}$ is compact. So its closed subsets are compact by Cor. \ref{lb234}.
\end{proof}



\begin{sexe}
Let $N\in\Zbb_+$. Prove that the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $X$ is a compact Hausdorff space. Moreover, there exist $f_1,\dots,f_N\in C(X,\Rbb)$ separating points of $X$.
\item $X$ is homeomorphic to a bounded closed subset of $\Rbb^N$.
\end{enumerate}
\end{sexe}


\newpage

\section{The injection \pmb{$\Psi:C(X,C(Y,\mc V))\rightarrow C(X\times Y,\mc V)$}}\label{lb352}





In this chapter, unless otherwise stated,  $X,Y$ are topological spaces, all normed vector spaces are over $\Fbb\in\{\Rbb,\Cbb\}$, and $\mc V$ is a normed vector space.

\begin{rem}
Let $\Phi:\mc V\rightarrow\mc W$ be a linear map of normed vector spaces. Recall that $\Phi$ is an isometry (in the category of metric spaces) iff $\Vert \Phi(u)-\Phi(v)\Vert=\Vert u-v\Vert$ for all $u,v\in\mc V$. By linearity, we have
\begin{align}
\Phi\text{ is an isometry}\qquad \Longleftrightarrow\qquad \Vert\Phi(v)\Vert=\Vert v\Vert~~\text{for all } v\in\mc V
\end{align}
\end{rem}


\begin{df}\label{lb302}
A linear map $\Phi:\mc V\rightarrow\mc W$ of normed vector spaces over $\Fbb$ is a called an \textbf{isomorphism of normed vector spaces} \index{00@Isomorphism of normed vector spaces/Banach spaces} if $\Phi$ is an isometric isomorphism. If $\Phi$ is an isomorphism, and if one of $\mc V,\mc W$ is complete, then the other one is also complete. In this case, we call $\Phi$ an \textbf{isomorphism of Banach spaces}.
\end{df}


Recall that if $X$ is compact, then the norm on $C(X,\mc V)$ is assumed to be the $l^\infty$-norm (cf. Conv. \ref{lb88}).


\subsection{$\Psi$ is bijective when $Y$ is compact}



\begin{thm}\label{lb274}
Equip $C(Y,\mc V)$ with the uniform convergence topology (cf. Exp. \ref{lb272}). Then there is a well-defined injective linear map
\begin{gather}\label{eq77}
\begin{gathered}
\Psi:C(X,C(Y,\mc V))\rightarrow C(X\times Y,\mc V)\\[0.5ex]
\Psi(F)(x,y)=F(x)(y)
\end{gathered}
\end{gather}
(for each $F\in C(X,C(Y,\mc V))$ ). Moreover, the following are true:
\begin{enumerate}[label=(\alph*)]
\item If $Y$ is compact, then $\Psi$ is a linear isomorphism of vector spaces.
\item If $X,Y$ are compact, then $\Psi$ is an isomorphism of normed vector spaces.
\end{enumerate}
\end{thm}



\begin{proof}
Step 1. Write $\mc W=C(Y,\mc V)$ for simplicity. To prove that \eqref{eq77} is a well-defined map, we need to prove that for each $F\in C(X,\mc W)$, the map $f=\Psi(F):X\times Y\rightarrow \mc V$ sending $(x,y)$ to $f(x,y)=F(x)(y)$ is continuous.

The continuity of $F:X\rightarrow\mc W$ means that if $(x_\alpha)_{\alpha\in I}$ is a net in $X$ converging to $x$, then $F(x_\alpha)$ converges to $F(x)$, i.e., 
\begin{subequations}
\begin{align}
\lim_{\alpha\in I}A_\alpha=0
\end{align}
where each $A_\alpha\in\ovl\Rbb_{\geq0}$ is 
\begin{align}
A_\alpha= \sup_{y\in Y}\Vert f(x_\alpha,y)-f(x,y)\Vert
\end{align}
\end{subequations}
Now, suppose that $(x_\alpha,y_\alpha)_{\alpha\in I}$ is a net in $X\times Y$ converging to $(x,y)$. Then
\begin{align*}
&\Vert f(x_\alpha,y_\alpha)-f(x,y)\Vert\leq \Vert f(x_\alpha,y_\alpha)-f(x,y_\alpha)\Vert +\Vert f(x,y_\alpha)-f(x,y)\Vert\\
\leq& A_\alpha+\Vert f(x,y_\alpha)-f(x,y)\Vert
\end{align*}
Since $F(x):y\in Y\mapsto f(x,y)\in\mc V$ is continuous, we have $\lim_\alpha \Vert f(x,y_\alpha)-f(x,y)\Vert=0$. Therefore, by Squeeze theorem, we have
\begin{align}
\lim_{\alpha\in I}\Vert f(x_\alpha,y_\alpha)-f(x,y)\Vert=0
\end{align}
Thus, $f$ is continuous at every $(x,y)$.\\[-1ex]

Step 2. Clearly $\Psi$ is linear and injective. Assume that $Y$ is compact. Then the surjectivity of $\Psi$ follows from Exp. \ref{lb225}. This proves (a). Assume that $X$ is also compact. Choose any $F\in C(X,\mc W)$ and write $f=\Psi(F)$.  Then
\begin{align*}
\sup_{x\in X}\sup_{y\in Y}~\Vert f(x,y)\Vert=\sup_{x\in X,y\in Y}\Vert f(x,y)\Vert
\end{align*}
by the easy Lem. \ref{lb273}. This proves that $\Phi$ is an isometry, and hence proves (b).
\end{proof}

\begin{lm}\label{lb273}
Let $g:A\times B\rightarrow\ovl\Rbb$ be a function where $A,B$ are sets. Then
\begin{align*}
\sup_{a\in A}\sup_{b\in B}g(a,b)=\sup_{(a,b)\in A\times B}g(a,b)
\end{align*}
\end{lm}

\begin{proof}
Write $\lambda_a=\sup_{b\in B}g(a,b)$ and $\rho=\sup_{(a,b)\in A\times B}g(a,b)$. Then, clearly $\lambda_a\leq\rho$ for each $a$. So $\sup_a\lambda_a\leq\rho$. For each $a,b$ we have $g(a,b)\leq \lambda_a$, and hence $g(a,b)\leq \sup_a\lambda_a$. Taking $\sup$ over $a,b$ yields $\rho\leq\sup_a\lambda_a$.
\end{proof}





\begin{rem}
Thanks to Thm. \ref{lb274}, we can reduce many problems about multi-variable functions to problems about single-variable functions. Here is an example we will study in the future: If $I=[a,b],J=[c,d]$ are compact intervals and $F\in C(I\times J,\Rbb)$, then with the help of Thm. \ref{lb274}, the Fubini's theorem
\begin{align*}
\int_a^b \int_c^d F(x,y)dxdy=\int_c^d\int_a^b F(x,y)dxdy
\end{align*}
for Riemann integrals follows directly from the easy general fact
\begin{align*}
\int_a^b\Lambda\circ f(x)dx=\Lambda\Big(\int_a^b f(x)dx \Big)
\end{align*}
where $f:[a,b]\rightarrow\mc W$ is a continuous map to a real Banach space $\mc W$, and $\Lambda:\mc W\rightarrow\Rbb$ is a continuous linear map.

Thm. \ref{lb274} can be used the other way round: We will prove in the future that every Banach space $\mc V$ is isomorphic to a closed linear subspace of $C(Y,\Fbb)$ for some compact Hausdorff space $Y$. Thus, a problem about continuous maps $X\rightarrow \mc V$ (where $\mc V$ is an abstract Banach space) can be reduced to a problem about continuous scalar-valued functions $X\times Y\rightarrow\Fbb$. \hfill\qedsymbol
\end{rem}


In the following sections, we give a surprising application of Thm. \ref{lb274}: We show that uniform-convergence and equicontinuity, two closely related but different notions, can be understood in the same context.

\subsection{Equicontinuity}

Let $I$ be a set not necessarily preordered or directed.

\begin{df}\label{lb514}
Assume that $Y$ is a metric space. A family of functions $(f_\alpha)_{\alpha\in I}$ from $X$ to $Y$ is called \textbf{equicontinuous at} $x\in X$ \index{00@Equicontinuous at a point} if the following equivalent conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item The function
\begin{gather}
X\rightarrow Y^{I}\qquad x\mapsto (f_\alpha(x))_{\alpha\in I}
\end{gather}
is continuous at $x$, where $Y^{I}$ is equipped with the uniform convergence topology (Exp. \ref{lb272}).
\item For every $\eps>0$, there exists $U\in\Nbh_X(x)$ such that for every $p\in U$ we have
\begin{align*}
\sup_{\alpha\in I}d_Y(f_\alpha(p),f_\alpha(x))<\eps
\end{align*}
\end{enumerate}
Clearly, if $(f_\alpha)_{\alpha\in I}$ is equicontinuous at $x$, then $f_\alpha:X\rightarrow Y$ is continuous at $x$ for every $\alpha\in I$. We say that $(f_\alpha)_{\alpha\in I}$ is \textbf{(pointwise) equicontinuous} \index{00@Equicontinuous, pointwise} if it is equicontinuous at every point of $X$.
\end{df}



\begin{proof}[Proof of equivalence]
This is immediate if we choose the uniform convergence metric on $Y^I$ to be
\begin{align*}
d((y_\alpha),(y_\alpha'))=\min\Big\{\sup_{\alpha\in I}d_Y(y_\alpha,y'_\alpha),1\Big\}
\end{align*}
and use (the base version of) Def. \ref{lb188}-(2).
\end{proof}

\begin{rem}
Warning: The above definition of equicontinuity is weaker than the one in Rudin's book \cite[Ch. 7]{Rud-P}, which will be called \textbf{uniform equicontinuity} in this course (cf. Def. \ref{lb316}).
\end{rem}



\begin{eg}\label{lb309}
Assume that $X$ and $Y$ are metric spaces. Fix $C\geq 0$. Then
\begin{align*}
\{f\in Y^X:f\text{ has Lipschitz constant }C\}
\end{align*}
is an equicontinuous family of functions $X\rightarrow Y$.

In the future, we will see that if $f:[a,b]\rightarrow\Rbb$ (where $[a,b]\subset\Rbb$) is differentiable and satisfies $|f'(x)|\leq C$ for all $x\in[a,b]$, then $f$ has Lipschitz constant $C$. (For example, if we assume moreover that $f'$ is continuous, then for each $a\leq x<y\leq b$ we have $|f(y)-f(x)|=|\int_x^y f'|\leq \int_x^y|f'|\leq C(y-x)$.) Therefore, all such functions form an equicontinuous family of functions.  \hfill\qedsymbol
\end{eg}


Equicontinuity is important for several reasons. First, equicontinuity is closely related to compactness, both under the uniform convergence topology and under the pointwise convergence topology. This is hinted at in Rem. \ref{lb304}, and will be explored in more detail in a future chapter. Second, equicontinuity and uniform convergence are symmetric notions:

\begin{rem}
Note that if $x\in \ovl{X\setminus x}$, a map $\varphi:X\rightarrow Y$ is continuous at $x$ iff $\lim_{p\rightarrow x}f(p)=f(x)$, where $\lim_{p\rightarrow x}f(p)$ is the limit of a net (cf. Rem. \ref{lb275}). Now, assume that $Y$ is a metric space. Then we see that a family $(f_\alpha)_{\alpha\in I}$ in $Y^X$ satisfies that
\begin{align}
(f_\alpha)_{\alpha\in I}\text{ is equicontinuous at }x\qquad\Longleftrightarrow\qquad\lim_{p\rightarrow x}\sup_{\alpha\in I}d(f_\alpha(p),f_\alpha(x))=0
\end{align} 
If we compare this with
\begin{align}
f_\alpha\rightrightarrows f \qquad\Longleftrightarrow\qquad \lim_{\alpha\in I}\sup_{x\in X}d(f_\alpha(x),f(x))=0
\end{align}
(if $I$ is a directed set and $f\in Y^X$), we see that equicontinuity and uniform convergence are ``symmetric about the diagonal line of the Cartesian product $I\times X$": Equicontinuity is a uniform convergence over the index set $I$, and the uniform convergence $f_\alpha\rightrightarrows f$ is uniform over $X$.
\end{rem}



The symmetry of equicontinuity and uniform convergence will be further studied in Sec. \ref{lb306}. (Indeed, we will see that it is better to view ``uniform convergence + continuity" and ``pointwise convergence + equicontinuity" as symmetric conditions.) As an application, we will see that equicontinuity is equivalent to uniform convergence for any sequence $(f_n)$ of pointwise convergent continuous functions on a compact topological space. (See Cor. \ref{lb284}.) Thus, in this case, one can prove the uniform convergence of $(f_n)$ by proving for instance that it converges pointwise and has a uniform Lipschitz constant.







\begin{comment}

By \eqref{eq78}, the uniform topology of $Y^I$ has a base generated by $\{V_{(y_\alpha)}^\eps:(y_\alpha)\in Y^I,\eps>0\}$ where
\begin{align*}
V_{(y_\alpha)}^\eps=\Big\{(y'_\alpha)\in Y^I:\sup_{\alpha\in I}d(y'_\alpha,y_\alpha)<\eps\Big\}
\end{align*}
So the equivalence of (1) and (2) follows immediately from the base version of Def. \ref{lb188}-(2).
\end{comment}


\subsection{Uniform convergence and equicontinuity: two faces of $\Psi$}\label{lb306}



\subsubsection{Main results}\label{lb282}

In this subsection, we fix a directed set $I$, and let
\begin{align*}
I^*=I\cup\{\infty_I\}
\end{align*}
where $\infty_I$ is a new symbol not in $I$. Write $\infty_I$ as $\infty$ for simplicity. Equip $I^*$ with the standard topology as in Def. \ref{lb175}. Recall that this topology has basis
\begin{align*}
\mc B=\big\{\{\alpha\}:\alpha\in I \big\}\cup \big\{I^*_{\geq\alpha}:\alpha\in I \big\}
\end{align*}
Clearly $I\times X$ is dense in $I^*\times X$. Equip $C(X,\mc V)$ and $C(I^*,\mc V)$ with the uniform convergence topologies.

Throughout this subsection, we fix a net $(f_\alpha)_{\alpha\in I}$ in $\mc V^X$ and an element $f_\infty\in\mc V^X$. Define
\begin{align}
F:I^*\times X\rightarrow\mc V\qquad F(\mu,x)=f_\mu(x)  \label{eq88}
\end{align} 
The meaning of the title of this section is illustrated by the following theorem.





\begin{thm}\label{lb280}
We have (a)$\Leftrightarrow$(b) and (1)$\Leftrightarrow$(2)  where:
\begin{itemize}
\item[(a)] $(f_\alpha)_{\alpha\in I}$ converges uniformly to $f_\infty$, and $f_\alpha:X\rightarrow\mc V$ is continuous for each $\alpha\in I$.
\item[(b)] $F$ gives rise to a continuous map $I^*\rightarrow C(X,\mc V)$
\item[(1)] $(f_\alpha)_{\alpha\in I}$ is equicontinuous and converges pointwise to $f_\infty$.
\item[(2)] $F$ gives rise to a continuous map $X\rightarrow C(I^*,\mc V)$.
\end{itemize}
\end{thm}



%% Record #11 2023/10/25 three lectures  27



\begin{proof}
Assume (a). Then we have $f_\infty\in C(X,\mc V)$ due to Thm. \ref{lb279}. So $F$ gives rise to a map $I^*\rightarrow C(X,\mc V)$. Since $f_\alpha\rightrightarrows f_\infty$, we see that $F$ is continuous by Pb. \ref{lb278}-2. This proves (b).

Assume (b), then the fact that the map $I^*\rightarrow C(X,\mc V)$ has range in $C(X,\mc V)$ means precisely that each $f_\alpha$ and $f_\infty$ are continuous. The continuity of the map $I^*\rightarrow C(X,\mc V)$ at $\infty$ means $f_\alpha\rightrightarrows f_\infty$. This proves (a).


(1)$\Rightarrow$(2): Assume (1). The equicontinuity of $(f_\alpha)$ is equivalent to that
\begin{align}
x\in X\mapsto (f_\alpha(x))_{\alpha\in I}\in \mc V^I  \label{eq84}
\end{align}
is continuous where $\mc V^I$ is equipped with the uniform convergence topology. Equivalently, for each $x\in X$ and $\eps>0$ there is $U\in\Nbh_X(x)$ such that for all $p\in U$ and all $\alpha\in I$ we have
\begin{align}
\Vert f_\alpha(p)-f_\alpha(x)\Vert\leq\eps \label{eq83}
\end{align} 
Since $(f_\alpha)_{\alpha\in I}$ converges pointwise to $f_\infty$, by applying $\lim_{\alpha\in I}$ to \eqref{eq83}, we see that $\Vert f_\mu(p)-f_\mu(x)\Vert\leq\eps$ for all $p\in U$ and $\mu\in I^*$. So
\begin{align}\label{eq86}
x\in X\mapsto (f_\mu(x))_{\mu\in I^*}\in \mc V^{I^*}
\end{align}
is continuous, where $\mc V^{I^*}$ is given the uniform convergence metric. By Pb. \ref{lb278}-2, the pointwise convergence of $(f_\alpha)_{\alpha\in I}$ to $f_\infty$ is equivalent to the continuity of
\begin{align}\label{eq85}
\mu\in I^*\rightarrow f_\mu(x)\in\mc V
\end{align}
for each $x\in X$. So the map \eqref{eq86} has range inside $C(I^*,\mc V)$.

(2)$\Rightarrow$(1): Assume (2). The continuity of $X\rightarrow C(I^*,\mc V)$ implies that of \eqref{eq84}. So $(f_\alpha)_{\alpha\in I}$ is equicontinuous. Its pointwise convergence to $f$ is due to the continuity of \eqref{eq85} for each $x$, which is clearly true by (2).
\end{proof}


\begin{rem}\label{lb340}
Conditions (a) and (1) in Thm. \ref{lb280} are symmetric. Condition (a) says roughly that $F$ converges uniformly under the limit over $I$, and converges pointwise under the limit over $X$. Condition (1) says roughly that $F$ converges uniformly under the limit over $X$, and pointwise under the limit over $I$. The next theorem clarifies the relationship between these two symmetric conditions. We will see a similar condition in Thm. \ref{lb289}.
\end{rem}



\begin{thm}\label{lb277}
Consider the following statements:
\begin{enumerate}
\item[(1)] The function $F:I^*\times X\rightarrow\mc V$ is continuous.
\item[(2)] $(f_\alpha)_{\alpha\in I}$ converges uniformly to $f_\infty$, and $f_\alpha:X\rightarrow\mc V$ is continuous for each $\alpha\in I$.
\item[(3)] $(f_\alpha)_{\alpha\in I}$ is equicontinuous and converges pointwise to $f_\infty$.
\end{enumerate}
Then we have
\begin{gather*}
(2)\Longrightarrow(1)\Longleftarrow (3)\\
(2)\Longleftrightarrow(1)\qquad \text{if $X$ is compact}\\
(1)\Longleftrightarrow (3) \qquad \text{if }I=\Nbb
\end{gather*}
where $\Nbb$ is equipped with the usual order.
\end{thm}


A more explicit description of condition (1) will be given in Prop. \ref{lb281}.



\begin{proof}
This follows immediately from Thm. \ref{lb280}, Thm. \ref{lb274}, and the fact that $I^*$ is compact if $I=\Nbb$. 
\end{proof}

\begin{rem}
From the above proof, we see that the equivalence (1)$\Leftrightarrow$(3) holds in the more general case that $I^*$ is compact. See Pb. \ref{lb283} for an equivalent description of the compactness of $I^*$.
\end{rem}


\begin{eg}
Define $f_n:(0,1)\rightarrow\Rbb$ by $f_n(x)=x^n$. Then $(f_n)_{n\in\Zbb_+}$ is equicontinuous (by Exp. \ref{lb309}) and pointwise convergent, but not uniformly convergent. Accordingly, $(0,1)$ is not compact. 
\end{eg}

\begin{eg}
Let $I=\Zbb_+\times\Zbb_+$, equipped with the product preorder: $(k_1,n_1)\leq (k_2,n_2)$ means $k_1\leq k_2$ and $n_1\leq n_2$. Consider $(f_{k,n})_{(k,n)\in I}$, where $f_{k,n}:[0,1]\rightarrow\Rbb$ is defined by $\dps f_{k,n}(x)=\frac{x^n}{k}$. Then $\lim_{(k,n)\in I}f_{k,n}$ converges uniformly to $0$ by squeeze theorem and $0\leq f_{k,n}\leq k^{-1}$. Thus, condition (1) of Thm. \ref{lb277} is satisfied. However, this net of functions is not equicontinuous at $x=1$. Moreover, for every $(k_0,n_0)\in I$, the net of functions $(f_{k,n})_{(k,n)\in I_{\geq(k_0,n_0)}}$ is not equicontinuous at $1$.
\end{eg}

\begin{proof}
Choose any $x\in[0,1)$. Then (recalling Lem. \ref{lb273})
\begin{align*}
\sup_{k\geq k_0}\sup_{n\geq n_0}|f_{k,n}(1)-f_{k,n}(x)|=\sup_{k\geq k_0}\sup_{n\geq n_0}\frac{1-x^n}{k}=\sup_{k\geq k_0}\frac 1k=\frac 1{k_0}
\end{align*}
\end{proof}




In the following, let me give a more explicit description of condition (1) of Thm. \ref{lb277} in terms of $(f_\alpha)$ and $f_\infty$. More precisely, we show that (1) can be interpreted as the convergence of a double limit.


\begin{pp}\label{lb281}
Assume that $f_\alpha:X\rightarrow\mc V$ is continuous for each $\alpha\in I$. Then part (1) of Thm. \ref{lb277} is equivalent to both (1') and (1''), where
\begin{itemize}
\item[(1')] For each $x\in X$, we have 
\begin{align}\label{eq87}
\lim_{
\begin{subarray}{c}
(\alpha,p)\in I\times X\\
(\alpha,p)\rightarrow (\infty,x)
\end{subarray}
}
f_\alpha(p)=f_\infty(x)
\end{align}
\item[(1'')] For each $x\in X$ and $\eps>0$, there exist $\beta\in I$ and $U\in\Nbh_X(x)$ such that 
\begin{align}\label{eq79}
\Vert f_\alpha(p)-f_\infty(x)\Vert<\eps\qquad (\text{for all } \alpha\in I_{\geq\beta}\text{ and } p\in U)
\end{align}
\end{itemize}
\end{pp}

Note that one can make sense of the LHS of \eqref{eq87} because $I\times X$ is clearly dense in $I^*\times X$. %Also, if $(f_\alpha)$ and $f_\infty$ satisfy (1) or (2), we say that $(f_\alpha)$ \textbf{converges quasi-uniformly} to $f_\infty$. \index{00@Quasi-uniform convergence} If $(f_\alpha)$ and $f_\infty$ satisfy (1) or (2) for a given $x$ (instead of for all $x$), we say that $(f_\alpha)$ \textbf{converges quasi-uniformly} to $f_\infty$ at $x$.

\begin{proof}
The equivalence of (1') and (1'') is clear by Def. \ref{lb197}. The continuity of $f_\alpha$ for all $\alpha\in I$ means precisely that $F|_{I\times X}$ is continuous. Therefore, (1') is equivalent to part (1) of Thm. \ref{lb277}, thanks to the following Thm. \ref{lb276}.
\end{proof}


See Exp. \ref{lb401} for an elementary example satisfying (1') of Prop. \ref{lb281} (or equivalently, (1) of Thm. \ref{lb277}), but not satisfying (2) or (3) of Thm. \ref{lb277}. (See also Pb. \ref{lb285} and Thm. \ref{lb286} for related facts.)






\subsubsection{Proving continuity using limits}



\begin{thm}\label{lb276}
Let $\varphi:X\rightarrow Y$ be a map of topological spaces where $Y$ is metrizable. Let $A$ be a dense subset of $X$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $\varphi:X\rightarrow Y$ is continuous.
\item The restriction $\varphi|_A:A\rightarrow Y$ is continuous. Moreover, for each $x\in X\setminus A$, the restriction $\varphi|_{A\cup\{x\}}$ is continuous at $x$, namely (cf. Def. \ref{lb197}) ,
\begin{align}
\lim_{
\begin{subarray}{c}
p\in A\\
p\rightarrow x
\end{subarray}
}\varphi(p)=\varphi(x)
\end{align}
\end{enumerate}
\end{thm}




\begin{proof}
Clearly (2) is equivalent to
\begin{align}\label{eq81}
\varphi|_{A\cup\{x\}}\text{ is continuous at $x$ for all $x\in X$}
\end{align}
So (1)$\Rightarrow$(2). Assume (2) and that $Y$ is a metric space. Choose any $x\in X$. We want to show that $\varphi:X\rightarrow Y$ is continuous at $x$. Choose any $\eps>0$. Recall that an open subset of $A$ is precisely the intersection of $A$ and an open subset of $X$. Thus, by \eqref{eq81}, there is $U\in\Nbh_X(x)$ such that for all $p\in A\cap U$ we have
\begin{align}
d(\varphi(p),\varphi(x))\leq \eps/2\label{eq82}
\end{align}


It remains to prove \eqref{eq82} for all $p\in U$. Choose any $p\in U$. By Lem. \ref{lb342}, $A\cap U$ is dense in $U$.  Thus, there is a net $(p_\alpha)$ in $A\cap U$ converging to $p$. In particular, for each $\alpha$ we have
\begin{align*}
d(\varphi(p_\alpha),\varphi(x))\leq \eps/2
\end{align*}
Since $\varphi|_{A\cup\{p\}}$ is continuous (by \eqref{eq81}), we have $\lim_\alpha\varphi(p_\alpha)=\varphi(p)$. Thus, applying $\lim_\alpha$ to the above inequality proves \eqref{eq82} for $p\in U$.
\end{proof}


\begin{lm}\label{lb342}
Suppose that $A$ is a dense subset of $X$. Let $U$ be an open subset of $X$. Then $A\cap U$ is dense in $U$.
\end{lm}

This lemma is clearly false if $U$ is not assumed to be open: simply take $U=X\setminus A$.

\begin{proof}[First proof]
Choose any $x\in U$. We want to find a net in $A\cap U$ converging to $x$. Since $A$ is dense in $X$, there is a net $(x_\alpha)_{\alpha\in J}$ in $X$ converging to $x$. Since $U$ is a neighborhood of $x$, $(x_\alpha)$ is eventually in $U$, say $x_\alpha\in U$ whenever $\alpha\geq\beta$. Then $(x_\alpha)_{\alpha\in J_{\geq \beta}}$ is a net in $A\cap U$ converging to $x$.
\end{proof}

\begin{proof}[Second proof]
We want to show that every nonempty open subset of $U$ intersects $A\cap U$. But an open subset of $U$ is precisely an open subset of $X$ contained inside $U$ (Exe. \ref{lb341}). So this set (when nonempty) must intersect $A$ because $A$ is dense in $X$.
\end{proof}



\begin{sexe}
In Thm. \ref{lb276}, weaken the metrizability of $Y$ to the condition that $Y$ is regular. (See the definition below.) Prove the conclusion of Thm. \ref{lb276}.
\end{sexe}

\begin{sdf}\label{lb504}
A topological space $Y$ is called \textbf{regular} \index{00@Regular topological space} if for every $y\in Y$ and every $U\in\Nbh_Y(y)$ there exists $V\in\Nbh_Y(y)$ such that $\Cl_Y(V)\subset U$.
\end{sdf}









\subsubsection{Immediate consequences of Thm. \ref{lb277}}

The following result is parallel to Thm. \ref{lb279} for uniformly convergent nets of continuous functions.

\begin{co}\label{lb303}
Let $(f_\alpha)_{\alpha\in I}$ be an equicontinuous net of functions $X\rightarrow\mc V$. Assume that $(f_\alpha)$ converges pointwise to $f:X\rightarrow\mc V$. Then $f$ is continuous.
\end{co}

\begin{proof}
Write $f_\infty=f$ and define $F$ by \eqref{eq88}. Then $F$ is continuous by (3)$\Rightarrow$(1) of Thm. \ref{lb277}. So $f=f_\infty$ is continuous, since $f$ is the composition of $F$ with the inclusion map $x\in X\mapsto (\infty,x)\in I^*\times X$. (You can also prove it directly.)
\end{proof}






\begin{rem}\label{lb304}
In the future, we will study the general Tychonoff theorem, which says for example that if $(f_\alpha)_{\alpha\in I}$ is a net of functions $X\rightarrow\Rbb^N$ which is pointwise bounded, i.e. $\sup_{\alpha\in I}\Vert f(x)\Vert<+\infty$ for all $x\in X$, then $(f_\alpha)$ has a subnet converging poinwise. However, if we assume moreover that each $f_\alpha$ is continuous, we cannot conclude in general that $(f_\alpha)$ has a subnet converging pointwise to a \textit{continuous} function. But we can make such a conclusion when $(f_\alpha)$ is equicontinuous, thanks to Cor. \ref{lb303}. Therefore, Cor. \ref{lb303} tells us that equicontinuity is useful for studying the problems of compactness of families of continuous functions (under the pointwise convergence topology). Cf. Thm. \ref{lb509}.
\end{rem}


In fact, we have a slightly stronger version of Cor. \ref{lb303}:

\begin{co}\label{lb310}
Let $(f_\alpha)_{\alpha\in I}$ be a net of functions $X\rightarrow\mc V$ equicontinuous at $x$. Assume that $(f_\alpha)$ converges pointwise to $f:X\rightarrow\mc V$. Then $f$ is continuous at $x$.
\end{co}

\begin{proof}
Define $X_x$ to be the same as $X$ as a set, but has a different topology: the one generated by the basis
\begin{align*}
\mc B_x=\Nbh_X(x)\cup\big\{\{p\}:p\neq x\big\}
\end{align*}
(cf. Exe. \ref{lb308}). Define $g_\alpha:X_x\rightarrow\mc V$ and $g:X_x\rightarrow\mc V$ to be the same as $f_\alpha$ and $f$. Then $(g_\alpha)$ is a net of equicontinuous functions converging pointwise to $g$. Therefore, by Cor. \ref{lb303}, $g$ is continuous. So $f$ is continuous at $x$. 
\end{proof}



\begin{rem}
By a similar argument, we can generalize Thm. \ref{lb279} to the following form: Let $(f_\alpha)$ be a net of functions $X\rightarrow \mc V$ converging uniformly to $f:X\rightarrow\mc V$. Suppose that each $f_\alpha$ is continuous at $x$. Then $f$ is continuous at $x$.
\end{rem}






\begin{eg}\label{lb311}
In this example, we pretend to know derivatives. Let $(f_n)$ be a sequence of functions $\Rbb_{\geq0}\rightarrow\Rbb$ defined by $f_n(x)=x^{1/n}$. (We understand $0^{\frac 1n}=0$.) Find all $x\in\Rbb_{\geq 0}$ at which $(f_n)$ is equicontinuous.
\end{eg}

\begin{proof}
We prove that $\Rbb_{>0}$ is the set of all points at which $(f_n)$ is equicontinuous. First, assume $x>0$. Choose $0<a<1<b$ such that $a<x<b$. Then, on $[a,b]$, $f_n'(x)=\frac 1n x^{\frac 1n-1}$ is bounded by $C=\max\{a^{-1},b\}$. So $(f_n|_{[a,b]})$ has Lipschitz constant $C$ by Exp. \ref{lb309}. So $(f_n)$ is equicontinuous at $x$. 

Note that $(f_n)$ converges pointwise to $f$ where $f(x)=1$ if $x>0$ and $f(0)=0$. But $f$ is not continuous at $0$. So $(f_n)$ is not equicontinuous at $0$ due to Cor. \ref{lb310}.
\end{proof}

One can also prove that $(f_n)$ is equicontinuous on $(0,1)\cup(1,+\infty)$ without using derivatives: See Thm. \ref{lb286}-1.





\begin{co}\label{lb284}
Let $(f_\alpha)_{\alpha\in I}$ be a net in $C(X,\mc V)$ converging pointwise to $f\in\mc V^X$. Consider the following statements:
\begin{enumerate}[label=(\arabic*)]
\item $(f_\alpha)_{\alpha\in I}$ converges uniformly to $f$.
\item $(f_\alpha)_{\alpha\in I}$ is equicontinuous.
\end{enumerate}
Then the following are true.
\begin{enumerate}
\item If $(f_\alpha)_{\alpha\in I}$ is a sequence $(f_n)_{n\in\Zbb_+}$, then (1)$\Rightarrow$(2).
\item If $X$ is compact, then (2)$\Rightarrow$(1).
\end{enumerate}
\end{co}


\begin{proof}
Immediate from Thm. \ref{lb277}.
\end{proof}









\subsection{Uniform convergence and double limits}



In view of Prop. \ref{lb281}, Thm. \ref{lb277} implies that the convergence of a double limit is the consequence of uniform convergence. In this section, instead of using the language of topological spaces, we formulate this result in terms of double nets so that it can be applied to a broader context. We first give a useful criterion for uniform convergence.


\begin{pp}\label{lb288}
Assume that $\mc V$ is a Banach space. Let $(f_\alpha)_{\alpha\in I}$ be a net in $C(X,\mc V)$. Assume that $(f_\alpha)$ converges uniformly on a dense subset $E$ of $X$. Then $(f_\alpha)$ converges uniformly on $X$ to some $f\in C(X,\mc V)$.
\end{pp}

The completeness of $\mc V$ is important here.

\begin{proof}
Since $E$ is dense, by \eqref{eq80} (applied to the function $|f_\alpha-f_\beta|$), we have
\begin{align*}
\sup_{x\in X}\Vert f_\alpha(x)-f_\beta(x)\Vert=\sup_{x\in E}\Vert f_\alpha(x)-f_\beta(x)\Vert
\end{align*}
where the RHS converges to $0$ under $\lim_{\alpha,\beta}$. Thus, $(f_\alpha)$ is a Cauchy net in $\mc V^X$ where $\mc V^X$ is equipped with the uniform convergence metric as in Exp. \ref{lb272}. So $(f_\alpha)_{\alpha\in I}$ converges uniformly on $X$ to some $f:X\rightarrow\mc V$ by Thm. \ref{lb339}. By Thm. \ref{lb279}, $f$ is continuous.
\end{proof}




\begin{thm}[\textbf{Moore-Osgood theorem}]\label{lb289}  \index{00@Moore-Osgood theorem}
Let $(f_{\alpha,\beta})_{(\alpha,\beta)\in I\times J}$ be a net in a Banach space $\mc V$ with index set $I\times J$ where $I,J$ are directed sets. Assume the following conditions:
\begin{enumerate}[label=(\arabic*)]
\item For each $\alpha\in I$, there exists $f_{\alpha,\infty}\in\mc V$ such that 
\begin{align}
\lim_{\beta\in J} f_{\alpha,\beta}=f_{\alpha,\infty}
\end{align}
\item For each $\beta\in J$, there exists $f_{\infty,\beta}\in\mc V$ such that
\begin{align}
\lim_{\alpha\in I}\sup_{\beta\in J}\Vert f_{\alpha,\beta}-f_{\infty,\beta}\Vert=0
\end{align}
\end{enumerate}
Then the following are true:
\begin{enumerate}
\item The following limits exist and are equal:
\begin{align}
\lim_{(\alpha,\beta)\in I\times J}f_{\alpha,\beta}=\lim_{\alpha\in I}f_{\alpha,\infty}=\lim_{\beta\in J}f_{\infty,\beta}
\end{align}
\item If $I=\Nbb$ where $\Nbb$ is equipped with the usual order, then
\begin{align}\label{eq89}
\lim_{\beta\in J}\sup_{\alpha\in I}\Vert f_{\alpha,\beta}-f_{\alpha,\infty}\Vert=0
\end{align}
\end{enumerate}
\end{thm}

Conditions (1) and (2) in Thm. \ref{lb289}, which say that the limit of $f_{\alpha,\beta}$ is pointwise over one index and uniform in another index, should remind you of conditions (2) and (3) in Thm. \ref{lb277} (cf. Rem. \ref{lb340}). In fact, we shall use Thm. \ref{lb277} to understand and prove the Moore-Osgood theorem.


\begin{proof}
Part 1: By Thm. \ref{lb122}, it suffices to prove that $\lim_{\alpha,\beta}f_{\alpha,\beta}$ converges. Define topological spaces $I^*=I\cup\{\infty_I\}$ and $J^*=J\cup\{\infty_J\}$ as in Subsec. \ref{lb282}. Define 
\begin{gather*}
g_\alpha:J^*\rightarrow\mc V\qquad g_\alpha(\nu)=f_{\alpha,\nu}
\end{gather*}
where $g_\alpha(\infty_J)=f_{\alpha,\infty}$. By (1), for each $\alpha\in I$, the function $g_\alpha$ is continuous at $\infty_J$, and hence $g_\alpha\in C(J^*,\mc V)$. By (2), $(g_\alpha)_{\alpha\in I}$ converges uniformly on $J$. Since $J$ is a dense subset of $J^*$, by Prop. \ref{lb288}, $(g_\alpha)_{\alpha\in I}$ converges uniformly on $J^*$ to some $g_{\infty_I}:J^*\rightarrow\mc V$. Thus, by Thm. \ref{lb277}, the function
\begin{align*}
F:I^*\times J^*\rightarrow\mc V\qquad F(\mu,\nu)=g_\mu(\nu)
\end{align*}
is continuous. Its continuity at $(\infty_I,\infty_J)$ implies that $\dps\lim_{\alpha\in I,\beta\in J}f_{\alpha,\beta}=\dps\lim_{\alpha\in I,\beta\in J} F(\alpha,\beta)$ converges to $F(\infty_I,\infty_J)$.

Part 2: By Thm. \ref{lb277}, $(g_\alpha)_{\alpha\in I}$ is an equicontinuous family of functions $J^*\rightarrow\mc V$. Its equicontinuity at $\infty_J$ means precisely \eqref{eq89}.
\end{proof}


\begin{rem}
Whenever you see a theorem stated in very plain language but proved using a huge machinery, you should always ask yourself if a direct proof is possible. A huge machinery or fancy language is not always necessary for the proof, but often helps to understand the nature of the problem.

Now, since Thm. \ref{lb289} is stated without using the language of topological spaces and continuous maps, it is desirable to have a direct and elementary proof. It could be done by directly translating the above proof (and the proof of the results cited in that proof) into the pure language of nets. However, we prefer to give a simpler proof which is related to, but is not a direct translation of, the above topological proof.   \hfill\qedsymbol
\end{rem}





\begin{proof}[\textbf{A direct proof of Thm. \ref{lb289}}]
Part 1: By Thm. \ref{lb122}, it suffices to prove that $\lim_{\alpha,\beta}f_{\alpha,\beta}$ converges.  Since $V$ is complete, it suffices to prove the Cauchy condition:
\begin{itemize}
\item[(i)] For each $\eps>0$, there exists $(\alpha,\beta)\in I\times J$ such that for all $(\mu,\nu)\in I_{\geq\alpha}\times J_{\geq\beta}$, we have $\Vert f_{\alpha,\beta}-f_{\mu,\nu}\Vert<\eps$.
\end{itemize}
Choose $\eps>0$. By condition (2) of Thm. \ref{lb289}, $(f_{\alpha,\beta})$, as a net of functions $J\rightarrow \mc V$ with index set $I$, converges uniformly. Thus, by the Cauchy condition for the uniform convergence metric as in Exp. \ref{lb272} (which is available due to Thm. \ref{lb339}), we have:
\begin{itemize}
\item[(ii)] There exists $\alpha\in I$ such that for all $\mu\geq\alpha$, we have $\sup_{\nu\in J}\Vert f_{\alpha,\nu}-f_{\mu,\nu}\Vert<\eps/2$.
\end{itemize}
Fix $\alpha$ as above. By condition (1), the limit $\lim_{\beta\in J} f_{\alpha,\beta}$ exists. Thus:
\begin{itemize}
\item[(iii)] There exists $\beta\in J$ such that for all $\nu\geq\beta$ we have $\Vert f_{\alpha,\beta}-f_{\alpha,\nu}\Vert<\eps/2$.
\end{itemize}
Combining (ii) and (iii) and using triangle inequality, we see that for each $\mu\geq\alpha$ and $\nu\geq\beta$,
\begin{align*}
\Vert f_{\alpha,\beta}-f_{\mu,\nu}\Vert\leq \Vert f_{\alpha,\beta}-f_{\alpha,\nu}\Vert+\Vert f_{\alpha,\nu}-f_{\mu,\nu}\Vert<\eps
\end{align*}
This proves (i).\\[-1ex]

Part 2: Assume $I=\Nbb$. Since $(f_{\alpha,\beta})$ is a Cauchy net, for each $\eps>0$ there exist $\alpha_0\in I,\beta_0\in J$ such that for all $\alpha\geq\alpha_0$ and  $\beta,\nu\geq\beta_0$ we have $\Vert f_{\alpha,\beta}-f_{\alpha,\nu}\Vert<\eps$. Applying $\lim_\nu$ gives
\begin{align*}
\Vert f_{\alpha,\beta}-f_{\alpha,\infty}\Vert\leq\eps\qquad(\forall\alpha\geq\alpha_0,\beta\geq\beta_0)
\end{align*}
Since $I=\Nbb$, there are finitely many $\alpha$ not $\geq\alpha_0$.  For any such $\alpha$, by condition (1) of Thm. \ref{lb289}, there exists $\beta_\alpha\in J$ such that for all $\beta\geq\beta_{\alpha}$, we have $\Vert f_{\alpha,\beta}-f_{\alpha,\infty}\Vert\leq\eps$. Choose $\wtd\beta$  greater than or equal to $\beta_0$ and all these (finitely many) $\beta_\alpha$. Thus, we have $\Vert f_{\alpha,\beta}-f_{\alpha,\infty}\Vert\leq\eps$ for all $\alpha\in I$ and all $\beta\geq\wtd\beta$. This proves \eqref{eq89}.
\end{proof}


\begin{rem}
The main theme of this chapter is the study of the relationship between the convergence of $\lim_{\alpha,\beta}f_{\alpha,\beta}$ and the uniform convergence of $\lim_\alpha f_{\alpha,\beta}$ and $\lim_\beta f_{\alpha,\beta}$. The main results of this chapter (i.e. Thm. \ref{lb274}, Thm. \ref{lb277} (together with Prop. \ref{lb281}), and Moore-Osgood Thm. \ref{lb289}) can be summarized as follows:
\begin{enumerate}
\item[(1)] If one of $\lim_\alpha f_{\alpha,\beta}$ and $\lim_\beta f_{\alpha,\beta}$ converges uniformly and the other one converges pointwise, then $\lim_{\alpha,\beta}f_{\alpha,\beta}$ converges. (Consequently, by Thm. \ref{lb122}, we have $\lim_\alpha\lim_\beta f_{\alpha,\beta}=\lim_\beta\lim_\alpha f_{\alpha,\beta}=\lim_{\alpha,\beta}f_{\alpha,\beta}$.)
\item[(2)] If $\lim_\alpha f_{\alpha,\beta}$, $\lim_\beta f_{\alpha,\beta}$, and $\lim_{\alpha,\beta}f_{\alpha,\beta}$ all converge pointwise, and if ``there is a compactness on $\beta$", then $\lim_\alpha f_{\alpha,\beta}$ converges uniformly over all $\beta$.
\end{enumerate}
The detailed statements of (1) and (2) are given in Thm. \ref{lb277} ((together with Prop. \ref{lb281})), or equivalently, in Thm. \ref{lb274}. (See also Rem. \ref{lb340}.) Although Thm. \ref{lb274} and Thm. \ref{lb277} look very different, they are actually telling the same story. (We have proved Thm. \ref{lb277} from Thm. \ref{lb274}. But it is not hard to see that Thm. \ref{lb274} also implies Thm. \ref{lb277}.) The Moore-Osgood theorem is only about part (1), but not about part (2). (Or, more accurately, the second part of Moore-Osgood corresponds to a very weak version of (2).)
\end{rem}











%% Record #12 2023/10/30 two lectures  29





















\subsection{Problems and supplementary materials}


Recall from the beginning of this chapter that $X$ is a topological space and $\mc V$ is a normed vector space over $\Fbb\in\{\Rbb,\Cbb\}$.

\begin{prob}\label{lb283}
Let $I$ be a directed set. Let $I^*=I\cup\{\infty\}$, equipped with the standard topology as in Subsec. \ref{lb282}. Prove that the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $I^*$ is compact.
\item For each $\alpha\in I$, the complement of $I^*_{\geq\alpha}=\{\beta\in I^*:\beta\geq\alpha\}$ is a finite set.
\end{enumerate}
\end{prob}


\begin{proof}[Note]
Prop. \ref{lb249} can make your proof shorter.
\end{proof}


\begin{prob}
Let $(f_n)$ be a sequence of functions $\Rbb_{\geq0}\rightarrow\Rbb$ defined by $f(x)=x^{\frac 1n}$ (as in Exp. \ref{lb311}). Give a direct proof that $(f_n)$ is not equicontinuous at $0$ using the definition of equicontinuity. Do not use Cor. \ref{lb310}.
\end{prob}


\begin{prob}
Give a direct proof of Cor. \ref{lb303} without using Thm. \ref{lb274} (and its consequences) or using Thm. \ref{lb289}.
\end{prob}

\begin{prob}
Give a direct proof of Cor. \ref{lb284} without using Thm. \ref{lb274} (and its consequences) or using Thm. \ref{lb289}.
\end{prob}

\begin{sprob}\label{lb285}
Let $(f_\alpha)_{\alpha\in I}$ be a net in $C(X,\Rbb)$. Assume that $(f_\alpha)_{\alpha\in I}$ is increasing, i.e., $f_\alpha\leq f_\beta$ whenever $\alpha\leq\beta$. Assume that $(f_\alpha)_{\alpha\in I}$ converges pointwise to $f\in C(X,\Rbb)$. Prove that for every $x\in X$,
\begin{align}
\lim_{
\begin{subarray}{c}
\alpha\in I\\
p\rightarrow x
\end{subarray}
}
f_\alpha(p)=f(x)
\end{align}
in the sense of Prop. \ref{lb281}. Namely, prove that for every $x\in X$ and $\eps>0$ there exist $\beta\in I$ and $U\in\Nbh_X(x)$ such that $|f_\alpha(p)-f(x)|<\eps$ for all $\alpha\geq\beta$ and all $p\in U$.
\end{sprob}

\begin{proof}[Note]
Let $g_\alpha=f-f_\alpha$. Then $(g_\alpha)_{\alpha\in I}$ is a decreasing net of continuous functions converging pointwise to $0$. It suffices to prove the easier statement that $\dps\lim_{\alpha\in I,p\rightarrow x}g_\alpha(p)=0$ for every $x\in X$. (Why is this sufficient?)
\end{proof}

\begin{sthm}\label{lb286}
Let $(f_\alpha)_{\alpha\in I}$ be a net in $C(X,\Rbb)$. Assume that $(f_\alpha)_{\alpha\in I}$ is increasing and converges pointwise to $f\in C(X,\Rbb)$. The following statements are true.
\begin{enumerate}
\item If $(f_\alpha)_{\alpha\in I}$ is a sequence $(f_n)_{n\in\Zbb_+}$, then $(f_n)_{n\in\Zbb_+}$ is equicontinuous.
\item (\textbf{Dini's theorem}) \index{00@Dini's theorem} If $X$ is compact, then $(f_\alpha)_{\alpha\in I}$ converges uniformly to $f$.
\end{enumerate}
\end{sthm}


\begin{proof}
By Pb. \ref{lb285}, $(f_\alpha)_{\alpha\in I}$ and $f_\infty=f$ satisfy (1') of Prop. \ref{lb281}. Therefore, the two statements follow directly from Thm. \ref{lb277}.
\end{proof}


\begin{eg}\label{lb401}
Let $f_n:(0,1)\rightarrow \Rbb$ be $f_n(x)=x^n$, where $n\in\Zbb$. Then $(f_n)_{n\in\Zbb}$ is a decreasing net of continuous functions converging pointwise to $0$. Here, $\Zbb$ is given the usual order ``$\leq$". By Pb. \ref{lb285}, $(f_n)$ satisfies
\begin{align*}
\lim_{(n,p)\rightarrow(+\infty,x)
}f_n(p)=f(x)
\end{align*}
for all $x\in (0,1)$. (So it satisfies condition (1) of Thm. \ref{lb277}.) However, $(f_n)_{n\in\Zbb}$ is neither equicontinuous (since $\sup_{n\in\Zbb}|f_n(p)-f_n(x)|=+\infty$ whenever $0<p<x<1$) nor converging uniformly to $0$ (since $\sup_{x\in (0,1)}|f_n(x)|=1$ if $n>0$). Accordingly, $(0,1)$ is not compact, and $I^*=I\cup\{\infty_I\}$ is not compact if $I=\Zbb$. 

However, if we replace $\Zbb$ by $\Zbb_+$, then $(f_n)_{n\in\Zbb_+}$ is equicontinuous by Exp. \ref{lb309} (applied to any compact subinterval of $(0,1)$), or by Thm. \ref{lb286}. But $(f_n)_{n\in\Zbb_+}$ is still not uniformly convergent. 
 \hfill\qedsymbol
\end{eg}


\begin{prob}\label{lb453}
Let $X_1,X_2,\dots$ be a sequence of nonempty topological spaces. Let $S=\prod_{n\in\Nbb_+}X_n$, equipped with the product topology. Let $f: S \rightarrow \mathbb{R}$ be continuous. Fix $\left(p_n\right)_{n \in \mathbb{Z}_{+}} \in S$. For each $n \in \mathbb{Z}_{+}$, define
\begin{gather*}
\varphi_n : S \rightarrow S \\
\left(x_1, x_2, \ldots, x_{n-1}, x_n, x_{n+1}, \ldots\right)  \mapsto\left(x_1, x_2, \ldots, x_{n-1}, p_n, p_{n+1}, \ldots\right)
\end{gather*}
Prove for every $x_\blt=(x_n)_{n\in\Zbb_+}$ that
\begin{align*}
\lim_{
\begin{subarray}{c}
(n,y_\blt)\in \Zbb_+\times S\\
(n,y_\blt)\rightarrow(\infty,x_\blt)
\end{subarray}
}f\circ\varphi_n(y_\blt)=f(x_\blt)
\end{align*}
in the sense of Prop. \ref{lb281}. Conclude that $(f\circ\varphi_n)_{n\in\Zbb_+}$ is equicontinuous, and that if each $X_n$ is compact then $(f\circ\varphi_n)$ converges uniformly to $f$. (Recall that in this case $S$ is compact by the countable Tychonoff theorem, cf. Pb. \ref{lb241}.)
\end{prob}










\begin{comment}


Let $g_n:[0,1]\rightarrow\Rbb$ be $g_n(x)=n^{-1}x^n$ if $n\neq0$. Equip $\Zbb^\times=\Zbb\setminus\{0\}$ with the usual order $\leq$. Then $(g_n)_{n\in\Zbb^\times}$ is a net of continuous functions converging pointwise to $0$, and is decreasing over $n$ when  $n\in\Zbb_+$.  Thus, by Pb. \ref{lb285}, for every $x\in[0,1]$, we have $\dps\lim_{(n,p)\rightarrow(+\infty,x)
}g_n(p)=g(x)$. Clearly $(g_n)_{n\in\Zbb^\times}$ converges uniformly to $0$. However, it is not hard to check that this net of functions is not equicontinuous. (The bad thing happens when $n<0$.) 


These examples indicate why condition (1) of Thm. \ref{lb277} or (1') of Prop. \ref{lb281} is more natural than ``equicontinuity + pointwise convergence": Condition (1') of Prop. \ref{lb281} can be viewed as a continuity condition which is not ``equi" over all $\alpha$ in the index set $I$, but is ``equi" for sufficiently large $\alpha$.
\end{comment}

















\newpage


\section{Extending continuous functions to the closures}



\subsection{Introduction}

Let $\wtd X,Y$ be topological spaces, let $X\subset \wtd X$, and let $f:X\rightarrow Y$ be a continuous map. The \textbf{extension problem} asks whether $f$ can be extended to a continuous map $\wtd f:\wtd X\rightarrow Y$. ``Extended" means that $\wtd f|_X=f$.  Since we can try to first extend $f$ from $X$ to its closure $\Cl_{\wtd X}(X)$, and then from $\Cl_{\wtd X}(X)$ to $\wtd X$, the extension problem can naturally be divided into two cases: (1) $X$ is dense in $\wtd X$. (2) $X$ is closed in $\wtd X$.

In this chapter, we study the first case. (The second case will be discussed in Sec. \ref{lb464}.) Assume that $X$ is dense in $\wtd X$. Then by Prop. \ref{lb196}, we know that $f$ can have at most one extension if $Y$ is Hausdorff. So there is essentially no uniqueness issue. 


The study of extension problem in this case has a long history. As we have seen in Subsec. \ref{lb290}, the limits of functions can be understood in this light: If $x\in\wtd X\setminus X$, then $f$ can be extended to a continuous function on $X\cup\{x\}$ iff $\lim_{p\rightarrow x}f(p)$ exists. Of course, this is simply a rephrasing of the definition of $\lim_{p\rightarrow x}f(p)$. But the idea of ``extending $f$ to $\wtd X$ by first extending $f$ to a slightly larger set with one extra point $\{x\}$" is helpful and can sometimes simplify proofs.

Indeed, recall that in the proof of Prop. \ref{lb281} we used Thm. \ref{lb276}, which tells us that if $\lim_{p\rightarrow x}f(p)$ converges for all $x\in\wtd X\setminus X$, then $f$ can be extended (necessarily uniquely) to a continuous $\wtd f:\wtd X\rightarrow Y$ where $Y$ is assumed metrizable. Thus, \uline{the extensibility of $f$ to $\wtd X$ can be checked pointwise}. Thm. \ref{lb276} is our first important general result on the extension problem. Let me state Thm. \ref{lb276} in the following equivalent way, which is more convenient for the  study of extension problems.
\begin{co}\label{lb307}
Let $f:X\rightarrow Y$ be a continuous map of topological spaces where $Y$ is metrizable and $X$ is a dense subspace of a topological space $\wtd X$. The following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item There exists a continuous map $\wtd f:\wtd X\rightarrow Y$ such that $\wtd f|_X= f$.
\item For each $x\in\wtd X\setminus X$, the limit $\lim_{p\rightarrow x}f(p)$ exists.
\end{enumerate}
\end{co}

\begin{proof}
If (1) is true, then $\wtd f|_{X\cup\{x\}}$ is continuous whenever $x\in\wtd X\setminus X$. This proves (2). Conversely, assume (2). Extend $ f$ to a map $\wtd f:\wtd X\rightarrow Y$ by setting $\wtd f(x)=\lim_{p\rightarrow x}f(p)$ if $x\in\wtd X\setminus X$. Then $\wtd f$ is continuous by Thm. \ref{lb276}.
\end{proof}







This chapter will focus on another useful method for extending continuous functions in the setting of metric spaces. A main result (cf. Cor. \ref{lb298}) is that if $\wtd X,Y$ are metric spaces and $Y$ is complete, then a sufficient condition for the extensibility of $f$ onto $\wtd X$ is that $f$ is uniformly continuous. Moreover, uniform continuity is also a necessary condition if $\wtd X$ is compact. (Recall that compact metric spaces are complete, cf. Thm. \ref{lb79}.) It is worth mentioning that the extensibility of $f$ is a purely topological question, whereas the uniform continuity of $f$ depends on the metric on $\wtd X$.



\subsection{Uniform continuity}


Fix metric spaces $\wtd X,Y$ and a dense subset $X\subset\wtd X$. 

\subsubsection{Basics}


We first give some examples of $f\in C(X,Y)$ that cannot be extended to a continuous function on $\wtd X$. Since uniform continuity is a sufficient condition for the extensibility (when $Y$ is complete), these examples are not uniformly continuous. Recall our convention that subsets of $\Rbb$ or $\Rbb^N$ are equipped with the Euclidean metrics.

\begin{eg}
Assume $X=(0,+\infty)$, $\wtd X=[0,+\infty)$, $Y=\Rbb$, and $f:X\rightarrow Y$ is defined by $f(x)=1/x$. Then $\lim_{x\rightarrow 0}f(x)$ is $+\infty$ in $\ovl\Rbb$, and hence does not converge in $Y$. So $f$ cannot be extended onto $\wtd X$.
\end{eg}

\begin{eg}
$X=(0,1]$, $\wtd X=[0,1]$, $Y=\Rbb$, $f:X\rightarrow Y$ is defined by $f(x)=\sin(1/x)$. Then $\lim_{n\rightarrow\infty}f(x_n)$ equals $0$ if the sequence $(x_n)$ in $X$ converging to $0$ is defined by $x_n=1/2n\pi$, and equals $1$ if $x_n=1/(2n+\frac 12)\pi$. Thus, by Rem. \ref{lb202}, $\lim_{x\rightarrow0}f(x)$ does not exist in $Y$. So $f$ cannot be extended onto $\wtd X$.
\end{eg}


\begin{df}\label{lb291}
A map $f:X\rightarrow Y$ is called \textbf{uniformly continuous} \index{00@Uniformly continuous} if the following equivalent conditions are satisfied:
\begin{enumerate}[label=(\arabic*)]
\item For every $\eps>0$ there exists $\delta>0$ such that for all $x,x'\in X$ we have
\begin{subequations}
\begin{align}\label{eq91}
d(x,x')<\delta\qquad\Longrightarrow\qquad d(f(x),f(x'))<\eps
\end{align}
\item For every nets $(x_\alpha)_{\alpha\in I},(x'_\alpha)_{\alpha\in I}$ in $X$ (with the same index set $I$) we have
\begin{align}\label{eq92}
\lim_{\alpha\in I} d(x_\alpha,x'_\alpha)=0\qquad\Longrightarrow\qquad\lim_{\alpha\in I} d(f(x_\alpha),f(x'_\alpha))=0
\end{align}
\item For every sequences $(x_n)_{n\in\Zbb_+},(x_n')_{n\in\Zbb_+}$ in $X$ we have
\begin{align}\label{eq93}
\lim_{n\rightarrow\infty} d(x_n,x'_n)=0\qquad\Longrightarrow\qquad\lim_{n\rightarrow\infty} d(f(x_n),f(x'_n))=0
\end{align}
\end{subequations}
\end{enumerate}
\end{df}

Uniformly continuous maps are clearly continuous. Def. \ref{lb291}-(2) says that uniformly continuous functions are those sending Cauchy-equivalent nets (cf. Def. \ref{lb155}) to Cauchy-equivalent nets. 


\begin{proof}[Proof of equivalence]
(1)$\Rightarrow$(2): Assume (1). Choose nets $(x_\alpha)_{\alpha\in I},(x'_\alpha)_{\alpha\in I}$ in $X$. Choose any $\eps>0$. Choose $\delta>0$ such that \eqref{eq91} holds. If $d(x_\alpha,x'_\alpha)\rightarrow0$, then $d(x_\alpha,x'_\alpha)<\delta$ for sufficiently large $\alpha$. So $d(f(x_\alpha),f(x'_\alpha))<\eps$ for sufficiently large $\alpha$. This proves (2).

(2)$\Rightarrow$(3): Obvious.

$\neg$(1) $\Rightarrow$ $\neg$(3): Assume that (1) is false. Then there exists $\eps>0$ such that for all $\delta>0$  there exist $x,x'\in X$ with $d(x,x')<\delta$ such that $d(f(x),f(x'))\geq\eps$. Thus, for each $n\in\Zbb_+$, there exist $x_n,x_n'\in X$ such that $d(x_n,x_n')<1/n$ and $d(f(x_n),f(x_n'))\geq\eps$. The sequences $(x_n),(x_n')$ imply that \eqref{eq93} is false.
\end{proof}




\begin{co}\label{lb292}
Assume that $f:X\rightarrow Y$ is uniformly continuous. Let $(x_\alpha)_{\alpha\in I}$ be a Cauchy net in $X$. Then $(f(x_\alpha))_{\alpha\in I}$ is a Cauchy net in $Y$.
\end{co}

\begin{proof}
Apply Def. \ref{lb291}-(2) to the nets $(x_\alpha)_{(\alpha,\beta)\in I^2}$ and $(x_\beta)_{(\alpha,\beta)\in I^2}$ of $X$.
\end{proof}








\subsubsection{Extensibility of uniformly continuous functions}



The following theorem can be viewed as the uniform continuity version of Prop. \ref{lb288}. In particular, both results assume the completeness of the codomain.

\begin{thm}\label{lb297}
Let $f:X\rightarrow Y$ be uniformly continuous, and assume that $Y$ is complete. Then there exists a (necessarily unique) uniformly continuous $\wtd f:\wtd X\rightarrow Y$ satisfying $\wtd f|_X=f$.
\end{thm}


\begin{proof}
Choose any $x\in\wtd X$. Since $X$ is dense in $\wtd X$, we can choose a sequence $(x_n)$ in $X$ converging to $x$ in $\wtd X$. In particular, $(x_n)$ is a Cauchy sequence. Therefore, by Cor. \ref{lb292}, $(f(x_n))$ is a Cauchy sequence in $Y$, which converges to some point $\wtd f(x)\in Y$ by the completeness of $Y$. If $x\in X$, we assume that $(x_n)$ is the constant sequence $x$. This shows that $\wtd f(x)=f(x)$ if $x\in X$.

We have constructed a function $\wtd f:\wtd X\rightarrow Y$ satisfying $\wtd f|_X=f$. Let us prove that $\wtd f$ is uniformly continuous. Choose any $\eps>0$. Since $f$ is uniformly continuous, there is $\delta>0$ such that for all $p,q\in X$ we have
\begin{align*}
d(p,q)<2\delta\qquad\Longrightarrow\qquad d(f(p),f(q))<\eps/2
\end{align*}
Choose any $x,x'\in \wtd X$ satisfying $d(x,x')<\delta$. By our construction of $\wtd f$, there are sequences $(x_n)$ in $X$ converging to $x$ and $(x_n')$ in $X$ converging to $x'$ such that $f(x_n)\rightarrow \wtd f(x)$ and $f(x_n')\rightarrow\wtd f(x')$. Thus, there exist $N\in\Zbb_+$ such that for all $n\geq N$ we have
\begin{align*}
d(x,x_n)<\frac\delta 2\qquad d(x',x_n')<\frac\delta 2\qquad d(\wtd f(x),f(x_n))<\frac\eps 4\qquad d(\wtd f(x'),f(x'_n))<\frac\eps 4
\end{align*}
Choose $n=N$. Then by triangle inequality, we have $d(x_n,x_n')<2\delta$, and hence $d(f(x_n),f(x_n'))<\eps/2$. So $d(\wtd f(x),\wtd f(x'))<\eps$ by triangle inequality again.
\end{proof}






We now study the other direction. The following theorem implies that if a continuous $f:X\rightarrow Y$ can be extended to a continuous $\wtd f:\wtd X\rightarrow Y$, and if $\wtd X$ is compact, then $f$ is uniformly continuous.


\begin{thm}\label{lb294}
Suppose that $f:X\rightarrow Y$ is continuous and $X$ is compact. Then $f$ is uniformly continuous.
\end{thm}

In the same spirit as in Sec. \ref{lb293}, we give two proofs for this theorem, one using sequences and the other using open covers.

\begin{proof}[First proof]
Assume that $f$ is not uniformly continuous. By Def. \ref{lb291}-(3), there exist sequences $(x_n)$ and $(x_n')$ in $X$ such that $\lim_{n\rightarrow\infty}d(x_n,x_n')=0$, and that $d(f(x_n),f(x_n'))\nrightarrow0$. The latter means that there is $\eps>0$ such that $d(f(x_n),f(x_n'))$ is frequently $\geq\eps$. Thus, by passing to a subsequence, we may assume that $d(f(x_n),f(x_n'))\geq\eps$ for all $n$. Since $X\times X$ is sequentially compact, by replacing $(x_n,x_n')$ with a convergent subsequence, we assume that $x_n\rightarrow x$ and $x_n'\rightarrow x'$ where $x,x'\in X$. Since $d(x_n,x_n')\rightarrow0$, we must have $x=x'$. By the continuity of $f$, $f(x_n)$ and $f(x_n')$ converge to $f(x)=f(x')$, contradicting the fact that $d(f(x_n),f(x_n'))\geq\eps$ for all $n$. 
\end{proof}


To prove Thm. \ref{lb294} using open covers, we prove a more general result instead. The following theorem is useful for proving properties of the form ``there exists $\delta>0$ such that for all $x,x'\in X$ satisfying $d(x,x')<\delta$, we have ...".


\begin{thm}[\textbf{Lebesgue number lemma}]\index{00@Lebesgue number lemma}  \label{lb295}
Assume that the metric space $X$ is compact. Let $\fk U\subset 2^X$ be an open cover of $X$. Then there exists $\delta>0$ satisfying the following conditions:
\begin{itemize}
\item For every $x\in X$ there exists $U\in\fk U$ such that $B_X(x,\delta)\subset U$.
\end{itemize}
\end{thm}

The number $\delta$ in Thm. \ref{lb295} is called a \textbf{Lebesgue number of $\fk U$}. \index{00@Lebesgue number} In the following proof, we follow the local-to-global strategy as in Sec. \ref{lb293}. 

\begin{proof}
Choose any $p\in X$. Then there is $U\in\fk U$ containing $p$. So there is $\delta_p>0$ such that $B(p,2\delta_p)\subset U$. Therefore, there exists $V_p\in\Nbh_X(p)$ such that for every $x$ in $V_p$ we have $B(x,\delta_p)\subset U$. (Simply take $V_p=B(p,\delta_p)$.) This solves the problem locally: for each $x\in V_p$, the ball $B(x,\delta_p)$ is a subset of some member of $\fk U$.

Since $X=\bigcup_{p\in X}V_p$ and since $X$ is compact, there is a finite subset $E\subset X$ such that $X=\bigcup_{p\in E}V_p$. Take $\delta=\min\{\delta_p:p\in E\}$. For each $x\in X$, choose $p\in E$ such that $x\in V_p$. Then $B(x,\delta_p)$ is a subset of some member of $\fk U$ by the last paragraph. So the same is true for $B(x,\delta)$.
\end{proof}


Of course, similar to the examples studied in Sec. \ref{lb293}, Thm. \ref{lb295} can also be proved by contradiction and by using sequential compactness. See Pb. \ref{lb296}.



\begin{proof}[\textbf{Second proof of Thm. \ref{lb294}}]
Let us verify Def. \ref{lb291}-(1). Choose any $\eps>0$. For each $x\in X$, the set $U_x=f^{-1}(B_Y(f(x),\eps/2))$ is a neighborhood of $x$ by Prop. \ref{lb191}. So $\{U_x:x\in X\}$ is an open cover of $X$. Let $\delta$ be a Lebesgue number of $\fk U$. Choose any $x,y\in X$ satisfying $d(x,y)<\delta$.  Then $B_X(x,\delta)\subset U_{z}$ for some $z\in X$. So $x,y\in B_X(x,\delta)$ and hence $x,y\in U_z$. Therefore,
\begin{align*}
d(f(x),f(y))\leq d(f(x),f(z))+d(f(z),f(y))<\eps/2+\eps/2=\eps
\end{align*}
\end{proof}



\begin{co}\label{lb298}
Choose $f\in C(X,Y)$. Consider the following statements:
\begin{enumerate}[label=(\arabic*)]
\item $f$ is uniformly continuous.
\item There exists $\wtd f\in C(\wtd X,Y)$ such that $\wtd f|_X=f$.
\end{enumerate}
Then (1)$\Rightarrow$(2) if $Y$ is complete, and (2)$\Rightarrow$(1) if $\wtd X$ is compact.
\end{co}

\begin{proof}
Immediate from Thm. \ref{lb297} and Thm. \ref{lb294}.
\end{proof}


\begin{eg}
Let $D=B_\Cbb(0,1)=\{z\in\Cbb:|z|<1\}$ and $\Sbb^1=\{z\in\Cbb:|z|=1\}$. Let $f:D\rightarrow Y$ be a continuous function where $Y$ is a complete metric space. Then $f$ is uniformly continuous iff $\lim_{w\rightarrow z}f(w)$  exists for every $z\in \Sbb^1$.
\end{eg}

\begin{proof}
By Cor. \ref{lb307}, the limit $\lim_{w\rightarrow z}f(w)$  exists for every $z\in \Sbb^1$  iff $f$ can be extended to a continuous function $\wtd f:\ovl D=D\cup \Sbb^1\rightarrow Y$.  By Cor. \ref{lb298}, this is equivalent to that $f$ is uniformly continuous (because $\ovl D$ is compact and $Y$ is compete).
\end{proof}



\subsubsection{Uniform equicontinuity}

Although the notion of uniform equicontinuity will rarely be used in our notes, it is used in many textbooks.  So let me give a brief account of uniform equicontinuity. 



\begin{df}\label{lb316}
Let $(f_\alpha)_{\alpha\in I}$ be a family of functions $X\rightarrow Y$. (Here, the index set $I$ is not necessarily directed.) Define a metric $d$ on $Y^I$ in a similar way to \eqref{eq78}, namely, if $\mbf y,\mbf y'\in Y^I$ then
\begin{align*}
d(\mbf y,\mbf y')=\min\Big\{1,\sup_{\alpha\in I} d_Y(\mbf y(\alpha),\mbf  y'(\alpha))\Big\}
\end{align*}
We say that $(f_\alpha)_{\alpha\in I}$ is \textbf{uniformly equicontinuous} \index{00@Uniformly equicontinuous} if the map
\begin{gather}\label{eq106}
X\rightarrow Y^I\qquad x\mapsto (f_\alpha(x))_{\alpha\in I}
\end{gather}
is uniformly continuous with respect to the metric $d$. Clearly, this is equivalent to saying that:
\begin{itemize}
\item For every $\eps>0$ there exists $\delta>0$ such that for every $x,x'\in X$ satisfying $d_(x,x')<\delta$, we have
\begin{align*}
\sup_{\alpha\in I}d_Y(f_\alpha(x),f_\alpha(x'))<\eps
\end{align*}
\end{itemize}
\end{df}

Uniformly equicontinuous families of functions are equicontinuous, because uniformly continuous functions are continuous. Conversely, we have:

\begin{pp}
Assume that $X$ is compact and $(f_\alpha)_{\alpha\in I}$ is a family of functions $X\rightarrow Y$. Then $(f_\alpha)_{\alpha\in I}$ is equicontinuous iff it is uniformly equicontinuous.
\end{pp}

\begin{proof}
``$\Leftarrow$" is obvious, as mentioned above. ``$\Rightarrow$" follows immediately by applying Thm. \ref{lb294} to the continuous map \eqref{eq106}.
\end{proof}






\subsection{Completion of metric spaces}



Fix a metric space $X$ in this section. We are going to apply uniform continuity to the study of completions of metric spaces. Roughly speaking, a completion of $X$ is a complete metric space $\wht X$ containing $X$ as a dense subspace. However, completions are not unique, but are unique ``up to equivalence". So we want to show that two completions $\wht X,\wtd X$ of the same metric space $X$ are equivalent. However,  it is confusing to view $X$ as a subset of $\wtd X$ and $\wtd X$ simultaneously. A better approach is to consider (automatically injective) isometries $\varphi:X\rightarrow\wht X,\psi:X\rightarrow\wtd X$, and to show that $\varphi$ and $\psi$ are equivalent using the language of commutative diagrams (cf. Sec. \ref{lb299}).


\begin{df}
A \textbf{completion} \index{00@Completion of metric space} of the metric space $X$ is an isometry $\varphi:X\rightarrow\wht X$ where $\wht X$ is a complete metric space, and $\varphi(X)$ is dense in $\wht X$. We sometimes just say that $\wht X$ is a completion of $X$.
\end{df}


Thus, if $A$ is a dense subset of a complete metric space $B$, then the inclusion map $A\hookrightarrow B$ is a completion. Therefore, $\Rbb$ is a completion of $\Qbb$, and $[0,1]$ is a completion of $(0,1)$, $[0,1)$, $[0,1]\cap\Qbb$.



\begin{eg}
Let $A$ be a dense subset of a metric space $X$. Suppose that $\varphi:X\rightarrow\wht X$ is a completion of $X$. Then $\varphi|_A:A\rightarrow \wht X$ is clearly a completion of $A$. 
\end{eg}

\begin{eg}
Let $X$ be a subset of a complete metric space $Y$. Then $X\hookrightarrow\Cl_Y(X)$ is a completion of $X$ because every closed subset of $Y$ is complete (cf. Prop. \ref{lb86}), and hence $\Cl_Y(X)$ is complete. For example, $\{(x,y)\in\Rbb^2:x\geq0\}$ is a completion of both $A=\{(x,y)\in\Rbb^2:x>0\}$ and $B=A\cap\Qbb^2$.
\end{eg}



We want to prove that every metric space $X$ has a completion $\wht X$. First, we need a lemma, which can be viewed as analogous to Pb. \ref{lb287}.

\begin{lm}\label{lb300}
Suppose that $X$ is a dense subspace of a metric space $\wht X$. Suppose that every Cauchy sequence in $X$ converges to an element of $\wht X$. Then $\wht X$ is complete.
\end{lm}

\begin{proof}
Let $(x_n)$ be a Cauchy sequence in $\wht X$. Since $X$ is dense, there exists $x_n'\in X$ such that $d(x_n,x_n')<1/n$. So $(x_n')$ is Cauchy-equivalent to $(x_n)$. Thus $(x_n')$ is a Cauchy sequence by Exe. \ref{lb128}. By assumption, $(x_n')$ converges to some $x\in X$. So $(x_n')$ also converges to $x$ by Exe. \ref{lb128}.
\end{proof}



\begin{thm}\label{lb301}
Every metric space $X$ has a completion $\varphi:X\rightarrow\wht X$. Moreover, any completion $\psi:X\rightarrow\wtd X$ is \textbf{equivalent} (also called \textbf{isomorphic}) to $\varphi$ in the sense that there is an isometric isomorphism of metric spaces $\Phi:\wht X\rightarrow\wtd X$ such that the following diagram commutes:
\begin{equation}\label{eq94}
\begin{tikzcd}[column sep=small]
                     & X \arrow[ld,"\varphi"'] \arrow[rd,"\psi"] &   \\
\wht X \arrow[rr, "\Phi","\simeq"'] &                         & \wtd X
\end{tikzcd}
\end{equation}
\end{thm}


Recall that the commutativity of \eqref{eq94} means that $\psi=\Phi\circ\varphi$.

\begin{proof}[\textbf{Proof of existence}]
The construction of $\varphi:X\rightarrow\wht X$ is similar to the construction of $\Rbb$ from $\Qbb$ in Ch. \ref{lb167}. Let $\scr C$ be the set of Cauchy sequences in $X$. Let $\wht X=\scr C/\sim$ be the quotient set (cf. Def. \ref{lb157}) where $\sim$ is the Cauchy-equivalence relation: $(x_n)\sim(y_n)$ iff $\lim_{n\rightarrow\infty}d(x_n,y_n)=0$. We let $[x_n]_{n\in\Zbb_+}$ or simply let $[x_n]$ denote the equivalence class of $(x_n)$ in $\wht X$. The map $\varphi$ is defined by
\begin{align*}
\varphi:X\rightarrow\wht X\qquad x\mapsto [x]_{n\in\Zbb_+}
\end{align*}
where $[x]_{n\in\Zbb_+}$ is the equivalence class of the constant sequence $(x,x,\dots)$.\\[-0.5ex]


Step 1: Let us define a metric $d_{\wht X}$ on $\wht X$. Note that if $(x_n),(y_n)\in \scr C$, then by triangle inequality,
\begin{align*}
|d(x_m,y_m)-d(x_n,y_n)|\leq d(x_m,x_n)+d(y_m,y_n)
\end{align*}
where the RHS converges to $0$ as $m,n\rightarrow+\infty$. Therefore, the LHS also converges to $0$. This shows that $(d(x_n,y_n))_{n\in\Zbb_+}$ is a Cauchy sequence in $\Rbb_{\geq0}$, and hence converges. Therefore, we define
\begin{gather*}
d_{\wht X}:\wht X\times \wht X\rightarrow\Rbb_{\geq0}\\
d_{\wht X}([x_n],[y_n])=\lim_{n\rightarrow\infty}d(x_n,y_n)
\end{gather*}
This is well-defined: If $[x_n]=[x_n']$, and $[y_n]=[y_n']$, then 
\begin{align*}
|d(x_n,y_n)-d(x_n',y_n')|\leq d(x_n,x_n')+d(y_n,y_n')
\end{align*}
which converge to $0$ as $n\rightarrow\infty$. So $(d(x_n',y_n'))_{n\in\Zbb_+}$ and $(d(x_n,y_n))_{n\in\Zbb_+}$ are Cauchy-equivalent, and hence converge to the same number.

Clearly $d_{\wht X}([x_n],[y_n])=0$ iff $(x_n)\sim (y_n)$ iff $[x_n]=[y_n]$. And clearly $d_{\wht X}([x_n],[y_n])=d_{\wht X}([y_n],[x_n])$. If $[x_n],[y_n],[z_n]$ are in $\scr C$, applying $\lim_{n\rightarrow\infty}$ to
\begin{align*}
d(x_n,z_n)\leq d(x_n,y_n)+d(y_n,z_n)
\end{align*}
yields $d_{\wht X}([x_n],[z_n])\leq d_{\wht X}([x_n],[y_n])+d_{\wht X}([y_n],[z_n])$. So $d_{\wht X}$ is a metric.\\[-0.5ex]

Step 2. The map $\varphi:X\rightarrow\wht X$ is clearly an isometry. Let us show that it has dense range. Choose any $[x_n]_{n\in\Zbb_+}\in\wht X$. We shall show that $\varphi(x_k)=[x_k,x_k,\dots]$ approaches $[x_n]_{n\in\Zbb_+}$ as $k\rightarrow\infty$. 

For each $k$, we have
\begin{align}
d_{\wht X}(\varphi(x_k),[x_n]_{n\in\Zbb_+})=\lim_{n\rightarrow\infty}d(x_k,x_n)\label{eq96}
\end{align}
where the RHS converges because $d_{\wht X}$ is defined. Since $(x_n)_{n\in\Zbb_+}$ is a Cauchy sequence in $X$, we have
\begin{align}
\lim_{k,n\rightarrow\infty} d(x_k,x_n)=0   \label{eq95}
\end{align}
Therefore, by \eqref{eq95} and the convergence of the RHS of \eqref{eq96}, we can use  Thm. \ref{lb122} to conclude that
\begin{align*}
\lim_{k\rightarrow\infty}d_{\wht X}(\varphi(x_k),[x_n]_{n\in\Zbb_+})=\lim_{k\rightarrow\infty}\lim_{n\rightarrow\infty}d(x_k,x_n)=\lim_{k,n\rightarrow\infty}d(x_k,x_n)=0
\end{align*}


Step 3. It remains to prove that $\wht X$ is complete. By Lem. \ref{lb300} (applied to $\varphi(X)\subset\wht X$) and the fact that $\varphi$ is an isometry, it suffices to prove that for every Cauchy sequence $(x_k)_{k\in\Zbb_+}$ in $X$, the sequence $(\varphi(x_k))_{k\in\Zbb_+}$ converges in $\wht X$. But this is true: we have shown in Step 2 that $(\varphi(x_k))_{k\in\Zbb_+}$ converges to $[x_n]_{n\in\Zbb_+}$.
\end{proof}

\begin{proof}[\textbf{Proof of equivalence}]
Suppose that $\psi:X\rightarrow\wtd X$ is another completion. The map
\begin{gather*}
\Phi:\varphi(X)\rightarrow \psi(X)\qquad \varphi(x)\mapsto\psi(x)
\end{gather*}
is well-defined since $\varphi$ is injective. Moreover, $\Phi$ is an isometry since $\varphi$ and $\psi$ are isometries. In particular, $\Phi$ is uniformly continuous. Therefore, by Cor. \ref{lb298}, $\Phi$ can be extended to a uniformly continuous map $\Phi:\wht X\rightarrow\wtd X$. Clearly $\psi=\Phi\circ\varphi$. The continuous map
\begin{gather*}
\wht X\times\wht X\rightarrow \Rbb\\
(p,q)\mapsto d_{\wtd X}(\Phi(p),\Phi(q))-d_{\wht X}(p,q)
\end{gather*}
is zero on the dense subset $\varphi(X)\times \varphi(X)$ of its domain. Therefore it is constantly zero by Prop. \ref{lb196}. This proves that $\Phi$ is an isometry.

It remains to prove that $\Phi$ is surjective. Since $\wht X$ is complete and $\Phi$ restricts to an isometric isomorphism of metric spaces $\wht X\rightarrow\Phi(\wht X)$, $\Phi(\wht X)$ is a complete metric subspace of $\wht X$. Thus, by Prop. \ref{lb86}, $\Phi(\wht X)$ is a closed subset of $\wtd X$. But $\Phi(\wht X)$ is dense in $\wtd X$ since it contains $\psi(X)$. Therefore $\Phi(\wht X)=\wtd X$.
\end{proof}

The proof of Thm. \ref{lb301} is complete.












\subsection{Completion of normed vector spaces}

Fix a normed vector space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$.

\begin{df}\label{lb597}
A \textbf{completion of the normed vector space $V$} \index{00@Completion of normed vector spaces} (or a \textbf{Banach space completion} of $V$) \index{00@Banach space completion} is a \textit{linear} isomertry $\varphi:V\rightarrow\wht{V}$ such that $\wht{V}$ is a Banach space, and $\varphi(V)$ is dense in $\wht V$.
\end{df}

Thus, if $\varphi:V\rightarrow\wht V$ is a completion, then $V$ is isomorphic to $\varphi(V)$ as normed vector spaces, and hence can be viewed as equivalently a dense normed subspace of $\wht V$.



\begin{thm}\label{lb312}
Every normed vector space $V$ has a completion $\varphi:V\rightarrow\wht V$. Morevoer, every completion $\psi:V\rightarrow\wtd V$ is \textbf{isomorphic} to $\varphi$ in the sense that there is an isomorphism of Banach spaces (cf. Def. \ref{lb302}) $\Phi:\wht V\rightarrow\wtd V$ such that the following diagram commutes:
\begin{equation}
\begin{tikzcd}[column sep=small]
                     & V \arrow[ld,"\varphi"'] \arrow[rd,"\psi"] &   \\
\wht V \arrow[rr, "\Phi","\simeq"'] &                         & \wtd V
\end{tikzcd}
\end{equation}
\end{thm}

%% Record #13 2023/11/1 three lectures  32

\begin{proof}[\textbf{Proof of existence}]
By Thm. \ref{lb301}, we have a completion $\varphi:V\rightarrow\wht V$ in the context of metric spaces. So $\wht V$ is a completion of metric space with metric $d_{\wht V}$, and $\varphi$ is an isometry of metric spaces with dense range. We need to show that $\wht V$ is a complete normed vector space, and that $\varphi$ is linear with dense range. Indeed, we shall identify $V$ with $\varphi(\wht V)$ via $\varphi$ so that $V$ is the metric subspace of $\wht V$. We shall extend the structure of normed vector space from $V$ to $\wht V$. In the following, the convergence in $\wht V$ and the continuity of the maps about $\wht V$ are understood using the metric $d_{\wht V}$. 

The map
\begin{gather*}
+:V\times V\rightarrow V\qquad (u,v)\mapsto u+v
\end{gather*}
is Lipschitz continuous, and hence uniformly continuous. Therefore, by Cor. \ref{lb298}, it can be extended (uniquely) to a continuous map $+:\wht V\times\wht V\rightarrow\wht V$. Similarly, if $\lambda\in\Fbb$, the Lipschitz continuous map
\begin{gather*}
V\rightarrow V\qquad v\mapsto \lambda\cdot v
\end{gather*}
can be extended to a continuous map $\wht V\rightarrow\wht V$. Thus, we have defined the addition $+$ and the scalar multiplication $\cdot$ for $\wht V$. Similarly, the map
\begin{align*}
\Vert \cdot\Vert:V\rightarrow\Rbb_{\geq0}  \qquad v\mapsto\Vert v\Vert
\end{align*}
is uniformly continuous and hence can be extended to a map $\wht V\rightarrow\Rbb_{\geq0}$.


We want to show that the above addition, scalar multiplication, and norm function make $\wht V$ a normed vector space.  For example, suppose that $\lambda\in\Fbb$. We want to prove that $\lambda(u+v)=\lambda u+\lambda v$ for all $u,v\in\wht V$, and we know that this is true when $u,v\in V$. Indeed, since $V\times V$ is dense in $\wht V\times\wht V$, and since the following two continuous maps
\begin{gather*}
(u,v)\in\wht V\times\wht V\mapsto \lambda(u+v)\in\wht V\\
(u,v)\in\wht V\times\wht V\mapsto \lambda u+\lambda v\in\wht V
\end{gather*}
are equal on $V\times V$, these two maps are the same by Prop. \ref{lb196}. The same argument proves that $\wht V$ is a vector space.


Since the following continuous map
\begin{gather*}
\varphi:(u,v)\in\wht V\times\wht V\mapsto \Vert u\Vert+\Vert v\Vert-\Vert u+v\Vert\in\Rbb
\end{gather*}
satisfies $\varphi(V\times V)\subset\Rbb_{\geq0}$, by $\varphi(\wht V\times \wht V)\subset\ovl{\varphi(V\times V)}$ (due to Prop. \ref{lb196} again), we conclude that $\varphi(\wht V\times\wht V)\subset \Rbb_{\geq0}$. So $\Vert u+v\Vert\leq \Vert u\Vert+\Vert v\Vert$ for all $u,v\in\wht V$. A similar argument shows $\Vert\lambda v\Vert=|\lambda|\cdot\Vert v\Vert$. %Finally, suppose that $v\in\wht V$ satisfies $\Vert v\Vert =0$. Pick a sequence $(u_n)$ in $V$ satisfying $d_{\wht V}(u_n,v)\rightarrow 0$. Since $\Vert\cdot\Vert:\wht V\rightarrow\Rbb$ is continuous, 
%\begin{align*}
%\lim_{n\rightarrow\infty}d_V(u_n,0)=\lim_{n\rightarrow\infty}\Vert u_{n}\Vert=\big\Vert \lim_{n\rightarrow\infty}u_n\big\Vert=\Vert v\Vert=0
%\end{align*}
%Therefore $(u_n)$ converges to $0$ in $V$. This proves $v=0$. So $\wht V$ is normed.

Since the metric on $V$ is induced by the norm of $V$, the map
\begin{gather*}
\wht V\times\wht V\rightarrow\Rbb\qquad (u,v)\mapsto d_{\wht V}(u,v)-\Vert u-v\Vert
\end{gather*}
is zero on the dense subset $V\times V$ of $\wht V\times\wht V$. Since this map is continuous, it is constantly zero. In particular, if $v\in\wht V$ satisfies $\Vert v\Vert=0$, then $d_{\wht V}(v,0)=0$, and hence $v=0$. So $\Vert\cdot\Vert$ is a norm on $\wht V$, and the complete metric $d_{\wht V}$ on $\wht V$ (arising from the metric-space-completion of $V$) is defined by this norm. So this norm is complete. Therefore, $\wht V$ is a Banach space. Since $V$ is dense in $\wht V$ under $d_{\wht V}$, $V$ is dense in $\wht V$ under the norm of $\wht V$.
\end{proof}


\begin{proof}[\textbf{Proof of uniqueness}]
By Thm. \ref{lb301}, there is a unique isometric isomorphism of metric spaces $\Phi:\wht V\rightarrow\wtd V$ such that $\psi=\Phi\circ\varphi$. Since $\varphi$ and $\psi$ are linear injections, $\Phi$ is a linear isomorphism when restricted to $\varphi(V)\rightarrow\psi(V)$. Since $\Phi$ is continuous and $\varphi(V)$ is dense in $\wht V$, we conclude that $\Phi$ is linear thanks to the following property.
\end{proof}


\begin{pp}\label{lb315}
Let $T:V\rightarrow W$ be a continuous map of normed vector spaces. Assume that $V_0$ is a dense linear subspace of $V$. Assume that $T|_{V_0}:V_0\rightarrow W$ is linear. Then $T$ is linear.
\end{pp}


\begin{proof}
This is same as the proof of the existence part of Thm. \ref{lb312}. Choose any $\alpha,\beta\in\Fbb$. Then the following continuous map
\begin{gather*}
(u,v)\in V\times V\mapsto T(\alpha u+\beta v)-(\alpha T(u)+\beta T(v))
\end{gather*}
is zero on the dense subset $V_0\times V_0$. So it is zero on $V\times V$.
\end{proof}


\begin{exe}
Let $V$ and $W$ be normed vector spaces over $\Fbb$, where $\Fbb=\Rbb$ (resp. $\Fbb=\Cbb$). Let $T:V\rightarrow W$ be a continuous map. Assume that $V_0$ is a dense $\Kbb$-linear subspace of $V$, where $\Kbb=\Qbb$ (resp. $\Kbb=\Qbb+\im\Qbb$). Assume that the restriction $T|_{V_0}:V_0\rightarrow W$ is $\Kbb$-linear. Prove that $T:V\rightarrow W$ is $\Fbb$-linear.
\end{exe}


\begin{rem}\label{lb538}
So far in this course, we have proved a lot of results about functions whose codomains are normed vector spaces. Some results assume that these spaces are Banach (i.e. complete), some do not. Thanks to Thm. \ref{lb312}, we can assume that all these results are stated only for Banach spaces, and then check whether they also hold for normed vector spaces in general (which is not difficult). This will make us easier to remember theorems.

For example, suppose that we know that Thm. \ref{lb279} holds only for Banach spaces: Namely, suppose we know that for any Banach space $V$ and topological space $X$, if $(f_\alpha)$ is a net in $C(X,V)$ converging uniformly to $f:X\rightarrow V$, then $f$ is continuous. Then we know that this result also holds when $V$ is a normed vector space. To see this, consider the completion $V\subset\wht V$. Then $(f_\alpha)$ is a net of continuous functions $X\rightarrow\wht V$ converging uniformly to some $f:X\rightarrow \wht V$ (satisfying $f(X)\subset V$). Then $f:X\rightarrow\wht V$ is continuous. Hence $f:X\rightarrow V$ is continuous.

Consider Prop. \ref{lb288} as another example. It tells us that if $V$ is a Banach space and $(f_\alpha)$ is a net in $C(X,V)$ converging uniformly on a dense subset $E\subset X$, then $(f_\alpha)$ converges uniformly on $X$. Now assume that $V$ is only a normed vector space, and take completion $V\subset\wht V$. Then $(f_\alpha)$ is a net in $C(X,\wht V)$ converges uniformly on $E$ to a function $E\rightarrow V$. Thus, by Prop. \ref{lb288}, it converges uniformly to a function $f:X\rightarrow\wht V$. Although we know $f(E)\subset V$ by assumption, we do not know whether $f(X)\subset V$. So we cannot prove the normed vector space version of Prop. \ref{lb288}.  \hfill\qedsymbol 
\end{rem}





\subsection{Bounded linear maps}\label{lb620}

In this section, we consider normed vector spaces over a given field $\Fbb\in\{\Rbb,\Cbb\}$.

We have seen that uniform continuity is crucial to the construction of addition and scalar multiplication in Thm. \ref{lb312}. Indeed, uniform continuity is ubiquitous in the world of normed vector spaces: We shall see that every continuous linear map of normed vector spaces is uniformly continuous. 


\begin{df}
Let $T:V\rightarrow W$ be a linear map of normed vector spaces. The \textbf{operator norm} $\Vert T\Vert$ \index{00@Operator norm} is defined to be
\begin{align}
\Vert T\Vert\xlongequal{\mathrm{def}} \sup_{v\in\ovl B_V(0,1)}\Vert Tv\Vert  \label{eq120}
\end{align}
\end{df}

\begin{rem}\label{lb372}
$\Vert T\Vert$ is the smallest number in $\ovl\Rbb_{\geq0}$ satisfying
\begin{align}
\Vert Tv\Vert\leq \Vert T\Vert\cdot\Vert v\Vert\qquad (\forall v\in V)  \label{eq105}
\end{align}
\end{rem}


\begin{proof}
\eqref{eq105} is clearly true when $v=0$. Assume $v\neq0$. Since $v/\Vert v\Vert\in\ovl B_V(0,1)$, we have $\Vert T(v/\Vert v\Vert)\Vert\leq \Vert T\Vert$. This proves \eqref{eq105}.

Now suppose that $C\in\ovl\Rbb_{\geq0}$ satisfies that $\Vert Tv\Vert\leq C\Vert v\Vert$ for all $v$. Then for each $v\in\ovl B_V(0,1)$ we have $\Vert Tv\Vert\leq C$. So $\Vert T\Vert\leq C$.
\end{proof}



\begin{pp}\label{lb313}
Let $T:V\rightarrow W$ be a linear map of normed vector spaces. Then the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $T$ is Lipschitz continuous.
\item $T$ is continuous.
\item $T$ is continuous at $0$.
\item $\Vert T\Vert<+\infty$.
\end{enumerate}
Moreover, if one of these conditions holds, then $T$ has Lipschitz constant $\Vert T\Vert$.
\end{pp}

\begin{proof}
Clearly (1)$\Rightarrow$(2) and (2)$\Rightarrow$(3). Suppose (3) is true. Note that $T0=0$. So there is $\delta>0$ such that $Tv\in \ovl B_W(0,1)$ for all $v\in \ovl B_V(0,\delta)$. Namely, for all $v\in V$ satisfying $\Vert v\Vert\leq \delta$ we have $\Vert Tv\Vert=\Vert Tv-T0\Vert\leq 1$. Thus, if $\Vert v\Vert\leq 1$, then $\Vert \delta v\Vert\leq\delta$. So
\begin{align*}
\Vert Tv\Vert=\delta^{-1}\Vert T(\delta v)\Vert\leq \delta^{-1}
\end{align*}
This proves $\Vert T\Vert\leq\delta^{-1}$. So (4) is proved.

Assume (4). By Rem. \ref{lb372}, for each $u,v\in V$ we have
\begin{align*}
\Vert Tu-Tv\Vert=\Vert T(u-v)\Vert\leq \Vert T\Vert\cdot \Vert u-v\Vert
\end{align*}
This proves that $T$ has Lipschitz constant $\Vert T\Vert$.
\end{proof}





Due to Prop. \ref{lb313}-(4), we make the following definition:
\begin{df}
Let $V,W$ be normed vector spaces over $\Fbb$. We call $T:V\rightarrow W$ to be a \textbf{bounded linear map} \index{00@Bounded linear map} if $T$ is a continuous linear map. We write \index{LVW@$\fk L(V,W),\fk L(V)$}
\begin{align}
\fk L(V,W)=\{\text{bounded linear maps }V\rightarrow W\}\qquad \fk L(V)=\fk L(V,V)
\end{align}
\end{df}

Thus, the word ``bounded" means that the linear map $T$ is bounded on $\ovl B_V(0,1)$, but not that $T$ is bounded on $V$.

\begin{pp}\label{lb314}
$\fk L(V,W)$ is a linear subspace of $W^V$, and the operator norm $\Vert \cdot\Vert$ is a norm on $\fk L(V,W)$.
\end{pp}

\begin{proof}
By Rem. \ref{lb372}, for each linear $S,T:V\rightarrow W$ and $\lambda\in\Fbb$, and for each $v\in V$ we have
\begin{gather*}
\Vert (S+T)v\Vert\leq \Vert S v\Vert+\Vert Tv\Vert\leq(\Vert S\Vert+\Vert T\Vert)\Vert v\Vert\\
\Vert \lambda Tv\Vert=|\lambda|\cdot\Vert Tv\Vert\leq |\lambda|\cdot \Vert T\Vert \cdot\Vert v\Vert
\end{gather*}
Thus, by Rem. \ref{lb372} again, we have
\begin{align}
\Vert S+T\Vert\leq \Vert S\Vert+\Vert T\Vert\qquad \Vert\lambda T\Vert\leq |\lambda|\cdot \Vert T\Vert
\end{align}
The proposition now follows easily from the above inequalities. (Notice Rem. \ref{lb367})
\end{proof}


Since Lipschitz continuous functions are uniformly continuous, we have:
\begin{pp}\label{lb500}
Let $V_0$ be a dense linear subspace of a normed vector space $V$. Let $W$ be a Banach space. Let $T_0:V_0\rightarrow W$ be a bounded linear map. Then there is a unique bounded linear map $T:V\rightarrow W$ such that $T|_{V_0}=T_0$.
\end{pp}

\begin{proof}
Uniqueness is clear from the density of $V_0$. By Prop. \ref{lb313}, $T_0$ is uniformly continuous. Therefore, by Cor. \ref{lb298}, $T_0$ can be extended to a continuous map $T:V\rightarrow W$, which is linear by Prop. \ref{lb315}.
\end{proof}











\subsection{Problems and supplementary material}

\begin{prob}
Give a direct proof of Thm. \ref{lb294} using open covers instead of using subsequences. Do not use Lebesgue numbers.
\end{prob}


The following Pb. \ref{lb296} gives another proof that sequentially compact metric spaces are compact. Therefore, do not use this fact in your solution of Pb. \ref{lb296}.

\begin{sprob}\label{lb296}
Let $X$ be a sequentially compact metric space. Let $\fk U\subset 2^X$ be an open cover of $X$.
\begin{enumerate}
\item Prove that $\fk U$ has a Lebesgue number. Namely, prove that there exists $\delta>0$ such that for every $x\in X$ there is $U\in\fk U$ satisfying $B_X(x,\delta)\subset U$.
\item In our proof that $X$ is separable (cf. Thm. \ref{lb252}), we showed that for every $\delta>0$ there exists a finite set $E\subset X$ such that $d(x,E)<\delta$ for all $x\in X$. Use this fact and Part 1 to prove that $\fk U$ has a finite subcover.
\end{enumerate}
\end{sprob}





\begin{df}
Two norms $\Vert\cdot\Vert_1$ and $\Vert\cdot\Vert_2$ on a vector space $\Vbb$ over $\Rbb$ or $\Cbb$ are called \textbf{equivalent} \index{00@Equivalent norms} if there exist $\alpha,\beta>0$ such that for all $v\in V$ we have
\begin{align*}
\Vert v\Vert_1\leq \alpha \Vert v\Vert_2\qquad \Vert v\Vert_2\leq \beta \Vert v\Vert_1
\end{align*}
Clearly, two equivalent norms induce equivalent metrics, and hence induce the same topology.
\end{df}


\begin{prob}\label{lb559}
Let $\Fbb\in\{\Rbb,\Cbb\}$. Let $\Vert\cdot\Vert$ be the Euclidean norm on $\Fbb^n$. Let $\nu:\Fbb^n\rightarrow\Rbb_{\geq 0}$ be a norm on $\Fbb^n$.
\begin{enumerate}
\item Prove that there exists $\alpha>0$ such that $\nu(\mbf x)\leq \alpha\Vert\mbf x\Vert$ for all $\mbf x\in\Fbb^n$. In particular, show that $\nu$ is continuous (under the Euclidean topology).
\item Let $\beta=\inf\{\nu(\mbf x):\mbf x\in\Fbb^n,\Vert \mbf x\Vert\leq 1\}$. Prove that $\beta>0$. Prove that $\Vert \mbf x\Vert\leq\beta^{-1}\cdot\nu(\mbf x)$ for all $\mbf x\in\Fbb^n$.
\end{enumerate}
\end{prob}


The above problem proves

\begin{thm}\label{lb363}
Let $\Fbb\in\{\Rbb,\Cbb\}$. Then any norm on $\Fbb^n$ is equivalent to the Euclidean norm. In particular, the operator norm on $\Fbb^{m\times n}$ (if we view an $m\times n$ matrix as an element of $\fk L(\Fbb^n,\Fbb^m)$) is equivalent to the Euclidean norm.
\end{thm}













\newpage







\section{Derivatives}

\subsection{Basic properties of derivatives}\label{lb575}


Fix a Banach space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$. Let $\Omega$ be a nonempty open subset of $\Cbb$. The following assumption will be often considered:




\begin{df}
Let $f:[a,b]\rightarrow V$ (where  $-\infty<a<b<+\infty$)  be a map with variable $t$, and let $x\in[a,b]$. The \textbf{derivative} \index{00@Derivative} of $f$ at $x$ is
\begin{align*}
f'(x)\equiv \frac{df}{dt}(x)\xlongequal{\mathrm{def}}\lim_{
\begin{subarray}{c}
t\in[a,b]\setminus\{x\}\\
t\rightarrow x
\end{subarray}
}
\frac{f(t)-f(x)}{t-x}
=\lim_{
\begin{subarray}{c}
h\in [a-x,b-x]\setminus\{0\}\\
h\rightarrow 0
\end{subarray}
}
\frac{f(x+h)-f(x)}h
\end{align*}
provided that the limits converge. In other words (cf. Def. \ref{lb197}),
\begin{itemize}
\item $f'(x)$ converges to $v\in V$ iff for every $\eps>0$ there exists $\delta>0$ such that for every $t\in[a,b]$ satisfying $0<|t-x|<\delta$ we have
\begin{align*}
\Big\Vert \frac{f(t)-f(x)}{t-x}-v  \Big\Vert<\eps
\end{align*}
\end{itemize}


If $f'(x)$ exists for some $x$, we say that $f$ is \textbf{differentiable} \index{00@Differentiable} at $x$. If $f'(x)$ exists for  every $x\in [a,b]$, we say that $f$ is a \textbf{differentiable function} and view $f'$ as a function $[a,b]\rightarrow V$. 

Derivatives on intervals $[a,b),(a,b],(a,b)$ are understood in a similar way. \hfill\qedsymbol
\end{df}


\begin{comment}
To simplify subscripts, we write
\begin{align}\label{eq107}
f'(x)=\left\{
\begin{array}{ll}
\dps\lim_{t\rightarrow x}\frac{f(t)-f(x)}{t-x}&\text{ if }a<x<b\\[2ex]
\dps\lim_{t\rightarrow x^+}\frac{f(t)-f(x)}{t-x}&\text{ if }x=a\\[2ex]
\dps\lim_{t\rightarrow x^-}\frac{f(t)-f(x)}{t-x}&\text{ if }x=b
\end{array}
\right.
\end{align}
for the obvious reason. (Recall Def. \ref{lb200}.)

\begin{rem}
Note that in the three cases of \eqref{eq107}, $f'(x)$ can also equals
\begin{align*}
\lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}h\qquad \lim_{h\rightarrow 0^+}\frac{f(x+h)-f(x)}h\qquad \lim_{h\rightarrow 0^-}\frac{f(x+h)-f(x)}h
\end{align*}
\end{rem}

\end{comment}






\begin{df}
Let $E$ be a subset of $\Rbb^n$. Let $f:E\rightarrow V$ be a function with variables $t_1,\dots,t_n$, and $\mbf x=(x_1,\dots,x_n)\in E$. Let $1\leq i\leq n$. Suppose that there are $a,b$ satisfying  $-\infty<a<x_i<b<+\infty$ such that $(x_1,\dots,x_{i-1},t,x_{i+1},\dots,x_n)$ belongs to $E$ for all $t\in[a,b]$. The derivative of the function $t_i\mapsto f((x_1,\dots,x_{i-1},t_i,x_{i+1},\dots,x_n)$ at $t=x_i$ is denoted by
\begin{align*}
\frac{\partial f}{\partial t_i}(\mbf x)\equiv\partial_i f(\mbf x)
\end{align*} 
and called the \textbf{partial derivative} \index{00@Partial derivative} of $f$ at $\mbf x$ with respect to the variable $t_i$.
\end{df}



\begin{df}
If $V$ is over $\Cbb$, and if $f:\Omega\rightarrow V$ and $z\in\Omega$, we define the \textbf{derivative} of $f$ at $z$ to be
\begin{align*}
f'(z)=\lim_{
\begin{subarray}{c}
w\in\Omega\setminus\{z\}\\
w\rightarrow z
\end{subarray}
}\frac{f(w)-f(z)}{w-z}
\end{align*}
provided that the RHS exists, and simply write it as
\begin{align*}
\lim_{w\rightarrow z}\frac{f(w)-f(z)}{w-z}=\lim_{\zeta\rightarrow0}\frac{f(z+\zeta)-f(z)}\zeta
\end{align*}
\end{df}

\begin{cv}\label{lb332}
Unless otherwise stated, when talking about derivatives of a function defined on an interval $I$, we always assume that $I$ is inside $\Rbb$ and has at least two points.  When talking about derivatives of a function $f:\Omega\rightarrow V$, we always assume that $V$ is over $\Cbb$.
\end{cv}



\begin{df}
Given a function $f:E\rightarrow V$ where $E$ is an interval in $\Rbb$ with at least two points or $E=\Omega$, if $n\in\Nbb$ and $x\in E$, we define the \pmb{$n$}\textbf{-th derivative} $f^{(n)}(x)$ \index{fn@$f^{(n)}$}  inductively by $f^{(0)}=f$ and $f^{(n)}(x)=(f^{(n-1)})'(x)$ if $f^{(n-1)}$ exists on some neighborhood of $x$ with respect to $E$. $f'',f''',f'''',\dots$ mean $f^{(2)},f^{(3)},f^{(4)},\dots$.

The $n$-th partial derivative on the $i$-th variable is written as $\partial_i^nf$. \hfill\qedsymbol
\end{df}


It is desirable to use sequences or nets to study derivatives. For that purpose, the following lemma is useful:

\begin{lm}\label{lb322}
Let $E$ be  an interval in $\Rbb$ with at least two elements, or let $E=\Omega$. Let $z\in E$. Let $f:E\rightarrow V$. Let $v\in V$. 
The following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item We have $f'(z)=v$.
\item For any sequence $(z_n)_{n\in\Zbb_+}$ in $E\setminus\{z\}$ converging to $z$, we have $\dps\lim_{n\rightarrow\infty} \frac{f(z_n)-f(z)}{z_n-z}=v$.
\item For any net $(z_\alpha)_{\alpha\in\mc I}$ in $E$ converging to $z$, we have $\dps\lim_{\alpha\in\mc I}\varphi(z_\alpha)=v$, where $\varphi:E\rightarrow V$ is defined by
\begin{align}\label{eq110}
\varphi(w)=\left\{
\begin{array}{ll}
\dps\frac{f(w)-f(z)}{w-z}&\text{ if }w\neq z\\[2ex]
v&\text{ if }w=z
\end{array}
\right.
\end{align}
\end{enumerate}
\end{lm}

\begin{proof}
The equivalence of (1)$\Leftrightarrow$(2) is due to Def. \ref{lb197}-(3m). Also, by Def. \ref{lb197}-(1), that $f'(z)=v$ is equivalent to that the function $\varphi$ in \eqref{eq110} is continuous at $z$. So it is equivalent (3) by Def. \ref{lb188}-(1).
\end{proof}






\begin{pp}\label{lb319}
Let $E$ be an interval in $\Rbb$ or $E=\Omega$. If $f:E\rightarrow V$ is differentiable at $z\in E$, then $f$ is continuous at $z$.
\end{pp}


\begin{proof}
We consider the case $f:\Omega\rightarrow V$; the other case is similar. Choose any sequence $(z_n)$ in $\Omega\setminus\{z\}$ converging to $z$. By Lem. \ref{lb322}, we have $\lim_n \frac{f(z_n)-f(z)}{z_n-z}=v$. Since $\lim_n(z_n-z)=0$, by the continuity of scalar multiplication (Prop. \ref{lb82}),  we have
\begin{align*}
\lim_{n\rightarrow\infty}f(z_n)-f(z)=0\cdot v=0
\end{align*}
Thus, by Def. \ref{lb197}-(3m), we obtain $\lim_{w\neq z,w\rightarrow z}f(w)=f(z)$, which means by Def. \ref{lb197}-(1) that $f$ is continuous at $z$.
\end{proof}


\begin{pp}\label{lb320}
Let $E$ be an interval in $\Rbb$ or $E=\Omega$, and $x\in E$. Suppose that $f,g$ are functions $E\rightarrow V$ such that $f'(x)$ and $g'(x)$ exist. Then $(f+g)'(x)$ exists, and
\begin{subequations}
\begin{align}
(f+g)'(x)=f'(x)+g'(x)
\end{align}
If $\lambda$ is a function $E\rightarrow\Fbb$ such that $\lambda'(x)$ exists, then $(\lambda f)'(x)$ exists and satisfies the \textbf{Leibniz rule} \index{00@Leibniz rule}
\begin{align}
(\lambda f)'(x)=\lambda'(x)f(x)+\lambda(x)f'(x)  \label{eq111}
\end{align}
Assume moreover that $\lambda$ does not have value $0$. Then
\begin{align}
\Big(\frac 1\lambda\cdot f\Big)'(x)=\frac{-\lambda'(x)f(x)+\lambda(x)f'(x)}{\lambda(x)^2}
\end{align}
\end{subequations}
\end{pp}


\begin{proof}
The first formula is easy. To compute the second one, we choose any sequence $(x_n)$ in $[a,b]\setminus \{x\}$ or $\Omega\setminus\{x\}$ converging to $x$. Then
\begin{align*}
\frac{\lambda(x_n)f(x_n)-\lambda(x)f(x)}{x_n-x}=\frac{(\lambda(x_n)-\lambda(x))}{x_n-x}\cdot f(x_n)+\lambda(x)\frac{(f(x_n)-f(x))}{x_n-x}
\end{align*}
which, by Lem. \ref{lb322} and Prop. \ref{lb82} and the continuity of $f$ at $x$ (Prop. \ref{lb319}), converges to the RHS of \eqref{eq111}. This proves \eqref{eq111}, thanks to Lem. \ref{lb322}.

The third formula will follow from the second one if we can prove that $1/\lambda$ has derivative $-\frac{\lambda'(x)}{\lambda(x)^2}$ at $x$. This is not hard: Choose any sequence $x_n\rightarrow x$ but $x_n\neq x$. Then
\begin{align*}
\Big(\frac 1{\lambda(x_n)}-\frac 1{\lambda(x)}\Big)\Big/ (x_n-x)=-\frac{\lambda(x_n)-\lambda(x)}{x_n-x}\cdot \frac 1{\lambda(x_n)\lambda(x)}
\end{align*}
converges to $-\lambda'(x)\cdot \frac 1{\lambda(x)^2}$ as $n\rightarrow \infty$. Here, we have used the continuity of $\lambda$ at $x$ and Prop. \ref{lb82} again.
\end{proof}


%% Record #14 2023/11/6 two lectures  34


\begin{eg}
The derivative of a constant function is $0$. Thus, by Leibniz rule, if $\lambda$ is a scalar, and if $f'(z)$ exists, then $(\lambda f)'(z)=\lambda\cdot f'(z)$.
\end{eg}

\begin{eg}\label{lb323}
The identity map $f:z\in\Cbb\mapsto z\in\Cbb$ has derivative $\lim_{w\rightarrow z}\frac{w-z}{w-z}=1$. Thus, by induction and Prop. \ref{lb320}, we have $(z^n)'=nz^{n-1}$ if $n\in\Zbb_+$. If $-n\in\Zbb_+$, then when $z\neq 0$ we have
\begin{align*}
(z^n)'=(1/z^{-n})'=-\frac{(z^{-n})'}{z^{-2n}}=-\frac{-nz^{-n-1}}{z^{-2n}}=nz^{n-1}
\end{align*}
We conclude that $(z^n)'=nz^{n-1}$ whenever $n\in\Nbb$, or whenever $n=-1,-2,\dots$ and $z\neq0$. The same conclusion holds for the real variable function $x^n$.
\end{eg}


\begin{eg}
Let $f:z\in\Cbb\mapsto\ovl z\in\Cbb$. We claim that for every $z\in\Cbb$, the limit
\begin{align}
f'(z)=\lim_{w\rightarrow z}\frac{\ovl w-\ovl z}{w-z}=\lim_{h\rightarrow 0}\ovl h/h
\end{align}
does not exist with the help of Rem. \ref{lb202}: Take $h_n=1/n$. Then $h_n\rightarrow 0$ and $\ovl {h_n}/h_n=1\rightarrow 1$ as $n\rightarrow\infty$. Take $h_n=\im/n$. Then $h_n\rightarrow 0$ and $\ovl {h_n}/h_n=-\im/\im=-1\rightarrow-1$ as $n\rightarrow\infty$. So $f'(z)$ does not exist.
\end{eg}



\begin{thm}[\textbf{Chain rule}] \index{00@Chain rule}\label{lb331}
Let $\Omega,\Gamma$ be nonempty open subsets of $\Cbb$. Assume that $f:\Omega\rightarrow\Gamma$ is differentiable at $z\in\Omega$, and that $g:\Gamma\rightarrow V$ is differentiable at $f(z)$. Then $g\circ f$ is differentiable at $z$, and
\begin{align}
(g\circ f)'(z)=g'(f(z))\cdot f'(z)\label{eq125}
\end{align}
The same conclusion holds if $\Omega$ is replaced by an interval in $\Rbb$, or if both $\Omega$ and $\Gamma$ are replaced by intervals in $\Rbb$.
\end{thm}

Recall Conv. \ref{lb332} for the assumption on the field $\Fbb$.


\begin{comment}
The most natural idea is to  compute the limit of
\begin{align*}
\frac{g\circ f(w)-g\circ f(z)}{w-z}=\frac{f(w)-f(z)}{w-z}\cdot\frac{g\circ f(w)-g\circ f(z)}{f(w)-f(z)}
\end{align*}
as $w\rightarrow z$ (understood as limits of nets as indicated in Rem. \ref{lb318}). However, the RHS of this expression does not make sense when $f(w)=f(z)$, and this bad situation may happen for many $w\in\Omega\setminus\{z\}$. We overcome this difficulty by changing the language of the proof slightly, without changing the key idea too much.
\end{comment}



\begin{proof}
Define a function $A:\Gamma\rightarrow\Cbb$ by
\begin{gather}\label{eq231}
A(\zeta)=\left\{
\begin{array}{ll}
\dps\frac{g(\zeta)-g\circ f(z)}{\zeta-f(z)}&\text{ if }\zeta\neq f(z)\\[2ex]
\dps g'(f(z))&\text{ if }\zeta=f(z)
\end{array}
\right.
\end{gather}
Choose any sequence $(z_n)$ in $\Omega\setminus\{z\}$ converging to $z$. Then
\begin{align*}
\frac{g\circ f(z_n)-g\circ f(z)}{z_n-z}=A(f(z_n))\cdot\frac{f(z_n)-f(z)}{z_n-z}
\end{align*}
By Prop. \ref{lb319}, $f$ is continuous at $z$. So $\lim_n f(z_n)=f(z)$. Thus, by Lem. \ref{lb322}-(3), the above expression converges to $g'(f(z))f'(z)$ as $n\rightarrow\infty$.
\end{proof}



\begin{pp}\label{lb337}
Let $\Omega,\Gamma$ be nonempty open subsets of $\Cbb$. Let $f:\Omega\rightarrow\Gamma$ be a bijection. Let $z\in\Omega$. Suppose that $f'(z)$ exists and $f'(z)\neq 0$. Suppose also that $f^{-1}:\Gamma\rightarrow\Omega$ is continuous at $f(z)$. Then $f^{-1}$ is differentiable at $f(z)$, and
\begin{align}
(f^{-1})'(f(z))=\frac 1{f'(z)}
\end{align}
The same conclusion holds if $\Omega$ and $\Gamma$ are replaced by intervals of $\Rbb$.
\end{pp}


\begin{proof}
Choose any sequence $(w_n)$ in $\Gamma\setminus\{f(z)\}$ converging to $f(z)$. Then, as $n\rightarrow\infty$, we have $f^{-1}(w_n)\rightarrow f^{-1}(f(z))=z$ since $f^{-1}$ is continuous at $f(z)$, and hence
\begin{align}
\frac{f^{-1}(w_n)-f^{-1}(f(z))}{w_n-f(z)}=\frac{f^{-1}(w_n)-z}{f(f^{-1}(w_n))-f(z)}
\end{align}
converges to $1/f'(z)$ by Lem. \ref{lb322} and the continuity of the map $\zeta\in\Cbb^{\times}\mapsto 1/\zeta\in\Cbb$. This proves $(f^{-1})'(f(z))=1/f'(z)$, thanks to Lem. \ref{lb322}.
\end{proof}








\begin{comment}

The Leibniz rule \eqref{eq111} can be generalized to higher derivatives. 

\end{comment}


\subsection{Rolle's and Lagrange's mean value theorems (MVT)} \index{00@MVT=mean value theorem}

Fix a Banach space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$. Assume $-\infty<a<b<+\infty$.

\subsubsection{MVTs}



\begin{df}
Let $f:X\rightarrow \Rbb$ where $X$ is a topological space. We say that $f$ has a \textbf{local maximum} (resp. \textbf{local minimum}) \index{00@Local maximum/minimum} at $x\in X$, if there exists $U\in\Nbh_X(x)$ such that $f|_U$ attains its maximum (resp. minimum) at $x$. The word ``\textbf{local extremum}" \index{00@Local extremum} refers to either local maximum or local minimum.
\end{df}


You must know that derivatives can be used to find the monotonicity of real-valued real variable functions. Here is the precise statement:

\begin{pp}\label{lb324}
Assume that $f:[a,b]\rightarrow\Rbb$ is differentiable at $x\in[a,b]$, and $f'(x)>0$. Then there exists $\delta>0$ such that for any $y\in (x-\delta,x+\delta)\cap[a,b]$, we have
\begin{gather}
y>x\Rightarrow f(y)>f(x)\qquad y<x\Rightarrow f(y)<f(x)   \label{eq112}
\end{gather}
\end{pp}
We leave it to the readers the find the analogous statement for the case $f'(x)<0$.

\begin{proof}
Let $A=f'(x)>0$. Then there exists $\delta>0$ such that for all $y\in (x-\delta,x+\delta)\cap[a,b]$ not equal to $x$, we have $\dps\Big|\frac{f(y)-f(x)}{y-x}-A \Big|<\frac A2$, and hence $\dps\frac{f(y)-f(x)}{y-x}>\frac A2$. This proves \eqref{eq112}.
\end{proof}


\begin{co}\label{lb325}
Assume that $f:[a,b]\rightarrow\Rbb$ has a local extremum at $x\in (a,b)$. Assume that $f'(x)$ exists. Then $f'(x)=0$.
\end{co}
\begin{proof}
If $f'(x)$ is a non-zero number, then either $f'(x)>0$ or $(-f)'(x)>0$. In either case, Prop. \ref{lb324} indicates that $f$ cannot have a local extremum at $x$.
\end{proof}




From Prop. \ref{lb324}, it is clear that if $f'>0$ on $(a,b)$, then $f$ is strictly increasing. However, to prove that if $f'\geq0$ then $f$ is increasing, we need more preparation.


\begin{lm}[\textbf{Rolle's MVT}] \index{00@Rolle's MVT}
Suppose that $f\in C([a,b],\Rbb)$ is differentiable on $(a,b)$. Suppose moreover that $f(a)=f(b)$. Then there exists $x\in (a,b)$ such that $f'(x)=0$.
\end{lm}


\begin{proof}
If $f$ is constant than $f'=0$. Suppose that $f$ is not constant. Then there is $x\in(a,b)$ at which $f$ attains its maximum (if $f(t)>f(a)$ for some $t\in(a,b)$) or minimum (if $f(t)<f(b)$ for some $t\in(a,b)$). So $f'(x)=0$ by Cor. \ref{lb325}.
\end{proof}


\begin{eg}
Rolle's MVT does not hold for vector-valued functions. Especially, it does hot hold for functions to $\Cbb\simeq\Rbb^2$. Consider $f:[0,2\pi]\rightarrow\Cbb$ defined by $f(t)=e^{\im t}=\cos t+\im\sin t$. We assume that $\sin'=\cos$ and $\cos'=-\sin$ are proved. Then $f(0)=f(2\pi)=1$, whereas $f'(t)=-\sin t+\im\cos t$ is never zero.
\end{eg}





\begin{thm}[\textbf{Lagrange's MVT}] \index{00@Lagrange's MVT}\label{lb345}
Suppose that $f\in C([a,b],\Rbb)$ is differentiable on $(a,b)$. Then there is $x\in(a,b)$ such that
\begin{align}\label{eq113}
f'(x)=\frac{f(b)-f(a)}{b-a}
\end{align}
\end{thm}



\begin{proof}
The case $f(a)=f(b)$ is just Rolle's MVT. When $f(a)\neq f(b)$, we can ``shift the function $f$ vertically" so that its two end points have the same height. Technically, we consider $g(x)=f(x)-kx$ where $k=\frac{f(b)-f(a)}{b-a}$ is the slope of the interval from $(a,f(a))$ to $(b,f(b))$. Then $g(a)=g(b)$. By Rolle's MVT, there is $x\in(a,b)$ such that $g'(x)=0$, i.e. $f'(x)-k=0$.
\end{proof}


\subsubsection{Applications of MVTs}








\begin{co}\label{lb330}
Assume that $f\in C([a,b],\Rbb)$ is differentiable on $(a,b)$. Then
\begin{align}
f'\geq0\text{ on }(a,b)\qquad\Longleftrightarrow\qquad f\text{ is increasing on }[a,b] \label{eq114}
\end{align}
Moreover, if $f'>0$ on $(a,b)$, then $f$ is strictly increasing on $[a,b]$.
\end{co}


\begin{proof}
If $f'(x)<0$ for some $x\in (a,b)$, then Prop. \ref{lb324} implies that $x$ has a neighborhood on which $f$ is not increasing. Conversely, suppose that $f'(x)\geq 0$ for all $x\in (a,b)$. Choose $x,y\in[a,b]$ satisfying $a\leq x<y\leq b$. Then by Lagrange's MVT, there is $z\in(x,y)$ such that $f(y)-f(x)=f'(z)(y-x)\geq0$. So $f$ is increasing on $[a,b]$. We have finished proving \eqref{eq114}.

Suppose that $f'>0$ on $(a,b)$. Then by Prop. \ref{lb324}, $f$ is strictly increasing on $(a,b)$. If $a<x<b$, then there is $\eps>0$ such that $f(a+1/n)\leq f(x)-\eps$ for sufficiently large $n$. Since $f$ is continuous at $a$, by taking $\lim_{n\rightarrow\infty}$ we get $f(a)\leq f(x)-\eps$ and hence $f(a)<f(x)$. A similar argument proves $f(b)>f(x)$. So $f$ is strictly increasing on $[a,b]$.
\end{proof}

\begin{co}\label{lb424}
Suppose that $f\in C([a,b],\Rbb)$ is differentiable on $(a,b)$, and $f'(x)\neq 0$ for all $x\in(a,b)$. Then $f$ is strictly monotonic (i.e. strictly increasing or strictly decreasing). In particular, by Cor. \ref{lb330}, either $f'\geq0$ on $(a,b)$ or $f'\leq 0$ on $(a,b)$.
\end{co}

\begin{proof}
Rolle's MVT implies $f(b)-f(a)\neq 0$, and similarly, $f(y)-f(x)\neq 0$ whenever $a\leq x<y\leq b$. Therefore $f$ is injective. The strict monotonicity of $f$ follows from the following general fact:
\end{proof}

\begin{pp}\label{lb347}
Let $-\infty\leq a< b\leq +\infty$, and let $f:[a,b]\rightarrow\ovl\Rbb$ be a continuous injective function. Then $f$ is strictly monotonic.
\end{pp}


\begin{proof}
Choose a strictly increasing homeophism  $\varphi:[0,1]\rightarrow[a,b]$. It suffices to prove that $g=f\circ\varphi:[0,1]\rightarrow\ovl\Rbb$ is strictly monotonic. Assume for simplicity that $g(0)\leq g(1)$. Let us show that $g$ is increasing. Then the injectivity implies that $g$ is strictly increasing.

We claim that for every $x\in(0,1)$ we have $g(0)\leq g(x)\leq g(1)$. Suppose the claim is true. Then for every $0< x< y< 1$ we have $g(0)\leq g(y)\leq g(1)$. Applying the claim to the interval $[0,y]$ shows $g(0)\leq g(x)\leq g(y)$. So $f$ is increasing.

Let us prove the claim. Suppose the claim is not true. Then there is $x\in (0,1)$ such that either $g(0)\leq g(1)<g(x)$ or $g(x)< g(0)\leq g(1)$. In the first case, by intermediate value theorem (applied to $f|_{[0,x]}$), there is $p\in [0,x]$ such that $g(p)=g(1)$. So $g$ is not injective since $p<1$. This is impossible. Similarly, the second case is also impossible.
\end{proof}





Besides monotonicity, the uniqueness of antiderivatives is another classical application of MVT.

\begin{df}
An \textbf{antiderivative} \index{00@Antiderivative} of a function $f:E\rightarrow V$ is a differentiable function $g:E\rightarrow V$ satisfying $g'=f$ on $E$.
\end{df}

The renowned fact that any two antiderivatives $g_1,g_2$ of $f:[a,b]\rightarrow V$ differ by a constant is immediate from the following fact (applied to $g_1-g_2$):

\begin{co}\label{lb326}
Suppose that $f\in C([a,b],V)$ is differentiable on $(a,b)$ and satisfies $f'=0$ on $(a,b)$. Then $f$ is a constant function.
\end{co}

\begin{proof}[Proof for $V=\Fbb^N$]
Since $\Cbb^N\simeq\Rbb^{2N}$, it suffices to prove the case $V=\Rbb^N$. Since a sequence in $\Rbb^N$ converges to a vector iff each component of the sequence converges to the corresponding component of the vector, it suffices to prove the case $f:[a,b]\rightarrow\Rbb$.  

Choose any $x\in(a,b]$. By Lagrange's MVT, there exists $y\in(a,x)$ such that $\dps 0=f'(y)=\frac{f(x)-f(a)}{x-a}$. This proves $f(x)=f(a)$ for all $x\in(a,b]$.
\end{proof}


Now we discuss the general case. 

\begin{rem}\label{lb560}
When $V$ is not necessarily finite-dimensional, the method of reducing Cor. \ref{lb326} to the case of scalar-valued functions is quite subtle: How should we understand the ``components" of an element $v$ in the Banach space $V$? In fact, in the general case, we should view \index{zz@$\bk{\varphi,v}\equiv\bk{v,\varphi}:=\varphi(v)$}
\begin{align}
\bk{\varphi,v}\equiv\bk{v,\varphi}\xlongequal{\mathrm{def}}\varphi(v)
\end{align}
as a component of $v$, where $\varphi$ is an element inside the \textbf{dual (Banach) space} \index{00@Dual (Banach) space} of $V$, defined by \index{V@$V^*$}
\begin{align}
V^*=\fk L(V,\Fbb)
\end{align}
An element $\varphi$ in $V^*$ is called a \textbf{bounded linear functional} on $V$. \index{00@Bounded linear functional} (In general, a \textbf{linear functional} \index{00@Linear functional} on a vector space $W$ over a field $\Kbb$ is simply a linear map $W\rightarrow\Kbb$.)
\end{rem}


The vector space $V^*$, equipped with the operator norm, is indeed a Banach space. (This is why we call $V^*$ the dual \textit{Banach} space.) For the moment we do not need this fact. And we will discuss this topic in a later chapter.



\begin{rem}\label{lb393}
In the future, we will prove that $V^*$ separates points of $V$. (Recall Def. \ref{lb327}.) By linearity, this is equivalent to saying that for any $v\in V$ we have
\begin{align}\label{eq115}
v=0\qquad\Longleftrightarrow\qquad\bk{\varphi,v}=0\text{ for all }\varphi\in V^*
\end{align}
In fact, in the future we will prove the famous \textbf{Hahn-Banach extension theorem}, which implies (cf. Cor. \ref{lb502}) that if $v\in V$ then
\begin{align}
\exists \varphi\in V^*\setminus\{0\}\qquad\text{such that}\qquad\bk{\varphi,v}=\Vert\varphi\Vert\cdot\Vert v\Vert \label{eq116}
\end{align}
where $\Vert\varphi\Vert$ is the operator norm of $\varphi$. (Note that, by Rem. \ref{lb372}, we have $|\bk{\varphi,v}|\leq\Vert\varphi\Vert\cdot\Vert v\Vert$ for all $v\in V,\varphi\in V^*$. It is nontrivial that ``$\leq$" can be ``$=$" for some $\varphi\neq0$.) 
\end{rem}











\begin{proof}[\textbf{Proof of Cor. \ref{lb326} assuming Hahn-Banach}]
Let us prove that $f(x)=f(a)$ for any $x\in[a,b]$. Since $V^*$ separates points of $V$, it suffices to choose an arbitrary $\varphi\in V^*$ and prove that $\varphi\circ f(x)=\varphi\circ f(a)$. Indeed,  since $\varphi$ is continuous, for each sequence $(x_n)$ in $[a,b]\setminus\{x\}$ converging to $x$, in view of Lem. \ref{lb322} we have
\begin{align*}
\lim_{n\rightarrow\infty}\frac{\varphi\circ f(x_n)-\varphi\circ f(x)}{x_n-x}=\varphi\Big(\lim_{n\rightarrow\infty}\frac{f(x_n)-f(x)}{x_n-x}\Big)=\varphi(f'(x))=\varphi(0)=0
\end{align*}
if $a<x<b$. Thus $(\varphi\circ f)'=0$ on $(a,b)$. Therefore, by the finite-dimensional version of Cor. \ref{lb326}, we have that $\varphi\circ f$ is constant on $[a,b]$.
\end{proof}




Hahn-Banach theorem is extremely useful for reducing a problem about vector-valued functions to one about scalar-valued functions. In this course, we will also use Hahn-Banach to prove another fun fact: every Banach space over $\Fbb$ is isormorphic to a closed linear subspace of $C(X,\Fbb)$ where $X$ is a compact Hausdorff space. However, in the following section we would like to give an elementary proof of Cor. \ref{lb326} without using Hahn-Banach. 



\subsection{Finite-increment theorem}

Fix a Banach space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$. Assume $-\infty<a<b<+\infty$.

Cor. \ref{lb326} follows immediately from the following theorem by taking $g=0$.


\begin{thm}[]\label{lb329}
Suppose that $f\in C([a,b],V)$ and $g\in C([a,b],\Rbb)$ are differentiable on $(a,b)$. Assume that for every $x\in(a,b)$ we have $\Vert f'(x)\Vert\leq g'(x)$. Then
\begin{align}
\Vert f(b)-f(a)\Vert\leq g(b)-g(a)  \label{eq124}
\end{align}
\end{thm}





\begin{proof}
By continuity, it suffices to prove $\Vert f(\beta)-f(\alpha)\Vert\leq g(\beta)-g(\alpha)$ for all $\alpha,\beta$ satisfying $a<\alpha<\beta<b$. Therefore, by replacing $[a,b]$ by $[\alpha,\beta]$, it suffices to assume that $f,g$ are differentiable on $[a,b]$.\\[-1ex]

Step 1. For each $\eps>0$, consider the condition on $x\in[a,b]$:
\begin{align}
\Vert f(x)-f(a)\Vert\leq g(x)-g(a)+\eps(x-a)\label{eq121}
\end{align}
The set
\begin{align*}
E_\eps=\big\{x\in[a,b]:x\text{ satisfies \eqref{eq121}}\big\}
\end{align*}
is nonempty because $a\in E_\eps$. One checks easily that $E_\eps$ is a closed subset of $[a,b]$: This is because, for example, $E_\eps$ is the inverse image of the closed subset $(-\infty,0]$ of $\Rbb$ under the map
\begin{gather}
[a,b]\rightarrow\Rbb\qquad x\mapsto \Vert f(x)-f(a)\Vert- g(x)+g(a)-\eps(x-a)  \label{eq122}
\end{gather}
We now fix $x=\sup E_\eps$. Then $x\in E_\eps$ because $E_\eps$ is closed. We shall prove that $x=b$. Then the fact that $b\in E_\eps$ for all $\eps>0$ proves \eqref{eq124}.\\[-1ex]


Step 2. Suppose that $x\neq b$. Then $a\leq x<b$. We shall prove that there exists $y\in(x,b)$ such that
\begin{align}
\Vert f(y)-f(x)\Vert\leq g(y)-g(x)+\eps(y-x) \label{eq123}
\end{align}
Add this inequality to \eqref{eq121} (which holds because $x\in E_\eps$). Then by triangle inequality, we obtain $y\in E_\eps$, contradicting $x=\sup E_\eps$.


Let us prove the existence of such $y$. For each $y\in (x,b)$, define $v(y)\in V,\lambda(y)\in\Rbb$ such that
\begin{gather*}
f(y)-f(x)=f'(x)(y-x)+v(y)(y-x)\\
g(y)-g(x)=g'(x)(y-x)+\lambda(y)(y-x)
\end{gather*}
The definition of $f'(x)$ and $g'(x)$ implies that $v(y)\rightarrow0$ and $\lambda(y)\rightarrow0$ as $y\rightarrow x$. Therefore, there exists $y\in(x,b)$ such that $\Vert v(u)\Vert<\eps/2$ and $|\lambda(y)|<\eps/2$. Thus
\begin{align*}
&\Vert f(y)-f(x)\Vert-(g(y)-g(x))\nonumber\\
\leq&(\Vert f'(x)\Vert-g'(x)) (y-x)+(\Vert v(y)\Vert-\lambda(y))\cdot (y-x)\nonumber\\
\leq&0\cdot(y-x)+\big(\frac\eps2+\frac\eps2\big)\cdot(y-x)=\eps(y-x)
\end{align*}
This proves \eqref{eq123}.
\end{proof}


\begin{rem}
If we apply Thm. \ref{lb329} to the special case that $f=0$, we see that if $g\in C([a,b],\Rbb)$ satisfies $g'\geq0$ on $(a,b)$, then $g$ is increasing. This gives another proof of \eqref{eq114} besides the one via Lagrange's MVT.
\end{rem}


An important special case of Thm. \ref{lb329} is:

\begin{co}[\textbf{Finite-increment theorem}] \index{00@Finite-increment theorem}\label{lb333}
Suppose that $f\in C([a,b],V)$ is differentiable on $(a,b)$, and that there exists $M\in\Rbb_{\geq0}$ such that $\Vert f'(x)\Vert\leq M$ for all $x\in(a,b)$. Then
\begin{align}
\Vert f(b)-f(a)\Vert\leq M|b-a|
\end{align}
\end{co}

\begin{proof}
Choose $g(x)=Mx$ in Thm. \ref{lb329}.
\end{proof}

It is fairly easy to prove finite-increment theorem for complex-variable functions.

\begin{df}\label{lb364}
A subset $E$ of a real vector space is called \textbf{convex}, \index{00@Convex set} if for every $x,y\in E$, the interval \index{00@Interval $[x,y]$ in a real vector space}
\begin{align}
[x,y]=\{tx+(1-t)y:t\in[0,1]\}
\end{align}
is a subset of $E$.
\end{df}

When talking about convex subsets of $\Cbb$, we view $\Cbb$ as $\Rbb^2$. Then, for example, all open disks in $\Cbb$ are convex.

\begin{co}[\textbf{Finite-increment theorem}]\index{00@Finite-increment theorem}\label{lb335}
Assume $\Fbb=\Cbb$. Let $\Omega$ be a nonempty open convex subset of $\Cbb$. Let $f:\Omega\rightarrow V$ be differentiable on $\Omega$. Choose any $z_1,z_2\in\Omega$. Suppose that there exists $M\in\Rbb_{\geq0}$ such that $\Vert f'(z)\Vert\leq M$ for all $z$ in the interval $[z_1,z_2]$. Then 
\begin{align}
\Vert f(z_2)-f(z_1)\Vert\leq M|z_2-z_1|
\end{align}
\end{co}

\begin{proof}
Define $\gamma:[0,1]\rightarrow \Cbb$ by $\gamma(t)=(1-t)z_1+tz_2$. Then $\gamma([0,1])\subset\Omega$ because $\Omega$ is convex. By chain rule (Thm. \ref{lb331}), we have
\begin{align*}
(f\circ\gamma)'(t)=f'(\gamma(t))\cdot \gamma'(t)=(z_2-z_1)f'(\gamma(t))
\end{align*}
whose norm is bounded by $M|z_2-z_1|$. Applying Cor. \ref{lb333} to $f\circ\gamma$ finishes the proof.
\end{proof}





\begin{eg}
Let $X$ be an interval in $\Rbb$, or let $X=\Omega$ where $\Omega$ is convex. Let $\scr A$ be the set of differentiable functions $f:\Omega\rightarrow V$ satisfying $\Vert f'\Vert_{l^\infty}\leq M$. Then elements of $\scr A$ have Lipschitz constant $M$ by Finite-increment theorems. So $\scr A$ is equicontinuous.
\end{eg}







\subsection{Commutativity of derivatives and limits}

Fix a Banach space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$. Let $\Omega$ be a nonempty open subset of $\Cbb$. Recall Conv. \ref{lb332}. Recall Def. \ref{lb334} for the meaning of locally uniform convergence.


\subsubsection{Main theorem}




\begin{thm}\label{lb336}
Let $X$ be $\Omega$ or an interval in $\Rbb$. Let $(f_\alpha)_{\alpha\in I}$ be a net of differentiable functions $X\rightarrow V$. Suppose that the following are true:
\begin{enumerate}[label=(\alph*)]
\item The net $(f_\alpha)_{\alpha\in I}$ converges pointwise to some $f:X\rightarrow V$.
\item The net $(f_\alpha')_{\alpha\in I}$ converges uniformly to some $g:X\rightarrow V$. 
\end{enumerate}
Then $f$ is differentiable on $X$, and $f'=g$.
\end{thm}


\begin{proof}
We prove the case $X=\Omega$. The other case is similar. Choose any $z\in \Omega$. By shrinking $\Omega$, we assume that $\Omega$ is an open disk centered at $z$. We know $\lim_{w\rightarrow z}\frac{f_\alpha(w)-f_\alpha(z)}{w-z}$ converges to $f_\alpha'(z)$ for each $\alpha$. Therefore, if we can show that $\frac{f_\alpha(w)-f_\alpha(z)}{w-z}$ converges uniformly (over all $w\in \Omega\setminus\{z\}$) under $\lim_\alpha$, then it must converge uniformly to $\frac{f(w)-f(z)}{w-z}$ since it converges pointwise to $\frac{f(w)-f(z)}{w-z}$ by (a). Then, by Moore-Osgood Thm. \ref{lb289}, we have
\begin{align*}
\lim_{w\rightarrow z}\lim_\alpha\frac{f_\alpha(w)-f_\alpha(z)}{w-z}=\lim_\alpha\lim_{w\rightarrow z}\frac{f_\alpha(w)-f_\alpha(z)}{w-z}=\lim_\alpha f_\alpha'(z)=g(z)
\end{align*}
finishing the proof.

To prove the uniform convergence, by the Cauchy condition on $V^{\Omega\setminus\{z\}}$ (equipped with a complete uniform convergence metric as in Exp. \ref{lb272}), it suffices to prove that
\begin{align}\label{eq126}
\sup_{w\in\Omega\setminus\{z\}}\Big\Vert \frac{f_\alpha(w)-f_\alpha(z)}{w-z}-\frac{f_\beta(w)-f_\beta(z)}{w-z}\Big\Vert
\end{align}
converges to $0$ under $\lim_{\alpha,\beta\in I}$. Applying Cor. \ref{lb335} to the function $f_\alpha-f_\beta$, we see
\begin{align}
&\Vert f_\alpha(w)-f_\beta(w)-f_\alpha(z)+f_\beta(z)\Vert\leq |w-z|\cdot\sup_{\zeta\in[z,w]} \Vert f_\alpha'(\zeta)-f_\beta'(\zeta)\Vert\nonumber\\
\leq&|w-z|\cdot \Vert f_\alpha'-f_\beta'\Vert_{l^\infty(\Omega,V)}\label{eq127}
\end{align}
Thus, we have 
\begin{align*}
\eqref{eq126}\leq \Vert f_\alpha'-f_\beta'\Vert_{l^\infty(\Omega,V)}
\end{align*}
where the RHS converges to $0$ under $\lim_{\alpha,\beta}$ due to (b). This finishes the proof.
\end{proof}


We didn't assume the uniform convergence of $(f_\alpha)$ in Thm. \ref{lb336} because it is often redundant:

\begin{lm}\label{lb343}
Assume that either $X$ is a bounded interval in $\Rbb$, or $X=\Omega$ where $\Omega$ is assumed to be bounded and convex. Then under the assumptions in Thm. \ref{lb336}, the net $(f_\alpha)_{\alpha\in I}$ converges uniformly to $f$. 
\end{lm}




\begin{proof}
We already know that $(f_\alpha)$ converges pointwise to $f$. In fact, we shall only use the fact that $\lim_\alpha f_\alpha(z)=f(z)$  for some $z\in X$. Let $z$ be such a point. Motivated by the proof of Thm. \ref{lb336}, let us prove  the Cauchy condition that
\begin{align*}
\lim_{\alpha,\beta\in I}\sup_{w\in\Omega}\Vert f_\alpha(w)-f_\beta(w)-f_\alpha(z)+f_\beta(z)\Vert=0
\end{align*}
Then $(f_\alpha-f_\alpha(z))$ converges uniformly, and hence $(f_\alpha)$ converges uniformly. Indeed, the Cauchy condition follows easily from \eqref{eq127}, in which $\sup_{w\in\Omega}|w-z|$ is a finite number because $X$ is bounded.
\end{proof}


Thus, whether or not $\Omega$ satisfies boundedness and convexity, the net $(f_\alpha)$ must converge locally uniformly to $f$. Knowing the locally uniform convergence is often enough for applications. And here is another proof of this fact:

\begin{proof}[\textbf{Another proof} that $(f_\alpha)$ converges locally uniformly to $f$]
We consider the case $X=\Omega$; the other case is similar. For each $z\in X$, choose a convex precompact $U\in\Nbh_X(x)$. (Namely, $\Cl_X(U)$ is compact.) By (b) of Thm. \ref{lb336}, there is $\mu\in I$ such that $\sup_{x\in\ovl U}\Vert f_\alpha'(x)-f_\mu'(x)\Vert\leq 1$ for all $\alpha\geq\mu$. Let $h_\alpha=f_\alpha-f_\mu$, and replace $I$ by $I_{\geq\mu}$. By finite-increment Thm. \ref{lb335}, for each $x,y\in U$ we have
\begin{align*}
\Vert h_\alpha(x)-h_\alpha(y)\Vert\leq \Vert x-y\Vert
\end{align*}
i.e., $(h_\alpha|_U)_{\alpha\in I}$ has uniform Lipschitz constant $1$, and hence is an equicontinuous set of functions. Choose a closed ball $B$ centered at $z$ such that $B\subset U$. Then, since $(h_\alpha|_B)_{\alpha\in I}$ is equicontinuous and converges pointwise to $f-f_\mu$ (on $B$), by Cor. \ref{lb284}, $(f_\alpha-f_\mu)_{\alpha\in I}$ converges uniformly on $B$ to $f-f_\mu$. Thus $f_\alpha$ converges uniformly on $B$ to $f$.
\end{proof}



\subsubsection{An interpretation of Thm. \ref{lb336} in terms of Banach spaces}


We give a more concise way of understanding the two conditions in Thm. \ref{lb336}.


\begin{co}\label{lb344}
Let $X$ be $\Omega$ or an interval in $\Rbb$. Define \index{l1@$l^{1,\infty}$}
\begin{align*}
l^{1,\infty}(X,V)=\{f\in V^X: f\text{ is differentiable on }X\text{ and }\Vert f\Vert_{l^{1,\infty}}<+\infty\}
\end{align*}
where $\Vert \cdot\Vert_{l^{1,\infty}}=\Vert\cdot\Vert_{1,\infty}$ is defined by 
\begin{align*}
\Vert f\Vert_{1,\infty}=\Vert f\Vert_{l^\infty}+\Vert f'\Vert_{l^\infty}=\sup_{x\in X}\Vert f(x)\Vert+\sup_{x\in X}\Vert f'(x)\Vert
\end{align*}
Then $l^{1,\infty}(X,V)$ is a Banach space with norm $\Vert\cdot\Vert_{1,\infty}.$
\end{co}


\begin{proof}
It is a routine check that $\Vert f\Vert_{l^{1,\infty}}$ defines a norm on ${l^{1,\infty}}(X,V)$. We now prove that ${l^{1,\infty}}(X,V)$ is complete. Let $(f_n)$ be a Cauchy sequence in ${l^{1,\infty}}(X,V)$. So $(f_n)$ and $(f_n')$ are Cauchy sequences in $l^\infty$, converging uniformly to $f,g\in V^X$ respectively. By Lem. \ref{lb336}, $f$ is differentiable, and $f'=g$. (In particular, $\Vert f'\Vert_\infty<+\infty$.) So $f_n'\rightrightarrows f'$. Thus
\begin{align*}
\Vert f_n-f\Vert_{1,\infty}=\Vert f_n-f\Vert_\infty+\Vert f_n'-f'\Vert_\infty\rightarrow 0
\end{align*} 
\end{proof}


\begin{rem}
Thm. \ref{lb336} and Cor. \ref{lb344} are almost equivalent. We have proved Cor. \ref{lb344} using Thm. \ref{lb336}. But we can also prove a slightly weaker version of Thm. \ref{lb336} using Cor. \ref{lb344} as follows: In the setting of Thm. \ref{lb336}, assume that each $f_\alpha:X\rightarrow V$ is differentiable, and that 
\begin{align}\label{eq128}
f_\alpha\rightrightarrows f\qquad f_\alpha'\rightrightarrows g
\end{align}
where $f,g\in l^\infty(X,V)$. Then  Cor. \ref{lb344} implies that $f$ is differentiable and $f'=g$. 
\end{rem}


\begin{proof}[$\star$ Proof]
By \eqref{eq128}, there is $\beta\in I$ such that $\Vert f_\alpha-f\Vert_\infty<+\infty$ and $\Vert f_\alpha'-g\Vert<+\infty$ for all $\alpha\geq\beta$. Thus, by replacing $I$ with $I_\beta$, we assume that $f_\alpha$ and $f_\alpha'$ are bounded on $X$. So $f_\alpha\in l^{1,\infty}(X,V)$. 

By \eqref{eq128}, both $(f_\alpha)$ and $(f'_\alpha)$ converge in $l^\infty(X,V)$. So they are Cauchy nets under the $l^\infty$-norm. So $(f_\alpha)$ is a Cauchy net in $l^{1,\infty}(X,V)$. By Cor. \ref{lb344}, $(f_\alpha)$ converges to $\wtd f\in l^{1,\infty}(X,V)$ under the $l^{1,\infty}$ norm. In particular, $f_\alpha\rightrightarrows \wtd f$ and $f_\alpha'\rightrightarrows \wtd f'$. Since, by assumption, we have $f_\alpha\rightrightarrows f$ and $f_\alpha'\rightrightarrows g$, we therefore get $f=\wtd f$ and $g=\wtd f'$.
\end{proof}



It is not surprising that Thm. \ref{lb336} can be rephrased in terms of the completeness of a normed vector space. After all, our proof of Thm. \ref{lb336} uses Cauchy nets in an essential way. In the future, we will use the completeness of $l^{1,\infty}$ to understand the commutativity of derivatives and other limit processes. 








\subsection{Derivatives of power series}


This section is a continuation of the previous one. We shall use Thm. \ref{lb336} to compute derivatives of power series.



\subsubsection{General result}


\begin{co}\label{lb338}
Assume that $V$ is over $\Cbb$. Let $f(z)=\sum_{n=0}^\infty v_nz^n$ be a power series in $V$. Assume that its radius of convergence is $R>0$. Then $f$ is differentiable on $B_\Cbb(0,R)$ and
\begin{align*}
f'(z)=\sum_{n=0}^\infty nv_nz^{n-1} 
\end{align*}
\end{co}

Note that since $\lim_n\sqrt[n]{n}=1$, $(\sqrt[n]{\Vert v_n\Vert})_{n\in\Zbb_+}$ and $(\sqrt[n]{n\Vert v_n\Vert})_{n\in\Zbb_+}$ have the same cluster points. Therefore
\begin{align}
\limsup_{n\rightarrow\infty}\sqrt[n]{\Vert v_n\Vert}=\limsup_{n\rightarrow\infty}\sqrt[n]{n\Vert v_n\Vert}
\end{align}
So $\sum v_nz^n$ and $\sum_{n=0}^\infty nv_nz^{n-1}$ have the same radius of convergence.

\begin{proof}[First proof]
For each $n\in\Nbb_+$, let $g_n(z)=v_0+v_1z+\cdots+v_nz^n$. Then by Thm. \ref{lb112}, for each $0<r<R$, the sequences $(g_n)$ (resp. $(g_n')$) converges uniformly to $f$ (resp. converges uniformly to $h(z)=\sum_0^\infty nv_nz^{n-1}$) on $B_\Cbb(0,r)$. Therefore, by Thm. \ref{lb336}, we have $f'(z)=h(z)$ for all $z\in B_\Cbb(0,r)$, and hence all $z\in B_\Cbb(0,R)$ since $r$ is arbitrary.
\end{proof}

\begin{proof}[Second proof]
Choose any $0<r<R$, and let $X_r=B_\Cbb(0,r)$. Consider $\sum v_n z^n$ as a series in the Banach space $l^{1,\infty}(X_r,\Cbb)$ (cf. Cor. \ref{lb344}). The norm of each term is $\Vert v_n\Vert+(n+1)\Vert v_{n+1}\Vert$. So the radius of convergence is $R$. Thus  $\sum v_n z^n$ converges in $l^{1,\infty}(X_r,\Cbb)$ to some $g\in l^{1,\infty}(X_r,\Cbb)$. This means that, on $X_r$, $\sum v_nz^n$ converges uniformly to $g$ (and hence $f=g$ on $X_r$) and $\sum nv_nz^{n-1}$ converges uniformly  to $g'$. So $f'(z)=g'(z)=\sum nv_nz^{n-1}$ for all $z\in X_r$.
\end{proof}



\subsubsection{Examples}\label{lb353}

\begin{eg}
By Cor. \ref{lb338}, the function $\exp:\Cbb\rightarrow\Cbb$ is differentiable, and
\begin{align*}
\frac d{dz}e^z=e^z
\end{align*}
Thus, if $\gamma:[a,b]\rightarrow\Cbb$ is differentiable, then by chain rule, $\exp\circ\gamma$ is differentiable on $[a,b]$, and
\begin{align*}
\frac d{dt}e^{\gamma(t)}=e^{\gamma(t)}\cdot \frac d{dt}\gamma(t)
\end{align*}
For example:
\begin{align*}
(e^{\alpha t})'=\alpha e^{\alpha t}\qquad (e^{t^2+\im t})'=(2t+\im)e^{t^2+\im t}
\end{align*}
\end{eg}


\begin{eg}
Define functions $\sin:\Cbb\rightarrow\Cbb$ and $\cos:\Cbb\rightarrow\Cbb$ \index{sincos@$\sin,\cos$} by
\begin{gather*}
\cos z=\frac {e^{\im z}+e^{-\im z}}2\qquad \sin z=\frac{e^{\im z}-e^{-\im z}}{2\im}
\end{gather*}
It follows from $e^ze^w=e^{z+w}$ that
\begin{align}
\cos(z+w)=\cos z\cos w-\sin z\sin w\qquad \sin(z+w)=\sin z\cos w+\cos z\sin w  \label{eq138}
\end{align}
By chain rule, we have $(e^{\alpha z})'=\alpha e^{\alpha z}$. So
\begin{gather*}
\sin'z=\cos z\qquad \cos' z=-\sin z
\end{gather*}
\end{eg}


%% Record #15 2023/11/8 three lectures  37

\begin{rem}
From $e^z=\sum_{n\in\Nbb}z^n/n!$, it is clear that the complex conjugate of $e^z$ is 
\begin{align*}
\ovl{e^z}=\ovl{\sum_{n=0}^\infty\frac {z^n}{n!}}=\sum_{n=0}^\infty\frac {\ovl z^n}{n!}=e^{\ovl z}
\end{align*}
Here, we have exchanged the order of conjugate and infinite sum, because the function $z\in\Cbb\mapsto \ovl z$ is continuous. Thus, if $t\in\Rbb$, then
\begin{align*}
\ovl{e^{\im t}}=e^{-\im t}\qquad |e^{\im t}|^2=\ovl{e^{\im t}} e^{\im t}=e^{-\im t}e^{\im t}=1
\end{align*}
It follows that
\begin{gather*}
\cos t=\Real(e^{\im t})\qquad\sin t=\Imag(e^{\im t})\\
(\cos t)^2+(\sin t)^2=(\Real(e^{\im t}))^2+(\Imag(e^{\im t}))^2=|e^{\im t}|^2=1
\end{gather*}
It also follows from $|e^{\im t}|=1$ that if $a,b\in\Rbb$ then, by $e^{a+b\im}=e^ae^{b\im}$, we have
\begin{align*}
e^{a+b\im}=e^a\qquad\in\Rbb_{>0}
\end{align*}
\end{rem}





\begin{eg}
By Prop. \ref{lb337}, the function $\log:\Rbb_{>0}\rightarrow\Rbb$ is differentiable, and
\begin{align*}
(\log x)'=\frac 1x
\end{align*}
\end{eg}

\begin{eg}
We have 
\begin{align*}
\lim_{t\rightarrow 0}\frac{\log(1+t)}t=(\log x)'|_{x=1}=1
\end{align*}
and hence $\lim_{x\rightarrow +\infty}x\log(1+1/x)=1$ by Def. \ref{lb197}-(3) (since $\lim_{x\rightarrow+\infty}1/x=0$ as a net limit). Taking exponential, and using the continuity of $\exp$ at $1$, we get 
\begin{align*}
\lim_{x\rightarrow+\infty}\Big(1+\frac 1x\Big)^x=e
\end{align*} 
\end{eg}




\begin{eg}
If $a>0$ and $z\in\Cbb$, recalling $a^z=e^{z\log a}$, we use chain rule to find
\begin{align*}
\frac d{dz}a^z=a^z\log a
\end{align*}
Similarly, if $\alpha\in\Cbb$ and $x>0$, then the chain rule gives the derivative of $x^\alpha$:
\begin{align*}
\frac d{dx}x^\alpha=\alpha\cdot x^{\alpha-1}
\end{align*}
\end{eg}



\begin{eg}
Compute $\dps\sum_{n=0}^\infty \frac {n^2}{3^n}$
\end{eg}


\begin{proof}
The series $\dps f(z)=\sum_{n=0}^\infty \frac{z^n}{3^n}$ has radius of convergence $3$. When $|z|<3$, it converges absolutely to $(1-\frac z3)^{-1}=3(3-z)^{-1}$. So, by Cor. \ref{lb338}, when $|z|<3$ we have
\begin{gather*}
    \sum_{n=0}^\infty \frac{nz^{n-1}}{3^n}=f'(z)=3(3-z)^{-2}\\
    \sum_{n=0}^\infty \frac{n(n-1)z^{n-2}}{3^n}=f''(z)=6(3-z)^{-3}
\end{gather*}
So the value of the original series equals
\begin{align*}
f''(1)+f'(1)=\frac 32
\end{align*}
\end{proof}


\subsubsection{A proof of (generalized) Leibniz rule}



We end this section by giving a fun proof of Leibniz rule for higher derivatives. For simplicity, we consider only scalar-valued functions.



\begin{pp}[\textbf{Leibniz rule}] \index{00@Leibniz rule}  \label{lb348}
Let $X$ be either a nonempty interval in $\Rbb$ (resp. a nonempty open subset of $\Cbb$). Let $f,g$ be functions from $X$ to $\Rbb$ (resp. to $\Cbb$). Let $z\in X$. Suppose that $f^{(n)}(z)$ and $g^{(n)}(z)$ exist. Then
\begin{align}
(fg)^{(n)}(z)=\sum_{j=0}^n {n\choose j}f^{(n-j)}(z)g^{(j)}(z)
\end{align}
\end{pp}




The above Leibniz rule is usually proved using the formula
\begin{align}
{n+1\choose j}={n\choose j-1}+{n\choose j}
\end{align}
where $n\in\Nbb$ and $1\leq j\leq n$. In the following, we give a proof without using this formula. We need the fact that the function
\begin{align}
\Cbb^n\rightarrow C(\Rbb,\Cbb)\qquad  (a_0,\dots,a_{n-1})\mapsto p(x)=\sum_{j=0}^{n-1}a_jx^j  \label{eq133}
\end{align}
is injective: this is because $j!\cdot a_j=f^{(j)}(0)$ by Exp. \ref{lb323}.



\begin{proof}[\textbf{Proof of Prop. \ref{lb348}}]
By induction on $n$ and by the classical Leibniz rule (Prop. \ref{lb320}), we have
\begin{align}
(fg)^{(n)}(z)=\sum_{j=0}^n C_{n,j}\cdot f^{(n-j)}(z)g^{(j)}(z) \label{eq132}
\end{align}
where each $C_{n,j}$ is an integer independent of $f$ and $g$. (In particular, $C_{n,j}$ is independent of whether the variables are real of complex.) Thus, to determine the value of $C_{n,j}$, we can use some special functions. 

We consider $f(x)=e^{s x}$ and $g(x)=e^{t x}$ where $s,t\in\Rbb$. Recall that we have proved that $(e^{\alpha t})'=\alpha e^{\alpha t}$ using chain rule and the derivative formula for exponentials. So \eqref{eq132} reads
\begin{align*}
(s+t)^n\cdot e^{(s+t)x}=\sum_{j=0}^n C_{n,j}\cdot s^{n-j}t^{j}\cdot e^{(s+t)x}
\end{align*}
Taking $x=0$ gives
\begin{align}
(s+t)^n=\sum_{j=0}^n C_{n,j}\cdot s^{n-j}t^j  \label{eq135}
\end{align}
Comparing this with the binomial formula \eqref{eq60}, and noticing the injectivity of  \eqref{eq133} (first applied to \eqref{eq135} for each fixed $t$, where \eqref{eq135} is viewed as a polynomial of $s$; then applied to each coefficient before $s^{n-j}$, which is a polynomial of $t$), we immediately get $C_{n,j}={n\choose j}$.
\end{proof}




\begin{comment}
\begin{rem}
By induction on $k$, one easily proves
\begin{align}
(z_1+\cdots+z_k)^n=\sum_{j_1+\cdots+j_k=n}{n\choose j_1,\dots,j_k}z_1^{j_1}\cdots z_k^{j_k}
\end{align}
where
\begin{align}
{n\choose j_1,\dots,j_k}=\frac{n!}{j_1!\cdots j_k!}
\end{align}
is the \textbf{multinomial coefficient}. Then, the same method as above proves
\begin{align}
(f_1\cdots f_k)^{(n)}=\sum_{j_1+\cdots+j_k=n}{n\choose j_1,\dots,j_k} f_1^{(j_1)}\cdots f_k^{(j_k)}
\end{align}
\end{rem}
\end{comment}

















\subsection{Problems and supplementary material}


Let $\Omega$ be nonempty open subset of $\Cbb$. Let $V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$. Assume that $\Fbb=\Cbb$ if we take derivatives with respect to complex variables.


\begin{df}\label{lb354}
Let $X$ be either $\Omega$ or an interval in $\Rbb$. Define \index{Cn@$C^n(X,V)$} \index{C@$C^\infty$}
\begin{gather*}
C^n(X,V)=\{f\in V^X:f,f',\dots,f^{(n)}\text{ exist and are continuous}\}\qquad (\text{if }n\in\Nbb)\\
C^\infty(X,V)=\bigcap_{n\in\Nbb}C^n(X,V)
\end{gather*}
If $X\subset\Rbb$, elements in $C^\infty(X,V)$ are called \textbf{smooth functions}. \index{00@Smooth functions}
\end{df}


\begin{prob}\label{lb355}
Let $X$ be either $\Omega$ or an interval in $\Rbb$. For each $n\in\Nbb$, define \index{ln@$l^{n,\infty}$}
\begin{align*}
l^{n,\infty}(X,V)=\{f\in V^X:f,f',\dots,f^{(n)}\text{ exist, and }\Vert f\Vert_{n,\infty}<+\infty\}
\end{align*}
where $\Vert f\Vert_{n,\infty}=\Vert f\Vert_{l^{n,\infty}}$ is defined by
\begin{align*}
\Vert f\Vert_{n,\infty}=\Vert f\Vert_\infty+\Vert f'\Vert_\infty+\cdots+\Vert f^{(n)}\Vert_\infty
\end{align*}
(In particular, we understand $l^{0,\infty}$ as $l^\infty$.) Clearly $\Vert\cdot\Vert_{n,\infty}$ is a norm. We have proved that $l^{n,\infty}(X,V)$ is complete when $n=0,1$. 
\begin{enumerate}
\item Prove by induction on $n$ that $l^{n,\infty}(X,V)$ is complete for every $n$.
\item Prove that for each $n\in\Nbb$, $C^n(X,V)\cap l^{n,\infty}(X,V)$ is a closed subset of $l^{n,\infty}(X,V)$ (and hence, is a Banach space by Prop. \ref{lb86}).  Prove that if $X$ is compact then $C^n(X,V)\subset l^{n,\infty}(X,V)$.
\end{enumerate}
\end{prob}







\begin{cv}
Unless otherwise stated, when $X$ is compact, we always choose $l^{n,\infty}$ to be the norm on $C^n(X,V)$.
\end{cv}








\newpage




\section{More on derivatives}

\subsection{Cauchy's MVT and L'H\^opital's rule}


The goal of this section is to prove L'H\^opital's rule. For that purpose, we first need to prove Cauchy's MVT.



\subsubsection{Main theorems}




\begin{thm}[\textbf{Cauchy's MVT}] \index{00@Cauchy's MVT}
Let $-\infty<a<b<+\infty$. Let $f,g\in C([a,b],\Rbb)$ be differentiable on $(a,b)$. Then there exists $x\in(a,b)$ such that
\begin{align*}
    f'(x) (g(b)-g(a))=g'(x)(f(b)-f(a))
\end{align*}
\end{thm}

In particular, if $g'\neq0$ on $(a,b)$, then $g$ is injective (Cor. \ref{lb424}), and we can write the above formula as
\begin{align*}
\frac{f'(x)}{g'(x)}=\frac{f(b)-f(a)}{g(b)-g(a)}
\end{align*}


\begin{proof}
Cauchy's MVT specializes to Lagrange's MVT if we set $g(x)=x$. Moreover, in the proof of Lagrange's MVT (Thm. \ref{lb345}), we applied Rolle's MVT to the function $f(x)-kx$ where $k$ is the slope of a line segment. Motivated by this observation, we consider the function $\psi(x)=f(x)-kg(x)$. If one wants $\psi(a)=\psi(b)$, one then solves that $k=\frac{f(b)-f(a)}{g(b)-g(a)}$. But we would rather consider $(g(b)-g(a))\psi$ in order to avoid the issue that the denominator is possibly zero. So we set
\begin{align*}
h(x)=(g(b)-g(a))f(x)-(f(b)-f(a))g(x)
\end{align*}
Clearly $h(a)=h(b)$. By Rolle's MVT, there exists $x\in(a,b)$ such that
\begin{align*}
0=h'(x)=(g(b)-g(a))f'(x)-(f(b)-f(a))g'(x)
\end{align*}
\end{proof}








\begin{thm}[\textbf{L'H\^opital's rule}]  \index{00@L'H\^opital's rule}
Let $-\infty\leq a<b\leq+\infty$. Let $f,g\in C((a,b),\Rbb)$ be differentiable on $(a,b)$. Assume that $g'$ is nowhere zero on $(a,b)$. (So $g$ is strictly monotonic, cf. Prop. \ref{lb347}.) Assume 
\begin{align}
\lim_{x\rightarrow a}\frac{f'(x)}{g'(x)}=A\qquad \text{exists in }\ovl\Rbb    \label{eq129}
\end{align}
Assume that one of the following two cases are satisfied:
\begin{gather*}
\lim_{x\rightarrow a}f(x)=\lim_{x\rightarrow a}g(x)=0  \tag{Case $\frac 00$}\\
\lim_{x\rightarrow a}|g(x)|=+\infty \tag{Case $\frac *\infty$}
\end{gather*}
Then we have $\dps\lim_{x\rightarrow a}\frac{f(x)}{g(x)}=A$. The same conclusion holds if ``$x\rightarrow a$" is replaced by ``$x\rightarrow b$".
\end{thm}


\begin{rem}
Since $g$ is strictly monotonic, there is at most one $x\in(a,b)$ such that $g(x)=0$. So $\lim_{x\rightarrow a}f(x)/g(x)$ means the limit over $x\in (a,b)\setminus g^{-1}(0)$. Alternatively, one can assign an arbitrary value to $f(x)/g(x)$ when $g(x)=0$, and understand $\lim_{x\rightarrow a}$ as a limit over $x\in (a,b)$.
\end{rem}


\begin{eg}
Compute $\dps\lim_{x\rightarrow+\infty}\frac{x^n}{e^x}$
\end{eg}

\begin{proof}
By L'H\^opital's rule in the case $\frac *\infty$, we have
\begin{align*}
\lim_{x\rightarrow+\infty}\frac{x^n}{e^x}=\lim_{x\rightarrow+\infty}\frac{nx^{n-1}}{e^x}=\lim_{x\rightarrow+\infty}\frac{n(n-1)x^{n-2}}{e^x}=\cdots=\lim_{x\rightarrow+\infty}\frac{n!}{e^x}=0
\end{align*}
where the convergence of the limit is derived from right to left.
\end{proof}




\subsubsection{Proof of L'H\^opital's rule}\label{lb349}




We divide the proof of L'H\^opital's rule into several steps. Also, we only treat the case $x\rightarrow a$, since the other case is similar. In the following, $(a,b)$ means an interval, but not an element in the Cartesian product (which will be written as $a\times b$).


\begin{proof}[\textbf{Step 1}]
We let $\dps\frac{f(x)-f(y)}{g(x)-g(y)}$ take value $\dps\frac{f'(x)}{g'(x)}$ if $x=y$. In this step, we prove
\begin{align}\label{eq130}
\lim_{x\times y\rightarrow a\times a}~\frac{f(x)-f(y)}{g(x)-g(y)}=A
\end{align}
where $x\times y$ is defined on $(a,b)^2=(a,b)\times (a,b)$. In view of Def. \ref{lb197}-(3m), we pick any sequence $x_n\times y_n$ in $(a,b)^2$. By Cauchy's MVT, there is $\xi_n \in [x_n,y_n]$ (if $x_n\leq y_n$) or $\xi_n\in[y_n,x_n]$ (if $x_n\geq y_n$) such that
\begin{align*}
f'(\xi_n)(g(x_n)-g(y_n))=g'(\xi_n)(f(x_n)-f(y_n)).
\end{align*} 
So we have
\begin{align*}
    \frac{f'(\xi_n)}{g'(\xi_n)}=\frac{f(x_n)-f(y_n)}{g(x_n)-g(y_n)} 
\end{align*}
Since $\lim_n x_n=\lim_n y_n=a$, we clearly have $\lim_n \xi_n=a$.  Therefore, by \eqref{eq129} (this is the only place where we use \eqref{eq129}), we have
\begin{align*}
\lim_{n\rightarrow\infty} \frac{f(x_n)-f(y_n)}{g(x_n)-g(y_n)}=\lim_{n\rightarrow\infty}\frac{f'(\xi_n)}{g'(\xi_n)}=A
\end{align*}
This proves \eqref{eq130}.
\end{proof}





\begin{proof}[\textbf{Step 2}]
It follows from Def. \ref{lb197}-(3) that if $(x_n)$ and $(y_k)$ are sequences in $(a,b)$ converging to $a$, then
\begin{align}
\lim_{n,k\rightarrow\infty} \frac{f(x_n)-f(y_k)}{g(x_n)-g(y_k)}=A \label{eq131}
\end{align}  
In other words, we apply Def. \ref{lb197}-(3) to the net $(x_n\times y_k)_{n\times k\in\Zbb_+^2}$ which replaces the sequence $(x_n\times y_n)_{n\in\Zbb_+}$ in Step 1. We shall use \eqref{eq131} to prove the two cases of L'H\^opital's rule.


Let us prove the case $\frac 00$. This is the easier case. Choose any sequence $(x_n)$ in $(a,b)$ converging to $a$. We want to prove that $\lim_n f(x_n)/g(x_n)=A$. So we choose any sequence $(y_k)$ in $(a,b)$ converging to $a$, and we know that the double limit \eqref{eq131} exists. Moreover, if $n$ is fixed, then $\lim_k f(y_k)=\lim_k g(y_k)=0$ by assumption. Thus
\begin{align}
\lim_{k\rightarrow\infty}\frac{f(x_n)-f(y_k)}{g(x_n)-g(y_k)}=\frac{f(x_n)}{g(x_n)} \label{eq134}
\end{align}
Thus, by Thm. \ref{lb122}, when $n\rightarrow\infty$, the RHS of the above equation converges to \eqref{eq131}. This finishes the proof for the case $\frac 00$.
\end{proof}



\begin{proof}[\textbf{Step 3}]
Finally, we address the (more difficult) case $\frac *\infty$. Assume $\lim_{x\rightarrow a}|g(x)|=+\infty$. Again, we choose a sequence $(x_n)$ in $(a,b)$ converging to $a$. To prove $f(x_n)/g(x_n)\rightarrow A$, one may want to pick any sequence $(y_k)$ in $(a,b)$, and compute the limit on the LHS of \eqref{eq134}. Unfortunately, in this case, we do not know whether this limit converges or not: As one can compute, it is equal to $\lim_{k\rightarrow\infty}f(y_k)/g(y_k)$, whose convergence is part of the result we need to prove!

It is not hard to address this issue: Since $\ovl\Rbb$ is (sequentially) compact, by Thm. \ref{lb74}, it suffices to prove that any cluster point $B\in\ovl\Rbb$ of $(f(x_n)/g(x_n))_{n\in\Zbb_+}$ is equal to $A$. Thus, we let $(y_k)$ be any subsequence of $(x_n)$ such that $(f(y_k)/g(y_k))_{k\in\Zbb_+}$ converges to $B$. Let us prove $A=B$ using the same method as in Step 2. We compute that
\begin{align}
\frac{f(x_n)-f(y_k)}{g(x_n)-g(y_k)}=\frac{g(y_k)}{g(x_n)-g(y_k)}\cdot\frac{f(x_n)-f(y_k)}{g(y_k)}  \label{eq136}
\end{align}
Since $\lim_k |g(y_k)|=+\infty$, we have $\lim_{k\rightarrow\infty}C/g(y_k)\rightarrow 0$ for any $C\in\Rbb$ independent of $k$. Therefore, as $k\rightarrow\infty$, the first factor on the RHS of \eqref{eq136} converges to $-1$, and the second factor converges to $-B$. It follows that
\begin{align*}
\lim_{n\rightarrow\infty}\lim_{k\rightarrow\infty}\frac{f(x_n)-f(y_k)}{g(x_n)-g(y_k)}=\lim_{n\rightarrow\infty}B=B
\end{align*}
Therefore $A=B$ by Thm. \ref{lb122}.
\end{proof}




\begin{comment}

\begin{rem}
In this course, I have often encouraged the reader to give an elementary proof of a theorem that has been proved in fancy language or in a language different from the common one. However, I shall not make the same suggestion this time.  Many textbook proofs of case $\frac *\infty$ of L'H\^opital's rule use elementary techniques of estimation. However, these proofs seem difficult to digest because they (implicitly) involve approximations with respect to two variables, but they do not use the correct language to discuss such approximations: the language of double limits. Without the correct language, math will become a mess.
\end{rem}
\end{comment}


The proof of L`H\^opital's rule is now complete.


\begin{rem}
The above proof can be easily translated into a language without double limits. We consider the case of $\frac *\infty$ and assume for example that $-\infty<A<+\infty$ and $a\in\Rbb$, and sketch the proof as follows. 

By \eqref{eq129} and Cauchy' MVT, for every $\eps>0$ there is $\delta>0$ such that for all $a<x,y<a+\delta$ (where $x\neq y$) we have
\begin{align*}
A-\eps\leq\frac{f(x)-f(y)}{g(x)-g(y)}\leq A+\eps
\end{align*}
Choose any sequence $(x_n)$ in $(a,b)$ converging to $a$. Let $B$ be any cluster point of $(f(x_n)/g(x_n))_{n\in\Zbb_+}$ in $\ovl\Rbb$. We need to prove that $A=B$. Let $(y_k)_{k\in\Zbb_+}$ be any subsequence of $(x_n)$ such that $\lim_k f(y_k)/g(y_k)=B$. Then there is $N\in\Nbb$ such that for all $n\geq N,k\geq N$ satisfying $x_n\neq y_k$, we have
\begin{align*}
A-\eps\leq\frac{f(x_n)-f(y_k)}{g(x_n)-g(y_k)}\leq A+\eps
\end{align*}
For each $n\geq N$, apply $\lim_{k\rightarrow\infty}$ to the above inequality, and notice $\lim_k |g(y_k)|=+\infty$. Then we get $A-\eps\leq B\leq A+\eps$, finishing the proof. \hfill\qedsymbol
\end{rem}










\subsection{Trigonometric functions and $\pi$}\label{lb397}



In this section, we prove that $\sin$, $\cos$, and $\pi$ satisfy the properties we learned in high schools. Some of them have already been proved in Subsec. \ref{lb353}. We leave the proof of the basic properties of the other trigonometric functions to the reader.

Let $x$ be a real variable. Recall that $\sin,\cos:\Rbb\rightarrow\Rbb$ are determined by the fact that $e^{\im x}=\cos x+\im\sin x$. In particular, that $|e^{\im x}|=1$ implies $(\cos x)^2+(\sin x)^2=1$. We have proved that
\begin{align*}
\sin'=\cos\qquad \cos'=-\sin
\end{align*}
Since $e^{\im\cdot 0}=1$, we have
\begin{align*}
(\sin x)'|_{x=0}=\cos 0=1\qquad (\cos x)'|_{x=0}=-\sin 0=0
\end{align*}
In particular, since $\sin'=\cos$ is strictly positive on a neighborhood of $0$, by Cor. \ref{lb330}, $\sin$ is strictly increasing on that neighborhood.




We shall define $\frac \pi 2$ to be the smallest positive zero $\cos$. However, we must first prove the existence of this number:


\begin{lm}
There exists $x\geq 0$ such that $\cos x=0$.
\end{lm}


\begin{proof}
Suppose this is not true. Then by $\cos 0=1$ and intermediate value theorem, we have $\cos x>0$ for all $x\geq 0$. In other words, $\sin'>0$ on $\Rbb_{\geq 0}$. Thus, by Cor. \ref{lb330}, $\sin$ is strictly increasing on $\Rbb_{\geq0}$. Therefore $A=\lim_{x\rightarrow+\infty}\sin x$ exists in $\ovl\Rbb$. Since $\sin 0=0$, we must have $A\in\ovl\Rbb_{>0}$. By L'H\^opital's rule in case $\frac *\infty$, we have
\begin{align*}
\lim_{x\rightarrow+\infty} \frac{\cos x}x=\lim_{x\rightarrow+\infty}-\sin x=-A<0
\end{align*}
contradicting the fact that $\cos x>0$ if $x\geq 0$.
\end{proof}



\begin{df}
We define the number $\pi$ to be \index{zz@$\pi$, the number pi}
\begin{align*}
\pi=2\cdot\inf\big(\Rbb_{\geq 0}\cap\cos^{-1}(0)\big)=2\cdot\inf\{x\in\Rbb_{\geq 0}:\cos x=0\}
\end{align*}
Note that $\big(\Rbb_{\geq 0}\cap\cos^{-1}(0)\big)$ is a closed subset of $\Rbb$. So its infimum belongs to this set. Therefore, $\frac \pi 2$ is the smallest $x\geq0$ satisfying $\cos(x/2)=0$.
\end{df}




\begin{pp}
We have
\begin{align}\label{eq137}
\sin 0=0\qquad\sin\frac\pi 2=1\qquad\cos 0=1\qquad\cos\frac\pi2=0
\end{align}
On $(0,\pi/2)$, $\sin$ and $\cos$ are strictly positive. On $[0,\pi/2]$, $\sin$ is strictly increasing, and $\cos$ is strictly decreasing.
\end{pp}

\begin{proof}
All the formulas in \eqref{eq137}, except $\sin(\pi/2)=1$, has been proved. Since $(\sin\frac\pi 2)^2=1-(\cos\frac\pi2)^2$, we have $\sin\frac\pi2=\pm1$.

By the definition of $\pi$, we know that $\sin'=\cos$ is $>0$ on $[0,\frac\pi2)$. So $\sin$ is strictly increasing on $[0,\frac\pi2]$. Thus, $\sin0=0$ implies that $\sin>0$ on $(0,\frac\pi 2]$. In particular, $\sin\frac \pi2=1$. Since $\cos'=-\sin$ is $<0$ on $(0,\frac\pi2)$, $\cos$ is strictly decreasing on $[0,\frac\pi2]$.
\end{proof}


\begin{pp}
We have $\sin(-x)=-\sin x$ and $\cos(-x)=\cos x$.
\end{pp}


\begin{proof}
Immediate from $e^{-\im x}=1/e^{\im x}$ and the definitions of $\sin$ and $\cos$.
\end{proof}


From what we have proved, we know that the graph of $\sin$ and $\cos$ on $[-\frac\pi2,\frac\pi2]$ looks as follows.
\begin{align*}
\vcenter{\hbox{{
			\includegraphics[height=2.2cm]{fig2.png}}}}
\end{align*}

\begin{pp}
We have
\begin{gather*}
\sin x=\cos(x-\frac\pi2)=\cos(\frac\pi2-x)\qquad \cos(x)=\sin(\frac\pi 2-x)
\end{gather*}
\end{pp}

\begin{proof}
Immediate from \eqref{eq138} and \eqref{eq137}.
\end{proof}
Thus, the graph of $\sin$ is the rightward translation of that of $\cos$ by $\frac\pi 2$. Therefore, the graph of $\sin$ on $[-\frac\pi2,0]$ is translated to the graph of $\cos$ on $[-\pi,-\frac\pi2]$. That $\cos(x)=\cos(-x)$ gives us the graph of $\cos$ on $[\frac\pi2,\pi]$. Thus, we know the graph of $\cos$ on $[-\pi,\pi]$. 



\begin{thm}[\textbf{Euler's formula}] \index{00@Euler's formula}
We have $e^{\im\pi}=-1$, and hence $e^{2\im\pi}=e^{\im\pi}e^{\im\pi}=1$.
\end{thm}


\begin{proof}
We have $e^{\im\pi/2}=\cos(\frac\pi2)+\im\sin(\frac\pi2)=\im$. Hence $e^{\im\pi}=\im^2=-1$.
\end{proof}

\begin{pp}
We have $\sin x=\sin(x+2\pi)$ and $\cos x=\cos(x+2\pi)$
\end{pp}


\begin{proof}
Immediate from \eqref{eq138} and that $1=e^{2\im\pi}=\cos(2\pi)+\im\sin(2\pi)$.
\end{proof}




Thus, $\cos$ and $\sin$ have period $2\pi$. This completes the graphs of $\cos x$ and $\sin x=\cos(x-\frac\pi2)$ on $\Rbb$.

The fact that $2\pi$ is the length of the unit circle will be proved in Exp. \ref{lb398}.



\subsection{Taylor's theorems}


Assume throughout this section that $-\infty<a<b<+\infty$ and $V$ is a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$.


In this section, we generalize MVTs and finite-increment theorem to higher derivatives. These generalizations are all under the name ``Taylor theorem". Recall Def. \ref{lb354} and Pb. \ref{lb355} for the meaning of $l^{n,\infty},C^n,C^\infty$. We first discuss the generalization of finite-increment theorem, which can be applied to vector-valued functions.





 
\subsubsection{Taylor's theorems for vector-valued functions}



\begin{df}\label{lb574}
Let $X$ be a normed vector space. Let $A\subset X$. Let $a\in\Cl_X(A)\setminus A$ (or more generally, assume $a\in\Cl_X(A\setminus \{a\})$). Let $f:A\rightarrow V$. Let $r\in\Rbb_{\geq0}$.
\begin{itemize}
\item We write $\dps f(x)=o(\Vert x-a\Vert^r)$ if $\dps\lim_{x\rightarrow a}\frac{f(x)}{\Vert x-a\Vert^r}=0$.
\item We write $\dps f(x)=O(\Vert x-a\Vert^r)$ if $\dps\limsup_{x\rightarrow a}\frac{\Vert f(x)\Vert}{\Vert x-a\Vert^r}<+\infty$ where $\limsup$ is the limit superior of a net (cf. Rem. \ref{lb269} and Pb. \ref{lb346}). In other words, there exists $U\in\Nbh_X(a)$ such that $\sup_{x\in A\cap U}\Vert f(x)\Vert/\Vert x-a\Vert^r<+\infty$.
\end{itemize}
When $r=0$, we simply write $o(1)$ and $O(1)$. The two symbols $o,O$ are called \textbf{Landau symbols}. \index{00@Landau symbols $o,O$}
\end{df}


In this section, we will frequently use the formula
\begin{align}
S_n(x)=\sum_{k=0}^n\frac{f^{(k)}(a)}{k!}(x-a)^k
\end{align}
whenever the RHS makes sense.


\begin{thm}[\textbf{Taylor's theorem, Peano form}]\index{00@Taylor's theorem, Peano form}\label{lb360}
Let $f:[a,b]\rightarrow V$ and $n\in\Zbb_+$. Assume that $f',f'',\dots,f^{(n)}$ exist at $a$ (resp. at $b$). Then for each $x\in (a,b)$ we have
\begin{subequations}
\begin{gather}
f(x)=\sum_{k=0}^n\frac{f^{(k)}(a)}{k!}(x-a)^k+o((x-a)^n)\label{eq142}\\
\text{resp.}\nonumber\\
f(x)=\sum_{k=0}^n\frac{f^{(k)}(b)}{k!}(x-b)^k+o((b-x)^n) \label{eq143}
\end{gather}
\end{subequations}
\end{thm}


Expressions of the form \eqref{eq142} are called \textbf{Taylor expansions} \index{00@Taylor expansion} of $f$ with \textbf{center} $a$.

\begin{rem}
In order for $f^{(n)}(a)$ to exist, it is assumed that $f^{(n-1)}$ exists on a neighborhood of $a$.
\end{rem}


\begin{proof}[Proof of Peano-form]
Since the two cases are similar, we only treat the case at $a$. Define \textbf{remainder} \index{00@Remainder of Taylor expansion} $g(x)=f(x)-S_n(x)$. Then
\begin{align}
g(a)=g'(a)=\cdots=g^{(n)}(a)=0  \label{eq140}
\end{align}
It suffices to prove Taylor's theorem for $g$, i.e.
\begin{align}
g(x)=o((x-a)^n)
\end{align}
We prove this by induction. The case $n=1$ is obvious from the definition of derivatives, which says
\begin{align}
\frac{g(x)-g(a)}{x-a}-g'(a)=o(1)
\end{align}
and hence $g(x)=(x-a)o(1)=o(x-a)$. 

Now assume $n\geq 2$. Assume that Peano form has been proved for case $n-1$. Applying this result to $g'$. We then get $g'(x)=o((x-a)^{n-1})$. Since $g''(a)$ exists,  $g'$ exists on $[a,c]$ where $a<c<b$. In particular, $g$ is continuous on $[a,c]$. Therefore, by finite-increment Thm. \ref{lb333}, if $x\in(a,c)$, then
\begin{align*}
\Vert g(x)\Vert\leq (x-a)\cdot\sup_{a<t<x}\Vert g'(t)\Vert
\end{align*}
If we can prove $\sup_{a\leq t\leq x}\Vert g'(t)\Vert=o((x-a)^{n-1})$, then we immediately have $g(x)=o((x-a)^n)$. Thus, the proof of Peano form is finished by the next lemma.
\end{proof}

\begin{lm}
Assume that $f:[a,b]\rightarrow V$ satisfies $f(x)=o((x-a)^r)$. Define
\begin{align*}
\wtd f(x)=\sup_{a<t<x}\Vert f(t)\Vert
\end{align*}
Then $\wtd f(x)=o((x-a)^r)$.
\end{lm}


\begin{proof}
Choose any $\eps>0$. Since $f(x)=o((x-a)^r)$, we know that there is $c\in (a,b)$ such that for all $a<x<c$ we have $\Vert f(x)\Vert\leq \eps |x-a|^r$. Thus
\begin{align*}
|\wtd f(x)|\leq\sup_{a<t<x}\eps |t-a|^r =\eps|x-a|^r
\end{align*}
\end{proof}


Among all the versions of Taylor's theorem discussed in this section, the following one is most useful. (Another useful version, the integral form of Taylor's theorem, will be proved in Thm. \ref{lb425}.) Note that if we assume $f\in C^{(n+1)}([a,b],V)$ in Thm. \ref{lb360}, then Thm. \ref{lb359} immediately implies Thm. \ref{lb360}.  



\begin{thm}[\textbf{Higher order finite-increment theorem}]\index{00@Higher order finite-increment theorem}\label{lb359}
Let $n\in\Nbb$ and $f\in C^n([a,b],V)$. Assume that $f^{(n+1)}$ exists everywhere on $(a,b)$. Then, for every $x\in(a,b]$ resp. $x\in[a,b)$, we have respectively
\begin{subequations}
\begin{gather}
\Big\Vert f(x)-\sum_{k=0}^n\frac{f^{(k)}(a)}{k!}(x-a)^k \Big\Vert \leq \frac{(x-a)^{n+1}}{(n+1)!}\cdot \sup_{a<t<x}\Vert f^{(n+1)}(t)\Vert  \label{eq139}\\
\Big\Vert f(x)-\sum_{k=0}^n\frac{f^{(k)}(b)}{k!}(x-b)^k \Big\Vert \leq \frac{(b-x)^{n+1}}{(n+1)!}\cdot \sup_{x<t<b}\Vert f^{(n+1)}(t)\Vert
\end{gather}
\end{subequations} 
\end{thm}





\begin{proof}
We only prove the first formula: applying the first formula to $\wtd f(x)=f(-x)$ implies the second one. We prove \eqref{eq139} by induction on $n$. Moreover, we shall prove \eqref{eq139} for the case $x=b$. The general case follows by restricting $f$ to $[a,x]$.  When $n=0$, \eqref{eq139} is the content of (classical) finite-increment Thm. \ref{lb333}. Assume case $n-1$ has been proved ($n\in\Zbb_+$). In case $n$, take $g(x)=f(x)-S_n(x)$. Then \eqref{eq140} is true. Let
\begin{align*}
M=\sup_{a<t<b}\Vert f^{(n+1)}(t)\Vert =\sup_{a<t<b}\Vert g^{(n+1)}(t)\Vert
\end{align*}
By case $n-1$, for each $a\leq x\leq b$ we have
\begin{align*}
\Vert g'(x)\Vert \leq\frac{(x-a)^n}{n!}\cdot M=h'(x)\qquad\text{where }~h(x)=\frac{M(x-a)^{n+1}}{(n+1)!} 
\end{align*}
Thus, by Thm. \ref{lb329}, we have
\begin{align*}
\Vert g(b)-g(a)\Vert\leq h(b)-h(a)=\frac{M(b-a)^{n+1}}{(n+1)!} 
\end{align*}
This proves \eqref{eq139} for $g$, and hence for $f$.
\end{proof}



\subsubsection{Taylor's theorem for real-valued functions}



\begin{thm}[\textbf{Taylor's theorem, Lagrange form}]\index{00@Taylor's theorem, Lagrange form}\label{lb395}
Let $n\in\Nbb$ and $f\in C^n([a,b],\Rbb)$. Assume that $f^{(n+1)}$ exists everywhere on $(a,b)$. Then for every $x\in(a,b]$ resp. $x\in[a,b)$, there exists $\xi\in(a,x)$ resp. $\eta\in (x,b)$ such that, respectively,
\begin{subequations}
\begin{gather}
f(x)=\sum_{k=0}^n\frac{f^{(k)}(a)}{k!}(x-a)^k+\frac{f^{(n+1)}(\xi)}{(n+1)!}(x-a)^{n+1}\label{eq141}\\
f(x)=\sum_{k=0}^n\frac{f^{(k)}(b)}{k!}(x-b)^k+\frac{f^{(n+1)}(\eta)}{(n+1)!}(x-b)^{n+1}
\end{gather}
\end{subequations}
\end{thm}



\begin{proof}
We only prove \eqref{eq141}. Applying \eqref{eq141} to $\wtd f(x)=f(-x)$ (defined on $[-b,-a]$) implies the second formula. Again, it suffices to prove \eqref{eq141} for $g(x)=f(x)-S_n(x)$, which satisfies \eqref{eq140}. Thus, we want to find $\xi\in(a,x)$ satisfying
\begin{align*}
g(x)=\frac{g^{(n+1)}(\xi)}{(n+1)!}(x-a)^{n+1}
\end{align*}
This can be proved by applying Cauchy's MVT repeatedly:
\begin{align*}
&\frac{g(x)}{(x-a)^{n+1}}\xlongequal{{\color{ForestGreen}\exists x_1\in (a,x)}}\frac{g'(x_1)}{(n+1)(x_1-a)^n}\xlongequal{{\color{ForestGreen}\exists x_2\in (a,x_1)}}\frac{g''(x_2)}{(n+1)n(x_2-a)^{n-1}}\\
=&\cdots \xlongequal{{\color{ForestGreen}\exists x_n\in (a,x_{n-1})}}\frac{g^{(n)}(x_n)}{(n+1)!(x_n-a)}\xlongequal{{\color{ForestGreen}\exists \xi\in (a,x_n)}}\frac{g^{(n+1)}(\xi)}{(n+1)!}
\end{align*}
\end{proof}




We will mainly use Thm. \ref{lb359} instead of the Lagrange form, since the latter does not apply directly to vector valued functions. However, Thm. \ref{lb359} can be derived from the Lagrange form and Hahn-Banach theorem. We have used the fact that $V^*$ separates points of $V$ to prove that a function $[a,b]\rightarrow V$ is constant if its derivative exists and is constantly zero. (See Cor. \ref{lb326}.) However, to prove Thm. \ref{lb359}, we need the stronger fact that for every $v\in V$ there exists a nonzero $\varphi\in V^*$ such that $\bk{\varphi,v}=\Vert\varphi\Vert\cdot\Vert v\Vert$. (See Rem. \ref{lb393}.) By scaling $\varphi$, we can assume that $\Vert\varphi\Vert=1$ and $\bk{\varphi,v}=\Vert v\Vert$.

We now give the second proof of Thm. \ref{lb359}:


%% Record #16 2023/11/15 three lectures  40


\begin{proof}[\textbf{Proof of Thm. \ref{lb359} using Lagrange form and Hahn-Banach}]
The Lagrange form clearly implies Thm. \ref{lb359} in the special case that $V=\Rbb$. Now consider the general case, and view $V$ as a real Banach space if it was originally over $\Cbb$. Take $g(x)=f(x)-S_n(x)$. We need to prove $\Vert g(x)\Vert\leq \frac{(x-a)^{n+1}}{(n+1)!}M$ where $M=\sup_{a<t<x}\Vert g^{(n+1)}(t)\Vert$.

By Hahn-Banach (Rem. \ref{lb393}), there exists $\varphi\in V^*$ with $\Vert\varphi\Vert=1$ such that $\varphi\circ g(x)=\Vert g(x)\Vert$. Applying the one dimensional special case to $\varphi\circ g$, we have
\begin{align}
\Vert g(x)\Vert=\varphi\circ g(x)\leq \frac{(x-a)^{n+1}}{(n+1)!}\cdot\sup_{a<t<x}\big|(\varphi\circ g)^{(n+1)}(t)\big|  \label{eq179}
\end{align}
provided that $\varphi\circ g\in C^n([a,b],V)$ and that $(\varphi\circ g)^{(n+1)}$ exists on $(a,b)$.

By the continuity of $\varphi$, we have
\begin{align}\label{eq180}
(\varphi\circ g)'(t)=\lim_{s\rightarrow t}\frac{\varphi\circ g(s)-\varphi\circ g(t)}{s-t}=\varphi\Big(\lim_{s\rightarrow t}\frac{g(s)-g(t)}{s-t}\Big)=\varphi(g'(t))
\end{align}
Applying this formula repeatedly, we see that $\varphi\circ g\in C^n([a,b],V)$, that $(\varphi\circ g)^{(n+1)}$ exists on $(a,b)$, and that $(\varphi\circ g)^{(n+1)}=\varphi\circ g^{(n+1)}$. By Rem. \ref{lb372}, we have
\begin{align*}
\sup_{a<t<x}\big|(\varphi\circ g)^{(n+1)}(t)\big|= \sup_{a<t<x}\big|\bk{\varphi,g^{(n+1)}(t)}\big|\leq \sup_{a<t<x}\Vert g^{(n+1)}(t)\Vert=M
\end{align*}
Combining this result with \eqref{eq179} finishes the proof.
\end{proof}


When $V$ is $\Rbb^N$ equipped with the Euclidean norm, the Hahn-Banach theorem (in the form of Rem. \ref{lb393}) is very easy: Define the linear map $\varphi:\Rbb^N\rightarrow \Rbb$ sending each $v\in \Rbb^N$ to its dot product with $g(x)/\Vert g(x)\Vert$. Then $\varphi$ satisfies $\Vert\varphi\Vert=1$ and $\varphi\circ g(x)=\Vert g(x)\Vert$.  So there is nothing mysterious in the above proof. (You are encouraged to compare this proof with the one of \cite[Thm. 5.19]{Rud-P}.)






\subsection{Functions approximated by their Taylor series}


Taylor's theorems do not imply that a smooth function $f$ on an interval of $\Rbb$ can be approximated by its \textbf{Taylor series} \index{00@Taylor series} (with \textbf{center} $a$):
\begin{align}
\sum_{k=0}^\infty \frac{f^{(k)}(a)}{k!}(x-a)^k
\end{align}
The following is a typical example:

\begin{eg}\label{lb358}
Define $f:\Rbb\rightarrow\Rbb$ by
\begin{align*}
f(x)=\left\{
\begin{array}{ll}
\dps \exp\big(-\frac 1{x^2}\big)& (\text{if }x>0)\\[1ex]
0&(\text{if }x\leq 0)
\end{array}
\right.
\end{align*}
Then $f^{(n)}(0)=0$ for all $n\in\Nbb$. So the Taylor series of $f$ at $0$ is $0$, which cannot approximate $f(x)$ when $x>0$.
\end{eg}


On the contrary, if $f$ is defined on an open subset of $\Cbb$, and if $f'$ exists everywhere on its domain, then $f^{(n)}$ exists for all $n$, and $f$ can be approximated locally uniformly by its Taylor series. This is a deep result in complex analysis. In fact, a thorough understanding of power series is impossible without the help of complex analysis.

In the following, we show that some important real variable functions can be approximated by their Taylor series. Actually, the proof can be simplified by complex analysis, since these examples are the restriction of some differentiable complex variable functions (aka \textbf{holomorphic functions}) to the real line.


\begin{eg}\label{lb480}
Consider the Taylor expansion of $\log:\Rbb_{>0}\rightarrow\Rbb$ at $x=1$. By induction on $n\in\Zbb_+$, one computes that
\begin{align*}
\log^{(n)}(x)=(-1)^{n-1}\frac{(n-1)!}{x^n}
\end{align*}
Therefore, its Taylor expansion in order $n$ is
\begin{align*}
\sum_{k=1}^n \frac{(-1)^{k-1}}{k} (x-1)^k+R_{n+1}(x)
\end{align*}
where $R_{n+1}(x)$ is the remainder. To show that $\log x$ is approximated uniformly (on certain domain) by its Taylor series, one need to show that $R_{n+1}$ converges uniformly to $0$ on that domain. 

We would like to prove that for every $0<r<1$ we have $R_{n+1}\rightrightarrows 0$ on $[1-r,1+r]$. This would imply that series on the RHS of the following formula (whose radius of convergence is $1$) converges uniformly to $f$ on $[1-r,1+r]$:
\begin{align}
\log(x)=\sum_{k=1}^n \frac{(-1)^{k-1}}{k} (x-1)^k
\end{align}
However, using the Taylor's theorems proved in the previous section, one can prove the uniform convergence only when $0<r\leq1/2$. The general case of $0<r<1$ should be proved by another method.   \hfill\qedsymbol
\end{eg}


\begin{proof}[\textbf{Proof for the case $0<r\leq \frac 12$}] In fact, we shall prove the uniform convergence on $[1-r,2]$. 
By Thm. \ref{lb359}, for all $x\in[1-r,1+r]$ we have
\begin{align*}
|R_{n+1}(x)|\leq \frac{|x-1|^{n+1}}{(n+1)!}\cdot\sup_{
\begin{subarray}{c}
1\leq t\leq x\\
\text{or }x\leq t\leq 1
\end{subarray}
}
\big|\log^{(n+1)}(t)\big|=\frac{|x-1|^{n+1}}{n+1}\cdot\sup_{
\begin{subarray}{c}
1\leq t\leq x\\
\text{or }x\leq t\leq 1
\end{subarray}
}\frac 1{t^{n+1}}
\end{align*}
where the $\sup$ is over $1\leq t\leq x$ or $x\leq t\leq 1$, depending on whether $1\leq x\leq 1+r$ or $1-r\leq x\leq 1$.

If $1\leq x\leq 1+r$, then $1\leq t\leq x$ implies $1/t^{n+1}\leq 1$. So
\begin{align*}
|R_{n+1}(x)|\leq\frac{(x-1)^{n+1}}{n+1}\leq\frac{r^{n+1}}{n+1} 
\end{align*}
where the RHS converges to $0$ as $n\rightarrow\infty$ whenever $0<r\leq 1$. In particular, we get the renowned formula
\begin{align}
\log 2=\sum_{n=1}^\infty \frac{(-1)^{n-1}}n
\end{align}

If $1-r\leq x\leq 1$, then $x\leq t\leq 1$ implies $1/t^{n+1}\leq 1/x^{n+1}$. Thus
\begin{align*}
|R_{n+1}(x)|\leq\frac 1{n+1}\Big(\frac 1x-1 \Big)^{n+1}\leq \frac 1{n+1}\Big(\frac 1{1-r}-1 \Big)^{n+1}=\frac 1{n+1}\Big(\frac r{1-r}\Big)^{n+1}
\end{align*}
If $0<r\leq 1/2$, then $0<r/(1-r)\leq 1$, and hence the RHS above converges to $0$ as $n\rightarrow\infty$. This proves that $R_{n+1}\rightrightarrows0$ on $[1-r,1+r]$ when $0<r\leq1/2$.
\end{proof}



\begin{proof}[\textbf{Proof for the case $0<r<1$}]
Assume $0<r<1$. For the convenience of discussion, we prove instead that 
\begin{align}
\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k} x^k  \label{eq144}
\end{align}
the Taylor series of $\log(1+x)$ at $0$, converges uniformly to $\log(1+x)$ on $[-r,r]$

The radius of convergence of the series \eqref{eq144} is $1$. Thus, by Thm. \ref{lb112}, \eqref{eq144} converges locally uniformly on $(-1,1)$ to some function $f:(-1,1)\rightarrow\Rbb$. By Cor. \ref{lb338}, $f$ is differentiable on $(-1,1)$, and the series
\begin{align}
\sum_{k=0}^\infty (-1)^kx^k   \label{eq145}
\end{align}
converges locally uniformly on $(-1,1)$ to $f'$. But we clearly have
\begin{align}
\eqref{eq145}=\frac{1}{1-(-x)}=\frac 1{1+x}
\end{align}
Thus $f'(x)=\frac d{dz}(\log(1+x))$. Now, \eqref{eq144} clearly implies that $f(0)=0=\log(1+0)$. Therefore, by Cor. \ref{lb326}, we obtain $f(x)=\log(1+x)$ on $(-1,1)$. In other words, \eqref{eq144} converges locally uniformly on $(-1,1)$ (and hence uniformly on $[-r,r]$) to $\log(1+x)$.
\end{proof}



\begin{eg}
Let $\alpha\in\Cbb$. Then
\begin{align}
\sum_{k=0}^\infty{\alpha\choose k}x^k   \label{eq146}
\end{align}
the Taylor series of $(1+x)^\alpha=\exp(\alpha\log(1+x))$ at $x=0$, converges locally uniformly on $(-1,1)$ to $(1+x)^\alpha$.
\end{eg}



\begin{proof}
Using Prop. \ref{lb109}, one easily checks that the radius of convergence of \eqref{eq146} is $1$. So Thm. \ref{lb112} implies that \eqref{eq146} converges locally uniformly on $(-1,1)$ to some $f:(-1,1)\rightarrow\Cbb$. Let
\begin{align*}
g(x)=(1+x)^\alpha
\end{align*}
Our goal is to prove $f=g$. 

It is clear that $(1+x)g'(x)=\alpha g(x)$. By Cor. \ref{lb338},  the series
\begin{align}
\sum_{k=0}^\infty k{\alpha\choose k}x^{k-1}=\sum_{k=0}^\infty (k+1){\alpha\choose k+1}x^k
\end{align}
converges locally uniformly on $(-1,1)$ to $f'$. Thus, by Cor. \ref{lb362}, we have
\begin{align*}
&(1+x)f'(x)=\sum_{k=0}^\infty \bigg( k{\alpha\choose k}+(k+1){\alpha\choose k+1}\bigg)x^k\\
=&\sum_{k=0}^\infty \alpha{\alpha\choose k}x^k=\alpha f(x)
\end{align*}
Therefore, $f$ satisfies the same differential equation as $g$, namely $(1+x)f'=\alpha f$. Moreover, we clearly have $f(0)=1=g(0)$. So we have $f=g$ on $(-1,1)$ if we apply the next lemma to $f-g$.
\end{proof}


\begin{lm}\label{lb553}
Let $I$ be an interval of $\Rbb$ (with at least two points) such that $0\in I$. Let $\Fbb\in\{\Rbb,\Cbb\}$. Let $\varphi\in C(I,\Fbb^{n\times n})$. Assume that $f\in C^1(I,\Fbb^n)$ satisfies
\begin{align}
f'(x)=\varphi(x)\cdot f(x)\qquad f(0)=0
\end{align} 
Then for all $x\in I$ we have $f(x)=0$.
\end{lm}

\begin{proof}
We prove this lemma for the case that $I$ is an open interval. The proof for the other types of intervals is similar. Also, we equip $\Fbb^{n\times n}$ with the operator norm by viewing $n\times n$ matrices as elements of $\fk L(\Fbb^n)$. (Recall that the operator norm is equivalent to the Eucliden norm, see Thm. \ref{lb363}.) Let
\begin{align*}
\Omega=\{x\in I:f(x)=0\}=f^{-1}(0)
\end{align*}
which is a closed subset of $I$ (since the inverse image under a continuous map of a closed set is closed). Clearly $\Omega$ is nonempty since $0\in\Omega$. If we can prove that $\Omega$ is open, then we have $\Omega=I$ because $I$ is connected. This will finish the proof.

So let us prove that any $p\in\Omega$ is an interior point of $\Omega$ with respect to $I$. Choose $r>0$ such that $[p-r,p+r]\subset I$. Let
\begin{align*}
C=\sup_{-r\leq x\leq r}\Vert\varphi(x)\Vert
\end{align*}
which is a finite number by extreme value theorem. Let $\delta=\min\{\frac 1{2C},r\}$ which is $>0$. It suffices to prove that
\begin{align*}
M=\sup_{x\in[p-\delta,p+\delta]}\Vert f(x)\Vert
\end{align*}
is zero. (Note that $M<+\infty$ again by EVT.) Then we will have $[p-\delta,p+\delta]\subset\Omega$, finishing the proof. 

For each $x\in[p-\delta,p+\delta]$, by Rem. \ref{lb372} for operator norms, we have
\begin{align*}
\Vert f'(x)\Vert=\Vert\varphi(x)f(x)\Vert\leq\Vert\varphi(x)\Vert\cdot \Vert f(x)\Vert\leq CM
\end{align*}
Thus, by finite-increment theorem, we have for all $x\in[p-\delta,p+\delta]$ that
\begin{align*}
\Vert f(x)\Vert=\Vert f(x)-f(p)\Vert\leq CM|x-p|\leq CM\delta\leq \frac M2
\end{align*}
Applying $\sup_{x\in[p-\delta,p+\delta]}$ to $\Vert f(x)\Vert$, we get $M\leq M/2$. So $M=0$.
\end{proof}

\begin{rem}
The above Lemma can also be proved in a similar way to Thm. \ref{lb329}: Let $x\in I$. Assume WLOG that $x>0$. Let $E=f^{-1}(0)\cap[0,x]$, which is a closed subset of $[0,x]$. So $t=\sup E$ is in $[0,x]$. To show $f(x)=0$, one just need to prove $t=x$. If not, then $t<x$. Then, as in the above proof, one can find $\delta>0$ such that $f(s)=0$ whenever $s\in[t,t+\delta]$, impossible.
\end{rem}






\subsection{Convex functions}






In this section, we fix an interval $I\subset\Rbb$ containing at least two points.


\begin{df}
Let $\mbf x=(x_1,x_2)$, $\mbf y=(y_1,y_2)$, $\mbf z=(z_1,z_2)$ be three points of $\Rbb^2$ satisfying $x_1<y_1<z_1$. We say that the ordered triple $(\mbf x,\mbf y,\mbf z)$ is a \textbf{convex triple} \index{00@Convex triple} if  the following equivalent conditions are satisfied:
\begin{enumerate}[label=(\arabic*)]
\item $\mbf y$ is below or on the interval $[\mbf x,\mbf z]$. In other words, we have $y_2\leq tx_2+(1-t)z_2$ if $t\in[0,1]$ is such that $y_1= tx_1+(1-t)z_1$.
\item We have $\dps \frac{y_2-x_2}{y_1-x_1}\leq \frac{z_2-y_2}{z_1-y_1}$.
\item We have $\dps \frac{y_2-x_2}{y_1-x_1}\leq \frac{z_2-x_2}{z_1-x_1}$.
\item We have $\dps \frac{z_2-x_2}{z_1-x_1}\leq\frac{z_2-y_2}{z_1-y_1}$.
\end{enumerate}
\end{df}

\begin{proof}[Proof of equivalence]
The equivalence of these statements is clear from the picture, and is not hard to check rigorously using inequalities. We leave the details to the reader.
\end{proof}


Recall the definition of convex subsets in real vector spaces (Def. \ref{lb364}).

\begin{df}
A function $f:I\rightarrow\Rbb$ is called \textbf{convex} if the following equivalent conditions are true:
\begin{enumerate}
\item[(1)] The set
\begin{align}
D_f=\{(x,y)\in\Rbb^2:x\in I,y\geq f(x)\}\label{eq147}
\end{align}
is a convex subset of $\Rbb^2$. 
\item[(1)] For any three points $x<y<z$ of $I$, the points $(x,f(x)),(y,f(y)),(z,f(z))$ form a convex triple.
\end{enumerate}
\end{df}

\begin{proof}[Proof of equivalence]
Again, the equivalence is clear from the picture. The details are left to the readers.
\end{proof}



The convexity of differentiable functions is easy to characterize:

\begin{thm}\label{lb366}
Let $f:I\rightarrow\Rbb$ be differentiable. Then $f$ is convex iff $f'$ is increasing. In particular, if $f''$ exists on $I$, then $f$ is convex iff $f''\geq0$ on $I$.
\end{thm}

\begin{proof}
Assume that $f'$ is increasing. Choose $x<y<z$ in $I$. By Lagrange's MVT, there exist $\xi\in(x,y)$ and $\eta\in(y,z)$ such that the slope of the interval $[(x,f(x)),(y,f(y))]$ equals $f'(\xi)$, and that the slope of $[(y,f(y)),(z,f(z))]$ equals $f'(\eta)$. Since $f'(\xi)\leq f'(\eta)$, the points $(x,f(x)),(y,f(y)),(z,f(z))$ form a convex triple. This proves that $f$ is convex.

Now assume that $f$ is convex. Choose any $x<y$ in $I$. We need to prove that $f'(x)\leq f'(y)$. Choose any $\eps>0$. Then there exist $x_1$ and $y_1$ such that $x<x_1<y_1<y$, that $f'(x)-\eps$ is $\leq$ the slope $k_1$ of $[(x,f(x)),(x_1,f(x_1))]$, and that $f'(y)+\eps$ is $\geq$ the slope $k_2$ of $[(y_1,f(y_1)),(y,f(y))]$. Since $f$ is convex, $k_1$ is $\leq$ the slope $k'$ of $[(x_1,f(x_1)),(y_1,f(y_1))]$, and $k'\leq k_2$. Therefore $k_1\leq k_2$. Thus $f'(x)-\eps\leq f'(y)+\eps$. Since $\eps>0$ is arbitrary, we get $f'(x)\leq f'(y)$.

When $f''$ exists, the equivalence between $f''\geq0$ and the increasing monotonicity of $f'$ is due to Cor. \ref{lb330}.
\end{proof}











The most important general property about convex functions is:

\begin{thm}[\textbf{Jensen's inequality}]  \index{00@Jensen's inequality}
Let $f:I\rightarrow\Rbb$ be a convex function. Let $n\in\Zbb_+$ and $x_1,\dots,x_n\in I$. Choose $t_1,\dots,t_n\in[0,1]$ such that $t_1+\cdots+t_n=1$. Then
\begin{align}
f(t_1x_1+\cdots+t_nx_n)\leq t_1f(x_1)+\cdots+t_nf(x_n)
\end{align}
\end{thm}

\begin{proof}
The points $(x_1,f(x_1)),\dots,(x_n,f(x_n))$ are in $D_f=\eqref{eq147}$. Therefore, by Lem. \ref{lb365}, the point
\begin{align*}
t_1(x_1,f(x_1))+\cdots+t_n(x_n,f(x_n))=(t_1x_1+\cdots+t_nx_n,t_1f(x_1)+\cdots+t_nf(x_n))
\end{align*}
is in the convex set $D_f$. 
\end{proof}



\begin{lm}\label{lb365}
Let $V$ be a real vector space. Let $E$ be a convex subset of $V$. Let $n\in\Zbb_+$ and $p_1,\dots,p_n\in E$. Any \textbf{convex combination} of $p_1,\dots,p_n$ \index{00@Convex combination} (i.e., any point of the form $t_1p_1+\cdots+t_np_n$ where $t_1,\dots,t_n\in[0,1]$ and $t_1+\cdots+t_n=1$) is inside $E$.
\end{lm}

The geometric meaning of this lemma is clear: If $V=\Rbb^2$ (which is the main case we are interested in), then $t_1p_1+\cdots+t_np_n$ stands for an arbitrary point inside the polygon with vertices $p_1,\dots,p_n$. So this point is clearly inside $E$.


\begin{proof}
We prove by induction on $n$. The case $n=1$ is obvious. Suppose case $n-1$ has been proved $n\geq 2$. Consider case $n$. It is trivial when $t_1+\cdots+t_{n-1}=0$. So let us assume $t_1+\cdots+t_{n-1}>0$. By case $n-1$, the point $q=\lambda_1 p_1+\cdots+\lambda_{n-1}p_{n-1}$ is in $E$ where
\begin{align*}
\lambda_i=\frac{t_i}{t_1+\cdots+t_{n-1}}
\end{align*}
Since $E$ is convex, the point $(t_1+\cdots+t_{n-1})q+t_np_n$ (which equals $t_1p_1+\cdots+t_np_n$) is in $E$.
\end{proof}


\begin{eg}
Since $(-\log x)''=x^{-2}$ is positive on $\Rbb_{>0}$, by Thm. \ref{lb366}, $-\log$ is a convex function on $\Rbb_{>0}$. Therefore, if $0<\lambda_1,\dots,\lambda_n\leq 1$ and $\lambda_1+\cdots+\lambda_n=1$, then by Jensen's inequality, for each $x_1,\dots,x_n>0$ we have $-\log(\sum_i\lambda_ix_i)\leq -\lambda_i\log x_i$. Taking exponentials, we get
\begin{align*}
x_1^{\lambda_1}\cdots x_n^{\lambda_n}\leq \lambda_1x_1+\cdots+\lambda_n x_n
\end{align*}
for all $x_1,\dots,x_n>0$, and hence for all $x_1,\dots,x_n\geq0$. In particular, we get the \textbf{inequality of arithmetic and geometric means}
\begin{align}
(x_1\cdots x_n)^{\frac 1n}\leq \frac{x_1+\cdots+x_n}{n}
\end{align}
and the \textbf{Young's inequality} \index{00@Young's inequality}
\begin{align}
x^{\frac 1p}y^{\frac 1q}\leq \frac xp+\frac yq
\end{align}
if $p,q>1$ and $\frac 1p+\frac 1q=1$.
\end{eg}


\begin{df}
Let $p\in[1,+\infty]$. We say that $q\in[1,+\infty]$ is the \textbf{H\"older conjugate} \index{00@H\"older conjugate} of $p$ if $\frac 1p+\frac 1q=1$.
\end{df}



%% Record #17 2023/11/20 two lectures  42



\subsection{H\"older's and Minkowski's inequalities; $l^p$ spaces}



In this section, we use Young's inequality to prove two inequalities that are of vital importance to the development of modern analysis:





\begin{thm}\label{lb853}
Let $x_1,\dots,x_n,y_1,\dots,y_n\in\Rbb_{\geq0}$. Let $p,q\in(1,+\infty)$ satisfy $\frac 1p+\frac 1q=1$. Then the following inequalities (called respectively \textbf{H\"older's inequality} \index{00@H\"older's inequality} and \index{00@Minkowski's inequality} \textbf{Minkowski's inequality}) are true:
\begin{subequations}
\begin{gather}
x_1y_1+\cdots+x_ny_n\leq\sqrt[p]{x_1^p+\cdots+x_n^p}\cdot\sqrt[q]{y_1^q+\cdots+y_n^q}\\
\sqrt[p]{(x_1+y_1)^p+\cdots+(x_n+y_n)^p}\leq  \sqrt[p]{x_1^p+\cdots+x_n^p}+\sqrt[p]{x_1^p+\cdots+x_n^p}
\end{gather}
\end{subequations}
\end{thm}


In the special case that $p=q=2$, H\"older's inequality is called the \textbf{Cauchy-Schwarz inequality}.

The following proof is quite tricky. In Sec. \ref{lb991}, we will give a more straightforward proof of the two inequalities using Lagrange multipliers.

\begin{proof}[$\star\star$ Proof]
Assume WLOG that $x_i>0$ and $y_j>0$ for some $i,j$. Young's inequality implies that for each $i$,
\begin{align*}
\frac{x_i}{\sqrt[p]{\sum_k x_k^p}}\cdot \frac{y_i}{\sqrt[q]{\sum_k y_k^q}}\leq \frac{x_i^p}{p\sum_k x_k^p}+\frac{y_i^q}{q\sum_k y_k^q}
\end{align*}
Taking sum over $i$ gives
\begin{align*}
\sum_i\frac{x_i}{\sqrt[p]{\sum_k x_k^p}}\cdot \frac{y_i}{\sqrt[q]{\sum_k y_k^q}}\leq\frac 1p+\frac 1q=1
\end{align*}
This proves H\"older's inequality.

Notice that $pq=p+q$. Let $z_i=x_i+y_i$. By H\"older's inequality, we have
\begin{align*}
x_1z_1^{p-1}+\cdots+x_nz_n^{p-1}\leq \Big(\sum_k x_k^p\Big)^{\frac 1p}\cdot\Big(\sum_k z_k^{(p-1)q}\Big)^{\frac 1q}=\Big(\sum_k x_k^p\Big)^{\frac 1p}\cdot\Big(\sum_k z_k^p\Big)^{\frac 1q}
\end{align*}
and similarly
\begin{align*}
y_1z_1^{p-1}+\cdots+y_nz_n^{p-1}\leq\Big(\sum_k y_k^p\Big)^{\frac 1p}\cdot\Big(\sum_k z_k^p\Big)^{\frac 1q}
\end{align*}
Adding up these two inequalities, we get
\begin{align*}
\sum_k z_k^p\leq \bigg(\Big(\sum_k x_k^p\Big)^{\frac 1p}+\Big(\sum_k y_k^p\Big)^{\frac 1p}\bigg)\cdot\Big(\sum_k z_k^p\Big)^{\frac 1q}
\end{align*}
Dividing both sides by $\Big(\sum_k z_k^p\Big)^{\frac 1q}$ proves Minkowski's inequality.
\end{proof}



Minkowski's inequality is often used in the following way:


\begin{thm}\label{lb596}
Let $X$ be a set, and let $V$ be a normed vector space over $\Fbb\in\{\Rbb,\Cbb\}$. Let $1\leq p<+\infty$. For each $f\in V^X$, define the \pmb{$l^p$}\textbf{-norm} \index{lp@$l^p(X,V)$ and $l^p$ norm}
\begin{align}
\Vert f\Vert_p\equiv\Vert f\Vert_{l^p}=\Big(\sum_{x\in X}\Vert f(x)\Vert^p\Big)^{\frac 1p}
\end{align}
Then for each $f,g\in V^X$ and $\lambda\in\Fbb$ we have
\begin{align}\label{eq148}
\Vert f+g\Vert_p\leq \Vert f\Vert_p+\Vert g\Vert_p\qquad \Vert \lambda f\Vert_p =|\lambda|\cdot \Vert f\Vert_p
\end{align}
In particular, $\Vert\cdot\Vert_p$ is a norm on the \pmb{$l^p$}\textbf{-space}
\begin{align}
l^p(X,V)=\{f\in V^X:\Vert f\Vert_{l^p}<+\infty\}
\end{align}
If $V$ is Banach space, then so is $l^p(X,V)$.
\end{thm}

Recall $0\cdot(\pm\infty)=0$.

\begin{proof}
Choose any $A\in\fin(2^X)$. By Minkowski's and triangle inequality, we have
\begin{align*}
&\sum_A |f+g|^p\leq\sum_A (|f|+|g|)^p\leq\Big(\Big(\sum_A |f|^p\Big)^{\frac 1p}+\Big(\sum_B |f|^p\Big)^{\frac 1p} \Big)^p\\
\leq&\Big(\Big(\sum_X |f|^p\Big)^{\frac 1p}+\Big(\sum_X |f|^p\Big)^{\frac 1p} \Big)^p=(\Vert f\Vert_p+\Vert g\Vert_p)^p
\end{align*}
Taking $\lim_{A\in\fin(2^X)}$ gives $\Vert f+g\Vert_p^p\leq (\Vert f\Vert_p+\Vert g\Vert_p)^p$, proving the first inequality of \eqref{eq148}. The second of \eqref{eq148} clearly holds by taking $\lim_{A\in\fin(2^X)}$ of
\begin{align*}
\sum_A |\lambda f|^p=|\lambda|\sum_A |f|^p
\end{align*}
and noting that the multiplication map $t\in\ovl\Rbb_{\geq 0}\mapsto |\lambda|t\in\ovl\Rbb_{\geq0}$ is continuous.

Suppose that $V$ is complete. Let $(f_n)$ be a Cauchy sequence in $l^p(X,V)$. Then for each $x\in X$, $(f_n(x))$ is a Cauchy sequence in $V$, converging to some element $f(x)\in V$. By Cauchyness, for each $\eps>0$ there is $N\in\Zbb_+$ such that for all $n,k\geq N$ we have $\Vert f_n-f_k\Vert_p\leq\eps$, and hence
\begin{align*}
\sum_{x\in A} \Vert f_n(x)-f_k(x)\Vert^p\leq\eps^p
\end{align*}
for all $A\in\fin(2^X)$. Taking $\lim_k$ gives $\sum_A |f_n-f|^p\leq\eps^p$. Taking $\lim_{A\in\fin(2^X)}$ gives $\Vert f_n-f\Vert_p\leq\eps$ for all $n\in\geq N$. (In particular, $\Vert f\Vert_p\leq \Vert f_N\Vert+\eps<+\infty$, and hence $f\in l^p(X,V)$.) This proves that $(f_n)$ converges to $f$ under the $l^p$-norm. So $l^p(X,V)$ is complete.
\end{proof}



\begin{comment}
To interpret H\"older's inequality, we notice the following fact:
\begin{rem}\label{lb368}
Let $V,W$ be normed vector spaces over $\Fbb\in\{\Rbb,\Cbb\}$. Let $T:V\rightarrow W$ be a linear map. Let $C\in\ovl\Rbb_{\geq 0}$. Let $\Vert T\Vert\in\ovl\Rbb_{\geq0}$ be the operator norm of $T$. Then 
\begin{align}
\Vert T\Vert\leq C\qquad\Longleftrightarrow\qquad \Vert T\xi\Vert\leq C\Vert\xi\Vert~~(\forall\xi\in V)
\end{align} 
Indeed, ``$\Rightarrow$" follows from Rem. \ref{lb372}, and ``$\Leftrightarrow$" follows by taking arbitrary $\xi\in \ovl B_V(0,1)$. Alternatively, it follows by dividing both sides of $\Vert T\xi\Vert\leq C\Vert\xi\Vert$ by $\Vert\xi\Vert$ (when $\Vert\xi\Vert>0$) and noticing the easy fact
\begin{align}
\Vert T\Vert=\sup_{\xi\in V,\Vert \xi\Vert=1}\Vert T\xi\Vert \label{eq149}
\end{align}
It is also obvious from \eqref{eq149} that if $C<+\infty$, then
\begin{align}
\Vert T\Vert\geq C\qquad\Longleftrightarrow\qquad \forall\eps>0,~\exists \xi\in V\setminus\{0\}~\text{such that }\Vert T\xi\Vert\geq(C-\eps)\Vert\xi\Vert
\end{align}
To see this, we again divide both sides of $\Vert T\xi\Vert\geq(C-\eps)\Vert\xi\Vert$ by $\Vert\xi\Vert$.
\end{rem}
\end{comment}

\begin{thm}\label{lb369}
Let $X$ be a set. Let $\Fbb\in\{\Rbb,\Cbb\}$. Let $p,q\in[1,+\infty]$ such that $\frac 1p+\frac 1q=1$. Then there is a linear isometry
\begin{subequations}
\begin{gather}\label{eq150}
\Psi: l^p(X,\Fbb)\rightarrow l^q(X,\Fbb)^*\qquad f\mapsto\Psi(f)
\end{gather}
where for each $g\in l^q(X,\Fbb)$, the value of $\Psi(f)$ at $g$ is
\begin{align}
\bk{\Psi(f),g}=\sum_{x\in X}f(x)g(x)  \label{eq151}
\end{align}
\end{subequations}
where the RHS converges. 
\end{thm}


In fact, we will see in Thm. \ref{lb527} that if $q<+\infty$ (and hence $p>1$), $\Psi$ is surjective, and hence is an isomorphism of normed vector spaces. (This is not a difficult fact. So you can prove it yourself.)


\begin{proof}
We treat the case $1<p,q<+\infty$, and leave the case that $p\in\{1,+\infty\}$ to the readers. Assume $f\in l^p$ and $g\in l^q$, then for each $A\in\fin(2^X)$ we have by H\"older's inequality that
\begin{align*}
\Big\Vert\sum_A fg\Big\Vert\leq \sum_A |fg|\leq \Big(\sum_A|f|^p \Big)^{\frac 1p}\Big(\sum_A|g|^q \Big)^{\frac 1q}\leq \Vert f\Vert_p\cdot\Vert g\Vert_q
\end{align*}
Applying $\lim_{A\in\fin(2^X)}$ to the second term above implies that $\sum_X |fg|<+\infty$. So $\sum_Xfg$ converges absolutely, and hence converges. So \eqref{eq151} makes sense, and hence $\Psi$ is a well-defined linear map. Applying $\lim_{A\in\fin(2^X)}$ to the first term above implies that
\begin{align*}
|\bk{\Psi(f),g}|\leq \Vert f\Vert_p\cdot\Vert g\Vert_q
\end{align*}
Thus, by Rem. \ref{lb372}, we obtain $\Vert\Psi(f)\Vert\leq\Vert f\Vert_p$.

To show $\Vert\Psi(f)\Vert=\Vert f\Vert_p$, assume WLOG that $f\neq 0$, and define $g:X\rightarrow\Fbb$ to be $g=\frac{\ovl f}{|f|}\cdot |f|^{p-1}$, where $g(x)$ is understood as $0$ if $f(x)=0$. Then
\begin{align*}
\bk{\Psi(f),g}=\sum_X |f|^p=\Vert f\Vert_p^p
\end{align*}
and $\Vert g\Vert_q^q=\sum_X |f|^{pq-q}=\sum_X|f|^p=\Vert f\Vert_p^p$. So
\begin{align*}
\Vert f\Vert_p\cdot\Vert g\Vert_q=\Vert f\Vert_p^{1+p/q}=\Vert f\Vert_p^p=\bk{\Psi(f),g}
\end{align*}
This proves $\Vert\Psi(f)\Vert=\Vert f\Vert_p$ by Rem. \ref{lb372}. So $\Psi$ is a linear isometry.
\end{proof}



I do not want to deviate too much from the main purpose of this section, which is to show some important applications of convex functions. I will therefore stop my discussion about $l^p$ spaces, and continue this topic in the future. The crucial role of $l^p$ spaces and their continuous versions (namely $L^p$ spaces) in modern analysis is a long story. The study of these objects constitutes a major part of the second half of this course. Let me mention just one point: the compactness of $\ovl B_{l^2(\Zbb,\Cbb)}(0,1)$ under the pointwise convergence topology (by viewing it as a subspace of $\Cbb^\Zbb$) was the most important reason for Hilbert and Schmidt to study the Hilbert space $l^2(\Zbb,\Cbb)$, and it was the crucial property that allowed them to fully solve the eigenvalue problem in integral equations (cf. Ch. \ref{lb672}).












\subsection{Problems and supplementary material}


Let $-\infty<a<b<+\infty$. Let $V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$.


\begin{prob}
Let $f$ be the function in Exp. \ref{lb358}. Prove that $f^{(n)}(0)=0$ for all $n\in\Nbb$.
\end{prob}




\begin{prob}\label{lb361}
Let $n\in\Nbb$. Let $f:[a,b]\rightarrow V$ such that $f,f',\dots,f^{(n)}$ exist everywhere on $[a,b]$. Use the higher order finite-increment theorem to prove that
\begin{align}
\Big\Vert f(x)-\sum_{k=0}^n\frac{f^{(k)}(a)}{k!}(x-a)^k\Big\Vert\leq \frac{(x-a)^{n}}{n!}\cdot \sup_{a<t<x}\Vert f^{(n)}(t)-f^{(n)}(a)\Vert  \label{eq174}
\end{align}
\end{prob}

\begin{rem}\label{lb404}
Setting $n=1$ and dividing both sides by $x-a$, we obtain an especially useful formula for any differentiable $f:[a,b]\rightarrow V$ as follows.
\begin{align}
\Big\Vert \frac{f(x)-f(a)}{x-a}-f'(a)\Big\Vert\leq \sup_{a<t<x}
\big\Vert f'(t)-f'(a)\big\Vert  \label{eq169}
\end{align}
\end{rem}


\begin{prob}
Use Thm. \ref{lb336} to prove the following theorem. (Formula \eqref{eq169} might be helpful.)
\end{prob}



\begin{thm}\label{lb406}
Let $I=[a,b]$ and $J=[c,d]$ be intervals in $\Rbb$ with at least two points. Let $f:I\times J\rightarrow V$ be a function such that $\partial_1f,\partial_2f,\partial_2\partial_1f$ exist on $I\times J$, and that $\partial_2\partial_1f$ is continuous. Then $\partial_1\partial_2f$ exists on $I\times J$ and equals $\partial_2\partial_1f$.
\end{thm}




\begin{sprob}
Prove that, for $x \in(-1,1]$,
\begin{align}\label{eq198}
\arctan x=\sum_{k=0}^{\infty}(-1)^k \frac{x^{2 k+1}}{2 k+1}=x-\frac{x^3}{3}+\frac{x^5}{5}-\frac{x^7}{7}+-\cdots,
\end{align}
and hence (\textbf{Leibniz formula})
\begin{align*}
\frac{\pi}{4}=\sum_{k=0}^{\infty} \frac{(-1)^k}{2 k+1}=1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+-\cdots
\end{align*}
\end{sprob}


\begin{proof}[Hint]
Use the method in the second proof of Exp. \ref{lb480} to prove \eqref{eq198} for $x\in(-1,1)$. To prove \eqref{eq198} for $x=1$, show that the series on the RHS of \eqref{eq198} converges uniformly on $[0,1]$ to a continuous function using Dirichlet's test for uniform convergence (Thm. \ref{lb481}).
\end{proof}







\begin{sprob}\label{lb357}
Let $n\in\Nbb$. Find the radius of convergence of
\begin{align}
f(z)=\sum_{k=n}^\infty {k\choose n}z^k
\end{align}
Find the explicit formula of $f(z)$.
\end{sprob}



\begin{prob}
Prove the following higher order finite-increment theorem for complex variables. (For simplicity, it suffices prove the case that $z_0=0$.)
\end{prob}

\begin{thm}[\textbf{Higher order finite-increment theorem}]\index{00@Higher order finite-increment theorem}  \label{lb356}
Let $V$ be a Banach space over $\Cbb$. Let $R>0$ and $z_0\in\Cbb$. Let $f:\Omega\rightarrow V$ where
\begin{align*}
\Omega=B_\Cbb(z_0,R)=\{z\in\Cbb:|z-z_0|<R\}
\end{align*}
Assume that $f',f'',\dots,f^{(n+1)}$ exist everywhere on $\Omega$. Then for every $z\in\Omega$ we have
\begin{align}
\Big\Vert f(z)-\sum_{k=0}^n\frac{f^{(k)}(z_0)}{k!}(z-z_0)^k \Big\Vert \leq\frac{|z-z_0|^{n+1}}{(n+1)!}\cdot \sup_{\xi\in[z_0,z]} \Vert f^{(n+1)}(\xi)\Vert
\end{align}
where $[z_0,z]=\{tz+(1-t)z_0:0\leq t\leq 1\}$.
\end{thm}



\begin{sprob}
Let $V$ be a Banach space over $\Cbb$. Assume that the power series $f(z)=\sum_{k=0}^\infty v_kz^k$ (where $v_k\in V$) has radius of convergence $R>0$. Choose any $z_0\in B_\Cbb(0,R)$. Prove that there exists a neighborhood $\Omega\in\Nbh_\Cbb(z_0)$ contained inside $B_\Cbb(0,R)$, such that the Taylor series of $f$ at $z_0$ converges uniformly on $\Omega$ to $f$. Namely, prove that the series $g(z)$ converges locally uniformly to $f$ on $\Omega$ where
\begin{align}
g(z)=\sum_{k=0}^\infty\frac{f^{(k)}(z_0)}{k!}(z-z_0)^k
\end{align}
\end{sprob}

\begin{proof}[Hint]
Use Thm. \ref{lb356}.  Pb.  \ref{lb357} might also be helpful.
\end{proof}




\begin{sprob}
Let $W$ be a real vector space. Let $A$ be a nonempty subset of $W$. Define the \textbf{convex hull} \index{00@Convec hull} of $A$ to be the set of all convex combinations (recall Lem. \ref{lb365}) of elements of $A$, i.e.
\begin{align}
\mathrm{Cvh}(A)=\big\{\text{convex combinations of }v_1,\dots,v_n:n\in\Zbb_+\text{ and } v_1,\dots,v_n\in A\big\}
\end{align}
Prove that $\mathrm{Cvh}(A)$ is the smallest convex set containing $A$. In other words, prove that $\mathrm{Cvh}(A)$ is a convex set containing $A$, and that $\mathrm{Cvh}(A)\subset B$ if $B$ is a convex subset of $W$ containing $A$.
\end{sprob}



\begin{prob}
Prove Thm. \ref{lb369} for the case $p=1$ and $p=+\infty$.
\end{prob}












\newpage



\section{Riemann integrals}



\subsection{Introduction: the origin of integral theory in Fourier series}\label{lb550}



\subsubsection{Antiderivatives VS. approximation by areas of rectangles}

Modern people can easily appreciate the importance of giving a rigorous definition to the integral $\int_a^bf(x)dx$ where $f$ is a general (say, continuous) function. And you may already know that this integral is defined by taking the limit of Riemann sums, which are ``areas of some rectangles". This idea sounds so natural to you, because you know that by the time Calculus was invented, people knew very well that  $\int_a^b f$ means the area of the region between the graph of $f$ and the $x$-axis, and that this area can be approximated by the areas of some rectangles or triangles. So why did Riemann integral not appear until 19th century, more than a hundred years after Newton's and Leibniz's invention of calculus? And why was the inadequacy of defining integrals by means of antiderivatives not recognized until 19th century?


Beyond the superficial reason that 19th century is the century in which people began to pay attention to the foundations of calculus, there is a deeper reason: the study of \textbf{partial differential equations (PDE)} and the introduction of \textbf{Fourier series} caused a drastic change in the general view of what functions are. This change of view motivated people to search for a general definition of integrals, in particular one that does not use antiderivatives.

Before the systematic study of PDEs (i.e., before 19th century), functions only mean analytic functions, which means that they can be approximated by their Taylor series. But if $f$ is such a function, then $f(x)=\sum_{n=0}^\infty \frac{f^{(n)}(a)}{n!}(x-a)^n$. So the values of $f$ are all determined by $f(a),f'(a),f''(a),\dots$, and hence \uwave{are determined by $f|_I$ where $I$ is an arbitrary nonempty open interval}. (Technically, such functions are called \textbf{(real) analytic functions}.) Therefore, periodic functions (except trigonometric functions) were not accepted, because they are not determined by their values on a small interval. (A function with expression $f(x)=x$ on $[0,1]$ should also have the same expression on $\Rbb$. So it must not be the periodic function $f(x)=x-n$ where $x\in(n,n+1]$.) The function Exp. \ref{lb358} was not accepted, because it was not determined by $f(0),f'(0),f''(0),\dots$.

Therefore, in these old days, people did not worry about the rigorous definition of integrals, because they can simply \uline{define integrals using antiderivatives} instead of using the areas of rectangles to approximate the integrals, which is practically less convenient than finding the antiderivatives. In particular, one understood
\begin{align*}
\int_a^b \sum a_n (x-c)^ndx\xlongequal{\mathrm{def}}F(b)-F(a)\qquad\text{where}\qquad F(x)=\sum \frac{a_n}{n+1}(x-c)^{n+1}
\end{align*}

\subsubsection{PDEs and periodic functions}

The wonderful dream was shattered when people started working on PDEs. The simplest such example is \textbf{wave equation}
\begin{align}
\partial_x^2f(x,t)-\partial_t^2f(x,t)=0
\end{align} 
This equation describes the vibration of a string: at time $t$, the shape of the string is the graph of the function $x\in[a,b]\mapsto f(x,t)\in\Rbb$. (Here, we assume that the two end points of the string are $(a,0)$ and $(b,0)$.)

D'Alambert solved the wave equation in the following way. Using the trick
\begin{align*}
\partial_x^2-\partial_t^2=4\partial_u\partial_v\qquad\text{where}\qquad u=x+t,v=x-t
\end{align*}
it is not hard to find the general solution of the wave equation:
\begin{align}
f(x,t)=\frac 12\big(g(x+t)+g(x-t) \big)+\frac 12\int_{x-t}^{x+t}h(s)ds
\end{align}
where $g(x)=f(x,0)$ and $h(x)=\partial_t f(x,0)$. In particular, if we assume that $h=0$ (i.e., at time $t=0$ the string is held in place and does not vibrate), then the solution is
\begin{align}
f(x,t)=\frac 12\big(g(x+t)+g(x-t) \big)
\end{align}

Here comes the trouble. If we assume that the two end points of the string are always pinned at $(0,0)$ and $(1,0)$ respectively, then we have $f(0,t)=f(1,t)=0$ for all $t\in\Rbb$. Translating this condition to $g$, we get $g(t)=-g(-t)=-g(2-t)$ and hence $g$ is a function with period $2$, totally unacceptable! Worse still, the derivatives of periodic functions might have points of discontinuities.

\subsubsection{Fourier series}


The next important progress was made by Fourier in the study of \textbf{heat equation}
\begin{align}
\partial_t f(x,t)-\partial_x^2 f(x,t)=0
\end{align}
where $x$ is defined on a closed interval (say $[-\pi,\pi]$) representing a thin rod, $f(x,t)$ is the temperature   of the point $x$ of this rod at time $t$. Fourier solved the problem by \textbf{separation of variables}: He first assumed $f(x,t)=u(x)v(t)$. Then the heat equation implies $u''(x)v(t)=u(x)v'(t)$, and hence
\begin{align}
\frac{u''(x)}{u(x)}=\frac{v'(t)}{v(t)}  \label{eq152}
\end{align}
The LHS is independent of $t$, and the RHS is independ of $x$. So \eqref{eq152} should be a constant $-\lambda$. The solution is then $u(x)=e^{\im\sqrt\lambda x}$ and $v(t)=e^{-\lambda t}$. If one assumes that the temperature at the two end points $-\pi,\pi$ are equal, then $\sqrt\lambda$ must be an integer $n\in\Zbb$. So $f(x,t)=e^{\im nx-n^2t}$. Taking infinite linear combinations, Fourier found the general solution
\begin{align}
f(x,t)=\sum_{n=-\infty}^{+\infty} a_n e^{\im nx-n^2t}  \label{eq153}
\end{align}
The initial temperature $g(x)=f(x,0)$ is a \textbf{Fourier series}
\begin{align}
g(x)=\sum_{n=-\infty}^{+\infty} a_n e^{\im nx} \label{eq156}
\end{align}
and, in particular, a function with period $2\pi$ (since each $e^{\im nx}$ is so). 

In order to use \eqref{eq153} to determine the solution $f(x,t)$ when the initial condition $f(x,t)=g(x)$ is given, one must first find the values of these \textbf{Fourier coefficients} $a_n$ in terms of $g$. In fact, since 
\begin{align}
\frac 1{2\pi}\int_{-\pi}^\pi e^{\im kx}\cdot e^{-\im nx}dx=\delta_{k,n}
\end{align}
(recall \eqref{eq154}), it is not hard to guess the formula
\begin{align}
\tcboxmath{a_n=\frac 1{2\pi}\int_{-\pi}^\pi g(x)e^{-\im nx}dx}  \label{eq155}
\end{align}
since this formula is true when $g(x)=e^{\im kx}$.



\subsubsection{From Riemann integrals to Lebesgue integrals}\label{lb598}

Here comes the question that is closely related to integral theory: What is the meaning of the integral \eqref{eq155} if $g$ is no longer a real analytic function? 

To be more precise, in 19th century there was a long debate about what are (good) functions, and what functions have \textbf{Fourier expansions}, i.e., expansions of the form \eqref{eq156}. Fourier himself believed that all ``functions" can be approximated by trigonometric functions (equivalently, functions of the form $e^{\im nx}$). But Lagrange did not, partly due to his (and many people's) insistence that functions must be real analytic (cf. \cite[Sec. 28.2]{Kli}). The doubt on whether many functions have Fourier expansions is quite understandable. From the modern perspective, we know that many Lebesgue measurable functions are not approximated by their Fourier series pointwise or uniformly, but are approximated under some other norms (e.g. the $L^2$-norm $\Vert f\Vert_{L^2}=\sqrt{\int_{-\pi}^\pi |f|^2}$). Indeed, there are many continuous functions $[-\pi,\pi]\rightarrow\Rbb$ whose Fourier series diverge on a dense subset of $[-\pi,\pi]$ (cf. \cite[Thm. 5.12]{Rud-R}). Therefore, Fourier's pioneering view that all ``reasonable" functions can be approximated by Fourier series is incorrect unless we define what ``approximation" means in a new and appropriate way.

In order to understand which functions have Fourier series expansions (in whatever sense), the first step is to understand for which function $g$ the integral \eqref{eq155} makes sense. Therefore, \uline{the history of extending the class of integrable functions from continuous functions to Riemann integrable functions and finally to Lebesgue integrable functions is also part of the history of understanding which functions can have Fourier expansions and which functions are ``reasonable".}

%By ``all functions" (or more precisely, all ``reasonable" functions), Fourier also had in mind periodic functions that are not necessarily differentiable on their domains. (By contrast, power series are almost always differentiable on their domains, see Cor. \ref{lb338}.) From modern perspective, we know that many non-differentiable Lebesgue measurable functions can be approximated (in a suitable sense) by their Fourier series. Thus, Fourier's intuition that many functions admitting Fourier expansions are not differentiable is correct. Therefore, the integral \eqref{eq155} cannot be understood in terms of antiderivatives.

%The pursuit of a rigorous foundation of analysis was deeply impacted by these confusions. For example, Cauchy first gave a rigorous definition of continuous functions (though not quite rigorous in today's standard since he did not use the language of $\eps-\delta$). It was also Cauchy who first defined integrals for general continuous functions. In other words, Cauchy made an important progress in understanding what functions can have Fourier expansions by showing that the integral \eqref{eq155} makes sense whenever $g$ is continuous. 




The goal of this chapter is to learn Riemann integrals. The construction of Riemann integrals is much easier than Lebesgue theory. But compared to the latter, Riemann integrals have some serious drawbacks. 

For example, suppose that a sequence of functions $(f_n)$ on $[-\pi,\pi]$ converges to $f$ in some sense. It is natural to ask whether the Fourier coefficients of $(f_n)$ converge to those of $f$. (A typical example is $f_n(x)=\sum_{k=-n}^na_k e^{\im kx}$. Then this question asks whether the $n$-th Fourier coefficient of the series $\sum_{k=-\infty}^{+\infty}a_k e^{\im kx}$ is $a_n$.) In view of \eqref{eq155}, this problem is reduced to the problem of showing $\int f=\lim_n\int f_n$. If $(f_n)$ is a sequence of Riemann integrable functions converging uniformly to $f$, then $f$ is Riemann integrable, and $\int f=\lim \int f_n$. (See Cor. \ref{lb380}.) However, if $(f_n)$ only converges pointwise to $f$, then $f$ is not necessarily Riemann integrable. Even if $f$ is Riemann integrable, one does not have a useful criterion for $\int f=\lim \int f_n$ in the framework of Riemann integrals. 

But uniform convergence often does not hold in application, and especially in Fourier theory and PDEs. For example, let $f$ be the function on $\Rbb$ with period $2\pi$ defined by $f(x)=x$ if $-\pi<x<\pi$ and $f(\pi)=0$. Then the Fourier series
\begin{align}
\sum_{n=1}^\infty (-1)^{n-1}\frac 2n\sin(nx) \label{eq194}
\end{align}
converges pointwise to $f$. (See also Pb. \ref{lb394}.) It does not converge uniformly to $f$, because the uniform limit of a sequence of continuous functions is continuous, but $f$ is not continuous.



Lebesgue's integral theory will provide a more satisfying answer to the above problem. We will learn it in the second semester.




\subsection{Riemann integrability and oscillation}

In this section, we fix a Banach space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$, and let $I=[a,b]$ where $-\infty<a<b<+\infty$. We understand $|I|$ as $b-a$. \index{I@$\vert I\vert=b-a$ if $I=[b-a]$}


\subsubsection{Riemann integrals}\label{lb384}


\begin{df}\label{lb843}
A \textbf{partition} \index{00@Partition of an interval} of the interval $I=[a,b]$ is defined to be an element of the form
\begin{align}
\sigma=\{a_0,a_1,\dots,a_n\in I:a_0=a<a_1<a_2<\cdots<a_n=b,n\in\Zbb_+\}
\end{align}
Equivalently, this partition can be written as
\begin{align}
I=I_1\cup I_2\cup\cdots\cup I_n\qquad I_j=[a_{j-1},a_j]
\end{align}
If $\sigma,\sigma'\in \fin(2^I)$ are partitions of $I$, we say that $\sigma'$ is a \textbf{refinement} \index{00@Refinement of a partition} \index{00@Finer partition} of $\sigma$ (or that $\sigma'$ is \textbf{finer than} $\sigma$), if $\sigma\subset\sigma'$. In this case, we also write  \index{zz@$\sigma\prec\sigma'$} 
\begin{align*}
\sigma\prec\sigma'
\end{align*}
We define $\mc P(I)$ or simply $\mc P$ to be\index{PI@$\mc P(I)$, the set of partitions of $I$}
\begin{align*}
\mc P(I)=\{\text{partitions of $I$}\}
\end{align*}
\end{df}



\begin{rem}
If $\sigma,\sigma'\in\mc P(I)$, then clearly $\sigma\cup\sigma'\in\mc P(I)$ and $\sigma,\sigma'\prec \sigma\cup\sigma$. Therefore, $\prec$ is a partial order on $\mc P(I)$. We call $\sigma\cup\sigma'$ the \textbf{common refinement} \index{00@Common refinement} of $\sigma$ and $\sigma'$.
\end{rem}


\begin{df}\label{lb844}
A \textbf{tagged partition} \index{00@Tagged partition} of $I$ is an ordered pair
\begin{align*}
(\sigma,\xi_\blt)=\big(\{a_0=a<a_1<\cdots<a_n=b\},(\xi_1,\dots,\xi_n) \big)
\end{align*}
where $\sigma\in\mc P(I)$ and $\xi_j\in I_j=[a_{j-1},a_j]$ for all $1\leq j\leq n$. The set\index{QI@$\mc Q(I)$, the directed set of tagged partitions}
\begin{align*}
\mc Q(I)=\{\text{tagged partitions of $I$}\}
\end{align*}
equipped with the preorder $\prec$ defined by
\begin{align}
(\sigma,\xi_\blt)\prec(\sigma',\xi_\blt')\qquad\Longleftrightarrow\qquad \sigma\subset\sigma'
\end{align}
is a directed set.
\end{df}


\begin{df}\label{lb1005}
Let $f:I\rightarrow V$. For each $(\sigma,\xi_\blt)\in\mc Q(I)$, define the \textbf{Riemann sum}\index{00@Riemann sum} \index{Sf@$S(f,\sigma,\xi_\blt)$}
\begin{align*}
S(f,\sigma,\xi_\blt)=\sum_{j\geq 1}f(\xi_j)(a_j-a_{j-1})
\end{align*}
The \textbf{Riemann integral} \index{00@Riemann integral} is defined to be the limit of the net $(S(f,\sigma,\xi_\blt))_{(\sigma,\xi_\blt)\in\mc Q(I)}$:
\begin{align*}
\int_a^b f\equiv\int_a^b f(x)dx=\lim_{(\sigma,\xi_\blt)\in\mc Q(I)}S(f,\sigma,\xi_\blt)
\end{align*}
When the RHS exists, we way that $f$ is \textbf{Riemann integrable} \index{00@Riemann integrable} on $I$. We let \index{R@$\scr R([a,b],V)$}
\begin{align*}
\scr R(I,V)=\{\text{Riemann integrable }f\in V^I\}
\end{align*}
\end{df}


\begin{cv}\label{lb381}
There are several equivalent ways to write the integrals:
\begin{align*}
\int_a^b f=-\int_b^a f=\int_{[a,b]}f
\end{align*}
if $a<b$. Also, if $a=b$, the above terms are understood to be $0$,  and all functions on $[a,b]$ are considered Riemann integrable.
\end{cv}


\begin{rem}
It is clear that $\int_a^b f=v\in V$ iff for every $\eps>0$ there exists $\sigma_0\in \mc P(I)$ such that for any partition $\sigma=\{a_0<\cdots<a_n\}$ finer than $\sigma_0$, and for any $\xi_j\in[a_{j-1},a_j]$ (for all $1\leq j\leq n$) we have
\begin{align*}
\Big\Vert v-\sum_{j\geq 1}f(\xi_j)(a_j-a_{j-1})  \Big\Vert<\eps
\end{align*}
There is not need to tag $\sigma_0$.
\end{rem}




\subsubsection{Riemann integrability and strong Riemann integrability}

In this subsection, we give a useful criterion for Riemann integrability.


\begin{df}\label{lb416}
Let $A$ be a nonempty subset of a metric space $Y$. The \textbf{diameter} of $A$ is defined to be \index{diam@$\diam(A)$}
\begin{align*}
\diam(A)=\sup_{x,y\in A}d(x,y)
\end{align*}
If $f:X\rightarrow Y$ is a map where $X$ is a set, and if $E\subset X$, the \textbf{oscillation} \index{00@Oscillation on a subset} of $f$ on $E$ is defined to be $\diam f(E)$.
\end{df}


The following lemma allows us to control the difference of Riemann sums by means of the oscillation.

\begin{lm}\label{lb371}
Let $f:I=[a,b]\rightarrow V$ and $M=\diam(f(I))$. Then for each $(\sigma,\xi_\blt),(\sigma',\xi_\blt')\in\mc Q(I)$ we have
\begin{align}
\Vert S(f,\sigma,\xi_\blt)-S(f,\sigma',\xi_\blt')\Vert\leq M(b-a)
\end{align}
\end{lm}



\begin{proof}
Write $\sigma\cup\sigma'=\{a_0=a<a_1<\cdots<a_n=b\}$. Then there exist $\gamma_1,\dots,\gamma_n\in\{\xi_1,\xi_2,\dots\}$  such that
\begin{align*}
S(f,\sigma,\xi_\blt)=\sum_{i=1}^n f(\gamma_i)(a_i-a_{i-1})
\end{align*}
(Here is how to choose $\gamma_i$: Let $k$ be the unique number such that the $k$-th subinterval of $\sigma$ contains $[a_{i-1},a_i]$. Then let $\gamma_i=\xi_k$.)
Similarly, there exist $\gamma_1',\dots,\gamma_n'\in\{\xi_1',\xi_2',\dots\}$ such that
\begin{align*}
S(f,\sigma',\xi_\blt')=\sum_{i=1}^n f(\gamma_i')(a_i-a_{i-1})
\end{align*}
Then
\begin{align*}
&\Vert S(f,\sigma,\xi_\blt)-S(f,\sigma',\xi_\blt')\Vert\leq\sum_{i=1}^n\Vert f(\gamma_i)-f(\gamma_i')\Vert\cdot(a_i-a_{i-1})\\
\leq& \sum_{i=1}^n M(a_i-a_{i-1})\leq M(b-a)
\end{align*}
\end{proof}



\begin{df}
Let $f:I\rightarrow V$. For each $\sigma=\{a_0<\cdots<a_n\}\in\mc P(I)$, write $I_i=[a_{i-1},a_i]$ and define the \textbf{oscillation of $f$ on $\sigma$} \index{00@Oscillation on a partition} to be
\begin{align}
\omega(f,\sigma)=\sum_{j=1}^n \diam(f(I_j))\cdot (a_j-a_{j-1})
\end{align}
\end{df}


\begin{exe}
Show that if $\sigma'\supset\sigma$, then $\omega(f,\sigma')\leq \omega(f,\sigma)$. Therefore, $(\omega(f,\sigma))_{\sigma\in\mc P(I)}$ is a decreasing net in $\ovl\Rbb_{\geq0}$.
\end{exe}


Now, Lem. \ref{lb371} can be upgraded to the following version.

\begin{lm}\label{lb373}
Let $f:I\rightarrow V$. Let $\sigma\in\mc P(I)$. Choose $(\sigma',\xi_\blt'),(\sigma'',\xi_\blt'')\in\mc Q(I)$ such that $\sigma\subset\sigma'$ and $\sigma\subset\sigma''$. Then
\begin{align}
\Vert S(f,\sigma',\xi_\blt')-S(f,\sigma'',\xi_\blt'')\Vert\leq \omega(f,\sigma)  \label{eq157}
\end{align}
\end{lm}



\begin{proof}
Write $\sigma=\{a_0<\cdots<a_n\}$ and $I_j=[a_{j-1},a_j]$. Let $S(f,\sigma',\xi_\blt')_{I_j}$ be the \textbf{restriction of $S(f,\sigma',\xi_\blt')$ to $I_j$}. Namely, 
\begin{align}
S(f,\sigma',\xi_\blt')_{I_j}=\sum_{
\begin{subarray}{c}
\text{all $k$ such that}\\
[a_{k-1},a_k]\subset I_j
\end{subarray}
} f(\xi_k)(a_k-a_{k-1})
\end{align} 
Define $S(f,\sigma'',\xi_\blt'')_{I_j}$ in a similar way. Then, by Lem. \ref{lb371} we have
\begin{align*}
\Vert S(f,\sigma',\xi_\blt')_{I_j}-S(f,\sigma'',\xi_\blt'')_{I_j}\Vert\leq \diam(f(I_j))|I_j|
\end{align*}
Thus, \eqref{eq157} follows immediately from triangle inequality and
\begin{align*}
\sum_{j=1}^n  S(f,\sigma',\xi_\blt')_{I_j}= S(f,\sigma',\xi_\blt')\qquad \sum_{j=1}^n  S(f,\sigma'',\xi_\blt'')_{I_j}= S(f,\sigma'',\xi_\blt'')
\end{align*}
\end{proof}



\begin{df}\label{lb774}
We say that $f:I\rightarrow V$ is \textbf{strongly Riemann integrable} \index{00@Strong Riemann integrability} if 
\begin{align*}
\inf_{\sigma\in\mc P(I)} \omega(f,\sigma)=0
\end{align*}
\end{df}

\begin{thm}\label{lb410}
Let $f:I\rightarrow V$. Consider the following statements:
\begin{enumerate}[label=(\arabic*)]
\item $f\in\scr R(I,V)$.
\item $f$ is strongly Riemann integrable.
\end{enumerate}
Then (2)$\Rightarrow$(1). If $V$ is $\Rbb^N$ or $\Cbb^N$, then (1)$\Leftrightarrow$(2).
\end{thm}

When $V$ is infinite-dimensional, Riemann integrable functions are not necessarily strongly Riemann integrable. See Pb. \ref{lb389}.

\begin{proof}
Assume (2). Choose any $\eps>0$. Then there exists $\sigma\in\mc P(I)$ such that $\omega(f,\sigma)<\eps$. By Lem. \ref{lb373}, for every $(\sigma',\xi_\blt'),(\sigma'',\xi_\blt'')\in\mc Q(I)$ satisfying $\sigma\subset\sigma'$ and $\sigma\subset\sigma''$, we have $\Vert S(f,\sigma',\xi_\blt')-S(f,\sigma'',\xi_\blt'')\Vert<\eps$. This proves that $(S(f,\sigma,\xi_\blt))_{(\sigma,\xi_\blt)\in\mc Q(I)}$ is a Cauchy net in $V$, and hence $f\in\scr R(I,V)$.

Now assume that $V$ is $\Rbb^N$ or $\Cbb^N$. Since $\Cbb^N\simeq\Rbb^{2N}$, it suffices to consider the case $V=\Rbb^N$. Since a net in $\Rbb^N$ converges iff each component of this net converge, and since the strong Riemann integrability can be checked componentwisely, it suffices to prove (1)$\Rightarrow$(2) for the case $V=\Rbb$.

So let us assume $f\in\scr R(I,\Rbb)$. Then $(S(f,\sigma,\xi_\blt))_{(\sigma,\xi_\blt)\in\mc Q(I)}$ is a Cauchy net in $\Rbb$. Thus, there exists $\sigma=\{a_0<\cdots<a_n\}\in\mc P(I)$ such that for all $(\sigma',\xi_\blt'),(\sigma'',\xi_\blt'')\in\mc Q(I)$ satisfying $\sigma\subset\sigma'$ and $\sigma\subset\sigma''$, we have $\Vert S(f,\sigma',\xi_\blt')-S(f,\sigma'',\xi_\blt'')\Vert<\eps$. To prove (2), we only need to take $\sigma'=\sigma''=\sigma$. Thus, for any tags $\xi_\blt',\xi_\blt''$ of $\sigma$, we have
\begin{align*}
\Vert S(f,\sigma,\xi_\blt'')-S(f,\sigma,\xi_\blt')\Vert<\eps
\end{align*}
Write $I_j=[a_{j-1},a_j]$. Then
\begin{align*}
\diam(f(I_j))=\sup f(I_j)-\inf f(I_j)
\end{align*}
So  there exist $\xi_j',\xi_j''\in I_j$ such that
\begin{gather*}
f(\xi_j')\leq \inf f(I_j)+\eps\qquad f(\xi_j'')\geq\sup f(I_j)-\eps
\end{gather*}
It follows that $\dps\diam(f(I_j))-2\eps\leq f(\xi_j'')-f(\xi_j')$. Thus
\begin{align*}
&\omega(f,\sigma)=\sum_j \diam(f(I_j))\cdot|I_j|\leq\sum_j (f(\xi_j'')-f(\xi_j'))\cdot|I_j|+\sum_j2\eps\cdot|I_j|\\
=& S(f,\sigma,\xi_\blt'')-S(f,\sigma,\xi_\blt')+2(b-a)\eps<\eps+2(b-a)\eps
\end{align*}
Since $\eps>0$ is arbitrary, we have $\inf_{\sigma\in\mc P(I)} \omega(f,\sigma)=0$.
\end{proof}

\begin{eg}\label{lb377}
Every continuous function $f:I\rightarrow V$ is strongly Riemann integrable, and hence Riemann integrable.
\end{eg}


\begin{proof}
Since $I=[a,b]$ is compact, by Thm. \ref{lb294}, $f\in C(I,V)$ is uniformly continuous. Therefore, for every $\eps>0$, there exists $n\in\Zbb_+$ such that for all $x,y\in I$ satisfying $|x-y|\leq 1/n$, we have $\Vert f(x)-f(y)\Vert<\eps$. Let $\sigma=\{a_0<a_1<\cdots<a_n\}$ be the partition of $I$ such that $|I_j|=a_j-a_{j-1}=1/n$. Then $\diam(f(I_j))\leq\eps$, and hence
\begin{align*}
\omega(f,\sigma)\leq\sum_j \eps\cdot|I_j|=\eps(b-a)
\end{align*}
Since $\eps$ is arbitrary, we get $\inf_{\sigma\in\mc P(I)} \omega(f,\sigma)=0$.
\end{proof}


\begin{eg}\label{lb704}
The \textbf{Dirichlet function} $\chi_\Qbb$ is not (strongly) Riemann integrable on $I=[a,b]$, since for every $\sigma\in\mc P(I)$ we have $\omega(\chi_\Qbb,\sigma)=b-a$.
\end{eg}




\subsection{Basic properties of Riemann integrals}


Let $I=[a,b]$ be a compact interval in $\Rbb$. Let $V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$. We begin this section with the following fundamental fact, which will be used to prove Fubini's theorem, the second fundamental theorem calculus, and much more.


\begin{thm}\label{lb392}
Let $W$ be also a Banach space over $\Fbb$. Let $T\in\fk L(V,W)$. Then for every $f\in\scr R(I,V)$, we have $T\circ f\in\scr R(I,W)$ and
\begin{align}
T\Big(\int_a^b f \Big)=\int_a^b T\circ f
\end{align}
\end{thm}

In other words, we have a commutative diagram
\begin{equation}\label{eq166}
\begin{tikzcd}[column sep=large]
\scr R(I,V) \arrow[r,"T\circ"] \arrow[d,"\int_I"'] & \scr R(I,W) \arrow[d,"\int_I"] \\
V \arrow[r,"T"]           & W        
\end{tikzcd} 
\end{equation}
where the top arrow denotes the composition map $f\mapsto T\circ f$. 

\begin{proof}
By linearity, we have
\begin{align}
S(T\circ f,\sigma,\xi_\blt)=T\big(S(f,\sigma,\xi_\blt) \big)  \label{eq164}
\end{align}
Since $T$ is continuous, the limit over $(\sigma,\xi_\blt) \in \mc Q(I)$ of \eqref{eq164} is
\begin{align*}
T\Big(\lim_{(\sigma,\xi_\blt)\in\mc Q(I)}S(f,\sigma,\xi_\blt)\Big)=T\Big(\int_a^b f \Big)
\end{align*}
This proves that $\lim S(T\circ f,\sigma,\xi_\blt)$ converges to $T(\int_a^bf)$, i.e., $\int_a^b T\circ f$ exists and equals $T(\int_a^bf)$.
\end{proof}




\begin{rem}\label{lb374}
Let $f:I\rightarrow V$ and $\eps>0$. To simplify the following discussion, we say that $f$ is \textbf{$\eps$-dominated} \index{zz@$\eps$-dominated} by $\sigma\in\mc P(I)$, if for all $(\sigma',\xi_\blt'),(\sigma'',\xi_\blt'')\in\mc Q([a,b])$ satisfying $\sigma\subset\sigma',\sigma''$, we have $\Vert S(f,\sigma',\xi_\blt')-S(f,\sigma'',\xi_\blt'')\Vert<\eps$. 

Thus, by Cauchy condition, if $f$ is $\eps$-dominated by some partition for every $\eps>0$, then $f\in\scr R(I,V)$. Moreover,
\begin{align}
\Big\Vert \int_a^b f-S(f,\sigma,\xi_\blt) \Big\Vert\leq\eps
\end{align}
for every $(\sigma,\xi_\blt)\in\mc Q(I)$ such that $f$ is $\eps$-dominated by $\sigma$. \hfill\qedsymbol
\end{rem}





\subsubsection{Integral operators as bounded linear maps}


\begin{pp}\label{lb379}
Let $f\in\scr R(I,V)$ and $g\in\scr R(I,\Rbb)$. Assume that $|f|\leq g$, i.e., $\Vert f(x)\Vert\leq g(x)$ for all $x\in I$. Then $\dps \Big\Vert \int_a^b f \Big\Vert\leq\int_a^b g$.
\end{pp}


\begin{proof}
Apply $\lim_{(\sigma,\xi_\blt)\in\mc Q(I)}$ to the obvious inequality $\Vert S(f,\sigma,\xi_\blt) \Vert\leq S(g,\sigma,\xi_\blt)$.
\end{proof}


\begin{co}\label{lb417}
Assume that $f:I\rightarrow V$ is strongly Riemann integrable. Then $|f|:I\rightarrow\Rbb$ is (strongly) Riemann integrable, and $\dps\dps \Big\Vert \int_a^b f \Big\Vert\leq\int_a^b |f|$
\end{co}


\begin{proof}
By triangle inequality, for every $\sigma\in\mc P(I)$ we have $\omega(|f|,\sigma)\leq \omega(f,\sigma)$. So $|f|$ is strongly integrable. The rest of the corollary follows from Prop. \ref{lb379}.
\end{proof}




\begin{thm}\label{lb375}
$\scr R(I,V)$ is a closed linear subspace of $l^\infty(I,V)$. So $\scr R(I,V)$ is a Banach space under the $l^\infty$-norm. Moreover,  the map
\begin{align}
\int: \scr R(I,V)\rightarrow V\qquad f\mapsto\int_a^b f \label{eq159}
\end{align}
is a bounded linear map with operator norm $b-a$ if we equip $\scr R(I,V)$ with the $l^\infty$-norm.
\end{thm}

%% Record #18 2023/11/22 three lectures  45


\begin{proof}
By the basic properties of limits of nets, we know that if $f,g\in\scr R(I,V)$ and $\alpha,\beta\in\Fbb$, then $\alpha f+\beta g\in\scr R(I,V)$, and
\begin{align}
\int_a^b (\alpha f+\beta g)=\alpha\int_a^b f+\beta\int_a^b g
\end{align}
This proves that $\scr R(I,V)$ is a linear subspace of $V^I$, and that \eqref{eq159} is linear. 

Let us prove $\scr R(I,V)\subset l^\infty(I,V)$. Choose $f\in\scr R(I,V)$. Then $f$ is $1$-dominated by some $\sigma=\{a_0<\cdots<a_n\}\in\mc P(I)$. Fix any tag $\xi_\blt$ on $\sigma$. Choose any $x\in X$. Let $[a_{i-1},a_i]$ be the subinterval containing $x$. Let $\eta_\blt=(\xi_1,\dots,\xi_{i-1},x,\xi_{i+1},\dots,\xi_n)$. Then $\Vert S(f,\sigma,\eta_\blt)-S(f,\sigma,\xi_\blt)\Vert<1$ implies that $\Vert f(x)-f(\xi_i)\Vert\leq 1/(a_i-a_{i-1})$. So
\begin{align*}
\Vert f\Vert_{l^\infty}\leq \max\big\{\Vert f(\xi_i)\Vert+(a_i-a_{i-1})^{-1}:1\leq i\leq n  \big\}<+\infty
\end{align*}

Let $(f_n)$ be a sequence in $\scr R(I,V)$ converging to $f\in l^\infty(I,V)$. Choose any $\eps>0$. Then there is $n$ such that $\Vert f-f_n\Vert_\infty<\eps$. Since $f_n$ is Riemann integrable, $f_n$ is $\eps$-dominated by some $\sigma\in\mc P(I)$. By triangle inequality, $f$ is $(\eps+(b-a)\eps)$-dominated by $\sigma$. Since $\eps$ is arbitrary, we conclude that $f\in\scr R(I,V)$. This proves that $\scr R(I,V)$ is closed, and hence is Banach by Prop. \ref{lb86}.

Let us prove the claim about the operator norm. Choose any $f\in\scr R(I,V)$. Let $M=\Vert f\Vert_\infty<+\infty$. Then $|f|\leq M$. It is easy to see that $\int_a^b M=M(b-a)$. Thus, by Prop. \ref{lb379}, we have $\Vert\int_a^b f\Vert\leq M(b-a)=\Vert f\Vert_\infty\cdot(b-a)$, where ``$\leq$" becomes ``$=$" if we let $f$ be a nonzero constant function. This proves that \eqref{eq159} has operator norm $b-a$ thanks to Rem. \ref{lb372}.
\end{proof}






\begin{co}\label{lb380}
Let $(f_\alpha)_{\alpha\in\scr I}$ be a net in $\scr R(I,V)$ converging uniformly to $f\in V^I$. Then $f\in\scr R(I,V)$ and $\dps\lim_{\alpha\in\scr I}\int_a^b f_\alpha=\int_a^b f$.
\end{co}


\begin{proof}
This is immediate from Thm. \ref{lb375}, which implies that $\scr R(I,V)$ is closed in $l^\infty(I,V)$ (and hence closed in $V^I$ since $l^\infty(I,V)$ is closed in $V^I$), and that the map \eqref{eq159} is continuous.
\end{proof}



\subsubsection{Some criteria for Riemann integrability}



\begin{pp}\label{lb382}
Let $f,g:I\rightarrow V$. Suppose that $\{x\in I:f(x)\neq g(x)\}$ is a finite set. Suppose that $f\in\scr R(I,V)$. Then $g\in\scr R(I,V)$, and $\dps\int_a^bf=\int_a^b g$.
\end{pp}

\begin{proof}
By Thm. \ref{lb375}, it suffices to prove that $g-f$ is Riemann integrable and $\int_a^b(g-f)=0$. This is easy to show, since $g-f$ is zero outside finitely many points. 
\end{proof}





\begin{pp}\label{lb376}
Let $f:[a,b]\rightarrow V$. Let $c\in[a,b]$. Then $f\in\scr R([a,b],V)$ iff $f|_{[a,c]}\in\scr R([a,c],V)$ and $f|_{[c,b]}\in\scr R([c,b],V)$. Moreover, if $f\in\scr R([a,b],V)$, then
\begin{align}
\int_a^b f=\int_a^cf+\int_c^bf\label{eq158}
\end{align}
\end{pp}






\begin{proof}
This is obvious when $c=a$ or $c=b$ (recall Conv. \ref{lb381}). So we assume $a<c<b$. 

First, we assume $f\in\scr R([a,b],V)$. By Cauchy condition, for each $\eps>0$, $f$ is $\eps$-dominated by some $\sigma\in\mc P(I)$.  By enlarging $\sigma$, we assume that $c\in\sigma$. Then it is easy to see that $f|_{[a,c]}$ is $\eps$-dominated by $\sigma\cap[a,c]$, and $f|_{[c,b]}$ is $\eps$-dominated by $\sigma\cap[c,b]$. So $f|_{[a,c]}$ and $f|_{[c,b]}$ are Riemann integrable.

Now assume that $f|_{[a,c]}$ and $f|_{[c,b]}$ are Riemann integrable. Choose any $\eps>0$. Then $f|_{[a,c]}$ is $\eps$-dominated by some $\tau\in \mc P([a,c])$, and $f|_{[c,b]}$ is $\eps$-dominated by some $\varrho\in\mc P([c,b])$. Then $f$ is $2\eps$-dominated by $\sigma=\tau\cup\varrho$. This proves that $f\in\scr R(I,V)$. Let  $\alpha_\blt$ be a tag on $[a,c]$, and let $\beta_\blt$ be  a tag on $[c,b]$. Then $\xi_\blt=(\alpha_\blt,\beta_\blt)=(\alpha_1,\alpha_2,\dots,\beta_1,\beta_2,\dots)$ is a tag on $[a,b]$, and
\begin{align*}
S(f,\sigma,\xi_\blt)=S(f|_{[a,c]},\tau,\alpha_\blt)+S(f|_{[c,b]},\varrho,\beta_\blt)
\end{align*} 
By Rem. \ref{lb374}, we have
\begin{gather*}
\Big\Vert \int_a^b f-S(f,\sigma,\xi_\blt) \Big\Vert\leq 2\eps\\
\Big\Vert \int_a^c f-S(f|_{[a,c]},\tau,\alpha_\blt) \Big\Vert\leq \eps\\
\Big\Vert \int_c^b f-S(f|_{[c,b]},\varrho,\beta_\blt) \Big\Vert\leq \eps
\end{gather*}
Therefore, the difference of the LHS and the RHS of \eqref{eq158} has norm $\leq 4\eps$. This proves \eqref{eq158} since $\eps$ can be arbitrary.
\end{proof}



\begin{eg}\label{lb378}
Let $f\in l^\infty(I,V)$. Suppose that there exist $\sigma=\{a_0<a_1<\cdots<a_n\}\in\mc P(I)$ such that $\dps f|_{(a_{j-1},a_j)}:(a_{j-1},a_j)\rightarrow V$ is continuous for each $1\leq j\leq n$. Then $f\in\scr R(I,V)$.
\end{eg}

\begin{proof}
By Prop. \ref{lb376}, it suffices to prove that each $f|_{[a_{j-1},a_j]}$ is Riemann integrable. Thus, we assume WLOG that $M:=\Vert f\Vert_\infty<+\infty$, and that $f$ is continuous when restricted to $(a,b)$. Choose any $\eps>0$. Choose $\delta>0$ such that $M\delta<\eps$ and $a+\delta<b-\delta$. Let $J=[a+\delta,b-\delta]$. Then $f|_J$ is continuous, and hence Riemann integrable by Exp. \ref{lb377}. So $f|_J$ is $\eps$-dominated by some $\varrho\in\mc P(J)$. Since $\diam(f(I))\leq 2M$, by Lem. \ref{lb371}, $f|_{[a,a+\delta]}$ is $2\eps$-dominated by $\{a,a+\delta\}$, and $f|_{[b-\delta,b]}$ is $2\eps$-dominated by $\{b-\delta,b\}$. So $f$ is $5\eps$-dominated by $\sigma=\varrho\cup\{a,b\}$. Since $\eps>0$ is arbitrary, we conclude $f\in\scr R(I,V)$ by Cauchy condition.
\end{proof}

\begin{eg}
The function $f:[0,1]\rightarrow\Rbb$ defined by $f(x)=\sin(1/x)$ if $0<x\leq 1$ and $f(0)=0$ is Riemann integrable, although $f$ is not uniformly continuous on $(0,1]$.
\end{eg}

\begin{eg}\label{lb388}
Let $I_1,\dots,I_n$ be intervals inside $I$. Choose $v_1,\dots,v_n\in V$ and set $f=\sum_{j=1}^n v_j\chi_{I_j}$. Then $f\in\scr R(I,V)$. 
\end{eg}

\begin{proof}
The case of arbitrary $n$ follows from the case $n=1$ by linearity and Thm. \ref{lb375}. Assume $n=1$, and let $c=\inf I_1$ and $d=\sup I_1$. Then the restriction of $f$ to $[a,c]$ (resp. $[c,d]$ and $[d,b]$) equals a constant function except possibly at the end points of the interval. So $f|_{[a,c]},f|_{[c,d]},f|_{[d,b]}$ are Riemann integrable by Prop. \ref{lb382}. So $f$ is Riemann integrable by Prop. \ref{lb376}.
\end{proof}




\begin{eg}\label{lb383}
Let $f\in C(I,V)$. For each $n\in\Zbb_+$, choose a tag $\xi_{\blt,n}$ for the partition $\sigma=\{a,a+|I|/n,a+2|I|/n,\dots,a+(n-1)|I|/n,b\}$ of $I$. Then
\begin{align}
\lim_{n\rightarrow\infty} \frac {b-a}n\sum_{i=1}^n f(\xi_{i,n})=\int_a^bf  \label{eq161}
\end{align}
\end{eg}



\begin{proof}
Let $f_n=\sum_{i=1}^n f(\xi_{i,n})\cdot\chi_{J_{i,n}}$ where $J_{i,n}=\big(a+\frac{i-1}n|I|,a+\frac in|I|\big]$ if $i>1$, and $J_{1,n}=[a,a+|I|/n]$. Then $f_n\in\scr R(I,V)$ by Exp. \ref{lb388}. Moreover, by Prop. \ref{lb376}, the LHS of \eqref{eq161} equals $\lim_n\int_a^b f_n$.

By Thm. \ref{lb294}, $f$ is uniformly continuous. So for every $\eps>0$ there exists $N\in\Zbb_+$ such that for all $n\geq N$ and all $x,y\in \Cl_\Rbb(J_{i,n})$ we have $\Vert f(x)-f(y)\Vert<\eps$. Thus, for all $n\geq N$ we have $\Vert f-f_n\Vert_{l^\infty}<\eps$. Therefore $f_n\rightrightarrows f$. Thus, by Cor. \ref{lb380} we have $\int_a^b f_n\rightarrow\int_a^b f$. This proves \eqref{eq161}.
\end{proof}



\begin{eg}
By Thm. \ref{lb391}, we have $\int_1^2x^{-1}dx=\log 2$. Thus, by Exp. \ref{lb383}, we have $\lim_{n\rightarrow\infty}\sum_{i=1}^n\frac{2-1}{n}\cdot (1+i/n)^{-1}=\log 2$, namely
\begin{align*}
\lim_{n\rightarrow\infty}\big((n+1)^{-1}+(n+2)^{-1}+\cdots+(2n)^{-1} \big)=\log 2
\end{align*}
\end{eg}








\subsection{Integrals and derivatives}




Let $I=[a,b]$ be an interval in $\Rbb$. Let $V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$.


\subsubsection{Fundamental theorems of calculus (FTC)} \index{00@FTC=fundamental theorem of calculus}


There are two versions of FTC. Roughly speaking, the first FTC says that integrals give antiderivatives. The second FTC says that antiderivatives give integrals. These two FTC are equivalent when the function $f$ to be integrated is continuous. Otherwise, there is a subtle difference (which I can never remember) between these two theorems. 


\begin{thm}[\textbf{First FTC}]\label{lb390}
Let $f\in\scr R(I,V)$. Define
\begin{gather}
F:I\rightarrow V\qquad F(x)=\int_a^x f
\end{gather}
Then $F\in C(I,V)$. If $f$ is continuous at $x$, then $F'(x)=f(x)$.
\end{thm}

In particular, if $f\in C(I,V)$, then $F'=f$. Thus, by Cor. \ref{lb326}, the antiderivatives of $f$ are precisely of the form $F(x)+v_0$ where $v_0\in V$ is viewed as a constant function. 


Recall Conv. \ref{lb381}.

\begin{proof}
Recall by Thm. \ref{lb375} that $\Vert f\Vert_\infty<+\infty$. For each $x,y\in[a,b]$ we have
\begin{align*}
\Vert F(y)-F(x)\Vert=\Big\Vert\int_a^y f-\int_a^x f \Big\Vert=\Big\Vert\int_x^y f \Big\Vert\leq \Vert f\Vert_\infty\cdot|y-x|
\end{align*}
So $F$ has Lipschitz constant $\Vert f\Vert_\infty$. Now suppose that $f$ is continuous at $x$. Then for every $\eps>0$, there exists $U\in\Nbh_I(x)$ such that $\Vert f(x)-f(y)\Vert<\eps$ for every $y\in U$. Thus, for each $y\in U\setminus\{x\}$, since $\int_x^y f(x)dt=f(x)(y-x)$, we have
\begin{align*}
&\Big\Vert \frac{F(y)-F(x)}{y-x}-f(x)\Big\Vert=|y-x|^{-1}\Big\Vert \int_x^y (f(t)-f(x))dt\Big\Vert\\
\leq& |y-x|^{-1}\int_{[x,y]}\Vert f(t)-f(x)\Vert dt\leq |y-x|^{-1}\int_{[x,y]}\eps dt=\eps
\end{align*}
This proves $F'(x)=f(x)$.
\end{proof}


\begin{thm}[Second FTC]\label{lb391}
Let $f\in\scr R(I,V)$. Assume that $F:I\rightarrow V$ is differentiable and $F'=f$. Then
\begin{align}
\int_a^bf=F\big|^b_a\xlongequal{\mathrm{def}} F(b)-F(a)  \label{eq163}
\end{align}
\end{thm}

This theorem is easy when $f\in C(I,V)$: In this case,   by Thm. \ref{lb390}, we have $F(x)=v_0+\int_a^x f$ for some $v_0\in V$. Then \eqref{eq163} follows immediately from Prop. \ref{lb376}. The proof for the general case is more difficult:

\begin{proof}[Proof assuming Hahn-Banach]
Since $\Rbb$ is a subfield of $\Cbb$, we may view $V$ as a real Banach space. We first consider the special case that $V=\Rbb$. Let $A=\int_a^bf$. Choose any $\eps>0$. Since $f\in\scr R(I,\Rbb)$, there exists $\sigma=\{a_0<\cdots<a_n\}\in\mc P(I)$ such that for every tag $\xi_\blt$ on $\sigma$, we have $|A-S(f,\sigma,\xi_\blt)|<\eps$. By Lagrange's MVT (Thm. \ref{lb345}), there exists $\xi_i\in (a_{i-1},a_i)$ such that
\begin{align*}
F(a_i)-F(a_{i-1})=f(\xi_i)(a_i-a_{i-1})
\end{align*}
Thus, we have a tag $\xi_\blt$ such that $S(f,\sigma,\xi_\blt)=F(b)-F(a)$. Hence $|A-F(b)+F(a)|<\eps$. Since $\eps$ is arbitrary, we get $A=F(b)-F(a)$.

The case $V=\Rbb^N$ can be reduced to the above special case easily. We now consider the general case that $V$ is a Banach space over $\Rbb$. Similar to \eqref{eq180}, for every $\varphi\in V^*=\fk L(V,\Rbb)$,  we have that $\varphi\circ F$ is differentiable, and that $(\varphi\circ F)'=\varphi\circ f$. Note that $\varphi\circ f\in\scr R(I,\Rbb)$ by Thm. \ref{lb392}. Apply the one-dimensional special case to $\varphi\circ f$. Then by Thm. \ref{lb392}, we have
\begin{align*}
\varphi\Big(\int_a^b f\Big)=\int_a^b \varphi\circ f=\varphi\circ F\big|_a^b=\varphi(F(b)-F(a))
\end{align*}
By Hahn-Banach theorem, $V^*$ separates points of $V$. (See Rem. \ref{lb393}.) Therefore $\int_a^b f=F(b)-F(a)$.
\end{proof}




\subsubsection{Applications of FTC: integration by parts}




\begin{pp}[\textbf{Integration by parts}]  \index{00@Integration by parts}
Let $f\in C^1(I,V)$ and $g\in C^1(I,\Fbb)$. Then
\begin{align}
\int_a^b f'g=(fg)\big|_a^b-\int_a^b fg'
\end{align}
\end{pp}


\begin{proof}
$(fg)\big|_a^b=\int_a^b(fg)'=\int_a^bf'g+\int_a^b fg'$.
\end{proof}

\begin{thm}[\textbf{Taylor's theorem, integral form}] \index{00@Taylor's theorem, integral form}  \label{lb425}
Let $n\in\Nbb$ and $f\in C^{n+1}([a,b],V)$. Then for every $x\in[a,b]$ we have
\begin{align}\label{eq165}
f(x)=\sum_{k=0}^n\frac{f^{(k)}(a)}{k!}(x-a)^k+\int_a^x\frac{f^{(n+1)}(t)}{n!}(x-t)^ndt
\end{align}
\end{thm}

\begin{proof}
When $n=0$, \eqref{eq165} is just FTC. We now prove \eqref{eq165} by induction. Suppose that case $n-1$ has been proved, then by integration by parts,
\begin{align*}
&f(x)-\sum_{k=0}^{n-1}\frac{f^{(k)}(a)}{k!}(x-a)^k=\int_a^x\frac{f^{(n)}(t)}{(n-1)!}(x-t)^{n-1}dt\\
=&\int_a^x -\frac{f^{(n)}(t)}{n!}\partial_t(x-t)^ndt\\
=&-\frac{f^{(n)}(t)}{n!}(x-t)^n\Big|_{t=a}^x+\int_a^x\frac{f^{(n+1)}(t)}{n!}(x-t)^ndt\\
=&\frac {f^{(n)}(a)}{n!}(x-a)^n+\int_a^x\frac{f^{(n+1)}(t)}{n!}(x-t)^ndt
\end{align*}
\end{proof}


\begin{exe}
Use the integral form of Taylor's theorem to give a quick proof higher order finite-increment Thm. \ref{lb359} under the assumption that $f\in C^{n+1}([a,b],V)$. (This assumption is slightly stronger than that in Thm. \ref{lb359}, but is enough for applications.)
\end{exe}




In the case that $V=\Rbb$, the integral form of Taylor's theorem actually implies a slightly weaker (but useful enough) version of Lagrange form. This relies on the following easy fact:


\begin{pp}[\textbf{Mean value theorem}]
Let $f,g\in C([a,b],\Rbb)$ such that $g(x)\geq 0$ for all $x\in(a,b)$. Then there exists $\xi\in [a,b]$ such that
\begin{align}
\int_a^bfg=f(\xi)\int_a^bg
\end{align}
Moreover, $\xi$ can be chosen to be in $(a,b)$ if $g(x)>0$ for all $x\in(a,b)$.
\end{pp}

\begin{proof}
Let $m=\inf f(I)$ and $M=\sup f(I)$. Then $mg\leq fg\leq Mg$, and hence $m\int_Ig\leq \int_Ifg\leq \int_IMg$. So there is $y\in [m,M]$ such that $\int_Ifg=y\int_Ig$. By extreme value theorem, we have $m,M\in f(I)$. Thus, by intermediate value property, we have $y\in f(I)$. So $y=f(\xi)$ for some $\xi\in I$.

Now assume $g(x)>0$ for all $a<x<b$. Let $\varphi(x)=\int_a^xfg$ and $\psi(x)=\int_a^xg$. By Cauchy's MVT, there exists $\xi\in(a,b)$ such that $g(\xi)(\varphi(b)-\varphi(a))=f(\xi)g(\xi)(\psi(b)-\psi(a))$. This finishes the proof.
\end{proof}



\begin{rem}
Let $f\in C^{n+1}([a,b],\Rbb)$. By the above mean value theorem, for each $x\in(a,b]$ there exists $\xi\in(a,x)$ such that
\begin{align*}
\int_a^x\frac{f^{(n+1)}(t)}{n!}(x-t)^ndt=f^{(n+1)}(\xi)\int_a^x\frac{(x-t)^n}{n!}dt=\frac{f^{(n+1)}(\xi)}{(n+1)!}(x-a)^{n+1}
\end{align*}
Thus, the integral form of Taylor's theorem implies Lagrange's form (Thm. \ref{lb395}) in the case that $f\in C^{n+1}(I,\Rbb)$.
\end{rem}


\subsubsection{Application of FTC: change of variables}



\begin{pp}[\textbf{Change of variables}]\label{lb396}
Let $\Phi\in C^1(I,\Rbb)$ such that $\Phi(I)\subset J=[c,d]$. Let $f\in C(J,V)$. Then
\begin{align}\label{eq278}
\int_{\Phi(a)}^{\Phi(b)} f=\int_a^b(f\circ\Phi)\cdot\Phi'
\end{align}
\end{pp}

\begin{proof}
Define $F:J\rightarrow V$ and $G:I\rightarrow V$ by $\dps F(y)=\int_{\Phi(a)}^y f$ and $\dps G(x)=F\circ\Phi(x)=\int_{\Phi(a)}^{\Phi(x)}f$. Then, by chain rule and FTC, $G'=(F'\circ\Phi)\cdot\Phi'=(f\circ\Phi)\cdot\Phi'$. By FTC, we have $G'=H'$ where $H:I\rightarrow V$ is defined by
\begin{align*}
H(x)=\int_a^x (f\circ\Phi)\cdot\Phi'
\end{align*}
Thus, since $G(a)=F(a)=0$, by Cor. \ref{lb326} we have $G=H$. Then $G(b)=H(b)$ finishes the proof.
\end{proof}



The change of variable formula allows us to define the length of a curve:


\begin{df}
Let $\gamma$ be a \textbf{$C^1$-curve} in $V$, i.e. $\gamma\in C^1([a,b],V)$. Its \textbf{length} \index{00@Length of a curve} is defined to be
\begin{align*}
l(\gamma)=\int_a^b\Vert \gamma'(t)\Vert dt
\end{align*}
\end{df}

\begin{pp}\label{lb477}
The length of $\gamma$ is invariant under a reparametrization. Namely, if $f:[c,d]\rightarrow[a,b]$ is a bijection and is in $C^1([c,d],\Rbb)$, then $l(\gamma)=l(\gamma\circ f)$.
\end{pp}

\begin{proof}
By Prop. \ref{lb347}, $f$ is either increasing or decreasing. We prove the case that $f$ is decreasing; the other case is similar. Then $f(c)=b$ and $f(d)=a$. By chain rule, we have
\begin{align*}
l(\gamma\circ f)=\int_c^d |(\gamma\circ f)'|=\int_c^d |(\gamma'\circ f)\cdot f'|=\int_c^d (|\gamma'|\circ f)\cdot |f'|
\end{align*}
which equals $-\int_c^d (|\gamma'|\circ f)\cdot f'=\int_d^c(|\gamma'|\circ f)\cdot f'$ because $f'\leq 0$ by Cor. \ref{lb330}. This expression equals $\int_a^b |\gamma'|=l(\gamma)$ by Prop. \ref{lb396}.
\end{proof}


\begin{eg}\label{lb398}
The upper half circle $\Sbb^1_+=\{z\in\Cbb:|z|=1,\Imag z\geq 0\}$ has a bijective $C^\infty$-parametrization $\gamma:[0,\pi]\rightarrow\Cbb,\gamma(t)=e^{\im t}$. Its length is $\pi$.
\end{eg}


\begin{proof}
We have $l(\gamma)=\int_0^\pi |\gamma'|=\int_0^\pi 1=\pi$. So it remains to prove that $\gamma$ restricts to a bijection $[0,\pi]\rightarrow \Sbb^1_+$. Clearly $\gamma([0,\pi])\subset \Sbb^1=\{z\in\Cbb:|z|=1\}$. Note that $\gamma(t)=\cos(t)+\im\sin(t)$. In Sec. \ref{lb397}, we have proved that $\sin(x)\geq0$ when $x\in[0,\pi]$. So $\gamma([0,\pi])\subset \Sbb^1_+$. 

We have also proved in Sec. \ref{lb397} that $\cos:[0,\pi/2]\rightarrow\Rbb$ is a decreasing (continuous) function such that $\cos(0)=1$ and $\cos(\pi/2)=0$, and that $\cos(x)=\cos(\pi-x)$. The last relation shows that $\cos:[0,\pi]\rightarrow\Rbb$ is decreasing, and $\cos(0)=1,\cos(\pi)=-1$. Therefore, by the intermediate value theorem, we see that $\cos$ sends $[0,\pi]$ bijectively to $[-1,1]$. Since the projection map onto the $x$-axis sends $\Sbb^1_+$ bijectively to $[-1,1]$, we conclude that $\gamma$ sends $[0,\pi]$ bijectively to $\Sbb^1_+$.
\end{proof}

\begin{rem}
You may wonder if the above argument really proves that $\pi$ is the length of $\Sbb^1_+$: Suppose that $\lambda:[a,b]\rightarrow \Cbb$ is another $C^\infty$ map restricting to a bijection $[a,b]\rightarrow \Sbb^1_+$, how can we show that $\int_0^\pi |\gamma'|=\int_a^b|\lambda'|$ ? Clearly, there is a bijection $f:[a,b]\rightarrow[0,\pi]$ such that $\lambda=\gamma\circ f$. Thus, by Prop. \ref{lb477}, the two integrals are equal if $f\in C^\infty$, or at least if $f\in C^1$. However, it seems that there is no general argument ensuring that $f\in C^1$.

In the next semester, we will learn that $f\in C^\infty$ if the two $C^\infty$-parametrizations $\lambda,\gamma$ satisfy that $\lambda'$ and $\gamma'$ are nowhere zero. (Clearly $\gamma'$ is nowhere zero if $\gamma(t)=e^{\im t}$.) Such parametrizations are called \textbf{(smooth) immersions}.  \hfill\qedsymbol
\end{rem}

%% Record #19 2023/11/27 two lectures  47








\subsection{Problems and supplementary material}


Let $I=[a,b]$ where $-\infty<a<b<+\infty$.



\begin{prob}\label{lb386}
Let $f\in l^\infty(I,\Rbb)$. Recall from Subsec. \ref{lb384} that the refinements of partitions define preoders on $\mc P(I)$ and $\mc Q(I)$ so that they are directed sets. For each $\sigma=\{a_0<a_1<\cdots<a_n\}\in\mc P(I)$, define the \textbf{upper Darboux sum} and the \textbf{lower Darboux sum} \index{00@Upper and lower Darboux sums}
\begin{gather*}
\ovl S(f,\sigma)=\sum_{i=1}M_i(a_i-a_{i-1})\qquad~~~ \underline S(f,\sigma)=\sum_{i=1}m_i(a_i-a_{i-1})\\
\text{where}\qquad M_i=\sup_{\xi\in[a_{i-1},a_i]}f(\xi)\qquad m_i=\inf_{\xi\in[a_{i-1},a_i]}f(\xi)
\end{gather*}
Prove that 
\begin{align*}
-(b-a)\Vert f\Vert_\infty\leq\underline S(f,\sigma)<\ovl S(f,\sigma)\leq (b-a)\Vert f\Vert_\infty
\end{align*}
Choose any tag $\xi_\blt$ on $\sigma$. Prove that
\begin{gather}
\ovl S(f,\sigma)=\sup_{(\sigma',\xi_\blt')\succ (\sigma,\xi_\blt)} S(f,\sigma',\xi_\blt')\qquad~~~ \underline S(f,\sigma)=\inf_{(\sigma',\xi_\blt')\succ (\sigma,\xi_\blt)} S(f,\sigma',\xi_\blt')
\end{gather}
\end{prob}


Pb. \ref{lb386} immediately implies:
\begin{thm}\label{lb444}
Let $f\in l^\infty(I,\Rbb)$. Define the \textbf{upper Darboux integral} and the \textbf{lower Darboux integral} \index{00@Upper and lower Darboux integrals} \index{00@Darboux integrals} to be
\begin{align*}
\ovl\int_a^b f=\inf_{\sigma\in\mc P(I)}\ovl S(f,\sigma)\qquad~~~\underline\int_a^b f=\sup_{\sigma\in\mc P(I)}\underline S(f,\sigma)
\end{align*}
which are elements of $[-(b-a)\Vert f\Vert_\infty,(b-a)\Vert f\Vert_\infty]$. Then we have (recalling Pb. \ref{lb346})
\begin{align*}
\ovl\int_a^b f=\limsup_{(\sigma,\xi_\blt)\in\mc Q(I)}S(f,\sigma,\xi_\blt)\\
\underline\int_a^b f=\liminf_{(\sigma,\xi_\blt)\in\mc Q(I)}S(f,\sigma,\xi_\blt)
\end{align*}
Therefore, by Cor. \ref{lb385}, we have 
\begin{align}
f\in\scr R(I,\Rbb)\qquad\Longleftrightarrow\qquad \ovl\int_a^bf=\underline\int_a^bf
\end{align}
Moreover, if $f\in\scr R(I,\Rbb)$, then $\int_a^b f=\ovl\int_a^bf=\underline\int_a^bf$.
\end{thm}



\begin{prob}\label{lb387}
Let $\mc V$ be a vector space over $\Cbb$. Since $\Rbb$ is a subfield of $\Cbb$, $\mc V$ can be viewed as a real normed vector space. Let $\Lambda:\mc V\rightarrow\Rbb$ be a $\Rbb$-linear map. Recall $\im=\sqrt{-1}$. Define the \textbf{complexification} of $\Lambda$ \index{00@Complexification of real linear functionals} to be
\begin{align}
\Lambda_\Cbb:\mc V\rightarrow\Cbb\qquad \Lambda_\Cbb(v)=\Lambda(v)-\im\Lambda(\im v) \label{eq162}
\end{align}
\begin{enumerate}
\item Prove that $\Lambda_\Cbb$ is $\Cbb$-linear.
\item Given a $\Cbb$-linear $\Phi:\mc V\rightarrow\Cbb$, we define its \textbf{real part} \index{00@Real part of a $\Cbb$-linear functional}
\begin{align}
\Real \Phi:\mc V\rightarrow\Rbb\qquad v\mapsto\Real~\big(\Phi(v)\big)
\end{align}
Then clearly $\Real(\Phi)$ is $\Rbb$-linear. Prove that $\Phi\mapsto\Real\Phi$ is a bijection from the set of $\Cbb$-linear maps $\mc V\rightarrow\Cbb$ to the set of $\Rbb$-linear maps $\mc V\rightarrow\Rbb$, and that its inverse is the map $\Lambda\mapsto\Lambda_\Cbb$ defined by \eqref{eq162}.
\item Assume that $\mc V$ is a (non-necessarily complete) normed $\Cbb$-vector space. For each $\Cbb$-linear $\Phi:\mc V\rightarrow\Cbb$, prove the following equation about operator norms:
\begin{align}
\Vert \Phi\Vert=\Vert\Real\Phi\Vert
\end{align}
(Hint: One of ``$\leq$" and ``$\geq$" is obvious. To prove the other one, for each $v\in \mc V$, find some $\theta\in\Rbb$ such that $e^{\im\theta}\Phi(v)\in\Rbb$.)
\end{enumerate}
\end{prob}


\begin{rem}
The above problem shows how to extend a real-valued integral to a complex-valued one. For example, suppose that we define real-valued Riemann integrals using Darboux integrals. Suppose we have proved that the map $f\in\scr R(I,\Rbb)\mapsto\int_a^b f$ is $\Rbb$-linear with operator norm $(b-a)$. Then, applying Pb. \ref{lb387} to the $\Rbb$-linear map
\begin{align*}
\Lambda:\scr R(I,\Cbb)\rightarrow \Rbb\qquad f\mapsto \int_a^b \Real f(t)dt
\end{align*}
gives a $\Cbb$-linear map
\begin{gather*}
\int_a^b:\scr R(I,\Cbb)\rightarrow\Cbb\\
\int_a^b f=\int_a^b\Real f+\im\int_a^b\Imag f
\end{gather*}
since $\Real(\im f)=-\Imag f$. Moreover, this linear map has operator norm $(b-a)$. This defines the complex integral operator by means of real Darboux integrals. In the next semester, we will use the same method to extend real-valued Lebesgue integrals to complex-valued ones. Pb. \ref{lb387} will also be used to prove the Hahn-Banach extension theorem.
\end{rem}


\begin{exe}
Let $u,v\in C(I,\Rbb)$. Find the $\Cbb$-linear map $C(I,\Cbb)\rightarrow\Cbb$ whose real part is $f\in C(I,\Cbb)\mapsto \int_I(u\Real f+v\Imag f)\in\Rbb$. 
\end{exe}



\begin{sprob}\label{lb389}
Let $V=l^\infty([0,1],\Rbb)$, equipped with the $l^\infty$-norm. Define 
\begin{align*}
f:[0,1]\rightarrow V\qquad f(x)=\chi_{[x,1]}
\end{align*}
Then, for every $x\neq y$ in $[0,1]$ we have $\Vert f(x)-f(y)\Vert_{l^\infty([0,1],\Rbb)}=1$. This implies $\omega(f,\sigma)=1$ for every $\sigma\in\mc P(I)$. So $f$ is not strongly Riemann integrable on any closed subintegral of $[a,b]$. 

Define $F:[0,1]\rightarrow V$ such that for each $x\in [0,1]$,
\begin{align*}
F(x):[0,1]\rightarrow\Rbb\qquad t\mapsto\min\{t,x\}
\end{align*}
Choose any $x\in[0,1]$. Prove that $f\in\scr R([0,x],V)$ and $\int_0^xf=F(x)$. (In particular, $\int_0^1f=\id_{[0,1]}$.) Prove that $F'(x)$ does not exist.  \hfill\qedsymbol
\end{sprob}

\begin{comment}
\begin{proof}[Hint]
To find $\int_0^1f$, for each $y\in\Rbb$, define $\varphi_y:V\rightarrow\Rbb$ by $\varphi_y(f)=f(y)$. Then $\varphi_y\in\fk L(V,\Rbb)$. Use $\varphi_y(\int_0^1f)=\int_0^1\varphi_y(f)$ to calculate $\int_0^1f$.
\end{proof}
\end{comment}



\begin{prob}
Let $V$ be a Banach space. Use the fundamental theorem of calculus to give another proof that $C^1(I,V)$ is complete under the $l^{1,\infty}$-norm. (Do not use Thm. \ref{lb336}.)
\end{prob}





\begin{sthm}[\textbf{Gronwall's inequality}] \index{00@Gronwall's inequality}
Let $f\in C([a,b],\Rbb_{\geq0})$. Let $\alpha\in\Rbb_{\geq0}$, and $\beta\in C([a,b],\Rbb_{\geq0})$. Assume that for each $x\in[a,b]$ we have
\begin{align}
f(x)\leq  \alpha+\int_a^x\beta(t)f(t) dt  \label{eq160}
\end{align}
Then for each $x\in[a,b]$ we have
\begin{align}
f(x)\leq \alpha\cdot  \exp\Big(\int_a^x \beta(t)dt \Big)
\end{align}
\end{sthm}
In particular, if $\beta$ is a constant, then Gronwall's inequality reads
\begin{align*}
f(x)\leq\alpha\cdot e^{\beta (t-a)}
\end{align*}

\begin{sprob}
Prove Gronwall's inequality. Hint: Let $g(x)$ be the RHS of \eqref{eq160}. Show that $\exp(-\int_a^x\beta)\cdot g(x)$ is a decreasing function.
\end{sprob}

\begin{srem}
Gronwall's inequality is often used in the following way. Let $V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$. Let $f\in C(I,V)$, $v\in V$, and $\beta\in C(I,\Rbb_{\geq0})$. Suppose that for all $x\in[a,b]$ we have
\begin{align}
\Vert f(x)-v\Vert\leq\int_a^x\beta(t)\Vert f(t)\Vert dt
\end{align}
Applying Gronwall's inequality to $|f|$ and $\alpha=\Vert v\Vert$, we see that for every $x\in[a,b]$,
\begin{align}
\Vert f(x)\Vert\leq \Vert v\Vert\cdot  \exp\Big(\int_a^x \beta(t)dt \Big)
\end{align}
\end{srem}





\begin{sprob}
Let $V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$. Assume that $\varphi\in C(I\times V,V)$ has Lipschitz constant $L\in\Rbb_{\geq0}$ over the second variable, i.e., for each $t\in[a,b]$ and $u,v\in V$ we have
\begin{align}
\Vert\varphi(t,u)-\varphi(t,v)\Vert\leq L\Vert u-v\Vert
\end{align}
Use Gronwall's inequality  to solve the following problems.
\begin{enumerate}
\item Let $f_1,f_2:I\rightarrow V$ be differentiable and satisfying the differential equation
\begin{align*}
\dps f'_i(t)=\varphi(t,f_i(t))\qquad (\forall t\in I)
\end{align*}
with the same initial condition $f_1(a)=f_2(a)$. Prove that $f_1=f_2$ on $I$.
\item Let $X$ be a topological space. Let $f:I\times X\rightarrow V$ be a function such that $\partial_1 f$ exists everywhere, and that
\begin{align*}
\partial_1 f(t,x)=\varphi(t,f(t,x))\qquad(\forall t\in I,x\in X)
\end{align*}
Assume that the function $f(a,\cdot):X\rightarrow V$ (sending $x$ to $f(a,x)$) is continuous. Prove that $f\in C(I\times X,V)$.
\end{enumerate} 
\end{sprob}


\begin{rem}\label{lb479}
In practice, $V$ is often $\Rbb^N$, and $\varphi$ is a ``smooth function", i.e. a function whose (mixed) partial derivatives of all orders exist and are continuous. It is also common that $\varphi$ is independent of $t\in I$. (Indeed, a $t$-dependent differential equation $f'=\varphi(t,f)$ can be transformed into a $t$-independent one $(t,f)'=(1,\varphi(t,f))$.) However, sometimes $f$ is not defined on $\Rbb^N$, but on a closed subset of $\Rbb^N$, for example, on a closed ball. In this case, the uniqueness and the continuity of the solutions of differential equations can be treated by extending $\varphi$ to a smooth function on $\Rbb^N$ that is zero outside a compact set. (Then the Lipschitz continuity of this extended function will follow automatically.) 

In fact, by the \textbf{smooth Tietze extension theorem} (Thm. \ref{mc30}), every smooth function $A\rightarrow\Rbb^k$ (where $A$ is a compact subset of a smooth real manifold $M$ (such as a Euclidean space, an $n$-dimensional sphere, etc.)) can be extended to a smooth function $M\rightarrow\Rbb^k$ vanishing outside a compact set. We will study this theorem in the second semester. (The case $A\subset\Rbb$ will be proved in Exp. \ref{lb478}.) \hfill\qedsymbol
\end{rem}
















\newpage




\section{More on Riemann integrals}


\subsection{Commutativity of integrals and other limit processes}\label{lb419}


Let $I=[a,b]$ and $J=[c,d]$ where $-\infty<a<b<+\infty$ and $-\infty<c<d<+\infty$. Let $V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$.


\subsubsection{Fubini's theorem}


\begin{thm}[\textbf{Fubini's theorem for Riemann integrals}] \label{lb399} \index{00@Fubini's theorem for Riemann integrals}
Let $f\in C(I\times J,V)$. Then $\int_I\int_Jf=\int_J\int_If$. More precisely,
\begin{align}
\int_I\Big(\int_Jf(x,y)dy\Big)dx=\int_J\Big(\int_I f(x,y)dx\Big)dy
\end{align}
\end{thm}

Our strategy is to view $\int_I f(x,y)dx$ as the integral of the function $I\rightarrow C(J,V)$ sending $x$ to $f(x,\cdot)$. Then Fubini's theorem follows from the commutativity of integrals and the bounded linear map $\int_J:C(J,V)\rightarrow V$ (cf. Thm. \ref{lb392}). We first make some general discussion before giving the rigorous proof.


Let $Y$ be a compact topological space. By Thm. \ref{lb274}, we have a canonical equivalence $C(I\times Y,V)\simeq C(I,C(Y,V))$ by viewing $f\in C(I\times Y,V)$ as a map
\begin{subequations}\label{eq167}
\begin{align}
\Phi(f):I\rightarrow C(Y,V)
\end{align}
where
\begin{align}
\Phi(f)(x)=f(x,\cdot):Y\rightarrow V\qquad y\mapsto f(x,y)
\end{align}
\end{subequations}
Recall that the space of continuous functions on a compact space is equipped with the $l^\infty$-norm, and $C(Y,V)$ is complete since $V$ is complete (Cor. \ref{lb101}).

\begin{lm}\label{lb400}
The integral  $\int_I\Phi(f)$, which is an element of $C(Y,V)$, is the function
\begin{align}
\int_If(x,\cdot)dx:Y\rightarrow V\qquad y\mapsto \int_I f(x,y)dx
\end{align}
In other words, for every $y\in Y$ we have
\begin{align}
\Big(\int_I\Phi(f)\Big)(y)=\int_I f(x,y)dx
\end{align}
Consequently, the function $\int_If(x,\cdot)dx$ is continuous.
\end{lm}


It is easy to show that $\int_If(x,\cdot)dx$ is continuous without assuming that $Y$ is compact. See Exe. \ref{lb408}.


\begin{proof}
For each $y\in Y$, define linear map
\begin{align*}
\varphi_y:C(Y,V)\rightarrow V\qquad g\mapsto g(y)
\end{align*}
Then this linear map is clear bounded (with operator norm $1$). Thus, by Thm. \ref{lb392}, we have
\begin{align*}
\Big(\int_I\Phi(f)(x)dx\Big)(y)=\varphi_y\Big(\int_I\Phi(f)(x)dx\Big)=\int_I\varphi_y\big(\Phi(f)(x)\big)dx=\int_I f(x,y)dx
\end{align*}
\end{proof}



\begin{proof}[\textbf{Proof of Thm. \ref{lb399}}]
By Thm. \ref{lb375}, the integral operator $\int_J:C(J,V)\rightarrow V$ is a bounded linear map. Therefore, by Thm. \ref{lb392} (and in particular \eqref{eq166}), we have a commutative diagram
\begin{equation*}
\begin{tikzcd}[column sep=huge]
C(I,C(J,V)) \arrow[r,"\int_J\circ"] \arrow[d,"\int_I"'] & C(I,V) \arrow[d,"\int_I"] \\
C(J,V) \arrow[r,"\int_J"]           & V          
\end{tikzcd} 
\end{equation*}
where the top arrow is the map sending $\Phi(f)$ to $\int_J\circ\Phi(f)$, i.e., sending $x\mapsto f(x,\cdot)$ to $x\mapsto \int_J f(x,y)dy$. Thus, the direction ${}^\rightarrow\!\downarrow$ sends $\Phi(f)$ to $\int_I\int_Jf(x,y)dydx$. By Lem. \ref{lb400}, the left downward arrow sends $\Phi(f)$ to the function $y\in J\mapsto \int_I f(x,y)dx$. So $\downarrow_\rightarrow$ sends $\Phi(f)$ to $\int_J\int_I f(x,y)dxdy$. Thus, the commutativity of the above diagram proves Fubini's theorem.
\end{proof}


\begin{df}\label{lb487}
Let $I_1,\dots,I_N$ be compact intervals in $\Rbb$. Let $B=I_1\times\cdots\times I_N$ and $f\in C(B,V)$. We define the \textbf{Riemann integral} of $f$ to be
\begin{align*}
\int_Bf=\int_{I_1}\cdots\int_{I_N}f(x_1,\dots,x_N)dx_N\cdots dx_1
\end{align*}
Then, by Fubini's theorem, for any bijection $\sigma:\{1,\dots,N\}\rightarrow\{1,\dots,N\}$ we have
\begin{align*}
\int_Bf=\int_{I_{\sigma(1)}}\cdots\int_{I_{\sigma(N)}}f(x_1,\dots,x_N)dx_{\sigma(N)}\cdots dx_{\sigma(1)}
\end{align*}
\end{df}


\subsubsection{Commutativity of integrals and derivatives}


Recall from Cor. \ref{lb344} that $l^{1,\infty}(J,V)$ is a Banach space. So its closed linear subspace $C^1(J,V)$ (cf. Pb. \ref{lb355}) is a Banach space under the $l^{1,\infty}$-norm $\Vert g\Vert_{1,\infty}=\Vert g\Vert_\infty+\Vert g'\Vert_\infty$.

Let $f:I\times J\rightarrow V$. Consider $f$ as a map $\Psi(f):I\rightarrow V^J$ sending $x$ to
\begin{align}
\Psi(f)(x)=f(x,\cdot):J\rightarrow V\qquad  y\mapsto f(x,y)  \label{eq173}
\end{align}
Let $\partial_J$ be the (partial) derivative with respect the variable $y\in J$. Clearly
\begin{align}
\partial_J\big(\Psi(f)(x)\big)=\partial_Jf(x,\cdot)
\end{align}
The linear map of derivative
\begin{align}
\partial_J:C^1(J,V)\rightarrow C(J,V)\qquad g\mapsto g'=\partial_Jg
\end{align}
is clearly bounded (with operator norm $\leq 1$).

\begin{pp}\label{lb402}
Let $X$ be a topological space. Let $f:X\times J\rightarrow V$, and define $\Psi(f):X\rightarrow V^J$ by \eqref{eq173}. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $\Psi(f)$ is an element of $C(X,C^1(J,V))$. In other words:
\begin{itemize}
\item[(1a)] For each $x\in X$ we have $\Psi(f)(x)\in C^1(J,V)$.
\item[(1b)] The function $x\in X\mapsto \Psi(f)(x)\in C^1(J,V)$ is continuous.
\end{itemize}
\item $\partial_Jf$ exists everywhere on $X\times J$. Moreover, we have $f,\partial_Jf\in C(X\times J,V)$. 
\end{enumerate}
\end{pp}



\begin{proof}
(1a) means that the functions $y\mapsto f(x,y)$ and $y\mapsto \partial_Jf(x,y)$ exist and are continuous. (1b) is equivalent to that the maps
\begin{gather*}
x\in X\mapsto\Psi(f)(x)=f(x,\cdot)\in C(J,V)\\
x\in X\mapsto \partial_J\Psi(f)(x)=\partial_Jf(x,\cdot)\in C(J,V)
\end{gather*}
are continuous (under the $l^\infty$-norm). By Thm. \ref{lb274}, this is equivalent to that $f$ and $\partial_Jf$ are continuous maps $X\times J\rightarrow V$. So (1)$\Leftrightarrow$(2).
\end{proof}

We return to the setting of $f:I\times J\rightarrow V$.

\begin{lm}\label{lb403}
The integral  $\int_I\Psi(f)$, which is an element of $C^1(J,V)$, is the function
\begin{align}
\int_If(x,\cdot)dx:J\rightarrow V\qquad y\mapsto \int_I f(x,y)dx
\end{align}
Consequently, the function $\int_If(x,\cdot)dx$ is in $C^1(J,V)$.
\end{lm}


\begin{proof}
This lemma can be proved in the same way as Lem. \ref{lb400}, using the fact that for every $y\in J$, the linear map $g\in C^1(J,V)\rightarrow g(y)$ is bounded.
\end{proof}



\begin{comment}
The inclusion map
\begin{align}
\kappa:C^1(J,V)\rightarrow C(J,V)\qquad g\mapsto g
\end{align}
is a bounded linear map (with operator norm $\leq 1$). What we really want to prove is that $\kappa(\int_I\Psi(f))$, which is an element of $C(J,V)$, is given by the function $y\mapsto \int_If(x,y)dx$. By Thm. \ref{lb392}, we have $\kappa(\int_I\Psi(f))=\int_I\kappa\circ\Psi(f)=\int_I\Phi(f)$ where $\Phi(f)$ is defined as in \eqref{eq167}, i.e. $\Phi(f)(x)=f(x,\cdot)$. By Lem. \ref{lb400}, $\int_I\Phi(f)$ is the function $y\mapsto\int_If(x,y)dx$. This finishes the proof.
\end{comment}



\begin{thm}\label{lb405}
Let $f:I\times J\rightarrow V$. Assume that $\partial_Jf$ exists everywhere on $I\times J$. Assume moreover that $f,\partial_Jf\in C(I\times J,V)$. Then for each $y\in J$, the LHS of \eqref{eq168} exists and equals the RHS of \eqref{eq168}, where
\begin{align}
\partial_J\int_I f(x,y)dx=\int_I\partial_J f(x,y)dx  \label{eq168}
\end{align}
\end{thm}


\begin{proof}[First proof]
Again, by Thm. \ref{lb392}, we have a commutative diagram
\begin{equation*}
\begin{tikzcd}[column sep=huge]
C(I,C^1(J,V)) \arrow[r,"\partial_J\circ"] \arrow[d,"\int_I"'] & C(I,C(J,V)) \arrow[d,"\int_I"] \\
C^1(J,V) \arrow[r,"\partial_J"]           & C(J,V)         
\end{tikzcd} 
\end{equation*}
By Prop. \ref{lb402}, $\Psi(f)$ is an element of $C(I,C^1(J,V))$. The map $\Psi(f):I\rightarrow C^1(J,V)$, composed with $\partial_J$, gives $x\in I\mapsto\partial_Jf(x,\cdot)$. 
%So $\partial_J\circ\Psi(f)=\Phi(\partial_Jf)$ where $\Phi(\partial_Jf)$ is defined as in \eqref{eq167}. 
By Lem. \ref{lb400}, the direction ${}^\rightarrow\!\downarrow$ sends $\Psi(f)$ to $\int_I\partial_J f(x,\cdot)dx$. By Lem. \ref{lb403}, $\int_I\Psi(f)$ equals $\int_I f(x,\cdot)$. In particular, $\int_I f(x,\cdot)$ is a $C^1$-function. So $\downarrow_\rightarrow$ sends $\Psi(f)$ to $\partial_J\int_I f(x,\cdot)dx$. This finishes the proof.
\end{proof}



\begin{proof}[Second proof]
Fix any $y\in J$. In view of Cor. \ref{lb380}, it suffices to prove that the limit of the net of functions $(\varphi_p)_{p\in J\setminus\{y\}}$ from $I$ to $V$ converges uniformly to $\partial_Jf(\cdot,y)$ under $\lim_{p\rightarrow y}$, where
\begin{align*}
\varphi_p(x)=\frac{f(x,p)-f(x,y)}{p-y}
\end{align*}
By Rem. \ref{lb404}, we have
\begin{align*}
\Vert \varphi_p(x)-\partial_Jf(x,y)\Vert\leq A(x,p):=\sup_{q\in[p,y]\cup[y,p]}\Vert \partial_Jf(x,q)-\partial_Jf(x,y)\Vert
\end{align*}
Since $\partial_Jf$ is continuous, it can be viewed as a continuous map $J\rightarrow C(I,V)$ by Thm. \ref{lb274}. Thus, for every $\eps>0$ there exists $\delta>0$ such that for every $p\in J$ satisfying $|p-y|\leq\delta$, we have $\sup_{x\in I}\Vert \partial_Jf(x,q)-\partial_Jf(x,y)\Vert\leq\eps$ for all $q\in[p,y]\cup[y,p]$, and hence $\sup_{x\in I}A(x,p)\leq\eps$. This proves that $A(\cdot,p)$ converges uniformly to $0$ (as a net of functions $I\rightarrow\Rbb$) as $p\rightarrow y$, finishing the proof.
\end{proof}




\subsubsection{Commutativity of partial derivatives}


We write $\partial_If(x,y)$ as $\partial_1f(x,y)$ and $\partial_Jf(x,y)$ as $\partial_2f(x,y)$. In the following, we use Thm. \ref{lb405} to give a new proof of a slightly weaker version of Thm. \ref{lb406} on the commutativity of $\partial_1$ and $\partial_2$. The idea is as follows. Suppose we know that $A,B$ are linear operators on a vector space such that $A$ is invertible and $A^{-1}B=BA^{-1}$. Then one deduces $A^{-1}BA=BA^{-1}A=B$ and hence $BA=AA^{-1}BA=AB$. Now, Thm. \ref{lb405} says that $\partial_J$  commutes with $\int_I$, the inverse of $\partial_I$ (in a vague sense). So one can use a similar algebraic argument to prove that $\partial_J$ commutes with $\partial_I$.

%For the reader's convenience, we reproduce the content of Thm. \ref{lb406} as follows, along with some additional conclusions (i.e. the continuity of $\partial_1f$ and $\partial_2f$).


\begin{thm}\label{lb407}
Let $f:I\times J\rightarrow V$ be a function such that $\partial_1f,\partial_2f,\partial_2\partial_1f$ exist and are continuous on $I\times J$. Then $\partial_1\partial_2f$ exists on $I\times J$ and equals $\partial_2\partial_1f$. (So $\partial_1\partial_2f$ is also continuous.)
\end{thm}


Thm. \ref{lb407} is weaker than Thm. \ref{lb406} in that we assume $\partial_1f,\partial_2f$ to be continuous. Indeed, as we shall see in the proof, the continuity of $\partial_2f$ is not used. However, in concrete examples, it is fairly easy to check the continuity of  $\partial_1f,\partial_2f$. 


\begin{proof}
%Since $\partial_2\partial_1f$ exists, the function $y\in J\mapsto\partial_1f(a,y)$ is differentiable and in particular continuous. Thus, the continuity of $\partial_1f$ follows easily from
%\begin{align*}
%\partial_1f(x,y)=\partial_1f(a,y)+\int_a^x\partial_2\partial_1f(u,y)du
%\end{align*}
%and the continuity of $\partial_2\partial_1f$. (See Exe. \ref{lb408}.) Similarly, one can prove that $\partial_2f$ is continuous if one can prove $\partial_1\partial_2f=\partial_2\partial_1f$. 
Let $\dps F(x,y)=\int_a^x\partial_2\partial_1 f(u,y)du$, which can be defined because $\partial_2\partial_1f$ is continuous. By FTC, we have $\partial_1F=\partial_2\partial_1f$. On the other hand, by Thm. \ref{lb405} and the continuity of $\partial_1f,\partial_2\partial_1f$, we have
\begin{align*}
F(x,y)=\partial_2\int_a^x\partial_1f(u,y)du=\partial_2(f(x,y)-f(a,y))
\end{align*}
Therefore $\partial_1\partial_2f$ exists and equals $\partial_1F=\partial_2\partial_1f$.
\end{proof}


\begin{exe}\label{lb408}
Let $Y$ be a topological space. Let $f\in C(I\times Y,V)$. Prove that the following function is continuous:
\begin{gather}
I\times Y\rightarrow V\qquad (x,y)\mapsto\int_a^x f(u,y)du
\end{gather}
\end{exe}



\begin{exe}
Use Fubini's Thm \ref{lb399} to prove Thm. \ref{lb405}.
\end{exe}




\subsection{Lebesgue's criterion for Riemann integrability}\label{lb522}


Fix $I=[a,b]$ where $-\infty<a<b<+\infty$. Let $V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$. The goal of this section is to prove:


\begin{thm}[\textbf{Lebesgue's criterion}] \index{00@Lebesgue's criterion for strong Riemann integrability}  \label{lb411}
Let $f:I\rightarrow V$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $f$ is strongly Riemann integrable.
\item $f$ is bounded (i.e. $\Vert f\Vert_{l^\infty}<+\infty$). Moreover, the set of discontinuities
\begin{align}
\{x\in I:f\text{ is not continuous at }x\}
\end{align}
is a null set.
\end{enumerate}
\end{thm}


\begin{df}\label{lb409}
A subset $E$ of $\Rbb$ is called a  \textbf{(Lebesgue) null set} \index{00@Null set, Lebesgue} (or a set of \textbf{(Lebesgue) measure zero}) if for every $\eps>0$ there exist countably many closed intervals $I_1,I_2,\dots$ such that $E\subset\bigcup_i I_i$, and that $\sum_i |I_i|<\eps$. Here, $|I_i|$ is the length of $I_i$.
\end{df}

The word ``countably many" can be omitted, because the sum of uncountably many strictly positive reals numbers must be $+\infty$ due to Pb. \ref{lb413}.

\begin{rem}
Covering $E$ by open intervals instead of closed ones does not change the definition of null sets. This is because any open/closed interval can be stretched by a factor of $1+\delta$ to a larger closed/open interval, where $\delta$ is any given positive number.
\end{rem}


\begin{pp}\label{lb412}
A countable union of null subsets of $\Rbb$ is a null set.
\end{pp}

\begin{proof}
If $E=E_1\cup E_2\cup\cdots$ where each $E_i$ is a null set, then for each $\eps$, $E_i$ can be covered by countably many closed intervals of total length $<2^{-i}\eps$. So $E$ can be covered by by countably many closed intervals of total length $<\eps$.
\end{proof}


\begin{eg}
Every interval with at least two points is not a null set.
\end{eg}

\begin{proof}
Since every such interval contains a closed invertal with at least two points, it suffices to prove that the latter is not null. Thus, let us prove that $I$ is not null. Suppose $I$ is covered by some open intervals. Then, since $I$ is compact, $I$ is covered by finitely many of these open intervals, say $U_1,\dots,U_n$. It is easy to see that  $\sum_{i=1}^n |U_i|\geq|I|= b-a$. (For example, let $f=\sum_i \chi_{U_i}$. Then $f\geq \chi_I$. So $\sum_i |U_i|=\sum_i\int\chi_{U_i}=\int f\geq\int_a^b 1=b-a$.)
\end{proof}



Before proving Lebesgue's criterion, let us first see some useful applications. Recall that if $V=\Rbb^N$ then Riemann integrability is equivalent to strong Riemann integrability (Thm. \ref{lb410}).

\begin{co}
Let $f\in\scr R(I,\Rbb^n)$. Let $\Omega$ be a subset of $\Rbb^n$ containing $f(I)$. Let $g\in C(\Omega,\Rbb^m)$ such that $\Vert g\Vert_\infty<+\infty$. Then $g\circ f\in\scr R(I,\Rbb^m)$
\end{co}

Note that if $\Omega$ is compact, we automatically have $\Vert g\Vert_\infty<+\infty$.

\begin{proof}
Clearly $g\circ f$ is bounded. The set of discontinuities of $g\circ f$ is null since it is a subset of the set of discontinuities of $f$, where the latter is a null set.
\end{proof}


\begin{co}
Let $f\in\scr R(I,\Fbb^{m\times n})$ and $g\in\scr R(I,\Fbb^{n\times k})$. Then $fg\in\scr R(I,\Fbb^{m\times k})$.
\end{co}

\begin{proof}
This is immediate from Lebesgue's criterion.
\end{proof}


\subsubsection{Proof of Lebesgue's criterion}


The first step of proving Lebesgue's criterion is to express the set of discontinuities by the oscillation.

\begin{df}\label{lb462}
Let $X$ be a topological space. Let $Y$ be a metric space. The \textbf{oscillation} \index{00@Oscillation at a point} \index{zz@$\omega(f,x)$} of a function $f:X\rightarrow Y$ at $x\in X$ is defined to be
\begin{align*}
\omega(f,x)=\inf_{U\in\Nbh_X(x)}\diam(f(U))
\end{align*}
\end{df}


\begin{pp}\label{lb461}
Let $X$ be a topological space, let $Y$ be a metric space, and let $f:X\rightarrow Y$. Then  $f$ is continuous at $x\in X$ iff $\omega(f,x)=0$.
\end{pp}


\begin{proof}
Assume that $f$ is continuous at $x$. Then for every $\eps>0$, there exists $U\in\Nbh(x)$ such that $d(f(p),f(x))<\eps/2$ for every $p\in X$. Then clearly $\diam(f(U))\leq\eps$. So $\omega(f,x)\leq \eps$. Since $\eps>0$ is arbitrary, we get $\omega(f,x)=0$.

Conversely, suppose $\omega(f,x)=0$. Then for every $\eps>0$ there exists $U\in\Nbh(x)$ such that $\diam(f(U))<\eps$. So for every $p\in U$ we have $d(f(p),f(x))<\eps$.
\end{proof}



\begin{proof}[\textbf{Proof of Thm. \ref{lb411}, part 1}]
Let us prove (1)$\Rightarrow$(2). Assume that $f$ is strongly Riemann integrable. Choose any $\eps>0$. Let us prove that
\begin{align}
\Omega_\eps(f)=\{x\in I:\omega(f,x)\geq\eps\}\label{eq200}
\end{align}
is a null set. Then the set of discontinuities, which is $\bigcup_{n\in\Zbb_+}\Omega_{1/n}(f)$, is a null set by Prop. \ref{lb412}.

Since $\inf_{\sigma\in\mc P(I)}\omega(f,\sigma)=0$, for every $\delta>0$, there exists $\sigma=\{a_0<\cdots<a_n\}\in\mc P(I)$ such that, with $I_i=[a_{i-1},a_i]$, we have 
\begin{align}
\sum_{i=1}^n \diam(f(I_i))\cdot |I_i|<\delta\eps\label{eq170}
\end{align}
Note that if $x\in I\setminus\sigma$ is in some $I_i$ where $\diam(f(I_i))<\eps$, then clearly $\omega(f,x)<\eps$. Thus, if $\omega(f,x)\geq \eps$ (i.e., if $x\in\Omega_\eps(f)$), then either $x\in\sigma$, or $x\in I_i$ for some $I_i$ such that $\diam(f(I_i))\geq\eps$. We conclude
\begin{align*}
\Omega_\eps(f)\subset\{a_0,\dots,a_n\}\cup\Big(\bigcup_{k\in K}I_k\Big)
\end{align*}
where $K=\{1\leq k\leq n:\diam(f(I_k))\geq\eps\}$. Clearly $\{a_0,\dots,a_n\}$ can be covered by some intervals with total length $<\delta$. But \eqref{eq170} implies that $\sum_{k\in K}\eps|I_k|<\delta\eps$ and hence $\sum_{k\in K}|I_k|<\delta$. So $\Omega_\eps(f)$ can be covered by intervals with total length $<2\delta$ for every $\delta>0$. Thus $\Omega_\eps(f)$ is a null set.
\end{proof}


To prove the other direction, we need some preparation.


\begin{lm}\label{lb414}
Let $f:X\rightarrow Y$ where $X$ is a topological space and $Y$ is a metric space. Then for every $\eps>0$, $\Omega_\eps(f)=\{x\in X:\omega(f,x)\geq\eps\}$ is a closed subset of $X$.
\end{lm}

\begin{proof}
Let us prove that each $x\in X\setminus\Omega_\eps(f)$ is an interior point. (Recall Prop. 7\ref{lb179}.) Indeed, since $\inf_{U\in\Nbh(x)}\diam(f(U))<\eps$, there exists $U\in\Nbh(x)$ such that $\diam(f(U))<\eps$. Then for each $p\in U$ we have $\inf_{V\in\Nbh(p)}\diam(f(V))<\eps$ since $U\in\Nbh(p)$. So $U\subset X\setminus\Omega_\eps(f)$.
\end{proof}



\begin{lm}\label{lb415}
Let $\eps>0$. Suppose that for every $x\in I$ we have $\omega(f,x)<\eps$. (Namely, suppose $\Omega_\eps(f)=\emptyset$.) Then there exists a partition $I=I_1\cup\cdots\cup I_n$ satisfying $\diam(f(I_i))<\eps$ for all $i$.
\end{lm}


\begin{proof}
For every $x\in I$, there exists $U_x\in\Nbh_I(x)$ such that $\diam(f(U_x))<\eps$. Choose $n\in\Zbb_+$ such that $1/n$ is a Lebesgue number of the open cover $\mc U=\{U_x:x\in I\}$ of $I$. (Recall Thm. \ref{lb295}.) Dividing $I$ into $2n$ subintervals with the same length gives the desired partition.
\end{proof}


\begin{proof}[\textbf{Proof of Thm. \ref{lb411}, part 2}]
Let us prove (2)$\Rightarrow$(1). \hypertarget{Lebesgue-part2}{} Suppose that $M=\Vert f\Vert_\infty$ is $<+\infty$, and that the set of discontinuities is a null set. Then for each $\eps>0$, $\Omega_\eps(f)$ is a null set. By Lem. \ref{lb414} and Heine-Borel, $\Omega_\eps(f)$ is compact. Thus, for every $\delta>0$, $\Omega_\eps(f)$ can be covered by finitely many closed intervals with total length $<\delta$. Let $\Delta$ be the union of these closed intervals. Then $\Omega_\eps(f)\subset\Delta$. Clearly, both $\Delta$ and $J=I\setminus\Int(\Delta)$ can be written as disjoint unions of finitely many closed intervals, which are their connected components. And $\Delta$ has length $|\Delta|<\delta$.

Since $J\cap\Omega_\eps(f)=\emptyset$, applying Lem. \ref{lb415} to each of the components $J_1,J_2,\dots$ of $J$, we see that $J_i$ has a partition $\varrho_i$ such that the oscillation of $f$ (recall Def. \ref{lb416}) on each subinterval cut out by $\varrho_i$  is $<\eps$. Let $\sigma=\varrho_1\cup\varrho_2\cup\cdots\cup\{a,b\}$, which is a partition of $I$. Then $\sigma$ divides $I$ into subintervals $I_1,I_2,\dots$ such that either $I_j\subset J$ or $I_j\subset\Delta$.
\begin{itemize}
\item If $I_j\subset J$, then $I_j$ belongs to a subinterval cut out by one of $\varrho_1,\varrho_2,\dots$ in $J_1,J_2,\dots$. This implies $\diam(f(I_j))<\eps$ by the construction of $\varrho_1,\varrho_2,\dots$.
\item If $I_j\subset\Delta$, then $I_j$ is a component of $\Delta$. We have $\diam(f(I_j))\leq 2M$. Moreover, the total length of such $I_j$ is equal to $|\Delta|$, which is $<\delta$.
\end{itemize}
From the discussion of these two cases, we see that 
\begin{align*}
\omega(f,\sigma)=\sum_j\diam(f(I_j))\cdot|I_j|\leq \eps\cdot (b-a)+2M\cdot\delta
\end{align*}
Since $b-a$ and $M$ are fixed numbers and $\eps,\delta$ are arbitrary, we see that $\inf_{\sigma}\omega(f,\sigma)=0$. So $f$ is strongly Riemann integrable.
\end{proof}





\subsection{Improper integrals}


In this section, all intervals in $\Rbb$ are assumed to contain at least two points. Let $I$ be an interval in $\Rbb$ with $a=\inf I$ and $b=\sup I$. So $-\infty\leq a<b\leq+\infty$. Let $V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$.



\begin{df}
We define \index{R@$\scr R([a,b],V)$}
\begin{align*}
\scr R(I,V)=\{f\in V^I:f|_J\in\scr R(J,V)\text{ for every compact interval }J\subset I\}
\end{align*}
Define the \textbf{improper integral} \index{00@Improper integral}
\begin{align}\label{eq171}
\int_If\equiv\int_a^bf\xlongequal{\mathrm{def}}\lim_{
\begin{subarray}{c}
u\rightarrow a\\
v\rightarrow b
\end{subarray}}
\int_u^vf=\lim_{J}\int_Jf
\end{align}
Here, the last limit is over the directed set $\{\text{compact intervals in $I$}\}$ with preorder ``$\subset$". If the above limit exists, we say that $\int_If$ \textbf{exists} or \textbf{converges}. 

When $f\in\scr R(I,\Rbb)$ and  takes values in $\Rbb_{\geq 0}$, we write $f\in\scr R(I,\Rbb_{\geq0})$. Then $\int_If$ clearly exists in $\ovl\Rbb_{\geq0}$. We write $\dps\int_If<+\infty$ if $\int_If$ converges in $\Rbb$.   \hfill\qedsymbol
\end{df}





In the case that $a$ or $b$ is in $I$, when taking the limit over $u\rightarrow a$ and $v\rightarrow b$ in \eqref{eq171}, it is immaterial whether $u,v$ can take values $a,b$ or not, due to the following easy observation:
\begin{lm}
Let $f\in\scr R(I,V)$. If $I=[a,b]$, then the meanings of $\scr R(I,V)$ and $\int_If$ are the same as before. If $I=[a,b)$ resp. $I=(a,b]$, then 
\begin{gather*}
\int_If=\lim_{v\rightarrow b}\int_a^vf\qquad\text{resp.}\qquad \int_If=\lim_{u\rightarrow a}\int_u^bf
\end{gather*}
where the convergence of the LHS is equivalent to that of the RHS. 
\end{lm}


\begin{proof}
Assume $I=[a,b]$. Then $I$ is a compact interval. The new and old meanings of $\scr R(I,V)$ are the same by Prop. \ref{lb376}. Let $f\in\scr R(I,V)$. Then by Thm. \ref{lb375}, we have $\Vert f\Vert_\infty<+\infty$. If $a\leq u<v\leq b$, then Thm. \ref{lb375} and Prop. \ref{lb376} show that
\begin{align*}
\Big\Vert \int_a^bf-\int_u^vf \Big\Vert=\Big\Vert \int_a^uf+\int_v^bf \Big\Vert\leq \Vert f\Vert_\infty\cdot((u-a)+(b-v))
\end{align*}
which converges to $0$ as $u\rightarrow a$ and $v\rightarrow b$, whether $u,v$ take values $a,b$ or not. 

Similarly, if $I=[a,b)$, then since $f$ is Riemann integrabe on the compact subinterval $J=[a,(a+b)/2]$, we have $M:=\Vert f|_J\Vert_\infty<+\infty$. This implies that for all $u,v$ such that $a\leq u<v<b$ and $u\leq (a+b)/2$,
\begin{align*}
\Big\Vert \int_a^vf-\int_u^vf \Big\Vert=\Big\Vert \int_a^uf \Big\Vert\leq M(u-a)
\end{align*}
which converges to $0$ as $u\rightarrow a$ and $v\rightarrow b$. So $(\int_a^v f)_{u,v}$ and $(\int_u^vf)_{u,v}$ are Cauchy-equivalent nets. So their convergences and values are equivalent. The case $I=(a,b]$ is similar.
\end{proof}



%% Record #20 2023/11/29 three lectures  50


\begin{rem}\label{lb418}
Let $f\in\scr R(I,V)$. The Cauchy condition for the convergence of $\int_a^bf$ is easy to describe. In view of $\int_u^v-\int_{u'}^{v'}=\int_u^{u'}+\int_v^{v'}$ (Prop. \ref{lb376}), we have:
\begin{itemize}
\item For every $\eps>0$, there exist $u_0<v_0$ in $I$ such that for all $u,u',v,v'\in I$ satisfying $a\leq u,u'<u_0$ and $v_0<v,v'\leq b$ we have
\begin{align*}
\Big\Vert\int_u^{u'}f\Big\Vert<\eps\qquad \Big\Vert \int_v^{v'}f\Big\Vert<\eps
\end{align*} 
\end{itemize}
\end{rem}


\begin{df}\label{lb421}
Let $f\in\scr R(I,V)$. We say that $\int_If$ \textbf{converges absolutely} \index{00@Absolute convergence of improper integral} (or that $f$ is \textbf{absolutely integrable on $I$}) \index{00@Absolutely (Riemann) integrable} if there exists $g\in\scr R(I,\Rbb)$ such that $|f|\leq g$ (i.e., $\Vert f(x)\Vert\leq g(x)$ for all $x\in I$, in particular $g(x)\geq0$) and that $\int_I g<+\infty$. We let \index{R1@$\scr R^1(I,V)$}
\begin{align}
\textstyle\scr R^1(I,V)=\big\{f\in\scr R(I,V):\int_If\text{ converges absolutely}\big\}
\end{align}
which is clearly a linear subspace of $V^I$. By the Cauchy condition in Rem. \ref{lb418}, it is clear that $\int_If$ converges if $\int_If$ converges absolutely. Though $\Rbb_{\geq0}$ is not a Banach space, we still write
\begin{align*}
\textstyle\scr R^1(I,\Rbb_{\geq0})=\big\{f\in\scr R(I,\Rbb_{\geq0}):\int_If\text{ converges absolutely}\big\}
\end{align*}
which is clearly the set of all $f\in\scr R(I,\Rbb_{\geq0})$ satisfying $\int_If<+\infty$.
\end{df}




The superscript $1$ of $\scr R^1$ has a similar meaning as that of $l^1$, but is different from that of $C^1$.



\begin{rem}
Assume that $f:I\rightarrow V$ is strongly integrable on each compact subinterval of $I$. (This is the case, for example, when $f\in C(I,V)$, or when $f\in\scr R(I,V)$ and $V=\Fbb^N$.) Then $|f|:x\in I\mapsto \Vert f(x)\Vert\in\Rbb_{\geq0}$ is an element of $\scr R(I,\Rbb_{\geq0})$ by Cor. \ref{lb417}. Thus, in this case,
\begin{align*}
f\in\scr R^1(I,V)\qquad\Longleftrightarrow\qquad \int_I |f|<+\infty
\end{align*}
\end{rem}


\begin{eg}
We have
\begin{align*}
\int_1^{+\infty}x^{-2}dx=\lim_{v\rightarrow+\infty}\int_1^v x^{-2}dx=\lim_{v\rightarrow+\infty}(-x^{-1})\big|_1^v=1<+\infty
\end{align*}
Therefore $\dps\int_1^{+\infty} \frac{e^{\im x}}{x^2}dx$ converges absolutely, and hence converges.
\end{eg}


The following proposition generalizes Prop. \ref{lb379}.
\begin{pp}\label{lb427}
Let $f\in\scr R^1(I,V)$ and $g\in\scr R^1(I,\Rbb_{\geq0})$ such that $|f|\leq g$. Then $\dps\Big\Vert\int_If\Big\Vert\leq\int_Ig$.
\end{pp}

\begin{proof}
Apply the limit over $u\rightarrow a,v\rightarrow b$ to $\Vert\int_u^vf\Vert\leq\int_u^vg$.
\end{proof}



The next proposition shows that improper integrals are helpful for studying series:

\begin{pp}
Let $f\in\scr R([1,+\infty),\Rbb_{\geq0})$ be decreasing. Then we have
\begin{align}
\int_1^{+\infty} f<+\infty\qquad\Longleftrightarrow\qquad\sum_{n=1}^{+\infty}f(n)<+\infty
\end{align}
\end{pp}


\begin{proof}

Since $f$ is decreasing, we clearly have $g\leq f\leq h$ where $g,h$ are defined by the series in $l^\infty([0,+\infty),\Rbb)$:
\begin{align*}
g=\sum_{n=1}^{+\infty} f(n+1)\cdot \chi_{[n,n+1)}\qquad h=\sum_{n=1}^{+\infty} f(n)\cdot \chi_{[n,n+1)}
\end{align*}
One computes easily that $\int_1^{+\infty}g=\sum_{n=2}^{+\infty}f(n)$ and $\int_1^{+\infty}h=\sum_{n=1}^{+\infty}f(n)$ in $\ovl\Rbb_{\geq0}$. Thus
\begin{align*}
\sum_{n=2}^{+\infty}f(n)\leq\int_1^{+\infty} f\leq \sum_{n=1}^{+\infty}f(n)
\end{align*}
The proposition follows easily.
\end{proof}


\begin{eg}
Let $s>0$. The function $f:[2,+\infty)\rightarrow+\infty$ defined by $\dps f(x)=\frac 1{x(\log x)^s}$ is decreasing, and
\begin{align*}
\int_2^xf=\left\{
\begin{array}{ll}
(1-x)^{-1}\big((\log x)^{1-s}-(\log 2)^{1-s} \big) &\text{ if }s\neq 1\\[1ex]
\log(\log x)-\log(\log 2)&\text{ if }s= 1
\end{array}
\right.
\end{align*}
So $\sum_{n=2}^\infty f(n)<+\infty$ iff $\int_2^{+\infty}f<+\infty$  iff $s>1$.
\end{eg}



\subsection{Commutativity of improper integrals and other limit processes}



In this section, all intervals in $\Rbb$ are assumed to contain at least two points. Let $I$ be an interval in $\Rbb$ with $a=\inf I$ and $b=\sup I$. Let $J=[c,d]$ be a compact interval. Let $V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$.

The goal of this section is to generalize the main results of Sec. \ref{lb419} to improper integrals. Namely, we shall prove the commutativity of $\int_I$ with $\int_J$ and with $\partial_J$ under reasonable assumptions. There are three ways to achieve this goal: 
\begin{itemize}
\item We know that $\int_I$ is the limit of integrals over compact intervals. Therefore, the problem is reduced to that of proving that $\lim_{u\rightarrow a,v\rightarrow b}$ can be moved inside in  $\lim\int_J\int_u^v$ and in $\lim\partial_J\int_u^v$.
\item We generalize Thm. \ref{lb392} to improper integrals, and use this generalized version to prove the commutativity in a similar way as in Sec. \ref{lb419}.
\item The commutativity of $\int_I$ with $\partial_J$ can also be studied by generalizing Cor. \ref{lb380} to improper integrals, similar to the second proof of Thm. \ref{lb405}.
\end{itemize}



We will use the second approach because its proof is more conceptual and involves fewer technical calculations, thus making it easier for us to remember the conditions of the theorems to be proved. Nevertheless, we will also give the appropriate generalization of Cor. \ref{lb380}, which is helpful for future application. Recall Def. \ref{lb421} for the meaning of $\scr R^1$. 


\subsubsection{Commutativity of improper integrals and bounded linear maps}



\begin{thm}\label{lb420}
Let $W$ be also a Banach space over $\Fbb$. Let $T\in\fk L(V,W)$. Then for every $f\in\scr R^1(I,V)$ we have $T\circ f\in\scr R^1(I,W)$ and
\begin{align}
T\Big(\int_a^b f \Big)=\int_a^b T\circ f
\end{align}
\end{thm}

In other words, we have a commutative diagram
\begin{equation}\label{eq175}
\begin{tikzcd}[column sep=large]
\scr R^1(I,V) \arrow[r,"T\circ"] \arrow[d,"\int_I"'] & \scr R^1(I,W) \arrow[d,"\int_I"] \\
V \arrow[r,"T"]           & W        
\end{tikzcd} 
\end{equation}


\begin{proof}
By Thm. \ref{lb392}, $T\circ f$ is Riemann integrable on compact subintervals of $I$. Since $f\in\scr R^1$, there exists $g\in\scr R(I,\Rbb_{\geq0})$ such that $|f|\leq g$ and $\int_Ig<+\infty$. Let $M=\Vert T\Vert$ be the operator norm, which is a finite number. By Rem. \ref{lb372}, for each $x\in I$ we have $\Vert T\circ f(x)\Vert\leq M\Vert f(x)\Vert\leq Mg(x)$, and hence $|T\circ f|\leq Mg$. This proves $T\circ f\in\scr R^1(I,W)$. In particular, the integrals of $f,T\circ f$ over $I$ converge. Thus, by the continuity of $T$ and the commutativity of $T$ with $\int_u^v$ (when  $a<u<v<b$) due to Thm. \ref{lb392}, we have
\begin{align*}
T\Big(\int_If\Big)=T\Big(\lim_{
\begin{subarray}{c}
u\rightarrow a\\
v\rightarrow b
\end{subarray}}\int_u^v f\Big)=\lim_{
\begin{subarray}{c}
u\rightarrow a\\
v\rightarrow b
\end{subarray}}T\Big(\int_u^v f\Big)=\lim_{
\begin{subarray}{c}
u\rightarrow a\\
v\rightarrow b
\end{subarray}}\int_u^v T\circ f=\int_IT\circ f
\end{align*}
\end{proof}



\subsubsection{Fubini's theorem}

Recall that $J=[c,d]$ is a compact interval but $I$ is not necessarily compact.

\begin{lm}\label{lb423}
Lem. \ref{lb400} holds verbatim to the current case that $I$ is not necessarily compact.
\end{lm}


\begin{proof}
We can prove this general case in the same way as Lem. \ref{lb400}, using the commutativity of $\int_I$ and the bounded map $g\in C(Y,V)\mapsto g(y)\in V$, which is available thanks to Thm. \ref{lb420}.
\end{proof}


\begin{thm}[\textbf{Fubini's theorem for improper integrals}] \label{lb422} \index{00@Fubini's theorem for improper integrals}
Let $f\in C(I\times J,V)$. Assume that there exists $h\in\scr R^1(I,\Rbb_{\geq0})$ satisfying
\begin{align}
\Vert f(x,y)\Vert\leq h(x)\qquad(\forall x\in I,y\in J)  \label{eq177}
\end{align}
Then the functions $\int_J f(\cdot,y)dy:I\rightarrow V$ and $\int_If(x,\cdot)dx:J\rightarrow V$ are continuous, and the equation
\begin{align}
\int_I\Big(\int_Jf(x,y)dy\Big)dx=\int_J\Big(\int_I f(x,y)dx\Big)dy \label{eq176}
\end{align}
holds where the integral over $I$ on the LHS converges absolutely.
\end{thm}



\begin{proof}
Let $T:C(J,V)\rightarrow V$ be the bounded linear map $\int_J$. By Thm. \ref{lb420}, we have a commutative diagram
\begin{equation}\label{eq178}
\begin{tikzcd}[column sep=large]
\scr R^1(I,C(J,V)) \arrow[r,"T\circ"] \arrow[d,"\int_I"'] & \scr R^1(I,V) \arrow[d,"\int_I"] \\
C(J,V) \arrow[r,"T"]           & V        
\end{tikzcd} 
\end{equation}
Since $J$ is compact, by Thm. \ref{lb274}, we can view $f$ as a continuous function $\Phi(f):I\rightarrow C(J,V)$ sending $x$ to $f(x,\cdot)$. Then \eqref{eq177} says that $\Phi(f)\leq g$. Since $g\in\scr R^1$, we conclude $\Phi(f)\in\scr R^1(I,C(J,V))$. 

By Lem. \ref{lb423}, $\int_I\Phi(f)$ equals the function $\int_I f(x,\cdot)dx$. In particular, $\int_I f(x,\cdot)dx$ is continuous since $\int_I\Phi(f)\in C(J,V)$ by \eqref{eq178}. The continuity of $\int_J f(\cdot,y)dy$ is similar, or is even easier because $J$ is compact.


Clearly $T(\int_I\Phi(f))$ is $\int_J\int_I f$. By the top arrow of \eqref{eq178}, $T\circ\Phi(f)$ belongs to $\scr R^1(I,V)$. Since $T\circ\Phi(f)$ is the function sending $x$ to $\int_J f(x,\cdot)dy$, the  integral of this function over $I$ is absolutely convergent, and $\int_I T\circ\Phi(f)=\int_I\int_Jf$. Thus, the commutativity of \eqref{eq178} proves \eqref{eq176}. 
\end{proof}



The continuity of $\int_If(x,\cdot)dx$ can be generalized: see Cor. \ref{lb429}.



\subsubsection{Commutativity of improper integrals and partial derivatives}


\begin{lm}\label{lb426}
Lemma \ref{lb403} holds verbatim to the current case that $I$ is not necessarily compact.
\end{lm}

\begin{proof}
Again, this is proved in the same way as Lem. \ref{lb400} by applying Thm. \ref{lb420} to the bounded linear functional $g\in C^1(J,V)\rightarrow g(y)$ (where $y\in J$).
\end{proof}


\begin{thm}\label{lb434}
Let $f:I\times J\rightarrow V$. Assume that $\partial_Jf$ exists everywhere on $I\times J$. Assume that $f,\partial_J f\in C(I\times J,V)$. Assume moreover that there exists $h\in\scr R^1(I,\Rbb_{\geq0})$ satisfying
\begin{align}\label{eq183}
\Vert f(x,y)\Vert\leq h(x)~~\text{ and }~~\Vert\partial_Jf(x,y)\Vert\leq h(x)\qquad(\forall x\in I,y\in J)
\end{align}
Then for each $y\in J$, the LHS of \eqref{eq181} exists and equals the RHS of \eqref{eq181}, where
\begin{align}
\partial_J\int_I f(x,y)dx=\int_I\partial_J f(x,y)dx  \label{eq181}
\end{align}
\end{thm}


\begin{proof}
Let $T:C^1(J,V)\rightarrow C(J,V)$ be the bounded linear map $\partial_J$. By Thm. \ref{lb420}, we have a commutative diagram
\begin{equation}\label{eq182}
\begin{tikzcd}[column sep=large]
\scr R^1(I,C^1(J,V)) \arrow[r,"T\circ"] \arrow[d,"\int_I"'] & \scr R^1(I,C(J,V)) \arrow[d,"\int_I"] \\
C^1(J,V) \arrow[r,"T"]           & C(J,V)      
\end{tikzcd} 
\end{equation}
Define $\Psi(f):X\rightarrow V^J$ sending $x$ to $f(x,\cdot)$. By Prop. \ref{lb402}, $\Psi(f)$ belongs to $C(I,C^1(J,V))$. By \eqref{eq183}, $\Psi(f)$ belongs to $\scr R^1(I,C^1(J,V))$. As in the first proof of Thm. \ref{lb405}, one can use Lem. \ref{lb423} and  \ref{lb426} (the improper version of Lem. \ref{lb400} and \ref{lb403}) to show that  $\int_I T\circ\Psi(f)=T\int_I\Psi(f)$ (which is a consequence of the commutativity of \eqref{eq182}) implies \eqref{eq181}.
\end{proof}












\subsubsection{Commutativity of improper integrals and net limits}



\begin{thm}\label{lb428}
Let $(f_\alpha)_{\alpha\in\scr I}$ be a net in $\scr R^1(I,V)$. Let $f\in V^I$. Assume that the following conditions are true:
\begin{enumerate}[label=(\arabic*)]
\item On every compact subinterval of $I$, the net $(f_\alpha)$ converges uniformly to $f$.
\item There exists $g\in\scr R^1(I,\Rbb_{\geq0})$ such that $|f_\alpha|\leq g$ for all $\alpha\in\scr I$.
\end{enumerate}
Then $f\in\scr R^1(I,V)$, and $\dps\int_If=\lim_{\alpha\in\scr I}\int_If_\alpha$.
\end{thm}


\begin{proof}
By Cor. \ref{lb380}, $f\in\scr R(I,V)$. Since $(f_\alpha)$ converges pointwise to $f$, we clearly have $|f|\leq g$. So $f\in\scr R^1(I,V)$.  Choose any $\eps>0$. Since $\lim_{u\rightarrow a,v\rightarrow b}\int_Ig$ converges, there exists $u,v$ such that $a<u<v<b$ and
\begin{align*}
\int_a^ug+\int_v^bg=\int_Ig-\int_u^v g<\eps
\end{align*}
Thus, by Prop. \ref{lb427}, for each $\alpha$ we have $\Vert\int_a^uf_\alpha\Vert+\Vert\int_v^bf_\alpha\Vert<\eps$ and $\Vert\int_a^uf\Vert+\Vert\int_v^bf\Vert<\eps$. Since $f_\alpha$ converges uniformly to $f$ on $[u,v]$, by Cor. \ref{lb380}, we get $\lim_\alpha\Vert \int_u^vf_\alpha-\int_u^vf\Vert=0$. Thus
\begin{align*}
&\Big\Vert \int_If-\int_If_\alpha\Big\Vert=\Big\Vert \int_a^uf+\int_v^b f-\int_a^u f_\alpha-\int_v^b f_\alpha+\int_u^v(f-f_\alpha)\Big\Vert\\
\leq&2\eps+\Big\Vert\int_u^v(f-f_\alpha)\Big\Vert
\end{align*}
where the $\limsup_\alpha$ of the RHS is $2\eps$. Thus $\Vert\int_If-\int_If_\alpha\Vert$ converges to $0$ under $\limsup_\alpha$, and hence under $\lim_\alpha$.
\end{proof}

It is a good practice to prove Thm. \ref{lb434} using Thm. \ref{lb428}. (See Pb. \ref{lb430}.)



\begin{co}\label{lb429}
Let $Y$ be a topological space. Let $f\in C(I\times Y,V)$. Assume that there exists $h\in\scr R^1(I,\Rbb_{\geq0})$ such that
\begin{align}
\Vert f(x,y)\Vert\leq h(x)\qquad (\forall x\in I,y\in Y)
\end{align}
Then the map $\int_If(x,\cdot)dx$ (sending $y\in Y$ to $\int_If(x,y)dx$) is continuous.
\end{co}

\begin{proof}
By Def. \ref{lb188}-(1), we need to prove that for every net $(y_\alpha)$ in $Y$ converging to $y$, we have $\int_If(x,y)dx=\lim_\alpha\int_If(x,y_\alpha)dx$. By Thm. \ref{lb428}, it suffices to prove that $\lim_\alpha f(\cdot,y_\alpha)$ converges uniformly  on any compact subinterval $[u,v]\subset I$ to $f(\cdot,y)$. This is true because, by Thm. \ref{lb274}, the restriction of $f$ to $[u,v]\times Y$ can be viewed as an element of $C(Y,C([u,v],V))$.
\end{proof}


\begin{eg}
Compute $\dps F(t)=\int_0^{+\infty}e^{-tx}\cdot \frac{\sin x}xdx$ for all $t>0$.
\end{eg}

\begin{proof}[Solution]
We first compute $F'(t)$. Choose any $\delta>0$. Then for any $t\geq\delta$, the norms of $e^{-tx}\frac{\sin x}x$ and $\partial_t(e^{-tx}\frac{\sin x}x)=-e^{-tx}\sin x$ are both bounded by $e^{-\delta x}$, where the latter is absolutely integrable since $\int_0^{+\infty}e^{-\delta x}dx=\delta^{-1}<+\infty$. Thus, by Thm. \ref{lb434}, we have
\begin{align*}
&F'(t)=\int_0^{+\infty}-e^{-tx}\sin xdx=\int_0^{+\infty}\frac{e^{(-t+\im)x}-e^{(-t-\im)x}}{2\im}dx\\
=&\frac{t\sin x+\cos x}{1+t^2}e^{-tx}\Big|_{x=0}^{+\infty}=-\frac 1{1+t^2}
\end{align*} 
for all $t\geq\delta$ and $\delta>0$, and hence for all $t>0$. Therefore $F(t)=C-\arctan t$ for some $C\in\Rbb$. Let us determine $C$ using $C=\lim_{t\rightarrow+\infty}F(t)+\frac\pi2$. 

To compute $\lim_{t\rightarrow+\infty}F(t)$, it suffices to assume $t\geq1$. Then $|e^{-tx}\frac{\sin x}x|\leq e^{-x}$ where $\int_0^{+\infty} e^{-x}<+\infty$. Moreover, on every compact interval $[a,b]$ in $(0,+\infty)$ (where $0<a<b<+\infty$), $\lim_{t\rightarrow+\infty}e^{-tx}\frac{\sin x}x$ converges uniformly to $0$ since $|e^{-tx}\frac{\sin x}x|\leq e^{-ta}$. Thus, the assumptions in Thm. \ref{lb428} are satisfied, and hence
\begin{align*}
\lim_{t\rightarrow+\infty}F(t)=\int_0^{+\infty} \lim_{t\rightarrow +\infty}e^{-tx}\cdot \frac{\sin x}xdx=0
\end{align*}
This proves $C=\frac\pi 2$, and hence $F(t)=\frac\pi 2-\arctan t$.
\end{proof}






\subsection{Convolutions and smooth/polynomial approximation}\label{mc52}


Fix a Banach space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$.


\begin{df}
Let $X$ be a topological space. The \textbf{support} of a function $f\in V^X$ \index{00@@Support} \index{Supp@$\Supp(f)$} is defined to be the closure
\begin{align*}
\Supp(f)=\ovl{\{x\in X:f(x)\neq 0\}}
\end{align*}
Define $C_c(X,V)$ \index{Cc@$C_c(X,V)$} to be the set of continuous functions with \textbf{compact support}
\begin{align*}
C_c(X,V)=\{f\in C(X,V):\Supp(f)\text{ is compact} \}
\end{align*}
Unless otherwise stated, $C_c(X,V)$ is equipped with the $l^\infty$-norm.
\end{df}


\subsubsection{Convolutions and approximation of identity}


A goal of this section is to show that the elements of $C_c(\Rbb,V)$ can be approximated by smooth functions with compact supports, i.e., elements in \index{Cc@$C_c^\infty$}
\begin{align*}
C_c^\infty(\Rbb,V)=C^\infty(\Rbb,V)\cap C_c(\Rbb,V) 
\end{align*}
Indeed, we will do more. We shall prove the celebrated \textbf{Weierstrass approximation theorem}, which implies that elements in $C_c(\Rbb,V)$ can be approximated uniformly by polynomials on compact intervals. The proof we will give is also due to Weierstrass, which relies on an important construction called convolution: If $f:\Rbb\rightarrow V$ and $g:\Rbb\rightarrow\Fbb$, then their \textbf{convolution} \index{00@Convolution} is a functions $f*g:\Rbb\rightarrow V$ defined by
\begin{subequations}\label{eq188}
\begin{align}
(f*g)(x)\equiv (g*f)(x)=\int_\Rbb f(x-y)g(y)dy  \label{eq186}
\end{align}
whenever the above integral converges for every $x\in\Rbb$. Taking $y=x-t$, we get $\int_u^v f(x-y)g(y)dy=-\int_{x-u}^{x-v}f(t)g(x-t)dt=\int_{x-v}^{x-u}f(t)g(x-t)dt$. Letting $u\rightarrow-\infty,v\rightarrow+\infty$, we get
\begin{align}
(f*g)(x)=\int_\Rbb f(y)g(x-y)dy  \label{eq187}
\end{align}
\end{subequations}


The main idea of doing approximation via convolutions is as follows. Suppose that $g$ is smooth, then by \eqref{eq187}, one should expect that $(f*g)^{(n)}(x)=\int_\Rbb f(y)(\partial_x)^ng(x-y)dy=\int_\Rbb f(y)g^{(n)}(x-y)dy$ to be true. Thus $f*g$ is expected to be smooth. Moreover, if $g$ can be approximated by polynomials, for example, if $g(x)=\sum a_nx^n$ on $\Rbb$, then it is expected that $f*g$ can be approximated by $f*g_n$ where $g_n(x)=a_nx^n$, and it is easy to see that $f*g_n=a_n\int_\Rbb f(y)(x-y)^ndy$ is a polynomial of $x$.

To summarize, one advantage of convolution is that whenever $g$ has a good property, the same is in general true for $f*g$. Another key property of convolution is that $f$ can be approximated by $f*g$ in some sense. The meaning of ``approximation" will depend on the analytic property of $f$, e.g. whether $f$ is continuous, continuous with compact support, or only integrable. In this section, we will only be interested in the case that $f\in C_c(\Rbb,V)$. In this case, the integrals in \eqref{eq188} are actually over compact intervals, which makes our lives easier. 

We shall show that $f\in C_c(\Rbb,V)$ can be approximated uniformly by $f*g$. More precisely, we shall show that for every absolutely convergent $g\in C(\Rbb,\Rbb_{\geq0})$ satisfying $\int_\Rbb g=1$, if we define $g_\eps\in C(\Rbb,\Rbb)$ (where $\eps\in\Rbb_{>0}$) by
\begin{align}
g_\eps(x)=\frac 1\eps g\big(\frac x\eps\big)  \label{eq189}
\end{align}
then $(f*g_\eps)$ converges uniformly to $f$ as $\eps\rightarrow 0$. This method is extremely useful and is used widely in analysis. (The assumption that $g\geq0$ is not necessary. We assume $g\geq0$ only for simplifying discussions.)








\begin{lm}\label{lb436}
Choose $g\in C(\Rbb,\Rbb_{\geq0})$ satisfying $\int_\Rbb g=1$, and define $g_\eps$ by \eqref{eq189}. Then $\int_\Rbb g_\eps=1$ for each $\eps>0$. Moreover, for every $\delta>0$ we have
\begin{align}
\lim_{\eps\rightarrow0}\int_\delta^{+\infty} g_\eps=\lim_{\eps\rightarrow0}\int_{-\infty}^{-\delta}g_\eps=0 \label{eq190}
\end{align}
\end{lm}


\begin{proof}
By the change of variable formula we have $\int_u^v \eps^{-1}g(\eps^{-1}x)dx=\int_{u/\eps}^{v/\eps}g(y)dy$. This gives $\int_\Rbb g_\eps=1$. Another change of variable shows $\int_\delta^{+\infty}g_\eps=\int_{\delta/\eps}^{+\infty}g=\int_0^{+\infty}g-\int_0^{\delta/\eps}g$, which clearly converges to $0$ as $\eps\rightarrow0$. This proves the first half of \eqref{eq190}. The second half is similar.
\end{proof}


%% Record #21 2023/12/4 two lectures  52


\begin{pp}\label{lb437}
Let $f\in C_c(\Rbb,V)$. Choose $g\in C(\Rbb,\Rbb_{\geq0})$ satisfying $\int_\Rbb g=1$, and define $g_\eps$ by \eqref{eq189} for each $\eps>0$. Then $(f*g_\eps)$ converges uniformly on $\Rbb$ to $f$ as $\eps\rightarrow0$.
\end{pp}

In other words, the convolution operator $f\mapsto f*g_\eps$ converges pointwise to the identity map when $\eps\rightarrow 0$.

\begin{proof}
Let $M=\Vert f\Vert_\infty$, which is $<+\infty$. Since $\int_\Rbb g_\eps=1$, for each $x\in\Rbb$ we have $\int_\Rbb f(x)g_\eps(y)dy=f(x)$. Thus
\begin{align}
&\Vert (f*g_\eps)(x)-f(x)\Vert=\Big\Vert \int_\Rbb(f(x-y)-f(x))g_\eps(y)dy \Big\Vert\nonumber\\
\leq &\int_\Rbb  \Vert f(x-y)-f(x)\Vert \cdot g_\eps(y)dy \label{eq191}
\end{align}
By Thm. \ref{lb294} and the compactness of $\Supp(f)$, $f$ is uniformly continuous on $\Rbb$. Therefore, for every $e>0$, there exists $0<\delta<1$ such that $\Vert f(x-y)-f(x)\Vert\leq e$ for all $x\in\Rbb$ and $y\in(-\delta,\delta)$. Thus, if we let $J_\delta=\Rbb\setminus(-\delta,\delta)$, then
\begin{align*}
&\eqref{eq191}\leq \int_{J_\delta}\Vert f(x-y)-f(x)\Vert \cdot g_\eps(y)dy+e\cdot \int_{-\delta}^\delta g_\eps(y)dy\\
\leq& 2M\cdot \int_{J_\delta} g_\eps(y)dy+e 
\end{align*}
which converges to $e$ under $\limsup_{\eps\rightarrow0}$ by Lem. \ref{lb436}. Since $e$ is arbitrary, we conclude that $\lim_{\eps\rightarrow0}\eqref{eq191}=0$.
\end{proof}

\begin{rem}
The uniform continuity of a function $f:\Rbb\rightarrow V$ is equivalent to the continuity of $F:\Rbb\rightarrow C(\Rbb,V)$ defined by $F(t)(x)=f(x-t)$. Note that the continuity of $F$ follows from Thm. \ref{lb274}. This means that Prop. \ref{lb437} can also be proved by Thm. \ref{lb274}.
\end{rem}




\begin{rem}
In analysis, there are two especially important classes of  $g\in C(\Rbb,\Rbb_{\geq0})$ satisfying $\int_\Rbb g=1$. The first class consists of $g\in C_c(\Rbb,\Rbb_{\geq0})$ satisfying $\int_\Rbb g=1$. Although functions with compact supports are often easy to use, they cannot be approximated by their Taylor series on $\Rbb$. (See Exp. \ref{lb358} for a related example.) Instead, we should consider another type of function:
\end{rem}


\subsubsection{Polynomial approximation}



\begin{eg}
Define the \textbf{Gauss function} $\dps g(x)=\frac 1{\sqrt\pi}e^{-x^2}$. \index{00@Gauss function} Then $g\in C(\Rbb,\Rbb_{\geq0})$ and $\int_\Rbb g=1$. Thus, $g$ satisfies the assumptions in Prop. \ref{lb437}. 
\end{eg}

Although $g$ does not have compact support, it is a real analytic function. So we can use $f*g_\eps$ to prove Weierstrass approximation theorem.

\begin{proof}
It is easy to see that $\int_1^{+\infty}1/x^2dx<+\infty$. Thus, since $e^{x^2}\geq x^2$, we get $\int_\Rbb e^{-x^2}dx<+\infty$.

It is not so easy to show that 
\begin{align} \label{eq172}
\int_{-\infty}^{+\infty}e^{-x^2}dx=\sqrt\pi
\end{align}
This integral is called  \textbf{Gauss integral}. \index{00@Gauss integral} In the next semester, we will use the change of variables formula for double integrals to prove \eqref{eq172}. (See Exp. \ref{mc43}.)
A more elementary (but also more complicated) proof is given in Pb. \ref{lb435}. For the purpose of this section, knowing $\int_\Rbb e^{-x^2}dx<+\infty$ is enough, since we can define $g$ to be $e^{-x^2}$ divided by its integral on $\Rbb$.
\end{proof}



We now show that if $g$ is the Gauss function, then $f*g_\eps$ can be approximated uniformly by polynomials on every compact interval. 

\begin{lm}\label{lb438}
Let $h(x)=\sum_{n=0}^\infty a_nx^n$ have radius of convergence $+\infty$, where $a_n\in\Fbb$ for each $a_n$. Let $h_n(x)=\sum_{j=0}^n a_jx^j$ be the partial sum. Let $f\in C_c(\Rbb,V)$. Then $\lim_{n\rightarrow\infty}f*h_n$ converges uniformly on compact intervals to $f*h$, and each $f*h_n$ is in \index{Vx@$V[x]$}
\begin{align}
V[x]=\{v_0+v_1x+\cdots+v_kx^k:k\in\Nbb,v_0,v_1,\dots,v_k\in V\}
\end{align}
\end{lm}

Note that we do not need the assumption $\int_\Rbb |h|<+\infty$ in this Lemma. So letting $h(x)=e^x$ is also OK. Clearly, if $g$ is the Gauss functions, then $g_\eps$ satisfies the assumptions on $h$. This implies that if $f\in C_c(\Rbb,V)$, then $f*g_\eps$ can be approximated uniformly on compact intervals by  polynomials with coefficients in $V$. Combining this fact with Prop. \ref{lb437}, we see that $f$ can be approximated uniformly by polynomials on compact intervals.

\begin{proof}
Note that $(f*h)(x)=\int_\Rbb h(x-y)f(y)dy$ is well-defined since it is equals $\int_{-a}^a h(x-y)f(y)dy$ if $a>0$ and if $[-a,a]$ contains $\Supp(f)$. (So this is a usual Riemann integral.) Similarly, $(f*h_n)(x)=\int_{-a}^a h_n(x-y)f(y)dy$. Since $h_n$ is a polynomial, it is obvious that $f*h_n$ is also a polynomial.

We now show that $f*h_n$ converges uniformly to $f*h$ on $[-b,b]$ for any $b>0$. Let $c=a+b$. Then 
\begin{align*}
&\sup_{x\in[-b,b]}\Vert (f*h)(x)-(f*h_n)(x)\Vert\leq\sup_{x\in[-b,b]}\int_{-a}^a |h(x-y)-h_n(x-y)|\cdot\Vert f(y)\Vert dy\\
\leq&A_n\int_{-a}^a\Vert f(y)\Vert dy
\end{align*}
where $A_n=\sup_{t\in[-c,c]}\Vert h(t)-h_n(t)\Vert$. By Thm. \ref{lb112}, $h_n$ converges uniformly on $[-c,c]$ to $h$. So $\lim_{n\rightarrow\infty}A_n=0$.
\end{proof}


\begin{thm}[\textbf{Weierstrass approximation theorem}]\index{00@Weierstrass approximation theorem}  \label{lb441}
Let $I=[a,b]$ where $-\infty<a<b<+\infty$. Then $V[x]$ is dense in $C(I,V)$ under the $l^\infty$-norm.
\end{thm}

\begin{proof}
Choose any $f\in C(I,V)$. Then $f$ can be extended to a continuous function $\Rbb\rightarrow V$ with compact support: For example, we let $f(x)=(x-a+1)f(a)$ if $x\in[a-1,a]$, let $f(x)=(b+1-x)f(b)$ if $b\in[b,b+1]$, and let $f(x)=0$ if $x<a-1$ or $x>b+1$. Let $g$ be the Gauss function. For every $e>0$, by Prop. \ref{lb437}, there exists $\eps>0$ such that $\Vert f-f*g_\eps\Vert_{l^\infty(\Rbb,V)}<e/2$. By Lem. \ref{lb438}, there exists a polynomial $p\in V[x]$ such that $\Vert f*g_\eps-p\Vert_{l^\infty(I,V)}<e/2$. So $\Vert f-p\Vert_{l^\infty(I,V)}<e$.
\end{proof}


\begin{co}\label{lb486}
Let $I=[a,b]$ where $-\infty<a<b<+\infty$. Then $C([0,1],\Rbb)$ is separable.
\end{co}

\begin{proof}
$\Qbb[x]$, the set of polynomials with coefficients in $\Qbb$, is countable. By Thm. \ref{lb441}, $\Qbb[x]$ is dense in $C([0,1],\Rbb)$.
\end{proof}

The Weierstrass approximation theorem will be generalized to \textbf{Stone-Weierstrass theorem} (cf. Thm. \ref{lb442}). Accordingly, Cor. \ref{lb486}  will be substantially generalized as an application of (the proof of) Stone-Weierstrass theorem: we will show that $C(X,\Rbb)$ is separable if $X$ is a compact metric space. (See Thm. \ref{lb482}) 



\subsubsection{Smooth approximation}

By the Weierstrass approximation theorem, we know that any $f\in C_c(\Rbb,V)$ can be approximated uniformly by polynomials on compact intervals. However, unless $f=0$, $f$ cannot be approximated by polynomials uniformly on $\Rbb$. (If $p,q\in V[x]$ are different, then $\Vert p-q\Vert_{l^\infty(X,V)}=+\infty$. So any Cauchy sequence in $V[x]$ under the ${l^\infty(X,V)}$-norm is eventually constant. So its limit is a polynomial, which does not have compact support unless when it is zero.) Nevertheless, we shall show that $f$ can be approximated by smooth compactly supported functions uniformly on $\Rbb$. This task is not difficult: one simply pick a nonzero $g\in C_c^\infty(\Rbb,\Rbb)$ satisfying $g\geq0$. Dividing $g$ by $g/\int_\Rbb g$, we may assume that $\int_\Rbb g=1$. Then it can be shown that $f*g_\eps\in C_c^\infty(\Rbb,V)$. By Prop. \ref{lb437}, $\lim_{\eps\rightarrow0}f*g_\eps$ converges uniformly on $\Rbb$ to $f$. This finishes the proof. However, we must first prove the existence of such $g$:



\begin{pp}\label{lb440}
Let $0<a<b$. Then there exists $g\in C_c^\infty(\Rbb,\Rbb)$ such that $g(\Rbb)=[0,1]$, that $g^{-1}(1)=[-a,a]$, and that $g^{-1}(0)=(-\infty,-b]\cup[b,+\infty)$.
\end{pp}



\begin{proof}
Let $\alpha:\Rbb\rightarrow\Rbb_{\geq0}$ be the smooth function in Exp. \ref{lb358}. Then $\alpha$ is increasing and $\alpha^{-1}(0)=(-\infty,0]$.  Define $\beta:\Rbb\rightarrow\Rbb_{\geq0}$ by $\beta(x)=\alpha(x+b)\alpha(-x+b)$. Then $\beta^{-1}(0)=(-\infty,-b]\cup[b,+\infty)$. In particular, $\beta\in C_c^\infty(\Rbb,\Rbb)$. Define $\gamma:\Rbb\rightarrow\Rbb_{\geq0}$ by $\gamma(x)=\alpha(x-a)+\alpha(-x-a)$. Then $\gamma^{-1}(0)=[-a,a]$. Note that $\beta(x)+\gamma(x)>0$ for all $x\in\Rbb$, since $\beta^{-1}(0)\cap\gamma^{-1}(0)=\emptyset$. 
\begin{align*}
\vcenter{\hbox{{
			\includegraphics[height=1.3cm]{fig3.png}}}}
\end{align*}
Then $g=\beta/(\beta+\gamma)$ is a desired function.
\end{proof}


\begin{co}\label{lb446}
Let $I$ be an interval in $\Rbb$ with $a=\inf I$ and $b=\sup I$ satisfying $-\infty\leq a<b\leq+\infty$. Then $C_c^\infty(I,V)$ is dense in $C_c(I,V)$ under the $l^\infty$-norm.
\end{co}

In the following, we only prove the case that $I=(a,b)$. The other cases can be reduced to this case: For example, the case $[a,b)$ is implied by the case $(a-1,b)$.

\begin{proof}[First proof]
Let $f\in C_c(\Rbb,V)$ supported in $[u,v]$ where $a<u<v<b$. By Prop. \ref{lb440}, there exists a nonzero smooth $g\in C_c(\Rbb,\Rbb_{\geq0})$ supported in $[-1,1]$ such that $\int_\Rbb g=1$. Since $g_\eps$ is supported in $[-\eps,\eps]$, it is easy to see that $f*g_\eps$ is supported in $[u-\eps,v+\eps]$. By Lem. \ref{lb400}, $f*g_\eps$ is continuous . Moreover, one can check that $f*g_\eps$ is smooth (cf. Pb. \ref{lb439}). So $f*g_\eps\in C_c^\infty(\Rbb,V)$, and $f*g$ is supported in $I$ when $\eps<\min\{u-a,b-v\}$. By Prop. \ref{lb437}, $\lim_{\eps\rightarrow 0}f*g_\eps$ converges uniformly on $\Rbb$ to $f$.
\end{proof}



\begin{proof}[Second proof]
Let $f\in C_c(\Rbb,V)$ supported in $[u,v]$ where $a<u<v<b$. Choose any $e>0$. Choose any positive $\eps<\min\{u-a,b-v\}$. By Weierstrass approximation Thm. \ref{lb441}, there exists $p\in V[x]$ such that $\Vert f(x)- p(x)\Vert\leq e$ for all $x\in[u-\eps,v+\eps]$. In particular, since $f=0$ on $J=[u-\eps,u]\cup[v,v+\eps]$, we have $\Vert p(x)\Vert\leq e$ for all $x\in J$. 

By Prop. \ref{lb440}, there exists $h\in C_c^\infty(\Rbb,\Rbb)$ such that $h(\Rbb)=[0,1]$, that $h^{-1}(1)=[u,v]$, and that $h^{-1}(0)=(-\infty,u-\eps]\cup[v+\eps,+\infty)$. Then $hp\in C_c^\infty(\Rbb,V)$ is supported in $[u-\eps,v+\eps]$ and hence in $(-a,a)$. One checks easily that $\Vert f(x)-h(x)p(x)\Vert\leq e$ for all $x\in(a,b)$.
\end{proof}


\begin{rem}
It should be noted that if $I$ is an open interval, then $C_c^\infty(I,V)$ and $C_c(I,V)$ are naturally subspaces of $C_c(\Rbb,V)$. This is not true when $I$ is a closed or an half-open-half-closed interval. Therefore, Cor. \ref{lb446} implies that any $f\in C(\Rbb,V)$ supported in an open interval $I$ can be uniformly approximated by smooth functions $\Rbb\rightarrow V$ supported in $I$.
\end{rem}


\begin{rem}
The above observation can be generalized: Let $X$ be an LCH space. Assume that $\Omega$ is a nonempty \textit{open} subset of $X$. Recall that $\Omega$ is LCH by Prop. \ref{lb245}. Then an element of $C_c(\Omega,V)$ is equivalently an element of $C_c(X,V)$ supported in $U$. The former gives the latter by ``extension by zero"; the latter gives the former by restriction to $\Omega$. We will say more about this in Sec. \ref{lb464}.
\end{rem}





\subsection{$L^1$-approximation; Riemann-Lebesgue lemma}


A non-continuous integrable function cannot be approximated uniformly by smooth functions. However, it can be approximated by the latter under the $L^1$-norm. To avoid distraction, in this section we consider $\Cbb$-valued functions. Fix $I\subset\Rbb$ to be an interval containing at least two points. Then on $\scr R^1(I,\Cbb)$ one can define the \textbf{$L^1$-seminorm} \index{L1@$L^1$-seminorm} to be
\begin{align}
\Vert f\Vert_{L^1}\equiv\Vert f\Vert_{L^1(I,\Cbb)}=\int_I |f|
\end{align}
It is easy to check that this is a \textbf{seminorm}, i.e., it satisfies the definition of a norm, except the assumption that $\Vert f\Vert_{L^1}=0$ implies $f=0$.

\begin{pp}\label{lb445}
Let $f\in\scr R^1(I,\Cbb)$. Choose any $\eps>0$. Then there exists $g\in C_c^\infty(\Rbb,\Cbb)$ supported in $I$ such that $\Vert f-g\Vert_{L^1}<\eps$. And there exists a \textbf{step function} \index{00@Step function} $h$ supported in $I$ (i.e., a linear combination of functions of the form $\chi_E$ where $E$ is a compact interval in $I$) such that $\Vert f-h\Vert_{L^1}<\eps$.
\end{pp}

Note that if $E$ is a bounded interval, then $\chi_E$ is clearly a linear combination of characteristic functions over compact intervals (including the single point sets). Thus, in the above definition of step functions, one can just assume that $E$ is a bounded interval whose closure is in $I$.

The following proof shows that Prop. \ref{lb445} can be easily generalized to the case that $f:I\rightarrow V$ is strongly integrable on compact subintervals of $I$ and $\int_I|f|<+\infty$. ($V$ is a Banach space.)

\begin{proof}
Let $a=\inf I,b=\sup I$. Since $\int_I|f|=\lim_{u\rightarrow a,v\rightarrow b} \int_a^b|f|$, there exist $u,v$ such that $a<u<v<b$ and that $\int_a^u|f|+\int_v^b|f|<\eps/2$. We claim that there exists a step function $h$ supported in $J=[u,v]$ such that $\int_J |f-h|<\eps/2$. Then $\int_I|f-h|<\eps$, finishing the proof that $f$ can be $L^1$-approximated by step functions supported in $I$.

Since $f|_J$ is strongly Riemann integrable, there exists $\sigma=\{a_0<\cdots<a_n\}\in\mc P(J)$ such that $\omega(f,\sigma)<\frac\eps 2$. Let $J_i=[a_{i-1},a_i]$. Pick any $\lambda_i\in f(J_i)$. Then $|f-\lambda_i\cdot\chi_{J_i}|\leq\diam(f(J_i))$ on $J_i$, and hence $\int_{J_i}|f-\lambda_i\cdot\chi_{J_i}|\leq \diam(f(J_i))\cdot|J_i|$. Let $h=\sum_{i=1}^n\lambda_i\cdot\chi_{J_i}$. It follows that
\begin{align*}
\Big|\int_J f-\int_Jh  \Big|\leq\sum_{i=1}^n\int_{J_i}|f-\lambda_i\cdot\chi_{J_i}|\leq\sum_{i=1}^n\diam(f(J_i))\cdot|J_i|=\omega(f,\sigma)<\frac\eps 2
\end{align*}
finishing the proof.

Finally, we show that $f$ can be $L^1$-approximated by smooth functions supported in $I$. It suffices to prove that any step function supported in $I$ is so. By linearity and triangle inequality, it suffices to prove that $\chi_E$ is so, if $E$ is a nonempty compact interval in $I$. For each $\eps>0$, it is easy to construct a piecewise linear (and hence continuous) function $g_0:\Rbb\rightarrow\Rbb$ supported in $(a,b)=\Int(I)$ such that $\int_I|\chi_E-g_0|<\eps$. Choose a bounded open interval $(c,d)\subset (a,b)$ containing $\Supp(g_0)$. By Cor. \ref{lb446}, there exists $g\in C_c^\infty(\Rbb,\Rbb)$ supported in $(c,d)$ such that $|g(x)-g_0(x)|<\eps/(d-c)$ for all $x\in(c,d)$. It follows that
\begin{align*}
\int_I|g-g_0|=\int_c^d |g-g_0|\leq\eps
\end{align*}
Thus $\int_I|\chi_e-g|<2\eps$, finishing the proof.
\end{proof}




We give an application of Prop. \ref{lb445} by proving Riemann-Lebesgue lemma. The RL lemma plays a fundamental role in Fourier analysis, see for instance Pb. \ref{lb447} and Cor. \ref{lb448}. 


\begin{thm}[\textbf{Riemann-Lebesgue lemma}] \index{00@Riemann-Lebesgue lemma}\label{lb871}
Let $f\in\scr R^1(\Rbb,\Cbb)$. Then
\begin{align*}
\lim_{t\rightarrow+\infty}\int_\Rbb f(x)e^{\im tx}dx=\lim_{t\rightarrow-\infty}\int_\Rbb f(x)e^{\im tx}dx=0
\end{align*}
\end{thm}

The idea of the proof is the following: We $L^1$-approximate $f$ by some compactly supported step function $g\in C_c(\Rbb,\Cbb)$. Then it suffices to prove the RL lemma for $g$. By linearity, it suffices to assume that $g=\chi_{[a,b]}$. This special case can be proved easily. 

\begin{proof}
By Prop. \ref{lb445}, for every $\eps>0$ there exists a compactly supported step function $g:\Rbb\rightarrow\Cbb$ such that  $\int_\Rbb|f-g|<\eps$. So $|\int_\Rbb f(x)e^{\im tx}-g(x)e^{\im tx}dx|<\eps$ by Prop. \ref{lb427}. Thus
\begin{align*}
\limsup_{t\rightarrow\pm\infty} \Big| \int_\Rbb f(x)e^{\im tx}dx\Big|\leq \limsup_{t\rightarrow\pm\infty} \Big|\int_\Rbb g(x)e^{\im tx}dx\Big|+\eps
\end{align*}
Since $\eps$ is arbitrary, it suffices to prove that $\lim_{t\rightarrow\pm\infty}\int_\Rbb g(x)e^{\im tx}dx=0$. Since $g$ is a linear combination of functions of the form $\chi_{[a,b]}$ where $-\infty<a<b<+\infty$, it suffices to prove the RL lemma for this function:
\begin{align*}
\int_\Rbb\chi_{[a,b]}\cdot e^{\im tx}dx=\int_a^b e^{\im tx}dx=\frac{e^{\im nb}-e^{\im na}}{\im t}
\end{align*}
converges to $0$ as $t\rightarrow\pm\infty$.
\end{proof}

\begin{comment}
\begin{rem}
The proof of Prop. \ref{lb445} also shows that $f\in\scr R^1(\Rbb,\Cbb)$ can be approximated by linear combinations of functions of the form $\chi_J$ (where $J$ is an interval) under the $L^1$-norm. Thus, the Riemann-Lebesgue lemma can also be proved by showing that $\lim_{t\rightarrow\pm\infty}\int_\Rbb \chi_J(x)e^{\im tx}dx=0$. For such a proof one does not need SW theorem. However, in the general measure theory, it is often more convenient to approximate an integrable function by continuous compactly supported ones. For example, if a function is defined on a manifold (e.g., a sphere, or a more complicated geometric object), it is not easy to approximate such a function by a linear combination of $\chi_E$ where $E$ is a set as simple as an interval. 
\end{rem}
\end{comment}















\subsection{Problems and supplementary material}



Let $V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$.

\begin{prob}
Solve Exe. \ref{lb408}.
\end{prob}

\begin{prob}\label{lb430}
Prove Thm. \ref{lb434} using Thm. \ref{lb428}.
\end{prob}


\begin{sprob}\label{lb435}
Define $\dps f(x)=\Big(\int_0^x e^{-t^2}dt\Big)^2$ and $\dps g(x)=\int_0^1\frac{e^{-x^2(t^2+1)}}{t^2+1}dt$
\begin{enumerate}
\item Show that $f'+g'=0$, and conclude that $f+g=\frac\pi 4$.
\item Use part 1 to prove
\begin{align}
\int_{-\infty}^{+\infty}e^{-t^2}dt=\sqrt\pi 
\end{align}
\end{enumerate}
\end{sprob}


\begin{prob}\label{lb439}
Let $f:\Rbb\rightarrow V$ be strongly integrable on compact intervals, and assume $\int_\Rbb |f|<+\infty$. Let $g\in C^1(\Rbb,\Rbb)$. Assume that $\Vert g\Vert_\infty,\Vert g'\Vert_\infty<+\infty$. (This is automatic when $g$ has compact support.) Use Thm. \ref{lb428} to prove that $f*g$ is well-defined, that $f*g\in C^1(\Rbb,\Rbb)$, and that $(f*g)'=f*g'$.
\end{prob}

\begin{proof}[Note]
Since $f$ is not assumed to be continuous, you cannot use Thm. \ref{lb434} \textit{directly} to compute $(f*g)'$ and to show $f*g\in C^1$. You have two options: (1) Use Thm. \ref{lb428}. (2) Use Prop. \ref{lb445} to  $L^1$-approximate $f$ by a continuous compactly-supported function. Then apply Thm. \ref{lb434} (together with Cor. \ref{lb429}) to that continuous function. Whichever method you use, I suggest you think about how you can use the other method to solve the problem.
\end{proof}


\begin{rem}
In particular, if $g\in C_c^\infty(\Rbb,\Rbb)$, then the above problem shows that $f*g\in C^\infty(\Rbb,\Rbb)$ and $(f*g)^{(n)}=f*g^{(n)}$ for all $n\in\Nbb$.
\end{rem}



\begin{sprob}
The translation of each $f\in\scr R^1(\Rbb,\Cbb)$ by $t\in\Rbb$ is defined to be
\begin{align*}
f_t:\scr R^1(\Rbb,\Cbb)\rightarrow\scr R^1(\Rbb,\Cbb)\qquad f_t(x)=f(x-t)
\end{align*}
Prove that the translation map is continuous under the $L^1$-seminorm, in the sense that $\lim_{t\rightarrow0}\Vert f-f_t\lVert_{L^1}=0$. Namely, prove that
\begin{align*}
\lim_{t\rightarrow 0}\int_\Rbb |f-f_t|=0
\end{align*}
\end{sprob}

\begin{proof}[Hint]
Use Prop. \ref{lb445} to $L^1$-approximate $f$ by compactly supported continuous functions or step functions. (Both types of functions will work.)
\end{proof}


\begin{df}
Let $f\in\scr R([-\pi,\pi],\Cbb)$. For each $n\in\Zbb$, define the $n$-th \textbf{Fourier coefficient} \index{fn@$\wht f(n)$} to be
\begin{align*}
\wht f(n)=\frac 1{2\pi}\int_{-\pi}^\pi f(x)e^{-\im nx}dx
\end{align*}
We call $\dps \sum_{n=-\infty}^{+\infty}\wht f(n)e^{\im nx}$ the \textbf{Fourier series} \index{00@Fourier series} of $f$.
\end{df}



\begin{df}
For each $N\in\Nbb$, define the \textbf{Dirichlet kernel} \index{00@Dirichlet kernel}
\begin{align*}
D_N(x)=\sum_{n=-N}^Ne^{\im nx}=\frac{\sin(N+\frac 12)x}{\sin(x/2)}
\end{align*}
(When $x\in2\pi\Zbb$, the RHS above should be $2N+1$.) From $\frac 1{2\pi}\int_{-\pi}^\pi e^{\im nx}dx=\delta_{n,0}$ we easily see $\dps\frac 1{2\pi}\int_{-\pi}^\pi D_N(x)dx=1$. 
\end{df}


\begin{prob}\label{lb447}
Let $f\in\scr R(\Rbb,\Cbb)$ have period $2\pi$. Define $\dps s_N(f;x)=\sum_{n=-N}^N\wht f(n)e^{\im nx}$.
\begin{enumerate}
\item Prove that $s_N(f;x)=(f*D_N)(x)$ where the convolution is defined with respect to the integral $\frac 1{2\pi}\int_I$ where $I$ is any interval of length $2\pi$. (Note that both $f$ and $D_N$ have period $2\pi$. So translating $I$ does not affect the result.) In other words, prove that
\begin{align}
s_N(f;x)=\frac 1{2\pi}\int_{-\pi}^{\pi} f(t)D_N(x-t)dt=\frac 1{2\pi}\int_{-\pi}^{\pi} f(x-t)D_N(t)dt
\end{align}
\item Fix $x\in\Rbb$. Assume that there exist $A,B\in\Cbb$ such that 
\begin{align}
\limsup_{t\rightarrow 0^+}\Big|\frac{f(x-t)-A}{t}\Big|<+\infty\qquad \limsup_{t\rightarrow 0^+}\Big|\frac{f(x+t)-B}{t}\Big|<+\infty
\end{align}
(In other words, assume that there exist $\delta,M>0$ such that $|(f(x-t)-A)/t|\leq M$ and $|(f(x+t)-B)/t|\leq M$ for all $0<t<\delta$.) Prove that
\begin{align}
\lim_{N\rightarrow+\infty} s_N(f;x)=\frac{A+B}2
\end{align}
\end{enumerate}
\end{prob}


\begin{proof}[Hint for part 2]
Choose $g:[-\pi,\pi]\rightarrow\Cbb$ such that $g(t)=B$ if $t<0$, and $g(t)=A$ if $t>0$. Prove that
\begin{align}
\frac 1{2\pi}\int_{-\pi}^\pi g(t)D_N(t)dt=\frac{A+B}2  \label{eq193}
\end{align}
Let $\varphi:[-\pi,\pi]\rightarrow \Rbb$ such that $\dps\varphi(t)=\frac{f(x-t)-g(t)}{\sin(t/2)}$ if $t\neq 0$. Use Lebesgue's criterion to show that $\varphi\in\scr R([-\pi,\pi],\Cbb)$. Use Riemann-Lebesgue lemma to prove $\dps\lim_{N\rightarrow+\infty}\int_{-\pi}^\pi \varphi(t)\sin\big(N+\frac 12\big)t\cdot dt=0$. %Combine this with \eqref{eq193} to finish the proof.
\end{proof}


\begin{co}\label{lb448}
Let $g\in C^1([a-\pi,a+\pi],\Cbb)$. Let $f:\Rbb\rightarrow\Cbb$ be a $2\pi$-periodic function such that $f(x)=g(x)$ if $a-\pi<x<a+\pi$, and that $\dps f(a+\pi)=\frac{g(a-\pi)+g(a+\pi)}2$. Clearly $f\in\scr R(\Rbb,\Cbb)$. Then the Fourier series of $f$ converges pointwise to $f$.
\end{co}

\begin{proof}
Immediate from part 2 of Pb. \ref{lb447}.
\end{proof}

\begin{eg}
If we let $a=0$ and $g(x)=x$, then one can compute that the Fourier series of $f$ is \eqref{eq194}. It converges pointwise but not uniformly to $f$.
\end{eg}



















\newpage



\section{A topological proof of the Stone-Weierstrass theorem}



\subsection{*-algebras and subalgebras}\label{mc77}

Fix $\Fbb\in\{\Rbb,\Cbb\}$.


\begin{df}
An \textbf{$\Fbb$-algebra} \index{00@Algebra}  is defined to be a ring $\scr A$ (not necessarily having $1$) which is at the same time also an $\Fbb$-vector space (where the vector addition is equal to the ring addition) such that the ring multiplication and the scalar multiplication satisfy the associativity: For every $\lambda\in\Fbb$ and $x,y\in\scr A$, we have
\begin{align}
\lambda(xy)=(\lambda x)y=x(\lambda y)
\end{align}

An $\Fbb$-algebra is called \textbf{unital} \index{00@Unital algebra} if $\scr A$, as a ring, has the identity $1$. In this case, we write $\lambda\cdot 1$ as $\lambda$ if $\lambda\in\Fbb$. 

An $\Fbb$-algebra is called \textbf{commutative} or \textbf{abelian} \index{00@Commutative algebra} \index{00@Abelian algebra} if $xy=yx$ for all $x,y\in\scr A$.

If $\scr A$ is an $\Fbb$-algebra, then an \textbf{($\Fbb$-)subalgebra} \index{00@Subalgebra} is a subset $\scr B$ which is invariant under the ring addition, ring multiplication, and scalar multiplication. (Namely, $\scr B$ is a subring and also a subspace of $\scr A$.) If $\scr A$ is unital, then a \textbf{unital ($\Fbb$-)subalgebra} of $\scr A$ is an $\Fbb$-subalgebra containing the identity of $\scr A$.  \hfill\qedsymbol
\end{df}


\begin{rem}
A unital $\Fbb$-algebra $\scr A$ is equivalently a ring with unit $1$, together with a ring homomorphism $\Cbb\rightarrow Z(\scr A)$ where $Z(\scr A)$ is the \textbf{center} of $\scr A$, i.e.
\begin{align*}
Z(\scr A)=\{x\in\scr A:xy=yx\text{ for every }y\in\scr A\}
\end{align*}
We leave it to the readers to check the equivalence.
\end{rem}


\begin{eg}
If $V$ is a $\Fbb$-vector space, then $\End(V)$, the set of $\Fbb$ linear maps $V\rightarrow V$, is naturally an $\Fbb$-algebra. If $V$ is a normed vector space, then $\fk L(V)$ is an $\Fbb$-algebra.
\end{eg}

\begin{df}\label{lb586}
A \textbf{(complex) *-algebra} \index{00@*-algebra} is defined to be a $\Cbb$-algebra together with an \textbf{antilinear map} \index{00@Antilinear map} $*:\scr A\rightarrow\scr A$ sending $x$ to $x^*$ (where ``antilinear" means that for every $a,b\in\Cbb$ and $x,y\in\scr A$ we have $(ax+by)^*=\ovl ax^*+\ovl by^*$) such that for every $x,y\in\scr A$, we have
\begin{align*}
(x^*)^*=x\qquad (xy)^*=y^*x^*
\end{align*}
Note that $*$ must be bijective. We call $*$ an \textbf{involution}. 
\index{00@Involution} A \textbf{*-subalgebra} \index{00@*-subalgebra} $\scr B$ is defined to be a subalgebra satisfying $x\in\scr B$ iff $x^*\in\scr B$. If $\scr A$ is a unital algebra with unit $\idt$, we say that $\scr A$ is a \textbf{unital *-algebra} if $\scr A$ is equipped with an involution $*:\scr A\rightarrow\scr A$ such that $\scr A$ is a *-algebra, and that
\begin{align*}
\idt^*=\idt
\end{align*}
A unital *-subalgebra is a unital subalegbra and also a *-subalgebra.
\end{df}


\begin{eg}
The set of complex $n\times n$ matrices $\Cbb^{n\times n}$ is naturally a unital $*$-algebra if for every $A\in\Cbb^{n\times n}$ we define $A^*=\ovl A^\tr$, the complex conjugate of the transpose of $A$.
\end{eg}

In this chapter, we are mainly interested in abelian algebras.

\begin{eg}
Let $X$ be a set. Then $\Fbb^X$ is naturally a unital $\Fbb$-algebra, and $l^\infty(X,\Cbb)$ is its unital $\Fbb$-subalgebra. If $X$ is a topological space, then $C(X,\Fbb)$ is a unital $\Fbb$-subalgebra of $\Fbb^X$. If $X$ is compact, then $C(X,\Fbb)$ is a unital $\Fbb$-subalgebra of $l^\infty(X,\Fbb)$.
\end{eg}



The following is our main example of this chapter.
\begin{eg}
Let $X$ be a set. Then $\Cbb^X$ is a unital *-algebra if for every $f\in\Cbb^X$ we define \index{f@$f^*(x)=\ovl{f(x)}$}
\begin{align}
f^*:X\rightarrow\Cbb\qquad f^*(x)=\ovl{f(x)}
\end{align}
Then $l^\infty(X,\Cbb)$ is a unital *-subalgebra of $\Cbb^X$. Assume that $X$ is a compact topological space. Then $C(X,\Cbb)$ is a unital *-subalgebra of $l^\infty(X,\Cbb)$. If $f_1,\dots,f_n\in C(X,\Cbb)$, then $\Cbb[f_1,\dots,f_n]$, the set of polynomials of $f_1,\dots,f_n$ with coefficients in $\Cbb$, is a unital subalgebra of $C(X,\Cbb)$. And $\Cbb[f_1,f_1^*,\dots,f_n,f_n^*]$ is a unital *-subalgebra of $C(X,\Cbb)$.
\end{eg}


More generally, we have:

\begin{eg}
Let $\scr A$ be an abelian unital $\Fbb$-algebra. Let $\fk S\subset\scr A$. Then \index{FS@$\Fbb[\fk S]$}
\begin{align}
\Fbb[\fk S]=\Span_\Fbb\{x_1^{n_1}\cdots x_k^{n_k}:k\in\Zbb_+,x_i\in\fk S,n_i\in\Nbb\}
\end{align}
the set of polynomials of elements in $\fk S$, is the smallest unital $\Fbb$-subalgebra containing $\fk S$, called the \textbf{unital $\Fbb$-subalgebra generated by $\fk S$}. \index{00@Subalgebra generated by...} (Here, we understand $x^0=1$ if $x\in\scr A$.) Thus, if $\scr A$ is an abelian unital *-algebra, then $\Cbb[\fk S\cup\fk S^*]$ (where $\fk S^*=\{x^*:x\in\fk S\}$) is the smallest unital *-algebra containing $\fk S$, called the \textbf{unital *-subalgebra generated by $\fk S$}.
\end{eg}



\subsection{The Stone-Weierstrass (SW) theorems} \index{00@SW=Stone-Weierstrass}




The main goal of this chapter is to prove the following theorem.

\begin{thm}[\textbf{SW theorem, compact real version}]\index{00@SW theorem, compact real version}\label{lb442}
Let $X$ be a compact Hausdorff space. Let $\scr A$ be unital subalgebra of $C(X,\Rbb)$ separating points of $X$. Then $\scr A$ is dense in $C(X,\Rbb)$ (under the $l^\infty$-norm).
\end{thm}

\begin{eg}
Let $X=[a,b]$ be a compact interval in $\Rbb$. Then $\Rbb[x]$ is a unital subalgebra of $C(X,\Rbb)$. It separates points of $[a,b]$ because it contains $\id$. Thus, by SW theorem, $\Rbb[a,b]$ is dense in $C([a,b],\Rbb)$. This special case was proved in Thm. \ref{lb441}.

More generally, let $X=I_1\times\cdots\times I_N$ where each $I_i\subset\Rbb$ is a compact interval. Let $\pi_i:X\rightarrow I_i$ be the projection onto the $i$-th component, i.e., the $i$-th coordinate function. Then $\pi_1,\dots,\pi_N$ separate points of $X$, since $\pi_1\times\cdots\times\pi_N$ is the identity map of $X$. Thus, by SW theorem, $\Rbb[\pi_1,\dots,\pi_N]$ is dense in $C(X,\Rbb)$. In fact, we will first prove this special case before we prove the general SW theorem. \hfill\qedsymbol
\end{eg}

From the above version of SW theorem it is easy to prove:

\begin{thm}[\textbf{SW theorem, compact complex version}]\index{00@SW theorem, compact complex version}\label{lb450}
Let $X$ be a compact Hausdorff space. Let $\scr A$ be a unital *-subalgebra of $C(X,\Cbb)$ separating points of $X$. Then $\scr A$ is dense in $C(X,\Rbb)$ (under the $l^\infty$-norm).
\end{thm}

\begin{proof}
Let $\Real\scr A=\{\Real f=(f+f^*)/2:f\in\scr A\}$. Since for each $f\in\scr A$ we have $f^*\in\scr A$, we know that $\Real f\in\scr A$. This proves that $\Real\scr A\subset\scr A$. Since $f=\Real( f)-\im\Real(\im f)$, we conclude
\begin{align}
\scr A=\Real\scr A+\im\Real\scr A  \label{eq192}
\end{align}
In other words, elements of $\scr A$ are precisely of the form $\alpha+\im\beta$ where $\alpha,\beta\in\Real\scr A$. From this, it is clear that $\Real\scr A$ is a unital subalgebra of $C(X,\Rbb)$ separating points of $X$. Thus, by Thm. \ref{lb442}, $\Real\scr A$ is dense in $C(X,\Rbb)$. It is clear from \eqref{eq192} that $\scr A$ is dense in $C(X,\Cbb)$.
\end{proof}


\begin{eg}\label{lb443}
Let $\Sbb^1=\{z\in\Cbb:|z|=1\}$. For each $n\in\Zbb$, let $e_n:\Sbb^1\rightarrow \Cbb$ be defined by $e_n(e^{\im x})=e^{\im nx}$. In other words, $e_n(z)=z^n$. Then $\Cbb[e_1,e_{-1}]=\Span_\Cbb\{e_n:n\in\Zbb\}$ is a unital *-subalgebra of $C(\Sbb^1,\Cbb)$. It separates points of $\Sbb^1$ since $e_1$ does. Therefore, by SW theorem, $\Cbb[e_1,e_{-1}]$ is dense in $\Cbb(\Sbb^1,\Cbb)$. 

One often views
\begin{align}
C(\Sbb^1,\Cbb)=\{g\in C([-\pi,\pi],\Cbb):g(-\pi)=g(\pi)\}
\end{align}
since any $g$ in the RHS corrsponds bijectively to $f$ in the LHS by setting $f(e^{\im t})=g(t)$. Therefore, the above conclusion is that \textit{any $g\in C([-\pi,\pi],\Cbb)$ satisfying $g(-\pi)=g(\pi)$ can be approximated uniformly by functions of the form $\sum_{n=-N}^N a_n\cdot e^{\im nx}$ where $a_n\in\Cbb$}. This property is fundamental  to the theory of Fourier series. \hfill\qedsymbol
\end{eg}


\begin{eg}
We continue the above discussion. $\Cbb[e_1]=\Span_\Cbb\{e_n:n\in\Nbb\}$ is a unital subalgebra (though not a *-subalgebra) of $C(\Sbb^1,\Cbb)$ separating points of $\Sbb^1$. Let us prove that it is not dense in $C(\Sbb^1,\Cbb)$. 
\end{eg}

\begin{proof}
We view functions on $\Sbb^1$ as those on $[-\pi,\pi]$ having the same values at $\pi$ and at $-\pi$. We claim that $e_{-1}$ is not in the closure of $\Cbb[e_1]$. Indeed, it can be checked that $\int_{-\pi}^{\pi}e_{-1}e_1=2\pi$, and that $\int_{-\pi}^{\pi} p\cdot e_1=0$ for every $p\in\Cbb[e_1]$ (since this is true when $p=e_n$ and $n\geq0$). If $e_{-1}$ is in the closure of $\Cbb[e_1]$, then there is a sequence $(p_k)_{k\in\Zbb_+}$ in $\Cbb[e_1]$ converging uniformly on $[-\pi,\pi]$ to $e_{-1}$. By Cor. \ref{lb380}, $0=\int_{-\pi}^\pi p_ke_1$ converges  to $\int_{-\pi}^\pi e_{-1}e_1=2\pi$ as $k\rightarrow\infty$, impossible.  
\end{proof}

\begin{eg}\label{lb539}
Let $X,Y$ be compact metric spaces spaces. Let $\scr A$ be the subspace of $C(X\times Y,\Rbb)$ spanned by elements of the form $fg$ where $f\in C(X,\Rbb)$ and $g\in C(Y,\Rbb)$. (More precisely, one should understand $fg$ as $(f\circ\pi_X)\cdot(g\circ\pi_Y)$ where $\pi_X,\pi_Y$ are the projections of $X\times Y$ onto $X$ and $Y$ respectively.) By the Urysohn functions (cf. Rem. \ref{lb257}), we see that $C(X,\Rbb)$ resp. $C(Y,\Rbb)$ separates points of $X$ resp. $Y$. (This is in fact also true when $X,Y$ are compact Hausdorff spaces.) Thus $\scr A$ is a unital subalgebra of $C(X\times Y,\Rbb)$ separating points of $X\times Y$. By SW theorem, $\scr A$ is dense in $C(X\times Y,\Rbb)$. Nevertheless, we will prove SW theorem by first proving this special case: see Cor. \ref{lb471}.\footnote{More precisely, we don't need Exp. \ref{lb539} to prove SW. But our method of proving SW immediately implies Exp. \ref{lb539}. To put it differently, we don't need the full power of the SW theorem to prove Exp. \ref{lb539}.}
\end{eg}




\subsection{Proof of SW, I: polynomial approximation on $[0,1]^{\scr I}$}



Starting from this section, we begin our proof of SW Thm. \ref{lb442}. We first explain our strategy of the proof. Let $X$ be a compact Hausdorff space. 

We first consider the special case that $X$ is metrizable. Then by Thm. \ref{lb261}, $X$ is homeomorphic to a closed (and hence compact) subset of $[0,1]^{\Zbb_+}$. Therefore, we may assume that $X$ is a closed subset of $[0,1]^{\Zbb_+}$. As we will see, any continuous real-valued function on $X$ can be extended to a continuous function on  $[0,1]^{\Zbb_+}$. (This is due to \textbf{Tietze extension theorem}, which will be proved in the next section.) Thus, it suffices to prove SW theorem for $[0,1]^{\Zbb_+}$. In fact, as we will see, it suffices to prove that any element of $C([0,1]^{\Zbb_+},\Rbb)$ can approximated uniformly by polynomials, i.e., by elements of $\Rbb[\pi_1,\pi_2,\dots]$ where $\pi_n:[0,1]^{\Zbb_+}\rightarrow[0,1]$ is the projection onto the $n$-th component. This task will be achieved in this section.

The above method can be easily genearlized to the case that $X$ is not necessarily metrizable. In fact, since $\scr A\subset C(X,\Rbb)$ separates points of $X$, as in the proof of  Thm. \ref{lb261}, $\scr A$ enables us to embed $X$ onto a compact subset of $[0,1]^{\scr I}$ where $\scr I$ is an index set. Therefore, we need to show that $[0,1]^{\scr I}$ is compact. This is indeed due to:

%% Record #22 2023/12/6 three lectures  55

\begin{thm}[\textbf{Tychonoff theorem}]\index{00@Tychonoff theorem}\label{lb452}
Let $(X_\alpha)_{\alpha\in\scr I}$ be a family of compact topological spaces. Then the product space $S=\prod_{\alpha\in\scr I}X_\alpha$ (equipped with the product topology) is compact.
\end{thm}

Note that $S$ is obviously Hausdorff if each $X_\alpha$ is Hausdorff. We will prove Tychonoff theorem in Sec. \ref{lb503} using Zorn's lemma. Assuming Tychonoff theorem, we will show that elements of $C([0,1]^{\scr I},\Rbb)$ can be approximated uniformly by polynomials. This is the goal of this section:


\begin{pp}\label{lb451}
Let $(I_\alpha)_{\alpha\in\scr I}$ be a family of nonempty compact  intervals in $\Rbb$. Let $S=\prod_{\alpha\in\scr I}I_\alpha$. For each $\alpha$, define the \textbf{coordinate function}
\begin{align*}
\pi_\alpha:S\rightarrow I_\alpha\qquad x_\blt=(x_\mu)_{\mu\in\scr I}\mapsto x_\alpha
\end{align*}
Then $\Rbb[\{\pi_\alpha:\alpha\in\scr I\}]$, the unital subalgebra of $C(S,\Rbb)$ generated by all coordinate functions, is dense in $C(S,\Rbb)$.
\end{pp}


Since the coordinate functions separate points of $S$, Prop. \ref{lb451} is clearly a special case of SW theorem. %According to \cite{Sto48}, Prop. \ref{lb451} was due to Dieudonn\'e. Interestingly, M. Stone reproved this proposition \textit{as an application of SW theorem} (cf. Thm. 14 in \cite[p.342, Sec. 8]{Sto48}), since he didn't use Prop. \ref{lb451} to prove SW theorem.


\begin{lm}\label{lb456}
Prop. \ref{lb451} holds when $\scr I$ is a finite set.
\end{lm}

\begin{proof}
We prove by induction on $N$ that elements of $C(S,\Rbb)$, where $S=I_1\times\cdots\times I_N$, can be approximated uniformly by polynomials (i.e. by elements of $\Rbb[\pi_1,\dots,\pi_N]$). The case $N=1$ follows from Weierstrass approximation Thm. \ref{lb441}. Assume that case $N-1$ has been proved. Let use prove case $N$ where $N>1$. 

Write $S=I_1\times Y$ where $Y=I_2\times\cdots\times I_N$. Then by Thm. \ref{lb274}, we have a canonical equivalence of normed vector spaces
\begin{align*}
C(S,\Rbb)\simeq C(I_1,\mc V)\qquad\text{where}\qquad\mc V=C(Y,\Rbb)
\end{align*}
Choose any $f\in C(S,\Rbb)$, viewed as an element of $C(I_1,\mc V)$. Then by Thm. \ref{lb441}, $f$ can be approximated uniformly on $I_1$ by elements of $\mc V[\pi_1]$. Thus, for any $\eps>0$, there exist $n\in\Zbb_+$ and $g_0,\dots,g_n\in C(Y,\Rbb)$ such that $\Vert f-\sum_{i=0}^n g_i\cdot\pi_1^i\Vert_{l^\infty(I_1,\mc V)}<\eps$. Equivalently,
\begin{align*}
\Big\Vert f-\sum_{i=0}^n g_i\cdot \pi_1^i\Big\Vert_{l^\infty(S,\Rbb)}<\eps
\end{align*}
where $g_i$ actually means the composition of $g_i$ with the projection $S\rightarrow Y$. By case $N-1$, each $g_i$ can be approximated uniformly on $Y$ by elements of $\Rbb[\pi_2,\dots,\pi_N]$. So by triangle inequality, $f$ can be uniformly approximated by elements of the form $\sum_{i=1}^n h_i\cdot\pi_1^i$ where each $h_i$ is a polynomial of $\pi_2,\dots,\pi_N$. This finishes the proof of case $N$.
\end{proof}



The key to the transition from finite to general index sets is the following lemma.


\begin{lm}\label{lb455}
Let $(X_\alpha)_{\alpha\in\scr I}$ be a family of nonempty topological spaces. Let $S=\prod_{\alpha\in\scr I} X_\alpha$. Let $f\in C(S,\Rbb)$. Let $p_\blt=(p_\alpha)_{\alpha\in\scr I}\in S$. For each $A\in\fin(2^{\scr I})$, define a map $\varphi_A:S\rightarrow S$ such that for each $x_\blt=(x_\alpha)_{\alpha\in\scr I}$,
\begin{gather*}
\varphi_A(x_\blt)_\alpha=\left\{
\begin{array}{ll}
x_\alpha&\text{ if }\alpha\in A\\
p_\alpha&\text{ if }\alpha\notin A
\end{array}
\right.
\end{gather*}
Then $\varphi_A$ is continuous, and hence $f\circ\varphi_A$ is continuous. Moreover, for every $x_\blt\in S$ we have
\begin{align}\label{eq195}
\lim_{
\begin{subarray}{c}
(A,y_\blt)\in\fin(2^{\scr I})\times S\\
(A,y_\blt)\rightarrow (\infty,x_\blt)
\end{subarray}
}f\circ\varphi_A(y_\blt)=f(x_\blt)
\end{align}
in the sense of Prop. \ref{lb281}. Thus, if each $X_\alpha$ is compact, then $S$ is compact by Tychonoff Thm. \ref{lb452}, and hence $\dps\lim_{A\in\fin(2^{\scr I})}f\circ\varphi_A$ converges uniformly to $f$ by Thm. \ref{lb277}.
\end{lm}

In other words, $\varphi_A$ fixes the $\alpha$-th component if $\alpha\in A$, and changes the $\alpha$-th component to $p_\alpha$ if $\alpha\notin A$. \eqref{eq195} means that for every $\eps>0$ there exist $U\in\Nbh(x_\blt)$ and a finite $A\subset \scr I$ such that for every $y_\blt\in U$ and for every finite set $B$ satisfying $A\subset B\subset\scr I$, we have $|f(x_\blt)-f\circ\varphi_B(y_\blt)|<\eps$.


\begin{proof}
The proof is similar to that of Pb. \ref{lb453}. The continuity of $\varphi_A$ follows easily from the net-convergence description of product topology in Thm. \ref{lb192}. Choose any $x_\blt\in S$ and $\eps>0$. Since $f$ is continuous, there exists $U\in\Nbh(x_\blt)$ such that $|f(x_\blt)-f(y_\blt)|<\eps$ for all $y_\blt\in U$. By the definition of product topology by means of basis (Def. \ref{lb454}), we can shrink $U$ to a smaller neighborhood of $x_\blt$ of the form
\begin{align*}
U=\prod_{\alpha\in \scr I}V_\alpha
\end{align*}
where $V_\alpha\in\Nbh_{X_\alpha}(x_\alpha)$ for each $\alpha\in\scr I$, and $V_\alpha=X_\alpha$ for all $\alpha$ outside some $A\in\fin(2^{\scr I})$. Thus, $y_\blt\in S$ belongs to $U$ iff $y_\alpha\in V_\alpha$ for each $\alpha\in A$. Therefore, if $y_\blt\in U$, then for each finite $B$ satisfying $A\subset B\subset\scr I$, we have that
\begin{align*}
\varphi_B(y_\blt)_\alpha=y_\alpha\in V_\alpha\qquad(\forall\alpha\in A)
\end{align*}
and hence that $\varphi_B(y_\blt)\in U$. It follows that $|f(x_\blt)-f\circ\varphi_B(y_\blt)|<\eps$.
\end{proof}


\begin{proof}[\textbf{Proof of Prop. \ref{lb451}}]
Choose any continuous $f:S=\prod_{\alpha\in\scr I}I_\alpha\rightarrow\Rbb$. By Lem. \ref{lb455}, $f$ can be approximated uniformly by functions depending on finitely many variables. In other words, for any $\eps>0$, there exist $A\in\fin(2^{\scr I})$ and a continuous $g:S_A=\prod_{\alpha\in A}I_\alpha\rightarrow\Rbb$ such that $\Vert f-g\circ\pi_A\Vert_{l^\infty(S,\Rbb)}<\eps$, where $\pi_A:S\rightarrow S_A$ is the natural projection. By Lem. \ref{lb456}, $g$ can be approximated uniformly by polynomials of $\{\pi_\alpha:\alpha\in A\}$. This finishes the proof.
\end{proof}




\subsection{Partition of unity and the Tietze extension theorem}\label{lb464}


In this section, we fix a Banach space $\mc V$ over $\Fbb\in\{\Rbb,\Cbb\}$, and fix a nonempty LCH space $X$. Recall from Prop. \ref{lb245} that every open subset of $X$ is LCH. We \index{CcX@$C_c(X,\Rbb_{\geq0})$} let \index{Cc@$C_c(X,[0,1])$}
\begin{gather}
C_c(X,[0,1])=\{f\in C_c(X,\Rbb):f(X)\subset[0,1]\}\\
C_c(X,\Rbb_{\geq0})=\{f\in C_c(X,\Rbb):f(X)\subset\Rbb_{\geq0}\}
\end{gather}



\begin{rem}\label{lb457}
Let $U$ be an open subset of $X$. Let $f\in C_c(U,\mc V)$ supported in $U$. Then by zero-extension, $f$ can be viewed as an element of $C_c(X,\mc V)$ supported in $U$. Briefly speaking, we have
\begin{align}
C_c(U,\mc V)\subset C_c(X,\mc V)
\end{align}
\end{rem}


\begin{proof}
Let $f$ take value $0$ outside $U$. Let  $A=\{x\in U:f(x)\neq 0\}$ and $K=\Cl_U(A)$, which is compact by assumption. In particular, $K$ is closed in $X$ by Cor. \ref{lb234}. Then $X=U\cup K^c$ is an open cover on $X$. By assumption, $f|_U$ is continuous. Also $f|_{K^c}=0$ is continuous. So $f$ is continuous by Exe. \ref{lb184}. To show that $f\in C_c(X,\mc V)$ and $\Supp(f)\subset U$, it remains to prove that $\ovl A=\Cl_X(A)$ is compact and is contained in $U$. This fact follows from Rem. \ref{lb459}.
\end{proof}



\begin{rem}\label{lb459}
Let $W$ be a subset of a Hausdorff space $Y$. (In this section, we are mainly interested in the case that $Y$ is the LCH space $X$ and $W$ is open. In this case, $W$ is LCH by Prop. \ref{lb245}.)  Let $A\subset W$, and recall $\ovl A=\Cl_Y(A)$. Then \index{00@Precompact subset}
\begin{align}\label{eq196}
A\text{ is precompact in }W\quad\Longleftrightarrow\quad \ovl A\text{ is compact, and }\ovl A\subset W
\end{align}
Moreover, if $A$ is precompact in $W$, then $\ovl A$ equals $\Cl_W(A)$.
\end{rem}

Note that if $W$ is open, but if $A$ is not precompact in $W$, then $\Cl_Y(A)$ and $\Cl_W(A)$ are not necessarily equal: take $Y=\Rbb$ and $A=W=\Rbb_{>0}$.

\begin{proof}
``$\Leftarrow$" is obvious from the definition of precompactness (recall Def. \ref{lb458}).

``$\Rightarrow$": Clearly $\Cl_W(A)\subset\ovl A$ in general. Assume that $A$ is a precompact subset of $W$. By Def. \ref{lb458}, we have $A\subset\Cl_W(A)\subset W$ where $\Cl_W(A)$ is compact. In particular, $\Cl_W(A)$ is closed in $Y$ (by Cor. \ref{lb234}). So $\ovl A\subset\Cl_W(A)$. So $\ovl A=\Cl_W(A)$. Thus $\ovl A$ is a compact subset of $W$ since $\Cl_W(A)$ is so.
\end{proof}


\begin{df}\label{lb930}
Let $W$ be a subset of a Hausdorff space $Y$. We write \index{zz@$\Subset$}
\begin{align}
A\Subset W
\end{align}
whenever $A$ is a precompact subset of $W$, or equivalently, whenever $A\subset Y$ satisfies that $\Cl_Y(A)$ is a compact subset of $W$.
\end{df}




\subsubsection{Tietze extension theorem}



The goal of this section is to prove the celebrated

\begin{thm}[\textbf{Tietze extension theorem}]\index{00@Tietze extension theorem}\label{lb468}
Let $K$ be a compact subset of $X$. Let $f\in C(K,\mc V)$. Then there exists $\wtd f\in C_c(X,\mc V)$ such that $\wtd f|_K=f$, and that $\Vert \wtd f\Vert_{l^\infty(X,\mc V)}=\Vert f\Vert_{l^\infty(K,\mc V)}$.
\end{thm}

The reader can first assume this theorem and read Sec. \ref{lb473} about the proof of SW theorem, and then return to this section to read the proof of Tietze extension theorem.

\begin{rem}
Tietze extension theorem is often used in the following form: Suppose that $U$ is an open subset of $X$ containing $K$. Applying Tietze extension to $U$ (which is LCH by Prop. \ref{lb245}) and noticing Rem. \ref{lb457}, we see that every $f\in C(K,\mc V)$ can be extended to some $\wtd f\in C_c(X,\mc V)$ supported in $U$ such that $\Vert \wtd f\Vert_{l^\infty(X,\mc V)}=\Vert f\Vert_{l^\infty(K,\mc V)}$. In other words, in Tietze extension theorem, we can assume that the extended function is compactly supported in a given open subset.
\end{rem}

\begin{co}\label{lb474}
$C_c(X,\Rbb)$ separates points of $X$.
\end{co}

\begin{proof}
Choose distinct points $x,y\in X$. Let $K=\{x,y\}$. Let $f:K\rightarrow\Rbb$ such that $f(x)=1$ and $f(y)=0$. By Thm. \ref{lb468}, $f$ can be extended to some $\wtd f\in C_c(X,\Rbb)$ which clearly separates $x$ and $y$.
\end{proof}



There is another version of Tietze extension theorem: If $A$ is a closed subset of a normal topological space $Y$, then any $f\in C(A,\Rbb)$ can be extended to some $\wtd f\in C(Y,\Rbb)$ without increasing the  $l^\infty$-norm. Its proof is not quite the same as the LCH version. See \cite[Sec. 35]{Mun}. We will not use this version in our course. 




\subsubsection{Urysohn's lemma}



The proof of Tietze extension theorem involves several steps. The first step is to prove a special case: If $K\subset X$ is compact, then the characteristic function $\chi_K:X\rightarrow\Rbb$ can be extended to a continuous $f\in C_c(X,\Rbb)$. Then $f|_K=1$. Replacing $f$ by $\max\{f,0\}$, we may assume that $f\geq0$. Replacing $f$ by $\min\{f,1\}$, we may assume $0\leq f\leq 1$. This special case is called


\begin{thm}[\textbf{Urysohn's lemma}]\index{00@Urysohn's lemma for LCH spaces}\label{lb711}
Let $K$ be a compact subset of $X$. Then there exists $f\in C_c(X,[0,1])$ such that $f|_K=1$. We call $f$ an \textbf{Urysohn function} \index{00@Urysohn functions for LCH spaces} with respect to $K$ and $X$.
\end{thm}

Note that since any open subset $U\subset X$ is LCH (Prop. \ref{lb245}), Urysohn's lemma can be applied to $U$ and any compact subset $K\subset U$, which shows that there exists $f\in C_c(X,[0,1])$ such that $\Supp(f)\subset U$ and $f|_K=1$.


\begin{comment}
\begin{df}\label{lb465}
Let $U$ be an open subset of $X$. Let $K$ be a compact subset of $X$.
\begin{itemize}
\item $f\prec U$ means $f\in C_c(U,[0,1])$. Equivaletly, it means that $f\in C_c(X,[0,1])$  (i.e. $f\in C_c(X,\Rbb)$ and $f(X)\subset[0,1]$) and that $\Supp(f)\subset U$. 
\item $K\prec f$ means that $f\in C_c(X,[0,1])$ and that $f|_K=1$.
\end{itemize} 
\end{df}
 

The symbol ``$\prec$" is chosen for the following reason. Assume $f\in C_c(X,[0,1])$. Then $K\prec f$ means that $\chi_K\leq f$. However, the meaning of $f\prec U$ is slightly stronger than that of $f\leq \chi_U$: the latter means that $U$ contains $\{x:f(x)\neq0\}$, but not that $U$ contains its closure $\Supp(f)$.

\end{comment}





To prove Urysohn's lemma we need some elementary observations:







\begin{lm}\label{lb460}
Let $W$ be an open subset of $X$. Let $K$ be a compact subset of $W$. Then there exists an open set $U$ of $X$ such that $K\subset U\Subset W$. 
\end{lm}


By Rem. \ref{lb459}, this lemma simply means that every compact $K\subset W$ is contained in a precompact open subset of $W$. To prove it, it suffices to assume $X=W$.


\begin{proof}
We assume $X=W$. Since $X$ is LCH, every $x\in K$ is contained in a precompact open subset $U_x$. Since $K$ is compact, $K$ is contained in $U=U_{x_1}\cup\cdots\cup U_{x_n}$ for some $x_1,\dots,x_n\in K$. Clearly $U$ is open and precompact.
\end{proof}


Recall Def. \ref{lb462} for the meaning of $\omega(f,x)$, the oscillation of a function $f$ at $x$.

\begin{lm}\label{lb463}
Let $Y$ be a topological space and $Z$ a metric space. Let $(f_n)$ be a sequence in $Z^Y$ converging uniformly to $f\in Z^Y$. Assume that for each $x\in Y$, $\lim_{n\rightarrow\infty}\omega(f_n,x)=0$. Then $f$ is continuous.
\end{lm}


Note that Thm. \ref{lb279} can be viewed as a special case of this lemma. However, this lemma is not used as often as Thm. \ref{lb279}. This is why we call this result only a lemma.

\begin{proof}
Choose any $\eps>0$. Then there is $N\in\Zbb_+$ such that for all $n\geq N$ we have $\Vert f-f_n\Vert_\infty<\eps$. Since $\lim_{n\rightarrow\infty}\omega(f_n,x)=0$, there is $n\geq N$ such that $\omega(f_n,x)<\eps$. Thus there exist $n\geq N$ and $U\in\Nbh_X(x)$ such that $\diam(f_n(U))<\eps$. Then by triangle inequality, we have $\diam(f(U))\leq 3\eps$. So $\omega(f,x)\leq3\eps$. Since $\eps$ is arbitrary, we conclude $\omega(f,x)=0$. So $f$ is continuous at $x$ by Prop. \ref{lb461}.
\end{proof}



\begin{proof}[$\star$ \textbf{Proof of Urysohn's lemma}]
By Lem. \ref{lb460}, we can choose $U_1\Subset X$ containing $K$. In the case that $X$ is metrizable, $f(x)=d(x,U_1^c)/(d(x,K)+d(x,U_1^c))$ gives a desired function. However, in the general case, we need to construct $f$ in a different way. 

We shall construct inductively a sequence of functions $f_n:X\rightarrow[0,1]$ such that the following conditions are satisfied:
\begin{enumerate}[label=(\alph*)]
\item $f_n|_K=1$ and $f_n|_{X\setminus U_1}=0$.
\item $\omega(f_n,x)\leq \frac 1{2^n}$ for all $x\in X$.
\item $\Vert f_{n+1}-f_n\Vert_{l^\infty}\leq \frac 1{2^{n+1}}$ for all $n$.
\end{enumerate}
Then $\Vert f_{n+k}-f_n\Vert_\infty\leq 1/2^n$ for all $n,k>0$. Thus $(f_n)_{n\in\Zbb_+}$ is a Cauchy sequence in $l^\infty(X,\Rbb)$, converging uniformly to some $f\in l^\infty(X,\Rbb)$. Clearly $f(X)\subset[0,1]$, $f|_K=1$, and $f|_{X\setminus U_1}=0$. So $f$ is compactly supported since $\ovl U_1$ is compact. By Lem. \ref{lb463}, $f\in C_c(X,[0,1])$, finishing the proof.

In fact, our construction of $f_n$ relies on
\begin{align*}
K~\subset~ U_0~\Subset~ U_{\frac 1{2^n}}~\Subset~ U_{\frac 2{2^n}}~\Subset~\cdots~\Subset ~U_{\frac{2^{n}-1}{2^n}}~\Subset ~U_1
\end{align*}
$f_0$ is simply defined to be $\chi_{U_0}$ where $U_0$ is a precompact open subset of $U_1$ containing $K$ (which exists due to Lem. \ref{lb460}). 

Suppose that $f_n$ and $U_{\frac j{2^n}}$ (where $0\leq j<2^n$) have been constructed. Clearly $U_{\frac j{2^{n+1}}}$ already exists when $j$ is even. Suppose that $j$ is odd, let $U_{\frac j{2^{n+1}}}$ be a precompact open subset of $U_{\frac {j+1}{2^{n+1}}}$ containing the closure of  $U_{\frac {j-1}{2^{n+1}}}$. Then $K\subset U_0\Subset U_{\frac 1{2^{n+1}}}\Subset U_{\frac 2{2^{n+1}}}\Subset\cdots\Subset U_1$. Let
\begin{align*}
h_{n+1}=\sum_{
\begin{subarray}{c}
0<j<2^{n+1}\\
j\text{ is odd}
\end{subarray}
}2^{-n-1}\cdot\chi_{\Delta_j}\qquad\text{where}\qquad \Delta_j=U_{\frac j{2^{n+1}}}\setminus U_{\frac{j-1}{2^{n+1}}}
\end{align*}
and let $f_{n+1}=f_n+h_{n+1}$. The best way to understand this construction is to look at the pictures:
\begin{gather*}
\vcenter{\hbox{{
			\includegraphics[height=3cm]{fig4.png}}}}
\qquad
\vcenter{\hbox{{
			\includegraphics[height=3cm]{fig5.png}}}}
\qquad
\vcenter{\hbox{{
			\includegraphics[height=3cm]{fig6.png}}}}
\end{gather*}


Clearly (a) and (c) are satisfied. Choose any $x\in X$. For each $n$, let $U_{\frac {2^n+1}{2^n}}=X$ and $U_{-\frac 1{2^n}}=\emptyset$. Then $X$ is a disjoint  union of $\Delta_j=U_{\frac j{2^{n+1}}}\setminus U_{\frac{j-1}{2^{n+1}}}$ over $0\leq j\leq 2^n+1$, and $f_n$ can be described by $f_n|_{\Delta_j}=\max\{1-\frac j{2^n},0\}$. For each $x\in \Delta_j$ (where $1\leq j\leq 2^n+1$), let
\begin{align*}
W=U_{\frac{j}{2^n}}\setminus\ovl{U_{\frac{j-2}{2^n}} }
\end{align*}
Then $W\in\Nbh_X(x)$, and $\diam(f_n(W))\leq \frac 1{2^n}$ since $W\subset \Delta_j\cup\Delta_{j-1}$. If $x\in\Delta_0$, then $\Delta_0\in\Nbh(x)$ and $\diam(f_n(\Delta_0))=0$. This proves (b).
\end{proof}



\subsubsection{Partition of unity}\label{lb467}


In the second step of the proof of Tietze extension theorem, we prove the theorem on partition of unity.

Recall that we defined Riemann integrals by partitioning a compact interval into small intervals. Thus, in order to define the integral of a function on $\Rbb^2$, one can partition a rectangle into smaller ones. However, it is more difficult to integrate a function defined on a more complicated space (a complicated compact surface $M$ in $\Rbb^3$, for example) by dividing $M$ into small pieces, since these small pieces may have complicated shapes.

Instead of partitioning $M$, a better way to define $\int_Mf$ is by partitioning $f$. Let $f:M\rightarrow\Rbb$ be continuous. Suppose first of all that $\Supp(f)$ is contained in a small enough neighborhood $U$ which can be ``parametrized by a rectangle". (More precisely: we can find a bijection $\varphi:R\rightarrow U$, where $R=(a,b)\times(c,d)$ is an open rectangle in $\Rbb^2$, such that $\varphi$ and $\varphi^{-1}$ are both smooth. Such $\varphi$ is called a \textbf{diffeomorphism}.) Then we can use integrals on rectangles to define $\int_Mf$ by ``pulling back $f$ to $R$". Now, in the general case, one can define $\int_Mf$ by writting $f$ as $f_1+\cdots+f_n$ where each $f_n\in C(M,\Rbb)$ has a small enough support such that $\int_Mf_i$ can be defined. Then $\sum_i\int_Mf_i$ gives the formula of $\int_Mf$. 

Notice that it suffices to write the constant function $1$ on $M$ as $h_1+\cdots+h_n$ where each $\Supp(h_i)$ is small enough. Then $f=fh_1+\cdots+fh_n$ gives a desired partition of $f$. Thus, $1=h_1+\cdots+h_n$ is called a \textbf{partition of unity} (where ``unity" means the constant function $1$).


%% Record #23 2023/12/11 two lectures  57

\begin{thm}\label{lb466}
Let $K$ be a compact subset of $X$. Let $\fk U=(U_1,\dots,U_n)$ be a finite set of open subsets of $X$ covering $K$ (i.e. $K\subset U_1\cup\cdots\cup U_n$). Then there exist $h_i\in C_c(U_i,\Rbb_{\geq0})$ (for all $1\leq i\leq n$) satisfying the following conditions:
\begin{enumerate}[label=(\arabic*)]
\item $0\leq \dps \sum_{i=1}^nh_i\leq 1$ on $X$. 
\item  $\dps\sum_{i=1}^nh_i\big|_K=1$.
\end{enumerate}
Such $h_1,\dots,h_n$ are called a \textbf{partition of unity of $K$ subordinate to $\fk U$}. \index{00@Partition of unity in LCH spaces}
\end{thm}


Note that since $h_i\in C_c(U_i,\Rbb_{\geq0})$, clearly $\sum_i h_i$ has compact support in $U=U_1\cup\cdots\cup U_n$. Therefore,  (1) and (2) simply say that $\sum_i h_i$ is an Urysohn function with respect to $K$ and $U$. Thus, $h_1,\dots,h_n$ should more precisely be referred to as a \textbf{partition of the Urysohn function} $\sum_i h_i$. 


\begin{proof}
Step 1. Let us construct $G_i\in C_c(U_i,\Rbb_{\geq0})$ for each $1\leq i\leq n$ such that $G:=\sum_i G_i$ is $>0$ on $K$ (i.e., $G(K)\subset\Rbb_{>0}$).  

By Urysohn's lemma, for each $x\in X$ there exists $g_x\in C_c(X,[0,1])$ supported in $U_i$ such that $g_x(x)\neq 0$. Since $K$ is compact and is contained in $\bigcup_{x\in K}g_x^{-1}(\Rbb_{>0})$, there exists a finite subset $E\subset K$ such that $K\subset \bigcup_{x\in E}g_x^{-1}(\Rbb_{>0})$. So $\sum_{x\in E}g_x\big|_K>0$. 

Now, for each $1\leq i\leq n$, define
\begin{align}\label{eq197}
G_i=\sum_{
\begin{subarray}{c}
x\in E\\
\Supp(g_x)\subset U_i
\end{subarray}}
g_x
\end{align}
Since for each $x\in E$ there is some $U_i$ containing $\Supp(g_x)$, when summing up \eqref{eq197} over all $i$, each $g_x$ must appear at least once in the summand. So $G:=\sum_i G_i$ is $\geq \sum_i g_i$, and hence $G|_K>0$. Clearly each $G_i$ is $\geq0$ and is compactly supported in $U_i$. \\[-1ex]


Step 2. $G_1,\dots,G_n$ does not necessarily satisfy (1) and (2). In order to find functions satisfying (1) and (2), it is tempting to define $h_i=G_i/G$. Then $h_1,\dots,h_n$ satisfy all the desired conditions except the continuity. To remedy this issue, we define $h_i=G_i/\wtd G$, where $\wtd G\in C_c(X,\Rbb)$ satisfies that $\wtd G>0$ on $X$ (so that $h_i$ is continuous), that $\wtd G\geq G$ (so that $0\leq \sum_ih_i\leq 1$), and that $\wtd G|_K=G|_K$ (so that $\sum_i h_i|_K=1$). Then $h_1,\dots,h_n$ are the desired functions.

Let us prove the existence of such $\wtd G$. Let $W=\{x\in X:G(x)>0\}$. Let $F\in C(X,[0,1])$ such that $F|_K=0$ and that $F|_{X\setminus W}=1$. The existence of such $1-F$ is ensured by Urysohn's lemma. Then one can let $\wtd G=G+F$. 
\begin{align*}
\vcenter{\hbox{{
			\includegraphics[height=1.5cm]{fig7.png}}}}
\end{align*}
\end{proof}





\subsubsection{How to use partition of unity}\label{lb490}


In Sec. \ref{lb293}, we have discussed how to use the condition of compactness: Suppose that $K$ is compact and $f$ is a function on $K$, for instance, a continuous one. To prove that $f$ satisfies a global finiteness condition, we first prove that each $x\in K$ is contained in a neighborhood $U_x$ on which $f$ satisfies this finiteness condition. Then we pick finitely many $U_{x_1},U_{x_2},\dots$ covering $K$, and show that $f$ satisfies the finiteness condition globally. 

To summarize, we can use compactness to prove many \uline{finiteness properties} by a local-to-global argument. As pointed out in Sec. \ref{lb293}, usually, these finiteness properties can also be proved by contradiction using net-compactness or sequential compactness.

Now assume that $K$ is a compact subset of the LCH space $X$, and let $f$ be a function on $K$. \uline{With the help of partition of unity, one can construct new objects from $f$ using a local-to-global argument}. Moreover, these constructions are usually very difficult to obtain by using net-compactness or sequential compactness. The following are two typical examples:
\begin{enumerate}
\item (\textbf{Integral problems}) Construction of an integral $\int_Kf$. This was already mentioned in Subsec. \ref{lb467}.
\item (\textbf{Extension problems}) Construct a ``good" function $\wtd f$ on $X$ extending (or ``approximately extending") $f$. The idea is simple: Suppose that the extension exists locally, i.e., suppose that for each $x\in K$ there exists $U_x\in\Nbh_X(x)$ such that $f|_{U_x\cap K}$ can be extended to a good function $g_x$ on $U_x$. By compactness, $K$ is covered by $\bigcup_{x\in E}U_x$ where $E$ is a finite subset of $K$. Let $(h_x)_{x\in E}$ be a partition of unity of $K$ subordinate to this open cover.  Then $\wtd f=\sum_{x\in E}h_x\cdot g_x$ gives a good extension.
\end{enumerate}

In the study of measure theory in the second semester, we will use partition of unity extensively. Readers who want to get a head start can do the problems in Subsec. \ref{lb494}, \ref{lb534}, and \ref{lb495} to see how to build a theory of multivariable Riemann integrals using partitions of unity. For the moment, let's look at a simple example of extension problem before we prove the Tietze extension theorem. This example is not used elsewhere in this chapter, but it serves as a good illustration of how to use partitions of unity.


\begin{eg}\label{lb478}
Let $I$ be an open interval in $\Rbb$, and let $K$ be a nonempty compact subset of $I$. Let $r\in\Zbb_+\cup\{\infty\}$. Assume that $f:K\rightarrow\Rbb$ is $C^r$, which means that for each $x\in K$ there exist an open interval $U_x\subset I$ containing $x$ and $g_x\in C^r(U_x,\Rbb)$ extending $f|_{U_x\cap K}$. Then there exists $\wtd f\in C^r(I,\Rbb)$ extending $f$ and is compactly supported in $I$. 
\end{eg}

This example is the \textbf{smooth Tietze extension theorem} in dimension $1$, as mentioned in Rem. \ref{lb479}.

\begin{proof}
Let $U_x$ and $g_x$ be as in the example. Since $K$ is compact, it can be covered by $U_{x_1},\dots,U_{x_n}$. Call this open cover $\fk U$. Similar to the proof of Thm. \ref{lb466}, one can find a set of $C^r$-partition of unities $h_1,\dots,h_n$ of $K$ subordinate to $\mc U$. In other words, $h_1,\dots,h_n$ are $C^r$ functions and form a partition of unity. (Similar to the proof of Thm. \ref{lb466}, in order to find such $h_1,\dots,h_n$, it suffices to prove the $C^r$-version of Urysohn's lemma. But this has been done in Prop. \ref{lb440}, noting that $K$ is contained in a compact subinterval of $I$.) Now each $h_ig_{x_i}$ is an $C^r$-function on $I$ compactly supported in $U_{x_i}$. Then $\wtd f=\sum_i h_ig_{x_i}$ is a desired extension.
\end{proof}



You will see many more examples in the future when you study differential manifolds and sheaf theory. It is no exaggeration to say that partition of unity is one of the most important techniques in modern mathematics.




\subsubsection{Proof of Tietze extension theorem}




Now you may wonder: Under the assumption of Tietze extension Thm. \ref{lb468}, we don't even know how to extend $f\in C(K,\mc V)$ locally. Then how can we use the local-to-global argument? Here is the answer: you can find an \textit{approximate} extension locally. Therefore, you can first find an approximate global extension of $f$. Then, passing to the limit, you get the desired extension. This will be our strategy of the proof of Thm. \ref{lb468}.




\begin{lm}\label{lb469}
Let $K$ be a compact subset of $X$, and let $f\in C(K,\mc V)$. Then for every $\eps$, there exists $\varphi\in \Span(C_c(X,\Rbb)\mc V)$ such that
\begin{align*}
\Vert f-\varphi\Vert_{l^\infty(K,\mc V)}\leq\eps\qquad \Vert \varphi\Vert_{l^\infty(X,\mc V)}\leq \Vert f\Vert_{l^\infty(K,\mc V)}
\end{align*}
\end{lm}

The meaning of $\Span(C_c(X,\Rbb)\mc V)$ is clear: the smallest linear subspace of $C_c(X,\mc V)$ containing $C_c(X,\Rbb)\mc V$. Thus \index{SpanCX@$\Span(C_c(X,\Rbb)\mc V)$}
\begin{align}
\Span(C_c(X,\Rbb)\mc V)=\{g_1v_1+\cdots+g_nv_n:n\in\Zbb_+,g_i\in C_c(X,\Rbb),v_i\in\mc V\}
\end{align}


\begin{proof}
Let $M=\Vert f\Vert_{l^\infty(K,\mc V)}$. For each $p\in K$, since $f$ is continuous at $p$, there exists $U_p\in\Nbh_X(p)$ such that $\diam(f(U_p\cap K))\leq\eps$ (cf. Prop. \ref{lb461}). Then the contant function $f(p)$ gives a local approximate extension of $f|_{U_p\cap K}$.

Since $K$ is compact, there exists a finite subset $E\subset K$ such that $K$ is covered by $\fk U=\{U_p:p\in E\}$. By Thm. \ref{lb466}, there is a partition of unity $(h_p)_{p\in E}$ of $K$ subordinate to $\fk U$. Since $h_p\in C_c(U_p,\Rbb)$ can be viewed as a compactly supported continuous function on $X$ (Rem. \ref{lb457}), the function $\varphi=\sum_{p\in E}h_pf(p)$ is an element of $C_c(X,\mc V)$. 

If $x\in K$, then since $h_p\geq0$, we have
\begin{align*}
\Vert f(x)-\varphi(x)\Vert=\Big\Vert \sum_{p\in E}h_p(x)\cdot \big(f(x)-f(p)\big)  \Big\Vert\leq\sum_{p\in E}h_p(x)\Vert f(x)-f(p)\Vert
\end{align*}
On the RHS, if $h_p(x)\neq 0$, then $x\in U_p$, and hence $\Vert f(x)-f(p)\Vert\leq\eps$. So the RHS is no greater than $\sum_{p\in E}h_p(x)\eps$, and hence no greater than $\eps$ since $\sum_{p\in E}h_p(x)=1$. Finally, for every $x\in X$, we have
\begin{align*}
\Vert \varphi(x)\Vert\leq\sum_{p\in E}h_p(x)\Vert f(p)\Vert\leq \sum_{p\in E}h_p(x)M=M
\end{align*}
finishing the proof.
\end{proof}




The following special case of Lem. \ref{lb469} is more useful for application.

\begin{pp}\label{lb470}
Assume that $X$ is a compact Hausdorff space, and let $f\in C(X,\mc V)$. Then for every $\eps>0$, there exists $\varphi\in\Span(C_c(X,\Fbb)\mc V)$ such that $\Vert f-\varphi\Vert_\infty<\eps$.
\end{pp}



\begin{co}\label{lb471}
Let $X,Y$ be compact Hausdorff spaces. Then for every $f\in C(X\times Y,\Fbb)$ and $\eps>0$, there exist $g_1,\dots,g_n\in C(X,\Fbb)$ and $h_1,\dots,h_n\in C(Y,\Fbb)$ such that $\Vert f-g_1h_1-\cdots-g_nh_n\Vert_{l^\infty(X\times Y,\Fbb)}<\eps$.
\end{co}


\begin{proof}
By Thm. \ref{lb274}, we view $f$ as an element of $C(X,\mc V)$ where $\mc V=C(Y,\Rbb)$. Then the corollary follows immediately from Prop. \ref{lb470}. From this proof, we see that it is not necessarily to assume that $Y$ is Hausdorff. (This is not an important fact anyway.)
\end{proof}



Now we are ready to finish the

\begin{proof}[\textbf{Proof of Tietze extension Thm. \ref{lb468}}]
Recall that $K$ is compact in $X$ and $f\in C(K,\mc V)$, and that our goal is to extend $f$ to $\wtd f\in C_c(X,\mc V)$. Moreover, we need that $\Vert\wtd f\Vert_{l^\infty(X,\mc V)}$ equals $M=\Vert f\Vert_{l^\infty(K,\mc V)}$. We first note that the last requirement is easy to meet. Assume WLOG that $M>0$. Let $\wtd f\in C_c(X,\mc V)$ extend $f$, and define $g:X\rightarrow\Rbb_{\geq0}$ by $g(x)=\max\{M,\Vert\wtd f(x)\Vert\}$. Then $g$ is continuous, $g\geq M$, and $g|_K=M$. Then $M\wtd f/g$ is an element of $C_c(X,\mc V)$ extending $f$ and is $l^\infty$-bounded by $M$, finishing the proof.

Second, note that it suffices to extend $f$ to $\wtd f\in C(X,\mc V)$. By Urysohn lemma, there exists $h\in C_c(X,[0,1])$ such that $h|_K=1$. Then $\wtd fh\in C_c(X,\mc V)$ extends $f$.

We now construct $\wtd f\in C(X,\mc V)$ extending $f$. By Lem. \ref{lb469}, there exist $\varphi_1,\varphi_2,\dots\in C_c(X,\mc V)$ such that
\begin{gather*}
\Vert f-\varphi_1\Vert_{l^\infty(K,\mc V)}\leq \frac M2\qquad \Vert \varphi_1\Vert_{l^\infty(X,\mc V)}\leq M\\
\Vert f-\varphi_1-\varphi_2\Vert_{l^\infty(K,\mc V)}\leq \frac M4\qquad \Vert \varphi_2\Vert_{l^\infty(X,\mc V)}\leq \frac M2\\
\Vert f-\varphi_1-\varphi_2-\varphi_3\Vert_{l^\infty(K,\mc V)}\leq \frac M8\qquad \Vert \varphi_3\Vert_{l^\infty(X,\mc V)}\leq \frac M4\\
\vdots
\end{gather*}
Then $\sum_{n=1}^\infty\Vert \varphi_n\Vert_{l^\infty(X,\mc V)}\leq 2M$, and hence $\sum_{n=1}^\infty\varphi_n$ converges to some $\wtd f$ in the Banach space $C(X,\mc V)\cap l^\infty(X,\mc V)$ (Cor. \ref{lb101}). Clearly $\wtd f$ extends $f$.
\end{proof}



\subsection{Proof of SW, II: embedding into $[0,1]^{\scr I}$}\label{lb473}

In this section, we shall finish the proof of SW Thm. \ref{lb442}.


\begin{rem}\label{lb472}
Suppose that $\Phi:X\rightarrow Y$ is a homeomorphism of topological spaces. Then $X$ and $Y$ can be ``viewed as the same space" via $\Phi$. This means that a point $x\in X$ can be identified with $\Phi(x)\in Y$, that an open or closed subset $A\subset X$ can be identified with $\Phi(A)$, which is open or closed in $Y$. It also means, for example, that if $A\subset X$, then the closure of $A$ can be identified with the closure of $\Phi(A)$ in $Y$. More precisely: $\Phi$ restricts to a homeomorphism $\Cl_X(A)\rightarrow\Cl_Y(\Phi(A))$.

The continuous functions of $X$ and $Y$ can also be identified: If $g\in C(Y,Z)$ where $Z$ is a topological space (e.g. $Z=\Rbb$), then $g$ is equivalent to its \textbf{pullback under $\Phi$}, \index{00@Pullback of functions} which is an element of $C(X,Z)$ given by
\begin{align}
\Phi^*g:=g\circ\Phi\qquad\in C(X,Z)
\end{align}
This equivalence of functions can be illustrated by the commutative diagram
\begin{equation}
\begin{tikzcd}[column sep=tiny]
X \arrow[rr, "\Phi","\simeq"'] \arrow[rd, "\Phi^*g"'] &   & Y \arrow[ld, "g"] \\
                                            & Z &                  
\end{tikzcd}
\end{equation}
\hfill\qedsymbol
\end{rem}



\begin{proof}[\textbf{Proof of SW Thm. \ref{lb442}}]
Recall that $X$ is a compact Hausdorff space and $\scr A$ is a unital subalgebra of $C(X,\Rbb)$ separating points of $X$. For each $f\in\scr A$, let $M_f=\Vert f\Vert_\infty$ and $I_f=[-M_f,M_f]$. Define
\begin{gather*}
\Phi:X\rightarrow S=\prod_{f\in\scr A}I_f\qquad x\mapsto (f(x))_{f\in\scr A}
\end{gather*}
In other words, $\Phi=\bigvee_{f\in\scr A}f$, using the notation in Pb. \ref{lb258}. Thus, by Pb. \ref{lb258} (or by Thm. \ref{lb192}), $\Phi$ is continuous. The fact that $\scr A$ separates points of $X$ is equivalent to that $\Phi$ is injective. Since $X$ is compact, by Thm. \ref{lb236}, $\Phi$ restricts to a homeomorphism $\Phi:S\rightarrow\Phi(S)$. 

Recall that the coordinate function $\pi_f:S\rightarrow I_f$ is the projection onto the $f$-component. So $\Phi^*\pi_f=\pi_f\circ\Phi=f$. Therefore, by Rem. \ref{lb472}, $X$ is equivalent to $\Phi(X)$ under $\Phi$, and $\pi_f|_{\Phi(X)}\in C(\Phi(X),\Rbb)$ is equivalent to $f\in C(X,\Rbb)$ under $\Phi$. Therefore, we can identify $X$ with $\Phi(X)$ via $\Phi$ so that $f$ is identified with $\pi_f|_{\Phi(X)}$. Thus, in this case, $\scr A$ is the set of all $\pi_f|_X$, and clearly $\scr A$ contains all the polynomials of the coordinate functions $\{\pi_f|_X:f\in\scr A\}$ since $\scr A$ is a unital subalgebra. Thus, it suffices to prove that the polynomials of coordinate functions are dense in $C(X,\Rbb)$. 

Choose any $g\in C(X,\Rbb)$. Since $X$ is compact, and since $S$ is a compact Hausdorff space (by Tychonoff Thm. \ref{lb452}), by Tietze extension Thm. \ref{lb468}, $g$ can be extended to $\wtd g\in C(S,\Rbb)$. By Prop. \ref{lb451}, $\wtd g$ can be approximated uniformly by the polynomials of coordinate functions of $S$.
\end{proof}



\begin{rem}
If you feel that identifying $X$ and $\Phi(X)$ is cheating, it is easy to revise the proof without identifying them: Choose any $g\in C(X,\Rbb)$. One first concludes that $g\circ\Phi^{-1}\in C(\Phi(X),\Rbb)$ can be uniformly approximated by the polynomials of coordinate functions. Then, since the pullback of these polynomials under $\Phi$ are elements of $\scr A$, one concludes that $g$ can be approximated uniformly by elements of $\scr A$.
\end{rem}





\subsection{Summary of the proof of SW}





The key steps of the proof of SW Thm. \ref{lb442} are as follows.

\begin{enumerate}
\item We first prove the case that $X$ is a compact interval $I$ and $\scr A$ is the polynomial algebra: Let $f\in C(I,\Rbb)$, and extend $f$ to an element in $C_c(\Rbb,\Rbb)$. Let $g(x)=\pi^{-\frac 12}e^{-x^2}$ and $g_\eps(x)=\eps^{-1}g(x/\eps)$. On the one hand, $\lim_{\eps\rightarrow 0}f*g_\eps$ converges uniformly to $f$. On the other hand, for each $\eps$, since $g_\eps$ is approximated by polynomials uniformly on compact intervals (consider the Taylor series of $g_\eps$), one shows that $f*g_\eps$ is also approximated by polynomials uniformly on compact intervals.  
\item When $\mc V$ is a Banach space, the same method shows that $\mc V[x]$, the set of polynomials with coefficients in $\mc V$, is $l^\infty$-dense in $C(I,\mc V)$.  
\item Taking $\mc V=C(J,\Rbb)$ where $J$ is a compact interval, the above step shows that polynomials are dense in $C(I\times J,\Rbb)$.\footnote{Instead of using step 2, one can also use step 1 and the fact that elements in $C(I\times J,\Rbb)$ can be approximated by those of the form $f_1g_1+\cdots+f_ng_n$ where $f_i\in C(I,\Rbb)$ and $g_i\in C(J,\Rbb)$, cf. Cor. \ref{lb471}.} Similarly, by induction, one sees that polynomials are dense in $C(I_1\times\cdots\times I_n,\Rbb)$ if each $I_j$ is a compact interval.
\item Let $S=\prod_{\alpha\in\scr I}I_\alpha$ where each $I_\alpha$ is a compact interval. Then $S$ is a compact Hausdorff space by the Tychonoff theorem. One shows that any $f\in C(S,\Rbb)$ can be approximated by a function $g$ depending on finitely many variables (Lem. \ref{lb455}, or Pb. \ref{lb453} when $\scr I$ is countable). By the previous step, $g$ can be approximated by polynomials. So $f$ can be approximated by polynomials (of coordinate functions of $S$).
\item Let $X$ be a compact subset of $S=\prod_{\alpha\in\scr I}I_\alpha$, and let $f\in C(X,\Rbb)$. Then by the Tietze extension theorem, $f$ can be extended to $\wtd f\in C(S,\Rbb)$ where $\wtd f$ can be approximated by polynomials by the previous step. So $f$ can be approximated by polynomials.
\item Now let $X$ be a compact Hausdorff space, and let $\scr A$ be a unital subalgebra of $C(X,\Rbb)$ separating points of $X$. Then the map $\Phi=\bigvee_{f\in\scr A}f$ maps $X$ homeomorphically to a compact subspace of $S=\prod_{\alpha\in\scr A}I_f$ where $I_f=[-\Vert f\Vert_\infty,\Vert f\Vert_\infty]$. By the previous step, continuous functions on $\Phi(X)$ can be approximated by polynomials of the coordinate functions of $S$. This is equivalent to the density of $\scr A$ in $C(X,\Rbb)$. The proof is complete.
\end{enumerate}


The proof we have given, which is different from the proofs in most textbooks, has several advantages. First, it clearly shows that \uline{``$\scr A$ separates points of $X$" is an embedding condition, which ensures that the map $\Phi=\bigvee_{f\in\scr A}f$ is injective}. The embedding of spaces is a common theme in many branches of mathematics. In differential geometry, one can show that every (second countable) smooth manifold can be smoothly embedded into a Euclidean space. (This is the \textbf{Whitney embedding theorem}.) \textbf{Projective manifolds}, the
compact complex manifolds that can be holomorphically embedded into complex projective spaces $\Cbb\Pbb^n$, are among the most important examples in complex (algebraic) geometry.

Second, Urysohn's lemma and partition of unity are extremely important tools in differential manifolds and in measure theory, both of which will be studied next semester.  

Thus, although our proof is longer than those in the other textbooks,\footnote{The proofs in most textbooks (e.g. \cite[Sec. 4.7]{Fol-R}, \cite[Ch. 7]{Rud-P}, \cite[Sec. 16.4]{Zor-2}) are similar and are due to M. Stone \cite{Sto48}, which used the idea of lattices. A lattice is a set $L$ together with operations $\wedge,\vee$ satisfying $a \vee(a \wedge b)=a$ and $a \wedge(a \vee b)=a$. In analysis, one considers $L\subset C(X,\Rbb)$ where $f\vee g=\max\{f,g\}$ and $f\wedge g=\min\{f,g\}$. In Stone's day, lattices were relatively popular in functional analysis. But today it seems that they are a bit cold. The shorter proof in \cite{Sto48} is actually not the original proof of SW theorem. The original proof was given in \cite{Sto37} and is much more complicated.} the methods we used in the proof (convolutions, embedding of spaces, partition of unity, etc.) will appear frequently in the future study. Through our proof, the SW theorem is closely and organically related to other mathematical concepts.  



We close this section with an immediate consequence of the proof of SW theorem, which is parallel to Thm. \ref{lb261}.

\begin{thm}
Let $X$ be a topological space. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $X$ is a compact Hausdorff space.
\item $X$ is homeomorphic to a closed subset of $[0,1]^{\scr I}$ for some set $\scr I$.
\end{enumerate}
\end{thm}


\begin{proof}
Clearly $[0,1]^{\scr I}$ is Hausdorff. By Tychonoff Thm. \ref{lb452}, $[0,1]^{\scr I}$ is compact. So its closed subsets are compact Hausdorff. Conversely, let $X$ be compact Hausdorff. By Cor. \ref{lb474}, $C(X,\Rbb)$ separates points of $X$. Thus there is a subset $\scr I\subset C(X,\Rbb)$ separating points of $X$ such that $f(X)\subset[-1,1]$ for all $f\in\scr I$. Therefore $\Phi=\bigvee_{f\in\scr I}f:X\rightarrow[-1,1]^{\scr I}$ is a continuous injective map of $X$ into $[-1,1]^{\scr I}$. So it reduces to a homeomorphism $X\rightarrow\Phi(X)$ by Thm. \ref{lb236}.
\end{proof}









\subsection{Application: separability of $C(X,\Rbb)$}\label{lb513}


Our proof of SW theorem relies on Tychonoff Thm. \ref{lb452}, which in turn relies on Zorn's lemma, an uncountable version of mathematical induction. Though Zorn's lemma is equivalent to the axiom of choice, it is much more difficult to grasp intuitively than mathematical induction. Thus, one would like to find a proof without using Zorn's lemma if possible. 

In the following, we will show that when the compact Hausdorff space $X$ is second countable (equivalenty, metrizable), in the proof of SW theorem, it suffices to embed $X$ into a countable product of compact intervals. The latter is compact by countable Tychonoff theorem, whose proof does not rely on Zorn's lemma (cf. Thm. \ref{lb89} or Pb. \ref{lb241}). 

We first discuss a general fact about countability in compact Hausdorff spaces. The following theorem is one of the most important general properties about separability: It tells us that for a compact Hausdorff space $X$, the countability property of the topology of $X$ is equivalent to that of the uniform convergence topology of $C(X,\Rbb)$. %(Metrizability is also a countability property, since it implies that one can use sequences to study convergence.) 
This is in stark contrast to compactness, where the compactness of $X$ does not in general imply the compactness of bounded closed subsets of  $C(X,\Rbb)$  (cf. Exp. \ref{lb518}).



\begin{thm}\label{lb482}
Let $X$ be a compact Hausdorff space. The following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $X$ is metrizable.
\item $X$ is second countable.
\item $C(X,\Rbb)$ is separable (equivalently, second countable, cf. Prop. \ref{lb250}).
\end{enumerate}
\end{thm}

Here, as usual, $C(X,\Rbb)$ is equipped with the $l^\infty$-norm. See Pb. \ref{lb484} for a generalization of Thm. \ref{lb482} to LCH spaces. Also, assuming (3), one can write down a metric and a countable basis explicitly; see Pb. \ref{lb533} for details.

\begin{proof}
By Thm. \ref{lb261}, we have (1)$\Leftrightarrow$(1') where
\begin{itemize}
\item[(1')] $X$ is homeomorphic to a closed subset of $[0,1]^{\Zbb_+}$. 
\end{itemize}
Let us prove that (2) and (3) are equivalent to (1').

(1')$\Rightarrow$(3): By Tietze extension theorem, it suffices to prove that $C(S,\Rbb)$ is separable where $S=[0,1]^{\Zbb_+}$. Let $\mc E=\Qbb[\{\pi_n:n\in\Zbb_+\}]$ be the set of polynomials of the coordinate functions of $S$ with coefficients in $\Qbb$. ($\pi_n:S\rightarrow[0,1]$ is the projection onto the $n$-th component.) Then $\mc E$ is countable (cf. Exe. \ref{lb476}), and is clearly dense in $\Rbb[\{\pi_n:n\in\Zbb_+\}]$. By Prop. \ref{lb451}, $\mc E$ is dense in $C(S,\Rbb)$.



(3)$\Rightarrow$(1'): Let $\mc E=\{f_1,f_2,\dots\}$ be a countable dense subset of $C(X,\Rbb)$. By enlarging $\mc E$, we assume WLOG that $\mc E$ is infinite. By Cor. \ref{lb474}, $C(X,\Rbb)$ separates points of $X$. So $\mc E$ also separates points of $X$. We scale $f_n\in\mc E$ by a nonzero real number such that $\Vert f_n\Vert_\infty\leq 1$. Then 
\begin{gather}
\Phi:X\rightarrow [-1,1]^{\Zbb_+} \qquad x\mapsto (f_1(x),f_2(x),\dots)  \label{eq199}
\end{gather}
is a continuous injective map, restricting to a homeomorphism $X\rightarrow\Phi(X)$ where $\Phi(X)$ is a compact (and hence closed) subset of $[-1,1]^{\Zbb_+}\simeq[0,1]^{\Zbb_+}$.

(1')$\Rightarrow$(2): Since $[0,1]$ is separable and hence second countable, by Pb. \ref{lb305}, $[0,1]^{\Zbb_+}$ is second countable. So its subsets are second countable by Prop. \ref{lb475}. Alternatively, one can also use Thm. \ref{lb252} to prove directly (1)$\Rightarrow$(2).

(2)$\Rightarrow$(1'): Let $(U_n)_{n\in\Zbb_+}$ be an infinite countable basis of the topology of $X$. For each $m,n\in\Zbb_+$, if $\ovl U_n\subset U_m$, we choose $f_{m,n}\in C_c(U_m,[0,1])\subset C_c(X,[0,1])$ such that $f|_{\ovl U_n}=1$ (which exists by Urysohn lemma); otherwise, we let $f_{m,n}=0$. Then $\{f_{m,n}:m,n\in\Zbb_+\}$ separates points of $X$. (Proof: Choose distinct $x,y\in X$. Since $X\setminus\{y\}\in\Nbh_X(x)$, there exists $U_m$ containing $x$ and is contained in $X\setminus\{y\}$. By Lem. \ref{lb460}, there is $n$ such that $\{x\}\subset U_n\Subset U_m$. Then $f_{m,n}(x)=1$ and $f_{m,n}(y)=0$.) Thus, as in \eqref{eq199}, the map
\begin{align*}
X\rightarrow[0,1]^{\Zbb_+\times\Zbb_+}\qquad x\mapsto (f_{m,n}(x))_{m,n\in\Zbb_+}
\end{align*}
restricts to a homeomorphism from $X$ to a compact subset of $[0,1]^{\Zbb_+\times\Zbb_+}$.
\end{proof}





\begin{exe}\label{lb476}
Let $\scr A$ be a unital $\Rbb$-algebra (resp. unital $\Cbb$-algebra). Let $\Kbb$ be $\Qbb$ (resp. $\Qbb+\im\Qbb$). Let $x_1,x_2,\dots$ be a possibly finite sequence of elements of $\scr A$. Let $\mc E=\Kbb[x_1,x_2,\dots]$ be the set of polynomials of $x_1,x_2,\dots$ with coefficients in $\Kbb$. Prove that $\mc E$ is a countable set.
\end{exe}




\begin{rem}
Note that Prop. \ref{lb451} is used (and is only used) in the proof of (1')$\Rightarrow$(3) of Thm. \ref{lb482}. Our proof of Thm. \ref{lb482} relies on Tychonoff theorem, which in turn relies on Zorn's lemma. However, in the proof of (1')$\Rightarrow$(3) we only consider countable products of integrals. In this special case, the proof of Tychonoff theorem uses mathematical induction but not Zorn's lemma. (See the proof of Thm. \ref{lb89} or Pb. \ref{lb241}.) Therefore, our proof of Thm. \ref{lb482} does not rely on Zorn's lemma.
\end{rem}

\begin{rem}
Since the proof of Prop. \ref{lb451} uses Weierstrass approximation Thm. \ref{lb441}, the proof of ``$\Rightarrow$(3)" in Thm. \ref{lb482} also relies on Thm. \ref{lb441}. This is as expected. In fact, even if one wants to prove that $C([0,1],\Rbb)$ is separable, one needs Thm. \ref{lb441}. (See Cor. \ref{lb486}.) Therefore, it is fair to say that the separability of $C(X,\Rbb)$ is one of the most important applications of Weierstrass approximation (or SW) theorem.
\end{rem}


\begin{claim}
If $X$ is a compact Hausdorff space satisfying one of the equivalent conditions in Thm. \ref{lb482}, then the SW Thm. \ref{lb442} can be proved without using Zorn's lemma.
\end{claim}


\begin{proof}
Let $\scr A$ be a unital subalgebra of $C(X,\Rbb)$ separating points of $X$. Since $C(X,\Rbb)$ is separable (equivalently, second countable), so is $\scr A$ (by Prop. \ref{lb475}). Therefore, $\scr A$ has a countable dense subset $\mc E=\{f_1,f_2,\dots\}$ which clearly separates points of $X$. By enlarging $\mc E$ we assume that it is infinite. So \eqref{eq199} restricts to a homeomorphism from $X$ to a closed subset of $S=[0,1]^{\Zbb_+}$. As in the proof of (1')$\Rightarrow$(3) of Thm. \ref{lb482}, the polynomials of the coordinate functions of $S$, when restricted to $\Phi(X)$, form a dense subset of $C(\Phi(X),\Rbb)$. Pulling back this result to $X$, we conclude that polynomials of $f_1,f_2,\dots$ (which are in $\scr A$) form a dense subset of $C(X,\Rbb)$.
\end{proof}

%% Record #24 2023/12/13 three lectures  60

\subsection{Problems and supplementary material}


We always let $\mc V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$.

\subsubsection{SW theorems for LCH spaces}

\begin{prob}\label{lb431}
Let $X$ be an LCH space with topology $\mc T$. Define a set $X^*=X\cup\{\infty\}$ where $\infty$ is a new symbol not in $X$. 
\begin{enumerate}
\item Prove that the set
\begin{align*}
\fk U=\mc T\cup\{X^*\setminus K:K\subset X\text{ is compact}\}
\end{align*}
is a basis for a topology on $X^*$. Let $\mc T^*$ be the topology on $X^*$ generated by $\fk U$. Prove that $\mc T$ is the subspace topology of $\mc T^*$. (Namely, prove that $U\subset X$ is open iff $U=X\cap V$ for some open $V\subset X^*$.)
\item Prove that $(X^*,\mc T^*)$ is a compact Hausdorff space. We call $(X^*,\mc T^*)$ (or simply call $X^*$) the \textbf{one-point compactification} \index{00@One-point compactification} of $X$.
\item Prove that if $X$ is not compact, then $X$ is dense in $X^*$.
\end{enumerate}
\end{prob}


More generally, we define:
\begin{df}
Let $X$ be LCH. A \textbf{one-point compactification (OPC)} of  $X$ is a compact Hausdorff space $\wht X$, together with an injective map $\varphi:X\rightarrow \wht X$ such that $\wht X\setminus \varphi(X)$ has exactly one element,  and that $\varphi$ restricts to a homeomorphism $\varphi:X\rightarrow\varphi(X)$. In particular, the $X^*$ constructed in Pb. \ref{lb431} is a one-point compactification of $X$.
\end{df}



\begin{prob}
Prove the uniqueness of one-point compactifications in the following sense. Let $X$ be LCH with one-point compactifications $(\wht X,\varphi)$ and $(\wtd X,\psi)$. Then there is a unique homeomorphism $\Phi:\wht X\rightarrow\wtd X$ such that the following diagram commutes:
\begin{equation}
\begin{tikzcd}[column sep=small]
                     & X \arrow[ld,"\varphi"'] \arrow[rd,"\psi"] &   \\
\wht X \arrow[rr, "\Phi","\simeq"'] &                         & \wtd X
\end{tikzcd}
\end{equation}
\end{prob}

\begin{eg}\label{lb433}
If $X$ is compact Hausdorff and contains at least two points, then for every $p\in X$, the subset $X\setminus\{p\}$ has OPC $X$ (together with the inclusion map). Thus $[0,1]$ has OPC $[0,1]\cup\{2\}$. $(0,1]$ has OPC $[0,1]$. $(0,1)$ has OPC $\Sbb^1$ (the unit circle in $\Cbb$) together with the map $\varphi:x\in(0,1)\mapsto e^{2\im\pi x}\in \Sbb^1$.
\end{eg}



\begin{cv}
Let $X$ be LCH and $f:X\rightarrow \mc V$. According to part 3 of Pb. \ref{lb431}, when $X$ is not compact, the limit of functions $\lim_{x\rightarrow\infty}f$ makes sense. In the case that $X$ is compact, we understand  $\lim_{x\rightarrow\infty}f$ as $0$.
\end{cv}




\begin{df}
Let $X$ be LCH with one-point compactification $X^*$. Define \index{C0@$C_0(X,\mc V)$}
\begin{align}
C_0(X,\mc V)=\big\{f\in C(X,\mc V):\lim_{x\rightarrow\infty}f(x)=0  \big\}
\end{align}
Since $\{X^*\setminus K:K\subset X\text{ is compact}\}$ is a neighborhood basis of $\infty\in X^*$ (recall Def. \ref{lb262}), by Def. \ref{lb197}-(2), it is clear that $f\in C(X,\mc V)$ belongs to $C_0(X,\mc V)$ iff
\begin{align*}
\tcboxmath{
\begin{array}{c}
\text{for every $\eps>0$ there exists a compact $K\subset X$ such that}\\
\text{for each $x\in X\setminus K$ we have $\Vert f(x)\Vert<\eps$}
\end{array}}
\end{align*}
For each $f:X\rightarrow \mc V$ define $\wtd f:X^*\rightarrow \mc V$ where
\begin{align}\label{eq184}
\wtd f(x)=\left\{
\begin{array}{ll}
f(x)& \text{ if }x\in X\\[1ex]
0& \text{ if }x=\infty
\end{array}
\right.
\end{align}
Then by Def. \ref{lb197}-(1),  $\wtd f$ is continuous at $\infty$ iff $\lim_{x\rightarrow\infty}f(x)=0$. Thus, we have
\begin{align}
C_0(X,\mc V)=\big\{\wtd f|_X:\wtd f\in C(X^*,\mc V)\text{ and }\wtd f(\infty)=0 \}
\end{align}
\end{df}

\begin{pp}\label{lb432}
Let $X$ be LCH with one-point compactification $X^*$. Then we have an linear isometry of Banach spaces (under the $l^\infty$-norms)
\begin{align}\label{eq185}
C_0(X,\mc V)\rightarrow C(X^*,\mc V)\qquad f\mapsto \wtd f=\eqref{eq184}
\end{align}
\end{pp}

\begin{proof}
Clearly $\Vert f\Vert_{l^\infty(X,\mc V)}=\Vert \wtd f\Vert_{l^\infty(X^*,\mc V)}$. So \eqref{eq185} is a linear isometry. The range of \eqref{eq185} is $\{g\in C(X^*,\mc V):g(\infty)=0\}$, which is clearly a closed subset of the Banach space $C(X,\mc V)$ and hence is complete by Prop. \ref{lb86}.
\end{proof}


\begin{cv}\label{lb449}
According to Prop. \ref{lb432}, people often identify $C_0(X,\mc V)$ with its image under \eqref{eq185}, i.e., identify $f\in C_0(X,\mc V)$ with $\wtd f$ defined by \eqref{eq184}.
\end{cv}








\begin{prob}\label{lb544}
Let $Y$ be a compact Hausdorff space. Let $E$ be a closed subspace of $Y$. Prove that 
\begin{align*}
C_0(Y\setminus E,\mc V)=\{g|_{Y\setminus E}:g\in C(Y,\mc V),g|_E=0\}
\end{align*}
\end{prob}



\begin{thm}[\textbf{SW theorem, LCH real version}]\index{00@SW theorem, LCH real version}\label{lb545}
Let $X$ be an LCH space. Let $\scr A$ be a subalgebra of $C_0(X,\Rbb)$. Assume that $\scr A$ separates points of $X$. Assume that $\scr A$ \textbf{vanishes nowhere on $X$} \index{00@Vanish nowhere} (i.e. for every $x\in X$ there is $f\in\scr A$ such that $f(x)\neq0$). Then $\scr A$ is dense in $C_0(X,\Rbb)$ (under the $l^\infty$-norm).
\end{thm}

\begin{prob}
Prove the above SW theorem by following the steps below. Let $X^*=X\cup\{\infty\}$ be the one-point compactification of $X$. By Conv. \ref{lb449}, $\scr A$ is naturally a subalgebra of $C(X^*,\Rbb)$. Define
\begin{align*}
\scr B=\{f+\lambda:f\in\scr A,\lambda\in\Rbb\}
\end{align*}
which is a unital subalgebra of $C(X^*,\Rbb)$. Use SW Thm. \ref{lb442} to prove that $\scr B$ is dense in $C(X^*,\Rbb)$. Use this fact to prove that $\scr A$ is dense in $C_0(X,\Rbb)$.
\end{prob}



\begin{thm}[\textbf{SW theorem, LCH complex version}]\index{00@SW theorem, LCH complex version}\label{lb828}
Let $X$ be an LCH space. Let $\scr A$ be a *-subalgebra of $C_0(X,\Cbb)$. Assume that $\scr A$ separates points of $X$. Assume that $\scr A$ vanishes nowhere on $X$. Then $\scr A$ is dense in $C_0(X,\Cbb)$ (under the $l^\infty$-norm).
\end{thm}


\begin{proof}
This follows from the LCH real version, just as the compact complex version of SW theorem (Thm. \ref{lb450}) follows from the compact real version (Thm. \ref{lb442}).
\end{proof}





\begin{prob}\label{lb485}
Let $X$ be LCH. Prove that $C_c(X,\mc V)$ is dense in $C_0(X,\mc V)$. (This proves that $C_0(X,\mc V)$ is the Banach space completion of $C_c(X,\mc V)$.) Conclude that $C_0(X,\mc V)$ is separable iff $C_c(X,\mc V)$ is separable.
\end{prob}

\begin{proof}[Hint]
Use Urysohn's lemma or Tietze extension.
\end{proof}


\begin{df}
Let $\scr A$ be an $\Fbb$-algebra. A subset $J\subset \scr A$ is called an \textbf{ideal} if $J$ is an $\Fbb$-linear subspace of $\scr A$ such that $\scr A J\subset J$ (i.e. $xy\in J$ for all $x\in\scr A,y\in J$). 
\end{df}

The following problem gives an interesting application of SW Thm. \ref{lb545}.

\begin{sprob}
(\textbf{Nullstellensatz}) \index{00@Nullstellensatz for $C(X,\Rbb)$}  Let $X$ be a compact Hausdorff space. For each closed subset $A\subset X$, let
\begin{align*}
I(A)=\{f\in C(X,\Rbb):f|_A=0\}
\end{align*} 
Clearly $I(A)$ is a closed ideal of $C(X,\Rbb)$. For each closed ideal $J$ of $C(X,\Rbb)$, let
\begin{align*}
N(J)=\{x\in X:f(x)=0\text{ for all }f\in J\}
\end{align*}
which is a closed subset of $X$. Prove that $A\mapsto I(A)$ gives a bijection between the  closed subsets of $A$ and the closed ideals of $C(X,\Rbb)$, and that its inverse map is $J\mapsto N(J)$. In other words, for every closed subset $A\subset X$ and every closed ideal $J\subset C(X,\Rbb)$, prove that
\begin{gather}
N(I(A))=A\qquad I(N(J))=J \label{eq210}
\end{gather}
\end{sprob}
\begin{proof}[Hint]
For both parts of \eqref{eq210} it is easy to prove ``$\supset$". To prove $N(I(A))= A$, use Urysohn's lemma or the Tietze extension theorem. To prove $I(N(J))=J$, identify $I(N(J))$ with $C_0(X\setminus N(J),\Rbb)$ (cf. Pb. \ref{lb544}) and apply SW Thm. \ref{lb545} to the LCH space $X\setminus N(J)$.
\end{proof}




\subsubsection{Lebesgue measures of open sets}\label{lb494}


The theory of Riemann integrals on $\Rbb$ can be easily generalized to $\Rbb^N$ by partitioning boxes, i.e. $I_1\times\cdots\times I_N$ where each $I_j$ is a compact interval in $\Rbb$. In the following, we establish the basic theory of Riemann integrals on bounded subsets of $\Rbb^N$ using partitions of unity. Compared to partitioning boxes, the methods provided below are closer to those in measure theory.

\begin{df}
If $f\in C_c(\Rbb^N,\Rbb)$, define $\dps\int f\equiv\int_{\Rbb^N} f=\int_Bf$ where $B\subset\Rbb^N$ is any box containing $\Supp(f)$. (See Def. \ref{lb487}.)
\end{df}


\begin{prob}\label{lb713}
Let $U$ be an open subset of $\Rbb^N$. Define the \textbf{(Lebesgue) measure} of $U$ to be
\begin{align}
\mu(U)=\sup\Big\{\int_{\Rbb^N}f:f\in C_c(U,[0,1]) \Big\}
\end{align}
which is an element of $\ovl\Rbb_{\geq0}$. It is clear that if $V$ is an open subset of $U$ then $\mu(V)\leq\mu(U)$.
\begin{enumerate}
\item In the case that $N=1$ and $U=(a,b)$ (where $-\infty\leq a<b\leq+\infty$), prove that $\mu(U)=b-a$.
\item Suppose that $U$ has compact closure. Prove that $\mu(U)<+\infty$. (Hint: use Urysohn's lemma.)
\item Let $(U_\alpha)_{\alpha\in\scr A}$ be an increasing net of open subsets of $\Rbb^N$. Prove
\begin{align*}
\mu\Big(\bigcup_{\alpha\in\scr A}U_\alpha \Big)=\sup_{\alpha\in\scr A}\mu(U_\alpha)
\end{align*}
\item Let $(V_j)_{j\in\scr I}$ be a (non-necessarily increasing) family of open subsets of $\Rbb^N$. Prove that
\begin{align*}
\mu\Big(\bigcup_{j\in\scr I}V_j  \Big)\leq\sum_{j\in\scr I}\mu(V_j)
\end{align*}
(Hint: Use part 3 to reduce to the special case $\mu(U\cup V)\leq\mu(U)+\mu(V)$. Prove it using partitions of unity.)
\item Let $(V_j)_{j\in\scr I}$ be a family of \textit{mutually disjoint} open subsets of $\Rbb^N$. Prove
\begin{align*}
\mu\Big(\bigcup_{j\in\scr I}V_j  \Big)=\sum_{j\in\scr I}\mu(V_j)
\end{align*}
\end{enumerate}
\end{prob}


\begin{df}
A subset $E\subset\Rbb^N$ is called a \textbf{(Lebesgue) null set} \index{00@Null set, Lebesgue} if for every $\eps$ there exists an open $U\subset\Rbb^N$ containing $E$ such that $\mu(E)<\eps$.
\end{df}

\begin{exe}
Show that a countable union of null sets is null.
\end{exe}

\begin{exe}
(This exercise is not need below.) Show that when $N=1$, the above definition of null sets agrees with Def. \ref{lb409}. More generally, for arbitrary $N$, show that $E\subset\Rbb^N$ is null iff for every $\eps>0$, $E$ can be covered by boxes whose total volumes are $<\eps$.
\end{exe}


\subsubsection{$\star$ Multiple Riemann integral}\label{lb534}

\begin{prob}\label{lb488}
Let $f\in C_c(\Rbb^N,\Rbb_{\geq0})$.
\begin{enumerate}
\item Let $M\geq0$. Assume that there is an open $U\subset\Rbb^N$ such that $f|_U\leq M$ and that $\Supp(f)\subset U$. Prove
\begin{align*}
\int_{\Rbb^N}f\leq\mu(U)\cdot M
\end{align*}
\item Let $\eps\geq0$. Assume that there is an open $U\subset\Rbb^N$ such that $f|_U\geq\eps$. Prove
\begin{align*}
\int_{\Rbb^N}f\geq\mu(U)\cdot \eps
\end{align*}
\end{enumerate}
\end{prob}


\begin{rem}
Pb. \ref{lb488} is easy but useful. It tells us that the values of $\int f$ and $\mu(U)$ are controlled by each other. For example, part 2 implies that if $\int f$ is small, then the measure of $\{x\in\Rbb^N:f(x)>\eps\}$ cannot be very big, and is converging to $0$ as $\eps\rightarrow+\infty$. 
\end{rem}


\begin{df}
Let $f\in l^\infty(\Rbb^N,\Rbb)$ have compact support. Define \textbf{upper integrals} and \textbf{lower integrals} to be
\begin{gather*}
\ovl\int f=\inf\Big\{\int g:g\in C_c(\Rbb^N,\Rbb),g\geq f  \Big\}\\
\underline\int f=\sup\Big\{\int h:h\in C_c(\Rbb^N,\Rbb),h\leq f  \Big\}
\end{gather*}
Clearly $\udl\int f\leq\ovl\int f$. Moreover, it is clear that if $f\in C_c(\Rbb^N,\Rbb)$ then $\udl\int f=\ovl\int f=\int f$. In general, if $\udl\int f=\ovl\int f$, we say that $f$ is \textbf{Riemann integrable}, \index{00@Riemann integrable} and define its integral $\int f$ to be $\ovl\int f$. Let \index{Rc@$\scr R_c(\Rbb^N,\Rbb)$}
\begin{align*}
\scr R_c(\Rbb^N,\Rbb)=\{f\in l^\infty(\Rbb^N,\Rbb):f\text{ has compact support and is Riemann integrable}\}
\end{align*}
\end{df}

\begin{rem}\label{lb489}
Let $f\in l^\infty(\Rbb^N,\Rbb)$ be compactly supported. It is clear from the definition that the following statements are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $f\in\scr R_c(\Rbb^N,\Rbb)$.
\item For every $\eps>0$ there exist $g,h\in C_c(\Rbb^N,\Rbb)$ satisfying $h\leq f\leq g$ and $\int(g-h)<\eps$.
\end{enumerate}
In fact, (2) is easier to use than the original definition of Riemann integrability.
\end{rem}


\begin{exe}
(This exercise is not needed below.) Prove that when $N=1$, the above definition of upper and lower integrals agrees with that in Pb. \ref{lb386}. 
\end{exe}


\begin{prob}\label{lb732}
Let $f,g\in l^\infty(\Rbb^N,\Rbb)$ have compact supports. Prove
\begin{align*}
\ovl\int(f+g)\leq\ovl\int f+\ovl\int g\qquad \udl\int(f+g)\geq\udl\int f+\udl\int g
\end{align*}
Prove that $\scr R_c(\Rbb^N,\Rbb)$ is a linear subspace of $\Rbb^{\Rbb^N}$. Prove that  $\int:\scr R_c(\Rbb^N,\Rbb)\rightarrow\Rbb$ is linear. Prove that if $f,g\in\scr R_c(\Rbb^N,\Rbb)$ then
\begin{align}
f\leq g\qquad\Longrightarrow\qquad\int f\leq\int g  \label{eq201}
\end{align}
\end{prob}


\begin{prob}\label{lb493}
(\textbf{Fubini's theorem})\index{00@Fubini's theorem for Riemann integrals} Let $X=\Rbb^M,Y=\Rbb^N$. Let $f\in\scr R_c(X\times Y,\Rbb)$.  Prove that $x\in X\mapsto \udl\int_Y f(x,y)dy $ and $x\in X\mapsto\ovl\int_Y f(x,y)dy$ are Riemann integrable, and that $\dps\int_{X\times Y}f=\int_X\udl\int_Yf=\int_X{\ovl\int_Y}f$.
\end{prob}

\begin{proof}[Hint]
Choose $g,h\in C_c(X\times Y,\Rbb)$ such that $g\leq f\leq h$ and $\int_{X\times Y}(h-g)<\eps$. Apply Fubini's theorem for compactly supported continuous functions (available due to Thm. \ref{lb399}) to $g,h,h-g$. (\eqref{eq201} is also useful.)
\end{proof}

\begin{rem}
In the next semester, we will prove Fubini's theorem for Lebesgue measurable functions using more complicated methods. The goal of Pb. \ref{lb493} is to show you how to prove Fubini's theorem for a large class of functions (sufficient for many applications) without using those methods. When studying mathematics, it is often important to know how to simplify a proof when the objects studied are simpler.
\end{rem}




\subsubsection{$\star$ Lebesgue's criterion for multiple Riemann integrals}\label{lb495} 

\begin{df}
As in \eqref{eq200}, for each $f:\Rbb^N\rightarrow\Rbb$ and $\eps>0$, define
\begin{align}
\Omega_\eps(f)=\{x\in\Rbb^N:\omega(f,x)\geq\eps\}
\end{align}
where $\omega(f,x)=\inf_{U\in\Nbh(x)}\diam f(U)$. Note that by Lem. \ref{lb414}, $\Omega_\eps(f)$ is a closed subset of $\Supp(f)$, and hence is compact when $f$ is compactly supported.
\end{df}


\begin{prob}
Let $f\in \scr R_c(\Rbb^N,\Rbb)$.   Prove that $\Omega_\eps(f)$ is a null set. (Thus, $\bigcup_{n\in\Zbb_+}\Omega_{1/n}(f)$ is null. This proves that the set of discontinuities of $f$ is null.)
\end{prob}

\begin{proof}[Hint]
For each $\delta>0$, choose $g,h\in C_c(\Rbb^N,\Rbb)$ such that $h\leq f\leq g$ and $\int(g-h)\leq\delta\eps$, which exist due to Rem. \ref{lb489}. Let $U=\{x\in\Rbb^N:g(x)-h(x)>\eps/2\}$. Use Pb. \ref{lb488} to give a small upper bound of $\mu(U)$. Prove that $\Omega_\eps(f)\subset U$.
\end{proof}


The following problem can be compared with Lem. \ref{lb415}.

\begin{prob}\label{lb491}
Let $f\in l^\infty(\Rbb^N,\Rbb)$ be supported in a compact set $K$. Let $W\subset\Rbb^N$ be an open set containing $K$. Let $\eps>0$, and assume that for every $x\in\Rbb^N$ we have $\omega(f,x)<\eps$. Prove that there exist $g,h\in C_c(W,\Rbb)$ such that
\begin{gather*}
g\leq f\leq h\qquad 0\leq g-h\leq\eps
\end{gather*}
\end{prob}

\begin{proof}[Hint]
First construct the functions locally. Then pass from local to global functions using a partition of unity of $K$ subordinate to an open cover.
\end{proof}


\begin{prob}\label{lb492}
Let $f\in l^\infty(\Rbb^N,\Rbb)$ be compactly supported. Assume that the set of discontinuities of $f$ is a null set. Prove that $f\in\scr R_c(\Rbb^N,\Rbb)$.
\end{prob}


\begin{proof}[Hint]
Choose any $\eps,\delta>0$. Choose an open set $U$ containing the compact set $\Omega_\eps(f)$ such that $\mu(U)<\delta$. Use a partition of unity of $K=\Supp(f)$ subordinate to $U$ and $V=\Rbb^N\setminus\Omega_\eps(f)$ to write $f=f_V+f_U$ where $f_V,f_U\in C_c(\Rbb^N,\Rbb)$ are supported in $K\cap V$ and $U$ respectively. Apply Pb. \ref{lb491} to $f_V$ to get $g_V\leq f_V\leq h_V$ with small $\int(h_V-g_V)$. Let $M=\Vert f\Vert_\infty$.  Find $g_U\in C_c(\Rbb^N,[0,M])$ such that $-g_U\leq f_U\leq g_U$. Show that $\int(g_U+h_V-(-g_U+g_V))$ is small.
\end{proof}



\begin{df}
Let $\Omega$ be a bounded subset of $\Rbb^N$. We say that $f:\Omega\rightarrow\Rbb$ is \textbf{Riemann integrable} \index{00@Riemann integrable} if $\wtd f\in\scr R_c(\Rbb^N,\Rbb)$, where $\wtd f$ is the zero extension of $f$ (i.e. $\wtd f|_\Omega=f$ and $\wtd f|_{X\setminus\Omega}=0$). If $f$ is Riemann integrable, we define
\begin{align*}
\int_\Omega f=\int_{\Rbb^N}\wtd f
\end{align*}
\end{df}


\begin{eg}
Let $D=\{(x,y)\in\Rbb^2:x^2+y^2\leq1\}$ and $f\in C(D,\Rbb)$. Then the set of discontinuities of the zero extension $\wtd f$ is a subset of $\Sbb^1=\{(x,y)\in\Rbb^2:x^2+y^2=1\}$. It is not hard to show that $\Sbb^1$ is a null subset of $\Rbb^2$. Since $\Vert f\Vert_\infty<+\infty$ by extreme value theorem, we conclude that $f$ is Riemann integrable thanks to Lebesgue's criterion (Pb. \ref{lb492}). Clearly $\int_\Rbb f(\cdot,y)dy$ is Riemann integrable. By Fubini's theorem (Pb. \ref{lb493}), we have
\begin{align*}
\int_D f=\int_{\Rbb^2}\wtd f=\int_{-1}^1\int_{-1}^1 \chi_D\wtd f(x,y)dydx=\int_{-1}^1\int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}}f(x,y)dydx
\end{align*}
\end{eg}








\subsubsection{Compactness and countability}


The following problem shows that the equivalence (2)$\Leftrightarrow$(3) in Thm. \ref{lb482} can be generalized to LCH spaces.

\begin{prob}\label{lb484}
Let $X$ be an LCH space with one-point compactification $X^*$. Prove that the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $X^*$ is second countable.
\item $X$ is second countable.
\item $C_0(X,\Rbb)$ is separable (equivalently, second countable).
\end{enumerate}
Here, as usual, $C_0(X,\Rbb)$ is equipped with the $l^\infty$-norm. Note also that by Pb. \ref{lb485}, (3) is equivalent to that $C_c(X,\Rbb)$ is separable.
\end{prob}


\begin{srem}
By Pb. \ref{lb484} and Thm. \ref{lb482}, if an LCH space $X$ is second countable, then $X^*$ is metrizable, and hence $X$ is metrizable. However, a metrizable LCH space is not necessarily second countable. For example, let $X$ be an uncountable set, equipped with the discrete topology $\mc T=2^X$. Then $\mc T$ is induced by a metric $d$ defined by $d(x,y)=1$ if $x\neq y$ and $d(x,x)=0$. $X$ is LCH, but not second countable.
\end{srem}


\begin{prob}\label{lb533}
Let $X$ be a compact Hausdorff space. Suppose that $(f_n)_{n\in\Zbb_+}$ is a sequence in $C(X,\Rbb)$ separating points of $X$. Assume for simplicity that $\Vert f_n\Vert_{l^\infty}\leq 1$ for all $n$. Use these functions to define an explicit metric on $X$ inducing its topology $\mc T$, and construct an explicit countable basis for $\mc T$. 
\end{prob}



\begin{proof}[Note]
This problem tests whether you truly understand the method of embedding and the proof of Thm. \ref{lb482}. Hint: How do you construct a metric and a countable basis for $[-1,1]^{\Zbb_+}$? What do their pullbacks look like under the embedding $X\rightarrow[-1,1]^{\Zbb_+}$ defined by $f_1,f_2,\dots$?
\end{proof}



\newpage




\section{Zorn's lemma and applications}\label{lb512}


\begin{displayquote}
\small The Axiom of Choice is obviously true, the well-ordering principle obviously false, and who can tell about Zorn's lemma?

\hfill ---- Jerry L. Bona
\end{displayquote}



\subsection{Zorn's lemma}



\begin{thm}[\textbf{Zorn's lemma}]\index{00@Zorn's lemma}
Let $(P,\leq)$ be a nonempty partially ordered set. Suppose that every totally oredered subset of $P$ has an upper bound in $P$. Then there is a maximal element $p\in P$.
\end{thm}


By a \textbf{totally ordered subset} \index{00@Totally ordered subset} $Q\subset P$, we mean that $Q$ satisfies that for every $x,y\in Q$, either $x\leq y$ or $y\leq x$. An upper bound of $Q$ (in $P$) means an element $p\in P$ such that $x\leq p$ for all $x\in Q$. A \textbf{maximal element} \index{00@Maximal element in a partially ordered set} $p\in P$ means that $p$ satisfies $\{x\in P:x\geq p\}=\{p\}$.


Zorn's lemma and the axiom of choice are equivalent. (They are both equivalent to the so called ``well-ordering principle".) Although it is easier to prove the axiom of choice from Zorn's lemma than the other way round, one may prefer to take the axiom of choice as the starting point, since axiom of choice is easier to grasp intuitively. Therefore, in the following, I will give a proof of Zorn's lemma under the assumption of axiom of choice, in order to comfort those who are obsessed with building a complete and rigorous mathematical theory in their heads from a few ``self-evident" axioms. However, it is recommended that you skip or only skim this proof, since it is safe enough to assume that Zorn's lemma is an axiom that needs no proof. Although Zorn's lemma is far from ``self-evident", knowing how to use it is much more important than knowing how to prove it. This is because in most areas of mathematics the ideas in the proof of Zorn's lemma are never used.


\begin{proof}[$\star\star$ \textbf{Proof of Zorn's lemma}]
Let $(P,\leq)$ satisfy the assumption in Zorn's lemma but has no maximal element. We shall find a contradiction. By assumption, every totally ordered subset $A\subset P$ has an upper bound $p\in P$, and $p$ is not maximal. So there exists $x_A>p$ in $P$. (Here, $x_A>p$ means that $x_A\geq p$ and $x\neq p$.) Thus, we have a function $A\mapsto x_A$ whose existence is due to axiom of choice.\\[-1ex]

Step 1. Fix $a\in P$ throughout the proof. For an arbitrary $\mc F\subset 2^P$, consider the following conditions:
\begin{enumerate}[label=(\alph*)]
\item $\{a\}\in\mc F$.
\item Every $A\in \mc F$ is a totally ordered subset of $P$.  %and satisfies $a\in A$
\item If $A\in\mc F$ then $A\cup\{x_A\}\in\mc F$.
\item If $\mc E$ is a nonempty totally ordered subset of $\mc F$ (under the partial order $\subset$), then $\bigcup_{A\in\mc E}A\in\mc F$. (Note that if every $A\in P$ is a totally ordered subset of $P$, then so is $\bigcup_{A\in\mc E}A$.)
\end{enumerate}
There exists at least one $\mc F$ satisfying the above conditions. For example, one can let $\mc F$ be the set of all totally ordered subsets of $P$ containing $a$. 

We let $\mc F$ be the intersection of all the subsets of $2^P$ satisfying the above four conditions. Then $\mc F$ clearly also satisfies these conditions. (In particular, $\mc F\neq\emptyset$ because $\{a\}\in\mc F$.) So $\mc F$ is the smallest subset of $2^P$ satisfying these four conditions.

We claim that $\mc F$ is a totally ordered subset of $2^P$. Suppose this is true. Let $B=\bigcup_{A\in\mc F}A$. Then $B\in\mc F$ by condition (d). In particular, by (b), $B$ is a totally ordered subset of $P$. Then $x_B$ is defined as at the beginning of the proof and satisfies $x_B>B$. By (c), we have $B\cup\{x_B\}\in\mc F$. By the definition of $B$, we get $x_B\in B$. This is impossible. So we are done with the proof.\\[-1ex]

Step 2. Let us prove that $\mc F$ is totally ordered. Let
\begin{align*}
\mc F_0=\{A\in\mc F:\text{every }B\in\mc F\text{ satisfies either }A\subset B\text{ or }B\subset A\}
\end{align*}
It is not hard to check that $\mc F_0$ satisfies (a,b,d). It suffices to prove that $\mc F_0$ satisfies (c). Then we will have $\mc F_0=\mc F$ and hence that $\mc F$ is totally ordered.

Let us prove (c) for $\mc F_0$. Choose any $A\in\mc F_0$. We need to prove that $A\cup\{x_A\}\in\mc F_0$. It suffices to prove that the following set equals $\mc F$:
\begin{align*}
\mc F_A=\{B\in\mc F:B\subset A\text{ or }A\cup\{x_A\}\subset B\}
\end{align*}
One checks easily that $\mc F_A$ satisfies (a,b,d). To check that $\mc F_A$ satisfies (c), we choose any $B\in\mc F_A$. Then there are two possible cases:
\begin{itemize}
\item $A\cup\{x_A\}\subset B$ or $B=A$. Then $A\cup\{x_A\}\subset B\cup\{x_B\}$. 
\item $B\subsetneq A$. Then, since $A\in\mc F_0$ and since $B\cup\{x_B\}\in\mc F$ (because $B\in\mc F$ and $\mc F$ satisfies (c)), we have either $A\subsetneq B\cup\{x_B\}$ or $B\cup\{x_B\}\subset A$. The former case is clearly impossible. So $B\cup\{x_B\}\subset A$.
\end{itemize}
Thus, in both cases we have $B\cup\{x_B\}\in\mc F_A$. This proves that $\mc F_A$ also satisfies (c). So $\mc F_A=\mc F$.
\end{proof}




\subsection{Comparison of Zorn's lemma and mathematical induction}



Zorn's lemma can be viewed as the uncountable version of mathematical induction. Therefore, the best way to understand Zorn's lemma is to first use it to prove some classical results traditionally proved by  mathematical induction.




\begin{eg}
Let $n\in\Nbb$ and $s_n=0+1+2+\cdots+n$. Then $s_n=\frac {n(n+1)}2$.
\end{eg}


\begin{proof}
Let $\Nbb^*=\Nbb\cup\{+\infty\}$ with the usual order. Let
\begin{align*}
P=\Big\{n\in\Nbb^*:s_i=\frac{i(i+1)}2\text{ for all }i\leq n\text{ and }i<+\infty \Big\}
\end{align*}
$P$ is nonempty since it contains $0$. (Checking that $P$ is nonempty is important, since it corresponds to checking the base case in mathematical induction.) $P$ is totally ordered, and clearly every nonempty subset  $Q\subset P$ has an upper bound $\sup Q$. Thus, by Zorn's lemma, $P$ has a maximal element. 

If $n<+\infty$, then from $s_n=\frac{n(n+1)}2$ and $s_{n+1}-s_n=n+1$ we have $s_{n+1}=\frac{(n+1)(n+2)}2$. (This step corresponds to checking ``case $n$ implies case $n+1$" in mathematical induction.) So $n+1\in P$, contradicting the maximality of $n$. So $n=+\infty$, and hence $+\infty\in P$, finishing the proof.
\end{proof}






\begin{eg}
Let $f:\Rbb\rightarrow\Rbb$ be a function not continuous at $0$. Assume that $f(0)=0$.  Then there exists $\eps>0$ and a sequence $(x_n)_{n\in\Zbb_+}$ in $\Rbb\setminus\{0\}$ converging to $0$ such that $|f(x_n)|>\eps$ for all $n$.
\end{eg}



\begin{proof}
By assumption, there is $\eps>0$ such that for every $\delta>0$, there exists $x\in(-\delta,\delta)\setminus\{0\}$ such that $|f(x)|>\eps$. Let
\begin{align*}
P=\{&\text{finite or countably infinite sequence }x_\blt=(x_1,x_2,\dots)\\
&\text{satisfying }0<|x_i|<1/i\text{ and }|f(x_i)|>\eps\text{ for all }i\}
\end{align*}
Then $P$ is nonempty. (This corresponds to checking the base case in mathematical induction.) View each element of $P$ as a subset of $\Zbb_+\times\Rbb$, and let $\subset$ be the partial order on $P$. Then every nonempty totally ordered subset $Q\subset P$ has an upper bound (defined by taking union). Thus, by Zorn's lemma, $P$ has a maximal element $x_\blt$.

Suppose that $x_\blt$ has finite length $N\in\Zbb_+$. (So $x_\blt=(x_1,\dots,x_N)$) Then by the first sentence of the proof, there exists $x_{N+1}$ satisfying $0<|x_{N+1}|<1/(N+1)$ satisfying $|f(x_{N+1})|>0$. (This step corresponds to checking ``case $n$ implies case $n+1$" in mathematical induction.) Then $(x_1,\dots,x_N,x_{N+1})$ belongs to $P$ and is $>x_\blt$, contradicting the maximality of $x_\blt$. So $x_\blt$ must be an infinite sequence. This finishes the construction of the sequence $(x_n)$.
\end{proof}




\subsection{Proof of the Tychonoff theorem}\label{lb503}





We first recall Pb. \ref{lb240}: Assume for simplicity that $X,Y$ are compact spaces. Let $(x_\alpha,y_\alpha)_{\alpha\in\scr I}$ be a net in $X\times Y$ such that $x\in X$ is a cluster point of $(x_\alpha)$. Then there exists $y\in Y$ such that $(x,y)$ is a cluster point of $(x_\alpha,y_\alpha)$.

The proof is easy. By the definition of cluster points (Pb. \ref{lb223}-(1)), $(x_\alpha)$ has a subnet $(x_{\alpha_\beta})_{\beta\in\scr J}$ converging to $x$. Since $Y$ is net-compact, $(y_{\alpha_\beta})$ has a subnet $(y_{\alpha_{\beta_\gamma}})_{\gamma\in\scr K}$ converging to some $y\in Y$. Then $(x_{\alpha_{\beta_\gamma}},y_{\alpha_{\beta_\gamma}})$ is a subnet of $(x_\alpha,y_\alpha)$ converging to $(x,y)$.



In the following, we present a proof of Tychonoff Thm. \ref{lb452} which was due to Chernoff \cite{Che92}. Our method is similar to the proof of the countable Tychonoff theorem (Pb. \ref{lb241}) which uses net-compactness. It is strongly recommended that you compare the proof with the one of Pb. \ref{lb241}, and even reprove Pb. \ref{lb241} using Zorn's lemma.

\begin{proof}[\textbf{Proof of Tychonoff Thm. \ref{lb452}}]
Recall the setting that $(X_\alpha)_{\alpha\in\scr I}$ is a family of compact topological spaces. Assume WLOG that $\scr I$ and each $X_\alpha$ are nonempty. We want to prove that $S=\prod_{\alpha\in\scr I}X_\alpha$ is compact. 

We first introduce a few notations. For each $I\subset\scr I$, let $S_I=\prod_{\alpha\in I}X_\alpha$. If $x\in S_I$, we write $x$ as $(x(\alpha))_{\alpha\in I}$, and view it as a function with domain $I$ and codomain $\fk X=\bigcup_{\alpha\in\scr I}X_\alpha$. We write $\Dom(x)=I$. If $x\in S_I$ and $J\subset I$, the restriction $x|_J=(x(\alpha))_{\alpha\in J}$ is clearly in $S_J$.\\[-1ex]

Step 1. Let $(f_\mu)_{\mu\in\fk M}$ be a net in $S$. Let
\begin{align*}
P=\bigcup_{I\subset\scr I}\big\{x\in S_I: x\text{ is a cluster point of }(f_\mu|_I)_{\mu\in\fk M} \text{ in }S_I \big\}
\end{align*}
Let ``$\subset$" be the partial order on $P$ (defined by identifying each element of $P$ with its graph, which is an element of $\scr I\times \fk X$). Thus $x\subset y$ iff $\Dom(x)\subset\Dom(y)$ and $y|_{\Dom(x)}=x$.


Clearly $P$ is nonempty: Choose any $\alpha\in\scr I$. Since $X_\alpha$ is compact, $(f_\mu(\alpha))_{\mu\in\fk M}$ has a cluster point in $X_\alpha$. This point, viewed as a function from $\{\alpha\}$ to this point, belongs to $P$.\footnote{This part corresponds to checking the base case in mathematical induction.} 

We claim that every totally ordered subset of $P$ has an upper bound. Suppose this is true. Then by Zorn's lemma, there is a maximal element $x\in P$. If $\Dom(x)\neq \scr I$, then by Pb. \ref{lb240} (applied to $S_{\Dom(x)}\times X_\beta$ where $\beta\in \scr I\setminus\Dom(x)$), $x$ can be extended to a function with larger domain which is again the cluster point of the restriction of $(f_\mu)_{\mu\in\fk M}$ to that domain.\footnote{This part corresponds to checking ``case $n$ implies case $n+1$" in mathematical induction. More precisely, it corresponds to constructing $(x(1),\dots,(x(n+1)))$ from $(x(1),\dots,x(n))$ in the proof of Pb. \ref{lb241}.} This proves that $P$ has an element strictly larger than $x$. This is impossible. So we must have $\Dom(x)=\scr I$, finishing the proof.\\[-1ex]

Step 2. Let $Q$ be a nonempty totally ordered subset of $P$. Let $x$ be the union of the elements of $Q$. Let $K=\Dom(x)$. Then $Q$ can be written in the form
\begin{align*}
Q=\{x|_I:I\in\scr U\}
\end{align*}
where $\scr U$ is a totally ordered subset of $2^K$ and $K=\bigcup_{I\in\scr U}I$.



To prove that $x\in P$,  let us use Pb. \ref{lb223}-(2) to prove that $x$ is a cluster point of $(f_\mu|_K)_{\mu\in\fk M}$.\footnote{This part corresponds to showing that $x$ is a cluster point of $(f_\alpha)$ in the proof of Pb. \ref{lb241}.} Let $W$ be a neighborhood of $x$ in $S_K$. By the definition of product topology (Def. \ref{lb454}), we can shrink $W$ to a smaller neighborhood of the form
\begin{align*}
W=\prod_{\alpha\in K}U_\alpha
\end{align*}
where each $U_\alpha$ is a neighborhood of $x(\alpha)$, and there exists a finite subset $E\subset K$ such that $U_\alpha=X_\alpha$ for all $\alpha\in K\setminus E$. Choose $I\in\scr U$ containing $E$. The fact that $x|_I$ is a cluster point of $(f_\mu|_I)_{\mu\in\fk M}$ implies (by Pb. \ref{lb223}-(2)) that $(f_\mu|_E)_{\mu\in\fk M}$ is frequently in $\prod_{\alpha\in E}U_\alpha$. Therefore $(f_\mu|_K)_{\mu\in\fk M}$ is frequently in $W$. This finishes the proof.
\end{proof}

%% Record #25 2023/12/18 two lectures  62


\subsection{Proof of the Hahn-Banach extension theorem}

Recall from Rem. \ref{lb560} that a \textbf{linear functional} on a vector space $V$ over a field $\Fbb$ is defined to be a linear map $V\rightarrow\Fbb$.

\begin{lm}\label{lb498}
Let $V$ be a normed vector space over $\Rbb$, and let $M$ be a linear subspace. Let $\varphi\in M^*=\fk L(M,\Rbb)$ with operator norm $\Vert\varphi\Vert\leq 1$. Assume that $e\in V\setminus M$, and let $\wtd M=M+\Rbb e$. Then $\varphi$ can be extended to a linear functional $\wtd\varphi:\wtd M\rightarrow\Rbb$ such that $\Vert\wtd \varphi\Vert\leq 1$. 
\end{lm}

\begin{proof}[$\star$ Proof]
Let $A\in\Rbb$ whose value will be determined later. Since any vector in $\wtd M$ can be written uniquely as  $x-\lambda e$ where $x\in M$ and $\lambda\in\Rbb$, we can define
\begin{align*}
\wtd\varphi:\wtd M\rightarrow\Rbb\qquad \wtd\varphi(x-\lambda e)=\varphi(x)-\lambda A
\end{align*}
It remains to prove $\Vert\wtd\varphi\Vert\leq 1$ (for some $A$). This means that we want to prove $|\varphi(x)-\lambda A|\leq \Vert x-\lambda e\Vert$ for all $x\in M,\lambda\in\Rbb$. Clearly this is true when $\lambda=0$. Assume $\lambda\neq 0$. Then replacing $x$ by $\lambda x$ and dividing both sides by $\lambda$, we see that it suffices to prove
\begin{align*}
|\varphi(x)-A|\leq \Vert x-e\Vert
\end{align*}
for all $x\in V$, or equivalently, 
\begin{align*}
\varphi(x)-\Vert x-e\Vert\leq A\leq \varphi(x)+\Vert x-e\Vert
\end{align*}
To prove the existence of $A$ satisfying the above inequalities for all $x\in V$, it suffices to prove
\begin{align}\label{eq227}
\sup_{x\in V}\big(\varphi(x)-\Vert x-e\Vert\big)\leq \inf_{y\in V}\big(\varphi(y)+\Vert y-e\Vert\big)
\end{align}
namely, to prove that $\varphi(x)-\Vert x-e\Vert\leq \varphi(y)+\Vert y-e\Vert$ for all $x,y\in V$. Using $\Vert\varphi\Vert\leq1$, we compute
\begin{align*}
\varphi(x)-\varphi(y)=\varphi(x-y)\leq \Vert(x-e)-(y-e)\Vert\leq \Vert x-e\Vert+\Vert y-e\Vert
\end{align*}
\end{proof}


\begin{thm}[\textbf{Hahn-Banach extension theorem}] \label{lb499} \index{00@Hahn-Banach extension theorem}
Let $V$ be a normed vector space over $\Fbb\in\{\Rbb,\Cbb\}$. Let $M$ be an $\Fbb$-linear subspace of $V$. Let $\varphi\in M^*=\fk L(M,\Fbb)$. Then there exists $\Phi\in V^*$ such that $\Phi|_M=\varphi$ and $\Vert\Phi\Vert=\Vert\varphi\Vert$.
\end{thm}


\begin{proof}
We first consider the case $\Fbb=\Rbb$. Assume WLOG that $\varphi\neq 0$. By scaling $\varphi$, we assume WLOG that $\Vert\varphi\Vert=1$. Let
\begin{align*}
P=\big\{(W,\Phi):&W\text{ is a linear subspace of }V\text{ and contains }M\\
&\Phi\in\Rbb^W\text{ is linear and satisfies }\Phi|_M=\varphi,\Vert\Phi\Vert=1\big\}
\end{align*}
Then $P$ is nonempty since it contains $(M,\varphi)$. Define a partial order on $P$ by setting $(W,\Phi)\leq(W',\Phi')$ whenever $W\subset W'$ and $\Phi=\Phi'|_W$.

Suppose that $Q$ is a totally ordered subset of $P$. Let $\wtd W=\bigcup_{(W,\Phi)\in Q}W$, and let $\wtd\Phi$ be the union of the functions $\Phi$ over all $(W,\Phi)\in Q$ (by taking the union of the graphs of the functions). So $\wtd\Phi:W\rightarrow\Rbb$ is the unique functions satisfying $\wtd \Phi|_W=\Phi$ for all $(W,\Phi)\in Q$. Then it is easy to see that $(\wtd W,\wtd\Phi)$ belongs to $P$ and is an upper bound of $Q$. 

Thus, we can use Zorn's lemma, which says that $P$ has a maximal element $(W,\Phi)$. If $W\neq V$, we let $e\in V\setminus W$. Then by Lem. \ref{lb498}, $\Phi$ can be extended to $\wtd\Phi\in \wtd W^*$ where $\wtd W=W+\Rbb e$, and $\Vert\wtd\Phi\Vert=1$. So $(\wtd W,\wtd\Phi)$ belongs to $P$ and is strictly larger than $(W,\Phi)$, impossible. So $W=V$.

We are done with the proof for the case $\Fbb=\Rbb$. Now assume $\Fbb=\Cbb$. By Pb. \ref{lb387}, the real part $\Real\varphi:M\rightarrow\Rbb$ sending $v$ to $\Real(\varphi(v))$ is linear with operator norm $\Vert\Real\varphi\Vert=\Vert\varphi\Vert$. By the real Hahn-Banach, $\Real\varphi$ can be extended to $\Lambda\in\fk L(V,\Rbb)$ with $\Vert\Lambda\Vert=\Vert\varphi\Vert$. By Pb. \ref{lb387}, there exists a unique $\Phi\in\fk L(V,\Cbb)$ with real part $\Lambda$ such that $\Vert\Phi\Vert=\Vert\varphi\Vert$. Since $\Real\Phi|_M=\Lambda|_M=\Real \varphi$, by Pb. \ref{lb387}, we have $\Phi|_M=\varphi$.
\end{proof}






In this course, we only use the following special case of Hahn-Banach theorem.

\begin{co}[\textbf{Hahn-Banach}]\label{lb502}
Let $V$ be a nonzero normed vector space over $\Fbb\in\{\Rbb,\Cbb\}$. Then for  every $v\in V$, there exists a nonzero $\varphi\in V^*$ such that $\bk{\varphi,v}=\Vert\varphi\Vert\cdot\Vert v\Vert$. Consequently, the linear map
\begin{align}\label{eq202}
V\rightarrow V^{**}\qquad v\mapsto \bk{\cdot,v}
\end{align}
is an isometry.
\end{co}

More precisely, the map \eqref{eq202} sends each $\varphi\in V^*$ to $\bk{\varphi,v}$. By scaling $\varphi$, Hahn-Banach implies that for each $v\in V$, there is $\varphi\in V^*$ with $\Vert\varphi\Vert=1$ such that $\bk{\varphi,v}=\Vert v\Vert$.

\begin{proof}
Let $v\in V$, and assume WLOG that $v\neq 0$. Let $\varphi:\Fbb v\rightarrow \Fbb$ send $\lambda v$ to $\lambda\Vert v\Vert$. Then $\varphi$ is linear and has operator norm $1$, and $\bk{\varphi,v}=\Vert v\Vert$. By Hahn-Banach Thm. \ref{lb499}, $\varphi$ can be extended to a bounded linear $V\rightarrow\Fbb$ with operator norm $1$. This is a desired linear functional.

Denote \eqref{eq202} by $\Psi$. To show that $\Psi$ is an isometry, we need to prove that for every $v\in V$, $\Psi(v):V^*\rightarrow\Fbb$ has operator norm $\Vert v\Vert$. Choose any $\varphi\in V^*$. Then 
\begin{align*}
\bk{\Psi(v),\varphi}=\bk{\varphi,v}\leq\Vert\varphi\Vert\cdot\Vert v\Vert
\end{align*}
where ``$\leq$" is ``$=$" for some nonzero $\varphi$ by the first paragraph. Therefore, by Rem. \ref{lb372}, we obtain $\Vert\Psi(v)\Vert=\Vert v\Vert$.
\end{proof}















\subsection{Problems and supplementary material}


\begin{prob}\label{mc64}
Let $V$ be a vector space over a field $\Fbb$. Use Zorn's lemma to prove that $V$ has a basis, i.e. a set $E$ of linearly independent vectors such that any vector of $V$ can be written as a (finite) linear combination of elements of $E$.
\end{prob}



\begin{prob}
Let $X$ be a set. Let $E\subset X$ be an infinite subset such that $X\setminus E$ is countable. (Recall that finite sets are also countable.) Prove that $\card(X)=\card(E)$.
\end{prob}

\begin{prob}\label{lb496}
Let $X$ be an infinite set. Use Zorn's lemma to prove that $X$ can be written as a countably infinite union  of subsets $X=\bigsqcup_{n=1}^\infty X_n$ such that $\card(X_i)=\card(X_j)$ for each $i,j$.
\end{prob}


\begin{proof}[Hint]
Assume WLOG that $X$ is uncountable. Consider
\begin{align*}
P=\Big\{\big((A_n)_{n\in\Zbb_+},(\varphi_n)_{n\in\Zbb_+} \big):&A_1,A_2,\dots\text{ are mutually disjoint subsets of }X\\
&\varphi_n:A_n\rightarrow A_{n+1}\text{ is a bijection (for every $n\in\Zbb_+$)}\Big\}
\end{align*}
which is nonempty (why?). Define a suitable partial order on $P$.
\end{proof}



\begin{thm}\label{lb497}
Let $X$ be an infinite set, and let $Y$ be a nonempty countable set. Then $\card(X)=\card(X\times Y)$
\end{thm}

\begin{proof}
By Pb. \ref{lb496}, we have $X\approx A\times\Nbb$ for some subset $A\subset X$. Since  $\Nbb\times Y$ is infinite and countable, we have $\Nbb\times Y\approx \Nbb$. Therefore
\begin{align*}
X\times Y\approx A\times \Nbb\times Y\approx A\times \Nbb\approx X
\end{align*}
\end{proof}


\begin{sprob}
Let $E,F$ be two bases of a vector space $V$. Use Thm. \ref{lb497} to prove that $\card(E)=\card(F)$. (When one of $E,F$ is finite, this result was proved in linear algebra. You can assume this in your proof.)
\end{sprob}

\begin{prob}\label{lb501}
Let $V$ be a  \textit{separable} normed vector space over $\Rbb$. Prove Hahn-Banach Thm. \ref{lb499} for $V$ using mathematical induction instead of Zorn's lemma. (You will need Prop. \ref{lb500} in the proof.)
\end{prob}












\newpage




\section{Compactness and completeness revisited}\label{lb909}





Tychonoff theorem asserts the compactness of function spaces under the pointwise convergence topology. In application, we are often interested in the compactness of function spaces satisfying certain additional condition such as the continuity. 

\begin{eg}\label{lb518}
$\fk X=C([0,1],[0,1])$ is not compact under either the pointwise convergence topology or the uniform convergence topology.
\end{eg}

\begin{proof}
We first choose the pointwise convergence topology. Choose any sequence $(f_n)$ in $\fk X$ converging pointwise to a non-continuous function $f$. Then $(f_n)$ has no subnet converging in $\fk X$, since any subnet converging to $g\in \fk X$ must satisfy $f=g$ and hence $f$ is continuous. This is impossible. So $\fk X$ is not compact.

Now we choose the uniform convergence topology for $\fk X$, which is metrizable by the $l^\infty$-norm. Let $(f_n)$ be a sequence in $\fk X$ such that $\Vert f_m-f_n\Vert_\infty=1$ whenever $m\neq n$. (For example, one chooses $f_n$ such that $\Supp f_n\subset I_n=(\frac 1{2n+2},\frac 1{2n+1})$ and that $f_n(\xi_n)=1$ for some $\xi_n\in I_n$.) Then every subsequence of $(f_n)$ is not Cauchy and hence not convergent. Therefore, $\fk X$ is not sequentially compact, and hence not compact.
\end{proof}



Note that this example does not contradict Tychonoff theorem. In fact, if we choose the pointwise convergence topology,  then Tychonoff theorem implies that every sequence $(f_n)$ in $C([0,1],[0,1])$ has a subnet convergent to some $f\in [0,1]^{[0,1]}$. However, one cannot deduce the continuity of $f$. To prove that the limit function is continuous, we need additional assumptions on the sequence $(f_n)$.  For example, Cor. \ref{lb303} tells us that we need the equicontinuity.




\subsection{Precompactness in function spaces}


Since $C(X,[0,1])$ is in general not compact, one should search for compact subsets of $C(X,[0,1])$, or more generally, subsets with compact closures in $C(X,[0,1])$. You know what precompact sets mean geometrically: In $\Rbb^N$, precompact subsets of $\Rbb^N$ are exactly bounded subsets of $\Rbb^N$. If $\Omega\subset\Rbb^N$, then precompact subsets of $\Omega$ are precisely bounded subsets of $\Rbb^N$ whose closures are inside $\Omega$, cf. Rem. \ref{lb459}. 

However, when studying function spaces, it is often more convenient to use another description of precompactness. As we shall see in Cor. \ref{lb508}, saying that $\scr A\subset C(X,[0,1])$ is precompact in $C(X,[0,1])$ is equivalent to saying that every net $(f_\alpha)$ in $\scr A$ converges to some $f\in C(X,[0,1])$.






Recall from Def. \ref{lb458} that a subset $A$ of a Hausdorff space $X$ is called \textbf{precompact} if $A$ is contained in a compact subset of $X$, or equivalently, if $\ovl A$ is compact. %Recall Rem. \ref{lb459} for two equivalent descriptions of precompactness in subsets of $X$.


\begin{pp}\label{lb505}
Let $X$ be a metrizable topological space, and let $A\subset X$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $A$ is precompact.
\item Every net in $A$ has a cluster point in $X$.
\item Every sequence in $A$ has a cluster point in $X$.
\end{enumerate}
\end{pp}

From the following proof, it is clear that (1)$\Rightarrow$(2) holds even without assuming that $X$ is metrizable.

\begin{proof}
(1)$\Rightarrow$(2): Since $\ovl A$ is compact, every net in $A$ has a cluster point in $\ovl A$ and hence in $X$. 

(2)$\Rightarrow$(3): Obvious.

(3)$\Rightarrow$(1): See Pb. \ref{lb287}.
\end{proof}



\subsubsection{$\star$ Precompactness in regular spaces}

(Since this section is a starred section, I will not use the results proved here in future sections. However, the material of this section is helpful for a better understanding of precompactness in function spaces.)

You may wonder to what general topological space the equivalence (1)$\Leftrightarrow$(2) generalizes. This equivalence is not true for an arbitrary topological space, but is true for regular spaces (recall Def. \ref{lb504}). Metrizable spaces are clearly regular. More generally, we have:

\begin{eg}\label{lb506}
Every subset of a regular space is regular. Every LCH space is regular. Products of regular spaces are regular.
\end{eg}

\begin{proof}%[$\star$ Proof]
Assume that $X$ is regular and $A\subset X$. For each $x\in A$, choose a neighborhood of $x$ in $A$, which must be of the form $U\cap A$ where $U\in\Nbh_X(x)$. Since $X$ is regular, there is $V\in\Nbh_X(x)$ such that $\ovl V\subset U$. So $\Cl_A(V\cap A)\subset \ovl V\cap A\subset U\cap A$. So $A$ is regular. That LCH spaces are regular follows from Lem. \ref{lb460} (together with Rem. \ref{lb459}).

Let $S=\prod_{\alpha\in\scr I}X_\alpha$ where each $X_\alpha$ is regular. Choose $x=(x_\alpha)_{\alpha\in\scr I}$ in $S$. Choose a neighborhood of $x$ which, after shrinking, is of the form $\prod_\alpha U_\alpha$ where $U_\alpha\in\Nbh_{X_\alpha}(x_\alpha)$, and there is a finite subset $E\subset\scr I$ such that $U_\alpha=X_\alpha$ if $\alpha\in\scr I\setminus E$. If $\alpha\in E$, let $V_\alpha$ be a neighborhood of $x$ such that $\ovl V_\alpha\subset U_\alpha$. If $\alpha\in\scr I\setminus E$, let $V_\alpha=X_\alpha$. Then one checks easily that $\prod_{\alpha\in\scr I} V_\alpha$ is a neighborhood of $x$ with closure $\prod_{\alpha\in\scr I} \ovl V_\alpha$, which is clearly inside $\prod_\alpha U_\alpha$. So $S$ is regular.
\end{proof}


\begin{thm}\label{lb507}
Let $X$ be a regular topological space, and let $A\subset X$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $\ovl A$ is compact.
\item $A$ is contained in a compact subset of $X$.
\item Every net in $A$ has a cluster point in $X$.
\end{enumerate}
\end{thm}

Thus, although regular spaces are not necessarily Hausdorff, the two equivalent definitions of precompact subsets of Hausdorff spaces in Def. \ref{lb458} are also equivalent in regular spaces. (However, most important examples of regular spaces are also Hausdorff. Regular Hausdorff spaces are called \textbf{T3 spaces}.) \index{00@T3 spaces}

\begin{proof}%[$\star$ Proof]
``(1)$\Rightarrow$(2)" is obvious. ``(2)$\Rightarrow$(3)" is also obvious: if $X\subset K$ where $K$ is a compact subset of $X$, then every net in $A$ is a net in $K$, which has a cluster point in $K$ and hence in $X$. 

Assume (3). Let us show that $\ovl A$ is compact by showing that every net $(x_\alpha)_{\alpha\in I}$ in $\ovl A$ has a cluster point in $\ovl A$. 
For each $\gamma\in I$, let $E_\gamma=\{x_\alpha:\alpha\in I,\alpha\geq\gamma\}$. Define 
\begin{align*}
J=\big\{(U,\gamma)\in 2^X\times I:U\text{ is open and contains } E_\gamma \big\}
\end{align*}
It is not hard to check that $J$ is a directed set if we define its preorder ``$\leq$" to be
\begin{align*}
(U,\gamma)\leq(U',\gamma')\qquad\Longleftrightarrow\qquad U\supset U',\gamma\leq \gamma'
\end{align*}
For each $(U,\gamma)\in J$, since $E_\gamma\subset U$, $U$ intersects $\ovl A$, and hence intersects $A$. Therefore, we can choose some $y_{U,\gamma}\in A\cap U$. In this way, we get a net $(y_{U,\gamma})_{(U,\gamma)\in J}$ in $A$. By (3), this net has a cluster point $x\in X$. So clearly $x\in\ovl A$. Let us prove that $x$ is also a cluster point of $(x_\alpha)_{\alpha\in I}$.


Assume that $x$ is not a cluster point of $(x_\alpha)_{\alpha\in I}$. Then, by the definition of cluster points (Pb. \ref{lb223}-(2)), there exists $\Omega\in\Nbh_X(x)$ such that $(x_\alpha)$ is not frequently in $\Omega$, i.e., eventually outside $\Omega$. So there exists $\gamma\in I$ such that $E_\gamma\subset X\setminus \Omega$. Since $X$ is regular, there exists $V\in\Nbh_X(x)$ such that $\ovl V\subset \Omega$. Let $U=X\setminus \ovl V$. Then $E_\gamma\subset U$, and hence $(U,\gamma)\in J$.

Since $x$ is a cluster point of $y_\blt$, for the neighborhood $V$ of $x$, there exists $(U',\gamma')\geq (U,\gamma)$ in $J$ such that $y_{U',\gamma'}\in V$. By the definition of the net $y_\blt$, we have $y_{U',\gamma'}\in A\cap U'\subset U$. This is impossible, since $U\cap V=\emptyset$.
\end{proof}


\begin{co}\label{lb508}
Let $X$ be a topological space, and let $Y$ be a metric space. Equip $C(X,Y)$ with either the pointwise convergence topology or the uniform convergence topology. (Note that both topologies are Hausdorff.) Let $\scr A$ be a subset of $C(X,Y)$. Then the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $\scr A$ is precompact.
\item Every net $(f_\alpha)_{\alpha\in\scr I}$  in $\scr A$ has a subnet converging to some $f\in C(X,Y)$.
\end{enumerate}
\end{co}

\begin{proof}
If the topology $\mc T$ on $C(X,Y)$ is the pointwise convergence topology, then $C(X,Y)$ is a subspace of $Y^X$ (equipped with the product topology). By Exp. \ref{lb506}, $C(X,Y)$ is regular. So one can use Thm. \ref{lb507} to prove (1)$\Leftrightarrow$(2). If $\mc T$ is the uniform convergence topology, then $C(X,Y)$ is metrizable (and hence also regular). So one can also use Thm. \ref{lb507} (or even Prop. \ref{lb505}) to prove (1)$\Leftrightarrow$(2). 
\end{proof}




%Compared to the original definition, it is better to view (2) as the definition of precompactness in $C(X,Y)$. In fact, when studying nonmetrizable regular topologies (such as the pointwise convergence topology), we will rarely use the original definition of precompactness.


\subsection{Equicontinuity and precompactness; the Arzel\`a-Ascoli theorem}\label{lb517}






\subsubsection{Precompactness under pointwise convergence topology}

\begin{displayquote}
\small Furthermore, however, even disregarding the intrinsic necessity of some new axiom... a decision about its truth is possible also in another way...  that is, its fruitfulness in consequences and in particular in "verifiable" consequences, i.e., consequences demonstrable without the new axiom, whose proofs by means of the new axiom, however, are considerably simpler and easier to discover, and make it possible to condense into one proof many different proofs.

\hfill ---- Kurt G\"odel (cf. \cite{God47})
\end{displayquote}



\begin{df}
Let $X$ be a set and $Y$ be a metric space. A subset $\scr A\subset Y^X$ is called \textbf{pointwise bounded} \index{00@Pointwise bounded} if
\begin{align}
\scr A(x)=\{f(x):f\in\scr A\}
\end{align}
is a bounded subset of $Y$ for every $x\in X$.
\end{df}





\begin{thm}\label{lb509}
Let $X$ be a topological space, and equip $C(X,\Rbb^N)$ with the pointwise convergence topology. Let $\scr A$ be an equicontinuous and pointwise bounded subset of $C(X,\Rbb^N)$. Then $\scr A$ is precompact in $C(X,\Rbb^N)$, and $\ovl{\scr A}$ is equicontinuous. 
\end{thm}




\begin{proof}
Write $Y=\Rbb^N$. Let us show that $\ovl{\scr A}=\Cl_{C(X,Y)}(\scr A)$ is equicontinuous. Since $\scr A$ is equicontinuous, for every $x\in X$ and $\eps>0$, there exists $U\in\Nbh(x)$ such that $\diam(f(U))\leq\eps$ for all $f\in\scr F$. Since each $g\in\ovl{\scr A}$ is the pointwise limit of a net in $\scr A$, we also have $\diam(g(U))\leq\eps$. This proves that $\ovl{\scr A}$ is equicontinuous at $x$.


Now let us show that $\ovl{\scr A}$ is compact. Choose any net $(f_\alpha)$ in $\ovl{\scr A}$. It is clear that $\ovl{\scr A}(x)$ is pointwise bounded. By Heine-Borel, for each $x\in X$, $\ovl{\scr A}(x)$ is contained in a compact subset $K_x\subset Y$. So $\ovl{\scr A}$ is contained in $S=\prod_{x\in X}K_x$ where $S$ is compact by Tychonoff theorem. Therefore, $(f_\alpha)$ has a subnet $(f_\beta)$ converging pointwise to some $f:X\rightarrow Y$. Since $(f_\beta)$ is equicontinuous (as $\ovl{\scr A}$ is equicontinuous), by Cor. \ref{lb303}, $f\in C(X,Y)$.\footnote{Alternatively, by the argument in the first paragraph, $\{f_\beta:\text{all }\beta\}\cup\{f\}$ is equicontinuous. So $f$ is continuous.}  So $f\in\Cl_{C(X,Y)}(\ovl{\scr A})=\ovl{\scr A}$ since $f$ can be approximated by elements of $\ovl{\scr A}$. This proves that $\ovl{\scr A}$ is compact.
\end{proof}

\begin{rem}\label{lb524}
Theorem \ref{lb509} is of fundamental importance because most compactness results about function spaces (such as Arzel\`a-Ascoli Thm. \ref{lb516}, Banach-Alaoglu Thm. \ref{lb519}) are derived from this theorem. As we will see in Claim \ref{lb510}, when $X$ is separable, the proof of Thm. \ref{lb509} uses only the countable version of Tychonoff theorem, and hence not using Zorn's lemma. This is in line with the history that Thm. \ref{lb509} (which is implicit in the proof of Arzel\`a-Ascoli theorem) appeared earlier than Zorn's lemma and was proved using diagonal method. (If you remember, the proof of countable Tychonoff theorem uses diagonal method, cf. Thm. \ref{lb89}. And we will use Thm. \ref{lb89} to prove Claim \ref{lb510}.) 

In the late 19th and early 20th centuries, the diagonal method was often used to derive compactness properties of function spaces. Prominent examples are Hilbert's and Schmidt's solutions of eigenvalue problems in integral equations (cf. Ch. \ref{lb672}) and F. Riesz's solution of moment problems (cf. Rem. \ref{lb526}). Thus, Thm. \ref{lb509} can be viewed as a summary of this method.  \hfill\qedsymbol
\end{rem}



\begin{comment}
\begin{rem}
In the above theorem, one can also prove that $\scr A$ is precompact without using Cor. \ref{lb508}: As in the above proof, we have $\scr A\subset S=\prod_{x\in X}K_x$ where $S$ is compact. So $\Cl_S(\scr A)$ is compact. Thus $\scr A$ is precompact in $C(X,Y)$ if we can prove that $\Cl_S(\scr A)$ is a subset of $C(X,Y)$. But this follows immediately from Cor. \ref{lb303}, or from the last paragraph of the above proof.
\end{rem}
\end{comment}


The following exercise is a variant of Thm. \ref{lb509}. Another variant, the Banach-Alaoglu theorem, will be discussed in the next section.



\begin{exe}\label{lb536}
Let $X$ be a metric space, and equip $C(X,\Rbb^N)$ with the pointwise convergence topology. Let $\scr A$ be a pointwise bounded subset of $C(X,\Rbb^N)$. Assume that $\scr A$ has a uniform Lipschitz constant $L<+\infty$. (Namely, $\Vert f(x)-f(y)\Vert\leq L\cdot d(x,y)$ for all $f\in\scr A$ and $x,y\in X$.) Prove that $\scr A$ is precompact in $C(X,\Rbb^N)$, and $\ovl{\scr A}$ has a uniform Lipschitz constant $L$. \footnote{In fact, instead of assuming that $\scr A$ is pointwise bounded, it suffices to assume that $\scr A(x)$ is bounded for some $x\in X$. Then the pointwise boundedness will follow automatically from the uniform Lipschitz continuity. Can you see why?}
\end{exe}



The proof of Thm. \ref{lb509} uses Tychonoff theorem for uncountable product spaces, and hence relies on Zorn's lemma. In the following, we shall show that Zorn's lemma is not needed when $X$ is separable. We first need a preparatory result: the following proposition is the equicontinuous analog of Prop. \ref{lb288}.



\begin{pp}\label{lb511}
Let $\mc V$ be a Banach space. Let $X$ be a topological space. Let $(f_\alpha)_{\alpha\in I}$ be an equicontinuous net in $C(X,\mc V)$ converging pointwise on a dense subset $E$ of $X$. Then $(f_\alpha)$ converges pointwise on $X$ to some $f\in C(X,\mc V)$.
\end{pp}

It follows that if $(f_\alpha)$ also converges pointwise on $E$ to some $g\in C(X,\mc V)$, then $(f_\alpha)$ converges pointwise on $X$ to $g$. (Indeed, since $f|_E=g|_E$, we have $f=g$ because $f,g$ are continuous and $E$ is dense.)  

\begin{proof}
Let $x\in X$. Since $\mc V$ is complete, to show that $(f_\alpha(x))$ converges, it suffices to prove that $(f_\alpha(x))_{\alpha\in I}$ is a Cauchy net. Choose any $\eps>0$. Since $(f_\alpha)$ is equicontinuous at $x$, there exists $U\in\Nbh_X(x)$ such that $\diam(f_\alpha(U))<\eps$ for all $\alpha$. Since $E$ is dense in $X$, $E$ intersects $U$. Pick $p\in E\cap U$. Since $(f_\alpha(p))$ is a Cauchy net, we have $\lim_{\alpha,\beta\in I}\Vert f_\alpha(p)-f_\beta(p)\Vert=0$. Then
\begin{align*}
&\Vert f_\alpha(x)-f_\beta(x)\Vert\leq \Vert f_\alpha(x)-f_\alpha(p)\Vert+ \Vert f_\alpha(p)-f_\beta(p)\Vert+  \Vert f_\beta(p)-f_\beta(x)\Vert\\
\leq&\Vert f_\alpha(p)-f_\beta(p)\Vert+2\eps
\end{align*}
where the RHS converges to $2\eps$ under $\limsup_{\alpha,\beta\in I}$. Therefore $\limsup_{\alpha,\beta\in I}\Vert f_\alpha(x)-f_\beta(x)\Vert$ is $\leq 2\eps$. Since $\eps$ is arbitrary, we conclude $\limsup_{\alpha,\beta\in I}\Vert f_\alpha(x)-f_\beta(x)\Vert=0$.

We have proved that $(f_\alpha)$ has a pointwise limit $f:X\rightarrow\mc V$. Since $(f_\alpha)$ is equicontinuous, by Cor. \ref{lb303}, $f$ is continuous.
\end{proof}








\begin{claim}\label{lb510}
When $X$ is a separable topological space, Thm. \ref{lb509} can be proved without using Zorn's lemma.
\end{claim}

We know that separable is equivalent to second countable when $X$ is metrizable, but is slightly weaker in general (cf. Sec. \ref{lb253}). In practice, however, almost all separable topological spaces you will encounter are Hausdorff and second countable. So there is no need to count the nuances of separability and second countability.

\begin{proof}
Let $Y=\Rbb^N$. As in the proof of Thm. \ref{lb509}, $\ovl{\scr A}=\Cl_{C(X,Y)}(\scr A)$ is equicontinuous and pointwise bounded. Let $(f_\alpha)$ be a net in $\ovl{\scr A}$. Since $X$ is separable, we can choose a countable dense subset $E\subset X$. For each $p\in E$, $\ovl{\scr A}(p)$ is contained in a compact $K_p\subset Y$. By the countable Tychonoff theorem (whose proof does not rely on Zorn's lemma, see Thm. \ref{lb89} or Pb. \ref{lb241}), $\prod_{p\in E}K_p$ is compact. Therefore, $(f_\alpha)$ has a subnet $(f_\beta)$ converging pointwise on $E$. Since $\ovl{\scr A}$ is equicontinuous, so is $(f_\beta)$. Therefore, by Prop. \ref{lb511}, $(f_\beta)$ converges pointwise on $X$ to some $f\in C(X,Y)$. So $f\in\Cl_{C(X,Y)}(\ovl{\scr A})=\ovl{\scr A}$. This proves that $\ovl{\scr A}$ is compact.
\end{proof}

\begin{rem}
Claim \ref{lb510} and its proof can be compared with Pb. \ref{lb501}. In particular,  Prop. \ref{lb500} plays the same role in the solution of Pb. \ref{lb501} as Prop. \ref{lb511} does in the proof of Claim \ref{lb510}. In both situations, if one wants to prove the separable case without using Zorn's lemma, one needs an extra analytic step to pass from a dense subset to the original space. 
\end{rem}


\begin{rem}
The readers may wonder why I often give two proofs of the same theorem, one using Zorn's lemma, which applies to a (slightly) larger setting and is somewhat simpler, and the other not using Zorn's lemma, but requires more extra steps. I have mentioned that Zorn's lemma is equivalent to the axiom of choice. However, whether or not to accept the axiom of choice is a matter of taste (or faith). After all, both the statements and the proof of Zorn's lemma are very hard to understand intuitively (at least to me).  

Nowadays, most mathematicians accept it because it often simplifies proofs and theories, it often proves theorems for a larger class of examples, and it is compatible with the theorems proved without using it. Therefore, the more theorems that can be proved both with and without Zorn's lemma, the more reason there is to believe in Zorn's lemma/axiom of choice. If there is any way to understand Zorn's lemma intuitively, it is to compare a proof using Zorn's lemma with a proof of the same theorem without using it, as we did in Sec. \ref{lb513} and Ch. \ref{lb512} and continue to do in this chapter.   \hfill\qedsymbol
\end{rem}










\subsubsection{Precompactness under uniform convergence topology}

In the last subsection, we see that equicontinuity implies precompactness under the pointwise convergence topology. The converse is not necessarily true. In this section, we will see that under reasonable assumptions, equicontinuity is equivalent to precompactness under the uniform convergence topology.


\begin{thm}\label{lb515}
Let $X$ be a topological space. Let $\mc V$ be a Banach space. Equip $C(X,\mc V)$ with the uniform convergence metric. Let $\scr A$ be a precompact subset of $C(X,\mc V)$. Then $\scr A$ is equicontinuous.
\end{thm}

\begin{proof}[First proof]
It suffices to prove that $\ovl{\scr A}$ is equicontinuous. Thus, by replacing $\scr A$ with $\ovl{\scr A}$, we assume that $\scr A$ is compact (under the uniform convergence metric).

Let us prove the equicontinuity of $\scr A$ at any $x\in X$. Choose any $\eps>0$. For each $f\in\scr A$, let $U_f$ be the open ball centered at $f$ with radius $\eps$, i.e.
\begin{align*}
W_f=\big\{g\in C(X,\mc V):\Vert g-f\Vert_{l^\infty(X,\mc V)}<\eps\big\}
\end{align*}
Since $\scr A$ is compact, there is a finite subset $\mc E\subset\scr A$ such that $\scr A\subset\bigcup_{f\in\mc E}W_f$. Since each $f\in\mc E$ is continuous at $x$, and since $\mc E$ is finite, there exists $U\in\Nbh_X(x)$ such that $\diam(f(U))<\eps$ for all $f\in\mc E$. Therefore, for each $g\in\scr A$, choose $f\in\mc E$ such that $g\in U_f$. Then since $\diam (f(U))<\eps$ for that particular $f$, by triangle inequality, we have $\diam (g(U))<3\eps$. Thus $\sup_{g\in\scr A}\diam(g(U))\leq 3\eps$. Since $\eps$ can be arbitrary, we conclude that $\scr A$ is equicontinuous at $x$.
\end{proof}



\begin{proof}[Second proof]
This is a fancy proof, just for entertainment. Again, we assume WLOG that $\scr A$ is compact. Consider the inclusion map $\scr A\mapsto C(X,\mc V)$ (sending $f$ to $f$). By Thm. \ref{lb274}, it can be viewed as a continuous map
\begin{gather*}
X\times\scr A\rightarrow \mc V\qquad (x,f)\mapsto f(x)
\end{gather*}
Since $\scr A$ is compact, by Thm. \ref{lb274}, the above map can be viewed as a continuous map
\begin{align*}
\Phi:X\rightarrow C(\scr A,\mc V)
\end{align*}
where for each $x\in X$, $\Phi(x):\scr A\rightarrow \mc V$ sends $f$ to $f(x)$. By enlarging the codomain of $\Phi$, we can view $\Phi$ as a map $X\rightarrow \mc V^{\scr A}$ where $\mc V^{\scr A}$ is equipped with the uniform convergence topology. The continuity of $\Phi$ means, by the very definition of equicontinuity (cf. Def. \ref{lb514}), that $\scr A$ is equicontinuous.
\end{proof}



\begin{thm}[\textbf{Arzel\`a-Ascoli (AA) theorem}]\index{00@Arzel\`a-Ascoli (AA) theorem} \label{lb516}
Let $X$ be a compact topological space. Equip $C(X,\Rbb^N)$ with the uniform convergence topology. Let $\scr A$ be a subset of $C(X,\Rbb^N)$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $\scr A$ is a precompact subset of $C(X,\Rbb^N)$.
\item $\scr A$ is pointwise bounded and equicontinuous.
\end{enumerate}
\end{thm}

%Note that ``uniformly bounded" means that $\sup_{f\in\scr A}\Vert f\Vert_\infty<+\infty$, or equivalently, that $\bigcup_{x\in X}\scr A(x)$ is bounded. 


\begin{proof}
Assume (1). For each $x\in X$, since the map $f\in\scr A\mapsto f(x)$ is continuous and $\scr A$ is compact, by the extreme value theorem, we have $\sup_{f\in\scr A}\Vert f(x)\Vert<+\infty$. So $\scr A$ is pointwise bounded. By Thm. \ref{lb515}, $\scr A$ is equicontinuous.

Assume (2). Write $Y=\Rbb^N$. Note that the uniform convergence topology is metrizable. Thus, to prove (1), by Prop. \ref{lb505} it suffices to choose an arbitrary net $(f_\alpha)$ in $\scr A$ and show that it has a cluster point in $C(X,Y)$. By Thm. \ref{lb509}, $\scr A$ is precompact under the pointwise convergence topology. So $(f_\alpha)$ has a subnet $(f_\beta)$ converging pointwise to some $f\in C(X,Y)$. Since $X$ is compact and $(f_\beta)$ is equicontinuous, by Cor. \ref{lb284}, $(f_\beta)$ converges uniformly to $f$. 
\end{proof}


In the next chapter, we will use the AA theorem to study differential equations. See Thm. \ref{lb557}.


\begin{rem}
The proof of AA theorem relies on Thm. \ref{lb509}, and hence in turn relies on Zorn's lemma. If $X$ is separable, then AA theorem does not rely on Zorn's lemma since Thm. \ref{lb509} does not (cf. Claim \ref{lb510}).
\end{rem}

\begin{srem}
One may wonder if AA theorem still holds when $\Rbb^N$ is replaced by an arbitrary normed vector space $\mc V$ (or even a metric space). In fact, in this case, if we assume that $\scr A$ is \textbf{pointwise precompact} (i.e., for each $x\in X$, $\scr A(x)$ is precompact in $\mc V$), then Thm. \ref{lb509} still holds, as one can check by reading the proof of Thm. \ref{lb509}. Therefore, AA theorem also holds if ``pointwise bounded" is replaced by ``pointwise precompact". However, in most applications, $\mc V$ is $\Rbb^N$.
\end{srem}

%% Record #26 2023/12/20 three lectures  65

\subsection{Operator norms and compactness: the Banach-Alaoglu theorem}\label{lb571}


\begin{displayquote}
\small Every interesting topological space is a metric space. Every interesting Banach space is separable. Every interesting real-valued function is Baire/Borel measurable.

\hfill ---- Barry Simon \cite[Preface of Part 1]{Sim-R}
\end{displayquote}


In this section, we fix a normed vector space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$.

We are going to apply the results and methods in Sec. \ref{lb517} to linear maps on $V$. Note that if $W$ is a normed vector space over $\Fbb$, the operator norm on $\fk L(V,W)$ is defined to be $\Vert T\Vert=\Vert T\Vert_{l^\infty(\ovl B_V(0,1),W)}$. Therefore, if $(T_\alpha)$ is a net in $\fk L(V,W)$ and $T\in\fk L(V,W)$, then
\begin{align}
\lim_\alpha \Vert T_\alpha-T\Vert=0\qquad\Longleftrightarrow\qquad T_\alpha\rightrightarrows T\text{ on }\ovl B_V(0,1) 
\end{align}
In other words, \uline{operator norms describe the uniform convergence of linear maps on the closed unit balls}.

To apply the results in the last section, we must let $W$ be $\Fbb^N$. Let us consider the case $W=\Fbb$. Then $\fk L(V,\Fbb)=V^*$. The closed unit ball $\ovl B_V(0,1)$ is not compact unless when $V$ is finite dimensional. (See Thm. \ref{lb565}.) We have seen such an example in Exp. \ref{lb518} where $V=C([0,1],\Rbb)$. Therefore, the Arzel\`a-Ascoli theorem is not available. Thus, one cannot expect general compactness in $V^*$ if the topology on $V^*$ is the uniform  convergence topology on $\ovl B_V(0,1)$, i.e. the topology induced by the operator norm. To get compactness in $V^*$, one must consider the pointwise convergence topology.



\subsubsection{Weak-* topology and Banach-Alaoglu theorem}


\begin{df}\label{lb625}
The topology on $V^*=\fk L(V,\Fbb)$ inherited from the product topology on $\Fbb^V$ is called the \textbf{weak-* topology}. \index{00@Weak-* topology} A net $(\varphi_\alpha)$ in $V^*$ is said to \textbf{converge weak-*} to $\varphi\in V^*$ if $(\varphi_\alpha)$ converges to $\varphi$ under the weak-* topology, equivalently, if $(\varphi_\alpha)$ converges pointwise to $\varphi$ when viewed as functions $V\rightarrow\Fbb$. By contrast, the \textbf{norm topology} \index{00@Norm topology} (cf. Def. \ref{lb529}) on $V^*$ is the topology induced by the (operator) norm of $V^*$.
\end{df}

Note that since $\ovl B_V(0,1)$ spans $V$, a net of linear maps converges pointwise on $V$ iff it converges pointwise on $\ovl B_V(0,1)$. Therefore, the weak-* topology is also the one induced by the product topology on $\Fbb^{\ovl B_V(0,1)}$.


We first prove the normed vector space version of Prop. \ref{lb511}.


\begin{pp}\label{lb520}
Let $V$ and $W$ be normed vector spaces over $\Fbb$ where $W$ is a Banach space. Let $M\in\Rbb_{\geq0}$, and let $(T_\alpha)$ be a net in $\fk L(V,W)$ such that $\Vert T_\alpha\Vert\leq M$ for all $\alpha$. Let $E$ be a subset of $V$ spanning a dense subspace of $V$. Assume that $(T_\alpha)$ converges pointwise on $E$. Then $(T_\alpha)$ converges pointwise on $V$ to some $T\in\fk L(V,W)$ satisfying $\Vert T\Vert\leq M$.
\end{pp}

It follows that if $(T_\alpha)$ also converges pointwise on $E$ to some $T'\in\fk L(V,W)$, then $(T_\alpha)$ converges pointwise on $V$ to $T'$. (This is because both $T$ and $T'$ are bounded linear, and they are equal on the dense subset $\Span_\Fbb E$ of $V$. So $T=T'$.)

\begin{proof}
By assumption, $F=\Span_\Fbb E$ is dense in $V$. By linearity, $(T_\alpha)$ converges pointwise on $F$. By Prop. \ref{lb313}, $(T_\alpha)$ has uniform Lipschitz constant $M$. So $(T_\alpha)$ is an equicontinuous net. By Prop. \ref{lb511} and the completeness of $W$, $(T_\alpha)$ converges pointwise on $V$ to $T\in C(V,W)$.

For each $u,v\in V,a,b\in\Fbb$ we have
\begin{align*}
T(au+bv)=\lim_\alpha T_\alpha(au+bv)=\lim_\alpha (a T_\alpha(u)+b T_\alpha(v))=a T(u)+b T(v)
\end{align*}
So $T$ is linear. For each $v\in V$, since $\Vert T_\alpha(v)\Vert\leq \Vert T_\alpha\Vert\cdot\Vert v\Vert\leq M \Vert v\Vert$, we have
\begin{align*}
\Vert T(v)\Vert=\lim_\alpha\Vert T_\alpha(v)\Vert\leq M\Vert v\Vert
\end{align*}
So $\Vert T\Vert\leq M$ by Rem. \ref{lb372}.
\end{proof}


Roughly speaking, Prop. \ref{lb520} says that if a net of bounded linear operators have a uniform upper bound for their operator norms, then pointwise convergence on a dense subset (or more generally, on a subset spanning a dense subspace) implies pointwise convergence on the whose space. The assumption on the uniform upper bound cannot be removed:
\begin{eg}
For each $n\in\Zbb_+$, define $T_n:l^1(\Zbb_+,\Rbb)\rightarrow\Rbb$ sending each $f$ to $n^3f(n)$. Let $E=\{\chi_{\{k\}}:k\in\Zbb_+\}$. Then $E$ spans a dense subspace of $l^1(\Zbb_+,\Rbb)$. For each $k\in\Zbb_+$ we have $\lim_n T_n\chi_{k}=0$. However, $\Vert T_n\Vert=n^3$ has no uniform upper bounds. Define $f\in l^1(\Zbb_+,\Rbb)$ by $f(n)=n^{-2}$. Then $T_nf=n$ does not converge in $\Rbb$ as $n\rightarrow\infty$. So $(T_n)$ does not converge pointwise on $l^1(\Zbb_+,\Rbb)$, although it converges pointwise on $E$ (and hence on $\Span E$) to $0$.
\end{eg}



The following Banach-Alaoglu theorem can be viewed as the normed vector space version of Thm. \ref{lb509}.

\begin{thm}[\textbf{Banach-Alaoglu theorem}]\index{00@Banach-Alaoglu theorem}\label{lb519}
$\ovl B_{V^*}(0,1)$ is \textbf{weak-* compact}, \index{00@Weak-* compact} i.e., it is compact under the weak-* topology. 
\end{thm}

By our notations, $\ovl B_{V^*}(0,1)$ is the set of all $\varphi\in V^*$ satisfying $\Vert\varphi\Vert\leq 1$. Note that weak-* topology is clearly Hausdorff.

\begin{proof}
Let $\scr A=\ovl B_{V^*}(0,1)$. Since elements in $\scr A$ have operator norms $\leq 1$, they have Lipschitz constant $1$ by Prop. \ref{lb313}. So $\scr A$ is equicontinuous on $V$. For each $v\in V$, $\scr A(v)$ is bounded since $\scr A(v)\subset\ovl B_\Fbb(0,\Vert v\Vert)$. Thus, by Thm. \ref{lb509}, $\scr A$ has compact closure in $C(V,\Fbb)$ under the pointwise convergence topology. Therefore, to show that $\scr A$ is compact, it suffices to show that $\scr A$ is closed in $C(V,\Fbb)$. Let $(\varphi_\alpha)$ be a net in $\scr A$ converging pointwise to $\varphi\in C(V,\Fbb)$. By Prop. \ref{lb520}, $\varphi\in V^*$ and $\Vert\varphi\Vert\leq 1$. So $\scr A$ is closed.
\end{proof}


\begin{rem}\label{lb525}
Similar to Arzel\`a-Ascoli theorem, the proof of the Banach-Alaoglu theorem relies on Thm. \ref{lb509}, and hence relies on Zorn's lemma. If $V$ is a separable normed vector space, the Banach-Alaoglu theorem does not rely on Zorn's lemma because the proof of Thm. \ref{lb509} does not, cf. Claim \ref{lb510}.
\end{rem}







\subsubsection{Application: embedding into $C(X,\Fbb)$}

Recall that $V$ is a normed vector space over $\Fbb$.





\begin{thm}\label{lb521}
There is a compact Hausdorff space $X$ and a linear isometry $\Phi:V\rightarrow C(X,\Fbb)$. Moreover, if $V$ is separable, then $X$ can be chosen to be metrizable.\footnote{In fact, every separable normed vector space can be embedded into $C([0,1],\Fbb)$. This is called the \textbf{Banach-Mazur theorem}, whose proof is more involved. Cf. \cite[Sec. 1.4]{AK}.} 
\end{thm}

In other words, $V$ is isomorphic to a linear subspace of $C(X,\Fbb)$ (namely, $\Phi(V)$). Clearly, if $V$ is Banach, then $\Phi(V)$ is complete and hence closed. So each Banach space is isomorphic to a closed linear subspace of $C(X,\Fbb)$ for some $X$.

A similar embedding for metric spaces is given in Pb. \ref{lb537}.

\begin{proof}
We let $X=\ovl B_{V^*}(0,1)$, equipped with the weak-* topology. By Banach-Alaoglu, $X$ is a compact Hausdorff space. The linear map $\Phi:V\rightarrow C(X,\Fbb)$ is defined by sending each $v$ to the function
\begin{align*}
\Phi(v):X\rightarrow \Fbb\qquad\varphi\mapsto \bk{\varphi,v}
\end{align*}
To check the continuity of $\Phi(v):X\rightarrow\Fbb$, we let $(\varphi_\alpha)$ be any net in $X$ converging weak-* to $\varphi\in X$. Then $\Phi(v)(\varphi_\alpha)=\bk{\varphi_\alpha,v}$ converges to $\bk{\varphi,v}=\Phi(v)(\varphi)$, proving that $\Phi(v)$ is continuous.

Let $v\in V$. For each $\varphi\in X$, we have
\begin{align*}
|\bk{\Phi(v),\varphi}|=|\bk{\varphi,v}|\leq\Vert\varphi\Vert\cdot\Vert v\Vert=\Vert v\Vert
\end{align*}
This proves that $\Vert \Phi(v)\Vert_{l^\infty(X,\Fbb)}\leq \Vert v\Vert$. (Recall Rem. \ref{lb372}.) By Hahn-Banach Cor. \ref{lb502}, there is $\varphi\in X$ with $\Vert\varphi\Vert=1$ such that $\bk{\varphi,v}=\Vert v\Vert$. Thus $\Vert \Phi(v)\Vert_{l^\infty(X,\Fbb)}=\Vert v\Vert$. This proves that $\Phi$ is a linear isometry.

Suppose that $V$ is separable. Then we can find a sequence $(v_n)_{n\in\Zbb_+}$ dense in $V$.  It is clear that $\Phi(V)$ separates points of $X$. So $\Phi(v_1),\Phi(v_2),\dots$ separate points of $X$.
Therefore,
\begin{align}
X\rightarrow S=\Fbb^{\Zbb_+}\qquad \varphi\mapsto \big(\Phi(v_n)(\varphi)\big)_{n\in\Zbb_+}
\end{align} 
is a continuous injective map of $X$ into $S$. Since $X$ is compact, $X$ is homeomorphic to $\Phi(X)$. Since $S$ is metrizable, so is $X=\ovl B_{V^*}(0,1)$.
\end{proof}


As an immediate consequence of the above proof we have:

\begin{thm}\label{lb523}
$V$ is separable iff $\ovl B_{V^*}(0,1)$ is metrizable (under the weak-* topology).
\end{thm}

Recall Thm. \ref{lb482} for equivalent descriptions of metrizable compact Hausdorff spaces. In fact, Thm. \ref{lb523} is closely related to Thm. \ref{lb482}, since the relationship between $V$ and $\ovl B_{V^*}(0,1)$ is similar to that between $C(X,\Rbb)$ and $X$, as implied by the proof of Thm. \ref{lb521}. 

\begin{proof}
The proof of Thm. \ref{lb521} shows that if $V$ is separable then $X=\ovl B_{V^*}(0,1)$ is metrizable. Conversely, assume that $X$ is metrizable. The proof of Thm. \ref{lb521} shows that $V$ is isomorphic to a linear subspace of $C(X,\Rbb)$. By Thm. \ref{lb482}, $C(X,\Rbb)$ is second countable. So $V$ is second countable, equivalently, separable.
\end{proof}

\begin{rem}
It follows from Thm. \ref{lb523} that if $V$ is separable then $\ovl B_{V^*}(0,1)$ is sequentially compact. In history, at a time when sequential compactness was still the primary way for people to understand compactness, there were good reasons for studying the sequential compactness of $\ovl B_{V^*}(0,1)$. This is because early examples of Banach spaces that people focused on were separable. 
\end{rem}

\begin{rem}
A typical example of a non-separable Banach space is $l^\infty(\Zbb,\Fbb)$, cf. Pb. \ref{lb567}. Precisely for this reason, the dual space of $l^\infty(\Zbb,\Fbb)$ is not much studied, and the norm topology on $l^\infty(\Zbb,\Fbb)$ is not good enough. The weak-* topology on (the unit ball of) $l^\infty(\Zbb,\Fbb)$ is more natural since, given the equivalence $l^1(\Zbb,\Fbb)^*\simeq l^\infty(\Zbb,\Fbb)$ (cf. Thm. \ref{lb527}) and the separability of $l^1(\Zbb,\Fbb)$, the closed unit ball of $l^\infty(\Zbb,\Fbb)$ is weak-* metrizable (equivalently, secound countable).\footnote{If $V$ is infinite dimensional, the weak-* topology of $V^*$ is indeed not first countable, and hence is neither metrizable nor second countable. \textit{Therefore}, the weak-* topology of $\ovl B_{V^*}(0,1)$ is more natural than that of $V^*$.} In the study of modern analysis, it is helpful to keep in mind the following two principles:
\begin{itemize}
\item Metrizability and second-countability are tests for whether or not a topological space is natural (e.g. whether or not it is reasonable from a natural science point of view% \footnote{For example, almost all topological vector spaces or their meaningful subsets related to quantum physics are metrizable and second countable.}
).
\item However, proving theorems only for metrizable and second-countable spaces will actually make the theory more complicated. It is mainly for the purpose of simplifying the theory (e.g. making the assumptions in the theorems shorter) that we prove the theorems in general, regardless of whether a topological space is metrizable/second-countable or not.\footnote{For example, the fact that $(l^1)^*\simeq l^\infty$ shows that separability is not closed under taking dual. Thus, if we stick to separable Banach spaces, the use of Hahn-Banach and Banach-Alaoglu will be more restricted (e.g. when discussing the relationship between $V$ and $V^{**}$, see Hahn-Banach Cor. \ref{lb502} and Goldstine's Thm. \ref{lb568}).}
\end{itemize}
In Rem. \ref{lb569}, I will say more about the significance of Thm. \ref{lb523}.
\end{rem}




\subsection{Banach-Alaoglu for $L^p$ and $l^p$ spaces}


So far, we have discussed $V^*$ and its weak-* topology on a very abstract level. In the following, we shall understand the results proved in Sec. \ref{lb571} in a more concrete setting.

\subsubsection{Weak-* topology in context}

Let $1<p\leq +\infty$ and $1\leq q<+\infty$ satisfy $\frac 1p+\frac 1q=1$. Let $I$ be an interval in $\Rbb$. Let $L^p(I)$ be the set of Lebesgue measurable functions \footnote{Lebesgue measurable functions are more general than Riemann integrable functions. We will discuss them in the next semester. To understand the material of this section, it is not important to know the precise meaning of them.} $f\rightarrow\Cbb$ satisfying that the \textbf{$L^p$-(semi)norm} $\Vert f\Vert_p=\sqrt[p]{\int_0^1 |f|^p}$ is finite. A remarkable \textbf{representation theorem} of F. Riesz says that we have an (isometric) isomorphism of Banach spaces
\begin{align*}
\Phi:L^p(I)\rightarrow L^q(I)^*
\end{align*}
such that for each $f\in L^p(I)$, $\Phi(f)$ is the linear map sending each $g\in L^q(I)$ to
\begin{align*}
\bk{\Phi(f),g}=\int fg
\end{align*}
Therefore, if $(f_\alpha)$ is a net in $L^p(I)$ and $f\in L^p(I)$, then $(f_\alpha)$ converges weak-* to $f$ (more precisely, $(\Phi(f_\alpha))$ converges weak-* to $\Phi(f)$) iff $\lim_\alpha\int_I f_\alpha g=\int_I fg$ for all $g\in L^q(I)$. 

In fact, when $I=[-\pi,\pi]$, using the $l^\infty$-density of $\Span\{e^{\im nx}:n\in\Zbb\}$ in $C([-\pi,\pi])$ (Exp. \ref{lb443}), it can be proved that if $(f_\alpha)$ is a net in $L^p([-\pi,\pi])$ satisfying $\sup_\alpha \Vert f_\alpha\Vert_p<+\infty$, then $(f_\alpha)$ converges weak-* to $f\in L^p([-\pi,\pi])$ iff
\begin{align*}
\lim_\alpha \int_{-\pi}^\pi f_\alpha(x)e^{-\im nx}dx=\int_{-\pi}^\pi f(x)e^{-\im nx}dx
\end{align*}
i.e., iff the Fourier coefficients of $(f_\alpha)$ converge to the corresponding ones of $f$.

\begin{rem}\label{lb569}
Let me discuss the importance of Thm. \ref{lb523} in the context of $L^p$ spaces. As we will see in the future, Lebesgue measure (and measure theory in general) is not very compatible with net convergence. The main reason is that measure theory is countable by nature, as one can feel in Sec. \ref{lb522}. For example, the pointwise limit of a sequence of Lebesgue measurable functions is Lebesgue measurable, but the pointwise limit of a net of measurable functions is not necessarily so. Lebesgue's dominated convergence theorem, a powerful theorem about the commutativity of limits and integrals, applies only to sequences but not nets of functions. 

However, it is true that $L^q(I)$ is separable. Therefore, by Thm. \ref{lb523}, the closed unit ball of $L^p(I)$ is a metrizable compact space under the weak-* topology. Therefore, to study the weak-* convergence for functions $f\in L^p(I)$ satisfying $\Vert f\Vert_p\leq 1$, it suffices to use sequences instead of nets, because metrizable topologies and their compactness are determined by sequential convergence. Therefore, one can use all the results in measure theory to study the weak-* topology on $\ovl B_{L^p(I)}(0,1)$.  \hfill\qedsymbol
\end{rem}

\subsubsection{Weak-* topology on $l^p$ spaces}

Let $\Fbb\in\{\Rbb,\Cbb\}$, and let $X$ be a set. Recall that $1<p\leq +\infty$ and $1\leq q<+\infty$ satisfy $\frac 1p+\frac 1q=1$. 

In this subsection, we prove that the linear isometry $\Psi$ in Thm. \ref{lb369} is surjective, thus establishing the isomorphism $l^p(X,\Fbb)\simeq l^q(X,\Fbb)^*$. Using this isomorphism, we give a concrete (and historically important) description of weak-* topology on the norm-bounded subsets of $l^p(X,\Fbb)$. We introduce a temporary notation
\begin{align}
\mc S(X,\Fbb)=\{f\in\Fbb^X:f=0\text{ except at finitely many points}\}
\end{align}
Then $\mc S(X,\Fbb)$ is clearly a subspace of $l^q(X,\Fbb)$.


\begin{lm}\label{lb528}
$\mc S(X,\Fbb)$ is dense in $l^q(X,\Fbb)$ under the $l^q$-norm.
\end{lm}

\begin{proof}
Let $f\in l^q(X,\Fbb)$. Then $\lim_{A\in\fin(2^X)}\sum_A|f|^q=\sum_X |f|^q<+\infty$. Thus, for every $\eps>0$ there is $A\in\fin(2^X)$ such that $\sum_{X\setminus A}|f|^q<\eps^q$, and hence $\Vert f-f\chi_A\Vert_q<\eps$. This finishes the proof, since $f\chi_A\in\mc S(X,\Fbb)$.
\end{proof}


\begin{exe}
Show that $\mc S(X,\Fbb)$ is not dense in $l^\infty(X,\Fbb)$ if $X$ is an infinite set.
\end{exe}

\begin{thm}\label{lb527}
The linear isometry
\begin{gather*}
\Psi:l^p(X,\Fbb)\rightarrow l^q(X,\Fbb)^*\\
\bk{\Psi(f),g}=\sum_{x\in X}f(x)g(x)
\end{gather*}
in Thm. \ref{lb369} is an isomorphism of Banach spaces.
\end{thm}

In the special case that $p=2$, Thm. \ref{lb527} is called the \textbf{Riesz-Fr\'echet representation theorem}. \index{00@Riesz-Fr\'echet representation theorem} Recall that we are assuming $1<p\leq+\infty$ in this theorem. When $X$ is infinite and $p=1$, $\Psi$ is not surjective. See Pb. \ref{lb532} for details.

%% Record #27 2023/12/25 two lectures  67

\begin{proof}
It remains to prove that $\Psi$ is surjective. Choose a nonzero bounded linear $\Lambda:l^q(X,\Fbb)\rightarrow\Fbb$. We want to show that $\Lambda$ is in the range of $\Psi$. By scaling $\Lambda$ we assume for simplicity that $\Vert\Lambda\Vert=1$.  Define 
\begin{align}
f:X\rightarrow\Fbb\qquad  f(x)=\bk{\Lambda,\chi_{\{x\}}}
\end{align}
Let us prove that $f\in l^p(X,\Fbb)$. If $p=+\infty$, then $|f(x)|\leq \Vert\Lambda\Vert\cdot\Vert\chi_{\{x\}}\Vert_q=1$, and hence $\Vert f\Vert_\infty\leq 1$. Assume $p<+\infty$. We understand $\ovl f(x)/|f(x)|$ as $0$ if $f(x)=0$. Choose any $A\in\fin(2^X)$. Define $g:X\rightarrow\Fbb$ to be $g=(\ovl f/|f|)\cdot |f|^{p-1}\chi_A$. Then clearly $g\in l^q(X,\Fbb)$. We compute
\begin{align*}
\bk{\Lambda,g}=\bigbk{\Lambda,\sum_{x\in A}g(x)\chi_{\{x\}}}=\sum_{x\in A}g(x)\bk{\Lambda,\chi_{\{x\}}}=\sum_{x\in A}f(x)g(x)=\sum_A|f|^p
\end{align*}
On the other hand,
\begin{align*}
\Vert g\Vert_q=\Big(\sum_A|f|^p \Big)^{1/q}
\end{align*}
Since $|\bk{\Lambda,g}|\leq \Vert\Lambda\Vert\cdot\Vert g\Vert_q=\Vert g\Vert_q$, we obtain $(\sum_A|f|^p)\leq (\sum_A|f|^p)^{1/q}$, and hence 
\begin{align*}
\sum_A |f|^p\leq 1
\end{align*}
Applying $\lim_{A\in\fin(2^X)}$, we get $\Vert f\Vert_p\leq 1$.

Now choose any $g\in l^q(X,\Fbb)$. Since $1\leq q<+\infty$, as in the proof of Lem. \ref{lb528}, it is easy to see that $\sum_{x\in X}g(x)\chi_{\{x\}}=\lim_{A\in\fin(2^X)}\sum_{x\in A}g(x)\chi_{\{x\}}$ converges to $g$ (under the $l^q$-norm). Thus, since $\Lambda$ is continuous, we have
\begin{align*}
&\bk{\Lambda,g}=\Bigbk{\Lambda,\lim_{A\in\fin(2^X)}\sum_{x\in A}g(x)\chi_{\{x\}}}=\lim_{A\in\fin(2^X)}\sum_{x\in A}\Bigbk{\Lambda,g(x)\chi_{\{x\}}}\\
=&\lim_{A\in\fin(2^X)}\sum_{x\in A}f(x)g(x)=\sum_X fg
\end{align*}
This proves that $\Psi(f)=\Lambda$.
\end{proof}

We are now able to give an explicit characterization of the weak-* topology on \uwave{norm-bounded subsets} (e.g. the unit ball) of $l^p(X,\Fbb)$.

\begin{thm}\label{lb530}
Let $(f_\alpha)$ be a net in $l^p(X,\Fbb)$ satisfying $\sup_\alpha\Vert f_\alpha\Vert_p<+\infty$, and let $f\in l^p(X,\Fbb)$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $(f_\alpha)$ converges weak-* to $f$. (More precisely, $(\Psi(f_\alpha))$ converges weak-* to $\Psi(f)$.)
\item $(f_\alpha)$ converges pointwise to $f$ as functions $X\rightarrow\Fbb$.
\end{enumerate}
\end{thm}

We warn the reader that (1) is not equivalent to (2) if $\sup_\alpha\Vert f_\alpha\Vert_p=+\infty$.

\begin{proof}
For each $x\in X$ we have $f_\alpha(x)=\bk{\Psi(f_\alpha),\chi_{\{x\}}}$ and $f(x)=\bk{\Psi(f),\chi_{\{x\}}}$. Therefore, (2) is equivalent to that $\Psi(f_\alpha)$ converges to $\Psi(f)$ when acting on each $\chi_{\{x\}}$.  Since $\Psi$ is an isometry, $\sup_\alpha \Vert\Psi(f_\alpha)\Vert=\sup_\alpha\Vert f_\alpha\Vert_p<+\infty$. Therefore, by Prop. \ref{lb520}, (2) is equivalent to that $\Psi(f_\alpha)$ converges pointwise on $l^q(X,\Fbb)$ to $\Psi(f)$, because functions of the form $\chi_{\{x\}}$ span $\mc S(X,\Fbb)$, a norm-dense subspace of $l^q(X,\Fbb)$ due to Lem. \ref{lb528}.
\end{proof}


\begin{rem}
Weak-* convergence and the Banach-Alaoglu theorem were first studied for (the closed unit ball of) $l^2(\Zbb,\Fbb)$ by Hilbert in his study of integral equations and eigenvalue problem (cf. Ch. \ref{lb310}). Of course, Hilbert didn't have the modern definition of weak-* topology. For him, the weak-* convergence on the unit ball simply means condition (2) of Thm. \ref{lb530}. Taking Thm. \ref{lb530}-(2) as the definition of weak-* convergence, the Banach-Alaoglu theorem can be proved quite easily for $l^2(\Zbb,\Fbb)$ (cf. Pb. \ref{lb531}). Therefore, as with many abstract definitions, the notion of weak-* topology has its origins in very concrete forms of expression. 
\end{rem}

After Hilbert's study of $l^2$ spaces (a.k.a. Hilbert spaces), F. Riesz generalized weak-* topology and Banach-Alaoglu theorem to $l^p$ and $L^p$ spaces for arbitrary $1<p\leq+\infty$, as we shall see in the next section.









\subsection{The birth of operator norms: moment problems}\label{lb543}

It can be said that F. Riesz made the first crucial contribution to the notion of dual spaces of Banach spaces. According to Riesz, bounded linear functionals on $L^q(I)$ (when $1<q<+\infty$ and $I$ is an interval in $\Rbb$) are nothing abstract. They are simply elements of $L^p(I)$. But what is the advantage of viewing $f\in L^p(I)$ not only as a function on $I$, but also as a linear functional on $L^q(I)$? Why was Riesz interested in characterizing $L^q(I)^*$ at all?


In fact, Riesz's study of dual spaces is related to the \textbf{moment problems} which have applications to probability. In his 1910 paper \cite{Rie10}, Riesz studied the following type of moment problem: Let $g_1,g_2,\dots$ be a sequence in $L^q(I)$, let $c_1,c_2,\dots\in\Cbb$, and find some $f\in L^p(I)$ such that
\begin{align}
\int fg_j=c_j\qquad(\text{for all } j) \label{eq204}
\end{align}
(For example, in the classical moment problem, $g_n(x)=x^n$, and $f$ is understood as a ``probability distribution". Then $\int f(x)xdx=c_1$ is the mean (i.e., expected value) of $f$, and $\int f(x)(x-c_1)^2dx$ is the variance of $f$. The number $c_n=\int f(x)x^ndx$ is called the \textbf{$n$-th moment} of $f$.)


By H\"older's inequality, if such $f$ exists, then there must be some $M\in\Rbb_{\geq0}$ (e.g. $M=\Vert f\Vert_{L^p}$), such that 
\begin{align}\label{eq203}
|a_1c_1+\cdots+a_nc_n|\leq M\cdot \Vert a_1g_1+\cdots+a_ng_n\Vert_{L^q}\qquad(\forall n\in\Zbb_+,a_1,\cdots,a_n\in\Cbb)
\end{align}
Riesz proved that the existence of $M$ satisfying \eqref{eq203} is also a sufficient condition for the existence of $f\in L^p(I)$ satisfying \eqref{eq204}. 

From the modern viewpoint, Riesz's result can be proved in the following way: Let $V$ be spanned by $g_1,g_2,\dots$. By \eqref{eq203}, there exists a unique linear functional $\varphi:V\rightarrow\Cbb$ with operator norm $\leq M$ satisfying $\varphi(g_j)=c_j$ for all $j$. By Hahn-Banach Thm. \ref{lb499}, $\varphi$ can be extended to a bounded linear functional $\varphi:L^q(I)\rightarrow\Cbb$ also with operator norm $\leq M$. Then, by the isomorphism $L^p(I)\simeq L^q(I)^*$, $\varphi$ can be realized by some $f\in L^p(I)$, which is the desired function.


\begin{rem}\label{lb526}
In fact, Riesz didn't find the linear functional $L^q(I)\rightarrow\Cbb$ in this way. He didn't see this problem as extending linear functionals. And Hahn-Banach theorem didn't exist before Riesz solved the moment problem. (Riesz's solution is actually an important motivation for the Hahn-Banach theorem.)

Riesz found $\varphi:L^q(I)\rightarrow\Cbb$ in the following way (cf. \cite[Sec. VI.2]{Die-H}). In the first step, by using complicated methods, he could find $f_n\in L^p(I)$ satisfying $\Vert f_n\Vert_{L^p}\leq M$ and 
\begin{align*}
\int_I f_ng_i=c_i\qquad(\text{for every }1\leq i\leq n)
\end{align*}
In Sec. \ref{lb548}, we will explain more about how to find these $f_n$.

In the second step, Riesz considered $\Phi(f_n):L^q(I)\rightarrow\Cbb$ sending each $g\in L^q(I)$ to $\int f_ng$. Then, for each $j$, we have $\lim_{n\rightarrow\infty}\bk{\Phi(f_n),g_j}=c_j$. Riesz made the following crucial steps:
\begin{itemize}
\item He proved the Banach-Alaoglu theorem for $L^q(I)^*$ using diagonal method. %\footnote{Cf. Rem. \ref{lb524} and \ref{lb525}, and note that $L^q(I)$ is actually separable.} 
Therefore, since $\sup_n \Vert\Phi(f_n)\Vert=\sup_n\Vert f_n\Vert_p\leq M$, one has a subsequence $\Phi(f_{n_k})$  converging weak-* to some $\varphi\in L^q(I)^*$.\footnote{Since $L^q(I)$ is separable, the closed ball of $L^q(I)^*$ with radius $M$ is compact metrizable by Thm. \ref{lb523}, and hence is sequentially compact.}  Then clearly $\bk{\varphi,g_j}=c_j$ for all $j$.\footnote{More precisely, the following is what Riesz did: Using the diagonal method as in the proof of Thm. \ref{lb89}, he found $\Phi(f_{n_k})$ whose evaluations with the elements in a given countable dense subset of $L^q(I)$ converge. Since $\sup_k\Vert\Phi(f_{n_k})\Vert<+\infty$, by Prop. \ref{lb520}, one concludes that $(\Phi(f_{n_k}))$ converges weak-* to some $\varphi\in L^q(I)^*$.}
\end{itemize}
Then $\varphi$ can be represented by some $f\in L^p(I)$ thanks to $L^p(I)\simeq L^q(I)^*$. \hfill\qedsymbol
\end{rem}

Therefore, Riesz's study of moment problems contributed to:
\begin{enumerate}[label=(\alph*)]
\item The discovery of important special cases of Banach-Alaoglu theorem.
\item The realization that \uline{operator norms play an important role in the compactness of dual Banach spaces}.
\item The discovery of $L^p(I)\simeq L^q(I)^*$.
\end{enumerate}
After the work of Riesz, operator norms became a central concept in modern analysis.  


We refer the readers to \cite[Ch. VI]{Die-H} and \cite{NB97} for more details about the relevant history, and to \cite[Sec. 4.17 \& 5.6]{Sim-R} for a modern treatment of moment problems.



\subsection{Operator norms and completeness: functional calculus}\label{lb610}


In this section, all normed vector spaces are over $\Fbb\in\{\Rbb,\Cbb\}$.

That one can do a lot of analysis on the \textit{linear maps} of function spaces is a remarkable fact. In fact, in the early history of functional analysis, people were more interested in \textit{nonlinear} functionals on function spaces, for example, the expression $S(f)$ in the calculus of variations (cf. \eqref{eq24}), for which one searched for the extreme values. The problem of finding extreme values is almost trivial if the functional $S$ is linear and defined on a vector space of functions. Even Hilbert studied the eigenvalue problem for the integral operator $(Tf)(x)=\int_0^1 K(x,y)f(x)dx$ (cf. Ch. \ref{lb672}) by transforming it to the extreme value problem of the functional $S(f)=\eqref{eq206}$ defined for all $f$ on the closed unit ball of $L^2([0,1],\Cbb)$, viewing $S(f)$ as an (infinite-dimensional) \textbf{quadratic form}.


The idea of operator norms was implicit in Hilbert's study of  boundedness of sesquilinear/quadratic forms. (See Subsec. \ref{lb643}.) But it was Riesz who gave the first systematic study of \textbf{operator norms}. Riesz used operator norms mainly in the following two cases:
\begin{enumerate}[label=(\arabic*)]
\item Bounded linear maps $V\rightarrow\Fbb$. By Banach-Alaoglu, one can use the operator norm to get a weak-* \uwave{compact} set $\ovl B_{V^*}(0,1)$. This has been discussed in previous sections.
\item Bounded linear maps $V\rightarrow V$. As we will see below, the operator norm makes $\fk L(V):=\fk L(V,V)$ a Banach space which is compatible with its $\Fbb$-algebra structure. Namely, $\fk L(V)$ is a \textbf{Banach algebra}. Here, the crucial analytic property is \uwave{completeness} rather than compactness. 
\end{enumerate} 
Thus, in these two cases, the operator norms are playing different roles: compactness in the first case, and completeness in the second one. For example, as I will argue in the future, Hilbert and Schmidt noticed the importance of $l^2(\Zbb,\Cbb)$ not so much because of its completeness, but because of the weak-* compactness of its closed unit ball. 

However, these two cases have one thing in common: there is a close relationship between operator norms and \uwave{equicontinuity}. In (1), equicontinuity ensures (pre)compactness. In (2), equicontinuity ensures the convergence of double limits (Thm. \ref{lb227}); see Rem. \ref{lb666} and \ref{lb903} for examples.





\subsubsection{The Banach algebra $\fk L(V)$}


Let me explain the meaning of the statement ``$\fk L(V)$ is a Banach algebra". First, we observe:


\begin{thm}\label{lb540}
Assume that $V$ is a normed vector spaces and $W$ is a Banach space. Recall that $\fk L(V,W)$ is a linear subspace of $W^V$ (cf. Prop. \ref{lb314}). Then $\fk L(V,W)$, equipped with the operator norm, is a Banach space.
\end{thm}

In particular, the dual space $V^*=\fk L(V,\Fbb)$ is a Banach space.

\begin{proof}
By Prop. \ref{lb314}, it remains to prove that $\fk L(V,W)$ is complete. Let $(T_n)$ be a Cauchy sequence in $\fk L(V,W)$. So $\lim_{m,n\rightarrow\infty}\Vert T_m-T_n\Vert=0$. For each $v\in V$, we have $\Vert T_mv-T_nv\Vert\leq \Vert T_m-T_n\Vert\cdot\Vert v\Vert$ which converges to $0$ under $\lim_{m,n}$. So $(T_nv)$ is a Cauchy sequence in $W$, converging to a vector $Tv\in W$. Thus, we have proved that $(T_n)$ converges pointwisely to $T$. Clearly $M:=\sup_{n\in\Zbb_+}\Vert T_n\Vert$ is a finite number. Since $T$ is obviously linear (as in the proof of Prop. \ref{lb520}), and since $\Vert T\xi\Vert=\lim_n\Vert T_n\xi\Vert\leq M\Vert \xi\Vert$ for all $\xi\in V$, we have $T\in\fk L(V,W)$ and $\Vert T\Vert\leq M$. 



Let us prove that $\lim_n\Vert T_n-T\Vert=0$. Since $(T_n)$ is Cauchy, for each $\eps>0$ there exists $K\in\Zbb_+$ such that $\Vert T_n-T_m\Vert\leq\eps$ for all $m,n\geq K$. Thus, for each $\xi\in\ovl B_V(0,1)$ we have $\Vert T_n\xi-T_m\xi\Vert\leq\eps$. Take $m\rightarrow\infty$. Then for each $n\geq K$ we have that $\Vert T_n\xi-T\xi\Vert\leq \eps$ for all $\xi\in\ovl B_V(0,1)$, and hence that $\Vert T_n-T\Vert\leq\eps$. This finishes the proof. 
\end{proof}


\begin{df}
Let $\scr A$ be an $\Fbb$-algebra. Suppose that $\scr A$, as a vector space, is equipped with a norm $\Vert\cdot\Vert$ so that $\scr A$ is a normed vector space, and that
\begin{align}
\Vert xy\Vert\leq\Vert x\Vert\cdot\Vert y\Vert \label{eq208}
\end{align}
for all $x,y\in\scr A$. Then we call $\scr A$ a \textbf{normed algebra} over $\Fbb$. \index{00@Normed algebra} If the norm is complete, we say that $\scr A$ is a \textbf{Banach algebra} \index{00@Banach algebra} over $\Fbb$. A \textbf{unital Banach algebra} \index{00@Unital Banach algebra} is a unital algebra (with unit $\idt$) which is also a Banach algebra and satisfies
\begin{align*}
\Vert\idt\Vert=1
\end{align*}
\end{df}




As mentioned above, the most important reason for considering operator norms on $V^*$ is due to the Banach-Alaoglu theorem. The most important reason for considering operator norms on $\fk L(V)$ is due to the following elementary but important fact:


\begin{thm}
Let $V$ be a Banach space. Then $\fk L(V)$, equipped with the operator norm, is a unital Banach algebra.
\end{thm}

Recall that the multiplication in $\fk L(V)$ is defined by the composition of linear operators.

\begin{proof}
This is immediate from Thm. \ref{lb540} and Prop. \ref{lb541}.
\end{proof}

\begin{pp}\label{lb541}
Let $S:U\rightarrow V$ and $T:V\rightarrow W$ be linear maps of normed vector spaces. Then
\begin{align}
\Vert TS\Vert\leq\Vert T\Vert \cdot\Vert S\Vert  \label{eq207}
\end{align}
\end{pp}


\begin{proof}
For each $u\in U$ we have $\Vert TSu\Vert\leq \Vert T\Vert\cdot \Vert Su\Vert\leq \Vert T\Vert\cdot\Vert S\Vert\cdot\Vert u\Vert$. According to Rem. \ref{lb372}, we get \eqref{eq207}.
\end{proof}


\subsubsection{Power series functional calculus}



The word ``functional calculus" refers in general to the procedure of replacing the variable $x$ or $z$ in the $\Fbb$-valued function $f(x)$ or $f(z)$ by $T$ to get $f(T)$, where $T$ is an element in a unital Banach algebra $T$. The notation $T$ suggests that the most important case is where $T\in\fk L(V)$ for some Banach space $V$. Depending on whether $f$ is a continuous/analytic/integrable/measurable function, $f(T)$ is defined in different ways. Let us consider the simplest case. In the following, we fix a complex unital Banach algebra $\scr A$. (For example, $\scr A=\fk L(V)$ where $V$ is a complex Banach space.)


\begin{comment}
Functional calculus was introduced by Riesz in \cite{Rie13} to the study of spectral theorem of bounded linear operators. See Fig. \ref{lb572} for a summary of historical motivation. The relationship between functional calculus and equicontinuity in Fig. \ref{lb572} will not be explained in this chapter; see Rem. \ref{lb903} for the related history.

\begin{figure}[h]
	\centering

\begin{equation*}
\begin{tikzcd}[row sep=small,column sep=tiny]
\tcboxmath{\text{Banach-Alaoglu}} && \tcboxmath{\text{functional calculus}}\\
\text{moment problems}\arrow[d] && \text{spectral theory}\arrow[d] \\
\begin{array}{c}
\text{infinite dimensional}\\
\text{compactness}
\end{array}
\arrow[d]&
\text{Arzel\`a-Ascoli}\arrow[l,dashed,dash pattern=on 3pt off 3pt] \arrow[ld,dashed,dash pattern=on 3pt off 3pt,shorten=12]
& 
\begin{array}{c}
\text{infinite dimensional}\\
\text{completeness}\\
\&\\
\text{equicontinuity}
\end{array}
\arrow[dd]\\
\text{equicontinuity}
\arrow[d]& &\\
\text{operator norm on $V^*$} && \text{operator norm on $\fk L(V)$}
\end{tikzcd}
\end{equation*}
	\caption{~The motivation in history}
\label{lb572}
\end{figure}
\end{comment}



Let $f(z)=\sum_{n=0}^\infty a_nz^n$ be a power series in $\Cbb$ with radius of convergence $R$. If $T\in\scr A$ and $\Vert T\Vert < R$, we can define
\begin{align}
f(T)=\sum_{n=0}^\infty a_nT^n  \label{eq209}
\end{align}
By \eqref{eq208}, we have $\Vert T^n\Vert\leq \Vert T\Vert^n$. Therefore, by root test, we have $\sum_n |a_n|\cdot \Vert T^n\Vert<+\infty$. So the RHS of \eqref{eq209} converges absolutely, and hence converges in $\scr A$. So \eqref{eq209} makes sense. 


The most important general fact about functional calculus is that $f\mapsto f(T)$ is a homomorhism of unital algebras:

\begin{pp}\label{lb573}
If $f(z)=\sum_n a_nz^n$ and $g(z)=\sum_n b_nz^n$ be power series in $\Cbb$ with radius of convergence $R_1,R_2$. Let $R=\min\{R_1,R_2\}$. If $\scr A$ is a complex unital Banach algebra with unit $\idt$, and if $T\in\scr A$ satisfies $\Vert T\Vert<R$, then for each $a,b\in\Cbb$ we have
\begin{align*}
1(T)=\idt\qquad (af+bg)(T)=af(T)+bg(T)\qquad   (fg)(T)=f(T)g(T)
\end{align*}
\end{pp}


\begin{proof}
The first two equations are obvious. We prove the last one. Let $c_n=\sum_{k=0}^n a_kb_{n-k}$. Then $h(z)=\sum_n c_nz^n$ equals $f(z)g(z)$ on $B_\Cbb(0,R)$. Cor. \ref{lb153} immediately implies $h(T)=f(T)g(T)$.
\end{proof}

Let me give a simple application of Prop. \ref{lb573}. Recall that one can use determinants to prove that the set of $n\times n$ complex matrices is open in $\Cbb^{n\times n}$. However, in the infinite dimensional case one clearly cannot use determinants. Functional calculus provides an easy method to treat this problem.

\begin{eg}\label{lb542}
Let $T\in\scr A$ such that $\Vert T\Vert<1$. Then $1+T$ is invertible.
\end{eg}

\begin{proof}
Let $f(z)=1+z$. Let $g(z)=\sum_{n=0}^\infty (-z)^n$, which has radius of convergence $1$ and equals $(1+z)^{-1}$ when $|z|<1$. Since $fg=gf=1$, by Prop. \ref{lb573} we have $(1+T)S=S(1+T)=1$ if we let $S=g(T)=\sum_{n=0}^\infty T^n$.
\end{proof}


\begin{pp}
The set $\scr A^\times$ of invertible elements is an open subset of $\scr A$.
\end{pp}

\begin{proof}
Let $T\in\scr A$ be invertible. Let $\delta=\Vert T^{-1}\Vert^{-1}$. Then for each $S\in\scr A$ satisfying $\Vert T-S\Vert<\delta$ we have
\begin{align*}
\Vert T^{-1}(S-T)\Vert\leq \Vert T^{-1}\Vert\cdot \Vert S-T\Vert <1
\end{align*}
Thus, by Exp. \ref{lb542}, $1+T^{-1}(S-T)$ is invertible. So its multiplication with $T$ (which is $S$) is invertible.
\end{proof}


Functional calculus is also useful in differential equations, even in the finite dimensional case:


\begin{exe}\label{lb582}
Let $A,B\in\scr A$.  Suppose that $AB=BA$. Show that $e^{A+B}=e^A\cdot e^B$. Show that
\begin{align*}
\frac {d e^{At}}{dt}=Ae^{At}=e^{At}A
\end{align*}
\end{exe}

\begin{exe}
Let $V$ be a complex Banach space. Let $v\in V$. Let $T\in\fk L(V)$. Show that there is a unique differentiable $f:\Rbb\rightarrow V$ satisfying the differential equation
\begin{align*}
f'(t)=Tf(t)\qquad f(0)=v
\end{align*}
Show that $f(t)=e^{Tt}v$ satisfies this differential equation.
\end{exe}





%% Record #28 2023/12/27 three lectures  70


\subsection{Contraction theorem}



\begin{df}
Let $f:X\rightarrow Y$ be a map of metric spaces. Suppose that $f$ has Lipschitz constant $L\in[0,1)$, we say that $f$ is a \textbf{contraction}.\index{00@Contraction}
\end{df}


\begin{thm}[\textbf{Contraction theorem}] \index{00@Contraction theorem}\label{lb555}
Let $X$ be a nonempty complete metric space. Let $T:X\rightarrow X$ be a contraction. Then $T$ has a unique \textbf{fixed point}, \index{00@Fixed point} i.e., there exists a unique $x\in X$ satisfying $T(x)=x$. 
\end{thm}

In the following proof, we let $L\in[0,1)$ be a Lipschitz constant of $T$.

\begin{proof}
Uniqueness: Suppose $x,y\in X$ satisfy $T(x)=x$ and $T(y)=y$. Then
\begin{align*}
0\leq d(x,y)=d(T(x),T(y))\leq Ld(x,y)
\end{align*}
showing that $d(x,y)$ must be $0$.

Existence: Choose $x_0\in X$. Define $(x_n)_{n\in\Nbb}$ inductively by $x_{n+1}=T(x_n)$. Then $d(x_{n+1},x_n)=d(T(x_n),T(x_{n-1}))\leq L d(x_n,x_{n-1})$. From this, we conclude
\begin{align*}
d(x_{n+1},x_n)\leq Ld(x_n,x_{n-1})\leq L^2 d(x_{n-1},x_{n-2})\leq\cdots\leq L^n d(x_1,x_0)
\end{align*}
Therefore, for each $k\in\Zbb_+$ we have
\begin{align*}
&d(x_{n+k},x_n)\leq d(x_{n+k},x_{n+k-1})+d(x_{n+k-1},x_{n+k-2})+\cdots+d(x_{n+1},x_n)\\
\leq& (L^{n+k-1}+L^{n+k-2}+\cdots+L^n)d(x_1,x_0)\leq \frac {L^n}{1-L}d(x_1,x_0)
\end{align*}
This proves that $(x_n)_{n\in\Nbb}$ is a Cauchy sequence in $X$. So it converges to some $x\in X$. Since $(T(x_n))=(x_{n+1})$ also converges to $x$, by the continuity of $T$ we conclude $T(x)=x$.
\end{proof}


The contraction theorem is also called the \textbf{Banach fixed-point theorem}. In the next chapter, we will use the contraction theorem to study differential equations. In the next semester, we will use the contraction theorem to prove the inverse function theorem for multivariable functions.












\subsection{Problems and supplementary material}


Let $1<p,q\leq +\infty$ satisfy $\frac 1p+\frac 1q=1$. %Unless otherwise stated, assume $p>1$ and hence $q<+\infty$. 
Let $\Fbb\in\{\Rbb,\Cbb\}$. 

\begin{sprob}\label{lb570}
Let $1\leq p<+\infty$. Let $X$ be a set. Let $\scr A$ be a subset of $l^p(X,\Fbb)$ equipped with the $l^p$-norm. Prove that the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $\scr A$ is precompact.
\item For each $x\in X$ we have $\sup_{f\in\scr A}|f(x)|<+\infty$. Moreover, for every $\eps>0$, there exists a finite subset $K\subset X$ such that for each $f\in\scr A$ we have $\Vert f|_{X\setminus K}\Vert_{l^p}<\eps$; in other words,
\begin{align}
\lim_{K\in\fin(2^X)}\sup_{f\in\scr A}\sum_{x\in X\setminus K}|f(x)|^p=0
\end{align}
\end{enumerate}
\end{sprob}

\begin{proof}[Hint]
(1)$\Rightarrow$(2): Mimic the first proof of Thm. \ref{lb515}. (2)$\Rightarrow$(1): Choose any net $(f_\alpha)$ in $\scr A$. First find a subnet $(f_\mu)$ converging pointwise to a function $f:X\rightarrow\Fbb$. Then show that $f\in l^p(X,\Fbb)$ and $\lim_\mu \Vert f-f_\mu\Vert_p=0$.
\end{proof}


Pb. \ref{lb570} is the $l^p$-version of the \textbf{Fr\'echet-Kolmogorov theorem}. \index{00@Fr\'echet-Kolmogorov theorem}

\begin{sexe}
In Pb. \ref{lb570}, assume that $\scr A$ is precompact. Prove that $E=\bigcup_{f\in\scr A}\Supp(f)\equiv\bigcup_{f\in\scr A}\{x\in X:f(x)\neq 0\}$ is a countable set.
\end{sexe}


\begin{proof}[Hint]
Method 1: Show that $\scr A$ is separable. Let $\mc E$ be a countable dense subset of $\scr A$. Prove $E=\bigcup_{f\in\mc E}\Supp(f)$.

Method 2: For each $\eps=1/n$, write the $K$ in (2) as $K_n$. Prove  $E\subset\bigcup_nK_n$.
\end{proof}


\begin{sprob}
Let $V$ be a Banach space. Let $\xi\in C(\Rbb,V)$ such that $\Vert \xi\Vert_{L^1}=\int_\Rbb \Vert \xi(t)\Vert dt<+\infty$. Let $\fk X=C(\Rbb,\Rbb)\cap l^\infty(\Rbb,\Rbb)$, equipped with the $l^\infty$-norm. Define a linear map
\begin{align*}
\Phi:\fk X\rightarrow V\qquad f\mapsto \int_I f(t)\xi(t)dt
\end{align*}
Show that $\Phi$ is a bounded linear map. Show that $\Phi$ is a \textbf{compact operator}, which means that $\Phi(\ovl B_{\fk X}(0,1))$ is a precompact subset of $V$.
\end{sprob}

\begin{proof}[Hint]
By Thm. \ref{lb521}, we can view $V$ as a closed linear subspace of $C(X,\Rbb)$ where $X$ is a compact Hausdorff space. So $\xi$ can be viewed as a function on $\Rbb\times X$. Use Arzel\`a-Ascoli to prove that $\Phi$ is a compact operator.
\end{proof}



\begin{prob}\label{lb535}
Let $V$ be a separable normed vector space over $\Fbb$. Let $(v_n)_{n\in\Zbb_+}$ be a dense sequence in $\ovl B_V(0,1)$. (The density is with respect to the norm topology.\footnote{Recall that subsets of separable (equivalently, second countable) metric spaces are separable.}) Use $(v_n)_{n\in\Zbb_+}$ to construct an explicit metric on $\ovl B_{V^*}(0,1)$ inducing its weak-* topology, and construct an explicit countable basis for the weak-* topology on $\ovl B_{V^*}(0,1)$.
\end{prob}

\begin{proof}[Hint]
Check the proof of Thm. \ref{lb523} (or more precisely, Thm. \ref{lb521}). This problem is related to Pb. \ref{lb533}.
\end{proof}


\begin{rem}
The metric you are asked to find in Pb. \ref{lb535} can actually be found in many analysis textbooks, although their authors do not tell you how they find it. The point of this problem (together with Pb. \ref{lb533}) is to tell you that the correct geometric viewpoint (i.e., embedding into Hilbert cubes) can lead you to the formula of the metric. 

Another goal of this problem is to justify the point in Rem. \ref{lb483}: For all concrete examples of compact metrizable spaces, you can explicitly construct countable bases for their topologies. Therefore, there is no need to use the indirect proof of the second countability in Thm. \ref{lb252}.\footnote{You can feel how much I hate the proof of Thm. \ref{lb252} :-)}  \hfill\qedsymbol
\end{rem}





\begin{comment}
\begin{exe}
Let $f:X\rightarrow Y$ be a continuous map of topological spaces. Show that if $X$ is separable, then $f(X)$ is separable. (This property is not true if ``separable" is replaced by ``second countable".)
\end{exe}
\end{comment}

\begin{prob}\label{lb537}
Let $Y$ be a metric space. Prove that there is a compact Hausdorff space $X$ and an isometry $\Phi:Y\rightarrow C(X,\Fbb)$ following the hint below. 
\end{prob}

In particular, any metric space can be (isometrically) embedded into a Banach space. \footnote{If we simply want to embed $Y$ into a Banach space $V$, there is a simpler method called \textbf{Kuratowski embedding}: Assume $Y$ is nonempty and fix $a\in Y$. Let $V=l^\infty(Y,\Rbb)$, and define the embedding sending each $y\in Y$ to the function $p\in Y\mapsto d(y,p)-d(a,p)$.}

\begin{proof}[Hint]
This problem is similar to Thm. \ref{lb521}. Since $C(X,\Rbb)\subset C(X,\Cbb)$, it suffices to assume $\Fbb=\Rbb$. In  Thm. \ref{lb521}, $X$ is constructed to be the set of linear functionals with operator norms $\leq 1$. The assumption on the operator norms ensures the equicontinuity and hence the (pre)compactness of $X$. Thus, in the current situation, in order to get a compact $X$, one should consider a pointwise bounded set of functions with a uniform Lipschitz constant  (cf. Thm. \ref{lb509} or Exe. \ref{lb536}). For example, assume $Y$ is nonempty and fix $a\in Y$, and define
\begin{align}\label{eq212}
X=\{f\in \Rbb^Y:f(a)=0\text{, and $f$ has Lipschitz constant }1\}
\end{align}
equipped with the pointwise convergence topology.
\end{proof}


\begin{rem}
Similar to the proof of Thm. \ref{lb523}, one can show that $X=\eqref{eq212}$ is metrizable (equivalently, second countable) iff $Y$ is separable.
\end{rem}

\begin{rem}
Pb. \ref{lb537} tells us that any metric space can be embedded into a Banach space. This fact is useful in the same way that the existence of the completions of normed vector spaces is useful, cf. Rem. \ref{lb538}. (Interestingly, Pb. \ref{lb537} gives a new proof that every metric space $Y$ has completion, since one can restrict $\Phi:Y\rightarrow V$ to $Y\rightarrow\ovl{\Phi(Y)}$.) 

For example, assume that $X,Y$ are topological spaces, and $Z$ is a metric space. Equip $C(Y,Z)$ with a uniform convergence metric (cf. Exp. \ref{lb272}). By Pb. \ref{lb537}, $Z$ can be viewed as a metric subspace of a Banach space $V$. By Thm. \ref{lb274}, there is a canonical injection $\Psi:C(X,C(Y,V))\rightarrow C(X\times Y,V)$ which is bijective when $Y$ is compact. It is easy to see that $\Psi$ restricts to an injective map $C(X,C(Y,Z))\rightarrow C(X\times Y,Z)$, and that this restriction is surjective when $Y$ is compact. Therefore, Thm. \ref{lb274} can be generalized to the case that the codomain is a metric space, but not necessarily a normed vector space.\footnote{Of course, we can prove the case of metric spaces for Thm. \ref{lb274} at the very beginning. We didn't do it just to avoid distraction.} Similarly, Thm. \ref{lb277} can be generalized to functions whose codomains are metric spaces, and the Moore-Osgood theorem can be generalized to functions whose codomains are complete\footnote{You need completeness because in the proof you need the fact that $Y$ is closed in $V$.} metric spaces.   \hfill\qedsymbol
\end{rem}








\begin{prob}\label{lb531}
Let $X$ be a set. By the Banach-Alaoglu theorem and Thm. \ref{lb530}, when $1< p\leq +\infty$, the closed unit ball
\begin{align}
B=\{f\in l^p(X,\Fbb):\Vert f\Vert_p\leq 1\}
\end{align}
is compact under the pointwise convergence topology (i.e. the product topology inherited from $\Fbb^X$). Give a direct proof of this fact for all $1\leq p\leq +\infty$ (including the case $p=1$) without using Banach-Alaoglu Thm. \ref{lb519}.
\end{prob}


Now you may wonder if the pointwise convergence topology on the closed unit ball of $l^1$ can be realized by a weak-* topology. The answer is yes:

\begin{sprob}
Let $X$ be a set. Let
\begin{align*}
c_0(X,\Fbb)=\{f\in\Fbb^X: \text{for all $\eps>0$ there exists $A\in\fin(2^X)$ such that }\Vert f\Vert_{l^\infty(A^c,\Fbb)}<\eps\}
\end{align*}
equipped with the $l^\infty$-norm. By Prop. \ref{lb432}, $c_0(X,\Fbb)$ is a Banach space. (You can also check it directly.) Find a natural isomorphism of Banach spaces
\begin{align}
\Psi:l^1(X,\Fbb)\xlongrightarrow{\simeq} c_0(X,\Fbb)^*
\end{align}
Let $(f_\alpha)$ be a net in $l^1(X,\Fbb)$ satisfying $\sup_\alpha \Vert f_\alpha\Vert_{l^1}<+\infty$, and let $f\in l^1(X,\Fbb)$. Prove that $\Psi(f_\alpha)$ converges weak-* to $\Psi(f)$ iff $(f_\alpha)$ converges pointwise to $f$ as functions $X\rightarrow\Fbb$.
\end{sprob}


\begin{sprob}\label{lb567}
Prove that $l^q(\Zbb_+,\Fbb)$ is separable (where $1\leq q<+\infty$), and $l^\infty(\Zbb_+,\Fbb)$ is not separable.
\end{sprob}

\begin{proof}[Hint]
Every subset of a second countable space is second countable and hence Lindel\"of. Find an uncountable discrete (and hence non-Lindel\"of) subset of $l^\infty(\Zbb_+,\Fbb)$.
\end{proof}



\begin{sprob}\label{lb532}
By Thm. \ref{lb369}, there is a linear isometry 
\begin{gather}
\Psi:l^1(\Zbb_+,\Fbb)\rightarrow l^\infty(\Zbb_+,\Fbb)^*  \label{eq205}
\end{gather}
such that $\bk{\Psi(f),g}=\sum_n f(n)g(n)$. Let $\mc B=\ovl B_{l^1(\Zbb_+,\Fbb)}(0,1)$, the closed unit ball of $l^1(\Zbb_+,\Fbb)$. If $\Psi$ is surjective (and hence an isomorphism), then $\Psi(\mc B)$ is the closed unit ball of $l^\infty(\Zbb_+,\Fbb)^*$, and hence is weak-* compact by Banach-Alaoglu. 

Let $f_n=\chi_{\{n\}}$, viewed as an element of $\mc B$. Prove that the sequence $(\Psi(f_n))_{n\in\Zbb_+}$ has no weak-* convergent subnet in $\Psi(\mc B)$.\footnote{It is not enough to consider subsequences, since $l^\infty(\Zbb_+,\Fbb)$ is not separable and hence the unit ball of $l^\infty(\Zbb_+,\Fbb)^*$ is not weak-* metrizable, cf. Thm. \ref{lb523}.} Conclude that the map $\Psi$ is not surjective.  \hfill\qedsymbol
\end{sprob}


\begin{comment}
\begin{sprob}
Let $V$ be a normed vector space such that $V^*$ is separable (under the operator norm). Prove that $V$ is separable. Use this fact to give another proof that \eqref{eq205} is not surjective.
\end{sprob}


\begin{proof}[Hint]
Show that $\ovl B_{V^*}(0,1)$ is second countable under the weak-* topology. Then use Thm. \ref{lb482} and \ref{lb523}. 
%Note that before proving that a space is metrizable, you cannot identify separability with second countability.
\end{proof}
\end{comment}



\subsection{$\star$ Supplementary material: a discussion of Riesz's and Helly's treatments of moment problems}\label{lb548}

Unless otherwise stated, $V$ is a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$.


\subsubsection{Quotient Banach spaces in moment problems}




\begin{prob}
Let $U$ be a closed linear subspace of $V$. Let $V/U$ be its quotient vector space. Prove that $V/U$ has a norm defined by
\begin{align}
\Vert v+U\Vert=\inf_{u\in U}\Vert v+u\Vert  \label{eq216}
\end{align}
for all $v\in V$. Prove that $V/U$ is complete under this norm. We call $V/U$ the \textbf{quotient Banach space} \index{00@Quotient Banach space} of $V$ by $U$.
\end{prob}

\begin{proof}[Hint]
Use Pb. \ref{lb566} to prove that $V/U$ is complete.
\end{proof}

\begin{pp}[Abstract moment problem, finite version]\label{lb546}
Let $\varphi_1,\dots\varphi_n\in V^*$. Let $c_1,\dots,c_n\in\Fbb$. Suppose that there exists $M\in\Rbb_{\geq0}$ such that
\begin{align}
|a_1c_1+\cdots+a_nc_n|\leq M\cdot\Vert a_1\varphi_1+\cdots+a_n\varphi_n\Vert\qquad(\forall a_1,\dots,a_n\in\Fbb)
\end{align}
Then for every $\eps>0$ there exists $v\in V$ satisfying that $\Vert v\Vert\leq M+\eps$ and that
\begin{align}
\bk{\varphi_i,v}=c_i\qquad(\text{for all }1\leq i\leq n) \label{eq213}
\end{align}
\end{pp}

The above proposition is due to Helly \cite{Hel21}.

\begin{prob}\label{lb547}
Assume the setting of Prop. \ref{lb546}. Define a bounded linear map
\begin{gather}\label{eq214}
\Phi:V\rightarrow \Fbb^n\qquad v\mapsto(\varphi_1(v),\dots,\varphi_n(v))
\end{gather}
The following two steps will lead you to prove Prop. \ref{lb546}.
\begin{enumerate}
\item Consider the special case that $\Ker(\Phi)=0$. In particular, $V$ is a finite dimensional normed vector space, and $\dim V=\dim\Span(\varphi_1,\dots,\varphi_n)$. We have $\dim V^*=\dim V<+\infty$ because all linear maps $V\rightarrow\Fbb$ are bounded. Similarly $\dim V^{**}=\dim V^*$. So the canonical linear isometry
\begin{gather}
V\rightarrow V^{**}\qquad v\mapsto \bk{\cdot,v}
\end{gather}
(cf. Cor. \ref{lb502}) must be bijective. Use this observation to prove that there exists $v\in V$ satisfying $\Vert v\Vert\leq M$ and \eqref{eq213}.

\item Reduce the general case to the special case in part 1 by considering $V/\Ker(\Phi)$ and its bounded linear functionals $\psi_1,\dots,\psi_n$ defined by
\begin{align}
\bk{\psi_i,v+\Ker(\Phi)}=\bk{\varphi_i,v}
\end{align}
(Note that you need to prove $\Vert\psi_i\Vert=\Vert\varphi_i\Vert$.)
\end{enumerate}
\end{prob}

\begin{rem}\label{lb552}
Recall from Sec. \ref{lb543} that Riesz wanted to solve the moment problem: Let $I=[a,b]$ be a compact interval in $\Rbb$. Let $g_1,g_2,\dots\in L^q(I)=L^q(I,\Fbb)$ (where $1<q<+\infty$) and $c_1,c_2,\dots\in\Cbb$ satisfying
\begin{align*}
|a_1c_1+\cdots+a_nc_n|\leq M\cdot \Vert a_1g_1+\cdots+a_ng_n\Vert_{L^q}\qquad(\forall n\in\Zbb_+,a_1,\cdots,a_n\in\Cbb)
\end{align*}
The goal is to find $f\in L^p(I)$ (where $p^{-1}+q^{-1}=1$) satisfying $\int_I fg_j=c_j$ for all $j=1,2,\dots$. As mentioned in Rem. \ref{lb526}, Riesz's first step in solving this problem is to find $f_n\in L^p(I)$ for each $n\in\Zbb_+$ satisfying $\Vert f_n\Vert_{L^p}\leq M$ and
\begin{align}
\int_I f_ng_i=c_i\qquad(\text{for every }1\leq i\leq n) \label{eq215}
\end{align}
The second step is then to find a weak-* convergent subsequence of $(f_n)_{n\in\Zbb_+}$. 

%In Sec. \ref{lb543}, I didn't explain how Riesz solved step 1. Some of the key ideas can now be explained. (For simplicity, the reader can replace $L^q(I),L^p(I)$ by $l^q(\Zbb),l^p(\Zbb)$ and replace the integrals by the series. The main idea remains the same.) 

Let us slightly weaken the above assumption to $\Vert f_n\Vert_{L^p}\leq M+\eps$ where $\eps>0$ is fixed at the beginning. (Later, I will explain why $\eps$ can be chosen to be $0$.) Then, in view of the canonical isomorphism $\Psi:L^q(I)\rightarrow L^p(I)^*$, Riesz's first step can be viewed as  Prop. \ref{lb546} in the special case that $V=L^p(I)$ and $\varphi_i=\Psi(g_i)$. However, Riesz did not prove Step 1 in the way we outlined in Pb. \ref{lb547}.  Riesz's method is more complicated and cannot be applied to normed vector spaces in general. The argument in Pb. \ref{lb547} is essentially due to Helly \cite{Hel21}.  \hfill\qedsymbol
\end{rem}

\begin{rem}\label{mc236}
It should be noted that the most non-trivial part of the argument in Pb. \ref{lb547} is the fact that if $U$ is a finite-dimensional normed vector space then the canonical map $U\rightarrow U^{**}$ is an isometry. (One needs this result for $U=V/\Ker(\Phi)$.) Since $\dim U<+\infty$, the map $\Gamma:U\rightarrow U^{**}$ is clearly a linear isomorphism, and one easily checks that $\Vert\Gamma(u)\Vert\leq \Vert u\Vert$. The difficult part lies in proving that $\Vert u\Vert\leq \Vert\Gamma(u)\Vert$, i.e., that $\Vert u\Vert\leq\sup_{\varphi\in \ovl B_{U^*}(0,1)}|\bk{\varphi,u}|$.  


In \cite{Hel21}, Helly proved this inquality by using a result on convex sets due to Minkowski. When $U$ is over $\Rbb$, Minkowski's result says that if $C$ is a convex subset of $U$, and if $u$ is a boundary point of $C$, then there is a hyperplane $H$ passing through $u$ such that $C$ is on one side of $H$. Now, assume WLOG that $\Vert u\Vert=1$, and let $C=\ovl B_U(0,1)$. Then $u$ is a boundary point of $C$, and hence such a hyperplane $H$ exists. Let $\varphi$ be the unique linear map $U\rightarrow\Rbb$ such that $\varphi^{-1}(1)=H$. Then for each $\xi\in \ovl B_U(0,1)$ we have $\varphi(\xi)\leq 1$ since $\xi$ and $0$ are on the same side of $H$. Replacing $\xi$ by $-\xi$ gives $|\varphi(\xi)|\leq 1$. Therefore, one has $\varphi\in\ovl B_{U^*}(0,1)$ and $\bk{\varphi,u}=1$. This proves the desired inequality. By generalizing Minkowski's result to complex finite-dimensional normed vector spaces, Helly proved the complex version of the above inequality.

From the above discussions, we learn two things. First, the Hahn-Banach theorem is nontrivial enough for finite dimensional spaces. Once one can prove that the canonical linear map $V\rightarrow V^{**}$ is an isometry whenever $\dim V<+\infty$, the moment problems that Riesz was concerned with can be solved by using the Banach-Alaoglu theorem. Second, the Hahn-Banach extension theorem is closely related to the geometric properties of convex subsets of a vector space. This close relationship will be further explored when you study functional analysis in the future.\hfill\qedsymbol
\end{rem}

\begin{rem}
The idea of quotient Banach spaces introduced in this section is also implicit in the works of Riesz and Helly. Indeed, Riesz wanted to find $f_n\in L^p(I)$ satisfying \eqref{eq215} for small enough $\Vert f_n\Vert_{L^p}$. This amounts to the fact that in \eqref{eq216}, the value of  $\Vert v+U\Vert$ can be estimated by finding $u\in U$ such that $\Vert v+u\Vert$ is small enough. 

In fact, Riesz was able to find $f_n$ satisfying \eqref{eq215} \textit{and minimizing $\Vert f_n\Vert$}; moreover, for such $f_n$, one has $\Vert f_n\Vert\leq M$ (but not just $\Vert f_n\Vert\leq M+\eps$). This follows from Pb. \ref{lb564}, applied to $V=L^q(I)$ and $E=\{g_1,\dots,g_n\}$.%\footnote{Riesz did not use the method provided in Pb. \ref{lb564} to find a minimizing $f_n$. He used Lagrange multipliers instead, according to \cite[Sec. 6.2]{Die-H}.}  
\hfill\qedsymbol
\end{rem}


\begin{prob}\label{lb564}
Let $E$ be a subset of $V$. Let
\begin{align}
E^\perp=\{\varphi\in V^*:\varphi|_E=0\}
\end{align}
which is clearly a weak-* closed linear subspace of $V^*$. Let $\varphi\in V^*$. Prove that there exists $\psi\in E^\perp$ such that $\Vert\varphi+\psi\Vert$ equals $\Vert\varphi+E^\perp\Vert\equiv\inf_{\eta\in E^\perp}\Vert\varphi+\eta\Vert$.
\end{prob}

It is in fact true that any weak-* closed linear subspace of $V^*$ is of the form $E^\perp$. To prove it one needs a more general version of the Hahn-Banach theorem. We will not discuss it in our notes.

\begin{proof}[Hint]
Choose a sequence $(\psi_n)$ in $V^*$ such that  $\lim_n\Vert \varphi+\psi_n\Vert=\Vert \varphi+E^\perp\Vert$. Since this sequence is clearly norm-bounded, by Banach-Alaoglu, it has a subnet $(\psi_\alpha)$ converging weak-* to some $\psi\in V^*$. Clearly $\psi\in E^\perp$. For each $\eps>0$, choose $v\in V$ with $\Vert v\Vert=1$ such that $|\bk{\varphi+\psi,v}|\geq \Vert\varphi+\psi\Vert-\eps$. Show that $|\bk{\varphi+\psi,v}|\leq \lim_\alpha\Vert\varphi+\psi_\alpha\Vert$. Conclude that $\Vert\varphi+\psi\Vert-\eps\leq\Vert\varphi+E^\perp\Vert$ for all $\eps>0$.
\end{proof}







\subsubsection{Some consequences}


The goal of this subsection is to give some quick consequences of the results and the methods introduced in the previous subsections. These important properties are mainly about compactness, and are not difficult to find in many books on functional analysis. The reason I present these results is to show that they can (or should?) be understood in the light of Riesz's and Helly's treatments of moment problems. (Unfortunately, this point is often not emphasized in many textbooks.)



\begin{thm}[\textbf{Goldstine's theorem}] \index{00@Goldstine's theorem}\label{lb568}
Let $\Gamma:V\rightarrow V^{**}$ be the linear isometry (cf. Cor. \ref{lb502}) sending $v$ to the bounded linear functional $\varphi\in V^*\mapsto\bk{\varphi,v}$. Then $\Gamma(\ovl B_V(0,1))$ is weak-* dense in $\ovl B_{V^{**}}(0,1)$. 
\end{thm}

Consequently, since $\ovl B_{V^{**}}(0,1)$ is a compact Hausdorff space by Banach-Alaoglu, we conclude that $\Gamma$ is bijective iff $\Gamma(\ovl B_V(0,1))$ is weak-* compact.\footnote{The \textbf{weak topology} \index{00@Weak topology} on $V$ is defined to be the pullback of the weak-* topology of $V^{**}$ by $V\rightarrow V^{**}$. So a net $(v_\alpha)$ in $V$ converges weakly to $v\in V$ iff $\lim_\alpha\bk{v_\alpha,\varphi}=\bk{v,\varphi}$ for all $\varphi\in V^*$. Thus, the conclusion is that $\Gamma:V\rightarrow V^{**}$ is bijective iff $\ovl B_V(0,1)$ is weakly compact.} A Banach space $V$ such that $\Gamma$ is bijective called \textbf{reflexive}. \index{00@Reflexive Banach spaces} For example, if $1<p<+\infty$, then Thm. \ref{lb527} shows that $l^p(X,\Fbb)$ is reflexive. It is also true that $L^p([a,b],\Fbb)$ is reflexive.

\begin{proof}
Since $\bigcup_{0<r<1}\ovl B_{V^{**}}(0,r)$ is norm dense and hence weak-* dense in  $\ovl B_{V^{**}}(0,1)$, it suffices to prove that for each $0<r<1$ and $\fk v\in\ovl B_{V^{**}}(0,r) $, $\fk v$ can be approximated weak-* by elements of $\Gamma(\ovl B_V(0,1))$.

We shall prove that for each $E\in\fin(2^{V^*})$ there exists $v_E\in \ovl B_V(0,1)$ such that $\bk{\fk v,\varphi}=\bk{v_E,\varphi}$ for all $\varphi\in E$. Then the net $(\Gamma(v_E))_{E\in\fin(2^{V^*})}$ converges weak-* in $\ovl B_{V^{**}}(0,1)$ to $\fk v$, finishing the proof. To find $v_E$, we write $E=\{\varphi_1,\dots,\varphi_n\}$. Let $c_i=\bk{\fk v,\varphi_i}$. Since $\Vert\fk v\Vert\leq r$, for each $a_1,\dots,a_n\in\Fbb$ we have
\begin{align*}
|a_1c_1+\cdots+a_nc_n|=|\bk{\fk v,a_1\varphi_1+\cdots+a_n\varphi_n}|\leq r\cdot\Vert a_1\varphi_1+\cdots+a_n\varphi_n\Vert
\end{align*}
Therefore, by Prop. \ref{lb546}, there exists $v_E\in \ovl B_V(0,1)$ such that $\bk{v_E,\varphi_i}=c_i$ for all $1\leq i\leq n$. This finishes the construction of $v_E$. 
\end{proof}

%The content of Goldstine's theorem is natural in view of Riesz's solution of moment problems: If we translate Rem. \ref{lb526} to the abstract language of Banach spaces, then the moment problem can be formulated as follows: Let $V$ a Banach space. If $\fk Y$ is a closed subspace of 

\begin{comment}
\begin{rem}
We will show in Exe. \ref{lb562} that if $V$ is reflexive and $U$ its closed linear subspace, then for each $v\in V$ there exists $u\in U$ minimizing $\Vert v+u\Vert$.  It follows immediately from Pb. \ref{lb547} that in Prop. \ref{lb546} one can choose $v\in V$ satisfying $\Vert v\Vert\leq M$ (but not just $\Vert v\Vert\leq M+\eps$) and \eqref{eq213}. Since $L^p(I)$ is reflexive (when $1<p<+\infty$), we thus have an explanation of why in Rem. \ref{lb552} one can choose $f_n$ satisfying $\Vert f\Vert_{L^p}\leq M$ and \eqref{eq215}.
\end{rem}
\end{comment}



%We end this section with a fun application of quotient Banach spaces.

\begin{prob}\label{lb561}
Let $M$ be a linear subspace of $V$. Suppose that $e\in V$ is not in $\ovl M=\Cl_V(M)$. Prove that there exists $\psi\in V^*$ such that $\psi|_M=0$ and $\psi(e)\neq 0$. 
\end{prob}

This problem is a special case of the \textbf{Hahn-Banach separation theorem}. \index{00@Hahn-Banach separation theorem} As a consequence of this exercise, we know that $M$ is dense in $V$ iff every $\psi\in V^*$ vanishing on $M$ is zero.


\begin{comment}
As in the proof of Thm. \ref{lb499}, reduce to the case that $\Fbb=\Rbb$. By using Thm. \ref{lb499}, it suffices to find $\wtd\varphi\in \wtd M^*$ satisfying $\wtd\varphi|_M=0$ and $\wtd\varphi(e)=A\neq 0$, where $\wtd M=M+\Rbb e$. Check the proof of Lem. \ref{lb498} for the special case that $\varphi=0$. Use the fact that the LHS of \eqref{eq227} is $<0$ and the RHS of \eqref{eq227} is $>0$ to find $A$.
\end{comment}

\begin{proof}[Hint]
Use Hahn-Banach Cor. \ref{lb502} to prove the special case that $M=0$. Then reduce the general case to the special case by considering $V/\ovl M$.
\end{proof}

\begin{prob}\label{lb562}
Let $V$ be a reflexive Banach space. Let $U$ be a closed linear subspace of $V$. Let $v\in V$. Show that there exists $u\in U$ such that $\Vert v+U\Vert=\Vert v+u\Vert$. 
\end{prob}


\begin{proof}[Hint]
The canonical linear isometry $\Gamma:V\rightarrow V^{**}$ is an isomorphism of Banach spaces. Use the Hahn-Banach separation theorem (Pb. \ref{lb561}) to show that $\Gamma(U)=W^\perp$ where $W=\{\psi\in V^*:\psi|_U=0\}$. Then apply Pb. \ref{lb564}.
\end{proof}


\begin{comment}
\begin{pp}\label{lb563}
Suppose that $V$ is reflexive. Then in Prop. \ref{lb546} the condition $\Vert v\Vert\leq M+\eps$ can be strengthened to $\Vert v\Vert\leq M$.
\end{pp}

\begin{proof}
This is immediate from the proof of Prop. \ref{lb546} (cf. Pb. \ref{lb547}) and Pb. \ref{lb562} (applied to $U=\Ker(\Phi)$).
\end{proof}

\end{comment}

\begin{thm}[\textbf{Riesz's theorem}]\label{lb565}
Let $V$ be a Banach space. Then the closed unit ball $\ovl B_V(0,1)$ is compact under the norm topology iff $\dim_\Fbb V<+\infty$.
\end{thm}

\begin{proof}
If $\dim_\Fbb V<+\infty$, then the norm on $V$ is equivalent to the Euclidean norm by Pb. \ref{lb559}. So $\ovl B_V(0,1)$ is compact by Bolzano-Weierstrass. 

Now we assume $\dim_\Fbb V$ is not finite. We fix any $0<\eps<1$. (For example, choose $\eps=1/2$.) Notice that for each closed linear subspace $U\subsetneq V$, there clearly exists $v\in U$ such that $\Vert v+U\Vert=1-\eps$. By replacing $v$ by $v+u$ for some $u\in U$, we assume moreover that $\Vert v\Vert\leq 1$.

Now we construct an infinite linearly-independent sequence $(v_n)_{n\in\Zbb_+}$ in $\ovl B_V(0,1)$ as follows. $v_1$ is arbitrary. Suppose $v_1,\dots,v_n$ have been constructed. Let $U_n=\Span_\Fbb(v_1,\dots,v_n)$. Then $U_n$ is a closed linear subspace of $V$ since $U_n$ is complete. (Any finite dimensional normed vector space is equivalent as a metric space to $\Fbb^n$ by Pb. \ref{lb559}, and hence is complete.) Then $U_n$ is a closed proper linear subspace of $V$ since $\dim_\Fbb V<+\infty$. Therefore, by the previous paragraph, there exists $v_{n+1}\in\ovl B_V(0,1)$ such that $\Vert v_{n+1}+U_n\Vert=1-\eps$. So $\Vert v_{n+1}-v_j\Vert\geq 1-\eps$ for all $j\leq n$.

The sequence constructed above satisfies that $\Vert v_m-v_n\Vert\geq 1-\eps$ for all $m\neq n$. So $(v_n)_{n\in\Zbb_+}$ has no Cauchy subsequence, and hence no norm-convergent subsequence. Therefore $\ovl B_V(0,1)$ is not sequentially compact under the norm topology, and hence not compact.
\end{proof}


\begin{rem}
If $V$ is a reflexive infinite dimensional Banach space (i.e. if $V$ is $L^p([0,1],\Fbb)$ or $l^p(X,\Fbb)$ where $1<p<+\infty$), the above proof that $\ovl B_V(0,1)$ is not compact can be simplified by choosing $\eps=0$. This is due to Pb. \ref{lb562}.
\end{rem}

\begin{comment}
\begin{rem}
In the above proof, when the infinite dimensional $V$ is reflexive, one can choose $\eps$ to be $0$ thanks to Pb. \ref{lb562}. Therefore, for example, if $V$ is $L^p([0,1],\Fbb)$ or $l^p(\Zbb,\Fbb)$ (where $1<p<+\infty$), one can choose a sequence $(f_n)$ in $\ovl B_V(0,1)$ inductively as follows: First choose $f_{n+1}\in V$ outside $U_n=\Span(f_1,\dots,f_n)$. Then choose $f'_{n+1}\in U_n$ minimizing $\Vert f_{n+1}-f'_{n+1}\Vert$. (This step is very intuitive: in the case that $V$ is an inner product space, $f_{n+1}'$ is just the projection of $f_{n+1}$ to $U_n$.) Replace $f_n$ by $f_{n+1}-f'_{n+1}$. Then scale $f_n$ so that $\Vert f_n\Vert=1$. Then we have $\Vert f_n-f_n\Vert\geq1$ for all $m\neq n$. Since Thm. \ref{lb565} is credited to Riesz, I guess Riesz first figured out this construction for $L^p$ and $l^p$ spaces.
\end{rem}

\end{comment}










\newpage


\section{Application to differential equations}



\subsection{The Picard-Lindel\"of theorem}

We fix a Banach space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$. Let $I$ be an interval in $\Rbb$ containing at least two points.


\begin{df}
Let $T$ be a set. Let $X,Y$ be metric spaces. We say that a function $f:T\times X\rightarrow Y$ is \textbf{Lipschitz continuous on $X$} \index{00@Lipschitz continuous} if there exists $L\in\Rbb_{\geq0}$ (called the \textbf{Lipschitz constant}) such that for every $t\in T$ and $x_1,x_2\in X$ we have
\begin{align*}
d(f(t,x_1),f(t,x_2))\leq Ld(x_1,x_2)
\end{align*}  
\end{df}



\begin{thm}\label{lb554}
Let $E\subset V$. Let $\varphi\in C(I\times E,V)$ be Lipschitz continuous on $E$. Fix $t_0\in I,\xi\in E$. Then there exists at most one differentiable $f:I\rightarrow E$ satisfying
\begin{gather}\label{eq217}
f'(t)=\varphi(t,f(t))\qquad f(t_0)=\xi
\end{gather} 
for all $t\in I$.
\end{thm}



\begin{proof}
This theorem generalizes Lem. \ref{lb553}. In fact, we will prove this theorem in a similar way as we proved Lem. \ref{lb553}. Let $f,g:I\rightarrow$ be differentiable and assume that they both satisfy \eqref{eq217}. Then $\Omega=\{t\in I:f(t)=g(t)\}$ is a closed subset of $I$ since $f,g$ are continuous. $\Omega$ is nonempty since $t_0\in\Omega$. Since $I$ is connected, to prove that $\Omega=I$, it suffices to prove that $\Omega$ is open.

Choose any $x\in\Omega$. We want to prove that $x\in\Int_I(\Omega)$. Let us prove that if $x<\sup I$ then there exists $\delta>0$ such that $[x,x+\delta)\subset \Omega$. Then a similar argument shows that if $x>\inf I$ then there exists $\delta>0$ such that $(x-\delta,x]\subset\Omega$. This proves $x\in\Int_I(\Omega)$ whether $x$ is an endpoint of $I$ or not.

We first choose $\delta>0$ such that $[x,x+\delta]\subset I$. Since $f,g$ are continuous, both $\varphi(t,f(t))$ and $\varphi(t,g(t))$ are continuous in $t$. Therefore, by the fundamental theorem of calculus, we have
\begin{gather*}
f(t)=f(x)+\int^t_x\varphi(s,f(s))ds\qquad g(t)=g(x)+\int_x^t\varphi(s,g(s))ds
\end{gather*}
Since $f(x)=g(x)$, we have
\begin{align*}
\Vert f(t)-g(t)\Vert\leq\int_x^t \Vert \varphi(s,f(s))-\varphi(s,g(s))\Vert ds\leq L\int_x^t\Vert f(s)-g(s)\Vert ds
\end{align*}
where $L\in\Rbb_{\geq0}$ is a Lipschitz constant of $\varphi$ on $E$. Let $\dps A=\sup_{t\in[x,x+\delta]}\Vert f(t)-g(t)\Vert$. Then the above inequality implies $\Vert f(t)-g(t)\Vert\leq LA\delta$ for all $t\in[x,x+\delta]$, and hence $A\leq LA\delta$. Now we shrink $\delta$ so that $L\delta<1$. Then we must have $A=0$. So $f=g$ on $[x,x+\delta]$, and hence $[x,x+\delta)\subset\Omega$.
\end{proof}



\begin{eg}
The function $\varphi(x)=x^{\frac 13}$ is not Lipschitz continuous on any compact interval containing $0$. For every $c\geq0$, the function
\begin{align*}
f(x)=\left\{
\begin{array}{ll}
\big(\frac 23(x-c)\big)^{\frac 32}&\text{ if }x\geq c\\[1ex]
0 &\text{ if }x<c
\end{array}
\right.
\end{align*}
is differentiable on $\Rbb$ and satisfies the differential equation
\begin{align*}
f'(t)=(f(t))^{\frac 13}\qquad f(0)=0
\end{align*}
Therefore, Thm. \ref{lb554} does not hold without assume the Lipschitz continuity.
\end{eg}



\begin{thm}[\textbf{Picard-Lindel\"of theorem}]\index{00@Picard-Lindel\"of theorem}\label{lb556}
Let $\xi\in V$ and $0<R<+\infty$. Let $I=[a,b]$ where $-\infty<a<b<+\infty$. Assume that $\varphi \in C\big(I\times\ovl B_V(\xi,R),V\big)$ satisfies the following conditions:
\begin{enumerate}[label=(\arabic*)]
\item $\varphi$ is Lipschitz continuous on $\ovl B_V(\xi,R)$.
\item $M=\Vert\varphi\Vert_{l^\infty}$ is $<+\infty$.
\end{enumerate}
Assume that 
\begin{align}
|I|\leq \frac RM  \label{eq219}
\end{align} 
where $|I|=b-a$. Then there exists a unique differentiable function $f:I\rightarrow \ovl B_V(\xi,R)$ satisfying the differential equation
\begin{align}
f'(t)=\varphi(t,f(t))\qquad f(a)=\xi  \label{eq218}
\end{align}
for all $t\in I$. The same conclusion holds if $f(a)=\xi$ is replaced by $f(b)=\xi$.
\end{thm}


Note that the assumption $M<+\infty$ is automatic when $V=\Fbb^N$, since in that case $I\times\ovl B_V(\xi,R)$ is compact.  


\begin{proof}
We only prove the existence, since the uniqueness follows from Thm \ref{lb554}. We treat the case $f(a)=\xi$. The other case is similar. Also, by translating $f$, it suffices to assume $a=0$. So we let $I=[0,b]$. Then $bM\leq R$. Let $L$ be the Lipschitz constant of $\varphi$ on $\ovl B_V(\xi,R)$. Note that if we can find $f\in C\big(I,\ovl B_V(\xi,R)\big)$ satisfying the integral equation
\begin{align}
f(t)=\xi+\int_0^t \varphi(s,f(s))ds  \label{eq220}
\end{align}
for all $t\in I$, then $f$ clearly satisfies \eqref{eq218}.\\[-1ex]

Step 1. We first consider the special case that $bL<1$. Define a map
\begin{gather*}
T:C\big(I,\ovl B_V(\xi,R)\big)\rightarrow C(I,V)\\
(Tf)(t)=\xi+\int_0^t\varphi(s,f(s))ds
\end{gather*}
Then $T$ has range inside $X=C\big(I,\ovl B_V(\xi,R)\big)$ since for each $f\in X$ and $t\in I=[0,b]$ we have
\begin{align}
\Vert (Tf)(t)-\xi\Vert\leq \int_0^t\Vert\varphi(s,f(s))\Vert ds\leq bM\leq R
\end{align}
by \eqref{eq219}. Therefore, $T$ can be viewed as a map $X\rightarrow X$. 

Any fixed point of $T$ satisfies \eqref{eq220}. Therefore, by the contraction Thm. \ref{lb555}, it suffices to prove that $T$ is a contraction. Here, the metric on $X$ is defined by the $l^\infty$-norm on $C(I,V)$. Then for each $f,g\in X$. We compute that for each $t\in[0,b]$,
\begin{align*}
&\Vert (Tf)(t)-(Tg)(t)\Vert=\Big\Vert\int_0^t \varphi(s,f(s))ds-\int_0^t\varphi(s,g(s))ds\Big\Vert\\
\leq&\int_0^t\big\Vert\varphi(s,f(s))-\varphi(s,g(s))\big\Vert ds\leq L\int_0^t\big\Vert f(s)-g(s)\big\Vert ds\leq bL\Vert f-g\Vert_\infty
\end{align*}
Applying $\sup_{t\in[0,b]}$ to the LHS, we get $\Vert Tf-Tg\Vert_\infty\leq bL\Vert f-g\Vert_\infty$. Since $bL<1$, $T$ is a contraction.\\[-1ex]

Step 2. We consider the general case. Choose $N\in\Zbb_+$ such that $bL/N<1$. Let us prove by induction that for each $n=0,1,\dots,N$ there exists
\begin{align*}
f_n\in C\big([0,nb/N],\ovl B_V(\xi,nR/N) \big)
\end{align*}
satisfying \eqref{eq220} for all $t\in[0,nb/N]$. Then $f_N$ gives the desired function satisfying \eqref{eq220} for all $t\in I=[0,b]$.

The case $n=0$ is obvious. Assume that case $n-1$ has been proved where $1\leq n\leq N$. Let $\xi_{n-1}=f_{n-1}((n-1)b/N)$, which is inside $\ovl B_V(\xi,(n-1)R/N)$. Now we apply step 1, but replace the $I$ in step 1 by $I_n=[(n-1)b/N,nb/N]$ and replace the $\ovl B_V(\xi,R)$ by $\ovl B_V(\xi_{n-1},R/N)$. Note that by triangle inequality we have
\begin{align*}
\ovl B_V(\xi_{n-1},R/N)\subset \ovl B_V(\xi,nR/N)
\end{align*}
Note also that assumption \eqref{eq219} becomes $b/N\leq R/NM$, which is still satisfied. Thus, according to step 1, there exists $\dps g_n\in C\big(I_n,\ovl B_V(\xi_{n-1},R/N)\big)$ satisfying
\begin{align*}
g_n(t)=\xi_{n-1}+\int_{(n-1)b/N}^t \varphi(s,g(s))ds
\end{align*}
for all $t\in I_n$. Then (the graph of) $f_n$ is defined to be the union of (the graphs of) $f_{n-1}$ and $g_n$.
\end{proof}


Thm. \ref{lb556} still holds if we assume $R=+\infty$ and $I=\Rbb$:

\begin{co}\label{lb558}
Let $\xi\in V$. Assume that $\varphi\in C(\Rbb\times V,V)$ satisfies the following conditions:
\begin{enumerate}[label=(\arabic*)]
\item $\varphi$ is Lipschitz continuous on $V$.
\item $M=\Vert\varphi\Vert_{l^\infty}$ is $<+\infty$.
\end{enumerate}
Choose any $t_0\in\Rbb$. Then there exists a unique differentiable $f:\Rbb\rightarrow V$ satisfying
\begin{align}
f'(t)=\varphi(t,f(t))\qquad f(t_0)=\xi \label{eq221}
\end{align}
for all $t\in\Rbb$.
\end{co}

\begin{proof}
By Thm. \ref{lb556}, for each $a>0$ there exists a unique differentiable $f:[t_0-a,t_0+a]\rightarrow V$ satisfying \eqref{eq221}. The union of the graphs of these $f_a$ (for all $a>0$) gives the graph of the desired function.
\end{proof}






\subsection{Peano's existence theorem}





\begin{thm}\label{lb557}
Let $\xi\in\Rbb^N$. Let $\varphi\in C(\Rbb\times\Rbb^N,\Rbb^N)$ satisfy $M:=\Vert\varphi\Vert_\infty<+\infty$. Let $t_0\in\Rbb$. Then there exists a differentiable $f:\Rbb\rightarrow\Rbb^N$ satisfying
\begin{align}
f'(t)=\varphi(t,f(t))\qquad f(t_0)=\xi \label{eq222}
\end{align}
for all $t\in\Rbb$.
\end{thm}


\begin{proof}
Assume WLOG that $t_0=0$. It suffices to find $f\in C([0,1],\Rbb^N)$ satisfying
\begin{align}
f(t)=\xi+\int_0^t\varphi(s,f(s))ds \label{eq224}
\end{align}
on $[0,1]$. Then $f$ is differentiable and satisfies \eqref{eq222}. Then we can similarly find $f_1:[1,2]\rightarrow\Rbb^N$ satisfying $f_1'(t)=\varphi(t,f_1(t))$ and $f_1(1)=f(1)$. Namely, $f$ can be extended to a function $[0,2]\rightarrow\Rbb^N$ satisfying \eqref{eq222}. Repeating this argument, we get $f:[0,+\infty)\rightarrow\Rbb^N$ satisfying \eqref{eq222}, and similarly $f:\Rbb\rightarrow\Rbb^N$ satisfying \eqref{eq222}.\\[-1ex]

Step 1. Let $X=\ovl B_{\Rbb^N}(\xi,M)$. Since $I\times X$ is compact Hausdorff, by Stone-Weierstrass Thm. \ref{lb442}, we have a sequence of multivariable polynomials $(\varphi_n)_{n\in\Zbb_+}$ (where $\varphi_n\in\Rbb^N[t,x_1,\dots,x_N]$) converging uniformly on $[0,1]\times X$ to $\varphi$. Since $M=\Vert\varphi\Vert_\infty$, we have $\lim_n\Vert\varphi_n\Vert_{l^\infty(I\times X,\Rbb^N)}=M$. Therefore, by scaling each $\varphi_n$, we assume that $\Vert\varphi_n\Vert_{l^\infty(I\times X,\Rbb^N)}\leq M$. Since polynomials are clearly Lipschitz continuous, by Picard-Lindel\"of Thm. \ref{lb556}, for each $n$ there exists a differentiable $f_n:[0,1]\rightarrow X$ satisfying $f_n'(t)=\varphi_n(t,f_n(t))$ and $f_n(0)=\xi$. Equivalently, $f_n\in C([0,1],X)$ and
\begin{align}
f_n(t)=\xi+\int_0^t\varphi_n(s,f_n(s))ds \label{eq223}
\end{align}
for all $t\in[0,1]$.\\[-1ex]

Step 2. Recall that $\Vert\varphi_n\Vert\leq M$. For each $0\leq t_1\leq t_2\leq 1$, by \eqref{eq223} we have
\begin{align*}
\Vert f_n(t_2)-f_n(t_1)\Vert\leq\int_{t_1}^{t_2}\Vert\varphi_n(s,f_n(s))\Vert ds\leq M(t_2-t_1)
\end{align*}
Therefore $(f_n)_{n\in\Zbb_+}$ is an equicontinuous sequence in $C([0,1],\Rbb^N)$ and is uniformly bounded because $f_n([0,1])\subset X$. By Arzel\`a-Ascoli Thm. \ref{lb516}, $\{f_n:n\in\Zbb_+\}$ is a precompact subset of $C([0,1],\Rbb^N)$. Thus, by Prop. \ref{lb505}, $(f_n)$ has a uniformly convergent subsequence. By replacing $(f_n)$ with this subsequence, we assume WLOG that $(f_n)$ converges uniformly to some $f\in C([0,1],\Rbb^N)$. Since $f_n\in C([0,1],X)$, we have $f\in C([0,1],X)$.

To prove \eqref{eq224}, in view of \eqref{eq223}, it suffices to prove for each $t\in[0,1]$ that
\begin{align*}
\lim_{n\rightarrow\infty}\int_0^t\varphi_n(s,f_n(s))ds=\int_0^t\varphi(s,f(s))ds
\end{align*}
By Cor. \ref{lb380}, it suffices to prove $\lim_n \varphi_n(\cdot,f_n(\cdot))=\varphi(\cdot,f(\cdot))$ in $C([0,1],\Rbb^N)$ under the $l^\infty$-norm. Note that
\begin{align*}
\Vert \varphi(\cdot,f(\cdot))-\varphi_n(\cdot,f_n(\cdot))\Vert\leq \Vert \varphi(\cdot,f(\cdot))-\varphi(\cdot,f_n(\cdot))\Vert+\Vert \varphi(\cdot,f_n(\cdot))-\varphi_n(\cdot,f_n(\cdot))\Vert
\end{align*}
The first term on the RHS converges uniformly to $0$ since $f_n\rightrightarrows f$ and since $\varphi$ is uniformly continuous (Thm. \ref{lb294}). The second term converges uniformly to $0$ since $\varphi_n\rightrightarrows \varphi$ on $[0,1]\times X$. So the LHS converges uniformly to $0$.
\end{proof}

\begin{comment}
By Thm. \ref{lb120}, it suffices to prove
\begin{align}\label{eq225}
\lim_{m,n\rightarrow\infty} \varphi_m(\cdot,f_n(\cdot))=\varphi(\cdot,f(\cdot)) 
\end{align}
For each $m$, $\varphi_m$ is uniformly continuous on the compact set $[0,1]\times X$ (by Thm. \ref{lb294}). Therefore, since $(f_n)$ converges uniformly to $f$, we obtain
\begin{align*}
\lim_{n\rightarrow\infty}\varphi_m(\cdot,f_n(\cdot))=\varphi_m(\cdot,f(\cdot))
\end{align*}
On the other hand, since $\lim_m\varphi_m$ converges uniformly to $\varphi$, we have
\begin{align*}
\lim_{m\rightarrow\infty}\sup_{n\in\Zbb_+} \big\Vert \varphi_m(\cdot,f_n(\cdot))-\varphi(\cdot,f_n(\cdot))\big\Vert_{C([0,1],\Rbb^N)}=0
\end{align*}
Thus, by Moore-Osgood Thm. \ref{lb289}, we get \eqref{eq225}.
\end{comment}



Thm. \ref{lb557} is parallel to Cor. \ref{lb558} since $\varphi$ is defined on the whole space $\Rbb\times\Rbb^N$. However, in applications it is common that $\varphi$ is only defined on a subset of $\Rbb\times\Rbb^N$. Thus, we want to prove an existence theorem similar to Thm. \ref{lb556} without assuming the Lipschitz continuity, and hence without concluding the uniqueness. We shall state this result for a finite dimensional real Banach space $V$. This means that we consider $V=\Rbb^N$, but not necessarily equipped with the Euclidean norm. Since all norms on $\Rbb^N$ are equivalent (cf. Pb. \ref{lb559}), we conclude that the closed balls under any norm of $\Rbb^N$ is compact (since they are closed subsets of standard closed balls of $\Rbb^N$). In practice, it is useful to consider non-Euclidean norms of $\Rbb^N$. For example, under the $l^\infty$-norm on $\Rbb^N=l^\infty(\{1,\dots,N\},\Rbb)$, the closed balls are actually the cubes. 




\begin{thm}[\textbf{Peano's existence theorem}]\index{00@Peano's existence theorem}
Let $V$ be a finite-dimensional real Banach space. Let $\xi\in V$ and $0<R<+\infty$. Let $I=[a,b]$ where $-\infty<a<b<+\infty$. Let $\varphi \in C\big(I\times\ovl B_V(\xi,R),V\big)$. Assume
\begin{align}
|I|\leq \frac RM  
\end{align} 
where $|I|=b-a$ and $M=\Vert\varphi\Vert_\infty$. Then there exists a differentiable function $f:I\rightarrow \ovl B_V(\xi,R)$ satisfying the differential equation
\begin{align}
f'(t)=\varphi(t,f(t))\qquad f(a)=\xi  \label{eq226}
\end{align}
for all $t\in I$. The same conclusion holds if $f(a)=\xi$ is replaced by $f(b)=\xi$.
\end{thm}


\begin{proof}
Since $\Rbb\times V\simeq \Rbb^{N+1}$ is LCH and $I\times \ovl B_V(\xi,R)$ is compact, by Tietze extension Thm. \ref{lb468}, $\varphi$ can be extended to an element in $C_c(I\times V,V)$ still satisfying $\Vert\varphi\Vert_\infty=M$. Therefore, by Thm. \ref{lb557}, there exists a differentiable $\xi:\Rbb\rightarrow V$ satisfying \eqref{eq226}. It remains to check that $f(I)\subset \ovl B_V(\xi, R)$: For each $t\in I=[a,b]$, since $f(t)=\xi+\int_a^t\varphi(s,f(s))dt$, we have
\begin{align*}
\Vert f(t)-\xi\Vert\leq\int_a^t\Vert\varphi(s,f(s))\Vert dt\leq (t-a)M\leq |I|\cdot M\leq R
\end{align*}
and hence $f(t)\in \ovl B_V(\xi,R)$.
\end{proof}

%% Record #29 2024/1/3 three lectures  73

\newpage




\section{Differential calculus on $\Rbb^N$}

In this chapter, we fix a Banach space $V$ over $\Rbb$. However, we will be mainly interested in the case that $V$ is finite dimensional.


\subsection{Differentiability and $C^1$}

A motivating question of this short chapter is the following: Suppose that $f$ is a function on an open subset $\Omega\subset\Rbb^N$, and $\gamma:(a,b)\rightarrow\Omega$ is differentiable. How to calculate $(f\circ\gamma)'$? The key to the answer of this question is the following definition:


\begin{df}\label{lb576}
Let $\Omega\subset\Rbb^N$ be open. Let $p\in\Omega$. Let $f:\Omega\rightarrow V$. Assume that there is an $\Rbb$-linear map $A:\Rbb^N\rightarrow V$ such that for all $v\in\Rbb^N$ we have
\begin{align*}
f(p+v)=f(p)+Av+o(\Vert v\Vert)
\end{align*}
(recall Def. \ref{lb574} for the meaning of $o(\Vert v\Vert)$). Namely,
\begin{align}
\lim_{v\rightarrow 0}\frac{\Vert f(p+v)-f(p)-Av\Vert}{\Vert v\Vert}=0 \label{eq228}
\end{align}
Then we say that $f$ is \textbf{differentiable at $p$}. \index{00@Differentiable on $\Rbb^N$} We write
\begin{align*}
A=df|_p=df(p):\Rbb^N\rightarrow V
\end{align*}
and call $A$ the \textbf{differential} of $f$ at $p$. If $f$ is differentiable at every point of $\Omega$, we simply say that $f$ is \textbf{differentiable on $\Omega$}. 
\end{df}

\begin{comment}
For simplicity, in the future, we write
\begin{align*}
o(\Vert v\Vert)=o(v)
\end{align*}
\end{comment}

\begin{rem}\label{lb577}
Every linear map $A:\Rbb^N\rightarrow V$ is bounded since, if $v=a_1e_1+\cdots+a_Ne_N$ where $e_1,\dots,e_N$ are the standard basis of $\Rbb^N$, then
\begin{align*}
\Vert Av\Vert \leq \sum_i |a_i|\cdot \Vert Ae_i\Vert\leq \Vert v\Vert \Big(\sum_i\Vert Ae_i\Vert^2\Big)^{\frac 12}
\end{align*}
by Minkowski's inequality.
\end{rem}

\begin{rem}\label{lb585}
If $f$ is differentiable at $p$, then $f$ is continuous at $p$ since, by the continuity of $A$, we have $\lim_{v\rightarrow0} (Av+o(\Vert v\Vert))=0$.
\end{rem}





Whenever $f$ is differentiable at $p$, its differential can be computed explicitly:

\begin{pp}\label{lb580}
Let $\Omega\subset\Rbb^N$ be open. Let $f:\Omega\rightarrow V$ be differentiable at $p\in\Omega$. Then $\partial_1f,\dots,\partial_Nf$ exist at $p$. Define the \textbf{Jacobian (matrix)} \index{00@Jacobian matrix} \index{Jac@$\Jac f$, the Jacobian matrix}
\begin{align}
\Jac f|_p=(\partial_1f(p),\dots,\partial_Nf(p))
\end{align}
viewed as an $1\times N$ matrix with entries in $V$. (When $V=\Rbb^M$, we view $\Jac f|_p$ as an $M\times N$ real matrix.) Then for each $v=(a_1,\dots,a_n)^\tr\in\Rbb^N$ (viewed as an $N\times 1$ matrix) we have 
\begin{align}
df|_p\cdot v=\Jac f|_p\cdot v=\sum_{i=1}^N a_i\partial_i f(p)\label{eq229}
\end{align}
\end{pp}

Note that when $V=\Rbb^M$ and $f=(f^1,\dots,f^N)^\tr$, \eqref{eq229} reads
\begin{align}
df|_p\cdot v=\begin{pmatrix}
\partial_1 f^1 & \cdots & \partial_N f^1\\
 & \vdots & \\
\partial_1 f^M & \cdots & \partial_N f^M
\end{pmatrix}_p
\cdot
\begin{pmatrix}
a_1 \\
\vdots\\
a_N
\end{pmatrix}
\end{align}
We also define the \textbf{Jacobian (determinant)} \index{00@Jacobian determinant} \index{Jac@$\Jbf(f)$, the Jacobian determinant} $\Jbf(f):\Omega\rightarrow\Rbb$ whose value at each $p\in\Omega$ is
\begin{align}\label{eq359}
\Jbf(f)|_p=\det\big(\Jac(f)_p \big)
\end{align}
Thus, $\Jac(f)_p$ is invertible iff $\Jbf(f)|_p\neq 0$.
\begin{proof}
Let $e_1,\dots,e_N\in\Rbb^N$ be the standard basis of $\Rbb^N$. So $v=a_1e_1+\cdots+a_Ne_N$. Let $A=df|_p$. By \eqref{eq228}, we have
\begin{align*}
\lim_{t\rightarrow 0}\Big\Vert \frac{f(p+te_i)-f(p)}{t}-Ae_i\Big\Vert=\lim_{t\rightarrow 0}\frac{\Vert f(p+te_i)-f(p)-tAe_i\Vert}{\Vert t e_i\Vert}=0
\end{align*}
which shows that $\partial_i f(p)=Ae_i$. Therefore
\begin{align*}
Av=\sum_i a_iAe_i=\sum_i a_i \partial_i f(p)
\end{align*}
\end{proof}






\begin{co}
$f$ has at most one differential at a point $p$. 
\end{co}

\begin{proof}
Immediate from \eqref{eq229}.
\end{proof}





\begin{eg}
When $N=1$, the above definition of differentiability in Def. \ref{lb576} agrees with the one in Sec. \ref{lb575}. Moreover, we clearly have $\Jac f|_p=f'(p)$. 
\end{eg}



\begin{thm}[\textbf{Chain rule}] \index{00@Chain rule in $\Rbb^N$}\label{lb578}
Let $\Gamma\subset\Rbb^M$ and $\Omega\subset\Rbb^N$ be open. Let $g:\Gamma\rightarrow\Omega$ be differentiable at $p\in\Gamma$. Let $f:\Omega\rightarrow V$ be differentiable at $g(p)$. Then $f\circ g:\Gamma\rightarrow V$ is differentiable at $p$, and 
\begin{align}
d(f\circ g)|_p=df|_{g(p)}\cdot dg|_p
\end{align}
Equivalently, we have
\begin{align}
\Jac(f\circ g)|_p=\Jac f|_{g(p)}\cdot \Jac g|_p\label{eq230}
\end{align}
\end{thm}

Note that when $V=\Rbb^L$, \eqref{eq230} is of type $L\times M=(L\times N)(N\times M)$, and reads
\begin{align}
\begin{pmatrix}
\partial_1 (f\circ g)^1 & \cdots & \partial_M (f\circ g)^1\\
 & \vdots & \\
\partial_1 (f\circ g)^L & \cdots & \partial_M (f\circ g)^L
\end{pmatrix}_p
=\begin{pmatrix}
\partial_1 f^1 & \cdots & \partial_N f^1\\
 & \vdots & \\
\partial_1 f^L & \cdots & \partial_N f^L
\end{pmatrix}_{g(p)}
\cdot\begin{pmatrix}
\partial_1 g^1 & \cdots & \partial_M g^1\\
 & \vdots & \\
\partial_1 g^N & \cdots & \partial_M g^N
\end{pmatrix}_{p}
\end{align} 


\begin{proof}
We write
\begin{align*}
g(p+v)=g(p)+Bv+\beta(v)\qquad f(g(p)+w)=f\circ g(p)+Aw+\alpha(w)
\end{align*}
where $A:\Rbb^N\rightarrow V$ and $B:\Rbb^M\rightarrow\Rbb^N$ are linear, and
\begin{align}
\lim_{v\rightarrow 0}\beta(v)/\Vert v\Vert=\lim_{w\rightarrow 0}\alpha(w)/\Vert w\Vert=0  \label{eq232}
\end{align}
Then
\begin{align*}
&f\circ g(p+v)=f(g(p)+Bv+\beta(v))=f\circ g(p)+A(Bv+\beta(v))+\alpha(Bv+\beta(v))\\
=&f\circ g(p)+ABv+A\beta(v)+\alpha(g(p+v)-g(p))
\end{align*}
Note that $A,B$ are bounded by Rem. \ref{lb577}. So $\Vert A\beta(v)\Vert\leq\Vert A\lVert \cdot\Vert\beta(v)\Vert$, and hence $\lim_{v\rightarrow 0}\Vert A\beta(v)\Vert/\Vert v\Vert=0$. To finish the proof, it remains to prove
\begin{align*}
\lim_{v\rightarrow0}\Vert \alpha(g(p+v)-g(p))\Vert/\Vert v\Vert=0
\end{align*}

Since $g$ is continuous at $p$, there is a neighborhood $\Delta$ of $0\in\Rbb^M$ such that $g(p+v)-g(p)$ is defined and is in the domain of $\alpha$ (which is $\{q-g(p):q\in\Omega\}$) for every $v\in \Delta$. Define $\gamma:\Delta\rightarrow V$ to be
\begin{align*}
\gamma(v)=\left\{
\begin{array}{ll}
\dps\frac{\alpha\big(g(p+v)-g(p)\big)}{\Vert g(p+v)-g(p)\Vert}&\text{ if }g(p+v)-g(p)\neq0\\[2ex]
0&\text{ otherwise}
\end{array}
\right.
\end{align*}
Then $\gamma$ is continuous at $v=0$ and $\gamma(0)=0$ by \eqref{eq232}. (This part is similar to the construction \eqref{eq231}.) Thus
\begin{align*}
&\frac{\Vert\alpha(g(p+v)-g(p))\Vert}{\Vert v\Vert}=\Vert\gamma(v)\Vert\cdot\frac{\Vert g(p+v)-g(p)\Vert}{\Vert v\Vert}\\
=&\Vert\gamma(v)\Vert\cdot\frac{\Vert Bv+\beta(v)\Vert}{\Vert v\Vert}\leq \Vert\gamma(v)\Vert\cdot\Vert B\Vert+\Vert \gamma(v)\Vert\cdot \frac{\Vert\beta(v)\Vert}{\Vert v\Vert}
\end{align*}
where the RHS converges to $0$ as $v\rightarrow 0$.
\end{proof}




\begin{co}[\textbf{Chain rule}]\label{lb581}
Let $I$ be an interval. Let $\Omega\subset\Rbb^N$ be open. Let $t_0\in I$. Let $\gamma:I\rightarrow\Omega$ be differentiable at $t_0$. Let $f:\Omega\rightarrow V$ be differentiable at $p=\gamma(t_0)$. Then $f\circ\gamma$ is differentiable at $t_0$, and 
\begin{align}
(f\circ\gamma)'(t_0)=\Jac f|_{\gamma(t_0)}\cdot \gamma'(t_0)=\sum_{i=1}^N (\gamma^i)'(t_0)\cdot\partial_i f(\gamma(t_0))
\end{align}
\end{co}

\begin{proof}
This follows easily from Thm. \ref{lb578} when $t_0$ is an interior point of $I$. Suppose that $t_0$ is an end point of $I$. For example, consider $t_0=b$ where $I$ is $[a,b]$ or $(a,b]$. Then we can easily extend $\gamma$ to a function on $[a,b+1)$ or $(a,b+1)$ which is differentiable at $t_0$. (For example, if $t\in(b,b+1)$, we can define $\gamma(t)=\gamma(b)+(t-b)\gamma'(b)$.) Then we can apply Thm. \ref{lb578} again to finish the proof.
\end{proof}



\begin{eg}\label{lb579}
Let $\Omega\subset\Rbb^N$ be open. Let $f:\Omega\rightarrow V$ be differentiable at $p\in\Omega$. Then for each $v\in\Rbb^N$, the \textbf{directional derivative} \index{00@Directional derivative $\nabla_vf$}
\begin{align*}
(\nabla_vf)(p)=\lim_{t\rightarrow 0}\frac{f(p+tv)-f(p)}{t}
\end{align*}
exists and equals $df|_p\cdot v=\Jac f|_p\cdot v$.
\end{eg}

\begin{proof}
Apply the chain rule to $\gamma(t)=p+tv$.
\end{proof}


We have thus proved the chain rule, one of the most important reasons for introducing differentiability on $\Rbb^N$. We know that differentiable functions have partial derivatives of first order. However, having first order partial derivatives does not imply differentiability or even continuity:


\begin{eg}
Let $\dps f(x,y)=\frac{xy}{x^2+y^2}$ when $(x,y)\neq (0,0)$, and $f(0,0)=0$. Then $\lim_{r\rightarrow 0}f(r,r)=\frac 12$ and $\lim_{r\rightarrow 0}f(r,0)=0$, showing that $f$ has no limit and is not continuous $(0,0)$ at. However, $f(x,0)=f(0,y)=0$. So $\partial_1f$ and $\partial_2f$ are both equal to $0$ at $(0,0)$.
\end{eg}

\begin{eg}
Let $\dps f(x,y)=\frac{x^3}{x^2+y^2}$ when $(x,y)\neq (0,0)$, and $f(0,0)=0$. Since $|f(x,y)|\leq |x|$ and $\lim_{(x,y)\rightarrow(0,0)}|x|=0$, we conclude that $f$ is continuous at $(0,0)$ (and hence is continuous everywhere). We have $\partial_1 f|_{(0,0)}=\frac d{dx}x|_{x=0}=1$ and $\partial_2 f|_{(0,0)}=0$. Let $\gamma(t)=(at,bt)$ where $(a,b)\in\Rbb^2\setminus\{(0,0)\}$. Then
\begin{align*}
(\nabla_{(a,b)} f)(0)=(f\circ\gamma)'(0)=\frac{a^3}{a^2+b^2}
\end{align*}
is not equal to $\Jac f|_{(0,0)}\cdot (a,b)^\tr=a$. Thus, by Exp. \ref{lb579}, $f$ is not differentiable at $(0,0)$.
\end{eg}



To have differentiability, we need the continuity of partial derivatives of first order.


\begin{df}\label{lb925}
Let $\Omega\subset\Rbb^N$ be open. For each $r\in\Nbb$, we let \index{Cr@$C^r$ on $\Rbb^N$}
\begin{align*}
C^r(\Omega,V)=\big\{& f\in C(\Omega,V):\partial_{i_1}\cdots\partial_{i_k}f\text{ exists and is in }C(\Omega,V)  \\
&\text{for all $0\leq k\leq r$ and $1\leq i_1,\dots,i_k\leq N$}
\big\}
\end{align*}
In particular, we understand $C^0(\Omega,V)$ as $C(\Omega,V)$, and
\begin{align*}
C^\infty(\Omega,V)=\bigcap_{r\in\Nbb} C^r(\Omega,V)
\end{align*}
Elements in $C^\infty(\Omega,V)$ are called \textbf{smooth functions}. \index{00@Smooth functions, $\Rbb^N$}
\end{df}

It is clear that $C^r(\Omega,V)\subset C^{q}(\Omega,V)$ if $r\geq q$.

\begin{rem}
Suppose that $r\in\Zbb_+$ and $f\in C^r(\Omega,V)$. Let $1\leq k\leq r$, and let $\sigma:\{1,\dots,k\}\rightarrow \{1,\dots,k\}$ be a bijection. Then by Thm. \ref{lb406} or \ref{lb407}, for each $1\leq i_1,\dots, i_k\leq N$ we have
\begin{align*}
\partial_{i_1}\cdots\partial_{i_k}f=\partial_{i_{\sigma(1)}}\cdots\partial_{i_{\sigma(k)}}f
\end{align*}
\end{rem}


\begin{pp}\label{lb927}
Let $\Gamma\subset\Rbb^M$ and $\Omega\subset\Rbb^N$ be open. Let $g:\Gamma\rightarrow\Omega$ and $f:\Omega\rightarrow V$ be $C^r$-functions (where $r\in\Nbb\cup\{\infty\}$). Then $f\circ g$ is $C^r$.
\end{pp}

\begin{proof}
This is obvious when $r=0$. Assume $r>0$. By induction on $k$ (where $1\leq k\leq r$), and by using the (one-variable) chain rule and the Leibniz product rule, for each $1\leq i_1,\dots,i_k\leq M$ one sees that $\partial_{i_1}\cdots\partial_{i_k}(f\circ g)$ is a linear combination of products of (possibly more than two) functions of the form
\begin{align}\label{eq360}
\big((\partial_{j_1}\cdots\partial_{j_{k'}}f)\circ g\big)\qquad \text{or}\qquad \partial_{l_1}\cdots\partial_{l_{k''}}g
\end{align}
where $0\leq k',k''\leq k$ and $0\leq j_1,\dots,j_{k'}\leq N$ and $0\leq l_1,\dots,l_{k''}\leq M$. So $f\circ g$ is $C^r$ since the functions in \eqref{eq360} are continuous.
\end{proof}



\begin{thm}\label{lb926}
Let $\Omega$ be an open subset of $\Rbb^N$. Let $f\in C^1(\Omega,V)$. Then $f$ is differentiable on $\Omega$.
\end{thm}

\begin{proof}
We prove this by induction. The case $N=1$ is obvious. Assume that the case $N$ is true where $N\in\Zbb_+$. Let $\Omega\subset \Rbb^{N+1}$ be open, and let $(p_0,p_1,\dots,p_N)=(p_0,p_\blt)\in\Omega$. Let $v=(a_0,a_\blt)=(a_0,a_1,\dots,a_N)\in\Omega$. Then
\begin{align*}
&f(p_0+a_0,p_\blt+a_\blt)-f(p_0,p_\blt)\\
=&f(p_0+a_0,p_\blt+a_\blt)-f(p_0,p_\blt+a_\blt)+f(p_0,p_\blt+a_\blt)-f(p_0,p_\blt)\\
=&\int_{0}^{a_0}\partial_0 f(p_0+t,p_\blt+a_\blt)dt+f(p_0,p_\blt+a_\blt)-f(p_0,p_\blt)
\end{align*}
By case $N$, there exist $\lambda_1,\dots,\lambda_N\in\Rbb$ such that
\begin{align*}
f(p_0,p_\blt+a_\blt)-f(p_0,p_\blt)=\sum_{i=1}^N \lambda_ia_i+o(\Vert a_\blt\Vert)
\end{align*}
(In fact, $\lambda_i=\partial_i f(p_0,p_\blt)$ by Prop. \ref{lb580}.) Let
\begin{align*}
&h(a_0,a_\blt)=\int_{0}^{a_0}\partial_0 f(p_0+t,p_\blt+a_\blt)dt-\partial_0 f(p_0,p_\blt)\cdot a_0\\
=&\int_{0}^{a_0}\big(\partial_0 f(p_0+t,p_\blt+a_\blt)-\partial_0 f(p_0,p_\blt)\big)dt
\end{align*}
Since $\partial_1f$ is continuous, for every $\eps>0$ there exists $\delta>0$ such that for all $(t,a_\blt)\in\Rbb^N$ with norm $\leq \delta$ we have
\begin{align*}
\Vert \partial_0 f(p_0+t,p_\blt+a_\blt)-\partial_0 f(p_0,p_\blt)\Vert\leq\eps
\end{align*}
and hence $\Vert h(a_0,a_\blt)\Vert\leq\eps |a_0|$ for all $(a_0,a_\blt)$ with norm $\leq\delta$. Thus $h(a_0,a_\blt)=o(|a_0|)$. Therefore
\begin{align*}
&f(p_0+a_0,p_\blt+a_\blt)-f(p_0,p_\blt)-\partial_0 f(p_0,p_\blt)\cdot a_0-\sum_{i=1}^N \lambda_ia_i\\
=&o(|a_0|)+o(\Vert a_\blt\Vert)=o(\Vert(a_0,a_\blt)\Vert)
\end{align*}
\end{proof}


\subsection{Applications of the chain rule}

\begin{comment}
\begin{eg}
Every $A\in\mc L(\Rbb^N)$ is differentiable everywhere, and $A$ is the diffferential of itself. It follows from chain rule that if $I$ is an open interval and $f\in C^1(I,\Rbb^N)$, then
\begin{align*}
\frac d{dt}Af(t)=Af'(t)
\end{align*}
\end{eg}
\end{comment}
\begin{eg}\label{lb583}
Let $I,J$ be nonempty open intervals in $\Rbb$. Choose $f\in C(I\times J,V)$ such that $\partial_2f$ exists and is in $C(I\times J,V)$. Let $\alpha,\beta\in C^1(J,\Rbb)$ such that $\alpha(J)\subset I,\beta(J)\subset I$. Then
\begin{align}\label{eq234}
\frac d{dy}\int_{\alpha(y)}^{\beta(y)}f(x,y)dx=\int_{\alpha(y)}^{\beta(y)}\partial_2 f(x,y)dx+f(\beta(y),y)\beta'(y)-f(\alpha(y),y)\alpha'(y)
\end{align}
\end{eg}


\begin{proof}
Define $F:I\times I\times J\rightarrow V$ by
\begin{align*}
F(r,s,t)=\int_r^s f(x,t)dx=\int_e^s f(x,t)dx-\int_e^r f(x,t)dx
\end{align*}
where $e$ is any element of $I$. By Exe. \ref{lb408}, $F$ is continuous. Since $\partial_2f$ is assumed to be continuous, by Thm. \ref{lb405}, we have
\begin{align*}
\partial_3 F(r,s,t)=\int_r^s \partial_2 f(x,t)dx
\end{align*}
By the fundamental theorem of calculus, we have
\begin{align*}
\partial_1 F(r,s,t)=-f(r,t)\qquad\partial_2 F(r,s,t)=f(s,t)
\end{align*}
By Exe. \ref{lb408}, $\partial_1F,\partial_2F,\partial_3F$ are continuous, and hence $F$ is a $C^1$-function. Therefore, by the chain rule (Cor. \ref{lb581}), the LHS of \eqref{eq234} can be calculated by setting $(r,s,t)=(\alpha(y),\beta(y),y)$:
\begin{align*}
&\frac d{dy}F(\alpha(y),\beta(y),y)\\
=&\partial_1 F(\alpha(y),\beta(y),y)\alpha'(y)+\partial_2 F(\alpha(y),\beta(y),y)\beta'(y)+\partial_3F(\alpha(y),\beta(y),y)
\end{align*}
which equals the RHS of \eqref{eq234}.
\end{proof}


\begin{eg}
Fix $v\in V$ and $\varphi\in C(\Rbb,V)$. Let $A\in\fk L(V)$. Then $\frac d{dt}e^{At}=Ae^{At}=e^{At}A$ by Exe. \ref{lb582}. By Exp. \ref{lb583} and Thm. \ref{lb392}, we have
\begin{align*}
\frac d{dt}\int_0^t e^{A(t-s)}\varphi(s)ds=\varphi(t)+\int_0^tAe^{A(t-s)}\varphi(s)ds=\varphi(t)+A\int_0^te^{A(t-s)}\varphi(s)ds
\end{align*}
It follows that
\begin{align}
f(t)=e^{At}v+\int_0^t e^{A(t-s)}\varphi(s)ds \label{eq235}
\end{align}
is a solution of the differential equation
\begin{align*}
f'(t)=Af(t)+\varphi(t)\qquad f(0)=v
\end{align*}
It is the unique solution by Picard-Lindel\"of Cor. \ref{lb558}. %The formula \eqref{eq235} is called the \textbf{variation of constants formula}.
\end{eg}


\begin{thm}[\textbf{Finite-increment theorem}]\index{00@Finite-increment theorem on $\Rbb^N$}\label{lb584}
Let $\Omega$ be an open subset of $\Rbb^N$. Assume that $f:\Omega\rightarrow V$ is differentiable. Assume that $x,y\in\Omega$ satisfy $[x,y]\subset\Omega$ where
\begin{align*}
[x,y]=\{(1-t)x+ty:0\leq t\leq 1\}
\end{align*}
Then
\begin{align}\label{eq236}
\Vert f(y)-f(x)\Vert \leq \Big(\sup_{z\in[x,y]}\Vert df|_z\Vert  \Big)\cdot \Vert y-x\Vert
\end{align}
where $\Vert df|_z\Vert$ is the operator norm of $df|_z$.
\end{thm}

\begin{proof}
This can be proved in a similar way to Cor. \ref{lb335}. Let $\gamma:[0,1]\rightarrow\Omega$ be $\gamma(t)=(1-t)x+ty$. Then by chain rule we have $(f\circ\gamma)'(t)=df|_{\gamma(t)}\cdot\gamma'(t)=df|_{\gamma(t)}\cdot (y-x)$. Thus $\Vert (f\circ\gamma)'(t)\Vert$ is $\leq$ the RHS of \eqref{eq236}. Therefore, by the single-variable finite-increment Thm. \ref{lb333}, we have
\begin{align*}
\Vert f(y)-f(x)\Vert=\Vert f\circ\gamma(1)-f\circ\gamma(0)\Vert\leq\sup_{t\in[0,1]}\Vert (f\circ\gamma)'(t)\Vert
\end{align*}
which is $\leq$ the RHS of \eqref{eq236}. 
\end{proof}


\begin{rem}\label{mc45}
From the above proof, it is clear that Thm. \ref{lb584} remains true if we choose a different norm on $\Rbb^N$, and let $\Vert df|_z\Vert$ be the operator norm of $df|_z$ defined with respect to this norm. We will use this fact in the proof of the change of variables formula, cf. Lem. \ref{mc46}.
\end{rem}



The following corollary provides a lot of examples satisfying the assumptions on $\varphi$ in Picard-Lindel\"of Thm. \ref{lb556}. Recall Def. \ref{lb364} for the meaning of convex sets.


\begin{co}
Let $\Omega$ be an open subset of $\Rbb^N$. Let $f\in C^1(\Omega,V)$. Let $K$ be a compact convex subset of $\Omega$. Then $f|_K$ is Lipschitz continuous.
\end{co}

\begin{proof}
Since $df:\Omega\rightarrow \fk L(\Rbb^N,V)$ is continuous (because it is essentially $\Jac f$ by Prop. \ref{lb580}), there exists $L\in\Rbb_{\geq0}$ such that $\Vert df|_x\Vert\leq L$ for all $x\in K$. By Thm. \ref{lb584}, $L$ is a Lipschitz constant of $f|_K$.
\end{proof}


\begin{co}
Let $\Omega$ be a nonempty open connected subset of $\Rbb^N$. Assume that $f:\Omega\rightarrow V$ satisfies that $df=0$ everywhere on $\Omega$. Then $f$ is a constant.
\end{co}

\begin{proof}
Fix $p\in\Omega$, and let $v=f(p)$. Let us prove that $f=v$ on $\Omega$. Let $\Delta=\{x\in\Omega:f(x)=v\}$, which is a closed subset of $\Omega$ by the continuity of $f$ (Rem. \ref{lb585}). $\Delta$ is nonempty since $p\in\Delta$. Thus, if we can show that $\Delta$ is open in $\Omega$, then $\Delta=\Omega$ because $\Omega$ is connected, and hence the proof is complete.

To see that $\Delta$ is open, we choose any $x\in\Delta$, and choose $r>0$ such that $U=B_{\Rbb^N}(x,r)$ is contained in $\Omega$. Since $U$ is path-connected and hence connected, by Thm. \ref{lb584} and the fact that $df=0$, for every $y\in U$ we have $\Vert f(x)-f(y)\Vert=0$ and hence $f(y)=v$. So $U\subset\Delta$. This proves that $x$ is an interior point of $\Delta$.
\end{proof}

%% Record #1 2024/02/26 two lectures  2


\newpage

\section{Inner product spaces}

Hilbert spaces and measure theory are two parallel but deeply connected theories that arose in the study of Fourier series and differential equations. We will spend half the semester learning these two theories in turn. The climax of this entire story is the Riesz-Fischer theorem, which establishes a connection between these two theories.

In the following three chapters, we develop the basic theory of Hilbert spaces. A Hilbert space is defined to be a complete inner product space. This definition indicates that Hilbert spaces have two important aspects:
\begin{itemize}
\item Geometry: orthogonal and orthonormal vectors.
\item Analysis: completeness, and more.
\end{itemize}
We will focus on the geometric aspect in this chapter, and leave the discussion of the analytic aspect to the next chapter. As we shall see, the geometry of orthogonal vectors (together with the powerful \textbf{Gram-Schmidt process}) provides a uniform understanding of many identities and inequalities: Bessel's inequality (and its special case, Cauchy-Schwarz inequality), Parserval's identity. We will apply this geometric understanding to Fourier series. Surprisingly, the geometry of inner product spaces provides an elegant proof of the following analytic result: Every Riemann integrable function on $[-\pi,\pi]$ is the limit of its Fourier series under the $L^2$-norm.


When referring to Hilbert spaces and inner product spaces, it is usually assumed that the field is $\Cbb$, since complex Hilbert spaces are more useful than real ones. We will present the theory only for complex Hilbert spaces, although it can be easily adapted to real ones. 



Starting from this chapter, we adopt the notations \index{lp@$l^p(X)=l^p(X,\Cbb)$} \index{CX@$C(X)=C(X,\Cbb)$} \index{CcX@$C_c(X)=C_c(X,\Cbb)$}
\begin{gather}
\begin{gathered}
l^p(X)=l^p(X,\Cbb)\qquad C(X)=C(X,\Cbb)\qquad C_c(X)=C_c(X,\Cbb)
\end{gathered}
\end{gather}




\subsection{Inner product spaces}


We fix a complex vector space $V$.





\begin{df}
A map of complex vector spaces $T:V\rightarrow W$ is called \textbf{antilinear} or \textbf{conjugate linear} \index{00@Antilinear map} if for every $a,b\in\Cbb$ and $u,v\in V$ we have
\begin{align*}
T(au+bv)=\ovl au+\ovl bv
\end{align*}
where $\ovl a,\ovl b$ are the complex conjugates of $a,b$.
\end{df}


For example, the involution $*:\scr A\rightarrow\scr A$ of a $*$-algebra is antilinear (recall Def. \ref{lb586}).

\begin{df}
A function $\bk{\cdot|\cdot}:V\times V\rightarrow\Cbb$ (sending $u\times v\in V^2$ to $\bk{u|v}$) is called a \textbf{sesquilinear form} \index{00@Sesquilinear form} if it is linear on the first variable, and antilinear on the second one.\footnote{Physicists prefer the opposite convention, i.e., their sesquilinear forms are antilinear on the first variables.} Namely, for each $a,b\in\Cbb$ and $u,v,w\in V$ we have
\begin{gather*}
\bk{au+bv|w}=a\bk{u|w}+b\bk{v|w}\qquad \bk{w|au+bv}=\ovl a\bk{w|u}+\ovl b\bk{w|v}
\end{gather*}
More generally, if $V,W$ are complex vector spaces, a map $V\times W\rightarrow\Cbb$ is also called \textbf{sesquilinear} if it is linear on the $V$-component and antilinear on the $W$-component.
\end{df}


Notice the difference between the notations $\bk{u|v}$ and $\bk{u,v}$: the latter always means a bilinear form, i.e., a function which is linear on both variables.


\begin{pp}\label{lb587}
Suppose that $\bk{\cdot|\cdot}$ and $(\cdot|\cdot)$ are sesquilinear forms on $V$ satisfying $\bk{v|v}=(v|v)$ for all $v\in V$. Then $\bk{u|v}=(u|v)$ for all $u,v\in V$.
\end{pp}


\begin{proof}
Let us prove that $\bk{u|v}$ can be written in terms of expressions of the form $\bk{\xi|\xi}$ where $\xi\in V$. Choose any $t\in[-\pi,\pi]$. Let
\begin{align*}
f(t):=\bk{u+e^{\im t}v|u+e^{\im t}v}=\bk{u|u}+\bk{v|v}+e^{-\im t}\bk{u|v}+e^{\im t}\bk{v|u}
\end{align*}
Then $\bk{u|v}$ is a Fourier coefficient of $f$. Namely, using the fact that $\frac 1{2\pi}\int_{-\pi}^\pi e^{\im nt}dt=\delta_{n,0}$ (where $n\in\Zbb$), we have
\begin{align}\label{eq237}
\bk{u|v}=\frac 1{2\pi}\int_{-\pi}^\pi \bk{u+e^{\im t}v|u+e^{\im t}v}e^{\im t}dt
\end{align}
This finishes the proof.
\end{proof}

\begin{rem}
In practice, it is sometimes more convenient to have a discrete version of \eqref{eq237}: We view $f(t)$ as a function on the finite abelian group $\{0,\frac \pi 2,\pi,\frac{3\pi}2\}\simeq\Zbb/4\Zbb$. Then $\bk{u|v}$ is a coefficient of the ``discrete Fourier transform" of $f$:
\begin{align}\label{eq238}
\begin{aligned}
&\bk{u|v}=\frac 14\sum_{t=0,\frac \pi 2,\pi,\frac{3\pi}2}~ \bk{u+e^{\im t}v|u+e^{\im t}v}e^{\im t}\\
=&\frac 14\Big(\bk{u+v|u+v}-\bk{u-v|u-v}+\im\bk{u+\im v|u+\im v}-\im\bk{u-\im v|u-\im v}\Big)
\end{aligned}
\end{align}
We call \eqref{eq238} the \textbf{polarization identity}. \index{00@Polarization identity}
\end{rem}






\begin{df}
A function $\bk{\cdot|\cdot}:V\times V\rightarrow\Cbb$ is called a \textbf{Hermitian form} \index{00@Hermitian form} if it is linear on the first variable and satisfies $\ovl{\bk{u|v}}=\bk{v|u}$ for all $u,v\in V$. Then $\bk{\cdot|\cdot}$ is automatically antilinear on the second variable, i.e., a Hermitian form is automatically a sesquilinear form.
\end{df}

\begin{eg}
Let $A\in\Cbb^{N\times N}$ be a complex $N\times N$ matrix. Define $\bk{\cdot|\cdot}:\Cbb^N\times\Cbb^N\rightarrow\Cbb$ by $\bk{u|v}=\ovl{v^\tr}\cdot A\cdot u$ where $u,v$ are viewed as column vectors. Then $\bk{\cdot|\cdot}$ is a sesquilinear form on $\Cbb^N$. (It is an easy linear algebra exercise that every sesquilinear form on $\Cbb^N$ is of this form.) Moreover, $\bk{\cdot|\cdot}$ is a Hermitian form iff $A$ is a \textbf{Hermitian matrix}, i.e., $A=\ovl{A^\tr}$.
\end{eg}



The following is our first application of the polarization identity:

\begin{pp}\label{lb588}
Let $\bk{\cdot|\cdot}$ be a sesquilinear form on $V$. The following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $\bk{\cdot|\cdot}$ is a Hermitian form.
\item For each $v\in V$ we have $\bk{v|v}\in\Rbb$.
\end{enumerate}
\end{pp}


\begin{proof}
(1)$\Rightarrow$(2): Obvious. (2)$\Rightarrow$(1): Let $(u|v)=\ovl{\bk{v|u}}$. Then $(\cdot|\cdot)$ is a sesquilinear form on $V$. Assuming (2), we have $\bk{v|v}=(v|v)$ for all $v\in \Rbb$. Therefore, by Prop. \ref{lb587}, we have $\bk{u|v}=(u|v)=\ovl{\bk{v|u}}$ for all $u,v$. So (1) is true.
\end{proof}

\begin{df}\label{lb1026}
A sesquilinear form $\bk{\cdot|\cdot}$ on $V$ is called \textbf{positive semi-definite} (or simply \textbf{positive}) and written as $\bk{\cdot|\cdot}\geq0$, \index{00@Positive sesquilinear form} if $\bk{v|v}\geq0$ for all $v\in V$. If a positive sesquilinear form $\bk{\cdot|\cdot}$ on $V$ is fixed, we define
\begin{align}
\Vert v\Vert=\sqrt{\bk{v|v}}\qquad\text{ for all }v\in V
\end{align} 
A vector $v\in V$ satisfying $\Vert v\Vert=1$ is called a \textbf{unit vector}. \index{00@Unit vector} 
\end{df}

By Prop. \ref{lb588}, a positive sesquilinear form is Hermitian.

\begin{df}
Let $\bk{\cdot|\cdot}$ be a positive sesquilinear form on $V$. By sesquilinearity, we clearly have $\bk{0|0}=0$. We say that $\bk{\cdot|\cdot}$ is an \textbf{inner product} \index{00@Inner product} if it is also \textbf{non-degenerate}, i.e., if the only $v\in V$ satisfying $\bk{v|v}=0$ is $v=0$. We call the pair $(V,\bk{\cdot|\cdot})$ (or simply call $V$) an \textbf{inner product space} or a \textbf{pre-Hilbert space} \index{00@Inner product space, also called pre-Hilbert space}.
\end{df}



\begin{eg}
$\Cbb^N$, equipped with the Euclidean inner product $\bk{u|v}=\ovl{v^\tr}u$, is an inner product space. 
\end{eg}

\begin{eg}
Let $X$ be a set. Then $l^2(X,\Cbb)$, together with the standard inner product
\begin{align}
\bk{f|g}=\sum_{x\in X}f(x)\ovl{g(x)}
\end{align}
(where the RHS converges by Thm. \ref{lb369}), is an inner product space.
\end{eg}

\begin{eg}
Let $-\infty<a<b<+\infty$. Then $C([a,b],\Cbb)$, together with the inner product
\begin{align}\label{eq241}
\bk{f|g}=\int_a^b fg^*=\int_a^b f(x)\ovl{g(x)}dx
\end{align}
is an inner product space.
\end{eg}





The gap between positive forms and inner products is not very big:
\begin{pp}\label{lb589}
Let $\bk{\cdot|\cdot}$ be a positive sesquilinear form on $V$. Let
\begin{align}
\scr N=\{v\in V:\Vert v\Vert=0\}
\end{align} 
Then $\scr N$ is a linear subspace of $V$. Moreover, there is an inner product $(\cdot|\cdot)$ on the quotient space $V/\scr N$ satisfying
\begin{align}
(u+\scr N|v+\scr N)=\bk{u|v}\qquad\text{ for all }u,v\in V \label{eq239}
\end{align}
\end{pp}

The following proof suggests that Prop. \ref{lb589} is an abstraction of the basic fact that if $f(x,y)=ax^2+2bxy+cy^2$ is a real quadratic form, and if $b\neq0,c=0$, then $f$ cannot be positive.

\begin{proof}
Step 1. We claim that
\begin{align}
\scr N=\{v\in V:\bk{u|v}=0\text{ for all }u\in V \} \label{eq240}
\end{align}
Then the linearity of $\scr N$ follows immediately from \eqref{eq240}. Moreover, if we define a function $(\cdot|\cdot)$ on $V/\scr N$ by \eqref{eq239}, then it is well-defined: If $v+\scr N=v'+\scr N$, then $v-v'\in\scr N$. Thus, by \eqref{eq240}, we have $\bk{u|v-v'}=0$. So 
\begin{align*}
(u+\scr N|v+\scr N)=\bk{u|v}=\bk{u|v'}=(u+\scr N|v'+\scr N)
\end{align*}
A similar argument shows that if $u+\scr N=u'+\scr N$ then $(u+\scr N|v+\scr N)=(u'+\scr N|v+\scr N)$. This proves the well-definedness. It is easy to check that $(\cdot|\cdot)$ is sesquilinear and positive. If $(v+\scr N|v+\scr N)=0$, then $\bk{v|v}=0$ and hence $v\in \scr N$. This proves that $(\cdot|\cdot)$ is non-degenerate.\\[-1ex]


Step 2. Let us prove \eqref{eq240}. Clearly $\Vert v\Vert=\sqrt{\bk{v|v}}=0$ holds whenever $\bk{u|v}=0$ for all $u$. Conversely, suppose that $\Vert v\Vert=0$, i.e., $\bk{v|v}=0$. Choose any $u\in V$. Let us prove that $\Real\bk{u|v}=0$. Then replacing $u$ with $\im u$, we get $\Imag\bk{u|v}=0$. Hence $\bk{u|v}=0$, finishing the proof of \eqref{eq240}.


Consider the quadratic form $f(x,y)=\bk{xu+yv|xu+yv}$ where $x,y\in\Rbb$. Then $\bk{v|v}=0$ implies
\begin{align*}
f(x,y)=a x^2+2b\cdot xy
\end{align*} 
where $a=\Vert u\Vert^2$ and $b=\Real\bk{u|v}$. Suppose that $b\neq0$. Then $f$ contains a non-zero term of $xy$ but does not contain $y^2$, contradicting the positivity of $f$. More precisely: Choose any nonzero $x\in\Rbb$. Then we can easily find $y$ such that $f(x,y)<0$, contradicting the positivity of $\bk{\cdot|\cdot}$. So $b\equiv\Real\bk{u|v}$ must be $0$.
\end{proof}

\begin{eg}\label{lb599}
Let $-\infty<a<b<+\infty$ and $\scr V=\scr R[a,b]=\scr R([a,b],\Cbb)$ (the space of Riemann integrable complex functions on $[a,b]$). Then $\scr V$ has a positive sesquilinear form defined by \eqref{eq241}. Let $\scr N=\{f\in V:\bk{f|f}=0\}$. Then
\begin{align}\label{eq249}
\scr N=\{f\in\scr V:\text{ $f$ is zero outside a null subset of $[a,b]$}\}
\end{align}
%We will see in the future that $\scr N$ is the set of all $f:[a,b]\rightarrow\Cbb$ such that $\{x:f(x)\neq 0\}$ is a Lebesgue null set. 
Thus, $V=\scr V/\scr N$ is the set of all $f\in\scr R[a,b]$ such that $f,g\in\scr R[a,b]$ are viewed as the same element of $V$ iff $f=g$ almost everywhere (i.e. $\{x:f(x)\neq g(x)\}$ is null).
\end{eg}

%Eq. \eqref{eq249} is almost obvious after we learn Lebesgue theory. Here, we give an elementary proof.

\begin{proof}
Let $g=|f|^2$. We want to show that $\int g=0$ iff $\Delta=\{x\in[a,b]:g(x)> 0\}$ is null. Assume that $\int g>0$. Then $f$ has a strictly positive lower Darboux sum (recall Thm. \ref{lb444}). This implies that there exist $c,d$ satisfying $a\leq c<d\leq b$ such that $(d-c)\cdot \inf_{\xi\in[c,d]}g(\xi)>0$. So $g>0$ on $[c,d]$. So $\Delta$ contains $[c,d]$, and hence is not null.

Assume that $\int g=0$. By Lebesgue's criterion \ref{lb411}, $g$ is continuous outside a null subset of $[a,b]$. Thus, it suffices to prove that $g(p)=0$ for any $p\in[a,b]$ at which $g$ is continuous. Suppose that $\eps:=g(p)>0$. Then by the continuity, there is an interval $I\subset [a,b]$ containing $p$ with $|I|>0$ such that $g>\eps/2$ on $I$. Thus $g\geq\frac\eps 2\cdot\chi_I$, and hence $0=\int g\geq\frac\eps 2\cdot |I|$, impossible.
\end{proof}

\begin{comment}
For each $\mu>0$, let us prove that $\Delta_\mu=\{x\in[-\pi,\pi]:g(x)>\mu\}$ is null. Then $\Delta=\bigcup_{n\in\Zbb_+}\Delta_{1/n}$ is null by Prop. \ref{lb412}. Choose any $\eps,\delta>0$. By the proof of (2)$\Rightarrow$(1) in Lebesgue's Thm. \ref{lb411}, there is a partition of $[-\pi,\pi]$ cutting it into subintervals $I_1,I_2,\dots,J_1,J_2,\dots$ such that $\diam(g(I_i))<\eps$ for all $i$, and that $\sum_j |J_j|<\delta$. For each $I_i$ we let $M_i=\sup_{\xi\in I_i}g(\xi)$ and $m_i=\inf_{\xi\in I_i}g(\xi_i)$. So $g\geq \sum_i m_i\cdot\chi_i$. Since $\int g=0$, we conclude $m_i=0$. Since $\diam (g(I_i))=M_i-m_i$, we get $M_i<\eps$. Now, we choose $\eps$ such that $\eps<\mu$. Then $M_i<\mu$, and hence $I_i\cap \Delta_\mu=\emptyset$ for all $i$. Therefore $\Delta_\mu\subset\bigcup_j |J_j|$. Thus, for each $\delta>0$, $\Delta_\mu$ can be covered a union of closed invertals with total length $<\delta$. So $\Delta_\mu$ is null.
\end{comment}


We close this section with an elementary but important fact. It says that linear maps are determined by their associated sesquilinear forms.


\begin{exe}
Suppose that $S,T:U\rightarrow V$ are linear maps of inner product spaces. 
\begin{enumerate}
\item Prove that $S=T$ iff $\bk{Su|v}=\bk{Tu|v}$ for all $u\in U,v\in V$. 
\item Assume that $U=V$. Prove that $S=T$ iff $\bk{Sv|v}=\bk{Tv|v}$ for all $v\in V$.
\end{enumerate}
\end{exe}





\subsection{Pythagorean and Gram-Schmidt}

Unless otherwise stated, we fix an inner product $\bk{\cdot|\cdot}$ on a complex vector space $V$ so that $V$ is an inner product space.

\begin{df}
A set $\fk S$ of vectors of $V$ are called \textbf{orthogonal} \index{00@Orthogonal} if $\bk{u|v}=0$ for any distinct $u,v\in V$. An orthogonal set $\fk S$ is called \textbf{orthonormal} \index{00@Orthonormal} if $\Vert v\Vert=1$ for all $v\in V$. 
\end{df}

\begin{rem}
We will also talk about an \textbf{orthogonal} resp.  \textbf{orthonormal family of vectors} $(e_i)_{i\in I}$. This means that $\bk{e_i|e_j}=0$ for any distinct $i,j\in I$ (resp. $\bk{e_i|e_j}=\delta_{i,j}$ for any $i,j\in I$). 
\end{rem}

In particular, two vectors $u,v\in V$ are called orthogonal when $\bk{u|v}=0$. A fundamental fact about orthogonal vectors is
\begin{pp}[\textbf{Pythagorean identity}]\index{00@Pythagorean identity}
Suppose that $u,v\in V$ are orthogonal. Then
\begin{align}\label{eq243}
\Vert u+v\Vert^2=\Vert u\Vert^2+\Vert v\Vert^2
\end{align}
In particular,
\begin{align}\label{eq245}
\Vert v\Vert\leq\Vert u+v\Vert
\end{align}
\end{pp}



\begin{proof}
$\Vert u+v\Vert^2=\bk{u+v|u+v}=\bk{u|u}+\bk{v|v}+2\Real \bk{u|v}=\bk{u|u}+\bk{v|v}$.
\end{proof}

Note that by applying \eqref{eq243} repeatedly, we see that if $v_1,\dots,v_n\in V$ are orthogonal, then
\begin{align}\label{eq244}
\Vert v_1+\cdots+v_n\Vert^2=\Vert v_1\Vert^2+\cdots+\Vert v_n\Vert^2
\end{align}

\begin{rem}
Suppose that $\fk S$ is an orthonormal set of vectors of $V$. Then $\fk S$ is clearly linearly independent. (If $e_1,\dots,e_n\in\fk S$ and $\sum_i a_ie_i=0$, then $a_j=\sum_i\bk{a_ie_i|e_j}=\bk{0|e_j}=0$.) Thus, by linear algebra, if $\fk S=\{e_1,\dots,e_n\}$ is finite, then one can find uniquely $a_1,\dots,a_n\in\Cbb$ and $u\in V$ such that $v=a_1e_1+\cdots+a_ne_n+u$ and that $u$ is orthogonal to $e_1,\dots,e_n$. The expressions of $a_1,\dots,a_n,u$ can be expressed explicitly:
\end{rem}


\begin{pp}[\textbf{Gram-Schmidt}]\index{00@Gram-Schmidt}
Let $e_1,\dots,e_n$ be orthonormal vectors in $V$. Let $v\in V$. Then
\begin{align}
v-\sum_{i=1}^n \bk{v|e_i}\cdot e_i
\end{align}
is orthogonal to $e_1,\dots,e_n$.
\end{pp}

\begin{proof}
This is a direct calculation and is left to the readers.
\end{proof}

\begin{rem}\label{lb593}
``Gram-Schmidt" usually refers to the following process. Let $v_1,\dots,v_n$ be a set of linearly independent vectors of $V$. Then there is an algorithm of finding an orthonormal basis of $U=\Span\{v_1,\dots,v_n\}$: Let $e_1=v_1/\Vert v_1\Vert$. Suppose that a set of orthonormal vectors $e_1,\dots,e_k$ in $U$ have been found. Then $e_{k+1}$ is defined by $\wtd v_{k+1}/\Vert\wtd v_{k+1}\Vert$ where $\wtd v_{k+1}=v_{k+1}-\sum_{i=1}^k \bk{v_{k+1}|e_i}\cdot e_i$.
\end{rem}



Combining Pythagorean with Gram-Schmidt, we have:
\begin{co}[\textbf{Bessel's inequality}]\label{lb634}
Let $(e_i)_{i\in I}$ be a family of orthonormal vectors of $V$. Then for each $v\in V$ we have
\begin{align}\label{eq242}
\sum_{i\in I}|\bk{v|e_i}|^2\leq \Vert v\Vert^2
\end{align}
In particular, the set $\{i\in I:\bk{v|e_i}\neq0\}$ is countable.
\end{co}

\begin{proof}
The LHS of \eqref{eq242} is $\lim_{J\in\fin(2^I)}\sum_{j\in J}|\bk{v|e_j}|^2$. Thus, it suffices to show that for each $J\in\fin(2^I)$ we have $\sum_{j\in J}|\bk{v|e_j}|^2\leq \Vert v\Vert^2$. Let 
\begin{align*}
u_1=\sum_{j\in J}\bk{v|e_j}\cdot e_j\qquad u_2=v-u_1
\end{align*}
(Namely, $v=u_1+u_2$ is the orthogonal decomposition of $v$ with respect to $\Span\{e_j:j\in J\}$.) By Gram-Schmidt, we have $\bk{u_1|u_2}=0$. By Pythagorean, we have $\Vert u_1\Vert^2\leq\Vert v\Vert^2$. But Pythagorean \eqref{eq244} also implies
\begin{align*}
\Vert u_1\Vert^2=\sum_{j\in J}|\bk{v|e_j}|^2
\end{align*}
The last statement about countability follow from Pb. \ref{lb413}.
\end{proof}


\begin{thm}[\textbf{Cauchy-Schwarz inequality}]\index{00@Cauchy-Schwarz inequality}\label{lb590}
For each $u,v\in V$ we have
\begin{align}
|\bk{u|v}|\leq \Vert u\Vert\cdot\Vert v\Vert
\end{align}
\end{thm}

\begin{proof}
If $v=0$, then the inequality trivially holds. Assume $v\neq 0$. Then $\Vert v\Vert\neq0$. By dividing $v$ by $\Vert v\Vert$, we assume $\Vert v\Vert=1$. Then $\{v\}$ is a set of orthonormal vector. By Bessel's inequality, we have $|\bk{u|v}|\leq\Vert u\Vert$. 
\end{proof}

\begin{rem}\label{lb654}
In the general case that $\bk{\cdot|\cdot}$ is a positive sesquilinear form, the Cauchy-Schwarz inequality $|\bk{u|v}|^2\leq\bk{u|u}\cdot\bk{v|v}$ still holds.
\end{rem}

\begin{proof}
We use the notations in Prop. \ref{lb589}. Applying Thm. \ref{lb590} to $V/\scr N$, we have $|(u+\scr N|v+\scr N)|^2\leq(u+\scr N|u+\scr N)\cdot(v+\scr N|v+\scr N) $. This proves $|\bk{u|v}|^2\leq\bk{u|u}\cdot\bk{v|v}$.
\end{proof}

\begin{co}
$V$ is a normed vector space if we define $\Vert v\Vert=\sqrt{\bk{v|v}}$. 
\end{co}

\begin{proof}
By Cauchy-Schwarz, we have
\begin{align*}
\Vert u+v\Vert^2=\Vert u\Vert^2+\Vert v\Vert^2+2\Real\bk{u|v}\leq \Vert u\Vert^2+\Vert v\Vert^2+2\Vert u\Vert\cdot\Vert v\Vert=(\Vert u\Vert+\Vert v\Vert)^2
\end{align*}
This proves the triangle inequality. The other conditions are obvious.
\end{proof}

\begin{co}\label{lb594}
The map $\bk{\cdot|\cdot}:V\times V\rightarrow\Cbb$ is continuous if $V$ is equipped with the norm topology. 
\end{co}

\begin{proof}
For each $u,u_0,v,v_0\in V$ such that $\Vert u-u_0\Vert\leq\eps,\Vert v-v_0\Vert\leq\eps$ where $0<\eps<1$, we have by Cauchy-Schwarz that
\begin{align*}
|\bk{u|v}-\bk{u_0|v_0}|\leq|\bk{u-u_0|v}|+|\bk{u_0|v-v_0}|\leq \eps (\Vert v_0\Vert+1)+\eps\Vert u_0\Vert
\end{align*}
\end{proof}



\begin{rem}
Since $V$ is a normed vector space, $V$ is also a metric space with $d(u,v)=\Vert u-v\Vert=\sqrt{\bk{u-v|u-v}}$. Now, the polarisation identity (Prop. \ref{lb587}) says that for inner product spaces, \uwave{norms determine inner produts}, and hence \uwave{metrics determine inner products}. Therefore, if $W$ is an inner product space, and if $T:V\rightarrow W$ is a linear isometry, then
\begin{align*}
\bk{Tu|Tv}=\bk{u|v}
\end{align*}
for all $u,v\in V$. In particular, if $T$ is an isomorphism of normed vector sapces (i.e., $T$ is a linear surjective isometry, cf. Def. \ref{lb302}), then $T$ is an equivalence of inner product spaces. In this case, we say that $T$ is a \textbf{unitary map}, \index{00@Unitary maps} and say that $V,W$ are \textbf{isomorphic inner product spaces} (or that $V,W$ are \textbf{unitarily equivalent}). \index{00@Unitarily equivalent} \hfill\qedsymbol
\end{rem}



\subsection{Orthogonal decompositions}

Fix an inner product space $V$. In the last section, we used Gram-Schmidt process and Pythagorean inequality \eqref{eq245} to derive many useful inequalities. In this section, we will have a deeper understanding of the geometry behind Gram-Schmidt process and orthogonal projections.


\begin{df}\label{lb615}
Let $U$ be a linear subspace of $V$. Let $v\in V$. An \textbf{orthogonal decomposition} \index{00@Orthogonal decomposition and orthonal projection} of $v$ with respect to $U$ is an expression of the form $v=u+w$ where $u\in U$ and $w\perp U$ (i.e. $w$ is orthogonal to every vector of $U$). Orthogonal decompositions of $v$ are unique if exist. We call $u$ the \textbf{orthogonal projection} of $v$ onto $U$.
\end{df}

\begin{proof}[Proof of uniqueness]
Suppose that $v=u'+w'$ is another orthogonal decomposition. Then $u-u'$ equals $w'-w$. Let $\xi=u-u'$. Then $\xi\in U$ and $\xi\perp U$. So $\bk{\xi|\xi}=0$, and hence $\xi=0$. So $u=u'$ and $w=w'$.
\end{proof}

\begin{eg}
Let $e_1,\dots,e_n$ be orthonormal vectors of $V$. Let $U=\Span\{e_1,\dots,e_n\}$. Choose any $v\in V$. Then by Gram-Schmidt, $v=u+w$ is the orthogonal decomposition if we let $u=\sum_{i=1}^n\bk{v|e_i}e_i$ and $w=v-u$.
\end{eg}

The inequalities in the last section relies on the Pythagorean inequality $\Vert u\Vert\leq \Vert v\Vert$ for an orthogonal decomposition $v=u+w$. In this section, we need an optimization property about orthogonal decompositions:

\begin{pp}\label{lb591}
Let $U$ be a linear subspace of $V$. Suppose that $v\in V$ has orthogonal decomposition $v=u+w$ with respect to $U$. Then
\begin{align}
\Vert v-u\Vert=\inf_{\xi\in U}\Vert v-\xi\Vert
\end{align}
\end{pp}

\begin{proof}
Clearly ``$\geq$" holds. Choose any $\xi\in U$. Then $v-\xi=v-u+u-\xi=w+(u-\xi)$. Since $u-\xi\in U$, we have $w\perp u-\xi$. Thus, by Pythagorean, we have $\Vert w\Vert\leq\Vert v-\xi\Vert$.
\end{proof}

\begin{co}\label{lb592}
Let $e_1,\dots,e_n$ be orthonormal vectors of $V$. For each $v\in V$ and $\lambda_1,\dots,\lambda_n\in\Cbb$ we have
\begin{align}
\Vert v\Vert^2-\sum_{i=1}^n|\bk{v|e_i}|^2=\Big\Vert v-\sum_{i=1}^n\bk{v|e_i}e_i\Big\Vert^2\leq \Big\Vert v-\sum_{i=1}^n \lambda_ie_i\Big\Vert^2
\end{align}
\end{co}

\begin{proof}
By Gram-Schmidt, we have orthogonal decomposition $v=u+w$ where $w=\sum_i\bk{v|e_i}e_i$. The Pythagorean identity $\Vert v\Vert^2-\Vert u\Vert^2=\Vert w\Vert^2$ proves the first equality. Prop. \ref{lb591} proves the ``$\leq$".
\end{proof}


We now give several applications of Cor. \ref{lb592}.


\begin{df}\label{lb611}
A set $\fk S$ (or a family $(e_i)_{i\in I}$) of orthonormal vectors of $V$ is called an \textbf{orthonormal basis} \index{00@Orthonormal basis} of $V$ if it spans a dense subspace of $V$.  
\end{df}

\begin{eg}
If $X$ is a set, by Lem. \ref{lb528}, $l^2(X)$ has an orthonormal basis $(\chi_{\{x\}})_{x\in X}$.
\end{eg}





\begin{eg}\label{lb613}
If $V$ is separable, then $V$ has a countable orthonormal basis.
\end{eg}

\begin{proof}
Let $\{v_1,v_2,\dots\}$ be a dense subset of $V$ where $v_1\neq 0$. Then by Gram-Schmidt (Rem. \ref{lb593}), we can find $e_1,e_2,\dots\in V$ such that the set $\{e_1,e_2,\dots\}$ is orthnormal (after removing the duplicated terms), and that $\Span\{v_1,\dots,v_n\}=\Span\{e_1,\dots,e_n\}$ for each $n$. Then $\{e_1,e_2,\dots\}$ clearly spans a dense subspace of $V$.
\end{proof}

We remark that there are non-separable and non-complete inner product spaces that do not have orthonormal bases. See \cite{Gud74}.


\begin{thm}\label{lb595}
Suppose that $(e_i)_{i\in I}$ is an orthonormal basis of $V$. Then for each $v\in V$, the RHS of the following converges (under the norm of $V$) to the LHS:
\begin{align}
v=\sum_{i\in I}\bk{v|e_i}\cdot e_i
\end{align}
\end{thm}

\begin{proof}
Note that for $J\in\fin(2^I)$, the expression
\begin{align*}
\Big\Vert v-\sum_{j\in J}\bk{v|e_j}e_j\Big\Vert^2=\Vert v\Vert^2-\sum_{j\in J}|\bk{v|e_j}|^2
\end{align*}
decreases when $J$ increases. Thus, it suffices to prove that the $\inf_{J\in \fin(2^I)}$ of this expression is $0$. This follows immediately from Cor. \ref{lb592} and the fact that we can find $J$ and $(\lambda_j)_{j\in J}$ in $\Cbb$ such that $\Vert v-\sum_{j\in J}\lambda_je_j\Vert$ is small enough.
\end{proof}

\begin{co}[\textbf{Parseval's identity}]\index{00@Parseval's identity}\label{lb601}
Suppose that $(e_i)_{i\in I}$ is an orthonormal basis of $V$. Then for each $u,v\in V$ we have
\begin{align}\label{eq246}
\bk{u|v}=\sum_{i\in I}\bk{u|e_i}\cdot\bk{e_i|v}
\end{align}
In particular,
\begin{align}
\Vert v\Vert^2=\sum_{i\in I}|\bk{v|e_i}|^2
\end{align}
\end{co}

\begin{proof}
By Thm. \ref{lb595}, $u=\lim_{J\in\fin(2^I)}u_J$ where $u_J=\sum_{j\in J}\bk{u|e_j}\cdot e_j$. By the continuity of $\bk{\cdot|\cdot}:V\times V\rightarrow\Cbb$ (Cor. \ref{lb594}), we have
\begin{align*}
\bk{u|v}=\lim_{J\in\fin(2^I)}\bk{u_J|v}=\lim_{J\in\fin(2^I)}\sum_{j\in J}\bk{u|e_j}\cdot\bk{e_j|v}=\sum_{i\in I}\bk{u|e_i}\cdot\bk{e_i|v}
\end{align*}
\end{proof}



\begin{rem}
In Hilbert's original definition, an orthonormal basis $(e_i)_{i\in I}$ (called by Hilbert a complete orthogonal system of functions) is a set of orthonormal vectors satisfying Parseval's identity \eqref{eq246} for all $u,v\in V$. Hilbert did not have the topological understanding of orthonormal basis as in Def. \ref{lb611} (i.e., a set of orthonormal vectors spanning a \textit{dense} subspace of $V$). See \cite[Sec. 8]{BK84}.
\end{rem}



\begin{co}\label{lb602}
Suppose that $(e_x)_{x\in X}$ is an orthonormal basis of $V$. Then there is a linear isometry
\begin{gather}\label{eq247}
\Phi:V\rightarrow l^2(X)\qquad v\mapsto \big(\bk{v|e_x})_{x\in X}
\end{gather} 
whose range is dense in $l^2(X)$.
\end{co}

Since $l^2(X)$ is complete (Thm. \ref{lb596}), it follows that $\Phi$ gives a Banach space completion of $V$, cf. Def. \ref{lb597}.


\begin{proof}
Parseval's identity shows that $(\bk{v|e_x})_{x\in X}$ has finite $l^2$-norm $\Vert v\Vert$. So the map $\Phi$ defined by \eqref{eq247} is clearly a linear isometry.
\end{proof}



\subsection{Application to Fourier series}

In this section, we apply the results about inner product spaces to the study of Fourier series.

Let $\scr V=\scr R[-\pi,\pi]=\scr R([-\pi,\pi],\Cbb)$, the vector space of (strongly) Riemann integrable complex valued functions on $[-\pi,\pi]$. For each $f\in\scr V$ and $n\in\Zbb$, define its $n$-th \textbf{Fourier coefficient} to be
\begin{align}\label{eq248}
\wht f(n)=\frac 1{2\pi}\int_{-\pi}^\pi f(x)e^{-\im nx}dx=\frac 1{2\pi}\int_{-\pi}^\pi fe_{-n}
\end{align}
where $e_n(x)=e^{\im nx}$. Then the \textbf{Fourier series} of $f$ is
\begin{align}\label{eq293}
\sum_{n\in\Zbb}\wht f(n)e_n
\end{align}
We view $\wht f$ as a function on $\Zbb$.

In Fourier analysis, one asks whether the Fourier series of $f$ converges to $f$, and if so, in which sense does it converge? We have seen in Subsec. \ref{lb598} that \eqref{eq293} might not converge uniformly to $f$. We have also mentioned there that \eqref{eq293} might be divergent at many points of $[-\pi,\pi]$, although in many cases it converges pointwise to $f$ (cf. Pb. \ref{lb447}). In this section, we will see that \eqref{eq293} converges to $f$ under the $L^2$-norm. Another important result of this section is the classification of all $f$ whose Fourier modes are all $0$. %Historically, this is a main motivation for Cantor to study set theory.



Let $V$ be the vector space of all $f\in\scr R[-\pi,\pi]$, where $f,g\in\scr R[-\pi,\pi]$ are equal elements in $V$ iff $\{x\in[-\pi,\pi]:f(x)\neq g(x)\}$ is null. By Exp. \ref{lb599}, $V$ is an inner product space whose inner product $\bk{\cdot|\cdot}$ is defined by
\begin{align}\label{eq250}
\bk{f|g}=\frac{1}{2\pi}\int_{-\pi}^\pi fg^*=\frac{1}{2\pi}\int_{-\pi}^\pi f(x)\ovl{g(x)}
\end{align}
It follows that
\begin{align}
\wht f(n)=\bk{f|e_n}
\end{align}

\begin{pp}\label{lb600}
$\{e_n:n\in\Zbb\}$ is an orthonormal basis of $V$.
\end{pp}

\begin{proof}
Clearly $\{e_n:n\in\Zbb\}$ is an orthonormal set of vectors. By Stone-Weierstrass, $\Span\fk S$ is $l^\infty$-dense in $C(\Sbb^1)$, the space of $2\pi$-periodic continuous functions (cf. Exp. \ref{lb443}). So $\Span\fk S$ is $L^2$-dense in $C(\Sbb^1)$. Indeed, for any $f\in C(\Sbb^1)$, pick a sequence $(f_k)_{k\in\Zbb_+}$ of elements in $\Span\fk S$ converging uniformly on $[-\pi,\pi]$ to $f$. Therefore $\lim_{k\rightarrow\infty}\int|f-f_k|^2=0$ by Cor. \ref{lb380}.

To show that $\Span\fk S$ is dense in $V$, it remains to prove that $C(\Sbb^1)$ is $L^2$-dense in $V$. Let $\mc S=\Span\{\chi_{I}:I\text{ is an interval in }[-\pi,\pi]\}$. It is easy to see that each $\chi_I$ can be $L^2$-approximated by elements of $C(\Sbb^1)$. Therefore, it suffices to prove that $\mc S$ is $L^2$-dense in $V$.

Let $f\in\scr R[-\pi,\pi]$. We want to show that $f$ can be $L^2$-approximated by elements of $\mc S$. By considering the real part and the imaginary part separately, we assume that $f$ is real. Let $M=\Vert f\Vert_{l^\infty}$, which is finite. By the proof of Prop. \ref{lb445} (or by approximating $\int f$ by upper Darboux sums, cf. Thm. \ref{lb444}), we can find a sequence $(f_n)$ in $\mc S$ such that $\lim_n\int_{-\pi}^\pi |f-f_n|=0$, and that $|f_n|\leq M$ for all $n$. Therefore
\begin{align*}
\int_{-\pi}^\pi |f-f_n|^2\leq 2M\int_{-\pi}^\pi |f-f_n|
\end{align*}
where the RHS converges to $0$ as $n\rightarrow\infty$.
\end{proof}



\begin{co}
Let $f\in\scr R[-\pi,\pi]$. Then the following are equivalent
\begin{enumerate}[label=(\arabic*)]
\item Each Fourier coefficient $\wht f(n)$ is $0$.
\item $f$ is zero outside a null set.
\end{enumerate}
\end{co}

\begin{proof}
This is immediate from Prop. \ref{lb600} and the obvious fact that a vector in an inner product space (equipped with an orthonormal basis) is zero iff its inner product with any element in the orthonormal basis (or more generally, any element in a densely-spanning subset) is zero.
\end{proof}


\begin{thm}
Let $f,g\in\scr R[a,b]$. Then we have \textbf{Parseval's identity}
\begin{align}
\frac 1{2\pi}\int_{-\pi}^\pi fg^*=\sum_{n=-\infty}^{+\infty} \wht f(n)\ovl{\wht g(n)}
\end{align}
where the RHS converges absolutely. In particular,
\begin{align}
\frac 1{2\pi}\int_{-\pi}^\pi|f|^2=\sum_{n=-\infty}^{+\infty}|\wht f(n)|^2
\end{align}
Moreover, we have
\begin{align}
\lim_{m,n\rightarrow+\infty} \int_{-\pi}^\pi \Big|f-\sum_{k=-m}^n \wht f(k)e_k\Big|^2=0
\end{align}
\end{thm}

\begin{proof}
Immediate from Cor. \ref{lb601} and Thm. \ref{lb595}.
\end{proof}



\begin{co}\label{lb603}
The space $C[-\pi,\pi]$, under the inner product \eqref{eq250}, has a Banach space completion
\begin{gather}
C[-\pi,\pi]\rightarrow l^2(\Zbb)\qquad f\mapsto \wht f
\end{gather}
The same is true if $C[-\pi,\pi]$ is replaced by $V$.
\end{co}
\begin{proof}
Prop. \ref{lb600} implies that $\{e_n:n\in\Zbb\}$ is also an orthonormal basis of $C[-\pi,\pi]$. Thus, the corollary follows from Cor. \ref{lb602}.
\end{proof}










\subsection{Problems and supplementary material}


\subsubsection{$\star$ The Sobolev space $H^s(\Sbb^1)$}


For each $s\geq0$, and for each $\varphi:\Zbb\rightarrow\Cbb$, let 
\begin{align}
\Vert \varphi\Vert_{h^s}=\sum_{n\in\Zbb}(1+n^2)^s|\varphi(n)|^2
\end{align}
It is clear that $\Vert \varphi\Vert_{h^0}=\Vert \varphi\Vert_2$, and that
\begin{align*}
s\leq t\qquad\Longrightarrow\qquad \Vert \varphi\Vert_{h^s}\leq \Vert \varphi\Vert_{h^t}
\end{align*} 
Define 
\begin{gather}
h^s(\Zbb)=\{\varphi\in \Cbb^\Zbb:\Vert \varphi\Vert_{h^s}<+\infty\}
\end{gather}
which is clearly a subset of $l^2(\Zbb)$. Clearly $h^s(\Zbb)\supset h^t(\Zbb)$ if $s\leq t$.

\begin{prob}
Prove that $h^s(\Zbb)$ is a linear subspace of $l^2(\Zbb)$, that $h^s(\Zbb)$ has a well-defined inner product described by
\begin{align}
\bk{\varphi|\psi}_{h^s}=\sum_{n\in\Zbb}(1+n^2)^s\varphi(n)\ovl{\psi(n)}
\end{align}
and that $h^s(\Zbb)$ is complete under this inner product.
\end{prob}


Let $C(\Sbb^1)$ be the set of complex continuous functions on $\Sbb^1$, equivalently, continuous $2\pi$-periodic functions on $\Rbb$. More generally, for each $n\in\Nbb\cup\{\infty\}$, let
\begin{align}
C^n(\Sbb^1)=\{2\pi\text{-periodic }f\in C^n(\Rbb)\}
\end{align}
Equip $C(\Sbb^1)$ with the inner product $\bk{f|g}=\frac 1{2\pi}\int_{-\pi}^\pi fg^*$. The norm determined by this inner product is called the $L^2$-norm. By Cor. \ref{lb603}, we have a Hilbert space completion
\begin{gather}
\Phi:C(\Sbb^1)\rightarrow l^2(\Zbb)\qquad f\mapsto \wht f
\end{gather}
Recall that $e_n(x)=e^{\im nx}$.

\begin{prob}\label{lb604}
Prove that $l^1(\Zbb)\subset\Phi(C(\Sbb^1))$, and that the linear injection
\begin{align}
\Phi^{-1}:l^1(\Zbb)\rightarrow C(\Sbb^1)
\end{align}
can be described by
\begin{align}
\Phi^{-1}(\varphi)=\sum_{n\in\Zbb} \varphi(n)e_n
\end{align}
where the RHS converges under the $l^\infty(\Sbb^1)$-norm (and hence under the $L^2$-norm).
\end{prob}

\begin{prob}\label{lb605}
Let $s>\frac 12$. Prove that $h^s(\Zbb)\subset l^1(\Zbb)$.
\end{prob}

\begin{proof}[Hint]
Use Cauchy-Schwarz or H\"older's inequality.
\end{proof}

\begin{df}
Let $s>\frac 12$. Define
\begin{align}
H^s(\Sbb^1)\xlongequal{\mathrm{def}}\Phi^{-1}(h^s(\Zbb))
\end{align}
According to Pb. \ref{lb604} and \ref{lb605}, we have 
\begin{align}\label{eq251}
H^s(\Sbb^1)\subset\Phi^{-1}(l^1(\Zbb)) \subset C(\Sbb^1)
\end{align}
and $\Phi$ restricts to a linear bijection
\begin{align}
\Phi: H^s(\Sbb^1)\xlongrightarrow{\simeq} h^s(\Zbb)
\end{align}
whose inverse sends
\begin{align*}
\varphi\mapsto \sum_{n\in\Zbb}\varphi(n)e_n
\end{align*}
where the RHS converges uniformly. Define inner product $\bk{\cdot|\cdot}_{H^s}$ on $H^s(\Sbb^1)$ to be the pullback of  $h^s$, i.e.
\begin{align}
\bk{f|g}_{H^s}=\bk{\wht f|\wht g}_{h^s}=\sum_{n=-\infty}^{+\infty} (1+n^2)^s\wht f(n)\ovl{\wht g(n)}
\end{align}
Then $H^s(\Sbb^1)$ is a Hilbert space since $h^s(\Zbb)$ is so. We call $H^s(\Sbb^1)$ a \textbf{Sobolev space} \index{00@Sobolev space $H^s(\Sbb^1)$} of $\Sbb^1$. Thus $\Phi$ is a unitary map.
\end{df}


\begin{prob}\label{lb607}
Let $k\in\Zbb_+$. Prove that $C^k(\Sbb^1)\subset H^k(\Sbb^1)$. Prove for each $f\in C^{2k}(\Sbb^1),g\in H^k(\Sbb^1)$ that
\begin{align}
\bk{f|g}_{H^k}=\frac 1{2\pi}\int_{-\pi}^\pi (1-\partial^2)^kf\cdot g^* \label{eq252}
\end{align}
where $\partial f=f'$.
\end{prob}


\begin{proof}[Hint]
For each $f\in C^k(\Sbb^1)$, prove by induction on $k$ that
\begin{align}
\wht{f^{(k)}}(n)=(\im n)^k\wht f(n)
\end{align}
Apply Parserval's identity to $\int |f^{(k)}|^2$ and to the RHS of \eqref{eq252}.
\end{proof}

As an application, we obtain a useful criterion for the uniform convergence of Fourier series:

\begin{co}
If $f\in C^1(\Sbb^1)$, then $\sum_{n\in\Zbb}\wht f(n)e_n$ converges uniformly to $f$.
\end{co}

\begin{proof}
By Pb. \ref{lb607} and \eqref{eq251}, we have $f\in C^1(\Sbb^1)\subset H^1(\Sbb^1)\subset \Phi^{-1}(l^1(\Zbb))$. Since $\wht f=\Phi(f)$ and hence $f=\Phi^{-1}(\wht f)$, by Pb. \ref{lb604} (the description of $\Phi^{-1}$ on $l^1(\Zbb)$), $\sum_{n\in\Zbb}\wht f(n)e_n$ converges uniformly to $f$. 
\end{proof}

\begin{thm}
Let $k\in\Zbb_+$. Then $H^k(\Sbb^1)$ is the Hilbert space completion of $C^\infty(\Sbb^1)$ under the inner product defined by \eqref{eq252} for all $f,g\in C^\infty(\Sbb^1)$.
\end{thm}

\begin{proof}
Equip $C^\infty(\Sbb^1)$ with the inner product defined by \eqref{eq252}. We know that
\begin{align}
\Phi:C^\infty(\Sbb^1)\rightarrow h^k(\Zbb)\qquad f\mapsto \wht f  \label{eq253}
\end{align}
is a linear isometry. Since $\Phi(e_n)=\delta_{\{n\}}$, the range of $\Phi$ contains $\Span\{\chi_{\{n\}}:n\in\Zbb\}$. From this it follows easily that the range is dense in $h^k(\Zbb)$. Thus, $\Phi$ gives a completion of $C^\infty(\Sbb^1)$. This is equivalent to saying that the inclusion map $C^\infty(\Sbb^1)\hookrightarrow H^k(\Sbb^1)$ is a completion of $C^\infty(\Sbb^1)$ (since \eqref{eq253} extends to a unitary map $\Phi:H^k(\Sbb^1)\rightarrow h^k(\Zbb)$).
\end{proof}



\begin{prob}\label{lb606}
Suppose that $s>\frac 32$. Prove that the map of derivative $\partial:C^1(\Sbb^1)\rightarrow C(\Sbb^1),f\mapsto f'$ restricts to
\begin{align}
\partial: H^s(\Sbb^1)\rightarrow H^{s-1}(\Sbb^1)
\end{align}
(Namely, prove that each $f\in H^s(\Sbb^1)$ is differentiable, and that $f'$ belongs to $H^{s-1}(\Sbb^1)$.) Prove for each $f\in H^s(\Sbb^1)$ that
\begin{align}
\Phi(f')(n)=\im n\wht f(n)
\end{align}
\end{prob}

\begin{proof}[Hint]
By Pb. \ref{lb604}, we have uniform convergence $f=\sum_{n\in\Zbb}\wht f(n)e_n$ where $\wht f\in h^s(\Zbb)$. Show that $\sum_{n\in\Zbb}\im n\wht f(n)e_n$ converges uniformly. Then use (for example) Thm. \ref{lb336}.
\end{proof}

\begin{thm}[\textbf{Sobolev embedding}]\label{lb608}
If $s>\frac 12$, then $H^s(\Sbb^1)\subset C^{\lceil s-\frac 32\rceil}(\Sbb^1)$ where $\lceil s-\frac 32\rceil$ is the smallest integer $\geq s-\frac 32$.
\end{thm}

\begin{proof}
Choose $f\in H^s(\Sbb^1)$. By \eqref{eq251} we have $f\in C(\Sbb^1)$. Thus the theorem is proved when $\frac 12<s\leq \frac 32$. Suppose that $s>\frac 32$. Let $k=\lceil s-\frac 32\rceil$. Then $\frac 12<s-k\leq \frac 32$. By Pb. \ref{lb606}, we have $f'\in H^{s-1}(\Sbb^1),f''\in H^{s-2}(\Sbb^1),\dots$, and hence $f^{(k)}\in H^{s-k}(\Sbb^1)\subset C(\Sbb^1)$. This proves $f\in C^k(\Sbb^1)$.
\end{proof}


\begin{co}
We have $C^\infty(\Sbb^1)=\bigcap_{k\in\Zbb_+}H^k(\Sbb^1)=\bigcap_{s>\frac 12}H^s(\Sbb^1)$.
\end{co}
\begin{proof}
By Pb. \ref{lb607}, Thm. \ref{lb608}, and the fact that $H^s(\Sbb^1)$ decreases as $s$ increases.
\end{proof}


\newpage




\section{Hilbert spaces}\label{lb665}

\begin{df}\label{lb609}
An inner product space $\mc H$ is called a \textbf{Hilbert space} \index{00@Hilbert space} if it is complete under the norm defined by $\Vert\xi\Vert=\sqrt{\bk{\xi|\xi}}$.
\end{df}

\begin{rem}
Let $\mc H$ be a Hilbert space. Since a subset of a complete metric space is complete iff it is closed (Prop. \ref{lb86}), the phrases ``closed linear subspaces of $\mc H$" and ``Hilbert subspaces of $\mc H$" are synonymous.
\end{rem}

\begin{eg}
If $\mc H$ is a finite-dimensional inner product space, then $\mc H$ is a Hilbert space. 
\end{eg}

\begin{proof}
Since $\mc H$ is spanned by finitely many vectors, by Gram-Schmidt process, $\mc H$ has an orthonormal basis $(e_x)_{x\in X}$ where $X$ is a finite set. The canonical linear isometry $\Phi:\mc H\rightarrow l^2(X)$ in Cor. \ref{lb602} must be surjective. So $\mc H\simeq l^2(X)$. Hence $\mc H$ is complete.
\end{proof}




\begin{thm}
Let $V$ be an inner product space. Then $V$ has a \textbf{Hilbert space completion}, \index{00@Hilbert space completion} i.e., a Hilbert space $\mc H$ and a linear isometry $\Phi:V\rightarrow\mc H$ with dense range.

Moreover, Hilbert space completions are unique up to unitary equivalences: If $\Psi:V\rightarrow\mc K$ is another Hilbert space completion, then there is a unitary $\Gamma:\mc H\rightarrow\mc K$ such that the following diagram commutes:
\begin{equation}
\begin{tikzcd}[column sep=small]
                     & V \arrow[ld,"\Phi"'] \arrow[rd,"\Psi"] &   \\
\mc H \arrow[rr, "\Gamma","\simeq"'] &                         & \mc K
\end{tikzcd}
\end{equation}
\end{thm}

When no confusion arises, we identify $V$ with $\Phi(V)$ so that $V$ can be viewed as a dense inner product subspace of $\mc H$.

\begin{proof}
Since $V$ is a normed vector space, by Thm. \ref{lb312}, we have a Banach space $\mc H$ (with norm $\Vert\cdot\Vert_{\mc H}$) and a linear isometry $\Phi:V\rightarrow\mc H$ with dense range. We assume WLOG that $V$ is a normed vector subspace of $\mc H$ so that the norm $\Vert\cdot\Vert_{\mc H}$ restricts to that of $V$. Define a function $\bk{\cdot|\cdot}_{\mc H}:\mc H\times\mc H\rightarrow\Cbb$ using the polarization identity \eqref{eq238}, i.e., for each $\xi,\eta\in\mc H$ we set
\begin{align*}
\bk{\xi|\eta}_{\mc H}=\frac 14\sum_{t=0,\frac \pi 2,\pi,\frac{3\pi}2}~ \Vert\xi+e^{\im t}\eta\Vert_{\mc H}^2\cdot e^{\im t}
\end{align*}
Then $\bk{\cdot|\cdot}_{\mc H}$ restricts to the inner product $\bk{\cdot|\cdot}$ of $V$. Moreover, the function $\bk{\cdot|\cdot}_{\mc H}$ is continuous (with respect to the norm $\Vert\cdot\Vert_{\mc H}$), and $V\times V$ is a dense subset of $\mc H\times\mc H$. Therefore, as in the proof of Thm. \ref{lb312}, we can use the fact that $\bk{\cdot|\cdot}$ is an inner product on $V$ to prove that $\bk{\cdot|\cdot}_{\mc H}$ is a positive sesquilinear form on $\mc H$, and we can use the fact that the norm of $V$ is defined by the inner product of $V$ to prove that $\Vert\xi\Vert_{\mc H}^2=\bk{\xi|\xi}_{\mc H}$. Therefore, $\bk{\cdot|\cdot}_{\mc H}$ is non-degenerate, i.e., an inner product, and this inner product defines the complete norm $\Vert\cdot\Vert_{\mc H}$. It follows that $\mc H$ is a Hilbert space, and hence a Hilbert space completion of $V$.

The uniqueness of Hilbert space completions (up to unitary equivalences) follows directly from that of Banach space completions, cf. Thm. \ref{lb312}.
\end{proof}








\subsection{Introduction: completeness, the most familiar stranger}\label{lb671}

\begin{comment}
\begin{displayquote}
\small Young man, in mathematics you don't understand things. You just get used to them.

\hfill ---- John von Neumann
\end{displayquote}
\end{comment}



\begin{displayquote}
\small What is familiar is what we are used to; and what we are used to is most difficult to ``know"---that is, to see as a problem; that is, to see as strange, as distant, as ``outside us".

\hfill ---- Friedrich Nietzsche (cf. \cite[Sec. 355]{Nie})
\end{displayquote}

We introduced completeness at the beginning of last semester and applied it to function spaces. It has allowed us to give a unified understanding of many analytic problems, especially those related to uniform convergence: the uniform convergence of series of functions, the commutativity of two limit processes and its relationship with uniform convergence, etc.. In fact, the vast majority of Banach spaces we considered last semester were defined by the $l^\infty$-norm.


From this perspective, it is perfectly natural to consider completeness for inner product spaces. However, we refuse to take lightly the consideration of completeness as natural for the following reasons:
\begin{itemize}
\item The notion of completeness was originally applied only to $\Rbb$. Historically, however, the idea of applying completeness to function spaces was not entirely inspired by the study of uniform convergence, since uniform convergence is not too far from pointwise convergence.\footnote{As a matter of fact, most results learned in the last semester can be formulated and proved without introducing completeness to function spaces, as implied by history and by many analysis textbooks.} {The apparently successful application of $l^\infty$-completeness to the problems of uniform convergence does not justify the \textit{a priori} value of completeness in the study of other norms} (such as the $L^2$-norm). \footnote{That $l^\infty$ and $L^2$ are both called ``norms" is a \textit{result}, not a starting point, of the observation in history that different types of problems can be treated in a similar fashion.} 

%\item It is therefore important to know the math problems that fundamentally rely on (and gave birth to) the concept of completeness of function spaces. They are not about uniform convergence, but about $L^2$-convergence (and more generally, $L^p$-convergence).  

%Applying completeness to other norms such as $L^2$ or $L^p$ norms is an unusual and significant historical event. What are the benefits of studying completeness under the $L^2$-norm?
%\item  Therefore, we must ask: 
\item For inner product spaces, some analytic properties are equivalent to completeness. The most important one is the weak (or weak-*) compactness of the unit ball.\footnote{We have learned that $l^2(X)$ satisfies this property due to $l^2(X)\simeq l^2(X)^*$ (cf. Thm. \ref{lb527}) and Banach-Alaoglu, or more directly, by Pb. \ref{lb531}.} The main reason that the Hilbert space $l^2(\Zbb)$ was introduced in history by Hilbert is due to this compactness rather than completeness. 
\end{itemize}


%As I will explain below, the Hilbert space techniques based on completeness were developed much later: F. Riesz made the first systematic use of completeness with the help of his novel (at his time) idea of operator norms.

\subsubsection{The late-coming concept of completeness}\label{lb1002}


The modern definition of Hilbert spaces as complete inner product spaces was due to von Neumann \cite{vNeu30} in late 1920s, many years after the introduction of $l^2(\Zbb)$ by Hilbert and Schmidt (same person as the Schmidt in the Gram-Schmidt process!\footnote{Thus, the discovery of Gram-Schmidt process is not only for the purpose of solving linear algebra problems. It has a deep background in analysis.}) to the study of integral equations in 1900s. We will see in this chapter that all separable Hilbert spaces are isomorphic to $\Cbb^N$ or $l^2(\Zbb)$, and that all Hilbert spaces are isomorphic to $l^2(X)$. Therefore, one can equivalently define a Hilbert space to be an inner product space isomorphic to $l^2(X)$ for some set $X$. This is indeed closer to how people originally understood Hilbert spaces than the modern definition.

As opposed to 1900s, by the time von Neumann gave Def. \ref{lb609}, the importance of completeness in function spaces was fully recognized. In my opinion, there are two main reasons for this change of viewpoint. The first one, which we will not discuss in detail, is the application of Baire's category theory (or its early version, the gliding hump method) to the study of function spaces. In this course, we will focus on the second reason: \uwave{The completeness of function spaces is closely related to the viewpoint of \textit{linear operators} as opposed to \textit{sesquilinear/bilinear forms}.} The emphasis on the linear operator perspective was due to F. Riesz:
\begin{itemize}
\item[(a)] In 1913, Riesz gave a new (and improved) interpretation of the spectral theorem for bounded Hermitian forms, originally due to Hilbert. Instead of working exclusively with bounded Hermitian forms, Riesz also took the perspective of bounded self-adjoint operators. This allowed him to introduce the influential idea of \textbf{functional calculus}, which remains the standard treatment of spectral theory to this day.
\item[(b)] In 1918, Riesz studied eigenvalue problems of compact operators on $C(X)$. His method is readily applied to compact operators on any Banach space, thus generalizing Hilbert-Schmidt's results for  the Hilbert space $l^2(\Zbb)$.
\end{itemize}
%Of course, the second problem is a mixture of completeness and compactness. We will not study the second problem in this course. (But see Sec. \ref{lb677} for a discussion of how the notion of compact operators evolved from Hilbert's original definition of completely continuous forms during Riesz's study of problem (b).) However, to show you at least one application of completeness to $l^2$ and $L^2$ norms, we will discuss the first problem in the middle of this semester. (Surprisingly, as we will see, the first problem is also related to the moment problems.)


In the following, we explain why the idea of completeness in function spaces is related to the viewpoint of linear operators. 

\subsubsection{Scalar-valued functions vs. vector-valued functions, linear operator vs. sesquilinear forms}\label{lb621}


Given inner product spaces $U,V$, a bounded linear map $T:U\rightarrow V$ can also be viewed as a continuous sesquilinear map
\begin{align}\label{eq255}
\omega_T:U\times V\rightarrow\Cbb\qquad (u,v)\mapsto \bk{Tu|v}
\end{align}
%(This equivalence of $T$ and $\omega_T$ is close in spirit to the equivalence $C(X,C(Y))\simeq C(X\times Y)$ in Thm. \ref{lb274}.) 
In the special case that $U=V$, $T$ can be viewed as a continuous \textbf{quadratic form}
\begin{align}\label{eq254}
V\times V\rightarrow \Cbb\qquad v\mapsto \bk{Tv|v}
\end{align}
(Note that \eqref{eq254} completely determines \eqref{eq255} by the polarization identity (Prop. \ref{lb587}), and hence determines $T$.) This viewpoint, insisting on the study of scalar-valued functions, was hold by people before Riesz, especially by Hilbert (and his students). On the other hand, the viewpoint of vector-valued functions and linear operators was emphasized by Riesz.

In Hilbert's scalar-valued function viewpoint, completeness plays a very marginal role (with very few exceptions, see Rem. \ref{lb639}), and emphasis was put on the compactness. To empathize with this phenomenon, compare it with the equivalence $C(X,C(Y))\simeq C(X\times Y)$ in Thm. \ref{lb274} (where $Y$ is compact): If we take the viewpoint of $C(X\times Y)$, we put more emphasis on the compactness of $Y$. However, if we take the viewpoint of $C(X,C(Y))$, we view $C(Y)$ as an abstract Banach space $V$. Therefore, we forget about the compactness of $Y$ and focus on the completeness of $V$.



%Riesz's more systematic use of the completeness of $l^2$ and $L^2$ spaces goes hand in hand with his emphasis on the viewpoint of vector-valued functions. Thus, the following three ideas were intertwined in Riesz's hands:

Therefore, the following ideas are closely related:
\begin{itemize}
\item[(1)] The completeness of function spaces.
\item[(2)] The study of linear maps between function spaces $U\rightarrow V$, as opposed to the study of scalar-valued functions on $U\times V$.
%\item[(3)] The operator norm on $\fk L(U,V)$.
\end{itemize}
%We have mentioned the relationship between (1) and (3) in Sec. \ref{lb610}. %(The key property behind this relationship is Thm. \ref{lb540}.) 
Let me briefly explain why (1) and (2) are related by recalling two fundamental facts learned before (cf. Exe. \ref{mc241} for another example): 

Suppose that $U,V$ are normed vector spaces and $U_0$ is a dense linear subspace of $V$. To extend a bounded linear map $T:U_0\rightarrow V$ to a bounded linear $U\rightarrow V$, one needs the completeness of $V$. (Cf. Prop. \ref{lb500}.) Given a net of bounded linear maps $(T_\alpha)$ from $U$ to $V$ satisfying $\sup_\alpha\Vert T_\alpha\Vert<+\infty$, to show that the pointwise convergence of $(T_\alpha)$ on $U_0$ implies the pointwise convergence on $U$, one also needs the completeness of $V$. (Cf. Prop. \ref{lb520}.) %\footnote{The discussion here does not imply that completeness is useless in the viewpoint of scalar-valued functions. One important method related to the completeness of domains (rather than codomains) is Baire's category theorem/Banach-Steinhaus theorem. However, there was no systematic application of this method to function spaces by the time Hilbert-Schmidt initiated the study of Hilbert spaces. And I don't really know whether  F. Riesz has used this method, especially when dealing with Hilbert spaces.}







%% Record #2 2024/02/29 three lectures  5




\subsection{Key property 1: convergence of summing orthogonal vectors}\label{lb640}

In this section, we fix a Hilbert space $\mc H$.

Hilbert and Schmidt introduced $l^2(\Zbb)$ to the study of integral equations. As we have mentioned, the main interesting analytic property for them is not completeness. Indeed, they mainly used 1 and 3 of the following conditions:
\begin{enumerate}
\item If $\sum_i|a_i|^2<+\infty$ and if $(e_i)_{i\in I}$ is orthormal, then $\sum a_ie_i$ converges.
\item Every bounded linear functional on $\mc H$ is equal to $\bk{\cdot|\xi}$ for some $\xi\in\mc H$.
\item The weak(-*) compactness of the closed unit ball.
\end{enumerate}
%(We will show the equivalence in Thm. \ref{lb612} and Cor. \ref{lb637}.) 
All these three properties are equivalent to Cauchy completeness. In the next three sections, we will learn about these three properties in turn. In the next chapter, we will see how 1 and 3 are used to study integral equations. As we will see in Sec. \ref{lb896} and \ref{lb1100}, property 2 are crucial for applying the measure theoretic techniques to Hilbert spaces.



\begin{thm}\label{lb612}
Let $V$ be an inner product space. The following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $V$ is complete.
\item For each orthonormal family $(e_i)_{i\in I}$ in $V$, and for each $(a_i)_{i\in I}$ in $\Cbb$ satisfying $\sum_{i\in I}|a_i|^2<+\infty$, the unordered sum $\sum_{i\in I}a_ie_i$ converges (under the norm of $V$).
\item $V$ is isomorphic to $l^2(X)$ for some $X$.
\end{enumerate}
\end{thm}


\begin{proof}
(3)$\Rightarrow$(1): This is because $l^2(X)$ is complete, cf. Thm. \ref{lb596}.

(1)$\Rightarrow$(2): Since $\sum_i |a_i|^2<+\infty$, by Rem. \ref{lb133}, for each $\eps>0$ there exists $J\in\fin(2^I)$ such that for all finite $K\subset I\setminus J$ we have $\sum_{k\in K}|a_k|^2<\eps$, and hence, by the Pythagorean identity,
\begin{align*}
\Big\Vert \sum_{k\in K}a_ke_k\Big\Vert^2=\sum_{k\in K}|a_ke_k|^2<\eps
\end{align*}
By Rem. \ref{lb133} again and the completeness of $V$, we see that $\sum_{i\in I}a_ie_i$ converges.

(2)$\Rightarrow$(3): Assume (2). We first show that $V$ has an orthonormal basis. By Zorn's lemma, we can find a maximal (with respect to the partial order $\subset$) set of orthonormal vectors, written as a family $(e_i)_{i\in I}$. The maximality implies that every nonzero vector $\xi\in V$ is not orthogonal to some $e_i$. (Otherwise, $\{e_i:i\in I\}$ can be extended to $\{e_i:i\in I\}\cup\{\xi/\Vert\xi\Vert\}$.)

Let us prove that $(e_i)_{i\in I}$ is an orthonormal basis. Suppose not. Then $U=\Span\{e_i:i\in I\}$ is not dense in $V$. Let $\xi\in V\setminus \ovl{U}$. By Bessel's inequality, we have
\begin{align*}
\sum_{i\in I}|\bk{\xi|e_i}|^2<+\infty
\end{align*}
Therefore, by (2),
\begin{align}
\sum_{i\in I}\bk{\xi|e_i}\cdot e_i
\end{align}
converges to some vector $\eta\in V$. By the continuity of $\bk{\cdot|\cdot}$, we see that $\bk{\eta|e_i}=\bk{\xi|e_i}$ for all $i$, and hence
\begin{align}
\bk{\xi-\eta|e_i}=0\qquad\text{ for all }i\in I
\end{align}
Since $\eta\in\ovl U$ and $\xi\notin\ovl U$, we conclude that $\xi-\eta$ is a nonzero vector orthogonal to all $e_i$. This contradicts the maximality of $(e_i)_{i\in I}$.

Now we have an orthonormal basis $(e_i)_{i\in I}$. By Cor. \ref{lb602}, we have a linear isometry
\begin{align*}
\Phi:V\rightarrow l^2(I)\qquad \xi\mapsto \big(\bk{\xi|e_i}\big)_{i\in I}
\end{align*}
with dense range. If $(a_i)_{i\in I}$ belongs to $l^2(I)$, by (2), the unordered sum $\sum_{i\in I}a_ie_i$ converges to some $\xi\in V$. Clearly $\Phi(\xi)=(a_i)_{i\in I}$. This proves that $\Phi$ is surjective, and hence is a unitary map. So $V\simeq l^2(I)$.
\end{proof}



Condition (2) of Thm. \ref{lb612} is the main subject of this section. From the above proof, we see that this condition is an easy special case of the completeness. This special case is often sufficient for applications without fully utilizing the completeness of $l^2(\Zbb)$. (To understand how nontrivial the direction (2)$\Rightarrow$(1) is even in the separable case, try to give a direct proof of it!)

In the following, we show that many well-known properties about Hilbert spaces follow Thm. \ref{lb612}-(2). Recall that we have fixed a Hilbert space $\mc H$.




\begin{co}\label{lb616}
$\mc H$ has an orthonormal basis. Moreover, $\mc H$ is separable iff the orthonormal basis can be chosen to be countable.
\end{co}

\begin{proof}
That $\mc H$ has an orthonormal basis follows from the proof of Thm. \ref{lb612} or from the fact that $l^2(X)$ has an orthonormal basis $(\chi_{\{x\}})_{x\in X}$. If $X$ is countable, then $l^2(X)$ has dense subset $\Span_{\Qbb+\im\Qbb}\{\chi_{\{x\}}:x\in X\}$ (by Lem. \ref{lb528}) and hence is separable. Conversely, we have proved in Exp. \ref{lb613} that every separable inner product space has a countable orthonormal basis.
\end{proof}



\begin{thm}\label{lb873}
Let $(e_x)_{x\in X}$ be an orthonormal basis of $\mc H$. Then we have a unitary map
\begin{gather}
\mc H\xlongrightarrow{\simeq} l^2(X)\qquad \xi\mapsto\big(\bk{\xi|e_x}\big)_{x\in X}
\end{gather}
\end{thm}



\begin{proof}
This is clear from the proof of Thm. \ref{lb612}.
\end{proof}


\begin{df}
If $\mc K$ is a linear subspace of $\mc H$, we define its \textbf{orthogonal complement} \index{00@Orthogonal complement}
\begin{align*}
\mc K^\perp=\{\xi\in\mc H:\bk{\xi|\eta}=0\text{ for all }\eta\in\mc K\}
\end{align*}
It is clear that 
\begin{align}\label{eq257}
{\mc K}^\perp={\ovl{\mc K}}^\perp
\end{align}
\end{df}
\begin{proof}[Proof of \eqref{eq257}]
If $\xi\in\mc H$ is orthogonal to $\ovl{\mc K}$, then $\xi$ is clearly orthogonal to $\mc K$. Conversely, if $\xi$ is orthogonal to $\mc K$, the continuity of $\eta\in\mc H\mapsto\bk{\xi|\eta}$ implies that  $\xi\perp\ovl{\mc K}$.
\end{proof}



\begin{df}\label{lb614}
Let $\mc H_1,\mc H_2$ be Hilbert spaces. Consider the direct sum of vector spaces $\mc H_1\oplus\mc H_2$. Namely, $\mc H_1\oplus\mc H_2$ equals $\mc H_1\times\mc H_2$ as a set, $(\xi,\eta)$ is also written as $\xi\oplus\eta$, and the linear structure is defined by $(\xi\oplus\eta)+(\xi'\oplus\eta')=(\xi+\xi')\oplus(\eta+\eta')$ and $\lambda(\xi\oplus\eta)=\lambda\xi\oplus\lambda\eta$ (where $\xi,\xi'\in\mc H_1,\eta,\eta'\in\mc H_2,\lambda\in\Cbb$), and the zero vector is $0\oplus 0$. Equip $\mc H_1\oplus\mc H_2$ with inner product defined by
\begin{align*}
\bk{\xi\oplus\eta|\xi'\oplus\eta'}=\bk{\xi|\xi'}+\bk{\eta|\eta'}
\end{align*}
Then $\mc H_1\oplus\mc H_2$ is clearly a Hilbert space. We call $\mc H_1\oplus\mc H_2$ the \textbf{(Hilbert space) direct sum}\index{00@Hilbert space direct sums} of $\mc H_1,\mc H_2$.
\end{df}


\begin{rem}
In Def. \ref{lb614}, we clearly have linear isometries
\begin{gather*}
\mc H_1\rightarrow\mc H_1\oplus\mc H_2\qquad\xi\mapsto \xi\oplus 0\\
\mc H_2\rightarrow \mc H_1\oplus\mc H_2\qquad\eta\mapsto 0\oplus\eta
\end{gather*}
with ranges $\mc H_1\oplus 0$ and $0\oplus\mc H_2$ respectively. It is clear that $\mc H_1\oplus0$ and $0\oplus\mc H_2$ are orthogonal complements of each other. We often identify $\mc H_1$ with $\mc H_1\oplus0$ and $\mc H_2$ with $0\oplus\mc H_2$. Then $\mc H_1$ and $\mc H_2$ are Hilbert subspaces of $\mc H_1\oplus\mc H_2$, and are orthogonal complements of each other.
\end{rem}



\begin{thm}\label{lb617}
Let $\mc K$ be a closed linear subspace of $\mc H$. Note that $\mc K$ and $\mc K^\perp$ are both Hilbert subspaces of $\mc H$. Then there is a unitary map
\begin{align}\label{eq256}
\Psi: \mc K\oplus\mc K^\perp\xlongrightarrow{\simeq}\mc H\qquad \xi\oplus\eta\mapsto\xi+\eta
\end{align}
\end{thm}

\begin{proof}
It is a routine check that $\Psi$ is a linear isometry. It remains to prove that $\Psi$ is surjective. This means that we need to write each $\psi\in\mc H$ in the form $\psi=\xi+\eta$ where $\xi\in\mc K,\eta\in\mc K^\perp$. Thus, the surjectivity of $\Psi$ means that every $\psi\in\mc H$ has an orthogonal decomposition with respect to $\mc K$ (recall Def. \ref{lb615}).

Let $\psi\in\mc H$. By Cor. \ref{lb616}, $\mc K$ has an orthonormal basis $(e_i)_{i\in I}$. As in the proof of (2)$\Rightarrow$(3) of Thm. \ref{lb612}, Bessel's inequality implies that  $\sum_{i\in I}\bk{\psi|e_i}\cdot e_i$ converges to some vector $\xi\in\mc K$. Then one checks easily that $\eta=\psi-\xi$ is orthogonal to all $e_i$, and hence is orthogonal to $\mc K_0=\Span\{e_i:i\in I\}$. Thus $\eta\perp\mc K$ by \eqref{eq257}. 
\end{proof}

\begin{rem}
Due to Thm. \ref{lb617}, given a Hilbert subspace $\mc K$, people often write
\begin{align}
\mc H=\mc K\oplus\mc K^\perp
\end{align}
\end{rem}


\begin{co}\label{lb618}
Let $\mc K$ be a closed linear subspace of $\mc H$. Then every vector $\psi\in\mc H$ has an orthogonal decomposition with respect to $\mc K$. Moreover, we have $(\mc K^\perp)^\perp=\mc K$.
\end{co}

\begin{proof}
The existence of orthogonal decomposition follows from Thm. \ref{lb617}.

By Thm. \ref{lb617}, it suffices to assume $\mc H=\mc H_1\oplus\mc H_2$ (where $\mc H_1,\mc H_2$ are Hilbert spaces) and $\mc K=\mc H_1\oplus 0$. Then any $\psi\in\mc H$ is of the form $\xi\oplus\eta$ where $\xi\in\mc H_1$ and $\eta\in\mc H_2$. So $\psi=(\xi\oplus0)+(0\oplus\eta)$ gives the orthogonal decomposition of $\psi$ with respect to $\mc K$.

Clearly $\mc K\subset(\mc K^\perp)^\perp$. Assume that $\psi=\xi\oplus\eta$ is orthogonal to $\mc K^\perp$, then it is orthogonal to $0\oplus\eta$, and hence $\eta=0$. So $\psi\in\mc K$. This proves $\mc K\supset(\mc K^\perp)^\perp$.
\end{proof}

\begin{co}\label{lb882}
Let $V$ be a linear subspace of $\mc H$. Then $V$ is dense iff the only vector of $\mc H$ orthogonal to $V$ is $0$. 
\end{co}

This corollary gives a useful criterion for the density of linear subspaces.

\begin{proof}
By Cor. \ref{lb618} we have $\ovl V=\ovl V^{\perp\perp}$ and $\mc H=\mc H^{\perp\perp}$. So $\ovl V=\mc H$ iff $\ovl V^\perp=\mc H^\perp$ (i.e., $\ovl V^\perp=0$) iff (by \eqref{eq257}) $V^\perp=0$.
\end{proof}


\begin{rem}
The existence of orthogonal decompositions with respect to closed linear subspaces (Thm. \ref{lb617} or Cor. \ref{lb618}) is a key feature of Hilbert spaces that is not satisfied by general inner product spaces. A different (and fancier) proof can be found in many textbooks which proves the existence of the orthogonal decomposition $\psi=\xi+\eta$ by defining $\xi$ to be the vector in $\mc K$ such that $\Vert\psi-\xi\Vert$ attains its minimum: the existence of such $\xi$ relies on the completeness of $\mc H$ and the parallelogram law
\begin{align}
\Vert u+v\Vert^2+\Vert u-v\Vert^2=2\Vert u\Vert^2+2\Vert v\Vert^2
\end{align}
cf. \cite[Thm. 5.24]{Fol-R} or \cite[Thm. 4.11]{Rud-R} for instance.\footnote{The proof of the existence of this minimizing $\xi$ makes use of the convexity of $\mc K$ and thus holds for $\mc K$ being an arbitrary closed convex subset. Convexity in Banach spaces is a very important topic, but its importance was not realized until long after the birth of Hilbert spaces and much of F. Riesz's work. We believe that introducing convexity (even if secretly introduced) at the first encounter with Hilbert spaces is off-topic and distracting, because it hinders the understanding of the roles played by the other central properties in Hilbert spaces, especially the analytic properties.}

The proof we give here is closer to Schmidt's method in that we used the Gram-Schmidt process instead of the parallelogram law. With this proof, we want to convey the idea that the existence of orthogonal decompositions is a direct consequence of the convergence of summing orthogonal vectors (condition (2) of Thm. \ref{lb612}).   \hfill\qedsymbol
\end{rem}




\subsection{Key property 2: the antilinear isomorphism $\mc H\simeq\mc H^*$}






Recall that if $T:V\rightarrow W$ is a linear map of normed vector spaces, its operator norm is $\Vert T\Vert=\sup_{v\in \ovl B_V(0,1)}\Vert Tv\Vert$.  Operator norms describe uniform convergence on $\ovl B_V(0,1)$: If $(T_\alpha)$ is a net of bounded linear operators $V\rightarrow W$, then $\lim_\alpha\Vert T-T_\alpha\Vert=0$ iff $T_\alpha$ converges uniformly on $\ovl B_V(0,1)$ to $T$. 


In the following, $V,W$ always denote inner product spaces.

\begin{lm}\label{lb623}
For each $\xi$ in an inner product space $V$, we have
\begin{align}\label{eq263}
\Vert \xi\Vert=\sup_{\eta\in\ovl B_V(0,1)}|\bk{\xi|\eta}|
\end{align}
\begin{proof}
Clearly ``$\geq$" holds by Cauchy-Schwarz. To prove ``$\leq$", assume WLOG that $\xi\neq0$. Then $\Vert\xi\Vert=\bk{\xi|\eta}$ if we choose $\eta=\xi/\Vert\xi\Vert$.
\end{proof}
\end{lm}


\begin{thm}[\textbf{Riesz-Fr\'echet representation theorem}]\label{lb898}\index{00@Riesz-Fr\'echet representation theorem}
Let $V$ be an inner product space. Then the following map is an antilinear isometry: 
\begin{gather}\label{eq266}
\Phi:V\rightarrow V^*\qquad \xi\mapsto\bk{\cdot|\xi}
\end{gather}
Moreover, $V$ is a Hilbert space iff $\Phi$ is surjective (and hence an antilinear isomorphism of normed vector spaces).
\end{thm}

Recall that $V^*$ is equipped with the operator norm, i.e., if $\varphi\in V^*$ then $\Vert\varphi\Vert=\sup_{\xi\in\ovl B_V(0,1)}|\bk{\varphi,\xi}|$.

\begin{proof}
Clearly $\Phi$ is antilinear. Lem. \ref{lb623} shows that $\Phi$ is an isometry.

Assume that $V$ is a Hilbert space. By Thm. \ref{lb612}-(3), we assume WLOG that $V=l^2(X)$. Thus, for $\xi,\eta\in l^2(X)$ we have $\bk{\xi|\eta}=\sum_{x\in X}\xi(x)\ovl{\eta(x)}$. By Thm. \ref{lb527}, $\Phi$ is surjective.

Conversely, assume that $\Phi$ is surjective. Since $V^*$ is complete (Thm. \ref{lb540})  and $\Phi$ is an isometry, $V$ is also complete, i.e., a Hilbert space.
\end{proof}


One of the most important applications of Thm. \ref{lb898} is the equivalence of bounded linear operators and bounded sesquilinear forms, i.e., Thm. \ref{lb627}. We first need some preparation.

\begin{df}
Let $\omega(\cdot|\cdot):V\times W\rightarrow\Cbb$ be sesquilinear. Define its \textbf{norm} \index{00@Norm $\Vert\omega\Vert$ of a sesquilinear form} \index{zz@$\Vert\omega\Vert$, the norm of the sesquilinear form $\omega$}
\begin{align}
\Vert\omega\Vert=\sup_{
\begin{subarray}{c}
\xi\in\ovl B_V(0,1)\\
\eta\in\ovl B_V(0,1)
\end{subarray}
}|\omega(\xi|\eta)|
\end{align}
Clearly $\Vert\omega\Vert$ is the smallest element in $[0,+\infty]$ satisfying
\begin{align*}
|\omega(\xi|\eta)|\leq\Vert\omega\Vert\cdot\Vert\xi\Vert\cdot\Vert\eta\Vert\qquad(\forall \xi\in\mc H,\forall \eta\in\mc K)
\end{align*}
We say that $\omega$ is \textbf{bounded} \index{00@Bounded sesquilinear form} if $\Vert\omega\Vert<+\infty$. 
\end{df}


\begin{exe}\label{mc242}
Let $\omega:V\times W\rightarrow\Cbb$ be sesquilinear. Equip $V\times W$ with the metric $d((v_1,w_1),(v_2,w_2))=\Vert v_1-v_2\Vert_V+\Vert w_1-w_2\Vert_W$. (This is the metric induced by the norm $\Vert v\oplus w\Vert=\Vert v\Vert_V+\Vert w\Vert_W$ on $V\oplus W\simeq V\times W$.) Prove that the following are equivalent. 
\begin{enumerate}[label=(\arabic*)]
\item $\omega$ is Lipschitz continuous on $\ovl B_V(0,1)\times\ovl B_W(0,1)$.
\item $\omega$ is continuous.
\item $\omega$ is continuous at $(0,0)$.
\item $\omega$ is bounded.
\end{enumerate}
Prove that if any of the above conditions holds, then for each $R\geq0$, the restriction of $\omega$ to $\ovl B_V(0,R)\times\ovl B_W(0,R)$ has Lipschitz constant $R\Vert\omega\Vert$.
\end{exe}

\begin{proof}[Hint]
Mimic the proof of Prop. \ref{lb313}.
\end{proof}



\begin{pp}\label{lb624}
For each linear map $T:V\rightarrow W$, define a sesquilinear map
\begin{align}
\omega_T:V\times W\rightarrow\Cbb \qquad \omega_T(\xi|\eta)=\bk{T\xi|\eta}
\end{align}
Then $\Vert T\Vert=\Vert\omega_T\Vert$, i.e.,
\begin{align}\label{eq262}
\Vert T\Vert=\sup_{
\begin{subarray}{c}
\xi\in\ovl B_V(0,1)\\
\eta\in\ovl B_W(0,1)
\end{subarray}
}\big|\bk{T\xi|\eta}\big|
\end{align}
\end{pp}

\begin{proof}
By Lem. \ref{lb623}, the RHS of \eqref{eq262} equals $\dps\sup_{\xi\in\ovl B_{\mc H}(0,1)}\Vert T\xi\Vert=\Vert T\Vert$.
\end{proof}

\begin{co}\label{lb646}
Let $T:\mc H\rightarrow\mc K$, and let $(T_\alpha)$ be a net of linear maps $\mc H\rightarrow\mc K$. Then $\lim_\alpha\Vert T-T_\alpha\Vert=0$ iff $(\omega_{T_\alpha})$ converges uniformly on $\ovl B_{\mc H}(0,1)\times\ovl B_{\mc K}(0,1)$ to $\omega_T$.
\end{co}


\begin{thm}\label{lb627}
Let $\mc H,\mc K$ be Hilbert spaces. Let $\omega(\cdot|\cdot):\mc H\times \mc K\rightarrow\Cbb$ be sesquilinear. Then $\omega$ is bounded iff $\omega=\omega_T$ for some $T\in\fk L(\mc H,\mc K)$. In the latter case, we have $\Vert\omega\Vert=\Vert T\Vert$.
\end{thm}



\begin{proof}[Hint]
``$\Leftarrow$": By Prop. \ref{lb624}, we have $\Vert\omega\Vert=\Vert T\Vert<+\infty$. Hence $\omega$ is bounded.

``$\Rightarrow$": Assume that $\omega$ is bounded. Then for each $\xi\in\mc H$, the antilinear functional $\eta\in\mc K\mapsto \omega(\xi|\eta)$ is bounded (with operator norm $\leq\Vert\omega\Vert\cdot\Vert\xi\Vert$). Since $\mc K$ is a Hilbert space, the Riesz-Fr\'echet representation Thm. \ref{lb898} implies the existence of an element $T\xi\in\mc K$ such that $\bk{T\xi|\eta}=\omega(\xi|\eta)$ for all $\eta\in\mc K$, and that $\Vert T\xi\Vert\leq \Vert\omega\Vert\cdot\Vert\xi\Vert$. Thus $T\in\fk L(\mc H,\mc K)$ and $\omega=\omega_T$.

The last sentence follows from Prop. \ref{lb624}.
\end{proof}


From the above proof, it is clear that Thm. \ref{lb627} remains valid if we replace $\mc H$ with a (not necessarily complete) inner product space. However, the completeness of $\mc K$ is essential and cannot be omitted.

\begin{exe}\label{mc241}
Let $V,W$ be inner product spaces. Let $\fk L(V\times W,\Cbb)$ be the set of bounded sesquilinear forms $\omega:V\times W\rightarrow\Cbb$. Then $\fk L(V\times W,\Cbb)$ is clearly a $\Cbb$-linear subspace of $\Cbb^{V\times W}$. Prove that $\omega\mapsto\Vert\omega\Vert$ is a norm on $\fk L(V\times W,\Cbb)$ under which $\fk L(V\times W,\Cbb)$ becomes a Banach space. 

(Note that the completeness of $V$ or $W$ is not required to prove the completeness of $\fk L(V\times W,\Cbb)$. However, one needs the completeness of $W$ to establish that the normed vector space $\fk L(V,W)$ is complete, cf. Thm. \ref{lb540}. This further illustrates the point made in Sec. \ref{lb671} that the completeness of function spaces is closely related to the perspective of vector-valued functions and linear operators, as opposed to scalar-valued functions and sesquilinear forms.)  \hfill\qedsymbol
\end{exe}





\begin{co}\label{lb631}
Let $\mc H,\mc K$ be Hilbert spaces. For every $T\in\fk L(\mc H,\mc K)$ there is a unique bounded linear map $T^*:\mc K\rightarrow\mc H$ (called the \textbf{adjoint} \index{00@Adjoint operator} of $T$) satisfying for all $\xi\in\mc H,\eta\in\mc K$ that
\begin{align}\label{eq269}
\bk{T\xi|\eta}=\bk{\xi|T^*\eta}
\end{align}
Moreover, we have $\Vert T\Vert=\Vert T^*\Vert$, and $(T^*)^*=T$.
\end{co}

\begin{proof}
For each sesquilinear form $\omega:V\times W\rightarrow\Cbb$ we define its \textbf{adjoint sesquilinear form} \index{00@Adjoint sesquilinear form}
\begin{align}\label{eq577}
\omega^*:W\times V\rightarrow\Cbb\qquad \omega^*(\eta|\xi)=\ovl{\omega(\xi|\eta)}
\end{align}
Then clearly
\begin{align}\label{eq568}
\Vert\omega\Vert=\Vert\omega^*\Vert\qquad (\omega^*)^*=\omega
\end{align}
By Thm. \ref{lb627}, there exists $T^*\in\fk L(W,V)$ such that $\omega_{T^*}=(\omega_T)^*$. Then \eqref{eq269} is clearly satisfied, and \eqref{eq568} and Prop. \ref{lb624} imply $\Vert T\Vert=\Vert T^*\Vert$ and $(T^*)^*=T$.
\end{proof}


\begin{rem}
Thm. \ref{lb627} establishes the equivalence between the linear operator perspective (i.e., the vector-valued function perspective) and the sesquilinear form perspective (i.e., the scalar-valued function perspective), allowing the benefits of both approaches to be combined.

The advantage of the linear operator approach is not only that it is the more modern and mainstream approach. More importantly, it can handle linear operator/integral equation problems on non-Hilbert spaces, particularly on non-reflexive Banach spaces.  This key insight stems from Riesz's seminal work \cite{Rie18} on compact operators. Even within Hilbert spaces, the sesquilinear form perspective faces significant challenges when dealing with non-self-adjoint operators.


On the other hand, the primary advantage of the sesquilinear form perspective lies in its historical importance--it was the viewpoint adopted by mathematicians such as Hilbert in the early development of functional analysis, which aligns more naturally with weak compactness. 

Beyond its historical significance, \uwave{a more crucial benefit of the sesquilinear form perspective is its stronger connection to measure theory}. This perspective not only facilitated the application of early 20th-century measure-theoretic techniques to problems in Hilbert spaces, but also significantly contributed to the advancement of integral theory itself. An illustrative example is Riesz's proof of the spectral theorem for bounded self-adjoint operators in \cite{Rie13}, which also serves as a significant application of Thm. \ref{lb627}. We will learn this topic in Sec. \ref{lb896} and \ref{lb1100}.   \hfill\qedsymbol
\end{rem}









\subsection{Key property 3: weak compactness of the closed unit balls}\label{lb641}



\subsubsection{Weak topology}


Recall from Def. \ref{lb625} that if $V$ is a normed vector space, the weak-* topology of $V^*$ is the unique topology such that a net $(\varphi_\alpha)$ in $V^*$ converges to $\varphi$ under this topology iff $\lim_\alpha\bk{\varphi_\alpha,v}=\bk{\varphi,v}$ for all $v\in V$. 
%It is more important to study the weak-* topology on $\ovl B_{V^*}(0,1)$ (or on any bounded closed ball of $V^*$): By Banach-Alaoglu Thm. \ref{lb519}, the closed unit ball $\ovl B_{V^*}(0,1)$ is weak-* compact. Moreover, the following elementary fact allows for a flexible characterization of weak-* topology:





\begin{df}\label{lb901}
Let $V$ be an inner product space $V$, and let $\Phi:V\rightarrow V^*$ be defined by \eqref{eq266}. Equip $\Phi(V)$ with the subset topology inherited from the weak-* topology of $V^*$. The \textbf{weak topology} \index{00@Weak topology of inner product spaces} of $V$ is defined to be the pullback of the topology of $\Phi(V)$ through the bijection $\Phi:V\rightarrow\Phi(V)$. In other words, it is the unique topology such that for any net $(\xi_\alpha)$ in $\mc H$ and any $\xi\in \mc H$,
\begin{align}
\xi_\alpha\xlongrightarrow{\text{weakly}}\xi\qquad\Longleftrightarrow\qquad \lim_\alpha\bk{\xi_\alpha|\eta}=\bk{\xi|\eta}\text{ for all }\eta\in \mc H
\end{align}
\end{df}


Due to the following lemma, it is more natural to study the weak-* topology on $\ovl B_{V^*}(0,1)$ (or on any norm-bounded subset of $V^*$) rather than on $V^*$.

\begin{lm}\label{lb626}
Let $V$ be a normed vector space. Let $(\varphi_\alpha)$ be a net in $V$ satisfying $\sup_\alpha\Vert\varphi_\alpha\Vert<+\infty$, and let $\varphi\in V^*$. Assume that $E\subset V$ spans a (norm-)dense subspace of $V$. Then $(\varphi_\alpha)$ converges weak-* to $\varphi$ iff $\lim_\alpha\bk{\varphi_\alpha,v}=\bk{\varphi,v}$ for all $v\in E$.
\end{lm}

\begin{proof}
This is immediate from Prop. \ref{lb520}. But here we give a direct proof. Clearly ``$\Rightarrow$" holds. Assume that $\lim_\alpha\bk{\varphi_\alpha,v}=\bk{\varphi,v}$ holds for all $v\in E$. Let $M=\sup_\alpha\Vert\varphi_\alpha\Vert$. Choose any $\xi\in V$. Then for each $\eps>0$ there exists $v\in\Span E$ such that $\Vert \xi-v\Vert\leq\eps$. Thus $|\bk{\varphi_\alpha,\xi-v}|\leq\eps$. Therefore
\begin{align*}
&\limsup_\alpha |\bk{\varphi-\varphi_\alpha,\xi}|\leq \limsup_\alpha|\bk{\varphi-\varphi_\alpha,\xi-v}|+\lim_\alpha |\bk{\varphi-\varphi_\alpha,v}|\\
\leq&(M+\Vert\varphi\Vert)\eps+0=(M+\Vert\varphi\Vert)\eps
\end{align*}
Since this holds for all $\eps$, we conclude that $\lim_\alpha\bk{\varphi-\varphi_\alpha,\xi}=0$.
\end{proof}


\begin{eg}\label{lb1001}
Suppose that $V$ is an inner product space with an orthonormal basis $(e_j)_{j\in J}$. Let $(\xi_\alpha)$ be a net in $V$ satisfying $\sup_\alpha \Vert\xi_\alpha\Vert<+\infty$, and let $\xi\in V$. Then by Lem. \ref{lb626}, we have
\begin{align}
\xi_\alpha\xlongrightarrow{\text{weakly}}\xi\qquad\Longleftrightarrow\qquad \lim_\alpha\bk{\xi_\alpha|e_j}=\bk{\xi|e_j}\text{ for all }j\in J
\end{align}

In the special case that $V=l^2(X)$ and the orthonormal basis is $(\chi_{\{x\}})_{x\in X}$, for any net $(f_\alpha)$ in $l^2(X)$ satisfying $\sup_\alpha\Vert f_\alpha\Vert_{l^2}<+\infty$ and any $f\in l^2(X)$, then
\begin{align}\label{eq264}
f_\alpha\xlongrightarrow{\text{weakly}}f\qquad\Longleftrightarrow\qquad \lim_\alpha f_\alpha(x)=f(x)\text{ for all }x\in X
\end{align}
See also Thm. \ref{lb530}.  \hfill\qedsymbol
\end{eg}





\subsubsection{Fatou's lemma}



Recall Pb. \ref{lb346} for the basic properties of $\limsup$ and $\liminf$.

\begin{pp}\label{lb770}
(\textbf{Fatou's lemma for weak-* convergence}) \index{00@Fatou's lemma for weak-* convergenc} Let $V$ be a normed vector space. Then the map $\varphi\in V^*\mapsto\Vert\varphi\Vert\in\Rbb_{\geq0}$ is lower semicontinuous, where $V^*$ is equipped with the weak-* topology. In other words, if $(\varphi_\alpha)$ is a net in $V^*$ converging weak-* to $\varphi\in V^*$, then
\begin{align*}
\liminf_\alpha\Vert\varphi_\alpha\Vert\geq\Vert\varphi\Vert
\end{align*}
\end{pp}

In Subsec. \ref{lb803}, we will learn more about semicontinuous functions.

\begin{proof}
By the definition of operator norms, for each $\eps>0$ there exists $v\in \ovl B_V(0,1)$ such that $|\bk{\varphi,v}|\geq \Vert\varphi\Vert-\eps$. By the weak-* convergence, we have $\lim_\alpha\bk{\varphi_\alpha,v}=\bk{\varphi,v}$, and hence
\begin{align*}
\liminf_\alpha \Vert\varphi_\alpha\Vert\geq\liminf_\alpha|\bk{\varphi_\alpha,v}|=|\bk{\varphi,v}|\geq\Vert\varphi\Vert-\eps
\end{align*}
This finishes the proof, because $\eps>0$ is arbitrary.
\end{proof}



\begin{co}\label{lb764}
(\textbf{Fatou's lemma for inner product spaces}) \index{00@Fatou's lemma for inner product spaces} Let $V$ be an inner product space. Then the map $\xi\in V\mapsto\Vert\xi\Vert\in\Rbb_{\geq0}$ is lower semicontinuous, where $V$ is equipped with the weak topology. In other words, if $(\xi_\alpha)$ is a net in $V$ converging weakly to $\xi\in V$, then
\begin{align*}
\liminf_\alpha\Vert\xi_\alpha\Vert\geq\Vert\xi\Vert
\end{align*}
\end{co}

\begin{proof}
This follows from Prop. \ref{lb770} and the fact that the map $\Psi:V\rightarrow V^*$ in Thm. \ref{lb898} is an isometry. Alternatively, we can prove it directly: Assume WLOG that $\xi\neq 0$ (and hence $\Vert\xi\Vert\neq 0$). The weak convergence implies $\lim_\alpha\bk{\xi_\alpha|\xi}=\bk{\xi|\xi}$, and hence 
\begin{align*}
\Vert\xi\Vert\cdot\liminf_\alpha\Vert\xi_\alpha\Vert\geq \liminf_\alpha|\bk{\xi_\alpha|\xi}|=\bk{\xi|\xi}=\Vert\xi\Vert^2
\end{align*}
\end{proof}

Assuming that $\lim_\alpha\Vert\varphi_\alpha\Vert$ converges, the inequality in the above Fatou's lemma becomes the equality iff $(\xi_\alpha)$ converges (in norm) to $\xi$:

\begin{pp}\label{lb635}
Let $(\xi_\alpha)$ be a net in an inner product space $V$ converging weakly to $\xi\in V$. Then $(\xi_\alpha)$ converges to $\xi$ iff $\lim_\alpha\Vert\xi_\alpha\Vert=\Vert\xi\Vert$.
\end{pp}
\begin{proof}
By the (norm-)continuity of the norm function $\Vert\cdot\Vert:V\rightarrow\Rbb_{\geq0}$ we clearly have ``$\Rightarrow$". Conversely, assume $\lim_\alpha\Vert\xi_\alpha\Vert=\Vert\xi\Vert$. Then
\begin{align*}
\bk{\xi-\xi_\alpha|\xi-\xi_\alpha}=\bk{\xi|\xi}+\bk{\xi_\alpha|\xi_\alpha}-\bk{\xi|\xi_\alpha}-\bk{\xi_\alpha|\xi}
\end{align*}
converges to $\bk{\xi|\xi}+\bk{\xi|\xi}-\bk{\xi|\xi}-\bk{\xi|\xi}=0$ by the weak convergence.
\end{proof}


\begin{eg}\label{lb661}
Suppose that $(e_n)_{n\in\Zbb_+}$ is an orthormal sequence in an inner product space $V$. Then $\lim_n e_n$ converges weakly to $0$ because for each $\xi\in\mc H$ we have $\sum_n |\bk{\xi|e_n}|^2<+\infty$ (due to Bessel's inequality, Cor. \ref{lb634}) and hence $\lim_n\bk{\xi|e_n}=0$. However, $\lim_n\Vert e_n\Vert=1\neq0$.
\end{eg}


\subsubsection{Weak compactness and weak metrizability}



The proof of Step 2 of the following theorem uses Fatou's lemma.


\begin{thm}\label{lb636}
Let $V$ be an inner product space. Then $V$ is a Hilbert space iff $\ovl B_V(0,1)$ is weakly compact.

If $V$ is a separable Hilbert space, then $\ovl B_V(0,1)$ is weakly metrizable.
\end{thm}

It follows from Thm. \ref{lb222} that if $V$ is a separable Hilbert space, then $\ovl B_V(0,1)$ is sequentially compact under the weak topology.

\begin{proof}
Step 1. Assume that $V$ is a Hilbert space. Then by the Riesz-Fr\'echet Thm. \ref{lb898}, we have an antilinear isometric isomorphism $\Psi:V\rightarrow V^*$. By the definition of weak topology, $\Psi$ is a homeomorphism from the weak topology of $V$ to the weak-* topology of $V^*$. Therefore, since the Banach-Alaoglu theorem implies that $\ovl B_{V^*}(0,1)$ is weak-* compact, we see that $\ovl B_V(0,1)$ is weakly compact.

We give an alternative and direct proof. By Thm. \ref{lb612}, we assume WLOG that $V=l^2(X)$. Let $(f_\alpha)$ be a net in $\ovl B_V(0,1)$. By the Tychonoff theorem, $(f_\alpha)$ has a subnet $(f_{\alpha_\mu})$ converging pointwise to $f:X\rightarrow\Cbb$. For each $A\in\fin(2^X)$ we have
\begin{align*}
\sum_A |f|^2=\lim_\mu\sum_A|f_{\alpha_\mu}|^2\leq 1
\end{align*}
Therefore, we have $\Vert f\Vert_{l^2(X)}\leq 1$, and hence $f\in\ovl B_V(0,1)$. Hence $(f_{\alpha_\mu})$ converges weakly to $f$ by Exp. \ref{lb1001}. This proves the weak compactness of $\ovl B_V(0,1)$.\\[-1ex]

Step 2. Assume that $\ovl B_V(0,1)$ is weakly compact. We want to show that $V$ is complete. Let $(\xi_n)$ be a Cauchy sequence in $V$. Since every Cauchy \textit{sequence} is norm-bounded, we may assume WLOG that $\sup_n\Vert\xi_n\Vert\leq1$. By the weak compactness of $\ovl B_V(0,1)$, the sequence $(\xi_n)$ has a \textit{subnet} $(\xi_{n_\alpha})_{\alpha\in I}$ (abbreviated to $(\xi_\alpha)_{\alpha\in I}$ for simplicity) converging weakly to some $\xi\in \ovl B_V(0,1)$. If we can show that the subnet $(\xi_\alpha)$ converges to $\xi$, then Prop. \ref{lb127} will imply that the original sequence $(\xi_n)$ converges to $\xi$, finishing the proof that $V$ is complete.

Since $(\xi_\alpha)$ is Cauchy, for each $\eps>0$, there exists $\gamma\in I$ such that for all $\alpha,\beta\in I_{\geq\gamma}$ we have $\Vert\xi_\alpha-\xi_\beta\Vert\leq\eps$. Since $\lim_\beta (\xi_\alpha-\xi_\beta)$ converges weakly to $\xi_\alpha-\xi$, by Fatou's lemma (Cor. \ref{lb764}), we get
\begin{align*}
\Vert\xi_\alpha-\xi\Vert\leq\liminf_\beta \Vert\xi_\alpha-\xi_\beta\Vert\leq\eps
\end{align*}
for all $\alpha\geq\gamma$. This proves that $(\xi_\alpha)$ converges to $\xi$.\\[-1ex]

Step 3. Assume that $V$ is complete and separable. Then the metrizability of the weak topology of $\ovl B_V(0,1)$ is clear from the antilinear isomorphism $\Psi:V\rightarrow V^*$ and Thm. \ref{lb523}. 

We may also prove it directly. By Cor. \ref{lb616} and Thm. \ref{lb873}, we can assume that $V=l^2(X)$ where $X$ is a countable set. Then we may view $\ovl B_V(0,1)$ as a subset of $\Cbb^X$. By Exp. \ref{lb1001}, the subset topology of $\ovl B_V(0,1)$ inherited from the product topology of $\Cbb^X$ agrees with the weak topology. Since $X$ is countable, by Cor. \ref{lb260}, $\Cbb^X$ is metrizable. Thus the weak topology of $\ovl B_V(0,1)$ is also metrizable.
\end{proof}





%% Record #3 2024/03/04 two lectures  7






















\subsection{Problems and supplementary material}

Fix Hilbert spaces $\mc H,\mc K$.

\subsubsection{Basic facts about Hilbert spaces}




\begin{sprob}
Prove that any two orthonormal bases of $\mc H$ have the same cardinality.
\end{sprob}

\begin{proof}[Hint]
The case $\dim\mc H<+\infty$ is obvious by linear algebra. In the case that either one of the two orthonormal bases is infinite, use Thm. \ref{lb497}.
\end{proof}













\begin{prob}\label{lb787}
Let $(e_i)_{i\in I}$ be an orthonormal basis of $\mc H$. 
\begin{enumerate}
\item For each $A\in\fin(2^X)$, let $P_A\in\fk L(\mc H)$ be defined by $P_A\xi=\sum_{i\in A}\bk{\xi|e_i}e_i$. Prove that $\dps\lim_{A\in\fin(2^X)}P_A$ converges pointwise to the identity operator.
\item Let $T\in\fk L(\mc H,\mc K)$. Use part 1 to prove that for every $\xi\in\mc H$, the RHS of the following equation converges to the LHS:
\begin{align}
T\xi=\sum_{i\in I} \bk{\xi|e_i}Te_i
\end{align}
\end{enumerate}
\end{prob}


\begin{prob}
Let $V,W$ be inner product spaces. Solve Exe. \ref{mc242}.
\end{prob}

\subsubsection{Projections and closed subspaces}\label{lb1003}

The results in subsection will only be used in Sec. \ref{lb896} and \ref{lb1100}.

\begin{df}
We say that $P\in\fk L(\mc H)$ is a \textbf{projection operator} \index{00@Projection operator} (or simply a \textbf{projection}) if $P^2=P$ and $P^*=P$.
\end{df}




\begin{prob}\label{lb815}
Assume that $\mc K$ is a closed linear subspace of $\mc H$. Define a map $P:\mc H\rightarrow\mc H$ such that for each $\xi\in\mc H$, $\xi=P\xi+(1-P)\xi$ is the orthogonal decomposition with respect to $\mc K$. (So $P\xi\in\mc K$ and $(1-P)\xi\in\mc K^\perp$.) Prove that $P$ is a bounded linear map, and $P^2=P$, $P^*=P$. We call $P$ the \textbf{projection operator} \index{00@Projection operator associated to a closed subspace} associated to $\mc K$. 
\end{prob}



\begin{prob}\label{lb894}
Let $P\in\fk L(\mc H)$ be a projection. Prove that 
\begin{equation}\label{eq569}
P(\mc H)=\Ker(1-P)
\end{equation}
and conclude that $P(\mc H)$ is a closed linear subspace of $\mc H$. Prove that $P$ is the projection operator associated to $P(\mc H)$.
\end{prob}


\begin{prob}\label{lb1007}
Let $P,Q\in\fk L(\mc H)$ be projections. 
\begin{enumerate}
\item Prove that the following are equivalent:
\begin{enumerate}
\item $P(\mc H)\subset Q(\mc H)$.
\item $PQ=P$. (Equivalently, $QP=P$, because $P=P^*$.)
\item $P\leq Q$, namely, $\bk{P\xi|\xi}\leq \bk{Q\xi|\xi}$ for all $\xi\in\mc H$.
\end{enumerate}
\item Assume that $P\leq Q$. Prove that $Q-P$ is the projection associated to $Q(\mc H)\cap P(\mc H)^\perp$.
\item Use part 1 to show that $P(\mc H)\perp Q(\mc H)$ iff $PQ=0$ iff $QP=0$.
\end{enumerate}
\end{prob}

\begin{proof}[Hint]
Use \eqref{eq569} to prove (c)$\Rightarrow$(a) of part 1.
\end{proof}

\begin{rem}\label{lb1006}
Applying Pb. \ref{lb1007} to any projection $P$ and the zero projection, we see that $P\geq0$. Of course, this can be proved directly: $\bk{P\xi|\xi}=\bk{P^*P\xi|\xi}=\Vert P\xi\Vert^2\geq0$.
\end{rem}

\subsubsection{Hilbert's notion of boundedness}\label{lb643}


Let $X,Y$ be sets. 

\begin{prob}\label{lb649}
Let $T:l^2(Y)\rightarrow l^2(X)$ be a bounded linear map. Prove that $T$ is uniquely determined by its \textbf{matrix representation} \index{00@Matrix representation}
\begin{align}\label{eq260}
K:X\times Y\rightarrow\Cbb\qquad K(x,y)=\bk{T\chi_{\{y\}}|\chi_{\{x\}}}
\end{align}
Prove that for each $x\in X$, the RHS of the following converges to the LHS:
\begin{gather}\label{eq258}
(T\xi)(x)=\sum_{y\in Y} K(x,y)\xi(y)
\end{gather}
\end{prob}

\begin{proof}[Hint]
Show that the RHS of \eqref{eq258} (together with its convergence) is equal to $\lim_{B\in\fin(2^Y)} \bk{T(\chi_B\xi)|\chi_{\{x\}}}$.
\end{proof}



Let's study the question of which $\infty\times\infty$ matrices are the matrix representations of bounded linear maps. We first consider the special case that $l^2(X)=\Cbb$, and write $K$ as a function $f:Y\rightarrow\Cbb$: 

\begin{exe}\label{lb632}
Let $f\in\Cbb^Y$. Prove that
\begin{align}\label{eq261}
\Vert f\Vert_{l^2(Y)}=\sup_{B\in\fin(2^Y)}~\sup_{g\in \ovl B_{l^2(Y)}(0,1)}\bk{f\chi_B|g}
\end{align}
In particular, we have $f\in l^2(Y)$ iff the RHS of \eqref{eq261} is finite.
\end{exe}
\begin{proof}[Hint]
Use Lem. \ref{lb623} to prove $\dps\sum_{y\in B}|f(y)|^2=\sup_{g\in \ovl B_{l^2(B)}(0,1)}\bk{f\chi_B|g}$.
\end{proof}

\begin{srem}\label{lb638}
There is indeed a stronger criterion: 
\begin{align*}
f\in l^2(Y)\qquad\Longleftrightarrow\qquad\sup_{B\in\fin(2^Y)}\bk{f\chi_B|g}<+\infty\text{ for all }g\in l^2(Y)
\end{align*}
You can think about how to prove it if you know Baire's category theorem. (If you want to know the answer directly, search for "Banach-Steinhaus theorem".)
\end{srem}


Now, we consider the general case.

\begin{prob}\label{lb619}
Let $K:X\times Y\rightarrow\Cbb$. For each $A\in\fin(2^X),B\in\fin(2^Y)$, define
\begin{gather}
M_{A,B}=\sup_{
\begin{subarray}{c}
\psi\in\ovl B_{l^2(X)}(0,1)\\
\xi\in\ovl B_{l^2(Y)}(0,1)
\end{subarray}
}~\bigg|\sum_{x\in A,y\in B}K(x,y)\xi(y)\ovl{\psi(x)} \bigg|
\end{gather}
Assume that $M<+\infty$ where
\begin{align}\label{eq259}
M=\sup_{A\in\fin(2^X),B\in\fin(2^Y)} M_{A,B}
\end{align}
In the following, $\dps\lim_{A,B}$ means $\dps\lim_{A\in\fin(2^X),B\in\fin(2^Y)}$.
\begin{enumerate}
\item For each $A\in\fin(2^X),B\in\fin(2^Y)$, define
\begin{align}\label{eq267}
T_{A,B}:l^2(Y)\rightarrow l^2(X)\qquad \xi\mapsto \sum_{x\in A,y\in B}K(x,y)\xi(y)\cdot\chi_{\{x\}}
\end{align}
Prove that $\Vert T_{A,B}\Vert=M_{A,B}$. 
\item For each $y\in Y$, prove that $\dps\lim_{A,B} T_{A,B}\chi_{\{y\}}$ converges in $l^2(X)$. 
\item Prove that $\dps\lim_{A,B}T_{A,B}$ converges pointwise on $l^2(Y)$ to some bounded linear
\begin{align*}
T:l^2(Y)\rightarrow l^2(X)
\end{align*}
satisfying $\Vert T\Vert=M$.
\item Prove that $K$ is the matrix representation of $T$, i.e., \eqref{eq260} is satisfied.
\end{enumerate}
\end{prob}


\begin{proof}[Hint]
Part 2: Use Exe. \ref{lb632}. Part 3: Use Prop. \ref{lb520} and the fact that $\{\chi_{y}:y\in Y\}$ spans a dense subspace of $l^2(Y)$.
\end{proof}





\begin{rem}\label{lb622}
If $T:l^2(Y)\rightarrow l^2(X)$ is a bounded linear map, then its matrix representation $K$ clearly satisfies $\eqref{eq259}<+\infty$ by Prop. \ref{lb624}. Therefore, Pb. \ref{lb619} gives a description of bounded linear maps $l^2(Y)\rightarrow l^2(X)$ in terms of an explicit analytic condition on the matrix representations, and \eqref{eq259} gives an equivalent definition of operator norms.

Indeed, the above definitions of bounded ``linear maps" and their ``operator norms" \eqref{eq259} were introduced by Hilbert in an influential paper published in 1906, i.e., the fourth part (vierter Abschnitt) of  \cite{Hil12} (cf. also \cite[Sec. 5.2]{Die-H}). If you compare them with the modern definitions of bounded linear maps and operator norms in Sec. \ref{lb620} (which are due to F. Riesz), you will notice two features.

First, of course, Hilbert's definition is more explicit and easier to calculate. Through learning this definition, we know that mathematicians never invent abstract definitions (such as those of Riesz) out of thin air.

The second and more important aspect is that Hilbert's definitions are not really about linear operators (i.e. maps from $l^2(Y)$ to $l^2(X)$), but are about sesquilinear forms. Thanks to the equivalence of linear operators and sesquilinear forms (cf. Thm. \ref{lb627}), we can  translate Pb. \ref{lb619} into the language of sesquilinear forms, as we are going to explain in the next remark.  \hfill\qedsymbol
\end{rem}





\begin{rem}\label{lb666}
Hilbert's goal is to find a general condition ensuring the existence of a bounded form $\omega:l^2(Y)\times l^2(X)\rightarrow\Cbb$ satisfying $\omega(\chi_{y}|\chi_{x})=K(x,y)$ for all $x\in X,y\in Y$. For each $A\in\fin(2^X),B\in\fin(2^Y)$, one defines the truncated form $\omega_{A,B}:l^2(Y)\times l^2(X)\rightarrow\Cbb$ by
\begin{align*}
\omega_{A,B}(\xi|\psi)=\sum_{x\in A,y\in B}K(x,y)\xi(y)\ovl{\psi(x)}
\end{align*}
(Namely, $\omega_{A,B}$ is defined to be $\omega_{T_{A,B}}$ where $T_{A,B}=\eqref{eq267}$.) One wants to find a condition so that $\lim_{A,B}\omega_{A,B}$ converges pointwise to some continuous function $\omega$ (which is clearly sesquilinear).

The condition found by Hilbert, namely $M<+\infty$ in Pb. \ref{lb619}, \uwave{is a condition of equicontinuity}\footnote{Recall that operator norms are also related to equicontinuity!}: Clearly $M_{A,B}=\Vert\omega_{A,B}\Vert$. Thus, $M<+\infty$ means that $\sup_{A,B}\Vert\omega_{A,B}\Vert<+\infty$. Therefore, by Exe. \ref{mc242}, $(\omega_{A,B})_{A\in\fin(2^X),B\in\fin(2^Y)}$ is an equicontinuous family of functions when restricted to $\Delta_R=\ovl B_{l^2(Y)}(0,R)\times\ovl B_{l^2(X)}(0,R)$ for every $R>0$. Moreover, this family clearly converges pointwise on the dense subset $\Delta_R\cap E$ where $E=\Span\{\chi_{\{y\}}:y\in Y\}\times \Span\{\chi_{\{x\}}:x\in X\}$. Therefore, by Prop. \ref{lb511}, $\lim_{A,B}\omega_{A,B}$ converges pointwise on each $\Delta_R$ to some continuous function.\footnote{This part is similar to the proof of Pb. \ref{lb619}-3, which uses Prop. \ref{lb520}, a special case of Prop. \ref{lb511}.} By considering all $R$, we get the desired function $\omega$ on $l^2(Y)\times l^2(X)$.  \hfill\qedsymbol
\end{rem}

\begin{srem}\label{lb639}
Soon after Hilbert's work, in 1906, Hellinger and Toeplitz simplified Hilbert's boundedness condition by proving that $\sup_{A,B}\Vert\omega_{A,B}\Vert<+\infty$ iff $\sup_{A,B}|\omega_{A,B}(\xi|\psi)|<+\infty$ for all $\xi\in l^2(Y),\psi\in l^2(X)$. Similar to Rem. \ref{lb638}, this result is nowadays proved using Baire's category theorem (or its consequence, the Banach-Steinhaus theorem). To my knowledge, this \textbf{Hellinger-Toeplitz theorem} (in its original form, cf. \cite[Sec. 6.4]{Die-H}) is one of the very few theorems before Riesz's work that made full use of the \textit{completeness} of $l^2(X)$ without adopting the viewpoint of linear operators, cf. Sec. \ref{lb671}.
\end{srem}






\subsubsection{$\star$ Direct sums of Hilbert spaces}\label{lb880}


A tip for solving the problems in this subsection: Use cleverly Prop. \ref{lb500} or Prop. \ref{lb520} or other ``reduction to densely-spanning subsets" tricks to simplify the proof. (We have already used such tricks in the solution of Pb. \ref{lb619}.)


\begin{prob}
Let $(\mc H_i)_{i\in I}$ be a family of Hilbert spaces. Recall that elements of $\dps\prod_{i\in I}\mc H_i$ are of the form $\xi_\blt=(\xi_i)_{i\in I}$ where $\xi_i\in\mc H_i$. Then $\dps\prod_{i\in I}\mc H_i$ is a vector space whose linear structure is defined componentwise. Define 
\begin{align}
\bigoplus_{i\in I}\mc H_i=\Big\{(\xi_i)_{i\in I}\in\prod_{i\in I}\mc H_i:\sum_{i\in I}\Vert\xi_i\Vert^2<+\infty  \Big\}
\end{align}
equipped with the inner product
\begin{align}\label{eq270}
\bk{\xi_\blt|\eta_\blt}=\bk{(\xi_i)_{i\in I}|(\eta_i)_{i\in I}}=\sum_{i\in I}\bk{\xi_i|\eta_i}
\end{align}
Prove that the rightmost term of \eqref{eq270} converges (absolutely). Prove that the inner product space $\bigoplus_{i\in I}\mc H_i$ is complete. (So $\bigoplus_{i\in I}\mc H_i$ is a Hilbert space, called the \textbf{(Hilbert space) direct sum}\index{00@Hilbert space direct sums} of $(\mc H_i)_{i\in I}$.) An element $(x_\blt)$ in $\bigoplus_{i\in I}\mc H_i$ is also written as $\oplus_{i\in I}\xi_i$.
\end{prob}






\begin{prob}
Let $(\mc H_i)_{i\in I}$ be a family of Hilbert spaces. For each $i\in I$, choose $T_i\in\fk L(\mc H_i)$. Assume that
\begin{align}
\sup_{i\in I}\Vert T_i\Vert<+\infty
\end{align} 
Prove that there is a unique bounded linear operator $T$ on $\mc H:=\bigoplus_{i\in I}\mc H_i$ such that for each $\oplus_i\xi_i\in\mc H$,
\begin{align}
T(\oplus_i\xi_i)=\oplus_i (T_i\xi_i)
\end{align}
We write $T=\oplus_{i\in I}T_i$ and call it the \textbf{direct sum} \index{00@Direct sum of bounded linear operators} of $(T_i)_{i\in I}$. Prove that
\begin{align}
(\oplus_i T_i)^*=\oplus_i(T_i^*)
\end{align}
\end{prob}

\begin{prob}\label{lb633}
Let $(\mc H_i)_{i\in I}$ be a mutually orthogonal family of closed linear subspaces of $\mc H$. Assume that this family spans a dense subspace of $\mc H$. Prove that there is a unitary map
\begin{gather}
\begin{gathered}
\Phi:\bigoplus_{i\in I}\mc H_i\xlongrightarrow{\simeq}\mc H\qquad \oplus_{i\in I}\xi_i\mapsto\sum_{i\in I}\xi_i
\end{gathered}
\end{gather}
\end{prob}
\begin{proof}[Hint]
Once you have proved that $\Phi$ is a linear isometry, to prove that $\Phi$ is surjective, you only need to show that $\Phi$ has dense range. (Why?) 
\end{proof}


\begin{prob}\label{lb659}
In Pb. \ref{lb633}, choose $T\in\fk L(\mc H)$ such that each $\mc H_i$ is \textbf{$T$-invariant}, i.e., $T\mc H_i\subset\mc H_i$. Thus, the restriction of $T$ to each $\mc H_i$ gives $T_i\in\fk L(\mc H_i)$. Clearly $\sup_i\Vert T_i\Vert\leq \Vert T\Vert<+\infty$. Prove that the following diagram commutes:
\begin{equation}
\begin{tikzcd}[column sep=large]
\bigoplus_{i\in I}\mc H_i\arrow[r,"\oplus_i T_i"] \arrow[d,"\simeq","\Phi"'] & \bigoplus_{i\in I}\mc H_i \arrow[d,"\Phi","\simeq"'] \\
 \mc H \arrow[r,"T"]           &  \mc H          
\end{tikzcd}
\end{equation}
In other words, $\Phi$ implements a \textbf{unitary equivalence} of $\oplus_i T_i$ and $T$. \index{00@Unitary equivalence of operators}
\end{prob}



\newpage


\section{The birth of Hilbert spaces}\label{lb672}

\subsection{From the Dirichlet problems to integral equations}\label{lb668}

Around 1906, the Hilbert space $l^2(\Zbb)$ was introduced by Hilbert and Schmidt to the study of integral equations. As mentioned in the previous chapter, the main analytic property of $l^2(\Zbb)$ attracting Hilbert and Schmidt is the weak compactness of the closed unit ball.  The goal of this chapter is to learn how Hilbert and Schmidt used this property to study integral equations.

\subsubsection{Dirichlet problems}


A main source of integral equations comes from solving the \textbf{Poisson equation with Dirichlet boundary condition}:
\begin{itemize}
\item Let $\ovl\Omega$ be a compact region in $\Rbb^N$ with interior $\Omega$ and smooth boundary $\partial\Omega$.\footnote{Technically speaking, $\ovl\Omega$ is a compact smooth $N$-dimensional submanifold of $\Rbb^N$ with boundary} Given good enough (say $C^r$, or $C^\infty$) functions $g$ on $\partial\Omega$ and $\varphi$ on $\Omega$, find good enough $u$ on $\Omega$ satisfying
\begin{gather}\label{eq271}
-\Delta u|_\Omega=\varphi\qquad u|_{\partial\Omega}=g
\end{gather}
Here, $\Delta$ is the Laplacian $\partial_1^2+\cdots+\partial_N^2$.
\end{itemize}
In the following, we abbreviate $-\Delta u|_\Omega$ to $-\Delta u$.

The Tietze type extension gives a good $\wtd g$ on $\ovl\Omega$ with $\wtd g|_{\partial\Omega}=g$. Then \eqref{eq271} becomes $-\Delta(u-\wtd g)=\varphi+\Delta\wtd g$ with $(u-\wtd g)|_{\partial\Omega}=0$. Therefore, \eqref{eq271} can be reduced to the special case
\begin{align}\label{eq272}
-\Delta u=\varphi\qquad u|_{\partial\Omega}=0
\end{align}
By replacing $\ovl\Omega$ with a more general smooth compact manifold with (or without) boundary, this problem, and also the \textbf{Helmholtz equation}
\begin{align}\label{eq273}
-\Delta u=\lambda u\qquad u|_{\partial\Omega}=0
\end{align}
have wide applications in differential geometry and in other types of differential equations. (For example, let $v=v(t,x_1,\dots,x_N)$, then the \textbf{heat equation} $\partial_t v=\Delta v$ and the \textbf{wave equation} $\partial_t^2v=\Delta v$ can be solved by $v=\sum_je^{-\lambda_jt}u_j$ and $v=\sum_j e^{\pm\im\sqrt{\lambda_j}t}u_j$ where $-\Delta u_j=\lambda_ju_j$.)


\subsubsection{Compact operators (i.e. completely continuous operators)}\label{lb667}

The following is roughly the modern treatment of the \textbf{Dirichlet problem} \eqref{eq272}: Let $L^2(\ovl\Omega)$ be the Hilbert space of Lebesgue integrable functions $u:\ovl\Omega\rightarrow\Cbb$ satisfying $\int_{\ovl\Omega} |u|^2<+\infty$. The inner product is given by $\bk{u|v}=\int_{\ovl\Omega} uv^*$. One shows that $-\Delta$, defined on a suitable dense linear subspace of $L^2(\ovl\Omega)$, has a bounded inverse $T\in\fk L(L^2(\ovl\Omega))$ satisfying $\bk{T\xi|\xi}\geq0$ for all $\xi\in L^2(\ovl\Omega)$.\footnote{In the case that ${\ovl\Omega}$ is a compact manifold without boundary, $-\Delta$ should be replaced by $C-\Delta$ where $C>0$.} (Namely, $T$ is a bounded \textbf{positive operator}.) Thus, the problem \eqref{eq272} has solution $u=T\varphi$ in $L^2(\ovl\Omega)$. An analysis of regularity (with the help of Sobolev spaces) then shows that $u$ is good enough.


Moreover, one shows that $T$ is a compact operator (equivalently, a completely continuous operator, cf. Def. \ref{lb653}):
\begin{df}
A linear map $T:V\rightarrow W$ of Banach spaces is called \textbf{compact} if $T(\ovl B_V(0,1))$ is precompact in $W$ (under the norm topology).
\end{df}
According to the \textbf{Hilbert-Schmidt theorem} (cf. Thm. \ref{lb662}), $T$ has countably many eigenvalues $\lambda_1\geq\lambda_2\geq\cdots\geq0$ satisfying $\lim_n\lambda_n=0$, and the (normalized) eigenvectors of $T$ form an orthonormal basis of $L^2(\ovl\Omega)$. The regularity analysis also shows that the eigenvectors of $T$ are smooth. Thus, the eigenvalue problem \eqref{eq273} can be fully solved.

We refer the interested readers to \cite[Ch. 6]{Eva}, \cite{Tay} (especially Sec. 5.1), \cite{Yu} (especially Sec. 78-80) for a detailed study of this topic.

\subsubsection{From Dirichlet problems to integral equations}


In the days of Hilbert and Schmidt, the Dirichlet problem \eqref{eq271} was understood in a different way by transforming it to a problem about integral equations. It was in the process of solving these integral equations that the Hilbert space $l^2(\Zbb)$ was discovered. In the following, I will sketch how to transform Dirichlet problems to integral equations using ``double layer potentials". Cf. \cite[Sec. 3C]{Fol-P} (where all the statements are accompanied by detailed proofs), \cite[Sec. 3.3]{Sim-O}, or \cite[Sec. 81]{RN}. A discussion of the history of this method can be found in \cite[Sec. 2.5]{Die-H}.

Set $x=(x_1,\dots,x_N)$. Without imposing the boundary condition $u|_{\partial\Omega}$, and assuming that the $\varphi$ in $-\Delta u=\varphi$ can be extended to a good function on $\Rbb^N$ with compact support, then $-\Delta u=\varphi$ has a solution
\begin{align*}
u(x)=(\Phi*\varphi)(x)=\int_{\Rbb^N}\Phi(x-y)\varphi(y)dy
\end{align*} 
where $\Phi$, called the \textbf{fundamental solution}, is defined by
\begin{align}
\Phi(x)=\left\{
\begin{array}{ll}
\dps-\frac 1{2\pi}\log\Vert x\Vert&\text{ if }N=2\\
\dps\frac 1{(N-2)\sigma_{N-1}\cdot\Vert x\Vert^{N-2}}&\text{ if }N\geq3
\end{array}
\right.
\end{align}
where $\sigma_{N-1}=2\pi^{\frac N2}\Gamma(N/2)^{-1}$ is the volume of $\Sbb^{N-1}=\{x\in\Rbb^N:\Vert x\Vert=1\}$. $\Delta\Phi$ is the delta function at $0$. In particular, it is zero outside $0$. Cf. \cite[Sec. 2.2.1]{Eva}.

By replacing $u$ with $u-\Phi*\varphi$, \eqref{eq271} is transformed to the \textbf{harmonic equation} (with Dirichlet boundary condition)
\begin{align}\label{eq274}
-\Delta u=0\qquad u|_{\partial\Omega}=g
\end{align}
Write $\nabla v=(\partial_1v,\dots,\partial_Nv)$ for each differentiable function $v$ on subsets of $\Rbb^N$. For each $y\in\partial\Omega$ we let $\mbf n_{y}$ be the outward pointing unit vector at $y$ orthogonal to (the tangent space of) $\partial\Omega$ at $y$. Define $G(x,y)$ for each $x\in\Rbb^N,y\in \partial\Omega$ by
\begin{align}\label{eq277}
G(x,y)=\bigbk{(\nabla\Phi)(x-y),\mbf n_{y}} =\frac{\bk{y-x,\mbf n_{y}}}{\sigma_{N-1}\Vert x-y\Vert^N} 
\end{align}
For each $x\in\Rbb^N$ and continuous function $f$ on $\partial\Omega$, define $(\mc Df)(x)=\int_{\partial\Omega}f(y)(\nabla\Phi)(x-y)\cdot d\Sbf$ where the RHS is a ``surface integral of a vector field" (cf. Thm. \ref{mc206}), i.e.
\begin{align}
(\mc D f)(x)=\int_{\partial\Omega}G(x,y)f(y)dy
\end{align}
When $x\in\partial\Omega$, this is an improper integral, which converges because
\begin{align}\label{eq276}
G(x,y)\sim \Vert x-y\Vert^{2-N}
\end{align}
when $x\in\partial\Omega$ approaches $y$. (Note that $\int_U\Vert y\Vert^{2-N}dy$ converges if $U\subset\Rbb^{N-1}$ is a bounded neighborhood of $0$.)

$\mc Df$ is not continuous at the points of $\partial\Omega$. However, if we define $u:{\ovl\Omega}\rightarrow\Cbb$ by
\begin{align}\label{eq275}
u(x)=\left\{
\begin{array}{ll}
(\mc Df)(x)&\text{ if }x\in\Omega\\
f(x)+(\mc Df)(x)&\text{ if }x\in\partial\Omega
\end{array}
\right.
\end{align}
then $u$ is continuous on ${\ovl\Omega}$. Moreover, $\Delta u=0$ on $\Omega$ since  $\Delta G(x,y)=0$ when $x\neq y$. Therefore, the Dirichlet problem \eqref{eq274} can be solved if there exists a good function $f$ on $\partial\Omega$ such that $f+\mc Df|_{\partial\Omega}=g$.

To summarize, define an integral operator $T$ on the space $L^2(\partial\Omega)$ of Lebesgue square integrable functions by
\begin{align}
(Tf)(x)=\int_{\partial\Omega}G(x,y)f(y)dy
\end{align}
The equation \eqref{eq274} has solution \eqref{eq275} if there is an (at least continuous) $f:\partial\Omega\rightarrow\Cbb$ satisfying $f+Tf=g$. The problem is then reduced to finding such $f$ for a given $g$.


\begin{rem}
Let us explain the physical meaning of $\Phi$ and $\mc D(f)$. If a point charge $Q$ is located at $y\in\Rbb^N$, then the electric potential energy at $x\in\Rbb^N$ generated by $Q$ is $V(x)=Q\cdot \Phi(x-y)$. Thus, if $\varphi:\Rbb^N\rightarrow \Rbb$ is a charge distribution function, the potential function generated by $\varphi$ is $V(x)=\int_{\Rbb^N}\varphi(y)\Phi(x-y)dy$. The electric field generated by $\varphi$ is $\mbf E=-\nabla V$.  Gauss's law predicts  $\varphi=\nabla\cdot \mbf E$ where $\nabla\cdot\mbf E$ is the gradient of $\mbf E$. Hence $\varphi=-\Delta V$.

Now, put a slightly smaller $(N-1)$-dimensional surface $\partial'\Omega$ inside $\partial\Omega$ such that the distance between $\partial'\Omega$ and $\partial\Omega$ is a very small positive number $\eps$. (Thus, $\partial'\Omega$ and $\partial\Omega$ form a thin ``\textbf{double layer}".) On $\partial\Omega$ and on $\partial'\Omega$, we put $(N-1)$-dimensional charge distribution functions $Q=Q(x)$ and $Q'=Q'(x)$ respectively satisfying $Q'(x)=-Q(x)=f(x)/\eps$. (The $x$ of $Q(x)$ is on $\partial\Omega$. The $x$ of $Q'(x)$ is on $\partial'\Omega$. Since $\partial'\Omega$ is close to $\partial\Omega$, the second $x$ can also be viewed as on $\partial\Omega$. Thus $Q,Q'$ are functions on $\partial\Omega$.) Then $\mc D(f)$ is the potential function generated by the electric charges on $\partial\Omega$ and $\partial'\Omega$. Since there are no charges inside $\partial'\Omega$, Gauss's law predices that $-\Delta\mc D(f)|_{\Omega}=0$. Eq. \eqref{eq257} means that the potential $\mc D(f)$ has jump discontinuity (by $-f$) when one moves from inside $\partial'\Omega$ to the middle between $\partial'\Omega$ and $\partial\Omega$.  \hfill\qedsymbol
\end{rem}


\subsubsection{Summary of the problem of integral equations}\label{lb642}


Given a function $g$ on $\partial\Omega$, we want to find a function $f$ on $\partial\Omega$ satisfying
\begin{subequations}\label{eq282}
\begin{align}
f+Tf=g
\end{align}
Moreover, we shall consider the case that $N=2$ and hence $\dim\partial\Omega=1$, which is in line with history. Let us assume that $\partial\Omega$ has only one connected component so that $\partial\Omega\simeq\Sbb^1$. So we view $f,g$ also as $2\pi$-periodic functions with $L^2$-norms $\Vert f\Vert=\sqrt{\frac 1{2\pi}\int_{-\pi}^\pi |f|^2}$ and $\Vert g\Vert=\sqrt{\frac 1{2\pi}\int_{-\pi}^\pi |g|^2}$. Then
\begin{align}
(Tf)(x)=\frac 1{2\pi}\int_{-\pi}^\pi K(x,y)f(y)dy
\end{align}
\end{subequations}
where $K(x,y)=G(x,y)\cdot \lambda(y)\lambda(x)$ for some $\lambda\in C^\infty(\Sbb^1,\Rbb)$ defined by the change of variable from $\partial\Omega$ to $\Sbb^1$ (similar to the function $\Phi'$ in \eqref{eq278}).  


Since $G$ takes real values, so does $K$. \eqref{eq276} suggests that $K$ is uniformly bounded on $\Sbb^1\times\Sbb^1$. Indeed, $K$ is continuous (cf. \cite[Sec. 81]{RN}). However, we will only need the weaker fact that $K\in L^2(\Sbb^1\times\Sbb^1)$, i.e. \footnote{When $N>2$, we do not necessarily have $\Vert K\Vert_{L^2}<+\infty$. However, $T$ is always a completely continuous operator (equivalently, a compact operator) on $L^2(\partial\Omega)$. See \cite{Fol-P} Sec. 3.B, Prop. 3.11.}
\begin{align}
\Vert K\Vert_{L^2}=\frac 1{(2\pi)^2}\int_{-\pi}^\pi\int_{-\pi}^\pi|K(x,y)|^2dydx<+\infty
\end{align}


In finite-dimensional linear algebra, we know that a linear operator is surjective iff it is injective. If this is the case for $1+T$, then solving $(1+T)f=g$ can be reduced to the easier task of proving that $-1$ is not an eigenvalue of $T$. However, there are bounded linear operators on infinite dimensional function spaces that are injective but not surjective: Consider the right translation operator on $l^2(\Nbb)$, which is the bounded linear operator sending each $\chi_{\{n\}}$ to $\chi_{\{n+1\}}$.

%In the present case, it is not hard to check (using a general argument for Hilbert spaces) that if $\Ker(1+T)=0$ then $1+T$ has dense range in $L^2(\Sbb^1)$. However, it is not clear why $1+T$ must be surjective and, in particular, why $1+T$ must have closed range. %(Indeed, many bounded linear operators on Hilbert spaces are injective but do not have closed ranges.)

To understand the behavior of $T$, and to solve other problems leading to integral equations, it turns out that we must have a good understanding of the eigenvalues and eigenvectors of $T$. As soon as we understand the eigenvalue problem of $T$ very well, we can prove the theorem of \textbf{Fredholm alternative}, which says that $\Ker(1+T)=0$ iff $1+T$ is surjective. 




\subsection{Discretizing the integral equations}\label{lb669}

Fix $K\in L^2(\Sbb^1\times\Sbb^1)$. (The readers can assume for simplicity that $K$ is continuous, which is often the case when $K$ is defined by the 2d Dirichlet problem as in Subsec. \ref{lb642}.) Define the integral operator $T$ sending each $2\pi$-periodic function $f$ to $Tf$, where 
\begin{align}
(Tf)(x)=\frac 1{2\pi}\int_{-\pi}^\pi K(x,y)f(y)dy
\end{align}
$K$ is called the \textbf{kernel} of $T$. Our goal is to understand the eigenvalues and eigenvectors of $T$.

Hilbert's idea is to use Fourier series. Functions on $\Sbb^1\times\Sbb^1$ have Fourier series of the form $\sum_{m,n}a_{m,n}e^{\im(-nx+my)}$ in a similar way as functions on $\Sbb^1$. Therefore, for each $m,n\in\Zbb$, define the Fourier coefficient
\begin{align}\label{eq283}
\wht K(m,n)=\bk{Te_n|e_m}=\frac 1{(2\pi)^2}\int_{-\pi}^\pi\int_{-\pi}^\pi K(x,y)e^{\im (nx-my)}dxdy
\end{align}
Then, by Thm. \ref{lb595}, we get $f=\sum_n \wht f_ne_n$ and $g=\sum_m \wht g_me_m$, and hence
\begin{align*}
\bk{Tf|g}=\sum_{m,n}\wht K(m,n)\wht f(n)\ovl{\wht g(m)}=\bk{\wht T\wht f|\wht g}
\end{align*}
if we view $\wht f,\wht g$ as in $l^2(\Zbb)$ and define a linear map $\wht T:l^2(\Zbb)\rightarrow l^2(\Zbb)$ by
\begin{align}\label{eq284}
\tcboxmath{(\wht T\wht f)(m)=\sum_{n\in\Zbb} \wht K(m,n)\wht f(n)}
\end{align}
By applying Parseval's identity to $K$, we obtain $\sum_{m,n}|\wht K(m,n)|^2=(2\pi)^{-2}\int\int K(x,y)dxdy$ (which is a finite number), and hence
\begin{align}
\wht K\in l^2(\Zbb\times\Zbb)
\end{align}
Thus, to understand the original integral equation, one must first understand the equation
\begin{align}
\wht f+\wht K\wht f=\wht g
\end{align}
%where $\wht K\in l^2(\Zbb\times\Zbb)$ and $\wht g\in l^2(\Zbb)$ are given.


In fact, at this point, Hilbert did not have the notion of $l^2(\Zbb)$ and $L^2$ yet. However, the idea of transforming the eigenvalue problem about $T$ to that about the \textit{matrix} $\wht K$ without introducing $l^2(\Zbb)$ is conceivable. After all, almost every mathematical progress leaves some questions about rigor until the end.

%\begin{rem}
%Parseval's identity $\frac 1{2\pi}\int_{-\pi}^\pi |f|^2=\sum_n |\wht f(n)|^2$ is well-known by the time Hilbert studied integral equations around 1906. However, Parseval's identity is far from enough to motivate the notion of $l^2(\Zbb)$: Unlike the completeness of $l^2(\Zbb)$ or the weak compactness of $\ovl B_{l^2(\Zbb)}(0,1)$, Parseval's identity is a property about individual functions, not about the set of all functions \textit{and their interactions}. 
%Knowing that \textit{some} functions on $\Zbb$ are square summable does not mean that the set of \textit{all} square summable functions should be studied. To have the motivation to move from some functions satisfying certain properties to the \emph{space} of all functions satisfying these properties, there must be a desire to use some algebraic/geometric/analytic properties about the entire space but not about the particular functions. In the case of the space $l^2(\Zbb)$, the weak compactness of the closed unit ball is about the set of all functions (and their interaction), but Parseval's identity is only stated for individual functions.
%\end{rem}


In the remaining sections, we will forget the original function $K$ on $\Sbb^1\times\Sbb^1$, as Hilbert did, and focus on the matrix $\wht K\in l^2(\Zbb\times\Zbb)$. Thus, we will let $K$ denote $\wht K$, or denote a general function $X\times Y\rightarrow\Cbb$ where $X,Y$ are sets. 



\subsection{Hilbert's complete continuity}

We fix Hilbert spaces $\mc H$ and $\mc K$. Let $X,Y$ be sets. For each linear map $T:\mc H\rightarrow\mc K$ we let \index{zz@$\omega_T$, the sesquilinear map for $T$}
\begin{gather}\label{eq280}
\omega_T:\mc H\times\mc K\rightarrow\Cbb\qquad \omega_T(\xi|\eta)=\bk{T\xi|\eta}
\end{gather}

In his important 1906 paper, Hilbert introduced two crucial analytic properties about sesquilinear forms. The first one is boundedness (i.e., the condition $M<+\infty$ in Pb. \ref{lb619}), which is equivalent to the boundedness of linear maps between Hilbert spaces. In particular, we have
\begin{align}
T\in\fk L(\mc H,\mc K)\qquad\Longleftrightarrow\qquad \omega_T\text{ is continuous}
\end{align}
See Subsec. \ref{lb643} for details. 

The second condition is stronger than the first one (cf. \cite[p.147]{Hil12}): A sesquilinear $\omega:\mc H\times\mc K\rightarrow\Cbb$ is called \textbf{completely continuous} if $\omega$ is weakly continuous when restricted to $\ovl B_{\mc H}(0,1)\times\ovl B_{\mc K}(0,1)$. It is easy to adapt this definition to linear maps:

\begin{df}\label{lb653}
A linear map $T:\mc H\rightarrow\mc K$ is called \textbf{completely continuous}\index{00@Completely continuous} if $\omega_T$ is continuous on $\ovl B_{\mc H}(0,1)\times\ovl B_{\mc K}(0,1)$ where $\ovl B_{\mc H}(0,1)$ and $\ovl B_{\mc K}(0,1)$ are equipped with their weak topologies.
\end{df}

Thus, complete continuity means that if $(\xi_\alpha)$ converges weakly in $\ovl B_{\mc H}(0,1)$ to $\xi$ and  $(\eta_\alpha)$ converges weakly in $\ovl B_{\mc K}(0,1)$ to $\eta$, then $\lim_\alpha \bk{T\xi_\alpha|\eta_\alpha}=\bk{T\xi|\eta}$. 




Completely continuous sesquilinear forms are clearly continuous (i.e., bounded, cf. Pb. \ref{lb627}). Thus, it is not hard see:

\begin{rem}\label{lb645}
A completely continuous linear map $T:\mc H\rightarrow\mc K$ is bounded. 
\end{rem}
\begin{proof}
$\omega_T$ is weakly continuous and hence continuous on $\ovl B_{\mc H}(0,1)\times\ovl B_{\mc K}(0,1)$. Therefore, $\omega:V\times V\rightarrow\Cbb$ is continuous at $(0,0)$. By Exe. \ref{mc242}, $\omega_T$ is bounded. Equivalently (cf. Prop. \ref{lb624}), $T$ is bounded.
\end{proof}

%\begin{rem}
%Though Rem. \ref{lb645} looks elementary, we will not need this lemma. In fact, all the completely continuous operators we will encounter are easily verified to be bounded. Thus, we do not lose much if we \textit{define} a completely continuous map $T$ to be a \textit{bounded} linear map $T$ such that $\omega_T$ is weakly continuous on $\ovl B_{\mc H}(0,1)\times\ovl B_{\mc K}(0,1)$.
%\end{rem}


\begin{eg}
Assume that $\mc H$ is an infinite-dimensional Hilbert space. Then its identity operator $1$ is not completely continuous. This is because $\omega_1$ is the inner product function $(\xi,\eta)\in\mc H\times\mc H\mapsto\bk{\xi|\eta}\in\Cbb $, which is not weakly continuous by Exp. \ref{lb661}.
\end{eg}


\begin{exe}
Show that a finite linear combination of completely continuous operators is continuous. Show that the adjoint of a completely continuous operator is completely continuous. %Show that if $T\in\fk L(\mc H_1,\mc H_2)$ and $S\in\fk L(\mc H_2,\mc H_3)$ where each $\mc H_i$ is a Hilbert space, and if one of $T$ and $S$ is completely continuous, then $ST:\mc H_1\rightarrow\mc H_3$ is completely continuous. In particular, the set of completely continuous operators on $\mc H$ is a two-sided ideal of $\fk L(\mc H)$.
\end{exe}


The easiest examples of completely continuous maps are finite-rank operators:

\begin{df}
A linear map of vector spaces is said to have \textbf{finite rank} if its range is finite-dimensional. \index{00@Finite rank operator}
\end{df}

\begin{pp}\label{lb644}
Let $T\in\fk L(\mc H,\mc K)$. The following are equivalent:
\begin{enumerate}
\item[(1)] $T$ has finite rank.
\item[(2)] There exist finitely many vectors $\mu_1,\dots,\mu_n\in\mc H$ and $\eta_1,\dots,\eta_n\in\mc K$ such that for all $\xi\in\mc H$,
\begin{align}
T\xi=\sum_{i=1}^n \bk{\xi|\mu_i}\eta_i
\end{align} 
\end{enumerate} 
\end{pp}

Note that without assume that $T$ is bounded, (1) does not imply (2).

\begin{proof}
``(2)$\Rightarrow$(1)" is obvious. Assume (1). Restrict the inner product of $\mc K$ to the finite-dimensional $V=T(\mc H)$. 
By Gram-Schmidt, $V$ is spanned by an orthonormal set of vectors $\eta_1,\dots,\eta_n$. Then, for each $\psi\in V$ we have (by Thm. \ref{lb595}) $\psi=\sum_{i=1}^n \bk{\psi|\eta_i}\eta_i$. Therefore
\begin{align*}
T\xi=\sum_i\bk{T\xi|\eta_i}\eta_i=\sum_i\bk{\xi|\mu_i}\eta_i
\end{align*}
where $\mu_i=T^*\eta_i$.
\end{proof}


\begin{eg}
If $T\in\fk L(\mc H,\mc K)$ has finite rank, then $T$ is completely continuous.
\end{eg}

\begin{proof}
By Prop. \ref{lb644}, and by linearity, it suffices to assume that $T$ takes the form $T\xi=\bk{\xi|\mu}\eta$ for some $\mu\in\mc H,\eta\in\mc K$. Then $\omega_T(\xi|\psi)=\bk{\xi|\mu}\bk{\eta|\psi}$ is clearly weakly continuous with respect to $\xi$ and $\psi$.
\end{proof}

In order to have nontrivial examples of completely continuous operators, we need the following simple fact:

\begin{thm}\label{lb647}
Let $(T_\alpha)$ be a net of completely continuous maps $\mc H\rightarrow\mc K$. Assume that $T:\mc H\rightarrow\mc K$ is linear and $\lim_\alpha\Vert T-T_\alpha\Vert=0$. Then $T$ is completely continuous.
\end{thm}

\begin{proof}
By Cor. \ref{lb646}, $\omega_{T_\alpha}$ converges uniformly on $\ovl B_{\mc H}(0,1)\times\ovl B_{\mc K}(0,1)$ to $\omega_T$. Since the uniform limit of a net of continuous functions is continuous, we conclude that $\omega_T$ is weakly continuous on $\ovl B_{\mc H}(0,1)\times\ovl B_{\mc K}(0,1)$.
\end{proof}


Motivated by the above theorem, we make the following definition:
\begin{df}
We say that a linear map $T:\mc H\rightarrow\mc K$ is \textbf{approximable} \index{00@Approximable} if there exists a net (equivalently, a sequence) of finite-rank operators $(T_\alpha)$ in $\fk L(\mc H,\mc K)$ such that $\lim_\alpha \Vert T-T_\alpha\Vert=0$. Approximable operators are clearly bounded.
\end{df}


\begin{thm}\label{lb648}
Let $T:\mc H\rightarrow\mc K$. Then $T$ is approximable iff $T$ is completely continuous.
\end{thm}



\begin{proof}[$\star$ Proof]
Since finite-rank bounded linear operators are completely continuous, by Thm. \ref{lb647}, approximability implies complete continuity. Conversely, assume that $T$ is completely continuous. Assume WLOG that $\mc H=l^2(Y)$ and $\mc K=l^2(X)$. For each $A\in\fin(2^X)$ and $B\in\fin(2^Y)$ we set
\begin{align}\label{eq281}
T_{A,B}:l^2(Y)\rightarrow l^2(X)\qquad T_{A,B}\xi=\chi_A\cdot T(\chi_B\xi)
\end{align}
which is a bounded linear map of finite rank. We claim that $\lim_{A,B}\Vert T-T_{A,B}\Vert=0$.

By Cor. \ref{lb646}, we need to show that $(\omega_{T_{A,B}})_{A\in\fin(2^X),B\in\fin(2^Y)}$ converges uniformly on $\Omega=\ovl B_{l^2(Y)}(0,1)\times\ovl B_{l^2(X)}(0,1)$ to $\omega_T$. Equip $\Omega$ with the product weak topology, which is compact by Cor. \ref{lb636}. Since each $\omega_{T_{A,B}}$ is (weakly) continuous, by (1)$\Rightarrow$(2) of Thm. \ref{lb277} (together with Prop. \ref{lb281}), it suffices to prove
\begin{align*}
\lim_{A,B,\xi',\eta'} |\omega_T(\xi'|\eta')-\omega_{T_{A,B}}(\xi'|\eta')|=|\omega_T(\xi|\eta)-\omega_T(\xi|\eta)|\equiv 0
\end{align*}
where $\xi'$ converges weakly to $\xi$ and $\eta'$ converges weakly to $\eta$. Equivalently, it suffices to prove that for each net $(\xi_i,\eta_i)_{i\in I}$ in $\Omega$ converging to $(\xi,\eta)\in\Omega$, we have
\begin{align*}
\lim_{A,B,i} |\bk{(T-T_{A,B})\xi_i|\eta_i}|=0
\end{align*}
Clearly $\lim \bk{T\xi_i|\eta_i}=\bk{T\xi|\eta}$ since $T$ is completely continuous. Note that $\bk{T_{A,B}\xi_i|\eta_i}=\bk{T\chi_B\xi_i|\chi_A\eta_i}$. It remains to show that this expression also converges to $\bk{T\xi|\eta}$. Since $T$ is completely continuous, it suffices to prove that $\lim_{B,i}{\chi_B\xi_i}$ converges weakly to $\xi$ and $\lim_{A,i}{\chi_A\eta_i}$ converges weakly to $\eta$.

By Exp. \ref{lb1001}, we know for each $y\in Y$ that  $\lim_i\xi_i(y)=\xi(y)$ and hence $\lim_{B,i}\chi_B(y)\xi_i(y)=\xi(y)$. By Exp. \ref{lb1001} again, we conclude that $\lim_{B,i}{\chi_B\xi_i}$ converges weakly to $\xi$. The second (weak) limit can be proved in the same way.
\end{proof}

\begin{rem}
Since the proof of the direction ``$\Leftarrow$" in Thm. \ref{lb648} is slightly more complicated (although the main idea is clear), we will not use this direction in the future.  But see Rem. \ref{lb817} for an alternative proof.
\end{rem}


\begin{rem}
In the proof of Thm. \ref{lb648} we have shown that if $T:l^2(Y)\rightarrow l^2(X)$ is completely continuous, then
\begin{align}
\lim_{A\in\fin(2^X),B\in\fin(2^Y)}\Vert T-T_{A,B}\Vert=0
\end{align}
In contrast, if $T$ is only bounded, then it is easy to see that $\lim_{A,B}T_{A,B}$ converges pointwise to $T$.
\end{rem}



\subsection{Hilbert-Schmidt operators}


Let $X$ and $Y$ be sets. Recall Pb. \ref{lb649} for the basic facts about matrix representations.

\begin{thm}\label{lb651}
Let $K\in l^2(X\times Y)$. Then $K$ is the matrix representation of a (necessarily unique) completely continuous $T:l^2(Y)\rightarrow l^2(X)$. Moreover, we have
\begin{align}
\Vert T\Vert\leq \Vert K\Vert_{l^2}
\end{align}
\end{thm}

Such $T$ is called a \textbf{Hilbert-Schmidt operator}. \index{00@Hilbert-Schmidt operator} See Pb. \ref{lb650} for the general definition of Hilbert-Schmidt operators.




\begin{lm}\label{lb652}
Thm. \ref{lb651} is true when $X,Y$ are finite sets.
\end{lm}

\begin{proof}
The only nontrivial part is $\Vert T\Vert\leq \Vert K\Vert_{l^2}$. By Prop. \ref{lb624}, it suffices to prove for all $f\in \ovl B_{l^2(Y)}(0,1)$ and $g\in\ovl B_{l^2(X)}(0,1)$ that $|\bk{Tf|g}|\leq\Vert K\Vert_2$. But
\begin{align*}
|\bk{Tf|g}|=\Big|\sum_{x,y}K(x,y)f(y)\ovl{g(x)}\Big|=|\bk{K|\Gamma}|\leq \Vert K\Vert_2\cdot\Vert\Gamma\Vert_2
\end{align*}
where $\Gamma:X\times Y\rightarrow\Cbb$ is defined by $\Gamma(x,y)=\ovl{f(y)}g(x)$. Since
\begin{align*}
\Vert\Gamma\Vert_2^2=\sum_{x,y}|f(y)^2g(x)^2|=\sum_y|f(y)|^2\cdot \sum_x|g(x)|^2\leq 1
\end{align*}
we have $|\bk{Tf|g}|\leq\Vert K\Vert_2$.
\end{proof}







\begin{proof}[\textbf{Proof of Thm. \ref{lb651}}]
For each $\Omega\in\fin(2^{X\times Y})$, let $K_\Omega:X\times Y\rightarrow\Cbb$ be $K_\Omega=K\chi_\Omega$. Let $T_\Omega:l^2(Y)\rightarrow l^2(X)$ be the finite rank operator whose matrix representation is $K_\Omega$, namely, 
\begin{align}
T_\Omega\xi=\sum_{(x,y)\in\Omega} K(x,y)\xi(y)\cdot\chi_{\{x\}}
\end{align}
Since $K\in l^2(X\times Y)$, we know that $\lim_\Omega \Vert K-K_\Omega\Vert_2=0$, and hence $(K_\Omega)_{\Omega\in\fin(2^{X\times Y})}$ is a Cauchy net in $l^2(X\times Y)$. For each $\Omega,\Gamma\in\fin(2^{X\times Y})$, since $T_\Omega-T_\Gamma$ has matrix representation $K_\Omega-K_\Gamma$,  by Lem. \ref{lb652} we have
\begin{align*}
\Vert T_\Omega-T_\Gamma\Vert\leq \Vert K_\Omega-K_\Gamma\Vert_{l^2}
\end{align*}
Therefore $\lim_{\Omega,\Gamma}\Vert T_\Omega-T_\Gamma\Vert=0$, i.e., $(T_\Omega)$ is a Cauchy net in $\fk L(l^2(Y),l^2(X))$. By Thm. \ref{lb540}, $\fk L(l^2(Y),l^2(X))$ is complete. So $\lim_\Omega T_\Omega$ converges under the operator norm to some $T\in\fk L(l^2(Y),l^2(X))$.

Clearly $T$ has matrix representation $K$. Since each $T_\Omega$ has finite rank, by Thm. \ref{lb648}, $T$ is completely continuous. Finally, by Lem. \ref{lb652}, $\Vert T_\Omega\Vert\leq \Vert K_\Omega\Vert_2\leq \Vert K\Vert_2$ for all $\Omega$. Taking $\lim_\Omega$, we get $\Vert T\Vert\leq\Vert K\Vert_2$.
\end{proof}

\begin{rem}
In the above proof, we have used the completeness of $\fk L(l^2(Y),l^2(X))$, which relies on the completeness of $l^2(X)$. This seems contradictory to our earlier statement that Hilbert and Schmidt did not rely on the completeness of $l^2$ spaces to study integral equations. In fact, there is no contradiction since Hilbert took the sesquilinear form perspective: One can modify the above proof by showing that for every $R>0$, $\omega_{T_\Omega}$ converges uniformly on $\ovl B_{l^2(X)}(0,R)\times \ovl B_{l^2(X)}(0,R)$ to some function $\omega$. This gives the desired completely continuous sesquilinear form for $T$ without using the completeness of $l^2$ spaces.
\end{rem}



\subsection{Triumph of weak(-*) compactness: the Hilbert-Schmidt theorem}\label{lb849}


Fix a Hilbert space $\mc H$. For each $T\in\fk L(\mc H)$, let $\omega_T:\mc H\times\mc H\rightarrow\Cbb$ be $\omega_T(\xi|\eta)=\bk{T\xi|\eta}$ as usual. 

Recall from linear algebra that $\lambda\in\Cbb$ is called an \textbf{eigenvalue} \index{00@Eigenvalue} of $T$ if there is a nonzero $\xi\in\mc H$ such that $T\xi=\lambda\xi$. In this case, $\xi$ is called the \textbf{$\lambda$-eigenvector} \index{00@Eigenvector} of $T$.


\subsubsection{Self-adjoint operators and positive operators}


\begin{df}\label{lb1004}
Let $T\in\fk L(\mc H)$. We say that $T$ is \textbf{self-adjoint} \index{00@Self-adjoint operator} if one of the following conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item $T=T^*$.
%\item $\bk{T\xi|\eta}=\bk{\xi|T\eta}$ for all $\xi,\eta\in\mc H$.
\item $\omega_T$ is a Hermitian, i.e., $\omega_T(\xi|\eta)=\ovl{\omega_T(\eta|\xi)}$ for all $\xi,\eta\in\mc H$.
\item $\bk{T\xi|\xi}\in\Rbb$ for all $\xi\in\mc H$.
\end{enumerate}
\end{df}

%% Record #4 2024/03/07 three lectures  10

\begin{proof}[Proof of equivalence]
Recall that $\omega_{T^*}=(\omega_T)^*$ where the adjoint sesquilinear form $(\omega_T)^*$ is defined by \eqref{eq577}, and $\omega_T$ is Hermitian iff $\omega_T=(\omega_T)^*$. This proves (1)$\Leftrightarrow$(2). By Prop. \ref{lb588}, we have (2)$\Leftrightarrow$(3).
\end{proof}


\begin{rem}
Let $T\in\fk L(\mc H)$. Assume that $E\subset\mc H$ spans a dense subspace of $\mc H$. By sesquilinearity, and by the continuity of $\bk{\cdot|\cdot}$, $T$ is self-adjoint iff $\omega_T(\xi|\eta)=(\omega_T)^*(\xi|\eta)$ for all $\xi,\eta\in E$. Therefore:
\end{rem}

\begin{eg}\label{lb678}
Let $X$ be a set. Let $T\in\fk L(l^2(X))$. Let $K:X\times X\rightarrow\Cbb$ be the matrix representation of $T$, i.e., $K(x,y)=\bk{T\chi_{\{y\}}|\chi_{\{x\}}}$ for all $x,y\in Y$.  Then $T$ is self-ajoint iff $K(x,y)=\ovl{K(y,x)}$ for all $x,y\in Y$.
\end{eg}


\begin{proof}
This is because $\{\chi_{\{x\}}:x\in X\}$ spans a dense subspace, $K(x,y)=\omega_T(\chi_{\{x\}}|\chi_{\{y\}})$, and $\ovl{K(y,x)}=\ovl{\bk{T\chi_{\{y\}}|\chi_{\{x\}}}}=(\omega_T)^*(\chi_{\{x\}}|\chi_{\{y\}})$.
\end{proof}


\begin{df}
Let $T\in\fk L(\mc H)$. We say that $T$ is \textbf{positive} \index{00@Positive operator} and write $T\geq0$ if $\omega_T$ is positive (cf. Def. \ref{lb1026}), i.e., $\bk{T\xi|\xi}\geq0$ for all $\xi\in\mc H$. Positive operators are clearly self-adjoint. More generally, if $S,T\in\fk L(\mc H)$, we write
\begin{align}
S\leq T\qquad\Longleftrightarrow\qquad T-S\geq0
\end{align}
In other words, $S\leq T$ means $\bk{S\xi|\xi}\leq \bk{T\xi|\xi}$ for all $\xi\in\mc H$. Clearly ``$\leq$" is a partial order on $\fk L(\mc H)$.\footnote{Note that if $T\leq S$ and $S\leq T$, then $\omega_{T-S}(\xi|\xi)=0$ for all $\xi$. By the polarization identity \eqref{eq238}, we get $\omega_{T-S}=0$ and hence $T=S$.}
\end{df}

A bounded self-adjoint operator can be shifted to a bounded positive operator:



\begin{eg}\label{lb656}
Suppose that $T\in\fk L(\mc H)$ is self-adjoint, and $\lambda\geq\Vert T\Vert$. Then $\lambda+T$ and $\lambda-T$ are positive, i.e., $-\lambda\leq T\leq\lambda$.
\end{eg}

\begin{proof}
Since $\bk{T\xi|\xi}\leq\Vert T\Vert\cdot\Vert\xi\Vert^2\leq\lambda\bk{\xi|\xi}$, we get $T\leq\lambda$. Similarly, $-T\leq\lambda$.
\end{proof}




The following two basic facts will be used in the proof of the Hilbert-Schmidt theorem:

\begin{lm}\label{lb655}
Suppose that $T\in\fk L(\mc H)$ is positive. Assume that $\xi\in\mc H$ satisfies $\bk{T\xi|\xi}=0$. Then $T\xi=0$.
\end{lm}

\begin{proof}
Our assumption is $\omega_T(\xi|\xi)=0$. Since the sesquilinear form $\omega_T$ is positive, by Cauchy-Schwarz (cf. Rem. \ref{lb654}), for each $\eta\in\mc H$ we have $|\omega_T(\xi|\eta)|^2\leq \omega_T(\xi|\xi)\omega_T(\eta|\eta)=0$ and hence $\bk{T\xi|\eta}=0$. (Alternatively, one can use \eqref{eq240} to show $\omega_T(\xi|\eta)=0$.) Therefore $\Vert T\xi\Vert^2=\omega_T(\xi|T\xi)=0$.
\end{proof}


\begin{comment}
Lem. \ref{lb655} gives a simple criterion for eigenvalues of self-adjoint operators.

\begin{eg}
Suppose that $T\in\fk L(\mc H)$ is self-adjoint and $\lambda\geq\Vert T\Vert$. If $\xi\in\mc H$ satisfies $\bk{T\xi|\xi}=\lambda\bk{\xi|\xi}$, then $T\xi=\lambda\xi$. 
\end{eg}
\begin{proof}
Apply Lem. \ref{lb655} to $\lambda-T$, which is positive by Exp. \ref{lb656}.
\end{proof}
\end{comment}


\begin{df}
Let $T\in\fk L(\mc H)$. We say that a linear subspace $\mc K\subset\mc H$ is \textbf{invariant under $T$} \index{00@Invariant subspace} (or simply \textbf{$T$-invariant}) if $T\mc H\subset\mc H$.
\end{df}

\begin{pp}\label{lb658}
Let $T\in\fk L(\mc H)$. Let $\mc K$ be a linear subspace of $\mc H$. Suppose that $\mc K$ is invariant under $T$ and $T^*$. Then so is $\mc K^\perp$.
\end{pp}

In particular, if $T$ is self-adjoint and $\mc K$ is $T$-invariant, then $\mc K^\perp$ is $T$-invariant.

\begin{proof}
Let $\eta\in\mc K^\perp$. Then $\bk{T\eta|\mc K}=\bk{\eta|T^*\mc K}\subset \bk{\eta|\mc K}=0$ and $\bk{T^*\eta|\mc K}=\bk{\eta|T\mc K}\subset \bk{\eta|\mc K}=0$. So $T\eta,T^*\eta\in\mc K^\perp$.
\end{proof}


\begin{rem}
Prop. \ref{lb658} gives a simple method of decomposing the action of $T$: If $\mc K$ is invariant under $T,T^*$, then by Pb. \ref{lb659}, $T$ is unitarily equivalent to the ``block diagonal operator" $T|_{\mc K}\oplus T|_{\mc K^\perp}$.
\end{rem}







\subsubsection{The Hilbert-Schmidt theorem}


We first prove the Hilbert-Schmidt theorem for positive operators.


\begin{thm}[\textbf{Hilbert-Schmidt theorem}]\index{00@Hilbert-Schmidt theorem}\label{lb657}
Assume that $T\in\fk L(\mc H)$ is positive and completely continuous. Then $\mc H$ has an orthonormal basis $(e_1,e_2,\dots)\cup(f_j)_{j\in J}$, where the countable family $(e_1,e_2,\dots)$ is possibly finite, such that:
\begin{enumerate}[label=(\alph*)]
\item $Te_n=\lambda_ne_n$ for some $\lambda_n\in\Rbb$, and $Tf_j=0$.
\item $\lambda_1\geq \lambda_2\geq\cdots >0$.
\item If $(e_1,e_2,\dots)$ is infinite, then $\lim_n\lambda_n=0$.
\end{enumerate}  
\end{thm}

Before proving this theorem, we give an interpretation:
\begin{rem}\label{lb663}
In Thm. \ref{lb657}, write $(e_1,e_2,\dots)$ as $(e_i)_{i\in I}$ where $I=\Zbb_+$ or $I=\{1,2,\dots,N\}$ for some $N\in\Zbb_+$. Let $X=I\sqcup J$. Let $\Phi:l^2(X)\rightarrow \mc H$ be the unitary map sending each $\varphi$ to $\sum_{x\in X}\varphi(x)\chi_{\{x\}}$. Then we have a commutative diagram
\begin{equation}
\begin{tikzcd}[column sep=large]
l^2(X)\arrow[r,"\wht T"] \arrow[d,"\simeq","\Phi"'] & l^2(X) \arrow[d,"\Phi","\simeq"'] \\
 \mc H \arrow[r,"T"]           &  \mc H          
\end{tikzcd}
\end{equation}
where $\wht T$ has matrix representation
\begin{align}
\diag(\lambda_1,\lambda_2,\dots,(0)_{j\in J})
\end{align} 
i.e., for each $i\in I,j\in J$, we have $\wht T\chi_{\{i\}}=\lambda_i\chi_{\{i\}}$ and $T\chi_{\{j\}}=0$. A similar description holds in Thm. \ref{lb662}.
\end{rem}

Thm. \ref{lb657} will be proved by finding $e_1,e_2,\dots$ inductively. $(f_j)_{j\in J}$ will be an arbitrary orthonormal basis of $\Ker(T)$. 


\begin{proof}[\textbf{Proof of Thm. \ref{lb657}}]
We make our first simplification by noting that (b) can be weakened to
\begin{enumerate}
\item[(b')]  $\lambda_1\geq\lambda_2\geq\cdots\geq0$.
\end{enumerate}
Then, by moving those of $e_1,e_2,\dots$ with $0$-eigenvalue to the list $(f_j)_{j,\in J}$, the theorem is proved. Moreover, we assume for simplicity that $\mc H$ is infinite dimensional; the finite dimensional case will follow from a similar but easier proof. \\[-1ex]

Step 1. We first explain how to find $\lambda_1,e_1$. Let $\Omega=\ovl B_{\mc H}(0,1)$. Since $T$ is completely continuous, the function $g:\Omega\rightarrow\Rbb_{\geq0}$ defined by $g(\xi)=\omega_T(\xi|\xi)=\bk{T\xi|\xi}$ is weakly continuous. By Cor. \ref{lb636}, $\Omega$ is weakly compact. Therefore, by the extreme value theorem (Lem. \ref{lb224}), $g$ attains its maximum $\lambda_1=g(e_1)\geq0$ at some $e_1\in\Omega$. Since $g$ attains its minimum at $0$, it suffices to assume $e_1\neq0$. Since $g(e_1/\Vert e_1\Vert)=\Vert e_1\Vert^{-2}g(e_1)\geq g(e_1)$, by replacing $e_1$ by $e_1/\Vert e_1\Vert$, we assume $\Vert e_1\Vert=1$. 

Since $\bk{T\xi|\xi}\leq\lambda_1$ for any unit vector $\xi\in\mc H$, by (sesqui)linearity, we get
\begin{align}
\bk{T\xi|\xi}\leq\lambda_1\bk{\xi|\xi}\qquad\text{ for all }\xi\in\mc H
\end{align}
This proves $0\leq T\leq\lambda_1$.

Since $\bk{(\lambda_1-T)e_1|e_1}=0$ and $\lambda_1-T\geq0$, by Lem. \ref{lb655}, we get $(\lambda_1-T)e_1=0$. This finishes the construction of $\lambda_1$ and $e_1$.\\[-1ex]

Step 2. Suppose that we have found $\lambda_1\geq\cdots\geq\lambda_n\geq0$ and orthonormal $e_1,\dots,e_n$ such that $Te_i=\lambda_ie_i$ for all $1\leq i\leq n$, and that
\begin{align}\label{eq279}
\bk{T\xi|\xi}\leq\lambda_n\bk{\xi|\xi}\qquad\text{ for all }\xi\in V_n^\perp
\end{align}
Here, $V_n=\Span\{e_1,\dots,e_n\}$, which is a finite-dimensional Hilbert subspace of $\mc H$. 

Clearly $V_n$ is $T$-invariant. Therefore, by Prop. \ref{lb658}, $V_n^\perp$ is $T$-invariant. (Here we have used $T=T^*$.) Clearly $T|_{V_n^\perp}\geq0$. By the process in Step 1, there exists a unit vector $e_{n+1}\in V_n^\perp$ such that $Te_{n+1}=\lambda_{n+1}e_{n+1}$ for some $\lambda_{n+1}\in\ovl\Rbb_{\geq0}$, and $\bk{T\xi|\xi}\leq\lambda_{n+1}\bk{\xi|\xi}$ for all $\xi\in V_n^\perp$. Since \eqref{eq279} holds for $\xi=e_{n+1}$, we have $0\leq\lambda_{n+1}\leq\lambda_n$.\\[-1ex]

Step 3. By the inductive process in Step 2, we obtain an (infinite) orthonormal sequence $(e_n)_{n\in\Zbb_+}$ satisfying that $Te_n=\lambda_ne_n$, that $\lambda_1\geq\lambda_2\geq\cdots\geq0$, and that \eqref{eq279} holds for each $n$. We claim that $\lim_n\lambda_n=0$. Suppose this is true. Let $\mc K=\ovl{\Span\{e_1,e_2,\dots\}}$. By \eqref{eq279}, for any vector $\xi\in\mc K^\perp$ we have $\bk{T\xi|\xi}=0$, and hence $T\xi=0$ by Lem. \ref{lb655}. \footnote{Since $\mc K^\perp$ is $T$-invariant, one can also use the polarization identity \eqref{eq238} (applied to $T|_{\mc K^\perp}:\mc K^\perp\rightarrow\mc K^\perp$) instead of Lem. \ref{lb655} to conclude $T\xi=0$.} So $T|_{\mc K^\perp}=0$. Thus, the proof is finished by choosing $(f_j)$ to be an orthonormal basis of $\mc K^\perp$: By Thm. \ref{lb617}, an orthonormal basis of $\mc H$ can be obtained by taking the union of one of $\mc K$ and one of $\mc K^\perp$.

Let us prove the claim. Let $\lambda=\lim_n\lambda_n=\inf_n\lambda_n$. So $\lambda=\lim_n\bk{Te_n|e_n}$. Since $\lim_n e_n$ converges weakly to $0$ (cf. Exp. \ref{lb661}), and since $T$ is completely continuous, we have $\lim_n\bk{Te_n|e_n}=\bk{T0|0}=0$. So $\lambda=0$.
\end{proof}



Thm. \ref{lb657} can be easily generalized to self-adjoint completely continuous operators by slightly weakening condition (b):



\begin{thm}[\textbf{Hilbert-Schmidt theorem}]\index{00@Hilbert-Schmidt theorem}\label{lb662}
Assume that $T\in\fk L(\mc H)$ is self-adjoint and completely continuous. Then $\mc H$ has an orthonormal basis $(e_1,e_2,\dots)\cup(f_j)_{j\in J}$, where the countable family $(e_1,e_2,\dots)$ is possibly finite, such that:
\begin{enumerate}[label=(\alph*)]
\item $Te_n=\lambda_ne_n$ for some $\lambda_n\in\Rbb$, and $Tf_j=0$.
\item $|\lambda_1|\geq |\lambda_2|\geq\cdots >0$.
\item If $(e_1,e_2,\dots)$ is infinite, then $\lim_n\lambda_n=0$.
%\item For each $\lambda\in\Rbb$, the set $\{n:\lambda_n=\lambda\}$ is finite.
\end{enumerate}  
\end{thm}

%Note that (d) is automatic in Thm. \ref{lb657}. However, in the case that the eigenvalues might have different signs, (d) is needed in order to avoid the cases such as $1,-1,1,-1/2,1,-1/3,\dots$. 


\begin{proof}
%Assume for simplicity that $\mc H$ is infinite dimensional. 
As in the proof of Thm. \ref{lb657}, (b) can be weakened to $|\lambda_1|\geq|\lambda_2|\geq\cdots \geq0$. One then produces orthonormal $e_1,e_1',e_2,e_2',\dots$ such that $Te_n=\mu_ne_n$ and $Te_k'=\mu_k' e_k'$ for each $n,k$, that $\mu_1\geq\mu_2\geq\cdots\geq0$ and $\mu_1'\leq\mu_2'\leq\cdots\leq0$, and that
\begin{gather*}
\bk{T\xi|\xi}\leq\mu_n\bk{\xi|\xi}\qquad\text{ if }\xi\perp\{e_1,\dots,e_n\}\\
\mu_k'\bk{\xi|\xi}\leq\bk{T\xi|\xi}\qquad\text{ if }\xi\perp\{e_1',\dots,e_k'\}
\end{gather*}
(To see this, one first finds $e_1$ as in the proof of Thm. \ref{lb657}. Restricting $-T$ to $\{e_1\}^\perp$, one finds $e_1'$. Restricting $T$ to $\{e_1,e_1'\}^\perp$, one finds $e_2$. Restricting $-T$ to $\{e_1,e_1',e_2\}^\perp$, one finds $e_2'$. Repeat this procedure.)
\end{proof}


\begin{rem}
The converse of Thm. \ref{lb662} is also true: If $T\in\fk L(\mc H)$ has an orthonormal basis $(e_1,e_2,\dots)\cup(f_j:j\in J)$ satisfying the description in Thm. \ref{lb662}, then $T$ is self-adjoint and completely continuous. In fact, by Rem. \ref{lb663}, it suffices to prove:
\end{rem}

\begin{exe}\label{lb664}
Let $I=\Zbb_+$ or $\{1,\dots,N\}$. Let $J$ be a set. Let $X=I\sqcup J$. Choose $(\lambda_i)_{i\in I}$ in $\Cbb\setminus\{0\}$ satisfying $\lim_i\lambda_i=0$ if $I=\Zbb_+$. Prove that there is a (necessarily unique) completely continuous $T\in\fk L(l^2(X))$ satisfying $T\chi_{\{i\}}=\lambda_i\chi_{\{i\}}$ for all $i\in I$, and $T\chi_{\{j\}}=0$ for all $j\in J$. Prove that $T=T^*$ iff $\lambda_i\in\Rbb$ for all $i\in I$.
\end{exe}

\begin{proof}[Hint]
Define $T$ to be the limit (under the operator norm) of a sequence of finite-rank operators. Then the complete continuity follows from Thm. \ref{lb648}.
\end{proof}


\begin{rem}
Not all completely continuous operators are Hilbert-Schmidt: According to Exe. \ref{lb664}, we have a completely continuous operator on $l^2(\Zbb_+)$ whose matrix representation is $\diag(1,1/{\sqrt2},1/{\sqrt 3},\dots)$. It is not Hilbert-Schmidt, because $\sum_n n^{-1}=+\infty$.
\end{rem}



\begin{co}[\textbf{Fredholm alternative}]\index{00@Fredholm alternative}\label{lb670}
Let $T\in\fk L(\mc H)$ be self-adjoint and completely continuous. Let $\lambda\in\Rbb\setminus\{0\}$. Then one of the following two, and only one of them, is true:
\begin{enumerate}
\item[(1)] $\lambda$ is an eigenvalue of $T$, i.e., $T\xi=\lambda\xi$ for some nonzero $\xi\in\mc H$.
\item[(2)] $\lambda-T$ is surjective. 
\end{enumerate}
\end{co}
In other words, $\lambda-T$ is surjective iff $\lambda$ is not an eigenvalue.

\begin{proof}
Assume for simplicity that $\mc H$ is infinite dimensional. By Hilbert-Schmidt Thm. \ref{lb662}, we may assume that $\mc H=l^2(X)$ where $X=\Zbb_+\sqcup J$ and $J$ is a set. We assume that there is a sequence $(\lambda_n)_{n\in\Zbb_+}$ in $\Rbb$ such that $|\lambda_n|$ decreases to $0$, and that $T$ has matrix representation $\diag(\lambda_1,\lambda_2,\dots,(0)_{j\in J})$.

If $\lambda=\lambda_n$ for some $n$, then clearly $\chi_{\{n\}}$ is not in the range of $\lambda-T$. So $\lambda-T$ is not surjective. Conversely, suppose that $\lambda\neq\lambda_n$ for all $n$. For each $\eta\in l^2(X)$, let $\xi:X\rightarrow\Rbb$ be defined by $\xi(n)=(\lambda-\lambda_n)^{-1}\eta(n)$ if $n\in\Zbb_+$, and $\xi(j)=\lambda^{-1}\eta(j)$ if $j\in J$. Then clearly $\xi\in l^2(X)$, and $(\lambda-T)\xi=\eta$.
\end{proof}










\subsection{Concluding remarks}

\subsubsection{On the proof of the Hilbert-Schmidt theorem}

The proof of the Hilbert-Schmidt theorem in the last section, despite written in the modern language, is very close to the proof in Hilbert's 1906 paper, the fourth part of his work \cite{Hil12}. (Hilbert's proof is located in p.148-150 of \cite{Hil12}.)


%The weak compactness of $\ovl B_{\mc H}(0,1)$ is the most crucial analytic property\footnote{Here, by ``analytic property" I mean any property about inner product spaces that is equivalent to completeness, such as those described in Thm. \ref{lb612}.} used in the proof of the Hilbert-Schmidt theorem. 

In the proof of the Hilbert-Schmidt Thm. \ref{lb657}, we have used weak compactness of $\ovl B_{\mc H}(0,1)$  to find the unit vector $e_1$ maximizing the function $g(\xi)=\bk{T\xi|\xi}$ defined on $\ovl B_{\mc H}(0,1)$. This method is heavily influenced by the method of variation, and is compatible with Hilbert's sesquilinear form viewpoint (rather than Riesz's operator viewpoint). The subsequent vectors $e_2,e_3,\dots$ are constructed in the same way by restricting $T$ to orthogonal complements of finite dimensional subspaces. Hilbert used exactly the same method in his work! \uwave{The weak compactness of $\ovl B_{l^2(\Zbb)}(0,1)$ is the most important reason that Hilbert spaces were introduced in history.}

%(By the way, Hilbert also treated positive forms first.)

%In Step 3 of the proof of the Hilbert-Schmidt Thm. \ref{lb657} we have used Thm. \ref{lb617} to show that the orthonormal vectors $e_1,e_2,\dots$ and $(f_j)_{j\in J}$ span a dense subspace of $\mc H$ (and hence form an orthonormal basis of $\mc H$). Thm. \ref{lb617} relies on the key property 1 in Sec. \ref{lb640}, a property equivalent to the completeness of inner product spaces. Hilbert did not use this property in his proof. He did not need the vectors $(f_j)_{j\in J}$ since his ``Hilbert-Schmidt" theorem is stated in the following form (cf. \cite[Satz 35]{Hil12}): There exist orthonormal vectors $e_1,e_2,\dots$ and $\lambda_1\geq\lambda_2\geq\cdots\geq0$ satisfying $\lim_n\lambda_n=0$ and
%\begin{align}
%\omega_T(\xi|\xi)=\sum_n \lambda_n \bk{\xi|e_n}\bk{e_n|\xi}
%\end{align}
%for all vectors $\xi$. That each $e_n$ is a $\lambda_n$-eigenvector of $T$ is a mere consequence of this formula.






%The key property 1, the convergence of summing orthogonal vectors, is used to ensure the existence of the orthogonal decompositions (cf. the proof of Thm. \ref{lb617}). In the proof of Thm. \ref{lb657}, this property is used (and only used) to show that $e_1,e_2,\dots$ and an orthonormal basis $(f_j)_{j\in J}$ of $\mc K^\perp=\{e_1,e_2,\dots\}^\perp$ form an orthonormal basis of $\mc H$. (Let us quickly recall the key point: It is obvious that $e_1,e_2,\dots$ and $(f_j)$ form an orthonormal family. To show that they are densely-spanning, for each $\xi\in\mc H$, one sets $\eta=\sum_n \bk{\xi|e_n}e_n$, which converges by key property 1. Then $\xi-\eta\in\mc K^\perp$. Apply Thm. \ref{lb595} to $\xi-\eta$. Then we have $\xi=\eta+\sum_j\bk{\xi-\eta|f_j}f_j$. So $\xi$ is approximated by linear combinations of $e_1,e_2,\dots$ and $(f_j)$.) 

%By the way, when $\mc H$ is separable (which is the main interesting case), the existence of an orthonormal basis $(f_j)$ does not rely on any analytic property, but follows directly from Gram-Schmidt: see Exp. \ref{lb613}. Even if one does not assume that $\mc H$ is separable, the existence of $(f_j)$ also follows from key property 1 (cf. the proof of (2)$\Rightarrow$(3) of Thm. \ref{lb612}).



\subsubsection{On the applicability of the Hilbert-Schmidt theorem}\label{lb920}


The Hilbert-Schmidt theorem lies at the heart of modern partial differential equations. As mentioned in Subsec. \ref{lb667}, the inverse of $-\Delta$ (with boundary condition $u|_{\partial\Omega}=0$) is a completely continuous \textit{positive} operator on $L^2(\ovl\Omega)$. Therefore, by the Hilbert-Schmidt theorem, the unbounded operator $-\Delta$ have eigenvalues $0<\lambda_1\leq \lambda_2\leq\cdots$ converging to $+\infty$, and the eigenvectors (which can be proved to be ``good enough" such as $C^r$ or $C^\infty$) form an orthonormal basis of $L^2(\ovl\Omega)$. With the spectral analysis of $-\Delta$, the Dirichlet problem \eqref{eq271} can be understood very well.

However, this modern theory was also developed with the help of some other theories that were not yet available at the time of Hilbert-Schmidt, such as unbounded operators and Sobolev spaces.  As we have mentioned in Sec. \ref{lb668}, in the early days, the Dirichlet problem was studied in terms of their associated integral equations of functions on $\partial\Omega$. However, the Hilbert-Schmidt theorem has very limited application to these integral equations. Let me explain this in the following. 


We have mentioned that the operator $T$ in the integral equation \eqref{eq282}, after discretization by taking Fourier series, gives a bounded linear operator $\wht T$ on $l^2(\Zbb)$ whose matrix representation $\wht K:\Zbb\times\Zbb\rightarrow\Cbb$ is $l^2$-finite, i.e. $\sum_{m,n}|\wht K(m,n)|^2<+\infty$. (See Sec. \ref{lb669}.) Therefore, $\wht T$ is a Hilbert-Schmidt operator, and hence is completely continuous by Thm. \ref{lb651}. Moreover, some elementary calculations show that $-1$ is not an eigenvalue of $T$, cf. \cite[Thm. 3.3.9]{Sim-O} or \cite[Sec. 81]{RN}. Therefore, if $T$ is self-adjoint, the  Fredholm alternative (Cor. \ref{lb670}) shows that for each $g\in L^2(\partial\Omega)$ there exists a (necessarily unique) $f\in L^2(\partial\Omega)$ satisfying \eqref{eq282}. More precisely, one finds the Fourier series $\wht f\in l^2(\Zbb)$ solving $\wht f+\wht T\wht f=\wht g$.


Unfortunately, in many cases $T$ is not self-adjoint (since the real-valued function $G$ in \eqref{eq277} does not satisfy $G(x,y)=G(y,x)$). Therefore, although the Hilbert-Schmidt theorem would later be proved to be an effective tool for studying the Dirichlet problem, at the time of its inception, its relevance to the Dirichlet problem was not significant. Hilbert restricted his study to self-adjoint operators (more precisely, Hermitian forms), perhaps in view of the many other uses of integral equations, such as the Sturm-Liouville problem. (See e.g. \cite[Sec. 3.2]{Sim-O}, \cite[Ch. 5]{Tes}, or \cite[Ch. 7]{CL} for a detailed discussion of the application of the Hilbert-Schmidt theorem to the integral equations in Sturm-Liouville problem.)


Assuming self-adjointness, the original problem about integral equation can be fully solved: Let $K\in C^r(\Sbb^1\times\Sbb^1)$ where $r\geq0$. Then we have a linear operator $T:C^r(\Sbb^1)\rightarrow C^r(\Sbb^1)$ defined by $(Tf)(x)=\frac 1{2\pi}\int_{-\pi}^\pi K(x,y)f(y)dy$. Assume that $K$ is \textbf{symmetric}, i.e. $K(x,y)=\ovl{K(y,x)}$. In the following Subsec. \ref{lb1027}, we prove the $C^r$-Fredholm alternative: If there is no non-zero $f\in C^r(\Sbb^1)$ satisfying $f+Tf=0$, then for each $g\in C^r(\Sbb^1)$ there exists $f\in C^r(\Sbb^1)$ such that $f+Tf=g$. 



\subsubsection{$\star\star$ Regularity of the solutions of integral equations}\label{lb1027}








Define $\wht K$ by \eqref{eq283}, which is an element of $l^2(\Zbb\times\Zbb)$. Equip $C^r(\Sbb^1)$ with the inner product $\bk{f|g}=\frac 1{2\pi}\int_{-\pi}^\pi fg^*$. Then we have a commutative diagram
\begin{equation}\label{eq286}
\begin{tikzcd}
C^r(\Sbb^1) \arrow[r,"\Psi"] \arrow[d,"T"'] & l^2(\Zbb) \arrow[d,"\wht T"] \\
C^r(\Sbb^1) \arrow[r,"\Psi"]           & l^2(\Zbb)          
\end{tikzcd} 
\end{equation}
where $\Psi$ is the map $f\mapsto \wht f$ (which is a linear isometry with dense range, cf. Cor. \ref{lb603}), and $\wht T$ is defined by \eqref{eq284}. Then $K(x,y)=\ovl{K(y,x)}$ implies that $\wht K(m,n)=\ovl{\wht K(n,m)}$, and hence that $\wht T$ is self-adjoint (cf. Exp. \ref{lb678}). Briefly speaking, \eqref{eq286} asserts $\wht{Tf}=\wht T\wht f$ where $f\in C^r(\Sbb^1)$.

It can be proved that
\begin{align}
\wht T\big(l^2(\Zbb)\big)\subset\Psi\big(C^r(\Sbb^1) \big)  \label{eq285}
\end{align}
To see this, choose $\varphi\in l^2(\Zbb)$, and let $f_n=\sum_{k=-n}^n \varphi(k)e_k$. It is not hard to check (using H\"older's inequality) that the linear map $T:C^r(\Sbb^1)\rightarrow C(\Sbb^1)$ is bounded if the source and the target are equipped respectively with the $L^2$-norm and the $l^\infty$-norm. Thus $\lim_n Tf_n$ converges uniformly on $\Sbb^1$ to some $g\in C(\Sbb^1)$. By a similar argument, one checks that $\lim_n (Tf_n)^{(k)}$ converges uniformly for all $k\leq r$. Thus, by Thm. \ref{lb336}, we see that $g\in C^r(\Sbb^1)$. Using Parseval's identity for continuous functions on $\Sbb^1\times\Sbb^1$, one checks that $\wht g=\wht T\varphi$, i.e., $\Psi(g)=\wht T\varphi$. This proves \eqref{eq285}.

We now show that if $\lambda\in\Cbb\setminus\{0\}$, a $\lambda$-eigenvector $\varphi$ of $\wht T$ corresponds to a $\lambda$-eigenvector $f\in C^r(\Sbb^1)$ of $T$ satisfying $\wht f=\varphi$. Proof: Let $\varphi\in l^2(\Zbb)$ and $\wht T\varphi=\lambda\varphi$. By \eqref{eq285}, there exists $f\in C^r(\Sbb^1)$ such that $\wht T\varphi=\lambda \wht f$. So $\wht f=\varphi$, and hence  $\wht {Tf}=\wht T\wht f=\wht T\varphi=\lambda\varphi=\lambda\wht f$, and hence $Tf=\lambda f$ (since $\Psi$ is injective). QED.

We now finish the proof. Suppose that there is no non-zero $f\in C^r(\Sbb^1)$ satisfying $f+Tf=0$. By the above paragraph, there is no non-zero $\varphi\in l^2(\Zbb)$ satisfying $\varphi+\wht T\varphi=0$. Choose any $g\in C^r(\Sbb^1)$.  By Fredholm alternative (Cor. \ref{lb670}), there exists $\varphi\in l^2(\Zbb)$ such that $\varphi+\wht T\varphi=\wht g$. By \eqref{eq285}, there is $f\in C^r(\Sbb^1)$ such that $\wht T\varphi=\wht{g-f}=\wht g-\wht f$. Thus $\wht f=\varphi$, and hence $\wht f+\wht{Tf}=\wht f+\wht T\wht f=\wht f+\wht T\varphi=\wht g$. So $f+Tf=g$.



\subsubsection{Toward measure theory}


We have seen that the problem of finding an $C^r$-solution $f$ of an integral equation $f+Tf=g$ is solved by first finding its Fourier series $\wht f$, which is an element of $l^2(\Zbb)$ solving the equation $\wht f+\wht T\wht f=\wht g$. To solve the later equation, one uses only the fact that $\wht K\in l^2(\Zbb\times\Zbb)$, or more precisely, that $\wht K$ is the matrix representation of a completely continuous (self-adjoint) operator on $l^2(\Zbb)$. 

The lesson here is that even if we are ultimately interested in the Fourier series of functions in $C^r(\Sbb^1)$, i.e., the elements of $\Psi(C^r(\Sbb^1))$, at the outset, we must consider all possible elements of $l^2(\Zbb)$: If you remember, the proof of the Hilbert-Schmidt theorem uses the weak-compactness of the closed unit ball of $l^2(\Zbb)$. However, $\Psi(C(\Sbb^1))$ is a dense proper subspace of $l^2(\Zbb)$, and its closed unit ball is therefore not weakly compact (by Thm. \ref{lb636}).

This lesson naturally leads to the question: What is the function-theoretic meaning of an element $\varphi\in l^2(\Zbb)$ that is not necessarily the Fourier series of a continuous (or even Riemann-integrable) $2\pi$-periodic function? This question becomes even more crucial upon realizing that for $\lambda=0$, a $\lambda$-eigenvector of $\wht T$ (i.e., an element of $\Ker T$) may not be the Fourier series of a continuous function.


Lebesgue's integral theory was invented in 1902. And it was F. Riesz and Fischer who realized that Lebesgue integral gives a satisfying answer to the above question. They showed in 1907 (a year after Hilbert's seminal work \cite{Hil12} introducing the $l^2$-method to integral equations) that the linear isometry $\Psi:C(\Sbb^1)\rightarrow l^2(\Zbb)$ can be extended to a unitary map
\begin{align*}
\Psi:L^2(\Sbb^1)\rightarrow l^2(\Zbb)
\end{align*}
where $L^2(\Sbb^1)$ is the space of $2\pi$-periodic Lebesgue measurable complex functions $f$ satisfying $\int_{-\pi}^\pi |f|^2<+\infty$, and
\begin{align*}
(\Psi f)(n)=\wht f(n):=\frac 1{2\pi}\int_{-\pi}^\pi fe_{-n}
\end{align*}
where $e_n(x)=e^{\im nx}$, and the integral on the RHS is the Lebesgue integral. This result is called the \textbf{Riesz-Fischer theorem}; see Cor. \ref{lb879} for the rigorous statement.

With this result, the proof of \eqref{eq285} becomes more straightforward: Let $\varphi\in l^2(\Zbb)$. By Riesz-Fischer, $\varphi=\wht f$ for some $f\in L^2(\Sbb^1)$. Using the commutativity of limits and integrals (under certain assumptions) one sees that $g\in C^r(\Sbb^1)$ if $g$ is defined by the Lebesgue integral $g(x)=\frac 1{2\pi}\int_{-\pi}^\pi K(x,y)f(y)$. Parseval's identity implies $\wht g=\wht T\wht f$. 

It will be our task in the next few chapters to study Lebesgue integrals, the Riesz-Fischer theorem, and some of their generalizations.














\begin{comment}
The second issue is that even if $T$ is self-adjoint, and therefore the Hilbert-Schmidt theorem is available, the function-theoretic meaning of the solution $\wht f$ of $\wht f+\wht T\wht f=\wht g$ was not clear when Hilbert gave his proof using $l^2$-method (in 1906). More precisely, it was not clear why $\wht f$, a general element in $l^2(\Zbb)$, is indeed the Fourier coefficients of a ``function" $f$ on $\Sbb^1$, let alone a continuous function or a ``good enough function". I have already mentioned this problem in Sec. \ref{lb549}.

Luckily, soon after Hilbert's proof, in 1907, Riesz and Fischer proved a theorem saying that elements of $l^2(\Zbb)$ are exactly the Fourier series of functions in $L^2(\Sbb^1)$ (i.e., Lebesgue measurable functions $f$ satisfying $\int |f|^2<+\infty$). But we shouldn't take that luck for granted. Hilbert's research method of slightly deviating from the context of the original function-theoretic problems in exchange for a more algebraic way of understanding is very worthwhile. History has proved that Hilbert spaces are one of the greatest inventions in the early 20th century. The context that was temporarily ignored in Hilbert's $l^2$-theorey was able to be dealt with systematically at a later date.\footnote{Actually, Hilbert has given several different proofs of the diagonalization theorem for integral operators, many of which are more function-theoretic than the $l^2$-method. However, the $l^2$-method is the only one that is still widely used today.}

\end{comment}






\subsection{$\star$ Epilogue: Riesz's compact operators}\label{lb677}

Let $\mc H,\mc K$ be Hilbert spaces. Recall \eqref{eq280} for the meaning of $\omega_T$.

In the previous section, we have mentioned that many integral equations do not have self-adjoint integral operators. When a completely continuous operator $T$ on a $\mc H$ is not self-adjoint, the Hilbert-Schmidt theorem does not hold. However, one can still expect that the Fredholm alternative is true. In fact, in Fredholm's  1900 paper there was no ``self-adjointness". However, Fredholm's original approach is quite complicated: Assuming that the function $K(x,y)$ in the integral operator $T=\int_{-\pi}^\pi K(x,y)f(y)dy$ is continuous, Fredholm used Riemann sums to approximate the Riemann integral, studied the determinants of these summation operators, and then passed to the integral operator $T$ by taking limit. (See \cite[Sec. 5.1]{Die-H} for a brief discussion. See \cite[Ch. 24]{Lax} and \cite[Sec. 3.11]{Sim-O} for a detailed account of Fredholm's approach in a modern language.)



Fredholm clearly did not have the idea of Hilbert spaces and completely continuous operators. Now, to study completely continuous operators that are not necessarily self-adjoint, one needs to give an equivalent but different characterization of complete continuity. 

Hilbert's original definition of complete continuity (cf. Def. \ref{lb653}) is essentially about \textit{sesquilinear forms}, not about \textit{linear operators}. Recall that $T$ is completely continuous iff $\omega_T:\ovl B_{\mc H}(0,1)\times\ovl B_{\mc K}(0,1)\rightarrow\Cbb$ is weakly continuous. To describe this property in terms of the linear map $T$,  the weak continuity on the second variable $\ovl B_{\mc K}(0,1)$, which is a property about the source, should be raised to the target. This is achieved with the help of the following variant of Prop. \ref{lb635}.

\begin{lm}\label{lb673}
Let $(\xi_\alpha)_{\alpha\in I}$ be a net in $\ovl B_{\mc H}(0,1)$, and let $\xi\in\ovl B_{\mc H}(0,1)$. Then the following are equivalent.
\begin{enumerate}
\item[(1)] $\lim_\alpha\xi_\alpha=\xi$.
\item[(2)] $(\xi_\alpha)$ converges weakly to $\xi$. Moreover, for every net $(\eta_\beta)_{\beta\in J}$ in $\ovl B_{\mc H}(0,1)$ converging weakly to $\eta\in\ovl B_{\mc H}(0,1)$ we have
\begin{align}
\lim_{\alpha\in I,\beta\in J}\bk{\xi_\alpha|\eta_\beta}=\bk{\xi|\eta}
\end{align}
\end{enumerate}
\end{lm}

Similar to Prop. \ref{lb635}, this lemma is also true when $\mc H$ is only an inner product space, as you can see from the following proof.

\begin{proof}
Assume (1). Let $(\eta_\beta)$ converge weakly in $\ovl B_{\mc H}(0,1)$ to $\eta$. For each $\beta\in J$, define a continuous function $g_\beta:\mc H\rightarrow\Cbb$ by $g_\beta(\psi)=\bk{\psi|\eta_\beta}$. Then $g_\beta$ converges pointwise to $g:\psi\in \mc H\mapsto \bk{\psi|\eta}\in\Cbb$. Since $\sup_\beta\Vert\eta_\beta\Vert<+\infty$, $(g_\beta)_{\beta\in J}$ is equicontinuous. Therefore, by (3)$\Rightarrow$(1) of Thm. \ref{lb277} (and noting Prop. \ref{lb281}), we get $\lim_{\alpha,\beta} g_\beta(\xi_\alpha)=g(\xi)$. This proves (2).\footnote{It is not hard to prove (1)$\Rightarrow$(2) directly. We leave such a direct proof to the readers as an exercise.}

Assume (2). Then (1) follows directly from Prop. \ref{lb635} by choosing $J=I$ and $\eta_\alpha=\xi_\alpha$ for each $\alpha\in I$.
\end{proof}


\begin{pp}
Let $T\in\fk L(\mc H,\mc K)$. The following are equivalent.
\begin{enumerate}
\item[(1)] $T$ is completely continuous, i.e., $\omega_T$ is weakly continuous on $\ovl B_{\mc H}(0,1)\times\ovl B_{\mc K}(0,1)$.
\item[(2)] $T:\ovl B_{\mc H}(0,1)\rightarrow\mc K$ is continuous if $\ovl B_{\mc H}(0,1)$ is equipped with the weak topology, and if $\mc K$ is equipped with the norm topology. 
\end{enumerate}
\end{pp}

\begin{proof}
(2) means that if $(x_\alpha)$ is a net converging weakly in $\ovl B_{\mc H}(0,1)$ to $\xi$, then $T\xi_\alpha$ converges in norm to $T\xi$. By Lem. \ref{lb673} (applied to $\Vert T\Vert^{-1}T\xi_\alpha$), we see that $\lim_\alpha T\xi_\alpha=T\xi$ is equivalent to that $\lim_{\alpha,\beta}\bk{T\xi_\alpha|\eta_\beta}=\bk{T\xi|\eta}$ for every net $(\eta_\beta)_{\beta\in J}$ converging weakly in $\ovl B_{\mc K}(0,1)$ to $\eta$. This proves the equivalence.
\end{proof}


\begin{df}\label{lb674}
A linear map of normed vector spaces $T:V\rightarrow W$ is called \textbf{completely continuous} \index{00@Completely continuous} if $T$ is bounded, and if the restriction $T:\ovl B_V(0,1)\rightarrow W$ is continuous, where $\ovl B_V(0,1)$ is given the weak topology, and $W$ is given the norm topology.
\end{df}

Def. \ref{lb674} was introduced by F. Riesz in 1910 \cite{Rie10} for linear maps on $L^2$ spaces. However, this is not a good definition for $C[0,1]$ because, unlike $L^p$ and $l^p$ spaces (where $1<p<+\infty$), $C[0,1]$ is not reflexive and (hence) its closed unit ball is not \textbf{weakly compact} (cf. Thm. \ref{lb568}), i.e., it is not true that for every net $(f_\alpha)$ in $\ovl B_{C[0,1]}(0,1)$ there exist a subnet $(f_{\alpha_\mu})$ and some $f\in \ovl B_{C[0,1]}(0,1)$ such that $\lim_\mu\bk{f_{\alpha_\mu},\varphi}=\bk{f,\varphi}$ for all $\varphi\in C[0,1]^*$. \uwave{In order to study integral equations on non-necessarily reflexive function spaces} such as $C[0,1]$, in 1918, Riesz introduced the modern definition of compact operators (which he still called completely continuous operators). Let us recall the definition: 

\begin{df}\label{lb675}
Let $T:V\rightarrow W$ be a linear map of normed vector spaces. We say that $T$ is a \textbf{compact operator} \index{00@Compact operator} if $T(\ovl B_V(0,1))$ is precompact in $W$ (under the norm topology).
\end{df}

Note that if $T$ is compact, then $T$ is bounded. This is because every compact set in a metric space, in particular $\ovl{T(\ovl B_V(0,1))}$, is bounded.

\begin{thm}
Let $T:\mc H\rightarrow\mc K$ be linear. Then $T$ is completely continuous iff $T$ is compact.
\end{thm}

The following proof shows that this theorem is also true when $\mc H,\mc K$ are only normed vector spaces and $\ovl B_{\mc H}(0,1)$ is weakly compact. (By Thm. \ref{lb568}, the latter condition is equivalent to that $\mc H$ is reflexive.)


\begin{proof}
Suppose that $T$ is completely continuous. Since $\ovl B_{\mc H}(0,1)$ is weakly compact, and since the range of a compact set under a continuous map is compact, we conclude that $T(\ovl B_{\mc H}(0,1))$ is norm-compact, and hence norm-precompact.\footnote{Note that we have actually proved that $T(\ovl B_{\mc H}(0,1))$ is compact rather than just precompact. In fact, for Hilbert spaces, the precompactness of $T(\ovl B_{\mc H}(0,1))$ implies the compactness. However, for a general non-reflexive Banach space, it is too restrictive to assume compactness.}

Conversely, assume that $T$ is compact. Let $(\xi_\alpha)$ be a net in $\ovl B_{\mc H}(0,1)$ converging weakly to $\xi\in\ovl B_{\mc H}(0,1)$. Since $T$ is compact, $\Gamma=\ovl{T(\ovl B_{\mc H}(0,1))}$ is (norm-)compact. Therefore, to show that $\lim_\alpha T\xi_\alpha=T\xi$, by Pb. \ref{lb237}, it suffices to prove that every cluster point of $(T\xi_\alpha)$ is $T\xi$. This is clear, since every cluster point of $(T\xi_\alpha)$ is a weak cluster point, which must be $T\xi$ by Pb. \ref{lb676}.
\end{proof}



Def. \ref{lb675} is the correct definition which allowed Riesz to prove the Fredholm alternative for compact operators on Banach spaces (including integral operators on $C[0,1]$) in 1918. A discussion of this history, as well as the main ideas in Riesz's proof of Fredholm alternative, can be found in \cite[Sec. 7.1]{Die-H}. Riesz's theory on compact operators can be found in many textbooks on functional analysis, such as  \cite[Ch. 21]{Lax}, \cite[Ch. 4]{Rud-F}, \cite[Sec. 3.3]{Sim-O}.




%% Record #5 2024/03/11 two lectures  12





























\subsection{Problems and supplementary material}

Let $\mc H,\mc K$ be Hilbert spaces. Recall \eqref{eq280} for the meaning of $\omega_T$.

\begin{prob}\label{lb676}
Let $T\in\fk L(\mc H,\mc K)$. Prove that $T$ is continuous if both $\mc H$ and $\mc K$ are equipped with their weak topologies.
\end{prob}


\begin{comment}
\begin{sprob}
Let $T:l^2(Y)\rightarrow l^2(X)$ be completely continuous. For each $A\in\fin(2^X)$ and $B\in\fin(2^Y)$, let $T_{A,B}:l^2(Y)\rightarrow l^2(X)$ be defined by \eqref{eq281}, i.e., $T_{A,B}=\chi_A T\chi_B$. Let $\Omega=\ovl B_{l^2(Y)}(0,1)\times\ovl B_{l^2(Y)}(0,1)$, equipped with the product weak topology. Prove that $(\omega_{T_{A,B}})_{A\in\fin(2^X),B\in\fin(2^Y)}$ is an equicontinuous family of functions on $\Omega$.
\end{sprob}

\begin{proof}[Note]
Compare this with the fact that if $T\in\fk L(l^2(Y),l^2(X))$, then $(\omega_{T_{A,B}})_{A,B}$ is an equicontinuous family of functions on $\Omega$ where $\Omega$ is equipped with the product norm topology. (Compare Rem. \ref{lb666}.)
\end{proof}
\end{comment}



\begin{comment}
The following problem studies the one-variable analog of Thm. \ref{lb648}. (Its proof is much simpler than that of Thm. \ref{lb648}.)

\begin{sprob}
Let $\varphi:\mc H\rightarrow\Cbb$ be a linear map. Prove that the following are equivalent:
\begin{enumerate}
\item[(1)] $\varphi$ belongs to $\mc H^*=\fk L(\mc H,\Cbb)$.
\item[(2)] $\varphi$ is weakly continuous.
\item[(3)] $\varphi$ is weakly continuous when restricted to $\ovl B_{\mc H}(0,1)$.
\end{enumerate}
\end{sprob}
\end{comment}








\begin{sprob}\label{lb650}
Let $(e_i)$ and $(f_j)$ be orthonormal bases of $\mc H,\mc K$ respectively. Let $T\in\fk L(\mc H,\mc K)$. Define
\begin{align}
\Vert T\Vert_{\mathrm{HS}}=\Big(\sum_{i,j} |\bk{Te_i|f_j}|^2\Big)^{\frac 12}
\end{align}
which is in $[0,+\infty]$. Prove that $\Vert T\Vert_{\mathrm{HS}}$ is independent of the choice of bases. We say that $T$ is a \textbf{Hilbert-Schmidt operator} \index{00@Hilbert-Schmidt operator} if $\Vert T\Vert_{\mathrm{HS}}<+\infty$.
\end{sprob}

\begin{comment}
\begin{prob}\label{lb660}
Let $T\in\fk L(\mc H)$ be positive. Prove that $\Vert T\Vert\leq 1$ iff $0\leq T\leq 1$.
\end{prob}
\begin{proof}[Hint]
To prove ``$\Leftarrow$", apply Cauchy-Schwarz to $\omega_T$.
\end{proof}
\end{comment}

\begin{prob}
Let $(\lambda_n)_{n\in\Zbb_+}$ be a sequence in $\Cbb$ satisfying $\sup_{n\in\Zbb_+}|\lambda_n|<+\infty$.
\begin{enumerate}
\item Prove that there is a (necessarily unique) $T\in\fk L(l^2(\Zbb_+))$ whose matrix representation is $(\delta_{m,n}\lambda_n)_{m,n\in\Zbb_+}$, i.e., $\bk{T\chi_{\{m\}}|\chi_{\{n\}}}=\delta_{m,n}\lambda_n$. Prove that $\Vert T\Vert=\sup_{n\in\Zbb_+}|\lambda_n|$.
\item Prove that $T$ is completely continuous iff $\lim_{n\rightarrow\infty}\lambda_n=0$.
\end{enumerate}
\end{prob}



\begin{sprob}
Let $T\in\fk L(\mc H)$ satisfy $0\leq T\leq 1$. Prove that $T^2\leq T$.
\end{sprob}
\begin{proof}[Hint]
Use Cauchy-Schwarz to give an upper bound of $|\omega_T(\xi|T\xi)|$.
\end{proof}


\begin{sprob}\label{lb816}
Let $(e_n)_{n\in\Zbb_+}$ be an orthonormal sequence in $\mc H$. Let $T:\mc H\rightarrow\mc K$ be completely continuous. Prove that $\lim_{n\rightarrow\infty}Te_n=0$.
\end{sprob}

\begin{proof}[Hint]
By Pb. \ref{lb676}, $\lim_nTe_n$ converges weakly to $0$.
\end{proof}


\begin{sprob}\label{lb786}
Assume that $\mc H$ is infinite dimensional. Let $T\in\fk L(\mc H,\mc K)$. Assume that for each orthonormal sequence $(e_n)_{n\in\Zbb_+}$ in $\mc H$ we have $\lim_{n\rightarrow\infty}Te_n=0$. 
\begin{enumerate}
\item By mimicking the proof of the Hilbert-Schmidt Thm. \ref{lb657}, find a sequence of orthonormal vectors $(e_n)$ in $\mc H$ such that, by setting $V_0=\{0\}$ and $V_n=\Span\{e_1,\dots,e_n\}$ (where $n>0$), we have
\begin{gather*}
\Vert Te_{n+1}\Vert\geq \frac 12\Vert T|_{V_n^\perp}\Vert
\end{gather*}
for each $n\in\Nbb$, where $\Vert T|_{V_n^\perp}\Vert$ is the operator norm of $T|_{V_n^\perp}:V_n^\perp\rightarrow\mc K$.
\item Let $P_n\in\fk L(\mc H)$ be the projection operator onto $V_n$ (cf. Pb. \ref{lb815}). Prove that $\lim_n\Vert T-TP_n\Vert=0$. Conclude that $T$ is approximable.
\end{enumerate}
\end{sprob}

\begin{rem}\label{lb817}
Pb. \ref{lb816} and \ref{lb786} give an alternative proof that any completely continuous operator $T:\mc H\rightarrow\mc K$ is approximable.
\end{rem}




\newpage


\section{Measure spaces}\label{mc237}


\subsection{Introduction}\label{lb722}


Starting from this chapter, we will study Lebesgue integrals, and study measure theory in general. We will be able to define $\int_{\Rbb^N} f$ for a large class of functions $f:\Rbb^N\rightarrow\Rbb$ called \textbf{Lebesgue measurable functions}. It is worth noting that when Lebesgue introduced his integral theory in 1902, he was primarily concerned with bounded measurable functions on a compact interval $[a,b]\subset\Rbb$. For example, the dominated convergence theorem, one of the most important theorems in measure theory, was first proved by Lebesgue for bounded measurable functions on $[a,b]$. 

%Only by knowing what were the earliest primary examples in history, and only by knowing how the theory can be developed and applied to these crucial examples, can one comprehend the essence of the theory. Therefore, I will sometimes give a more straightforward proof of an important special case of a theorem after proving this theorem in full generality. %The ideas in these straightforward proofs are closer to the original proofs of the theorem in history. 


In the following, we sketch Lebesgue's main idea of the construction of integrals. A detailed account of the history can be found in \cite[Sec. 5.1]{Haw} and \cite[Sec. 9.6]{Jah}.



Let $-\infty<a<b<+\infty$, and let $f:(a,b)\rightarrow\Rbb$ be bounded, say $-M+1\leq f\leq M-1$ for some $M>1$.\footnote{Lebesgue originally considered functions on $[a,b]$. For the simplicity of the following discussion, we consider functions on $(a,b)$ instead, which makes no essential difference to the development of the theory.} We know the Riemann/Darboux integral is defined by partitioning the domain $(a,b)$. By contrast, the Lebesgue integral $\int_a^b fdm$ is defined by partitioning the codomain: Let $\{c_0<c_1<\dots<c_n\}$ be a partition of $[-M,M]$. Then we can define the  \textbf{upper Lebesgue sum} and the \textbf{lower Lebesgue sum} \index{00@Lebesgue sum}
\begin{align}\label{eq287}
\sum_{i=1}^n c_i\cdot m(E_i)\qquad \sum_{i=1}^n c_{i-1}\cdot m(E_i)
\end{align}
where $E_i=f^{-1}(c_{i-1},c_i]$, and $m(E_i)$ is the ``measure" of $E_i$. 
The \textbf{upper integral} $\ovl\int^b_a fdm$ (resp. the \textbf{lower integral} $\underline\int^b_a fdm$) is defined to be the infimum (resp. supremum) of the upper (resp. lower) Lebesgue sums over all partitions of $[-M,M]$. 

Since the difference of the two expressions of \eqref{eq287} is bounded by $(b-a)\cdot\sup_{i=1}^n (c_i-c_{i-1})$, one easily sees that $\ovl\int^b_a fdm$ equals $\underline\int^b_a fdm$. This common number is denoted by $\int_a^bfdm$ and called the \textbf{Lebesgue integral} of $f$.


To ensure that the integral is additive, i.e., $\int_a^b (f+g)dm=\int_a^b fdm+\int_a^b gdm$, we need $m$ to be additive, i.e., if $E,F\subset (a,b)$ are disjoint then $m(E\cup F)=m(E)+m(F)$. In fact, assuming the additivity of $m$, then similar to Pb. \ref{lb732} one can show that $\ovl\int^b_a$ is \textbf{subadditive} and $\udl\int^b_a$ is \textbf{superadditive}, i.e., $\ovl\int_a^b (f+g)dm\leq\ovl\int_a^b fdm+\ovl\int_a^b gdm$ and $\udl\int_a^b (f+g)dm\geq\udl\int_a^b fdm+\udl\int_a^b gdm$





%Therefore, in order to define the Lebesgue integral, one must first define the \textbf{Lebesgue measure} $m(E_i)$. Let me temporarily denote this value by $m^*(E_i)$ to reflect the fact (to be explained shortly) that not every subset of $(a,b)$ can be assigned a measure. The construction is as follows. 


Lebesgue defined the measure $m(E)$ for $E\subset (a,b)$ as follows. Suppose that $E\subset(a,b)$. Let me temporarily denote $m(E)$ by $m^*(E)$ to reflect the fact (to be explained shortly) that not every subset of $(a,b)$ can be assigned a measure. Then
\begin{align}\label{eq294}
m^*(E)=\inf\Big\{\sum_{n\in\Zbb_+}|I_n|:I_1,I_2,\dots\text{ are intervals covering }E  \Big\}
\end{align}
is called the \textbf{outer Lebsgue measure} of $E$. Clearly $m^*(E)\leq m^*(F)$ if $E\subset F$. %It is an easy exercise that if $I$ is a subinterval of $(a,b)$ with endpoints $c\leq d$, then $m^*(I)=|I|:=d-c$.





Unfortunately, for \textit{arbitrary} disjoint $E,F\subset(a,b)$ it is not necessarily true that $m^*(E\cup F)=m^*(E)+m^*(F)$; in general, we only have
\begin{align}\label{eq288}
m^*(E\cup F)\leq m^*(E)+m^*(F)
\end{align}
Thus, we must focus on a class $\fk M$ of subsets of $(a,b)$ satisfying certain nice properties. The elements in $\fk M$ will be called \textbf{Lebesgue measurable sets}. Then an equivalent definition of a \textbf{Lebesgue measurable function} $f$ is that $E_i=f^{-1}(c_{i-1},c_i]$ belongs to $\fk M$ for any partition $\{c_0<\cdots<c_n\}$ of $[-M,M]$.

The class $\fk M$ constructed by Lebesgue indeed satisfies a much stronger condition called \textbf{countable additivity}: If $E_1,E_2,\dots\in \fk M$ are mutually disjoint, then $\bigcup_n E_n\in\fk M$, and $m^*(\bigcup_n E_n)=\sum_nm^*(E_n)$. This property ensures that if the pointwise limit $f$ of a uniformly bounded sequence $(f_n)$ of measurable functions exists, then $f$ is also measurable. Moreover, thanks to the countable additivity, \uwave{the definition of the integral by partitioning codomains matches perfectly the idea of \textbf{convergence in measure}, which enables one to show that $\int_a^b fdm=\lim_n\int_a^bf_ndm$}. See Rem. \ref{mc240} for further discussion.


\begin{comment}


Let $-\infty<a<b<+\infty$, and let $m^*:2^{(a,b)}\rightarrow\Rbb_{\geq0}$ be defined by \eqref{eq294}. In this section, we sketch the construction of the set $\fk M$ of Lebesgue measurable sets in $(a,b)$. The restriction of $m^*$ to $\fk M$ will be denoted by $m$ and called the \textbf{Lebesgue measure}. There are many equivalent definitions of $\fk M$. Our definition will follow the original one of Lebesgue (cf. \cite[Sec. 5.1]{Haw} and \cite[Sec. 9.6]{Jah}): a measurable set is a set whose ``outer measure is equal to the inner measure". (This definition needs to be modified when applied to unbounded subsets of $\Rbb$ and $\Rbb^N$. We will discuss this in Sec. \ref{lb688} and \ref{lb726}.)

It is not required that the reader first read this section before reading Sec. \ref{lb688} and \ref{lb726} for a formal discussion of the construction of the Lebesgue measure on $\Rbb^N$. The readers may return to this section when they feel the need for motivations when reading future sections (especially Sec. \ref{lb726}). The construction of the Lebesgue measure is usually viewed as the most complicated and technical part of the whole Lebesgue theory. One of the purposes of this section is to give the readers a general idea of at least how much effort is required to build the most central part of Lebesgue's theory of integrals. 


\subsubsection{Basic properties of the outer Lebsgue measure $m^*$}\label{lb715}





\begin{pp}\label{lb686}
Let $E_1,E_2,\dots\subset (a,b)$. Then 
\begin{align}
m^*(\bigcup_n E_n)\leq\sum_n m^*(E_n)\label{eq293}
\end{align}
\end{pp}

\begin{proof}
Let $\eps>0$. For each $E_n$, let $I_{n,1},I_{n,2},\dots$ be intervals covering $E_n$ whose total length is $\leq m^*(E_m)+\eps/2^n$. Then $\bigcup_nE_n$ is covered by $\{I_{n,k}\}$ whose total length is $\leq \sum_n m^*(E_n)+\eps$. 
\end{proof}

In some simple cases, the inequality in \eqref{eq293} becomes equality:

\begin{exe}\label{lb682}
Let $I_1,I_2,\dots$ be disjoint subintervals of $(a,b)$. Prove
\begin{align}\label{eq289}
m^*(\bigcup_n I_n)=\sum_n |I_n|
\end{align}
\end{exe}
\begin{proof}[Hint]
``$\leq$" is obvious from the definition of $m^*$. To prove ``$\geq$", it suffices to prove $m^*(\bigcup_n I_n)\geq|I_1|+\cdots+|I_N|$ for each $N$. Shrink each $I_n$ to a slightly smaller compact interval $J_n$. Use the compactness of $J_n$ to prove $m^*(J_1\cup\cdots\cup J_N)\geq|J_1|+\cdots+|J_N|$.
\end{proof}


Since each open subset of $(a,b)$ is a countable union of disjoint intervals (cf. Pb. \ref{lb679}), by Exe. \ref{lb682}, for each $E\subset (a,b)$ we have
\begin{align}\label{eq291}
m^*(E)=\inf\big\{m^*(O):E\subset O\subset(a,b)\text{ and $O$ is open}  \big\}
\end{align}
This gives a more elegant description of $m^*$.









\begin{lm}\label{lb687}
Suppose that $K_1,K_2,\dots$ are disjoint compact subsets of $(a,b)$. Then $m^*(\bigcup_n K_n)=\sum_n m^*(K_n)$.
\end{lm}
\begin{proof}
By Prop. \ref{lb686}, it suffices to prove ``$\geq$". Thus, it suffices to prove $m^*(\bigcup_nK_n)\geq \sum_{n=1}^Nm^*(K_n)$ and apply $\lim_{N\rightarrow\infty}$. Therefore, it suffices to prove $m^*(\bigcup_{n=1}^N K_n)\geq  \sum_{n=1}^Nm^*(K_n)$. By induction, it suffices to assume $N=2$. So we take disjoint compact $K_1,K_2$, and we shall prove $m^*(K_1)+m^*(K_2)\leq m^*(K)$ where $K=K_1\cup K_2$.

By \eqref{eq291}, for each $\eps>0$, there is an open $O$ covering $K$ such that $m^*(O)\leq m^*(K)+\eps$. Since $d(K_1,K_2)>0$, one can easily find open disjoint subsets $O_1,O_2$ of $O$ covering $K_1,K_2$ respectively. By Exe. \ref{lb682} and the fact that $O_1,O_2$ are disjoint unions of intervals, we get $m^*(O_1\cup O_2)=m^*(O_1)+m^*(O_2)$. Therefore $m^*(K_1)+m^*(K_2)\leq m^*(O_1)+m^*(O_2)=m^*(O_1\cup O_2)\leq m^*(O)\leq m^*(K)-\eps$.
\end{proof}


\begin{lm}\label{lb684}
Let $K\subset (a,b)$ be compact. Then for each open $\Omega\subset(a,b)$ containing $K$ we have $m^*(\Omega)=m^*(K)+m^*(\Omega\setminus K)$.
\end{lm}
\begin{proof}
It suffices to prove ``$\geq$". $\Omega\setminus K$ is open, and hence is a disjoint union of intervals. Thus, by Exe. \ref{lb682}, $m^*(\Omega\setminus K)$ can be approximated by $m^*(I)$ where $I$ is a finite disjoint union of closed subintervals of $\Omega\setminus K$. In particular,
\begin{align}
m^*(\Omega\setminus K)=\sup\big\{m^*(L):L\text{ is a compact subset of }\Omega\setminus K   \big\}
\end{align}
By Lem. \ref{lb687}, for each compact $L\subset \Omega\setminus K$ we have $m^*(K)+m^*(L)=m^*(K\cup L)\leq m^*(\Omega)$. Taking $\sup_L$ finishes the proof.
\end{proof}



\subsubsection{Lebesgue measurable sets}

%To ensure that the integral operator $\int$ is linear, we must restrict it to the (so called) measurable functions on $(a,b)$. To describe measurable functions, we must first describe measurable sets. 

For each $E\subset (a,b)$, the \textbf{inner measure} $m_*(E)$ is defined to be
\begin{align}\label{eq290}
m_*(E)=\sup\big\{m^*(K):K\subset E\text{ and $K$ is compact}  \big\}
\end{align}
Clearly $m_*(E)\leq m^*(E)$. A set $E\subset (a,b)$ is called \textbf{Lebesgue measurable} if
\begin{align}
m^*(E)=m_*(E)
\end{align}
If $E$ is (Lebesgue) measurable, we call $m(E):=m^*(E)$ the \textbf{Lebesgue measure} of $E$. We let $\fk M$ denote the set of Lebesgue measurable subsets of $(a,b)$. 

\begin{rem}\label{lb685}
Let $E\subset(a,b)$. Then $E\in\fk M$ iff for every $\eps>0$ there exist an open $O\subset(a,b)$ containing $E$ and a compact $K$ inside $E$ such that $m^*(O\setminus K)<\eps$.
\end{rem}

\begin{proof}
We have $m_*(E)=m^*(E)$ iff (by \eqref{eq291} and \eqref{eq290}) for every $\eps>0$ there exist an open $O\subset(a,b)$ containing $E$ and a compact $K$ inside $E$ such that $m^*(O)-m^*(K)<\eps$. But $m^*(O)-m^*(K)=m^*(O\setminus K)$ by Lem. \ref{lb684}.
\end{proof}



\begin{eg}\label{lb680}
If $E$ is an open or compact subset of $(a,b)$, then $E\in\fk M$.
\end{eg}

\begin{proof}
This is obvious when $E$ is compact. When $E$ is open, this follows from Exe. \ref{lb682}.
\end{proof}

\begin{pp}\label{lb683}
For each $E\subset (a,b)$ we have
\begin{align}\label{eq292}
m_*(E)=b-a-m^*((a,b)\setminus E)
\end{align}
\end{pp}

In fact, \eqref{eq292} is Lebesgue's original definition of inner measure. As an immediate consequence of \eqref{eq292}, we see that $E\in\fk M$ iff $(a,b)\setminus E\in\fk M$.

\begin{proof}
Let $F=(a,b)\setminus E$. We want to prove $m_*(E)+m^*(F)=b-a$. Choose any compact $K\subset E$. Then $m^*(K)+m^*((a,b)\setminus E)\leq m^*(K)+m^*((a,b)\setminus K)$ where the RHS equals $b-a$ by Lem. \ref{lb684}. This proves $m_*(E)+m^*(F)\leq b-a$. 

To prove ``$\geq$", by \eqref{eq291}, it suffices to pick any open $O\subset (a,b)$ containing $F$ and prove $m_*(E)+m^*(O)\geq b-a$. Note that $K_0=(a,b)\setminus O$ is closed in $(a,b)$ but not necessarily compact. But we still have $m_*(K_0)+m^*(O)\geq b-a$ by Prop. \ref{lb686}. To get compact sets, for each $\eps>0$ we choose a compact interval $I\subset (a,b)$ such that $|I|>b-a-\eps$. Thus $m^*(K_0\setminus I)\leq m^*((a,b)\setminus I)<\eps$. Let $K=K_0\cap I$, which is a closed subset of $I$ and hence compact. Therefore, by Prop. \ref{lb686}, we have $m^*(K_0)<m^*(K)+\eps$, and hence $m^*(K)+\eps+m^*(O)\geq b-a$. This proves $m_*(E)+\eps+m^*(F)\geq b-a$ for all $\eps$.
\end{proof}




















\subsubsection{Measures and $\sigma$-algebras}\label{lb717}


\begin{thm}
$\fk M$ is a \textbf{$\sigma$-algebra}, which means that $\emptyset\in\fk M$, that $E\in\fk M$ iff its complement $(a,b)\setminus E$ is in $\fk M$, and that $\bigcup_n E_n\in \fk M$ if $E_1,E_2,\dots\in\fk M$.
\end{thm}


\begin{proof}
The only nontrivial property is that $\fk M$ is closed under taking countable union. We first prove that $\fk M$ is closed under taking finite unions. By induction, it suffices to take $E_1,E_2\in\fk M$ and show $E_1\cup E_2\in\fk M$. By Rem. \ref{lb685}, for each $\eps>0$, there exist compact $K_i\subset E_i$ and open $O_i\supset E_i$ such that $m^*(O_i\setminus K_i)<\eps$ (where $i=1,2$). Let $K=K_1\cup K_2$ and $O=O_1\cup O_2$. Then $O\setminus K\subset (O_1\setminus K_1)\cup (O_2\setminus K_2)$, and hence $m^*(O\setminus K)\leq m^*((O_1\setminus K_1)\cup (O_2\setminus K_2))$, which is $<2\eps$ by Lem. \ref{lb686}. This proves $E_1\cup E_2\in\fk M$.


Now let $E_1,E_2,\dots\in\fk M$. Let $F_1=E_1$ and $F_n=E_n\setminus\{E_1\cup\cdots\cup E_{n-1}\}$ so that $E=\bigcup_n E_n$ is the disjoint union $\bigsqcup_n F_n$. Since $\fk M$ is closed under taking complement and finite union, we conclude that $F_n\in\fk M$ for each $n\in\Zbb_+$. Choose any $\eps>0$. By Rem. \ref{lb685}, for each $n$, there exist compact $K_n\subset F_n$ and open $O_n\supset F_n$ such that $m^*(O_n\setminus K_n)<\eps/2^n$. Let $O=\bigcup_n O_n$ and $K=\bigcup K_n$. Then $O\setminus K\subset\bigcup_n O_n\setminus K_n$ and hence, by Prop. \ref{lb686}, $m^*(O\setminus K)\leq\sum_n m^*(O_n\setminus K_n)<\eps$.

Note that $K$ is not necessarily compact. However, by Lem. \ref{lb687}, there exists $N\in\Zbb_+$ such that the compact set $\wtd K:=K_1\sqcup\cdots\sqcup K_N$ satisfies $m^*(K)\leq m^*(\wtd K)+\eps$. By Lem. \ref{lb687}, we get $m^*(K\setminus \wtd K)\leq \eps$. Thus $m^*(O\setminus\wtd K)\leq m^*(O\setminus K)+m^*(K\setminus\wtd K)<2\eps$.
\end{proof}


\begin{thm}
$m^*$ is a \textbf{measure} on $\fk M$ and is denoted by $m$. Namely, it satisfies $m(\emptyset)=0$, and $m(\bigcup_n E_n)=\sum_n m(E_n)$ if $E_1,E_2,\dots\in \fk M$ are mutually disjoint.
\end{thm}

\begin{proof}
By Prop. \ref{lb686}, it suffices to prove $m(\bigcup_n E_n)\geq\sum_n m(E_n)$. Similar to the proof of Lem. \ref{lb687}, it suffices to prove $m(E_1)+m(E_2)\leq m(E_1\cup E_2)$ if $E_1,E_2\in\fk M$ are mutually disjoint. For each $\eps>0$, choose compact $K_i\subset E_i$ and open $O_i\supset E_i$ such that $m(O_i\setminus K_i)<\eps$. So $m(E_i\setminus K_i)<\eps$. By Prop. \ref{lb686}, we get $m(E_i)< m(K_i)+\eps$. Thus, by Lem. \ref{lb687}, we have
\begin{align*}
m(E_1\cup E_2)\geq m(K_1\cup K_2)=m(K_1)+m(K_2)>m(E_1)+m(E_2)-2\eps
\end{align*}
\end{proof}
\end{comment}







\subsection{Measurable spaces and measurable functions}


\begin{df}\label{lb689}
Let $X$ be a set. A subset $\fk M$ of $2^X$ is called a \textbf{$\sigma$-algebra} \index{00@$\sigma$-algebra} if it satisfies the following conditions:
\begin{itemize}
\item $\emptyset\in\fk M$.
\item If $E\in\fk M$ then $X\setminus E\in\fk M$.
\item If we have countably many elements $E_1,E_2,\dots\in\fk M$, then $\bigcup_n E_n\in\fk M$.
\end{itemize}
If $\fk M$ is a $\sigma$-algebra, we say that $(X,\fk M)$ is a \textbf{measurable space}. \index{00@Measurable space}
\end{df}
The second condition means that $\fk M$ is closed under complements. The third condition means that $\fk M$ is closed under \textit{countable} unions. Since $(\bigcup_n E_n)^c=\bigcap_n E_n^c$, we see that a $\sigma$-algebra is also closed under countable intersections. 

\begin{rem}
In Def. \ref{lb689}-(3) it suffices to assume that $\fk M$ is closed under countably \textit{infinite} unions. This is because any finite union could be enlarged to a countably infinite union by including $\emptyset$.
\end{rem}

\begin{exe}\label{lb690}
If $(\fk M_i)_{i\in I}$ is a family of $\sigma$-algebras on $X$, then $\bigcap_{i\in I}\fk M_i$ is a $\sigma$-algebra on $X$.
\end{exe}

\begin{df}
Let $\fk E\subset 2^X$. By Exe. \ref{lb690},
\begin{align}
\sigma(\fk E):=\bigcap_{\fk M\text{ is a $\sigma$-algebra containing $\fk E$}}\fk M 
\end{align}
is a $\sigma$-algebra on $X$. We call $\sigma(\fk E)$ the \textbf{$\sigma$-algebra generated by $\fk E$}. \index{00@$\sigma$-algebra generated by $\fk E$} \index{zz@$\sigma(\fk E)$} It is the smallest $\sigma$-algebra containing $\fk E$.
\end{df}

The most important $\sigma$-algebras in this course are Borel $\sigma$-algebras:

\begin{df}
Let $(X,\mc T_X)$ be a topological space. Recall that $\mc T_X$ is the set of open subsets of $X$. We let \index{BX@$\fk B_X$}
\begin{align}
\fk B_X:=\sigma(\mc T_X)
\end{align}
and call $\fk B_X$ the \textbf{Borel $\sigma$-algebra} \index{00@Borel $\sigma$-algebra} of $X$. Elements of $\fk B_X$ are called \textbf{Borel sets}. \index{00@Borel set}
\end{df}

\begin{eg}
Let $X$ be a topological space. Every closed subset of $X$ is Borel since it is the complement of an open set. $[a,b)$ is Borel set of $\Rbb$ since it equals $(-\infty,b)\cap[a,+\infty)$
\end{eg}


\begin{df}
Let $(X,\fk M)$ and $(Y,\fk N)$ be measurable sets. Let $f:X\rightarrow Y$ be a function. Then 
\begin{align}
f^{-1}(\fk N)=\{f^{-1}(E):E\in\fk N\}
\end{align}
is clearly a $\sigma$-algebra on $X$. We say that $f$ is \textbf{measurable} \index{00@Measurable function/map} if $f^{-1}(\fk N)\subset\fk M$, i.e., if $f^{-1}(E)\in\fk M$ for each $E\in\fk N$.
\end{df}

\begin{rem}\label{lb696}
If $f:X\rightarrow Y$ and $g:Y\rightarrow Z$ are measurable, then clearly $g\circ f:X\rightarrow Z$ is measurable.
\end{rem}


\begin{df}
Let $(X,\fk M)$ be a measurable space, and let $(Y,\mc T_Y)$ be a topological space. A map $f:X\rightarrow Y$ is called \textbf{measurable} if $f$ is measurable as a map $(X,\fk M)\rightarrow (Y,\fk B_Y)$, i.e., $f^{-1}(E)\in\fk M$ for each Borel set $E\subset Y$.
\end{df}

\begin{rem}
The most important measurable functions $X\rightarrow Y$, where $Y$ is a topological space, are those such that $Y=\Rbb,\ovl\Rbb_{\geq 0},\Cbb$. Note that $\Rbb,\Cbb$ are equipped with the Euclidean topologies, and $\ovl\Rbb_{\geq0}=[0,+\infty]$ is equipped with its standard topology (cf. Exp. \ref{lb691}), i.e., the unique topology such that any increasing bijection $\ovl\Rbb_{\geq0}\rightarrow[0,1]$ is a homeomorphism.
\end{rem}



\begin{df}
Let $f:X\rightarrow Y$ be a map of topological spaces. We say that $f$ is \textbf{Borel measurable} (or simply \textbf{Borel}) \index{00@Borel function/map} if $f$ is measurable as a map of measurable spaces $f:(X,\fk B_X)\rightarrow (Y,\fk B_Y)$.
\end{df}




Checking that a map $f$ is Borel using the original definition is difficult, since Borel sets of the codomain could be very complicated. In the following, we will see a very useful method of showing that a map is measurable.


\begin{pp}\label{lb692}
Let $(X,\fk M)$ and $(Y,\fk N)$ be measurable spaces where $\fk N=\sigma(\fk E)$ for some $\fk E\subset 2^Y$. Then the following are equivalent.
\begin{enumerate}
\item[(1)] $f$ is measurable, i.e., $f^{-1}(\sigma(\fk E))\subset\fk M$.
\item[(2)] $f^{-1}(\fk E)\subset\fk M$.
\end{enumerate}
\end{pp}

\begin{proof}
Clearly (1) implies (2). Assume (2). Then
\begin{align*}
\fk K=\{E\in 2^Y:f^{-1}(E)\in\fk M\}
\end{align*}
is a $\sigma$-algebra containing $\fk E$. So $\fk K$ contains $\sigma(\fk E)$. Thus, for each $E\in\sigma(\fk E)$ we have $E\in\fk K$, i.e., $f^{-1}(E)\in\fk M$. This proves (1).
\end{proof}




\begin{co}\label{lb695}
Let $f:X\rightarrow Y$ be a map of sets. Let $\fk E\subset 2^Y$. Then
\begin{align}
\sigma(f^{-1}(\fk E))=f^{-1}(\sigma(\fk E))
\end{align}
\end{co}


\begin{proof}
$f^{-1}(\sigma(\fk E))$ is a $\sigma$-algebra on $X$, and it contains $f^{-1}(\fk E)$. Therefore $f^{-1}(\sigma(\fk E))$ contain the smallest $\sigma$-algebra containing $f^{-1}(\fk E)$. This prove ``$\subset$". Since $f^{-1}(\fk E)$ is contained in $\fk M:=\sigma(f^{-1}(\fk E))$, by Prop. \ref{lb692}, $f^{-1}(\sigma(\fk E))$ is contained in $\fk M$. This proves ``$\supset$".
\end{proof}

\begin{co}\label{lb693}
Let $(X,\fk M)$ be a measurable space. Let $(Y,\mc T_Y)$ be a topological space. Let $f:X\rightarrow Y$ be a map. The following are equivalent:
\begin{enumerate}
\item[(1)] $f$ is measurable, i.e., $f^{-1}(\fk B_Y)\subset\fk M$.
\item[(2)] $f^{-1}(\mc T_Y)\subset \fk M$.
\item[(3)] $f^{-1}\{\text{closed subsets of $Y$}\}\subset \fk M$.
\end{enumerate}
\end{co}

\begin{proof}
This follows from Prop. \ref{lb692} and the fact that $\fk B_Y$ is generated by $\mc T_Y$ and also by the set of closed subsets of $Y$.
\end{proof}

\begin{eg}
Every continuous map of topological spaces is Borel.
\end{eg}

\begin{proof}
Immediate from Cor. \ref{lb693}.
\end{proof}

Checking $f^{-1}(\mc T_Y)\subset\fk M$ is still not very easy. To make further simplification we observe:

\begin{pp}\label{lb694}
Let $(Y,\mc T_Y)$ be a second countable topological space. Let $\mc U$ be a basis for the topology $\mc T_Y$. Then $\sigma(\mc U)=\fk B_Y$. Consequently, a function $f:(X,\fk M)\rightarrow Y$ is measurable iff $f^{-1}(\mc U)\subset \fk M$.
\end{pp} 



\begin{proof}
Since $\mc U\subset\mc T_Y$, we clearly have $\sigma(\mc U)\subset\fk B_Y$. If we can prove that $\sigma(\mc U)\supset\mc T_Y$, then $\sigma(\mc U)\supset\sigma(\mc T_Y)$, finishing the proof.

Choose any open set $O\subset Y$. Then for each $y\in O$ there is a neighborhood $U_y\in \mc U$ of $y$ contained inside $O$. Thus $O=\bigcup_{y\in O}U_y$. So $U$ is a union of elements of $\mc U$. Since $Y$ is second countable, the subset $O$ is also second countable and hence (by Cor. \ref{lb265}) Lindel\"of. Therefore, $O$ is a countable union of elements of $\mc U$. This proves $O\in\sigma(\mc U)$. 
\end{proof}



\begin{eg}\label{lb703}
Let $(X,\fk M)$ be a measurable space. Let $Y$ be a separable (equivalently, second countable) metric space. Then a map $f:X\rightarrow Y$ is measurable iff $f^{-1}(B_Y(y,r))\in\fk M$ for each $y\in Y,r>0$. This is because the open balls of $Y$ form a basis for the topology of $Y$.
\end{eg}


\begin{eg}\label{lb697}
We have
\begin{align*}
&\fk B_{\ovl\Rbb}=\sigma\{(a,+\infty]:a\in\ovl\Rbb\}=\sigma\{[a,+\infty]:a\in\ovl\Rbb\}\\
=&\sigma\{[-\infty,a):a\in\ovl\Rbb\}=\sigma\{[-\infty,a]:a\in\ovl\Rbb\}
\end{align*}
\end{eg}

Thus, for example, if $f:X\rightarrow\ovl\Rbb$ where $X$ is a measurable space, then $f$ is measurable iff $f^{-1}(a,+\infty]$ is measurable for all $a\in\ovl\Rbb$.

\begin{proof}
Let $\fk M=\sigma\{(a,+\infty]:a\in\ovl\Rbb\}$, which is clearly a subset of $\fk B_{\ovl \Rbb}$. Then $[a,+\infty]\in\fk M$ since $[a,+\infty]=\bigcap_{n\in\Zbb_+}(a-1/n,+\infty]$. Taking complements and intersections, we see $[-\infty,b)\in\fk M$ and $(a,b)\in\fk M$. Therefore, $\fk M$ contains a basis for $\mc T_{\ovl\Rbb}$, and hence contains $\fk B_{\ovl\Rbb}$. This prove the first relation. The other relations can be proved in the same way.
\end{proof}





\begin{rem}
Let $f:(X,\fk M)\rightarrow (Y,\mc T_Y)$. Suppose that $Z$ is a subspace of $Y$ containing $f(X)$. Equip $Z$ with the subspace topology $\mc T_Z$. Then $f:X\rightarrow Y$ is measurable iff $f:X\rightarrow Z$ is measurable. 
\end{rem}

\begin{proof}
$f:X\rightarrow Y$ is measurable iff $f^{-1}(U)$ is measurable for each $U\in\mc T_Y$. But $f^{-1}(U)$ equals $f^{-1}(U\cap Z)$, and the open subsets of $Z$ are precisely of the form $U\cap Z$.
\end{proof}


\begin{eg}
Let $(X,\fk M)$ be a measurable space. Let $A\subset X$. Then $\chi_A:X\rightarrow\Rbb$ is measurable iff $\chi_A:X\rightarrow\{0,1\}$ is measurable iff $\chi_A^{-1}(1)=A$ and $\chi_A^{-1}(0)=X\setminus A$ are measurable iff $A\in\fk M$.
\end{eg}



\begin{pp}\label{lb699}
Let $(X,\fk M)$ be a measurable space. Let $Y_1,Y_2$ be second countable topological spaces. Let $f_1:X\rightarrow Y_1$ and $f_2:X\rightarrow Y_2$ be functions. Then $f_1\vee f_2:X\rightarrow Y_1\times Y_2$ is measurable iff $f_1$ and $f_2$ are both measurable. 
\end{pp}

\begin{proof}
Let $f=f_1\vee f_2$. Let $\pi_i:Y_1\times Y_2\rightarrow Y_i$ be the projection. Then $f_i=\pi_i\circ f$. Thus, if $f$ is measurable, since $\pi_i$ is continuous and hence Borel measurable, we conclude that $f_i$ is measurable (cf. Rem. \ref{lb696}).

Conversely, assume that $f_1,f_2$ are measurable. If $V_1$ and $V_2$ are open subsets of $Y_1,Y_2$ respectively, then $f_i^{-1}(V_i)$ belongs to $\fk M$, and hence $f^{-1}(V_1\times V_2)=f_1^{-1}(V_1)\cap f_2^{-1}(V_2)$ belongs to $\fk M$. Since subsets of the form $V_1\times V_2$ form a basis for the topology of $Y_1\times Y_2$, by Prop. \ref{lb694}, $f$ is measurable.
\end{proof}


\begin{co}\label{lb745}
Let $(X,\fk M)$ be a measurable space. Let $f,g:X\rightarrow\Cbb$ or $f,g:X\rightarrow\ovl\Rbb_{\geq0}$ be measurable. Then $f+g$ and $fg$ are measurable functions from $X$ to $\Cbb$ or $\ovl\Rbb_{\geq0}$.
\end{co}

Recall Def. \ref{lb114} for the definition of additions and multiplications in $\ovl\Rbb_{\geq0}$.


\begin{proof}
The multiplication map $\Cbb\times\Cbb\rightarrow\Cbb$ is continuous, and the multiplication map $\ovl\Rbb_{\geq0}\times\ovl\Rbb_{\geq0}\rightarrow\ovl\Rbb_{\geq0}$ is lower semicontinuous and hence Borel measurable (cf. Exp. \ref{lb698}). By Prop. \ref{lb699}, $f\vee g$ is measurable. So its composition with the multiplication map (i.e., $fg$) is measurable. The same argument shows that $f+g$ is measurable.
\end{proof}



The pointwise limit of a sequence of Riemann integrable functions is not necessarily Riemann integrable.  However, the following theorem shows that the pointwise limit of a sequence of measurable functions is measurable. Thus, for example, the Dirichlet function, which is the limit of $f_n(x)=\chi_{A_n}$ where $A_n=\{a_1,\dots,a_n\}$ and $\Qbb\cap[0,1]=\{a_1,a_2,\dots\}$, is not Riemann integrable (cf. Exp. \ref{lb704}). But it is Borel measurable.

\begin{thm}\label{lb700}
Let $X$ be a measurable space. Let $(f_n)_{n\in\Zbb_+}$ be a sequence of measurable functions $X\rightarrow\ovl\Rbb$. Then $\sup_n f_n$, $\inf_n f_n$, $\limsup_n f_n$, and $\liminf_n f_n$ are measurable.  
\end{thm}

\begin{proof}
Let $F=\sup_n f_n$. Then for each $a\in\ovl\Rbb$, we have
\begin{align*}
F^{-1}[-\infty,a]=\bigcap_n f_n^{-1}[-\infty,a]
\end{align*}
where the RHS is measurable. Therefore, by Exp. \ref{lb697}, $\sup_n f_n$ is measurable. Similarly, $\inf_n f_n$ is measurable.

For each $n$, let $g_n:X\rightarrow\ovl\Rbb$ be defined by $g_n(x)=\sup_{k\geq n}f_k(x)$. The first paragraph shows that $g_n$ is measurable for each $n$, and hence $\limsup_nf_n=\inf_n g_n$ is measurable. Similarly, $\liminf_nf_n$ is measurable.
\end{proof}


\begin{co}\label{lb701}
Let $X$ be a measurable space. Let $Y$ be $\ovl\Rbb$ or $\Rbb^N$ or $\Cbb^N$. Let $(f_n)$ be a sequence of measurable functions $X\rightarrow Y$ converging pointwise to $f:X\rightarrow Y$. Then $f$ is measurable.
\end{co}
\begin{proof}
This is immediate from Thm. \ref{lb700} and Prop. \ref{lb699}.
\end{proof}

The pointwise limit of a \textit{net} of measurable functions is not necessarily measurable:

\begin{eg}
Let $(X,\fk M)$ be a measurable space such that $\fk M\neq 2^X$, and that $\fk M$ contains all finite subsets of $X$. (For example, let $X$ be an uncountable set, and let $\fk M$ be the set of all $E\subset X$ such that either $E$ or $X\setminus E$ is countable.) Let $E\in 2^X\setminus\fk M$. Then $(\chi_A)_{A\in\fin(2^E)}$ is a net of measurable functions $X\rightarrow \Rbb$. However, its pointwise limit $\chi_E$ is not measurable.
\end{eg}



\subsection{Measures and measure spaces}




\begin{df}
Let $(X,\fk M)$ be a measurable space. A function $\mu:\fk M\rightarrow[0,+\infty]$ is called a \textbf{measure} \index{00@Measure} if it satisfies the following conditions:
\begin{itemize}
\item $\mu(\emptyset)=0$.
\item (\textbf{Countable additivity}) \index{00@Countable additivity} If we have countably many $E_1,E_2,\dots\in\fk M$ that are pairwise disjoint, then $\mu\big(\bigcup_n E_n\big)=\sum_n\mu(E_n)$.
\end{itemize}
We call $(X,\fk M,\mu)$ (or simply call $(X,\mu)$) a \textbf{measure space}. \index{00@Measure space} If $X$ is a topological space and $\mu$ is defined on $\fk M=\fk B_X$, we call $\mu$ a \textbf{Borel measure}. \index{00@Borel measure} If $\mu(X)<+\infty$, we say that $\mu$ is a \textbf{finite measure}. \index{00@Finite measure}
\end{df}

\begin{eg}
Let $X$ be a nonempty set. Fix $p\in X$. Define $\delta_p:2^X\rightarrow[0,+\infty]$ by $\delta_p(E)=1$ if $p\in E$, and $\delta_p(E)=0$ if $p\notin E$. Then $\delta_p$ is a measure on $\fk M$, called the \textbf{Dirac measure}. \index{00@Diract measure} 
\end{eg}

\begin{eg}
Let $(X,\fk M)$ be a measurable space. Let $(\mu_i)_{i\in I}$ be a family of measures $\fk M\rightarrow[0,+\infty]$. Then the {sum} $\sum_i\mu_i$ \index{00@Summation of measures} (sending each $E\in\fk M$ to the unordered sum $\sum_{i\in I}\mu_i(E)$) is a measure on $\fk M$.
\end{eg}


\begin{proof}
Clearly $\sum_i\mu_i$ sends $\emptyset$ to $0$. That $\sum_i\mu_i$ satisfies the countable additivity follows from Fubini's theorem for unordered sums (Thm. \ref{lb137}).
\end{proof}

\begin{eg}\label{lb765}
Let $X$ be a set. For each $E\subset X$, let $\mu(E)=\sum_{x\in E}1$. Namely, $\mu(E)$ is the cardinality of $E$ when $E$ is a finite set, and $\mu(E)=+\infty$ when $E$ is not finite. Then $(X,2^X,\mu)$ is a measure space. $\mu$ is called the \textbf{counting measure}. \index{00@Counting measure} It is easy to see that $\mu=\sum_{x\in X}\delta_x$.
\end{eg}


\begin{pp}\label{lb748}
Let $(X,\fk M,\mu)$ be a measure space. The following are true.
\begin{enumerate}[label=(\alph*)]
\item (\textbf{Monotonicity}) If $E,F\in\fk M$ and $E\subset F$, then $\mu(E)\leq \mu(F)$.
\item If $(E_n)_{n\in\Zbb_+}$ is an increasing sequence of elements of $\fk M$, then $\mu\big(\bigcup_n E_n\big)=\lim_{n\rightarrow\infty}\mu(E_n)$.
\item If $(E_n)_{n\in\Zbb_+}$ is a decreasing sequence of elements of $\fk M$, and if there exists $A\in\fk M$ satisfying $\mu(A)<+\infty$ and containing $E_n$ for all $n$, then $\mu\big(\bigcap_n E_n\big)=\lim_{n\rightarrow\infty}\mu(E_n)$.
\item (\textbf{Countable subadditivity}) \index{00@Countable subadditivity} If $E_1,E_2,\dots\in\fk M$, then $\mu\big(\bigcup_n E_n\big)\leq\sum_n\mu(E_n)$
\end{enumerate}
\end{pp}


\begin{proof}
(a) $\mu(F)=\mu(E\sqcup(F\setminus E))=\mu(E)+\mu(F\setminus E)\geq\mu(E)$.

(b) Let $F_1=E_1$, and $F_n=E_n\setminus E_{n-1}$ if $n>1$. Then
\begin{align*}
&\mu\big(\bigcup_n E_n \big)=\mu\big(\bigsqcup_n F_n \big)=\sum_n\mu(F_n)=\lim_n \big(\mu(F_1)+\cdots+\mu(F_n) \big)\\
=&\lim_n\mu(F_1\cup\cdots\cup F_n)=\lim_n\mu(E_n)
\end{align*}

(c) Let $F_n=A\setminus E_n$. By (b) we have $\mu(\bigcup_n F_n)=\lim_n\mu(F_n)$, equivalently, $\mu(A)-\mu(\bigcap_n E_n)=\mu(A)-\lim_n \mu(E_n)$. This proves (c) because $\mu(A)<+\infty$.

(d) We have $\mu(E_1\cup E_2)=\mu(E_1)+\mu(E_2\setminus E_1)\leq \mu(E_1)+\mu(E_2)$. By induction, we get $\mu(E_1\cup\cdots\cup E_n)\leq \mu(E_1)+\cdots+\mu(E_n)$. Thus
\begin{align*}
\mu(E_1\cup\cdots\cup E_k)\leq\sum_n \mu(E_n)
\end{align*}
for each $k$. Apply $\lim_k$ to the LHS. Then (b) implies $\mu(\bigcup E_n)\leq\sum_n \mu(E_n)$.
\end{proof}


\begin{df}
Let $(X,\fk M,\mu)$ be a measure space. A subset $E\subset X$ is called a \textbf{$\mu$-null set} \index{00@Null set, $\mu$-null set} (or simply a \textbf{null set}) if $E\in\fk M$ and $\mu(E)=0$. If $P:X\rightarrow\{\text{true}, \text{false}\}$ is a property on $X$, we say that $P$ is true \textbf{$\mu$-almost everywhere} \index{00@Almost everywhere=a.e.} \index{00@a.e.}(or simply that $P$ is true \textbf{$\mu$-a.e.}) if $P$ is true outside a $\mu$-null set.
\end{df}

\begin{rem}\label{lb709}
By the countable subadditivity, a countable union of null sets is null.
\end{rem}

\begin{df}
A measure space $(X,\mu)$ is called \textbf{complete} \index{00@Complete measure space} if every subset of a null set is measurable (and hence is null by the monotonicity).
\end{df}

A main advantage of completeness is the following property:

\begin{pp}\label{lb1032}
Let $(X,\fk M,\mu)$ be a complete measure space. Let $(Y,\fk N)$ be a measurable space. If $f,g:X\rightarrow Y$ are equal a.e. (namely, there is a null set outside of which $f$ and $g$ are equal), and if $f$ is measurable, then $g$ is measurable.
\end{pp}

\begin{proof}
Let $X_0\in\fk M$ with null complement such that $f|_{X_0}=g|_{X_0}$. Then for each $E\in\fk N$, we have $f^{-1}(E)\cap X_0=g^{-1}(E)\cap X_0$. Since $g^{-1}(E)\setminus X_0$ is a subset of $X_0^c$, by the completeness, $g^{-1}(E)\setminus X_0$ is measurable. So $g^{-1}(E)$ is measurable.
\end{proof}

\begin{df}
Let $(X,\fk M,\mu)$ be a measure space. If $\nu$ is a measure on a $\sigma$-algebra $\fk N\subset 2^X$, we say that $(\fk N,\nu)$ is an \textbf{extension of $(\fk M,\mu)$} \index{00@Extension of measure} and write $(\fk M,\mu)\subset(\fk N,\nu)$, if $\fk M\subset \fk N$ and $\nu|_{\fk M}=\mu$. 
\end{df}

\begin{thm}\label{lb708}
Let $(X,\fk M,\mu)$ be a measure space. Then there is a (necessarily unique) smallest complete extension $(\ovl{\fk M},\ovl\mu)$ of $(\fk M,\mu)$. Moreover, the elements of $\ovl{\fk M}$ are precisely of the form $E\cup F$ where $E\in\fk M$ and $F$ is a subset of a $\mu$-null set in $\fk M$, and $\ovl\mu(E\cup F)=\mu(E)$. We call $(\ovl{\fk M},\ovl\mu)$ the \textbf{completion} of $(\fk M,\mu)$. \index{00@Completion of measure}
\end{thm}
The phrase ``smallest complete extension" means that $(\ovl{\fk M},\ovl\mu)$ is a complete measure on $X$ extending $(\fk M,\mu)$, and that every complete measure extending $(\fk M,\mu)$ also extends $(\ovl {\fk M},\ovl\mu)$. 

We clearly have an equivalent description of $\ovl{\fk M}$: A subset $G\subset X$ belongs to $\ovl{\fk M}$ iff there exist $A,B\in\fk M$ such that $A\subset G\subset B$ and $\mu(B\setminus A)=0$.

\begin{proof}
Define $\ovl{\fk M}$ to be the set of subsets of $X$ of the form $E\cup F$ where $E\in\fk M$ and $F$ is a subset of a $\mu$-null set (in $\fk M$), and let $\ovl\mu(E\cup F)=\mu(E)$. This is well-defined: Suppose that $E\cup F=E'\cup F'$ where $E,E'\in\fk M$, and $F,F'$ are subsets of null sets $A,A'$ respectively. Then $\mu(E)\leq \mu(E'\cup A')$. Since $A'\setminus E'$ is null, we have $\mu(E'\cup A')=\mu(E')$. So $\mu(E)\leq\mu(E')$. Similarly, $\mu(E')\leq\mu(E)$.

Given sets $E_1\cup F_1,E_2\cup F_2,\dots$ where $E_n\in \fk M$ and $F_n$ is inside a null set, then $\bigcup_n E_n\in\fk M$, and $\bigcup F_n$ is inside a null set (Rem. \ref{lb709}). So $\ovl{\fk M}$ is closed under countable unions. Let $E\in\fk M$ and $F$ be inside a null set $A$. Then $(E\cup F)^c=E^c\setminus F$ can be written as $E^c\setminus A$ union a subset of $A$. So $\ovl{\fk M}$ is closed under complements. This proves that $\ovl{\fk M}$ is a $\sigma$-algebra. Using the countable additivity of $\mu$, one checks easily that $\ovl\mu$ is a measure.

If $(\fk N,\nu)$ is a complete measure on $X$ extending $(\fk M,\mu)$, then for each $E\in\fk M$ and $F$ inside a null set in $\fk M$, we have $F\in\fk N$ by the completeness of $\nu$. So $E\cup F\in\fk N$. This proves $\ovl{\fk M}\subset\fk N$. Moreover, $\nu(E\cup F)=\nu(E)+\nu(F\setminus E)=\nu(E)$ since $F\setminus E$ is $\nu$-null. So $\nu(E\cup F)=\nu(E)=\mu(E)=\ovl\mu(E\cup F)$. This proves that $\nu$ extends $\ovl\mu$.
\end{proof}
















\subsection{The Lebesgue measure $m$ on $\Rbb^N$}\label{lb688}


Let $N\in\Zbb_+$. In this section, we construct the Lebesgue measure $m^N$ on $\Rbb^N$, which is the completion of a Borel measure. We write $m^N$ as $m$ when no confusion arises.




Recall Subsec. \ref{lb494} for the definition of the Lebesgue measure $m(U)$ of an open set $U\subset\Rbb^N$: It is the supremum of the multiple Riemann integral $\int_{\Rbb^N}f$ (cf. Def. \ref{lb487}) where $f$ ranges over all elements of $C_c(U,[0,1])=\{f\in C_c(U,\Rbb):f(X)\subset[0,1]\}$.  It clearly satisfies the monotonicity: If $U_1\subset U_2$ are open, then $m(U_1)\leq m(U_2)$.
\begin{df}
For each $E\subset\Rbb^N$, define the \textbf{outer Lebesgue measure} \index{00@Outer Lebesgue measure $m^*$} to be
\begin{subequations}
\begin{align}
m^*(E)=\inf\big\{m(U):U\text{ is an open set containing }E \big\}
\end{align}
Clearly $m^*(U)=m(U)$ when $U$ is open. Clearly $m^*(E)\leq m^*(F)$ if $E\subset F\subset\Rbb^N$. Define the \textbf{inner Lebesgue measure} \index{00@Inner Lebesgue measure $m_*$} to be
\begin{align}
m_*(E)=\sup\big\{m^*(K):K\text{ is a compact subset of }E\big\}
\end{align}
\end{subequations}
Clearly $m_*(E)\leq m^*(E)$. A set $E\subset \Rbb^N$ is called \textbf{$m$-regular} if $m^*(E)=m_*(E)$.
\end{df}

From the definition, it is clear that compact sets are regular.

When Lebesgue introduced his integral theory in 1902, he focused on the measures of \textit{bounded subsets} of $\Rbb$. He defined a bounded measurable set to be a bounded $m$-regular set. (Cf. \cite[Sec. 5.1]{Haw} and \cite[Sec. 9.6]{Jah}.) This definition should be modified for unbounded sets. At this moment, let use show that open sets are regular.

\begin{lm}\label{lb714}
Any open subset $U\subset\Rbb^N$ is $m$-regular.
\end{lm}

\begin{proof}
Let $U$ be open. Then $m_*(U)\leq m^*(U)=m(U)$. We want to show $m_*(U)\geq m(U)$. Since $m(U)=\sup\{\int f:f\in C_c(U,[0,1])\}$, it suffices to show for each $f\in C_c(U,[0,1])$ that $\int f\leq m_*(U)$. By the definition of $m_*(U)$, it suffices to find a compact $K\subset U$ such that $\int f\leq m^*(K)$.

Let $K=\Supp(f)$, which is a compact subset of $U$. Then $m^*(K)$ is the infimum of $m(V)$ where $V$ is open and contains $K$. So we shall prove that $\int f\leq m(V)$ for each open $V\subset\Rbb^N$ containing $K$. But this is obvious from the definition of $m(V)$.
\end{proof}

\begin{comment}
By Urysohn's lemma (Thm. \ref{lb711}), there exists $g\in C_c(V,[0,1])$ satisfying $g|_K=1$. Then $f\leq g$, and hence $\int f\leq \int g$ (because $g-f\geq0$ implies $\int(g-f)\geq0$). By the definition of $m(V)$, we have $\int g\leq m(V)$. This proves $\int f\leq m(V)$.

Note that the only property about $\int$ used in this proof is that $\int:C_c(\Rbb^N,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ is an $\Rbb_{\geq0}$-linear map. 
\end{comment}


\begin{thm}\label{lb800}
$m^*$ is a measure on $\fk B_{\Rbb^N}$. Its completion will be denoted by $(\fk M,m)$ and called the \textbf{Lebesgue measure} \index{00@Lebesgue measure} on $\Rbb^N$. Elements in $\fk M$ are called \textbf{Lebesgue measurable sets}. \index{00@Lebesgue measurable set} Moreover, for each bounded  set $E\in\fk M$ we have $m(E)<+\infty$.
\end{thm}

\begin{proof}
That $m^*$ is a measure on $\fk B_{\Rbb^N}$ is an easy consequence of Thm. \ref{lb724} (which can be applied to the current situation, cf. Exp. \ref{lb725}), to be proved in the next section. Suppose that $E\in\fk M$ is bounded. Then $E$ is contained in a bounded open box $U=(a_1,b_1)\times\cdots\times(a_N,b_N)$. For each $f\in C_c(\Rbb^N,[0,1])$, we have $\int f\leq (b_1-a_1)\cdots(b_N-a_N)<+\infty$. This proves $m(U)<+\infty$, and hence $m(E)<+\infty$.
\end{proof}

There exist bounded subsets of $\Rbb^N$ that are not Lebesgue measurable. See \cite[Thm. 2.22]{Rud-R}.

%% Record #6 2024/03/14 three lectures  15

\subsection{A general method for constructing measures}\label{lb726}


Let $(X,\mc T_X)$ be a Hausdorff topological space. Let $\mu:\mc T_X\rightarrow[0,+\infty]$ be a function. Throughout this section, we assume the following assumption.

\begin{ass}\label{lb712}
For each $E\subset X$, define the \textbf{outer measure} \index{00@Outer measure} $\mu^*(E)$ and the \textbf{inner measure} \index{00@Inner measure} $\mu_*(E)$ to be 
\begin{subequations}\label{eq292}
\begin{gather}
\mu^*(E)=\inf\big\{\mu(U):U\text{ is an open subset of $X$ containing }E \big\}\\
\mu_*(E)=\sup\big\{\mu^*(K):K\text{ is a compact subset of }E \big\}\label{eq292b}
\end{gather}
\end{subequations}
Then the following conditions are satisfied:
\begin{enumerate}[label=(\alph*)]
\item $\mu(\emptyset)=0$.
\item (Monotonicity) If $U\subset V\subset X$ and $U,V$ are open, then $\mu(U)\leq\mu(V)$.
\item (Countable subadditivity) For countably many open subsets $U_1,U_2,\dots$ of $X$ we have $\mu\big(\bigcup_n U_n\big)\leq\sum_n\mu(U_n)$.
\item (Additivity) If $U_1,U_2$ are disjoint open subsets of $X$, then $\mu(U_1\cup U_2)=\mu(U_1)+\mu(U_2)$.
\item (Regularity on open sets) If $U\subset X$ is open, then $\mu(U)=\mu_*(U)$.
\end{enumerate}
\end{ass}

If $\mu:\mc T_X\rightarrow[0,+\infty]$ only satisfies (a,b,c,d), then $\mu$ is called a \textbf{premeasure} \index{00@Premeasure} (cf. \cite[Sec. 17.5]{RF}). We will not use this definition.


\begin{exe}
The reason we assume only additivity but not countable additivity in (d) is because the latter is automatic. More precisely, assuming (a,b,c), then (d) is true iff for any countable pairwise disjoint open sets $U_1,U_2,\dots$ we have $\mu(\bigcup_n U_n)=\sum_n\mu(U_n)$. Prove this fact. (We will not need this fact in the future.)
\end{exe}

\begin{rem}
From the monotonicity of $\mu$ on $\mc T_X$, it is clear that $\mu(U)=\mu^*(U)$ if $U$ is open, and $\mu^*:2^X\rightarrow[0,+\infty]$ is monotone increasing. This shows $\mu_*(K)=\mu^*(K)$ if $K$ is compact, and $\mu_*:2^X\rightarrow[0,+\infty]$ is monotone increasing.
\end{rem}



\begin{df}\label{lb810}
We say that $E$ is \textbf{$\mu$-regular} if $\mu_*(E)=\mu^*(E)$. Note that compact sets and open sets are clearly $\mu$-regular. If $E$ is $\mu$-regular (e.g $E$ is open or compact), we write 
\begin{align*}
\mu(E)=\mu^*(E)=\mu_*(E)\qquad\text{if $E$ is $\mu$-regular}
\end{align*}
\end{df}

We abbreviate ``$\mu$-regular" to ``regular" when no confusion arises. (It has nothing to do with regular topological spaces (defined in Def. \ref{lb504}).)

\begin{eg}\label{lb725}
Let $X=\Rbb^N$ and $\mu=m$. Then $m$ satisfies Asmp. \ref{lb712}: (a) and (b) are obvious. (c) and (d) were discussed in Pb. \ref{lb713}. (A different proof will be given in the proof of Thm. \ref{lb796}.) (e) was proved in Lem. \ref{lb714}.
\end{eg}


Our goal is to show that $\mu^*$ is countably additive on $\fk B_X$. In measure theory, there is a common strategy of proving that the elements inside a $\sigma$-algebra satisfy a property $P$. Let $P:2^X\rightarrow\{\text{true},\text{false}\}$ be a property. Suppose that we can find $\fk E\subset 2^X$ such that every element in $\fk E$ satisfies $P$. Suppose that the set of all $E\subset X$ satisfying $P$ is a $\sigma$-algebra. Then $P$ is clearly true for every element of $\sigma(\fk E)$.

However, countable additivity is not a property about subsets of $X$, but a property about pairwise disjoint sequences of subsets of $X$. Nevertheless, one can show that $\mu$ is countably additive on a pairwise disjoint sequence of \textit{regular} subsets based on the following simple idea:
\begin{align}\label{eq290}
\tcboxmath{
\begin{array}{c}
\text{$\mu^*$ satisfies countable subadditivity}\\
\text{$\mu_*$ satisfies countable superadditivity}\\
\text{If $\mu^*=\mu_*$, then the countable additivity is true}
\end{array}
}
\end{align} 
Therefore, since open sets are regular, if we can show that the class of regular sets is a $\sigma$-algebra, then this class contains $\fk B_X$. Thus, our goal is accomplished. 

As we will see, if $\mu(X)<+\infty$, the class of regular sets is indeed a $\sigma$-algebra. However, when $\mu(X)=+\infty$, this statement is not true, so we must find an alternative to regular sets. 




\subsubsection{Countable subadditivity and countable superadditivity}



In this subsection, we prove that $\mu^*$ satisfies the countable subadditivity, and $\mu_*$ satisfies the countable superadditivity.

\begin{pp}\label{lb718}
$\mu^*:2^X\rightarrow[0,+\infty]$ satisfies the following conditions:
\begin{enumerate}[label=(\alph*)]
\item $\mu^*(\emptyset)=0$.
\item (Monotonicity) If $E\subset F\subset X$, then $\mu^*(E)\leq\mu^*(F)$.
\item (Countable subadditivity)\index{00@Countable subadditivity} For countably many subsets $E_1,E_2,\dots$ of $X$ we have $\mu^*\big(\bigcup_n E_n\big)\leq\sum_n\mu^*(E_n)$.
\end{enumerate}
\end{pp}



\begin{proof}
The first two conditions are obvious. Let us check the countable subadditivity. Let $E_1,E_2,\dots\subset X$. Assume WLOG that each $\mu^*(E_n)$ is finite; otherwise the countable subadditivity is obvious. Let $\eps>0$. By the definition of $\mu^*$, each $E_n$ is contained in an open set $U_n$ such that $\mu(U_n)\leq \mu^*(E_n)+\eps/2^n$. Then $E=\bigcup_n E_n$ is contained in $\bigcup_n U_n$. By the countable subadditivity for open sets, we have $\mu(\bigcup_n U_n)\leq \sum_n\mu(U_n)\leq\sum_n\mu^*(E_n)+\eps$. By the monotonicity, we have $\mu(E)\leq\sum_n\mu^*(E_n)+\eps$. This finishes the proof, since $\eps$ can be arbitrary. 
\end{proof}

%We want to show that $\mu^*$ is countably additive on measurable sets. Since measurable sets with finite measures are approximated by their compact subsets, the first step of proving countable additivity is to prove it for compact sets:





To establish the countable superadditivity for $\mu_*$, we first need to prove the additivity for compact sets:

\begin{lm}\label{lb716}
Suppose that $K_1,K_2$ are disjoint compact subsets of $X$. Then $\mu(K_1\cup K_2)=\mu(K_1)+\mu(K_2)$.
\end{lm}

\begin{proof}
By the (countable) subadditivity of $\mu^*$, it remains to prove $\mu^*(K_1\cup K_2)\geq\mu^*(K_1)+\mu^*(K_2)$. By the definition of $\mu^*$, it suffices to prove that for each open $U$ containing $K_1\cup K_2$ we have $\mu(U)\geq\mu^*(K_1)+\mu^*(K_2)$. By Prop. \ref{lb1000}, there exist disjoint open $U_1,U_2\subset U$ containing $K_1,K_2$ respectively. Then by condition (d) of Asmp. \ref{lb712}, we get $\mu(U)\geq\mu(U_1\cup U_2)=\mu(U_1)+\mu(U_2)\geq\mu^*(K_1)+\mu^*(K_2)$.
\end{proof}


%Condition (e) of Asmp. \ref{lb712} will be used (and only used) in the following way.



\begin{pp}\label{lb719}
$\mu_*:2^X\rightarrow[0,+\infty]$ satisfies $\mu_*(E)\leq\mu^*(E)$ for all $E\subset X$. Moreover, the following are true.
\begin{enumerate}[label=(\alph*)]
\item $\mu_*(\emptyset)=0$.
\item (Monotonicity) If $E\subset F\subset X$, then $\mu_*(E)\leq\mu_*(F)$.
\item (\textbf{Countable superadditivity})\index{00@Countable superadditivity} For countably many \uwave{disjoint} subsets $E_1,E_2,\dots$ of $X$ we have $\mu_*\big(\bigcup_n E_n\big)\geq\sum_n\mu_*(E_n)$.
\end{enumerate}
\end{pp}

\begin{proof}
The monotonicity of $\mu^*$ implies $\mu_*(E)\leq\mu^*(E)$. (a) and (b) are obvious. To prove (c), it suffices to prove $\mu_*\big(\bigcup_k E_k\big)\geq\mu_*(E_1)+\cdots+\mu_*(E_n)$ for all $n$, and hence to prove $\mu_*(E_1\cup\cdots\cup E_n)\geq\mu_*(E_1)+\cdots+\mu_*(E_n)$. By induction on $n$, it suffices to prove $\mu_*(E_1\cup E_2)\geq\mu_*(E_1)+\mu_*(E_2)$. By the definition of $\mu_*$, it suffices to prove that for every compact $K_1\subset E_1$ and $K_2\subset E_2$ we have $\mu_*(E_1\cup E_2)\geq\mu(K_1)+\mu(K_2)$. By Lem. \ref{lb716}, it suffices to prove $\mu_*(E_1\cup E_2)\geq\mu(K_1\cup K_2)$. But this is obvious from the definition of $\mu_*$.
\end{proof}


\subsubsection{Criteria for $\mu$-regularity}\label{lb735}

We now use the idea \eqref{eq290} to derive many criteria for $\mu$-regularity. %In fact, the results in this subsection will imply that if $F\subset X$ satisfies $\mu^*(F)<+\infty$, then the set of $\mu$-regular subsets of $F$ is closed under countable unions and relative complements. (Such set is called a \textbf{$\sigma$-ring}.)

\begin{co}\label{lb727}
Let $E_1,E_2,\dots$ be pairwise disjoint $\mu$-regular subsets of $X$. Then $\bigcup_n E_n$ is $\mu$-regular, and 
\begin{align}\label{eq296}
\mu\Big(\bigcup_n E_n\Big)=\sum_n\mu(E_n)
\end{align}
\end{co}

\begin{proof}
Let $E=\bigcup_n E_n$. Then $\mu_*(E)\leq\mu^*(E)$. Since $\mu_*(E_n)=\mu^*(E_n)$, by Prop. \ref{lb718} and \ref{lb719} we have
\begin{align*}
\mu^*(E)\leq\sum_n\mu^*(E_n)=\sum_n\mu_*(E_n)\leq\mu_*(E)
\end{align*}
This proves that $\mu_*(E)=\mu^*(E)$, and that \eqref{eq296} is true.
\end{proof}







\begin{co}\label{lb731}
Let $E\subset X$ satisfy $\mu^*(E)<+\infty$. Then $E$ is $\mu$-regular iff for every $\eps>0$ there exist a compact set $K$ and an open set $U$ such that $K\subset E\subset U$ and $\mu(U\setminus K)<\eps$.
\end{co}



\begin{proof}
Since $\mu^*(E)<+\infty$, we know that $\mu^*(E)=\mu_*(E)$ iff one can find open $U\subset E$ (satisfying $\mu(U)<+\infty$) and compact $K\subset E$ such that $\mu(U)-\mu(K)$ is small.  Since $U,U\setminus K$ are open and $K$ is compact, they are $\mu$-regular. Therefore, by Cor. \ref{lb727}, we have $\mu(U)-\mu(K)=\mu(U\setminus K)$. So $\mu(U)-\mu(K)$ being small means $\mu(U\setminus K)$ being small.
\end{proof}

The following lemma is a special case of the main Thm. \ref{lb724}. But it can now be proved easily using Cor. \ref{lb731}.

\begin{lm}\label{lb730}
Let $E_1,E_2$ be $\mu$-regular subsets of $X$ satisfying $\mu(E_1)<+\infty$ and $\mu(E_2)<+\infty$. Then $E_1\cup E_2,E_1\cap E_2,E_2\setminus E_1$ are $\mu$-regular.
\end{lm}

\begin{proof}
It suffices to prove that $E_2\setminus E_1$ is regular. Then, similarly, $E_1\cap E_2=E_2\setminus(E_2\setminus E_1)$ is regular. By Cor. \ref{lb727}, $E_1\cup E_2=E_1\sqcup (E_2\setminus E_1)$ is regular. (Note that all the sets involved have finite $\mu^*$-values.)

Choose any $\eps>0$. By Cor. \ref{lb731}, there exist compact $K_i\subset E_i$ and open $U_i\supset E_i$ such that $\mu(U_i\setminus K_i)<\eps/2$. Then $U_2\setminus K_1$ is open and contains $E_2\setminus E_1$, and $K_2\setminus U_1$ is compact and is contained in $E_2\setminus E_1$. Moreover,
\begin{align}
(U_2\setminus K_1)\setminus (K_2\setminus U_1)\subset (U_2\setminus K_2)\cup (U_1\setminus K_1)
\end{align}
since $(U_2\setminus K_1)\setminus (K_2\setminus U_1)=U_2\cap K_1^c\cap (K_2\cap U_1^c)^c=(U_2\cap K_1^c\cap K_2^c)\cup (U_2\cap K_1^c\cap U_1)\subset (U_2\setminus K_2)\cup (U_1\setminus K_1)$. (See also Fig. \ref{lb721}.) By the subadditivity of $\mu^*$, we have $\mu^*((U_2\setminus K_1)\setminus (K_2\setminus U_1))\leq \mu(U_2\setminus K_2)+\mu(U_1\setminus K_1)<\eps$. Therefore, by Cor. \ref{lb731}, $E_2\setminus E_1$ is $\mu$-regular.
\end{proof}


\begin{figure}[h]
	\centering
\begin{equation*}
\vcenter{\hbox{{
			\includegraphics[height=3cm]{fig9.png}}}}\qquad\qquad
\vcenter{\hbox{{
			\includegraphics[height=3cm]{fig10.png}}}}
\end{equation*}
	\caption{. The shaded areas are $(U_2\setminus K_1)\setminus (K_2\setminus U_1)$ and $(U_2\setminus K_2)\cup (U_1\setminus K_1)$ respectively.}\label{lb721}
\end{figure}






\subsubsection{Locally $\mu$-regular sets}\label{lb736}


When $\mu(X)<+\infty$, the results in Subsec. \ref{lb735} imply easily that the set of $\mu$-regular sets form a $\sigma$-algebra $\fk M_\mu$ containing all open sets (and hence containing $\fk B_X$), and that $\mu$ is a measure on $\fk M_\mu$. However, when $\mu(X)=+\infty$,  $\mu$-regular sets are not good enough. One easily checks that if $\mu$ is finite on compact sets (e.g., $\mu$ is the Lebesgue measure), Cor.  \ref{lb731} fails for regular sets with infinite $\mu$-values. Therefore, one cannot prove that the $\mu$-regular sets form a $\sigma$-algebra. In fact, there is an example where  $\mu^*(E)=+\infty$ and $\mu_*(E)=0$ for some $E\in\fk B_X$. (See Rem. \ref{lb842}.) To overcome this difficulty, we consider the better notion of local $\mu$-regularity:
\begin{df}
Let $E\subset X$. We say that $E$ is \textbf{locally $\mu$-regular} \index{00@Locally $\mu$-regular} if $\mu^*(E\cap\Omega)=\mu_*(E\cap\Omega)$ for every open set $\Omega\subset X$ satisfying $\mu(\Omega)<+\infty$.
\end{df}

%We shall discuss the relationship between regular sets and locally regular sets. First, we need a lemma:



The following proposition shows that when $\mu(X)<+\infty$, the $\mu$-regularity and the local $\mu$-regularity are equivalent.

\begin{pp}\label{lb723}
Assume that $E\subset X$ satisfies $\mu^*(E)<+\infty$. Then $E$ is $\mu$-regular iff $E$ is locally $\mu$-regular. 
\end{pp}




\begin{proof}
Assume that $E$ is locally regular. Since $\mu^*(E)<+\infty$, there exists an open $\Omega\supset E$ such that $\mu(\Omega)<+\infty$. So $E\cap\Omega$ is regular. Hence $E$ is regular. Conversely, assume that $E$ is regular. Let $\Omega\subset X$ be an open set satisfying $\mu(\Omega)<\infty$. Since $\Omega$ is $\mu$-regular, by Lem. \ref{lb730}, $E\cap\Omega$ is regular. So $E$ is locally regular.
\end{proof}
























\subsubsection{The main theorem}

\begin{thm}\label{lb724}
Let $\mu:\mc T_X\rightarrow[0,+\infty]$ satisfy Asmp. \ref{lb712}. Let $\fk M_\mu$ be the set of locally $\mu$-regular subsets of $X$. Then $\fk M_\mu$ is a $\sigma$-algebra containing $\fk B_X$, and $\mu^*$ is a complete measure on $\fk M_\mu$. We denote the measure $(\fk M_\mu,\mu^*)$ by $(\fk M_\mu,\mu)$.
\end{thm}



%We divide the proof into two steps. In the first step, we prove that $\fk M_\mu$ is a $\sigma$-algebra. In the second step, we prove that $\fk M_\mu$ contains $\fk B_X$, and that $(\fk M_\mu,\mu)$ is complete.

According to the definition of $(\fk M_\mu,\mu)$ in Thm. \ref{lb724}, if $E\in\fk M_\mu$ then $\mu^*(E)=\mu(E)$ (even though $\mu^*(E)$ and $\mu_*(E)$ are not necessarily equal when $\mu^*(E)=+\infty$). The restriction $(\fk B_X,\mu)$ will be called a \textbf{Radon measure} if $X$ is LCH and $\mu$ is finite on compact sets. We will discuss Radon measures in detail in Ch. \ref{lb805}.

\begin{proof}
Step 1. We show that $\fk M_\mu$ is a $\sigma$-algebra. Clearly $\emptyset\in\fk M_\mu$.  Let $\Omega\in\mc T_X$ such that $\mu(\Omega)<+\infty$. We want to show that if $E\cap\Omega$ is regular then $E^c\cap\Omega$ is also regular. We want to show that if $E_1,E_2,\dots\subset 2^X$ are such that $E_1\cap\Omega,E_2\cap\Omega,\dots$ are regular, then $(\bigcup_n E_n)\cap\Omega$ is regular. By replacing $E$ with $E\cap\Omega$ and $E_n$ with $E_n\cap\Omega$, it suffices to prove:
\begin{enumerate}
\item[(a)] If $E\subset\Omega$ is regular, then $\Omega\setminus E$ is regular.
\item[(b)] If $E_1,E_2,\dots$ are regular subsets of $\Omega$, then $\bigcup_n E_n$ is regular. 
\end{enumerate}
By Lem. \ref{lb730}, (a) is true (since open sets are regular). Let $E_1,E_2,\dots\subset\Omega$ be regular. Let $F_1=E_1$ and $F_n=E_n\setminus(E_1\cup\cdots\cup E_{n-1})$ if $n>1$. Then each $F_n$ is regular by Lem. \ref{lb730}. Therefore, by Cor. \ref{lb727}, $\bigcup E_n=\bigsqcup_n F_n$ is regular.\\[-1ex]

Step 2. By Asmp. \ref{lb712}-(e), every open set is regular. Thus every open set is also locally regular. Therefore, $\fk M_\mu$ contains $\mc T_X$, and hence contains $\fk B_X=\sigma(\mc T_X)$.

Clearly $\mu^*(\emptyset)=0$. To show that $\mu^*$ is a measure on $\fk M_\mu$, we take mutually disjoint $E_1,E_2,\dots\in\fk M_\mu$, and we shall show that $\mu^*(E)=\sum_n\mu^*(E_n)$ where $E=\bigcup_n E_n$. If $\mu^*(E)=+\infty$, by the countable subadditivity, we have $+\infty=\mu^*(E)\leq\sum_n\mu^*(E_n)$, and hence $\mu^*(E)=\sum_n\mu^*(E_n)$. So it suffices to assume $\mu^*(E)<+\infty$. Therefore $\mu^*(E_n)<+\infty$ for each $n$. By Prop. \ref{lb723}, $E_n$ is regular. Therefore $\mu^*(E)=\sum_n\mu^*(E_n)$ by Cor. \ref{lb727}.

Finally, we need to prove that $\mu^*$ is complete on $\fk M_\mu$. Let $E\in\fk M_\mu$ such that $\mu^*(E)=0$. Let $F\subset E$. Then $\mu^*(F)\leq\mu^*(E)=0$ and hence $\mu^*(F)=0$. So $\mu_*(F)=\mu^*(F)=0$. Therefore $F$ is regular and has finite $\mu^*$-value. So $F\in\fk M_\mu$ by Prop. \ref{lb723}.
\end{proof}

\begin{exe}
Why do we define $\mu$ on $\fk M_\mu$ to be the restriction of $\mu^*$ but not $\mu_*$?
\end{exe}


%% Record #7 2024/03/18 two lectures  17

\subsubsection{A relationship between $\fk M_\mu$ and the completion of $\fk B_X$}\label{lb869}





By Thm. \ref{lb708}, $(\fk M_\mu,\mu)$ extends the completion of $(\fk B_X,\mu)$. Very often, we only care about the completion of $(\fk B_X,\mu)$ but not about the larger set $\fk M_\mu$. However, the following proposition shows that in many cases (e.g. when $X=\Rbb^N$ and $\mu=m$), $(\fk M_\mu,\mu)$ is equal to the completion.


\begin{df}\label{lb1031}
Let $(Y,\fk N,\nu)$ be a measure space. We say that $\nu$ is \pmb{$\sigma$-}\textbf{finite} \index{00@$\sigma$-finite} on $E$ if $E$ is a countable union of measurable subsets with finite $\nu$-measures. We say that $\nu$ is a \pmb{$\sigma$-}\textbf{finite measure} if $\nu$ is $\sigma$-finite on $Y$. 
\end{df}


\begin{spp}\label{lb737}
Assume that $(\fk B_X,\mu)$ is \textbf{$\sigma$-finite}. Then $(\fk M_\mu,\mu)$ is the completion of $(\fk B_X,\mu)$.
\end{spp}

\begin{proof}[$\star$ Proof]
$(\fk M_\mu,\mu)$ extends the completion $(\fk M,\mu)$. We want to show that $\fk M_\mu\subset\fk M$. Let $E\in\fk M_\mu$. Since $X$ is $\sigma$-finite, we have $X=\bigcup_n A_n$ where $A_n\in\fk B_X$ and $\mu(A_n)<+\infty$. It suffices to prove that $E_n:=E\cap A_n$ belongs to $\fk M$ for each $n$. Note that $E_n\in\fk M_\mu$ and $\mu(E_n)<+\infty$. Thus, by Cor. \ref{lb731}, for each $k\in\Zbb_+$ there exists a compact $K_k\subset E_n$ such that $\mu(E_n\setminus K_k)<1/k$. By replacing $K_k$ with $K_1\cup\cdots\cup K_k$, we assume $(K_k)$ is increasing. Let $F=\bigcup_k K_k$, which is a Borel set. Then $F\subset E_n$ and $E_n\setminus F$ is $\mu$-null. Since $(\fk M,\mu)$ is complete, we see that $E_n\setminus F$ belongs to $\fk M$. So $E_n\in\fk M$.
\end{proof}

In general, $(\fk M_\mu,\mu)$ is larger than the completion $(\fk M,\mu)$ of $(\fk B_X,\mu)$. $(\fk M_\mu,\mu)$ is called the \textbf{saturation} of $(\fk M,\mu)$. More generally, the measure $\nu$ of a measure space $(Y,\fk N,\nu)$ is called \textbf{saturated} provided that a set $E\subset Y$ belongs to $\fk N$ iff $E\cap A\in\fk N$ for every $A\in\fk N$ such that $\nu(A)<+\infty$. If a measure $(\fk N,\nu)$ is not necessarily saturated, the smallest saturated measure extending $(\fk N,\nu)$ is called the \textbf{saturation} of $(\fk N,\nu)$. \index{00@Saturated measure}  \index{00@Saturation of a measure}



\subsection{A discussion of measurable sets: from Jordan to Lebesgue to Carath\'eodory}\label{lb733}


Let $(X,\mc T_X)$ be a topological space, and assume that $\mu:\mc T_X\rightarrow[0,+\infty]$ satisfies Asmp. \ref{lb712}. 

\subsubsection{Lebesgue's outer measure and inner measure}

Here, I will make some comparisons between our approach in Sec. \ref{lb726} and Lebesgue's original method. We refer the readers to \cite[Sec. 5.1]{Haw} and \cite[Sec. 9.6]{Jah} for detailed discussions of Lebesgue's approach.


In the 1902 paper where Lebesgue introduced his integral theory, he focused on measurable subsets of $[a,b]$. For the convenience of the following discussion, I will consider the bounded open interval $(a,b)$ instead. For each $E\subset(a,b)$, Lebesgue defined the outer measure $m^*(E)$ by \eqref{eq294}, i.e., the infimum of the total sizes of intervals covering $E$. It is not hard to see that his definition agrees with ours, since any open subset of $\Rbb$ is a countable disjoint union of open intervals (cf. Pb. \ref{lb679}). 

On the other hand, Lebesgue's definition of inner measure is
\begin{align}\label{eq291}
m_*(E)=b-a-m^*((a,b)\setminus E)
\end{align}
If we generalize \eqref{eq291} to the setting of Sec. \ref{lb726} where $E$ is a subset of an open $\Omega\subset X$ satisfying $\mu(\Omega)<+\infty$, the inner measure of $E$ should be defined by $\mu(\Omega)-\mu^*(\Omega\setminus E)$. We now show that this definition is equal to our definition of $\mu_*(E)$ in \eqref{eq292b}: 



\begin{pp}\label{lb720}
Let $\Omega$ be an open subset of $X$ such that $\mu(\Omega)<+\infty$. Let $E\subset\Omega$. Then
\begin{align}\label{eq295}
\mu_*(E)=\mu(\Omega)-\mu^*(\Omega\setminus E)
\end{align}
\end{pp}



\begin{proof}[$\star$ Proof]
Let $F=\Omega\setminus E$. By the definition of $\mu^*$, we have
\begin{align*}
\mu^*(F)=\inf\big\{\mu(V): V\text{ is open in $\Omega$ and contains $F$} \big\}
\end{align*}
By Lem. \ref{lb730}, $\Gamma:=\Omega\setminus V$ is $\mu$-regular, and $\mu(\Omega)=\mu(V)+\mu(\Gamma)$. Therefore, $\mu(\Omega)-\mu^*(\Omega\setminus E)$ equals the supremum of $\mu(\Gamma)$ where $\Gamma$ is a closed subset of $\Omega$ contained in $E$. Thus,  proving \eqref{eq295} means proving
\begin{align*}
\sup\big\{\mu(K):K\subset E\text{ is compact}\big\}=\sup\big\{\mu(\Gamma):\Gamma\text{ is closed in $\Omega$, and }\Gamma\subset E\big\}
\end{align*}
We clearly have ``$\leq$". Since $\mu(\Gamma)=\mu_*(\Gamma)$, for each $\eps>0$ there exists a compact $K\subset \Gamma$ such that $\mu(K)>\mu(\Gamma)-\eps$. So ``$\geq$" is also true.
\end{proof}


For a further generalization of this proposition, see Pb. \ref{lb734}.


\subsubsection{Subadditivity and superadditivity}

As mentioned in the slogan \eqref{eq290}, the countable additivity of $\mu$ on regular sets follows directly from the fact that the outer measure $\mu^*$ is countably subadditive, and the inner measure $\mu_*$ is countably superadditive. This simple and intuitive idea is not new. It already appeared in Darboux integrals: Given a bounded real-valued function $f$ defined on $R=[a_1,b_1]\times\cdots[a_N,b_N]$, the upper Darboux integral $\ovl\int f$ and the lower Darboux integral $\udl\int f$ are defined in a similar way as in Thm. \ref{lb444}, where the Darboux sums are defined by partitioning the box $R$ into smaller boxes. It is not hard to check that $\ovl\int$ and $\udl\int$ satisfy respectively the subadditivity and the superadditivity:
\begin{align*}
\ovl\int(f+g)\leq\ovl\int f+\ovl\int g\qquad \udl\int(f+g)\geq\udl\int f+\udl\int g
\end{align*}
(See also Pb. \ref{lb732}.) Thus, since $f$ is Riemann integrable iff $\ovl\int f=\udl\int f$, $\ovl\int$ and $\udl\int$ must be linear on Riemann integrable functions.



In fact, before Lebesgue,  Jordan had utilized this idea (subadditivity $+$ superadditivity $\Rightarrow$ additivity) to study measurable sets in 1892 (cf. \cite[Sec. 9.4]{Jah} and \cite[4.1]{Haw}): For each bounded $E\subset\Rbb^N$, the \textbf{outer content}  $c^*(E)$ is defined to be the infimum of the total sizes of \textit{finitely many} boxes covering $E$, and the \textbf{inner content}  $c_*(E)$ is the supremum of the total sizes of finitely many disjoint boxes contained in $E$.  Jordan defined $E$ to be measurable if $c^*(E)=c_*(E)$. Using our familiar language, 
\begin{align}\label{eq308}
c^*(E)=\ovl\int\chi_E\qquad c_*(E)=\udl\int\chi_E
\end{align}
and $E$ is Jordan-measurable iff $\chi_E$ is Riemann integrable. $c^*$ and $c_*$ satisfy subadditivity and superadditivity respectively, just as $\ovl\int$ and $\udl\int$ do. So $c^*$ satisfies additivity on Jordan-measurable sets. 

\begin{eg}
Let $E=\Qbb\cap[0,1]$. We know that $m(E)=0$. It is not hard to see that $c_*(E)=0$ and $c^*(E)=1$. So $E$ is not Jordan-measurable. 
\end{eg}

Compared to Jordan, an important improvement Lebesgue made is that he extended the finite subadditivity and superadditivity to countable ones. He achieved this goal by giving the better definition of outer measure. Recall that the outer content $c^*(E)$ is defined by the infimum of the sizes of \textbf{simple regions} (i.e., finite unions of boxes) covering $E$. The outer Lebesgue measure $m^*(E)$ is defined in a similar way, except that one allows for \textit{countable} unions of boxes to cover $E$. From the modern viewpoint (i.e., the viewpoint in Sec. \ref{lb688} and \ref{lb726}), $m^*(E)$ is defined by covering $E$ by arbitrary open sets, not just by simple regions. The modern viewpoint is equivalent to the classical one due to the following observation:

\begin{pp}\label{mc38}
Let $\Omega$ be an open subset of $\Rbb^N$. Then $\Omega$ is a countable disjoint union of \textbf{boxes} $\Omega=\bigsqcup_n B_n$. Here, a box denotes a set $I_1\times\cdots\times I_N$ where each $I_i$ is a bounded interval in $\Rbb$. 
\end{pp}

\begin{proof}
Since $\Omega$ is a union of open boxes, and since $\Omega$ is second countable and hence Lindel\"of, $\Omega$ is a countable union of open boxes $\Omega=\bigcup_n B_n$. It is easy to show that
\begin{gather}
B',B''\text{ are boxes}\qquad\Rightarrow\qquad B'\setminus B''\text{ is a finite disjoint union of boxes}
\end{gather}
From this, it is easy to show that
\begin{gather}
\begin{gathered}
B',B''\text{ are finite disjoint unions of boxes}\\
\Downarrow\\
B'\setminus B''\text{ is a finite disjoint union of boxes}
\end{gathered}
\end{gather}
Therefore, if we define $C_1=B_1$ and $C_{n+1}=B_{n+1}\setminus (C_1\sqcup\cdots\sqcup C_n)$, then by induction on $n$, one checks that each $C_n$ is a finite disjoint union of boxes. 
\end{proof}


\subsubsection{The dilemma of $\mu$-regular sets with possibly infinite measures.}


We know that when $\mu(X)<+\infty$, the $\mu$-regular sets form a $\sigma$-algebra containing $\fk B_X$ (Thm. \ref{lb724} and Prop. \ref{lb723}). When $\mu(X)=+\infty$, this statement cannot be proved, so we must find alternatives to $\mu$-regular sets. 

The alternatives we gave in Sec. \ref{lb726} are locally $\mu$-regular sets, i.e., the sets $E$ such that $E\cap\Omega$ is $\mu$-regular for any open $\mu$-finite set $\Omega$. Our treatment is similar to that in Rudin's book \cite{Rud-R}, except that Rudin considered those $E$ such that $E\cap K$ is regular for any compact $K\subset X$. (Rudin assumed that $X$ is LCH, and $\mu$ is finite on compact sets.) See the proof of Thm. 2.14 in \cite{Rud-R}. In particular, Step III of the proof of that theorem is similar to Lem. \ref{lb714}, Step IV is similar to Cor. \ref{lb727}, Step V is similar to Cor. \ref{lb731}, Step VI is similar to Lem. \ref{lb730}, Step VII and IX are similar to Thm. \ref{lb724}, and Step VIII is similar to Prop. \ref{lb723}.



Another approach was introduced by Carath\'eodory in 1914 and is popular among many textbooks (cf. \cite[Sec. 1.4]{Fol-R}, \cite[Sec. 17.3]{RF}, \cite[Sec. 39]{Yu}). Since you may need to study this approach carefully in the future, I'll explain below how the approach of Carath\'eodory is related to those of Jordan and Lebesgue based on regular sets. (At first glance, they look very different!)


\subsubsection{$\star$ Carath\'eodory measurable sets}

The relationship between our approach (in Sec. \ref{lb726}) and Lebesgue's approach was already explained. Now, recall that a subset $E$ of $X$ is locally $\mu$-regular iff $\mu^*(\Omega\cap E)=\mu_*(\Omega\cap E)$ for all open $\Omega$ with finite $\mu(\Omega)$. By Prop. \ref{lb720}, we have $\mu_*(\Omega\cap E)=\mu(\Omega)-\mu^*(\Omega\setminus E)$. Therefore, 
\begin{gather}\label{eq297}
\begin{gathered}
E\text{ is locally $\mu$-regular}\\
\Updownarrow\\
\mu^*(\Omega\cap E)+\mu^*(\Omega\setminus E)=\mu(\Omega)\quad\text{if $\Omega\subset X$ is open and $\mu(\Omega)<+\infty$}
\end{gathered}
\end{gather}
Here comes the magic:

\begin{pp}\label{lb741}
Let $E\subset X$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $E$ is locally $\mu$-regular.
\item $E$ is \textbf{Carath\'eodory $\mu^*$-measurable}, which means that for any  $A\subset X$ we have
\begin{align}\label{eq298}
\mu^*(A\cap E)+\mu^*(A\setminus E)=\mu^*(A)
\end{align}
\end{enumerate}
\end{pp}

\begin{proof}
By \eqref{eq297}, clearly (2) implies (1). Conversely, assume (1). To prove \eqref{eq298}, by the subadditivity of $\mu^*$, it suffices to prove ``$\leq$". This is obvious when $\mu^*(A)=+\infty$. So we assume WLOG that $\mu^*(A)<+\infty$. Since $\mu^*(A)$ is the infimum of $\mu(\Omega)$ where $\Omega\supset A$ is open and $\mu(\Omega)<+\infty$, it suffices to prove for such $\Omega$ that $\mu^*(A\cap E)+\mu^*(A\setminus E)\leq\mu(\Omega)$. By the monotinicity of $\mu^*$, it suffices to prove $\mu^*(\Omega\cap E)+\mu^*(\Omega\setminus E)=\mu(\Omega)$. But this follows from the fact that $\mu^*$ is a measure on the $\sigma$-algebra $\fk M_\mu$ (cf. Thm. \ref{lb724}). (Alternatively, it follows directly from Lem. \ref{lb730} and Cor. \ref{lb727}.)
\end{proof}

The surprising part of the Carath\'eodory measurability is that we do not assume $A$ to be either open or compact or Borel or $\mu$-regular. By contrast, $\mu_*(A\cap E)+\mu^*(A\setminus E)$ is not necessarily equal to $\mu^*(A)$ or $\mu_*(A)$ when $A$ is not $\mu$-regular. (It is equal to $\mu(A)$ when $A$ is $\mu$-regular and $\mu(A)<+\infty$. See Prop. \ref{lb739}.)

\begin{eg}\label{lb742}
Let $E,F$ be subsets of $X$ such that there exist disjoint open subsets $U,V$ of $X$ containing $E,F$ respectively. Let $A=E\cup F$. Then $\mu_*(A)=\mu_*(E)+\mu_*(F)$ and $\mu^*(A)=\mu^*(E)+\mu^*(F)$. (Cf. Pb. \ref{lb729}.) 
Assume that $E,F$ have finite outer measures and are not $\mu$-regular, i.e.,  $\mu_*(E)<\mu^*(E)<+\infty$ and $\mu_*(F)<\mu^*(F)<+\infty$. Then
\begin{align*}
\mu_*(A)<\mu_*(A\cap E)+\mu^*(A\setminus E)<\mu^*(A)
\end{align*}
since the middle term is equal to $\mu_*(E)+\mu^*(F)$.
\end{eg}

We now briefly discuss Carath\'eodory's theory.

\begin{df}\label{lb743}
Let $Y$ be a set. A function $\nu^*:2^Y\rightarrow[0,+\infty]$ is called an \textbf{(abstract) outer measure} \index{00@Abstract outer measure} if it satisfies the three conditions in Prop. \ref{lb718}, namely, it satisfies $\nu^*(\emptyset)=0$, the monotonicity, and the countable subadditivity (on subsets of $Y$). A set $E\subset Y$ is called \textbf{Carath\'eodory $\nu^*$-measurable} (or simply \textbf{$\nu^*$-measurable}) \index{00@Carath\'eodory measurable} if for every $A\subset Y$ we have
\begin{align}\label{eq299}
\nu^*(A\cap E)+\nu^*(A\setminus E)=\nu^*(A)
\end{align}
\end{df}


The construction of Lebesgue measures (and more generally, measures on Hausdorff spaces) using Carath\'eodory measurable sets is based on the following key theorem.

\begin{thm}\label{lb740}
Let $\nu^*$ be an (abstract) outer measure on a set $Y$. Then the set $\fk M$ of Carath\'eodory $\nu^*$-measurable sets form a $\sigma$-algebra, and the restriction of $\nu^*$ to $\fk M$ is a complete measure.
\end{thm}

\begin{proof}
See \cite[Thm. 1.11]{Fol-R}.
\end{proof}

Our main Thm. \ref{lb724} follows easily from \ref{lb740}: Since $\mu$ satisfies (a,b,c) of Asmp. \ref{lb712}, $\mu^*$ is an abstract outer measure. By using (d,e) of Asmp. \ref{lb712}, one can show that open sets are $\mu^*$-measurable.\footnote{Sketch of the proof: Let $E$ be open. First prove \eqref{eq298} when $A$ is open. Then prove \eqref{eq298} for any $A$ by using a similar argument as in the proof of Prop. \ref{lb741}.} Therefore, the set $\fk M_\mu$ of Carath\'eodory $\mu^*$-measurable sets contains open subsets of $X$. Thus, by Thm. \ref{lb740}, $\fk M_\mu$ is a $\sigma$-algebra containing $\fk B_X$, and $\mu^*$ is a complete measure on $\fk M_\mu$.

The reason we use locally regular sets in our course instead of Carath\'eodory's approach is that the latter is very unintuitive. The intuition ``subadditivity $+$ superadditivity $\Rightarrow$ additivity", which goes back to Lebesgue, Jordan, and even Darboux, is very obscure in the proof of Thm. \ref{lb740}. One cannot interpret \eqref{eq299} to mean that the outer measure $\nu^*(A\cap E)$ of $A\cap E$ equals the ``inner measure" $\nu^*(A)-\nu^*(A\setminus E)$, because Exp. \ref{lb742} tells us that $\mu^*(A)-\mu^*(A\setminus E)$ is often not equal to the actual inner measure $\mu_*(A\cap E)$. %\footnote{Here, I am challenging the view expressed in the paragraph before Thm 1.11 of \cite{Fol-R}.} 
On the other hand, the advantage of Carath\'eodory's approach is that Thm. \ref{lb740} can be applied to more general situations than Thm. \ref{lb724}. For example, it can be used to construct measures on Hausdorff spaces not satisfying regularity (such as the Hausdorff measures, cf. \cite[Sec. 11.2]{Fol-R}).

I believe that many people will have this confusion when they first see the condition \eqref{eq299}: Why consider an arbitrary set $A$ instead of just a ``good" set, for example, an open set, a compact set, or a Borel set? How can one believe that a definition as strong as Def. \ref{lb743} would have nontrivial examples? The way to understand the motivation behind a definition or a theorem is not to immerse oneself in the technical details of the proof, but to clarify the genealogy of concepts. I hope that the exposition in this section will help the reader to get a general idea of how the concept of measurable sets evolved from its basic and intuitive form to the abstract definition of Carath\'eodory.






























\subsection{Problems and supplementary material}

\subsubsection{Basic properties}

\begin{df}\label{lb707}
Let $(X,\fk M)$ be a measurable space. Let $A$ be a subset of $X$. Let
\begin{align}
\fk M|_A=\iota^{-1}(\fk M)
\end{align}
where $\iota:A\rightarrow X$ is the inclusion map. In other words, $\fk M|_A=\{A\cap E:E\in\fk M\}$. Then $\fk M|_A$ is clearly a $\sigma$-algebra on $A$, called the \textbf{restriction} \index{00@Restriction of $\sigma$-algebra} of $\fk M$ to $A$. Moreover, if $A\in\fk M$, it is clear that $\fk M|_A\subset\fk M$.
\end{df}

\begin{comment}
\begin{eg}
Let $X$ be a topological space, equipped with the Borel $\sigma$-algebra $\fk B_X$. Let $A\subset X$ be Borel, equipped with the subspace topology. Since the inclusion map $\iota:A\hookrightarrow X$ is continuous and hence Borel, $\fk B_X|_A=\iota^{-1}(\fk B_X)$ must be a subset of $\fk B_A$. Conversely, $\fk B_X|_A$ contains all open subsets of $A$, and hence contains $\fk B_A$. We conclude
\begin{align}
\fk B_A=\fk B_X|_A\subset\fk B_X
\end{align}
\end{eg}
\end{comment}



\begin{exe}
Let $(X,\fk M)$ and $(Y,\fk N)$ be measurable spaces. Let $f:X\rightarrow Y$ be a map. Let $Z\subset Y$. Let $\fk N|_Z$ be the restriction of $\fk N$ to $Z$. Prove that $f:(X,\fk M)\rightarrow(Y,\fk N)$ is measurable iff $f:(X,\fk M)\rightarrow (Z,\fk N|_Z)$ is measurable.
\end{exe}

\begin{prob}\label{mc34}
Let $Y$ be a topological space, and let $Z$ be a subspace of $Y$ (equipped with the subspace topology). Prove $\fk B_Y|_Z=\fk B_Z$.
\end{prob}

\begin{proof}[Hint]
Apply Cor. \ref{lb695} to the inclusion map $\iota:Z\rightarrow Y$.
\end{proof}




\begin{prob}\label{lb778}
Let $(X,\fk M,\mu)$ be a measure space with completion $(\ovl{\fk M},\ovl\mu)$. Let $\mc V$ be a separable normed vector space, and let $f:X\rightarrow \mc V$ be $\ovl{\fk M}$-measurable (i.e., for each $U\in\fk B_{\mc V}$ we have $f^{-1}(U)\in\ovl{\fk M}$). Prove that there exists $A\in\fk M$ with $\mu(X\setminus A)=0$ such that $f\chi_A$ is $\fk M$-measurable.
\end{prob}


\begin{prob}\label{lb838}
Let $X$ and $Y$ be topological spaces. 
\begin{enumerate}
\item  Let $A\in\fk B_X$ and $B\in\fk B_Y$. Prove that $A\times B\in\fk B_{X\times Y}$.
\item Let $f:X\rightarrow[0,+\infty]$ be a Borel function. Prove that $R_f$ is a Borel subset of $X\times\ovl\Rbb$ where
\begin{align*}
R_f=\{(x,y)\in X\times\ovl\Rbb: 0\leq y\leq f(x)\}
\end{align*}
\end{enumerate}
\end{prob}
\begin{proof}[Hint]
1. The inverse image of any Borel set under a continuous (and hence Borel) map is Borel. 2. Realize $R_f$ as the inverse image of a closed set under a Borel map.
\end{proof}



\subsubsection{Lower and upper semicontinuity}\label{lb803}

\begin{df}\label{lb781}
Let $X$ be a topological space. A function $f:X\rightarrow\ovl\Rbb$ is called \textbf{lower semicontinuous} \index{00@Lower semicontinuous} if $f^{-1}(a,+\infty]$ is open for each $a\in\ovl\Rbb$. We say that $f$ is  \textbf{upper semicontinuous} \index{00@Upper semicontinuous} if $f^{-1}[-\infty,a)$ is open for each $a\in\ovl\Rbb$. By Exp. \ref{lb697}, semicontinuous functions are Borel functions.
\end{df}




\begin{prob}\label{lb782}
Let $X$ be a topological space.
\begin{enumerate}
\item Let $A\subset X$. Prove that $\chi_A$ is lower semicontinuous iff $A$ is open. 
\item Let $(f_i)_{i\in I}$ be a family of lower semicontinuous functions $X\rightarrow\ovl\Rbb$. Let $f(x)=\sup_{i\in I}f_i(x)$. Prove that $f:X\rightarrow\ovl\Rbb$ is lower semicontinuous.
\end{enumerate}
\end{prob}

Recall Pb. \ref{lb346} for the basic properties of $\limsup$ and $\liminf$.

\begin{prob}\label{lb767}
Let $X$ be a topological space. Let $f:X\rightarrow\ovl\Rbb$. Prove that the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $f$ is lower semicontinuous.
\item For each $x\in X$ and each net $(x_\alpha)$ in $X$ converging to $x$, we have $\liminf_\alpha f(x_\alpha)\geq f(x)$.
\item For each $x\in X$ and each net $(x_\alpha)$ in $X$ converging to $x$, we have $\limsup_\alpha f(x_\alpha)\geq f(x)$.
\end{enumerate}
\end{prob}


\begin{proof}[Hint for (3)$\Rightarrow$(1)]
Assume that (1) is false. Then there exists $a\in\ovl\Rbb$ such that some element $x\in f^{-1}(a,+\infty]$ is not an interior point of $f^{-1}(a,+\infty]$. Find a net $(x_\alpha)$ converging to $x$ such that $f(x_\alpha)\leq a$ for all $\alpha$.
\end{proof}

\begin{rem}
If $X$ is a metric space, the three conditions in Pb. \ref{lb767} are still equivalent if we replace ``each net $(x_\alpha)$" with ``each sequence $(x_n)$".
\end{rem}



\begin{eg}\label{lb698}
Recall Def. \ref{lb114} for the meaning of summations and multiplications in $\ovl\Rbb_{\geq0}$. Then the addition map $(a,b)\in\ovl\Rbb_{\geq0}\times\ovl\Rbb_{\geq0}\mapsto a+b\in\ovl\Rbb_{\geq0}$ is continuous. Using Pb. \ref{lb767}-(3), one easily checks that the multiplication map $(a,b)\in\ovl\Rbb_{\geq0}\times\ovl\Rbb_{\geq0}\mapsto ab\in\ovl\Rbb_{\geq0}$ is lower semicontinuous. (It is continuous outside $(\{0\}\times\ovl\Rbb_{\geq0})\cup (\ovl\Rbb_{\geq0}\times\{0\})$.)
\end{eg}

\begin{rem}\label{lb783}
From Pb. \ref{lb767}-(3), it is clearly that an $\ovl\Rbb_{\geq0}$-linear combination of lower semicotinuous functions $X\rightarrow\ovl\Rbb_{\geq0}$ is lower semicontinuous.
\end{rem}


\begin{sprob}
Let $X$ be a compact topological space, and let $f:X\rightarrow\ovl\Rbb$ be lower (resp. upper) semicontinuous. Show that $f$ attains its minimum (resp. maximum) at some point of $X$.
\end{sprob}




\subsubsection{$\star$ Weakly measurable functions}

Let $(X,\fk M)$ be a measurable space. 

\begin{df}\label{lb710}
Let $\mc V$ be a normed vector space over $\Fbb\in\{\Rbb,\Cbb\}$, equipped with the norm topology and the corresponding Borel $\sigma$-algebra $\fk B_{\mc V}$. We say that a map $f:X\rightarrow\mc V$ is \textbf{weakly measurable} \index{00@Weakly measurable} if for every $\varphi\in\mc V^*=\fk L(\mc V,\Fbb)$ the function $\varphi\circ f:X\rightarrow\Fbb$ is measurable. 
\end{df}

It is clear (from Rem. \ref{lb696}) that if $f$ is measurable, then $f$ is weakly measurable.

\begin{exe}\label{lb706}
Let $\mc V$ be a normed vector space. Let $f:X\rightarrow\mc V$ be a function. Suppose that $\mc W$ is a linear subspace of $\mc V$ containing $f(X)$. Prove that $f:X\rightarrow\mc V$ is weakly measurable iff $f:X\rightarrow\mc W$ is weakly measurable.
\end{exe}
\begin{proof}[Hint]
Use Hahn-Banach Thm. \ref{lb499}.
\end{proof}


\begin{prob}\label{lb702}
Let $\mc V$ be a normed vector space over $\Fbb\in\{\Rbb,\Cbb\}$. Let $f:X\rightarrow\mc V$. Suppose that $f(X)$ is separable (as a metric subspace of $\mc V$). Prove that $f$ is measurable iff $f$ is weakly measurable.
\end{prob}

\begin{proof}[Hint]
Let $f:X\rightarrow\mc V$ be weakly measurable. Use Exe. \ref{lb706} to show that one can assume WLOG that $\mc V$ is separable.  Then, by Thm. \ref{lb523} and the Banach-Alaoglu Thm. \ref{lb519}, $\ovl B_{\mc V^*}(0,1)$ is weak-* compact and metrizable, and hence separable (due to Thm. \ref{lb252}). So there exist countably many elements $\varphi_1,\varphi_2,\dots$ forming a weak-* dense subset of $\ovl B_{\mc V^*}(0,1)$. Prove that $\Vert v\Vert=\sup_n |\bk{\varphi_n,v}|$ for each $v\in\mc V$. (Hint: Show that $v$ can be viewed as a \textit{continuous} function on $\ovl B_{\mc V^*}(0,1)$.) Conclude that for each $v\in\mc V$, the function $x\in X\mapsto \Vert f(x)-v\Vert$ is measurable. Use this fact to show that $f$ is measurable.
\end{proof}



\begin{prob}\label{lb705}
Let $Y$ be a metric space. Let $(f_n)$ be a sequence of measurable functions $X\rightarrow Y$ converging pointwise to $f:X\rightarrow Y$. Assume that $f(X)$ is separable. Prove that $f$ is measurable.
\end{prob}

\begin{proof}[Hint]
First method: By Thm. \ref{lb521}, $Y$ can be viewed as a metric subspace of a real normed vector space $\mc V$. Show that $f:X\rightarrow\mc V$ is weakly measurable.

Second method: First prove that for each $y\in Y$, the function $x\in X\mapsto d(f(x),y)$ is measurable. Conclude that the map $f:X\rightarrow f(X)$ is measurable.
\end{proof}

\begin{comment}
\begin{proof}
By Thm. \ref{lb521}, $Y$ can be isometrically embedded into a real Banach space $\mc V$. So we view $Y$ as a metric subspace of $\mc V$. Since $Y$ is separable, $Y$ is contained in a separable linear subspace $\mc W$ of $\mc V$. (Proof: Let $E$ be a countable dense subset of $Y$. Then $\Span_\Qbb E$ is a countable countable dense subset of $\mc W=\Span_\Rbb E$.) So we can view $f_n$ and $f$ as functions $X\rightarrow\mc W$. By Cor. \ref{lb701}, $f$ is weakly measurable. Therefore, by Pb. \ref{lb702}, $f$ is measurable.
\end{proof}
\end{comment}


In fact, without assuming that $f(X)$ is separable, the statement in Pb. \ref{lb705} is still true, although the proof is more technical. (See the end of Sec. 38 in \cite{Yu}.) 



\begin{prob}
Let $f:X\rightarrow l^2(\Zbb_+)$ be a map. For each $x\in X$, write $f(x)=(f_1(x),f_2(x),\dots)$. Prove that $f$ is measurable iff $f_n:X\rightarrow\Cbb$ is measurable for each $n\in\Zbb_+$.
\end{prob}


\subsubsection{$\star$ Outer and inner measures}

Let $(X,\mc T_X)$ be a Hausdorff space. Let $\mu:\mc T_X\rightarrow[0,+\infty]$ and its associated $\mu^*,\mu_*:2^X\rightarrow[0,+\infty]$ be as in Asmp. \ref{lb712}. Recall from Thm. \ref{lb724} that $\mu^*$ is a measure on the Borel $\sigma$-algebra $\fk B_X$, and $\mu^*$ is denoted by $\mu$ when restricted to $\fk B_X$.


\begin{prob}\label{lb729}
Let $E$ and $F$ be subsets of $X$. Assume that there are mutually disjoint open subsets $U,V\subset X$ such that $E\subset U$ and $F\subset V$. Prove that $\mu_*(E\cup F)=\mu_*(E)+\mu_*(F)$ and $\mu^*(E\cup F)=\mu^*(E)+\mu^*(F)$.
\end{prob}

\begin{comment}
The following problem is similar to Cor. \ref{lb731}.

\begin{prob}\label{lb738}
Let $E\subset X$. Assume that $\mu^*(E)<+\infty$. Prove that $E$ is $\mu$-regular iff for every $\eps>0$ there is an open $U\subset X$ such that $\mu^*(U\setminus E)<\eps$.
\end{prob}

\begin{proof}[Hint for $\Leftarrow$]
Show that $E=G\setminus \Delta$ where $G\in\fk B_X$ and $\mu^*(\Delta)=0$.
\end{proof}
\end{comment}


\begin{prob}\label{lb734}
Let $E\subset X$. Prove that 
\begin{subequations}
\begin{gather}
\mu_*(E)=\sup\big\{\mu(A):A\in\fk B_X\text{ and }A\subset E \big\}\qquad\text{if }\mu^*(E)<+\infty\\
\mu^*(E)=\inf\big\{\mu(B):B\in\fk B_X\text{ and }E\subset B \big\}
\end{gather}
\end{subequations}
Conclude that if $\Omega\in\fk B_X$ satisfies $\mu(\Omega)<+\infty$, then
\begin{align}\label{eq326}
\mu_*(\Omega\cap E)=\mu(\Omega)-\mu^*(\Omega\setminus E)
\end{align}
This formula generalizes Prop. \ref{lb720}.
\end{prob}

The following proposition further generalizes \eqref{eq326}.

\begin{pp}\label{lb739}
Let $A\subset X$ and $E\subset X$. Assume that $\mu^*(A)<+\infty$. Then
\begin{align}\label{eq300}
\mu_*(A)\leq\mu_*(A\cap E)+\mu^*(A\setminus E)\leq\mu^*(A)
\end{align} 
\end{pp}

\begin{proof}
For each open $U$ containing $A$ and $\mu(U)<+\infty$, we have $\mu_*(A\cap E)+\mu^*(A\setminus E)\leq\mu_*(U\cap E)+\mu^*(U\setminus E)$ where the RHS equals $\mu(U)$ by \eqref{eq326}. Taking $\inf_U$, we get the second ``$\leq$" of \eqref{eq300}. For each compact $K\subset A$, by \eqref{eq326}, we have $\mu(K)=\mu_*(K\cap E)+\mu^*(K\setminus E)\leq\mu_*(A\cap E)+\mu^*(A\setminus E)$. Taking $\sup_K$, we get the first ``$\leq$" of \eqref{eq300}.
\end{proof}




\newpage



\section{Integrals on measurable spaces}

The goal of this chapter is to define the integral $\int_X fd\mu$ where $(X,\mu)$ is a measure space, and $f:X\rightarrow\Cbb$ is measurable. By considering $\Real f$ and $\Imag g$ separately, it suffices to define $\int_X fd\mu$ when $f:X\rightarrow\Rbb$. We shall first define $\int f$ when $f:X\rightarrow[0,+\infty]$. Then we extend the integral to real functions.

\subsection{Monotone convergence extension I: from simple to positive measurable functions}\label{lb891}

Let $(X,\fk M,\mu)$ be a measure space. Recall Def. \ref{lb114} for the addition and multiplication in $\ovl\Rbb_{\geq0}=[0,+\infty]$.


\subsubsection{Integrals of simple functions}

\begin{df}
Let $Y$ be a measurable space. A function $f:X\rightarrow Y$ is called a \textbf{simple function} \index{00@Simple function} if $f$ is measurable and $f(X)$ is a finite set. We let \index{SXY@$\mc S(X,Y)$}
\begin{align}
\mc S(X,Y)=\{\text{simple functions }f\in Y^X\}
\end{align}
If $Y=[0,+\infty]$, a simple function $f$ is called 
an \textbf{(extended) positive simple function} \index{00@Positive simple function}. This is equivalent to saying that $f$ is of the form
\begin{align}\label{eq301}
f=\sum_{i=1}^n a_i\chi_{E_i}
\end{align}
where $n\in\Zbb_+$, $a_i\in[0,+\infty]$, and $E_i\in\fk M$. Let \index{SX@$\mc S_+(X)=\mc S(X,\ovl\Rbb_{\geq0})$}
\begin{align}
\mc S_+(X)=\mc S(X,\ovl\Rbb_{\geq0})=\{\text{extended positive simple functions on }X\}
\end{align}
which is an $\ovl\Rbb_{\geq0}$-linear subspace of $[0,+\infty]^X$.
\end{df}

\begin{df}
For each $f\in \mc S_+(X)$, define
\begin{align}
\int_X f\equiv \int_X fd\mu=\sum_{i=1}^n a_i\mu(E_i)
\end{align}
if $f(X)=\{a_1,\dots,a_n\}$ (where $a_i\neq a_j$ if $i\neq j$) and $E_i=f^{-1}(a_i)$. 
\end{df}

To show the linearity of $\int_X$, we need a lemma:
\begin{lm}\label{lb744}
Suppose that $f=\sum_{i=1}^n a_i\chi_{E_i}$ where $a_i\in\ovl\Rbb_{\geq0}$, $E_i\in\fk M$, and $E_i\cap E_j=\emptyset$ if $i\neq j$. Then $\int_X f=\sum_i a_i\mu(E_i)$.
\end{lm}

\begin{proof}
For each $c\in\ovl\Rbb_{\geq0}$, we let $I_c=\{i\in\Nbb:1\leq i\leq n,a_i=c\}$. Then $f^{-1}(c)=\bigsqcup_{i\in I_c}E_i$. Thus, by the additivity of $\mu$,
\begin{align*}
\int f=\sum_{c\in\ovl\Rbb_{\geq0}} c\cdot\mu\Big(\bigsqcup_{i\in I_c}E_i\Big)=\sum_c\sum_{i\in I_c}c\cdot\mu(E_i)=\sum_c\sum_{i\in I_c}a_i\cdot\mu(E_i)=\sum_i a_i\mu(E_i)
\end{align*}
\end{proof}


\begin{pp}\label{lb750}
The map $\int_X:\mc S_+(X)\rightarrow\ovl\Rbb_{\ge0}$ is  $\ovl\Rbb_{\ge0}$-linear.
\end{pp}
\begin{proof}
Let $f,g\in \mc S_+(X)$. Write $f,g$ as finite sums $f=\sum a_i\chi_{E_i}$ and $g=\sum_j b_j\chi_{F_j}$ where $E_1,E_2,\dots\in\fk M$ are mutually disjoint, and $F_1,F_2,\dots\in\fk M$ are mutually disjoint. Write $G_{i,j}=E_i\cap F_j$. Then $f,g,f+g$ can be written as linear combinations of characteristic functions over a common set of disjoint measurable sets:
\begin{align*}
f=\sum_{i,j}a_i\chi_{G_{i,j}}\qquad g=\sum_{i,j}b_j\chi_{G_{i,j}}\qquad f+g=\sum_{i,j}(a_i+b_j)\chi_{G_{i,j}}
\end{align*}
By Lem. \ref{lb744}, we get
\begin{align*}
\int f=\sum_{i,j}a_i\mu(G_{i,j})\qquad \int g=\sum_{i,j}b_j\mu(G_{i,j})\qquad\int(f+g)=\sum_{i,j}(a_i+b_j)\mu(G_{i,j})
\end{align*}
Hence $\int(f+g)=\int f+\int g$. Similarly, if $c\in\ovl\Rbb_{\geq0}$, then $cf=\sum_{i,j}ca_i\chi_{G_{i,j}}$ and hence, by Lem. \ref{lb744}, $\int cf=\sum_{i,j}ca_i\mu(G_{i,j})=c\int f$.
\end{proof}


\begin{co}
If $f,g\in \mc S_+(X)$ and $f\leq g$, then $\int_Xfd\mu\leq \int_X gd\mu$
\end{co}
\begin{proof}
One easily finds $h\in \mc S_+(X)$ such that $f+h=g$. So $\int g=\int f+\int h\geq\int f$. 
\end{proof}


\subsubsection{Integrals of measurable functions}\label{lb762}


\begin{df}\label{lb747}
For each measurable space $(Y,\fk N)$, we let \index{LXY@$\mc L(X,Y)$}
\begin{align}
\mc L(X,Y)=\{\text{measurable }f\in Y^X\}
\end{align}
Let $\mc L_+(X,\fk M)\equiv\mc L_+(X)=\mc L(X,\ovl\Rbb_{\geq0})$.  \index{LX@$\mc L_+(X)=\mc L(X,\ovl\Rbb_{\geq0})$} In other words,
\begin{align}
\mc L_+(X)=\{\text{measurable }f\in[0,+\infty]^X\}
\end{align}
For each $f\in\mc L_+(X)$, define the integral
\begin{align}
\int_Xfd\mu=\sup\Big\{\int_X sd\mu:s\in\mc S_+(X),s\leq f\Big\}
\end{align}
\end{df}

\begin{rem}\label{lb746}
It is easy to see that
\begin{align}
\int_Xfd\mu=\sup\Big\{\int_X sd\mu:s\in\mc S(X,\Rbb_{\geq0}),s\leq f\Big\}
\end{align}
In other words, to define $\int_Xf$, it suffices to consider positive simple functions with finite values.
\end{rem}


\begin{rem}\label{mc33}
Let $A\in \fk M$. Let $\fk M|_A$ be the restriction of $\fk M$ to $A$ (cf. Def. \ref{lb707}). Then $\fk M|_A\subset\fk M$. So we can let $\mu|_A$ be the \textbf{restriction}of  $\mu$ to $\fk M|_A$ so that $(A,\fk M|_A,\mu|_A)$ is a measure space. \index{00@Restriction of measure} If $f\in\mc L_+(X)$, noting that $f\chi_A$ is measurable (Cor. \ref{lb745}), we clearly have
\begin{align}\label{eq351}
\int_A f|_A d\mu|_A=\int_X f\chi_A d\mu
\end{align}
(since this is true when $f\in \mc S_+(X,\Rbb_{\geq0})$). We denote the two sides of \eqref{eq351} by $\dps\int_Af$.
\end{rem}


We now discuss the linearity of $\int_X$. Clearly $\int_X cf=c\int_Xf$ if $c\in[0,+\infty)$. It is not hard to check that $\int_X$ is supperadditive: Suppose that $f,g\in\mc L_+(X)$.  For each simple functions $s\leq f$ and $t\leq g$ we have $s+t\leq f+g$, and hence $\int_X(f+g)\geq\int_X(s+t)=\int_Xs+\int_Xt$. Therefore $\int_X(f+g)\geq\int_Xf+\int_Xg$. 

This is not surprising, because the definition clearly suggests that $\int_X$ is actually a lower integral. When $f$ is bounded and $\mu(X)<+\infty$ (which is case that Lebesgue considered in his 1902 paper), we can also define the upper integral
\begin{align}
\ovl\int_X fd\mu=\inf\Big\{\int_X td\mu:t\in\mc S_+(X),f\leq t \Big\}
\end{align}
which clearly satisfies the subadditivity $\ovl \int_X(f+g)\leq\ovl\int_Xf+\ovl\int_Xg$. Clearly $\int_Xf\leq\ovl\int_Xf$. To show the $\ovl\Rbb_{\geq0}$-linearity of $\int_X$, it suffices to prove that $\int_Xf=\ovl\int_Xf$. By scaling $f$, assume that $f(X)\subset[0,1]$. For each $k=1,\dots,n$, let $E_k=f^{-1}(\frac {k-1}n,\frac kn]$. Following Lebesgue's idea of ``partitioning the codomain" (cf. Sec. \ref{lb722}), define the \textbf{Lebesgue sums} \index{00@Lebesgue sum}
\begin{align}\label{eq302}
s_n=\sum_{k=1}^n \frac {k-1}n \chi_{E_k}\qquad t_n=\sum_{k=1}^n \frac {~k~}n \chi_{E_k}
\end{align}
Then $s_n,t_n\in\mc S_+(X)$, $s_n\leq f\leq t_n$, and $\int_X (t_n-s_n)\leq\mu(X)/n$. This proves that $\ovl\int_Xf\leq\int_Xf+\mu(X)/n$ for any $n$, and hence $\ovl\int_Xf=\int_Xf$. The linearity of $\int_X$ on bounded positive measurable functions is thus established. See also Sec. \ref{lb722}.

%It also shows that $\int_Xf$ can be understood as the limit of Lebesgue sums, just as Riemann integrals are the limits of Riemann sums.

It is a subtle task to extend the additivity of $\int_X$ to unbounded functions or to functions $f$ such that $\{x\in X:f(x)>0\}$ has infinite measures. (Consider for example the case that $f+g=\chi_A$ for some $A\in\fk M$ such that $\mu(A)=+\infty$. It is not so obvious why $\mu(A)\leq\int f+\int g$ is true.) In the following, we shall study the additivity in a more modern way.



\subsubsection{The monotone convergence theorem}\label{lb785}



\begin{pp}\label{lb749}
Let $f\in\mc L_+(X)$. Then there is a sequence $(s_n)_{n\in\Zbb_+}$ in $\mc S(X,\Rbb_{\geq0})$ such that $s_1\leq s_2\leq\cdots$ and that $\lim_n s_n$ converges pointwise to $f$. (In particular, $s_n\leq f$.)
\end{pp}

\begin{proof}
Choose a strictly increasing homeomorphism $\varphi:[0,+\infty]\xrightarrow{\simeq}[0,1]$, and let $g=\varphi\circ f$. Similar to \eqref{eq302}, we let $\sigma_n=\sum_{k=1}^n \frac{k-1}n\chi_{E_k}$ where $E_k=g^{-1}(\frac {k-1}n,\frac kn]$. Then $0\leq \sigma_n<1$, and $\lim_n \sigma_n$ converges uniformly to $g$ (since $\Vert g-\sigma_n\Vert_{l^\infty}\leq 1/n$). The subsequence $(\sigma_{2^n})_{n\in\Zbb_+}$ is increasing. Let $s_n=\varphi^{-1}\circ\sigma_{2^n}$. Then $(s_n)$ satisfies the requirement.
\end{proof}


\begin{rem}\label{lb807}
The above proof shows that if $\Vert f\Vert_{l^\infty}<+\infty$, one can choose an increasing sequence $(s_n)$ in $\mc S(X,\Rbb_{\geq0})$ converging uniformly to $f$.
\end{rem}

Before proving the linearity of $\int_X$, we first use Prop. \ref{lb749} to give a fun proof of an (almost) special case of Pb. \ref{lb778}.

\begin{pp}\label{lb863}
Let $\mu$ be a measure on $\fk M$. Let $(\ovl{\fk M},\ovl\mu)$ be the completion of $(\fk M,\mu)$. Let $f$ be an $\ovl{\fk M}$-measurable map from $X$ to $[0,+\infty]$ (resp. to $\Cbb$). There there exist $A\in\fk M$ with $\mu(X\setminus A)=0$ such that $f\chi_A$ is $\fk M$-measurable.
\end{pp}

\begin{proof}
If $f$ is a complex function, by considering $\Real(f)$ and $\Imag(g)$ separately, we assume WLOG that $f$ is real. Since $f=f^+-f^-$ where $f^+=\max\{f,0\}$ and $f^-=\max\{-f,0\}$ are $\fk M$-measurable (by Thm. \ref{lb700}), by considering $f^+$ and $f^-$ separately, it suffices to prove the corollary when $f:X\rightarrow[0,+\infty]$.

We first consider the case that $f\in\mc S_+(X)$. By linearity, it suffices to assume $f=\chi_E$ where $E\in\ovl {\fk M}$. By Thm. \ref{lb708}, we have $B\subset E\subset C$ where $B,C\in\fk M$ and $\mu(C\setminus B)=0$. Set $A=B\cup(X\setminus C)$ and $g=\chi_B$. Then $\mu(X\setminus A)=0$ and $f\chi_A=\chi_B$ is $\fk M$-measurable.

Now consider the general case. By Prop. \ref{lb749}, there is an increasing sequence $(s_n)$ of simple functions $X\rightarrow\Rbb_{\geq0}$ converging pointwise to $f$. By the above special case, for each $n$ there exists $A_n\in\fk M$ with $\mu(X\setminus A_n)=0$ such that $s_n\chi_{A_n}$ is $\fk M$-measurable. Let $A=\bigcap A_n$. Then $s_n\chi_A=s_n\chi_{A_n}\cdot\chi_A$ is $\fk M$-measurable. Since $(s_n\chi_A)$ converges pointwise to $f\chi_A$, by Thm. \ref{lb700}, $f\chi_A$ is $\fk M$-measurable. 
\end{proof}


\begin{thm}[\textbf{Monotone convergence theorem}] \index{00@Monotone convergence theorem}\label{lb760}
Let $(f_n)_{n\in\Zbb_+}$ be an increasing sequence in $\mc L_+(X)$. Let $f$ be the pointwise limit $f=\lim_n f_n$, which is in $\mc L_+(X)$ by Cor. \ref{lb701}. Then
\begin{align*}
\int_X fd\mu=\lim_n\int_Xf_nd\mu
\end{align*}
\end{thm}


Some of the ideas behind the following proof will be explained in Rem. \ref{mc240}.

\begin{proof}
We clearly have ``$\geq$" since $f\geq f_n$ implies $\int f\geq\int f_n$. To prove the other direction, by Rem. \ref{lb746}, it suffices to choose any $s\in\mc S_+(X)$ satisfying $s\leq f$ and $s<+\infty$, and show that $\int_Xs\leq\lim_n\int_X f_n$. Since for any $0<\gamma<1$ we have $\gamma\int_Xs=\int_X\gamma s$, by replacing $s$ with $\gamma s$, we assume that $s(x)<f(x)$ for any $x\in X$ such that $s(x)>0$. 

The idea is to show that for sufficiently large $n$, we have $f_n>s$ on a sufficiently large region. Write $s$ as a finite sum $s=\sum_i a_i\chi_{E_i}$ where $a_1,a_2,\dots\in\Rbb_{>0}$, and $E_1,E_2,\dots\in\fk M$ are mutually disjoint. For each $i$, let
\begin{align}\label{eq567}
E_{i,n}=\{x\in E_i:f_n(x)>s(x)\}=\{x\in E_i:f_n(x)>a_i\}
\end{align}
which is in $\fk M$. Then $f_n\geq\sum_i a_i\chi_{E_{i,n}}$. Thus, by Def. \ref{lb747}, we have
\begin{align*}
\int_X f_n\geq\sum_i a_i\mu(E_{i,n})
\end{align*}
Clearly $(E_{i,n})_{n\in\Zbb_+}$ is increasing. Since $f>s$ on $E_i$, we have $\bigcup_n E_{i,n}=E_i$. Therefore, by Prop. \ref{lb748}-(b) (which is a consequence of the countable additivity of $\mu$), $\lim_n\mu(E_{i,n})=\mu(E_i)$. So $\lim_n\int_Xf_n\geq\sum_i a_i\mu(E_i)=\int_Xs$ because the map $t\in\Rbb_{\geq0}\mapsto a_it$ is continuous.
\end{proof}

Readers are encouraged to compare the above proof with the proof of the bounded convergence theorem using convergence in measure. See Rem. \ref{mc240} and Subsec. \ref{lb763} for details.


We are now ready to prove:
\begin{pp}\label{lb1017}
The map $\int_X:\mc L_+(X)\rightarrow\ovl\Rbb_{\geq0}$ is $\ovl\Rbb_{\geq0}$-linear.
\end{pp}

\begin{proof}
Let $f,g\in\mc L_+(X)$. By Prop. \ref{lb749}, there are increasing sequences $(s_n)$ and $(t_n)$ in $\mc S_+(X)$ converging pointwise to $f$ and $g$ respectively. Then $(s_n+t_n)_{n\in\Zbb_+}$ is increasing and converges pointwise to $f+g$. By the linearity of $\int_X$ on $\mc S_+(X)$ (Prop. \ref{lb750}), we have $\int(s_n+t_s)=\int s_n+\int t_n$. Taking $\lim_n$ and applying the monotone convergence theorem, we have $\int (f+g)=\int f+\int g$. That $\int cf=c\int f$ for all $c\in\ovl\Rbb_{\geq0}$ can be proved in a similar way using Lem. \ref{lb790}. %\footnote{When $c<+\infty$, the formula $\int cf=c\int f$ can be checked directly. In fact, we must check it directly because we have used this relation in the proof of the monotone convergence Thm. \ref{lb760}. Then we can prove the tricky case $c=+\infty$ using Thm. \ref{lb760}.}
\end{proof}

\begin{lm}\label{lb790}
The multiplication map $(a,b)\in\ovl\Rbb_{\geq0}\times \ovl\Rbb_{\geq0}\rightarrow ab\in\ovl\Rbb_{\geq0}$ is left continuous, i.e., if $(a_i)_{i\in I}$ and $(b_j)_{j\in J}$ are increasing nets in $\ovl\Rbb_{\geq0}$ converging to $a,b$ respectively, then $\lim_{i,j}a_ib_j=ab$.
\end{lm}

\begin{proof}
This is easy to check. 
\end{proof}


\begin{co}\label{lb761}
Let $A,B\in\fk M$ be disjoint. Let $f\in\mc L_+(X)$. Then $\int_{A\cup B}f=\int_Af+\int_Bf$
\end{co}

\begin{proof}
$\int_{A\cup B}f=\int_X f\chi_{A\cup B}=\int_X(f\chi_A+f\chi_B)=\int_X f\chi_A+\int_Xf\chi_B=\int_Af+\int_Bf$.
\end{proof}





\subsubsection{Criteria for $f=0$ a.e. and $f<+\infty$ a.e.}


\begin{pp}\label{lb752}
Let $f\in\mc L_+(X)$. The following are true.
\begin{enumerate}
\item[(a)] We have $\int_X fd\mu=0$ iff $f=0$ a.e..
\item[(b)] Suppose that $\int_Xfd\mu<+\infty$. Then  $f<+\infty$ a.e.. In other words, there is a null set $\Delta\subset X$ such that $f(x)<+\infty$ for all $x\in X\setminus\Delta$. 
\end{enumerate}
\end{pp}

Note that part (a) generalizes Exp. \ref{lb599}.

\begin{proof}
Proof of (a). Assume that $\int_Xf>0$. By the definition of integrals, there is a simple function $\leq f$ whose integral is positive. Thus, there exists $E\in\fk M$ and $a\in\ovl\Rbb_{\geq0}$ such that $a\chi_E\leq f$, and that $a\mu(E)=\int_X a\chi_E>0$. So $\mu(E)>0$ and $a>0$. Thus $f$ is non-zero on the non-null measurable set $E$.

Conversely, assume that $\int_Xf=0$. For each $n\in\Zbb_+$, let $E_n=f^{-1}[1/n,+\infty]$. Then $n^{-1}\chi_{E_n}\leq f$ and hence $\int_Xf\geq \int_X n^{-1}\chi_{E_n}=n^{-1}\mu(E_n)$. So $\mu(E_n)=0$. So $E=\bigcup_n E_n$ is null, and $f$ is zero outside $E$.

Proof of (b). Let $\Delta=f^{-1}\{+\infty\}$. Assume that $\mu(\Delta)>0$. Then $\int_Xfd\mu\geq \int_X (+\infty)\cdot\chi_\Delta d\mu=(+\infty)\cdot\mu(\Delta)=+\infty$, and hence $\inf_Xfd\mu=+\infty$.
\end{proof}







\subsection{Integrals of complex functions}

Let $(X,\fk M,\mu)$ be a measure space. In the last section, we have defined the integral operator $\int_X$ on $\mc L_+(X)$. Restricting to $\mc L(X,\Rbb_{\geq0})$, we have an $\Rbb_{\geq0}$-linear map $\int_X \mc L(X,\Rbb_{\geq0})\rightarrow\ovl\Rbb_{\geq0}$. In this section, we extend this integral to $\mc L^1(X,\mu)\rightarrow\Cbb$ where \index{L1X@$\mc L^1(X,\mu)=\mc L^1(X,\mu,\Cbb)$}
\begin{align}
\mc L^1(X,\mu)\equiv\mc L^1(X,\mu,\Cbb)=\{f\in\mc L(X,\Cbb):\Vert f\Vert_{L^1}<+\infty\}
\end{align}
and \index{L1@$L^1$ norm $\Vert f\Vert_{L^1}=\Vert f\Vert_1$}
\begin{align}
\Vert f\Vert_{L^1}=\int_X |f|d\mu
\end{align}
is abbreviated to $\Vert f\Vert_1$ when no confusion arises. A function $f:X\rightarrow\Cbb$ is called \textbf{$\mu$-integrable} (or simply \textbf{integrable}) \index{00@Integrable, i.e., $\mu$-integrable} if it is in $\mc L^1(X,\mu)$.

We shall first extend the integral from $\mc L^1(X,\mu,\Rbb_{\geq0})$ to $\mc L^1(X,\mu,\Rbb)$ using a purely algebraic method, where \index{L1X@$\mc L^1(X,\mu,\Rbb_{\geq0})$}
\begin{gather*}
\mc L^1(X,\mu,\Rbb)=\{f\in\mc L(X,\Rbb):\Vert f\Vert_{L^1}<+\infty\}\\
\mc L^1(X,\mu,\Rbb_{\geq0})=\{f\in\mc L(X,\Rbb_{\geq0}):\Vert f\Vert_{L^1}<+\infty\}
\end{gather*}
Then we extend it to $\mc L^1(X,\mu)$ by using Pb. \ref{lb387}.

\begin{rem}
$\mc L^1(X,\mu)$ is a $\Cbb$-linear subspace of $\Cbb^X$. 
\end{rem}

\begin{proof}
Let $f,g\in\mc L^1(X,\mu)$ and $a\in\Cbb$. Clearly $\int|af|=|a|\int|f|<+\infty$. Since $|f+g|\leq|f|+|g|$, we have $\int|f+g|\leq\int(|f|+|g|)=\int|f|+\int|g|<+\infty$.
\end{proof}


\begin{df}\label{lb922}
Let $V$ be an $\Rbb$-vector space. A subset $K\subset V$ is called a \textbf{convex cone} \index{00@Convex cone} if $K$ is an $\Rbb_{\geq0}$-linear subspace of $V$, i.e., for every $u,v\in K$ and $a,b\in\Rbb_{\geq0}$ we have $au+bv\in K$.
\end{df}

\begin{pp}\label{lb751}
Let $K$ be a convex cone in an $\Rbb$-vector space $V$. Let $\wtd V$ be a $\Rbb$-linear space. Let $\Gamma:K\rightarrow \wtd V$ be an $\Rbb_{\geq0}$-linear map. Suppose that $V=\Span_\Rbb K$. Then $\Gamma$ can be extended uniquely to an $\Rbb$-linear map $\Lambda:V\rightarrow \wtd V$. 
\end{pp}


\begin{proof}
The uniqueness is obvious. To prove the existence, note that any $v\in V$ can be written as
\begin{align*}
v=v^+-v^-
\end{align*}
where $v^+,v^-\in K$. (Proof: Since $V=\Span_\Rbb K$, we have $v=a_1u_1+\cdots+a_mu_m-b_1w_1-\cdots-b_nw_n$ where each $u_i,w_j$ are in $K$, and each $a_i,b_j$ are in $\Rbb_{\geq0}$. One sets $v^+=\sum_i a_iu_i$ and $v^-=\sum_j b_jw_j$.) We then define $\Lambda(v)=\Gamma(v^+)-\Gamma(v^-)$. 

Let us show that this gives a well-defined map $\Lambda:V\rightarrow \wtd V$. Assume that $v=w^+-w^-$ where $w^+,w^-\in K$. Then $\Gamma(v^+)-\Gamma(v^-)=\Gamma(w^+)-\Gamma(w^-)$ iff $\Gamma(v^+)+\Gamma(w^-)=\Gamma(v^-)+\Gamma(w^+)$, iff (by the additivity of $\Gamma$) $\Gamma(v^++w^-)=\Gamma(v^-+w^+)$. The last statement is true because $v^+-v^-=w^+-w^-$ implies $v^++w^-=v^-+w^+$.

It is easy to see that $\Lambda$ is additive. If $c\geq0$, then $cv=cv^+-cv^-$ where $cv^+,cv^-\in K$. So $\Lambda(cv)=\Gamma(cv^+)-\Gamma(cv^-)$, which (by the $\Rbb_{\geq0}$-linearity of $\Gamma$) equals $c\Gamma(v^+)-c\Gamma(v^-)=c\Lambda(v)$. Since $-v=v^--v^+$, we have $\Lambda(-v)=\Gamma(v^-)-\Gamma(v^+)=-\Lambda(v)$. Hence $\Lambda(-cv)=c\Lambda(-v)=-c\Lambda(v)$. This proves that $\Lambda$ commutes with the $\Rbb$-multiplication.
\end{proof}


\begin{thm}\label{lb779}
The integral operator $\int_X:\mc L^1(X,\mu,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ can be extended uniquely to a $\Cbb$-linear map
\begin{gather*}
\int_X:\mc L^1(X,\mu)\rightarrow\Cbb\qquad f\mapsto\int_Xf d\mu
\end{gather*}
\end{thm}

\begin{proof}
$K=\mc L^1(X,\mu,\Rbb_{\geq0})$ is a convex cone in $V=\mc L^1(X,\mu,\Rbb)$. Note that any $f\in V$ can be written as $f=f^+-f^-$ where 
\begin{align}\label{eq303}
f^+(x)=\max\{f(x),0\}\qquad f^-(x)=\max\{-f(x),0\}
\end{align}
Then $f^\pm$ are measurable (by Thm. \ref{lb700}), and $f^\pm\in K$ since $0\leq f^\pm\leq f$ and (in particular) $\int f^\pm<+\infty$. This proves that $V=\Span_\Rbb K$. Therefore, by Prop. \ref{lb751}, $\int_X$ can be extended uniquely to an $\Rbb$-linear functional on $\mc L^1(X,\mu,\Rbb)$, i.e., 
\begin{align}\label{eq304}
\int_X f=\int_X f^+-\int_Xf^-
\end{align}

Since $\mc L^1(X,\mu)$ is $\Cbb$-spanned by $\mc L^1(X,\mu,\Rbb)$ (and hence by $K$), the extension of $\int_X$ to $\mc L^1(X,\mu)$ must be unique. We now prove the existence. Let $\Lambda:\mc L^1(X,\mu)\rightarrow\Rbb$ be defined by $\Lambda(f)=\int_X\Real(f)$, noting that $\Real(f)\in\mc L^1(X,\mu,\Rbb)$. Then $\Lambda$ is $\Rbb$-linear. By Pb. \ref{lb387}, we have a $\Cbb$-linear map $\Phi:\mc L^1(X,\mu)\rightarrow\Cbb$ defined by
\begin{align*}
\Phi(f)=\Lambda(f)-\im\Lambda(\im f)=\int_X\Real(f)-\im\int_X\Real(\im f)=\int_X\Real(f)+\im\int_X\Imag(f)
\end{align*}
Then $\Phi$ clearly extends $\int_X:\mc L^1(X,\mu,\Rbb)\rightarrow\Rbb$. 
\end{proof}

To summarize, the integral $\int_X$ of $f\in\mc L^1(X,\mu)$ is defined by
\begin{align}\label{eq305}
\int_Xfd\mu=\int_X\Real(f)d\mu+\im\int_X\Imag(f)d\mu
\end{align}


\begin{pp}\label{lb753}
For each $f\in\mc L^1(X,\mu)$ we have $\dps\Big|\int_Xfd\mu \Big|\leq\int_X|f|d\mu$.
\end{pp}


\begin{proof}
We first assume that $f$ is real. Let $f^\pm$ be defined by \eqref{eq303}. Then $0\leq f^\pm\leq |f|$. So $0\leq\int f^\pm\leq\int |f|$. Hence, by \eqref{eq304}, we have $\int f\leq\int |f|$. Similarly, $\int(-f)\leq\int|f|$. So $|\int f|\leq\int|f|$. 

Now we consider the general case. We first note that
\begin{align}\label{eq306}
\Big| \Real\int_X f \Big|\leq \int_X|f|
\end{align}
(Namely, $\Real\int_X$ has operator norm $\leq 1$ if $\mc L^1(X,\mu)$ is equipped with the seminorm $\Vert\cdot\Vert_{L^1}$.) Indeed, by \eqref{eq305}, for each $f\in\mc L^1(X,\mu)$ we have $|\Real\int_Xf|=|\int_X\Real(f)|$, which, by the first paragraph, is $\leq\int_X|\Real(f)|\leq \int_X |f|$. 


The following argument is similar to that in the solution of Pb. \ref{lb387}-3. Choose $\theta\in\Rbb$ such that $e^{\im\theta}\int f\in\Rbb$. So $\int e^{\im\theta} f\in\Rbb$. By \eqref{eq306}, we have
\begin{align*}
\Big|\int_Xf\Big|=\Big|\int_X e^{\im\theta}f\Big|=\Big|\Real\int_X e^{\im\theta}f\Big|\leq\int_X|e^{\im\theta}f|=\int_X|f|
\end{align*}
\end{proof}



\begin{co}\label{lb852}
Let $f,g\in\mc L(X,\Cbb)$. Assume that there is a measurable $A\subset X$ such that $X\setminus A$ is null, and that $f|_A=g|_A$. Then $f$ is integrable iff $g$ is integrable. If they are integrable, then $\int_Xf=\int_Xg$.
\end{co}

\begin{proof}
By Prop. \ref{lb752} we have $\int_X|f|=\int_X |f|\chi_A=\int_X|g|\chi_A=\int_X|g|$. Thus $\int|f|<+\infty$ iff $\int|g|<+\infty$. Suppose that $\int|f|<+\infty$. Since $f-g=0$ a.e., by Prop. \ref{lb752}, we have $\int |f-g|=0$. By Prop. \ref{lb753}, we get $\int f-\int g=0$.
\end{proof}


%% Record #8 2024/03/21 three lectures  20


\begin{eg}\label{lb766}
Let $X$ be a set, equipped with the counting measure $\mu$ on the $\sigma$-algebra $2^X$ (cf. Exp. \ref{lb765}). Then for each $f:X\rightarrow[0,+\infty]$, we have
\begin{align}
\sum_{x\in X}f(x)=\sup_{A\in\fin(2^X)}\sum_{x\in A}f(x)=\int_X fd\mu
\end{align}
Therefore, for each $f\in\Cbb^X$ we have $f\in\mc L^1(X,\mu)$ iff $\sum_{x\in X}|f(x)|<+\infty$. Namely, 
\begin{align}
\mc L^1(X,\mu)=l^1(X)
\end{align}
The linear maps $f\in l^1(X)\mapsto\sum_{x\in X}f(x)$ and $f\in \mc L^1(X,\mu)\rightarrow \int_X fd\mu$ are equal, since they are equal on the subset of all positive $l^1$-functions (which spans $l^1(X)$).
\end{eg}


\begin{pp}\label{lb780}
Let $f\in\scr R[a,b]=\scr R([a,b],\Cbb)$ where $-\infty<a<b<+\infty$. Then $f\in\mc L^1([a,b],m)$, and the Riemann integral of $f$ equals the Lebesgue integral:
\begin{align}\label{eq313}
\int_a^b f(x)dx=\int_{[a,b]}fdm
\end{align} 
\end{pp}

\begin{proof}
By considering the real part and the imaginary part separately, it suffices to assume that $f$ is real. Let $S$ be the set of real step functions on $[a,b]$, i.e., $S=\Span_\Rbb\{\chi_{[c,d]}:a\leq c\leq d\leq b \}$. Then \eqref{eq313} clearly holds when $f\in S$. 

Now pick any $f\in\scr R([a,b],\Rbb)$. Since $f$ is strongly Riemann integrable (Def. \ref{lb774}), for each $\eps>0$, there is a partition of $[a,b]$ into compact subintervals $I_1\cup I_2\cup\cdots$ such that $\sum_i \diam f(I_i)\cdot|I_i|<\eps$. Let 
\begin{align*}
g=\sum_i \inf f(I_i)\cdot\chi_{I_i}\qquad h=\sum_i\sup f(I_i)\cdot\chi_{I_i}
\end{align*}
Then $g\leq f\leq h$, and $\int_a^b (h(x)-g(x))dx=\sum_i \diam f(I_i)\cdot|I_i|<\eps$. Since $g,h,h-g\in S$, their Riemann integrals and Lebsgue integrals are equal. (In particular, $\int_{[a,b]}(h-g)dm<\eps$.) If we can show that $f$ is Lebesgue measurable, then $f\in \mc L^1([a,b],m)$ (because $f$ is bounded), and 
\begin{align*}
\int_a^bg(x)dx\leq \int_a^bf(x)dx\leq\int_a^b h(x)dx\qquad \int_{[a,b]}gdm\leq \int_{[a,b]}fdm\leq\int_{[a,b]}hdm
\end{align*}
This implies $|\int_a^bf(x)dx-\int_{[a,b]}fdm|<2\eps$ for arbitrary $\eps$. Hence \eqref{eq313} is true.

By the above discussion, we can choose step functions $g_n,h_n$ such that $g_n\leq f\leq h_n$ and $\int (h_n-g_n)dm<1/n$. Replacing $g_n$ with $\max\{g_1,\dots,g_n\}$ and $h_n$ with $\min\{h_1,\dots,h_n\}$, we can assume that $(g_n)$ is increasing and $(h_n)$ is decreasing. Thus, they converge pointwise to $g,h:[a,b]\rightarrow\Rbb$ respectively. Since $g_n,h_n$ are Borel functions, by Thm. \ref{lb700}, $g,h$ are also Borel. Clearly $g\leq f\leq h$. Since $0\leq h-g\leq h_n-g_n$, we have $\int(h-g)dm<1/n$ for all $n$, and hence $\int(h-g)dm=0$. By Prop. \ref{lb752}, $\{x\in[a,b]:h(x)>g(x)\}$ is a Borel $m$-null set. Since the Lebesgue measure $m$ is complete (Thm. \ref{lb800}), the subset $\{x\in[a,b]:f(x)>g(x)\}$ is Lebesgue measurable and null. Therefore, $f$ and $g$ differ by a Lebesgue null set. By Prop. \ref{lb1032}, $f$ is Lebesgue measurable.
\end{proof}



\begin{rem}\label{mc240}
We end this section by discussing the difference in philosophy embodied in the construction of $\int_Xfd\mu$ in this chapter and the one given in Sec. \ref{lb722}. The integral in Sec. \ref{lb722} is defined by partitioning the codomain. As already mentioned at the end of Subsec. \ref{lb762}, this method is not very convenient when $f$ is unbounded, or when $\mu$ is not a finite (or $\sigma$-finite) measure. 

However, the partition of codomain  matches perfectly the proof of the dominated convergence theorem (DCT). The key idea behind the (historical) proof of that theorem is \textbf{convergence in measure}: Suppose that a uniformly bounded sequence of measurable functions $(f_n)$ on a finite $\mu$-measure $X$ converges pointwise to $0$. To show that $\int_{X} f_nd\mu$ converges to zero, one shows that for each $\eps>0$, the measure of $A_n=\{x\in X:|f_n(x)|>\eps\}$ converges to $0$. But note that $A_n$ is obtained by partitioning the codomain of $|f|$ into two parts: $[0,\eps)$ and $[\eps,+\infty)$.

The proof of DCT via convergence in measure can be found in Subsec. \ref{lb763}. Although this is the ``historically correct" proof, it is not the most compatible with the construction of integrals introduced in this chapter, i.e., first defining the integral operator $\int_X d\mu$ on simple functions, then extending it to $\mc L_+(X)$, and then (partially) extending it to $\mc L^1(X,\mu)$. In contrast to the method of partition of codomain which is closely related to the proof of DCT via convergence in measure, this method of extending the integral operators has its roots in the proof of the Riesz representation theorem, and also in Riesz's proof of spectral theorem for bounded self-adjoint operators on Hilbert spaces. We will discuss this in more details in Sec. \ref{lb833}, Subsec. \ref{lb923}, Sec. \ref{lb896}, and Sec. \ref{lb1100}.


One last comment: In the next section, we will prove DCT as an easy consequence of the monotone convergence theorem (MCT). However, convergence in measure is also implicit in our proof of MCT. Indeed, the set $E_{i,n}=\eqref{eq567}$ plays a similar role to the set $A_n$ (or rather, the set $X\setminus A_n$) mentioned above.   \hfill\qedsymbol
\end{rem}





\subsection{The convergence theorems}\label{lb754}

Let $(X,\fk M,\mu)$ be a measure space.


\begin{thm}\label{lb829}
Assume that $\mu(X)<+\infty$. Let $(f_\alpha)$ be a net in $\mc L^1(X,\mu)$ converging uniformly to $f:X\rightarrow\Cbb$. Then $f\in\mc L^1(X,\mu)$, and $\dps\lim_\alpha\int_Xf_\alpha d\mu=\int_X fd\mu$.
\end{thm}

\begin{proof}
For each $n\in\Zbb_+$, there is $\alpha_n$ such that $\Vert f-f_{\alpha_n}\Vert_{l^\infty}\leq 1/n$. Thus $(f_{\alpha_n})$ converges uniformly to $f$. Hence $f$ is measurable (by Cor. \ref{lb701}), and $|f|\leq |f_{\alpha_1}|+1$. So $\int|f|\leq\int|f_{\alpha_1}|+\mu(X)<+\infty$. This proves $f\in\mc L^1(X,\mu)$. 

For each $\alpha$, let $\lambda_\alpha=\Vert f-f_\alpha\Vert_{l^\infty}$. Then $\int |f-f_\alpha|\leq \int \lambda_\alpha=\lambda_\alpha\cdot\mu(X)$. Since $\lim_\alpha \lambda_\alpha=0$, and since $|\int f-\int f_\alpha|\leq \int|f-f_\alpha|$ (by Prop. \ref{lb753}), we have $\lim_\alpha |\int f-\int f_\alpha|=0$.
\end{proof}

\subsubsection{The dominated convergence theorem}


The following celebrated theorem was proved by Lebesgue in 1904. In fact, in Lebesgue's original theorem, instead of assuming $|f_n|\leq g$, the stronger conditions that $\mu(X)<+\infty$ and $\sup_n\Vert f_n\Vert_{l^\infty}<+\infty$ were assumed. Moreover, unlike the following proof, Lebesgue's original proof did not use the monotone convergence theorem since the latter was proved by Beppo Levi in 1906. We will explain Lebesgue's original proof in Subsec. \ref{lb763}.

\begin{thm}[\textbf{Dominated convergence theorem}] \index{00@Dominated convergence theorem}\label{lb755}
Suppose that $(f_n)$ is a sequence in $\mc L(X,\Cbb)$ converging pointwise to $f:X\rightarrow\Cbb$. Suppose that there exists $g\in\mc L^1(X,\mu,\Rbb_{\geq0})$ such that $|f_n|\leq g$ for all $n$. Then $f_n,f\in\mc L^1(X,\mu)$, and 
\begin{align*}
\lim_{n\rightarrow\infty}\int_X f_nd\mu=\int_Xfd\mu
\end{align*}
\end{thm}

%In the following proof, and especially in Step 1 (which is the case that Lebesgue originally considered in his 1902 paper), the reader should pay particular attention to how the countable additivity is used

\begin{proof}
By Cor. \ref{lb701}, $f$ is measurable. Clearly $f_n,f\leq g$. So $\int|f_n|,\int|f|\leq\int g<+\infty$. Therefore $f_n,f\in\mc L^1(X,\mu)$. To show that $\lim_n\int f_n=\int f$, since  $|\int f_n-\int f|\leq\int |f-f_n|$ (by Prop. \ref{lb753}), it suffices to prove $\lim_n\int|f_n-f|=0$. Note that $|f_n-f|\leq 2g$. Therefore, by replacing $f_n$ with $|f_n-f|$, it suffices to assume
\begin{itemize}
\item $(f_n)$ is a sequence in $\mc L^1(X,\mu,\Rbb_{\geq0})$ converging pointwise to $0$, and there exists $g\in\mc L^1(X,\mu,\Rbb_{\geq0})$ such that $|f_n|\leq g$ for all $n$.
\end{itemize}
We shall prove $\lim_n \int_Xf_n=0$.

If $(f_n)$ is decreasing (i.e. $f_1\geq f_2\geq\cdots$), then $g-f_n$ is increasing to $g$. Since $\int g<+\infty$, and since the monotone convergence theorem implies that $\int g-\int f_n$ converges to $\int g$, we conclude $\lim_n \int f_n=0$.

In the general case, we let $h_n(x)=\sup_{k\geq n}\{f_n(x)\}$. Then $h_n$ is measurable by Thm. \ref{lb700}. Since $\lim_n h_n(x)=\limsup_n f_n(x)=0$, we conclude that $(h_n)$ is a decreasing sequence in $\mc L^1(X,\mu,\Rbb_{\geq0})$ bounded by $g$ and converging pointwise to $0$. Therefore, by the above paragraph, we get $\lim_n\int h_n=0$. Since $f_n\leq h_n$, we have $\lim_n\int f_n=0$.
\end{proof}


\subsubsection{Applications of the dominated convergence theorem}

\begin{co}\label{lb775}
Let $Y$ be a metric space. Let $f:X\times Y\rightarrow\Cbb$. Let $y_0\in Y$. Assume that the following conditions are satisfied:
\begin{enumerate}[label=(\alph*)]
\item For each $y\in Y$, the function $f(\cdot,y):X\rightarrow\Cbb$ is in $\mc L^1(X,\mu)$.
\item For each $x\in X$, the function $f(x,\cdot):Y\rightarrow\Cbb$ is continuous at $y_0$.
\item There exists $g\in\mc L^1(X,\mu,\Rbb_{\geq0})$ such that $|f(x,y)|\leq g(x)$ for all $x\in X,y\in Y$.
\end{enumerate}
Then the map $y\in Y\mapsto\int_Xf(x,y)d\mu(x)$ is continuous at $y_0$.
\end{co}


\begin{proof}
Choose any sequence $(y_n)$ in $Y$ converging to $y_0$. Since $|f(\cdot,y_n)|\leq g$, and since $\lim_n f(\cdot,y_n)$ converges pointwise to $f(\cdot,y_0)$, by the dominated convergence theorem, we have $\lim_n\int f(\cdot,y_n)d\mu=\int f(\cdot,y_0)d\mu$.
\end{proof}

The following corollary generalizes Thm. \ref{lb434}.

\begin{co}\label{lb776}
Let $I=[a,b]$ be a compact interval. Assume that $f:X\times I\rightarrow\Cbb$ satisfies the following conditions:
\begin{enumerate}[label=(\alph*)]
\item For each $t\in I$, the function $f(\cdot,y):X\rightarrow\Cbb$ is in $\mc L^1(X,\mu)$.
\item For each $x\in X$, the function $f(x,\cdot):I\rightarrow\Cbb$ is differentiable. 
\item There exists $g\in\mc L^1(X,\mu,\Rbb_{\geq0})$ such that $|\partial_If(x,t)|\leq g(x)$ for all $x\in X,t\in I$.
\end{enumerate}
Then $t\in I\rightarrow\int_X f(x,t)d\mu(x)$ is differentiable, and its derivative is $\int_X\partial_If(x,t)d\mu(x)$ where $\partial_If(\cdot,t):X\rightarrow\Cbb$ is in $\mc L^1(X,\mu)$.
\end{co}

\begin{proof}
Fix $t_0\in I$. For any sequence in $I\setminus\{t_0\}$ converging to $t_0$, $\partial_If(\cdot,t_0)$ is the pointwise limit of the measurable function $h_n=(f(\cdot,t_n)-f(\cdot,t_0))/(t_n-t_0)$ on $X$, which is measurable by Cor. \ref{lb701}. By the finite increment theorem (Cor. \ref{lb333}), we have $|h_n|\leq g$. Thus $h_n\in\mc L^1(X,\mu,\Rbb_{\geq0})$. Since $h_n$ converges pointwise to $\partial_If(\cdot,t_0)$, the dominated convergence theorem shows that $\lim_n \int_Xh_nd\mu=\int_X\partial_If(\cdot,t_0)d\mu$.
\end{proof}






\subsubsection{Fatou's lemma}

The dominated convergence theorem fails when $(f_n)$ is not bounded by a positive $\mc L^1$-function.


\begin{eg}
Let $f_n:(0,1)\rightarrow\Cbb$ be $f_n=n\cdot\chi_{(0,1/n)}$. Then $(f_n)$ converges pointwise to $0$, but $\lim_n \int_{(0,1)}f_ndm=1$.
\end{eg}

\begin{eg}
Equip $\Zbb$ with the counting measure. (Recall Exp. \ref{lb766}.) Let $(f_n)_{n\in\Zbb_+}$ be a sequence in $\ovl B_{l^2(\Zbb)}(0,1)$ converging weakly to $f\in \ovl B_{l^2(\Zbb)}(0,1)$. In other words, $(f_n)$ converges pointwise to $f$ as a sequence of functions on $\Zbb$ (cf. Thm. \ref{lb530}). By Fatou's lemma for inner product spaces (cf. Cor. \ref{lb764}), we know that $\liminf_n \Vert f_n\Vert^2\geq \Vert f\Vert^2$, where the inequality can be strict (e.g. take $f_n=\chi_{\{n\}}$ and $f=0$). Thus, $g_n=|f_n|^2$ converges pointwise to $g=|f|^2$, but
\begin{align*}
\liminf_n\sum_\Zbb g_n\geq\sum_\Zbb g
\end{align*}
where the inequality could be strict.
\end{eg}


Motivated by the above two examples, we prove Fatou's lemma for integrals, which asserts that $\int_X:\mc L_+(X)\rightarrow\ovl\Rbb_{\geq0}$ is ``lower semicontinuous" under \textit{sequential} pointwise convergence. (It is not true for nets of functions. See Rem. \ref{lb769}.)


\begin{thm}[\textbf{Fatou's lemma}] \index{00@Fatou's lemma} \label{lb768}
Let $(f_n)$ be a sequence in $\mc L_+(X)$ converging pointwise to $f:X\rightarrow\ovl\Rbb_{\geq0}$. Then $f\in\mc L_+(X)$, and
\begin{align}\label{eq311}
\liminf_{n\rightarrow\infty}\int_X f_nd\mu\geq\int_Xfd\mu
\end{align}
\end{thm}

%The idea of the proof is to find a sequence $(g_n)$ in $\mc L_+(X)$ dominated by $f$ and converging pointwise to $f$ such that $g_n\leq f_n$. Then, when $\int f<+\infty$, the dominated convergence theorem implies $\lim\int g_n=\int f$, and hence \eqref{eq311} follows. When $\int f=+\infty$, this argument needs to be modified.

\begin{proof}
%By Thm. \ref{lb700} we have $f\in\mc L_+(X)$ and $g_n\in\mc L_+(X)$ where $g_n(x)=\min\{f_n(x),f(x)\}$. Note that $0\leq g_n\leq f$, and $(g_n)$ converges pointwise to $f$. So $\liminf_n\int f_n\geq\liminf_n\int g_n$. Thus, it suffices to prove
%\begin{align}\label{eq310}
%\liminf_{n\rightarrow\infty}\int_X g_nd\mu\geq\int_Xfd\mu
%\end{align}
%If $\int_Xf<+\infty$, the dominated convergence theorem implies $\lim_n\int_X g_n=\int_Xf$. So \eqref{eq310} is true. Since we do not assume $\int_Xf<+\infty$, we need to find another argument.
Let $g_n=\inf_{k\geq n}f_k$. Then $g_n\in\mc L_+(X)$ by Thm. \ref{lb700}, and $(g_n)$ converges pointwise to $\liminf_n f_n=f$. Since $g_1\leq g_2\leq\cdots$, by the monotone convergence Thm. \ref{lb760}, we get $\lim_n\int_X g_n=\int_Xf$. Since $f_n\geq g_n$, we get $\liminf_n\int_Xf_n\geq\lim_n\int_Xg_n$. This proves \eqref{eq311}. %\footnote{This strategy of proving the commutativity of integrals and limits by reducing to monotonic sequences of functions has been used in the proof of the dominated convergence Thm. \ref{lb755}.}
\end{proof}



\begin{exe}
Although we proved the dominated convergence theorem and Fatou's lemma using the monotone convergence theorem, the latter theorem is an immediate consequence of the first two. Explain the reason.
\end{exe}


\begin{rem}\label{lb769}
Equip $\mc L_+(X)$ with the pointwise convergence topology (i.e., the one inherited from $[0,+\infty]^X$). Then the map $\int_X:\mc L_+(X)\rightarrow\ovl\Rbb_{\geq0}$ is not necessarily lower semicontinuous. For example, take $X=[0,1]$ and $\mu=m$. Then the net $\{\chi_A\}_{A\in\fin(2^X)}$ converges pointwise to $1$. So $\liminf_A\int_X \chi_A=0<1=\int_X\lim_A\chi_A$. (Recall Pb. \ref{lb767} for the equivalent definition of lower semicontinuity in terms of nets.)
\end{rem}

The following version of Fatou's Lemma appears in many textbooks. However, we will not use this version in the future. (The result orginally proved by Fatou is in the form \eqref{eq311}, not in the form \eqref{eq312}. See \cite[Ch. 6, Thm. 6.6]{Haw}.)

\begin{sexe}[\textbf{Fatou's lemma}]
Let $(f_n)$ be a sequence in $\mc L_+(X)$. Prove
\begin{align}\label{eq312}
\liminf_{n\rightarrow\infty}\int_X f_nd\mu\geq\int_X\liminf_{n\rightarrow\infty}f_nd\mu
\end{align}
by mimicking the proof of Thm. \ref{lb768} (i.e., applying the monotone convergence theorem to $g_n=\inf_{k\geq n}f_k$)
\end{sexe}

Thm. \ref{lb768} and Cor. \ref{lb764} (see also Prop. \ref{lb770}) suggest that sequential pointwise convergence is related to weak or weak-* convergence. We will discuss this relationship in Pb. \ref{lb912}.








\subsection{Problems and supplementary material}

Unless otherwise stated, we let $(X,\fk M,\mu)$ be a measure space.




\begin{prob}\label{lb328}
Let $h\in\mc L_+(X)=\mc L_+(X,\fk M)$, i.e., $f$ is an $\fk M$-measurable function $X\rightarrow\ovl\Rbb_{\geq0}$. Prove that there is a unique measure $\nu$ on $\fk M$ such that
\begin{align}\label{eq307}
\int_X f d\nu=\int_Xfhd\mu
\end{align}
for all $f\in\mc L_+(X)$. We write \index{d@$d\nu=hd\mu$}
\begin{align}
d\nu=hd\mu
\end{align}
\end{prob}
\begin{proof}[Hint]
Define $\nu:\fk M\rightarrow[0,+\infty]$ to be $\nu(E)=\int_X \chi_Ehd\mu$. Prove that $\nu$ is a measure. First prove \eqref{eq307} when $f$ is a simple function. Then prove \eqref{eq307} for any $f\in\mc L_+(X)$.
\end{proof}

\begin{prob}\label{lb858}
Let $h,\nu$ be as in Pb. \ref{lb328}. Let $(\ovl{\fk M},\ovl\mu)$ be the completion of $\mu$. Let $(\fk N,\ovl\nu)$ be the completion of $\nu$. Prove that $\ovl{\fk M}\subset\fk N$. Prove that $d\ovl\nu=hd\ovl\mu$ on $\ovl{\fk M}$.
\end{prob}

\begin{sprob}\label{lb1035}
Let $(X,\fk M)$ be a measurable space, and let $\mu,\nu:\fk M\rightarrow[0,+\infty]$ be measures. Let $g:X\rightarrow\Rbb_{\geq0}$ be measurable. We say that $g$ is a \textbf{Radon-Nikodym derivative} \index{00@Radon-Nikodym derivative} of $\mu$ with respect to $\nu$ if $d\mu=gd\nu$. 

Assume that $\nu$ is $\sigma$-finite. Prove that if $g,h$ are Radon-Nikodym derivatives of $\mu$ with respect to $\nu$, then $g=h$ outside a $\nu$-null set.
\end{sprob}



\subsubsection{$\star$ Bochner integrals}\label{lb979}


Let $\mc V$ be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$. Recall that $\mc V^*=\fk L(\mc V,\Fbb)$ is the dual space. Recall that $\mc L(X,\mc V)$ is the set of measurable functions $X\rightarrow\mc V$.

\begin{df}\label{lb773}
A function $f:X\rightarrow\mc V$ is called \textbf{weakly integrable} \index{00@Weakly integrable} if $f$ is weakly measurable (cf. Def. \ref{lb710}), and if there exists an element $\int_Xfd\mu$ in $\mc V$ (often abbreviated to $\int_Xf$ or $\int f$) such that for every $\varphi\in\mc V^*$ we have
\begin{align}
\Bigbk{\varphi,\int_Xfd\mu}=\int_X\varphi\circ fd\mu
\end{align}
Note that such vectors $\int_Xfd\mu$ are unique because $\mc V^*$ separates points of $\mc V$ by the Hahn-Banach Cor. \ref{lb502}.
\end{df}


\begin{prob}\label{lb772}
Assume that $f:X\rightarrow\mc V$ is weakly integrable, and its absolute value function $|f|:X\rightarrow\Rbb_{\geq0}$ is measurable. Prove
\begin{align}
\Big\Vert \int_Xfd\mu \Big\Vert\leq\int_X|f|d\mu
\end{align}
\end{prob}
\begin{proof}[Hint]
Use the Hahn-Banach Cor. \ref{lb502}.
\end{proof}

Pb. \ref{lb772} will be helpful in solving the following problems.

\begin{prob}
Let $\mc W$ be a Banach space. Let $T\in\fk L(\mc V,\mc W)$. Let $f:X\rightarrow\mc V$. Prove that if $f$ is weakly measurable, then $T\circ f$ is weakly measurable. Prove that if $f$ is weakly integrable, then $T\circ f$ is weakly integrable, and 
\begin{align}
T\int_Xfd\mu=\int_X T\circ fd\mu
\end{align}
\end{prob}


Recall that $\mc V$, as a topological space, is equipped with the Borel $\sigma$-algebra $\mc B_{\mc V}$. In the following, we let
\begin{align}
\mc L_B(X,\mc V)=\{f\in\mc L(X,\mc V):f(X)\text{ is a separable subset of }\mc V\}
\end{align}
(Equivalently, $\mc L_B(X,\mc V)$ is the set of weakly measurable $f:X\rightarrow\mc V$ with separable $f(X)$. See Pb. \ref{lb702}.) A function $f:X\rightarrow\mc V$ is called \textbf{Bochner measurable} \index{00@Bochner integrable} if $f\in\mc L_B(X,\mc V)$.\footnote{In fact, in the usual definition, a function $f$ is called Bochner integrable if $f\in\mc L(X,\mc V)$, and if $f(X\setminus\Delta)$ is separable for some null set $\Delta$. Here, we do not bother with null sets.} 


\begin{eg}
Suppose that $X$ is a second countable LCH space and $\fk M=\fk B_X$. Let $f:X\rightarrow\mc V$ be continuous. Then $f$ is measurable. Since $X$ is a union of precompact open subsets, and since $X$ is Lindel\"of (by Cor. \ref{lb265}), $X$ is a countable union of precompact open subsets $X=\bigcup_n U_n$. Since $f(\ovl U_n)$ is a compact metric subspace of $\mc V$, it is separable (Thm. \ref{lb252}). Therefore $f(X)$ is a countable union of separable subsets, and hence is separable. This proves $f\in \mc L_B(X,\mc V)$.
\end{eg}

\begin{prob}\label{lb949}
Solve the following problems.
\begin{enumerate}
\item  Let $f\in\mc V^X$ have separable range $f(X)$. Prove that $f\in\mc L_B(X,\mc V)$ iff there is a separable closed linear subspace $\mc W\subset\mc V$ such that $f(X)\subset\mc W$ and that the restriction $f:X\rightarrow\mc W$ is measurable.
\item Prove that $\mc L_B(X,\mc V)$ is an $\Fbb$-linear subspace of $\mc V^X$.
\item Let $f\in\mc L_B(X,\mc V)$. Since $f$ is measurable, it is weakly measurable, and $|f|\in\mc L_+(X)$. Define
\begin{gather}
\Vert f\Vert_{L^1}\equiv \Vert f\Vert_1=\int_X|f|d\mu\\
\mc L^1(X,\mu,\mc V)=\big\{f\in\mc L_B(X,\mc V):\Vert f\Vert_{L^1}<+\infty  \}
\end{gather}
Elements in $\mc L^1(X,\mu,\mc V)$ are called \textbf{strongly integrable} (or \textbf{Bochner integrable}). \index{00@Strongly integrable}Prove that $\mc L^1(X,\mu,\mc V)$ is a linear subspace of $\mc L_B(X,\mc V)$. Prove that $\Vert\cdot\Vert_{L^1}$ is a seminorm on  $\mc L^1(X,\mu,\mc V)$, i.e., it satisfies
\begin{gather}
\Vert cf\Vert_{L^1}=|c|\cdot\Vert f\Vert_{L^1}\qquad \Vert f+g\Vert_{L^1}\leq\Vert f\Vert_{L^1}+\Vert g\Vert_{L^1}
\end{gather}
for all $f,g\in\mc L^1(X,\mu,\mc V)$ and $c\in\Fbb$.
\item Let $T\in\fk L(\mc V,\mc W)$ where $\mc W$ is a Banach space. Let $f\in\mc L_B(X,\mc V)$. Prove that $T\circ f\in\mc L_B(X,\mc W)$, and
\begin{align}
\Vert T\circ f\Vert_{L^1}\leq \Vert T\Vert\cdot\Vert f\Vert_{L^1}
\end{align}
\end{enumerate}
\end{prob}

\begin{proof}[Note]
When you prove that $\mc L_B(X,\mc V)$ is closed under addition, pay special attention to the fact that Prop. \ref{lb699} (i.e., $f,g$ measurable $\Rightarrow$ $f\vee g$ measurable) is available only when the codomains of $f,g$ are second countable.
\end{proof}


\begin{thm}\label{lb771}
Let $f\in\mc L^1(X,\mu,\mc V)$. Then $f$ is weakly integrable. The integral $\int_Xfd\mu$ (which is in $\mc V$) is called the \textbf{Bochner integral} of $f$. \index{00@Bochner integral}
\end{thm}


\begin{prob}\label{lb948}
The goal of this problem is to prove Thm. \ref{lb771}. Let
\begin{align}
\mc S^1(X,\mu,\mc V)=\Big\{\sum_{i=1}^n v_i\cdot\chi_{E_i}:n\in\Zbb_+,v_i\in \mc V,E_i\in\fk M,\mu(E_i)<+\infty\Big\}
\end{align}
In other words, $\mc S^1(X,\mu,\mc V)$ is the set of all $f\in\mc S(X,\mc V)$ such that $\int_X|f|d\mu<+\infty$.
\begin{enumerate}
\item Prove that any $f\in\mc S^1(X,\mu,\mc V)$ is weakly integrable. (What is the explicit expression of $\int_Xf$ ?)
\item Let $f$ be defined by the pointwise limit $f=\sum_{n=1}^\infty v_n\cdot\chi_{E_n}$ where $v_1,v_2,\dots\in\mc V$, and $E_1,E_2,\dots\in\fk M$ are mutually disjoint. Prove that $f\in\mc L_B(X,\mc V)$, and that
\begin{align}
\Vert f\Vert_{L^1}=\sum_{n=1}^\infty \mu(E_n)\Vert v_n\Vert
\end{align}
\item Prove that $\mc S^1(X,\mu,\mc V)$ is dense in $\mc L^1(X,\mu,\mc V)$ under the $L^1$-seminorm.
\item Use Part 1 and 3 to prove that every $f\in\mc L^1(X,\mu,\mc V)$ is weakly integrable.
\end{enumerate}
\end{prob}

Note: The completeness of $\mc V$ is only used in part 4.

\begin{proof}[Hint]
Part 2. Use Pb. \ref{lb705} to show that $f$ is measurable.

Part 3. For each $k\in\Zbb_+$, let $A_k=|f|^{-1}([1/k,k])$ and $f_k=f\cdot \chi_{A_k}$. Show that $\mu(A_k)<+\infty$ and $f_k\in\mc L^1(X,\mu,\mc V)$. Show that it suffices to approximate each $f_k$ by elements of $\mc S^1(X,\mu,\mc V)$. To achieve this approximation, for each $\eps>0$, write $\mc V$ as a disjoint union of Borel sets whose diameters are $\leq\eps$.

Part 4. Pick a sequence $(s_n)$ in $\mc S^1(X,\mu,\mc V)$ converging to $f$ under the $L^1$-seminorm. Prove that $(\int_Xs_n)_{n\in\Zbb_+}$ is a Cauchy sequence in $\mc V$. Let $\int_Xfd\mu$ be the limit of this sequence, and show that it satisfies the requirement in Def. \ref{lb773}.
\end{proof}



\begin{thm}[\textbf{Dominated convergence theorem}] \index{00@Dominated convergence theorem for Bochner integrals}
Let $(f_n)$ be a sequence in $\mc L^1(X,\mc V)$ converging pointwise to $f:X\rightarrow\mc V$. Suppose that there exists $g\in\mc L^1(X,\mu,\Rbb_{\geq0})$ such that $|f_n|\leq g$ for all $n$. Then $f\in\mc L^1(X,\mu,\mc V)$, and
\begin{align*}
\lim_{n\rightarrow\infty}\int_X f_nd\mu=\int_Xfd\mu
\end{align*}
\end{thm}
\begin{proof}
The closure of a countable union of separable subsets of $\mc V$ is clearly separable. Thus, since $f(X)$ is contained in the closure of $\bigcup_n f_n(X)$, we conclude that $f(X)$ is separable. By Pb. \ref{lb705}, $f$ is measurable. Thus $f\in\mc L_B(X,\mc V)$. Clearly $|f|\leq g$. So $f\in\mc L^1(X,\mu,\mc V)$.

Since $|f-f_n|$ is measurable, and since $|f-f_n|\leq 2g$, by the dominated convergence Thm. \ref{lb755}, we get $\lim_n \int_X|f-f_n|=0$. By Pb. \ref{lb772}, we have $\Vert\int_Xf-\int_Xf_n\Vert\leq \int_X|f-f_n|$. Therefore $\lim_n\Vert \int_Xf-\int_Xf_n\Vert=0$.
\end{proof}


\begin{exe}
Extend Cor. \ref{lb775} and \ref{lb776} to Bochner measurable functions.
\end{exe}




\subsubsection{Lebesgue's proof of dominated convergence theorem}\label{lb763}

The purpose of this subsection is to present a proof of the dominated convergence theorem that is similar to the original argument of Lebesgue.

\begin{df}
Let $(f_n)_{n\in\Zbb_+}$ be a sequence in $\mc L(X,\Cbb)$ (resp. in $\mc L_+(X)$). Let $f\in\mc L(X,\Cbb)$ (resp. $f=0$). We say that $(f_n)$ \textbf{converges in measure} \index{00@Converges in measure} to $f$ if for every $\eps>0$, we have
\begin{align}
\lim_{n\rightarrow\infty} \mu(\{x\in X:|f_n(x)-f(x)|\geq\eps\})=0
\end{align}
\end{df}

Do not use the monotone convergence theorem in your solutions to Pb. \ref{lb756} and \ref{lb757}.

\begin{prob}\label{lb756}
Let $(f_n)$ be a sequence in $\mc L_+(X)$. Consider the following conditions:
\begin{enumerate}
\item[(1)] $\dps\lim_n\int_X f_nd\mu=0$.
\item[(2)] $(f_n)$ converges in measure to $0$.
\end{enumerate}
Prove that (1)$\Rightarrow$(2). Prove that (2)$\Rightarrow$(1) if $\mu(X)<+\infty$ and $\sup_n \Vert f_n\Vert_{l^\infty}<+\infty$.
\end{prob}


\begin{prob}\label{lb757}
Assume that $\mu(X)<+\infty$. Let $(f_n)$ be a sequence in $\mc L_+(X)$ converging pointwise to $0$. 
\begin{enumerate}
\item Prove that $(f_n)$ converges in measure to $0$ under the assumption that $(f_n)$ is decreasing (i.e. $f_1\geq f_2\geq\cdots$).
\item Without assuming that $(f_n)$ is decreasing, prove that $(f_n)$ converges in measure to $0$ by applying part 1 to $h_n(x)=\sup_{k\geq n}f_n(x)$.
\end{enumerate}
\end{prob}

\begin{proof}[Note]
Can you find the similarity between your solution of Pb. \ref{lb757}-1 and the proof of $\lim_n\mu(E_{i,n})=\mu(E_i)$ in the proof of the monotone convergence Thm. \ref{lb760}?
\end{proof}


In Sec. \ref{lb754}, we proved the dominated convergence theorem using the monotone convergence theorem. In the following, we give an alternative proof using convergence in measure. First, we prove a special case:

\begin{thm}[\textbf{Bounded convergence theorem}] \index{00@Bounded convergence theorem} \label{lb758}
Let $(f_n)$ be a sequence in $\mc L(X,\Cbb)$ converging pointwise to $f:X\rightarrow\Cbb$. Assume that $\mu(X)<+\infty$ and $M:=\sup_{n\in\Zbb_+}\Vert f_n\Vert_{l^\infty}$ is finite. Then $f_n,f\in\mc L^1(X,\mu)$, and $\dps\lim_{n\rightarrow\infty}\int_X f_nd\mu=\int_Xfd\mu$.
\end{thm}

\begin{proof}
Since $0\leq |f_n|,|f|\leq M$, we have $f_n,f\in\mc L^1(X,\mu)$. Similar to the first paragraph of the proof of Thm. \ref{lb755}, by replacing $f_n$ with $|f_n-f|$, it suffices to assume that $(f_n)$ converges pointwise to $0$. Then, by Pb. \ref{lb757}, $(f_n)$ converges in measure to $0$. By Pb. \ref{lb756}, we conclude $\lim_n\int_X f_nd\mu=0$.
\end{proof}

We now use Thm. \ref{lb758} to prove the dominated convergence theorem:

\begin{proof}[\textbf{An alternative proof of Thm. \ref{lb755}}]
We are given a sequence $(f_n)$ in $\mc L(X)$ bounded by $g\in\mc L^1(X,\mu,\Rbb_{\geq0})$ and converging pointwise to $f$.  Let $\nu$ be the measure such that $d\nu=gd\mu$. Then $\nu(X)=\int_X gd\mu<+\infty$. Let $h_n(x)=f_n(x)/g(x)$ and $h(x)=f(x)/g(x)$ if $g(x)\neq 0$, and let $h_n(x)=h(x)=0$ if $g(x)=0$. It is easy to see that $h_n,h$ are measurable. Clearly $|h_n|\leq 1$, and $(h_n)$ converges pointwise to $h$. Therefore, by the bounded convergence Thm. \ref{lb758}, we have $\lim_n \int_Xh_nd\nu=\int_Xhd\nu$. Since $h_ng=f_n$ and $hg=f$, we get $\lim_n\int_X f_nd\mu=\int_X fd\mu$.
\end{proof}

\begin{prob}\label{lb1028}
Assume the setting of the dominated convergence Thm. \ref{lb755}, i.e., we are given a sequence $(f_n)$ in $\mc L(X,\Cbb)$ bounded by $g\in\mc L^1(X,\mu,\Rbb_{\geq0})$ and converging pointwise to $f$. For each $k\in\Zbb_+$, let
\begin{align}
E_k=g^{-1}[1/k,k]
\end{align}
Prove that $\mu(E_k)<+\infty$ and $\lim_k \int_X|g-g\chi_{E_k}|=0$. Give another proof of Thm. \ref{lb755} by applying the bounded convergence Thm. \ref{lb758} to the sequence $(f_n|_{E_k})_{n\in\Zbb_+}$ in $\mc L(E_k,\Cbb)$, where $k$ is ``large enough".
\end{prob}

\begin{proof}[Note]
The idea of passing from the finite-measure set $E_k$ to the whole set $X$ would be similar to that of solving Pb. \ref{lb759}.
\end{proof}



\begin{rem}
The original theorem of dominated convergence theorem proved by Lebesgue (in 1904) is the bounded convergence theorem. More precisely, Lebesgue proved Thm. \ref{lb758} where $X$ is a compact interval $[a,b]$ and $\mu=m$. 

The idea of using convergence in measure to prove Thm. \ref{lb758},  presented in this subsection, is almost identical to Lebesgue's original idea: In the setting of Thm. \ref{lb758}, assume WLOG that $f_n\geq0$ and $f=0$. Then Lebesgue proved $\lim_n\int f_n=0$ by proving that for each $\eps>0$, the $\mu$-measure of
\begin{align}\label{eq309}
E_{n,\eps}=\Big\{x\in X:\sup_{k\geq n}f_k(x)\geq\eps\Big\}
\end{align}
converges to $0$. (In the language of this subsection, what Lebesgue proved is that $h_n=\sup_{k\geq n}f_k$ converges in measure to $0$ as $n\rightarrow\infty$.) See Sec. 5.1 (especially p. 128) of \cite{Haw}.

In fact, Lebesgue's contribution to the convergence theorem is not primarily in the realization that $\lim_n\mu(E_{n,\eps})=0$ implies $\lim_n\int f_n=0$. In 1878, Kronecker already noticed that if $(f_n)$ is a uniformly bounded sequence of continuous functions $[a,b]\rightarrow\Rbb_{\geq0}$, then $\lim_n\int f_n=0$ iff $(f_n)$ ``\textbf{converges in content}", i.e., $\lim_nc^*(K_{n,\eps})=0$ where $c^*$ is the outer content (cf. \eqref{eq308}) of 
\begin{align}
K_{n,\eps}=\{x\in X:f_n(x)\geq\eps\}
\end{align}
In 1897, Osgood showed that if $(f_n)$ converges pointwise to $0$, then $\lim_n c^*(K_{n,\eps})=0$. (Thus, combined with Kronecker's result, one concludes $\lim_n\int f_n=0$.) The consideration of \eqref{eq309} is implicit in Osgood's argument.  See \cite[Sec. 4.4]{Haw} for details.

Since $f_n$ is continuous, $K_{n,\eps}$ is a closed subset of $[a,b]$ and hence is compact. Therefore, the finite covering property implies $c^*(K_{n,\eps})=m(K_{n,\eps})$. Therefore, if we look back at history from the perspective of measure theory, it is easy to understand why $\lim_n c^*(K_{n,\eps})=0$ if $(f_n)$ converges pointwise to $0$. 

The real novelty of Lebesgue's theory is that his convergence theorem applies to a broader class of functions whose associated $K_{n,\eps}$ are not necessarily Jordan-measurable, and therefore do not necessarily satisfy $\lim_n c^*(K_{n,\eps})=0$ when $(f_n)$ converges pointwise to $0$. (Consider for example $f_n=|g_n-g|$ where $(g_n)$ is a uniformly bounded sequence of continuous functions on $[a,b]$ converging pointwise to $g$. Then $g$ is not necessarily continuous or Riemann-integrable.) Lebesgue developed a theory of measure $m$ satisfying (most importantly) the countable additivity. Therefore, $E_{1,\eps}\supset E_{2,\eps}\supset\cdots$ and $\bigcap_n E_{n,\eps}=\emptyset$ imply $\lim_n m(E_{n,\eps})=0$. (One takes $E_{n,\eps}$ to be \eqref{eq309}.) Thus, since $K_{n,\eps}\subset E_{n,\eps}$, one obtains $\lim_n m(K_{n,\eps})=0$, generalizing the arguments of Kronecker and Osgood.  

From this observation, it seems fair to say that Lebesgue was not the first to realize that the problem of proving $\lim_n\int f_n=\int\lim_n f_n$ can be transform into proving that the measure/content of $K_{n,\eps}$ converges to $0$ as $n\rightarrow\infty$ (i.e., proving the convergence in measure). However, Lebesgue was the first person to define the correct measure that allowed this idea to be realized under very loose requirements.  \hfill\qedsymbol
\end{rem}


\begin{rem}
Our proof of the dominated convergence Thm. \ref{lb755} relies on the linearity of $\int_X$, which in turn relies on the monotone convergence theorem proved by Beppo Levi in 1906. (See \cite[p. 161]{Haw}.) However, when $\mu(X)<+\infty$, the linearity of $\int_X$ on bounded measurable functions can be established without using the monotone convergence theorem. (See Subsec. \ref{lb762}.) Therefore, Lebesgue's proof of the bounded convergence Thm. \ref{lb758} in 1904 clearly does not rely on the theorem of Beppo Levi (in 1906).
\end{rem}



\subsubsection{$\star$ Various types of convergence properties}

The following theorem provides an application of convergence in measure.

\begin{thm}[\textbf{Egorov's theorem}]\index{00@Egorov's theorem}\label{lb965}
Assume that $\mu(X)<+\infty$. Let $\mc V$ be a normed vector space. Assume that $(f_n)$ is a sequence in $\mc L(X,\mc V)$ converging pointwise to some $f\in\mc L(X,\mc V)$. Then $(f_n)$ converges \textbf{almost uniformly} \index{00@Almost uniform convergence} to $f$, which means that for every $\delta>0$ there exists $A\in\fk M$ such that $\mu(X\setminus A)<\delta$, and that $(f_n)$ converges uniformly on $A$ to $f$.
\end{thm}


\begin{prob}
Prove Egorov's theorem. (Hint: Let $g_n(x)=\sup_{k\geq n}\Vert f(x)-f_k(x)\Vert$. Then $(g_n)$ converges in measure to $0$. For each $k\in\Zbb_+$, choose $n_k\in\Zbb_+$ such that $A_k=g_{n_k}^{-1}([0,1/k])$ is large enough. Let $A=\bigcap_n A_n$.)
\end{prob}





\begin{thm}[\textbf{Generalized dominated convergence theorem}]\index{00@Generalized dominated convergence theorem}\label{lb1029}
Let $(g_n)$ be a sequence in $\mc L^1(X,\mu,\Rbb_{\geq0})$ converging pointwise to $g\in\mc L^1(X,\mu,\Rbb_{\geq0})$. Let $(f_n)$ be a sequence in $\mc L(X,\Cbb)$ converging pointwise to $f\in\mc L(X,\Cbb)$. Assume that $|f_n|\leq g_n$ and $|f|\leq g$. Assume that $\dps\lim_n \int_Xg_nd\mu=\int_X gd\mu$. Prove that $\dps\lim_n \int_Xf_nd\mu=\int_X fd\mu$.
\end{thm}

It follows, for example, that $\lim_n \int_Eg_nd\mu=\int_E gd\mu$ for any $E\in\fk M$.

\begin{prob}
Prove Thm. \ref{lb1029}.
\end{prob}

\begin{proof}[Hint]
First consider the special case that $0\leq f_n\leq g_n$, and apply Fatou's lemma to $f_n$ and $g_n-f_n$ (or their subsequences). (This special case is particularly important. It states, roughly, that if the equality in Fatou's lemma holds for $(g_n)$, then it also holds for any convergent sequence of positive functions bounded by $(g_n)$.) Then reduce the general case to the special case by considering $|f-f_n|$.
\end{proof}

\begin{comment}
\begin{df}
A family $(f_\alpha)_{\alpha\in\scr A}$ in $\mc L(X,\Cbb)$ is called \textbf{uniformly integrable} if for every $\eps>0$ there exists $g\in\mc L^1(X,\mu,\Rbb_{\geq0})$ such that
\begin{align*}
\sup_{\alpha\in\scr A}\int_{\{|f_\alpha|>g\}}|f_\alpha|d\mu\leq\eps
\end{align*}
Here, $\{|f_\alpha|>g\}$ is the abbreviation of $\{x\in X:|f_\alpha(x)|>g(x)\}$
\end{df}

\begin{prob}
Let $(f_n)_{n\in\Zbb_+}$ be a uniformly integrable sequence in $\mc L(X,\Cbb)$ converging pointwise to $f:X\rightarrow\Cbb$. Prove that $f_n,f\in\mc L^1(X,\mu)$ and that $\dps\lim_n \int_Xf_nd\mu=\int_X fd\mu$.
\end{prob}

\begin{proof}
Reduce to the case that $f_n,f$ are real-valued. Define $\varphi:\Rbb\times\Rbb_{\geq0}\rightarrow\Rbb$ by
\begin{align*}
\varphi(s,t)=\min\{|s|,t\}\cdot \sgn(s)
\end{align*}
where $\sgn(s)=s/|s|$ if $s\neq 0$ and $\sgn(s)=0$ if $s=0$. Show that $\varphi$ is continuous. Let $\eps,g$ be as in Def. Show that $|\varphi(f_n,g)|\leq g$, that $\lim_n\varphi(f_n,g)$ converges pointwise to $\varphi(f,g)$, and that $\dps\sup_n \int_X |f_n-\varphi(f_n,g)|d\mu\leq\eps$.
\end{proof}
\end{comment}





\begin{prob}\label{lb1030}
Assume that $\mu(X)<+\infty$. Let $(f_n)$ be a sequence in $\mc L(X,\Cbb)$ converging pointwise to $f\in\mc L(X,\Cbb)$. Let $\varphi:\Rbb_{\geq0}\rightarrow\Rbb_{\geq0}$ be a Borel function such that $\dps\liminf_{t\rightarrow+\infty}\varphi(t)=+\infty$. Assume that $\dps\sup_n\int_X |f_n|\cdot(\varphi\circ |f_n|)d\mu<+\infty$. Prove that $f_n,f\in\mc L^1(X,\mu)$ and $\dps\lim_n\int_X f_nd\mu=\int_X fd\mu$.
\end{prob}

\begin{proof}[Hint]
For each $\lambda\in\Rbb_{\geq0}$, let $\alpha_\lambda:\Rbb_{\geq0}\rightarrow\Rbb_{\geq0}$ be the (continuous) piecewise linear increasing function such that $\alpha_\lambda|_{[0,\lambda]}=0$ and $\alpha_\lambda|_{[\lambda+1,+\infty)}=1$. Let $\beta_\lambda=1-\alpha_\lambda$. Show that for each $\eps>0$, we have
\begin{align*}
\sup_n\int_X|f_n|\cdot(\chi_{[\lambda,+\infty)}\circ|f_n|)d\mu\leq\eps
\end{align*}
for sufficiently large $\lambda$. (This property is sometimes referred to as \textbf{uniform integrability}.)\index{00@Uniform integrability} Conclude that $\dps\sup_n\int_X |f_n|\cdot(\alpha_\lambda\circ|f_n|)\leq\eps$ for sufficiently large $\lambda$. Apply the bounded convergence theorem to $f_n\cdot(\beta_\lambda\circ |f_n|)$.
\end{proof}













\newpage


\section{Positive linear functionals and Radon measures}\label{lb805}

The goal of this chapter is to study a class of Borel measures on LCH spaces generalizing the Lebesgue measure on $\Rbb^N$. Our starting point is an LCH space $(X,\mc T_X)$ and a linear functional $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ where 
\begin{align}
C_c(X,\Rbb_{\geq0})=\{f\in C_c(X,\Rbb):f\geq0\}
\end{align}
We use $\Lambda$ to define a function $\mu:\mc T_X\rightarrow\ovl\Rbb_{\geq0}$ in the same way that we define the Lebesgue measures of open subsets of $\Rbb^N$. Namely, for each $U\in\mc T_X$ we let
\begin{align*}
\mu(U)=\sup\{\Lambda(f):f\in C_c(U,[0,1])  \}
\end{align*}
(Recall that a compactly supported continuous function on $U$ is equivalent to a continuous function on $X$ with compact support in $U$, cf. Rem. \ref{lb457}.) Then we use Thm. \ref{lb724} to extend $\mu$ to a measure on the Borel $\sigma$-algebra $\fk B_X$. Such measure will be called a \textbf{Radon measure}. 

In fact, we shall first define Radon measure to be a Borel measure satisfying certain regular conditions, and then show that they correspond bijectively to linear functionals on $C_c(X,\Rbb_{\geq0})$.




\subsection{Radon measures}

Let $(X,\mc T_X)$ be an LCH space with topology $\mc T_X$. Recall Rem. \ref{lb459} for the two equivalent descriptions of precompact subsets (and their closures) of an open $U\subset X$. Recall that every open subset of an LCH space is LCH (cf. Prop. \ref{lb245}).

\begin{df}\label{lb811}
Let $\fk M\subset 2^X$ be a $\sigma$-algebra containing $\fk B_X$. Let $\mu:\fk M\rightarrow\ovl\Rbb_{\geq0}$ be a measure. Let $E\in\fk M$. We say that $\mu$ is \textbf{outer regular} \index{00@Outer regular} on $E$ (or that $E$ is \textbf{outer $\mu$-regular}) if
\begin{align*}
\mu(E)=\inf\{\mu(U):U\supset E,U\text{ is open}\}
\end{align*}
We say that $\mu$ is \textbf{inner regular} on $E$ (or that $E$ is \textbf{inner $\mu$-regular}) if
\begin{align*}
\mu(E)=\sup\{\mu(K):K\subset E,K\text{ is compact}\}
\end{align*}
We say that $\mu$ is \textbf{regular} on $E$ (or that $E$ is \textbf{$\mu$-regular}) \index{00@Regular (measure)} if $\mu$ is outer regular and inner regular on $E$.
\end{df}

\begin{eg}\label{lb799}
Assume that $\mu:\mc T_X\rightarrow[0,+\infty]$ satisfies conditions (a)-(e) in Asmp. \ref{lb712}. Define $\mu^*:2^X\rightarrow[0,+\infty]$ by \eqref{eq292}. Then by Thm. \ref{lb724}, $\mu^*$ restricts to a complete measure on $\fk M_\mu$ containing $\fk B_X$, and $(\fk M_\mu,\mu)$ is \textit{defined to be} $(\fk M_\mu,\mu^*)$. Then $\mu$ is clearly outer regular on any $E\in\fk M_\mu$, and is inner regular on open sets by condition (e) of Asmp. \ref{lb712}. 

For each $E\in\fk M_\mu$, the meaning of $\mu$-regularity in Def. \ref{lb810} clearly agrees with the meaning in Def. \ref{lb811}: The former says $\mu^*(E)=\mu_*(E)$, and the latter says $\mu^*(E)=\mu(E)$ (which is a tautology) and $\mu_*(E)=\mu(E)$. \footnote{Note that $\mu_*$ is defined in terms of the outer measures $\mu^*(K)$ of compact sets $K$. But since $K\in\fk B_X\subset\fk M_\mu$, we know $\mu^*(K)=\mu(K)$.} However, Def. \ref{lb811} cannot be applied to non-measurable sets, but Def. \ref{lb810} can be applied to any subset of $X$. \hfill \qedsymbol
\end{eg}

The inner regularity on open sets can also be described in the following way:

\begin{lm}\label{lb777}
Let $\mu$ be a measure on $\fk B_X$. Let $U\in\mc T_X$. Then
\begin{align}
\sup\big\{\mu(K):K\subset U,K\text{ is compact}\big\}=\sup\Big\{\int_Xfd\mu:f\in C_c(U,[0,1])  \Big\}
\end{align}
\end{lm}

\begin{proof}
Let $A$ and $B$ denote the LHS and the RHS. If $f\in C_c(U,[0,1])$, then $K=\ovl{\Supp(f)}$ is compact in $U$. So $0\leq f\leq\chi_K$, and hence $\mu(K)=\int_X\chi_K\geq\int_Xfd\mu$. This proves $A\geq B$.

Conversely, let $K\subset U$ be compact. By Urysohn's lemma (Thm. \ref{lb711}), there exists $f\in C_c(U,[0,1])$ such that $f|_K=1$. So $\chi_K\leq f$, and hence $\mu(K)\leq\int_Xfd\mu$. This proves $A\leq B$.
\end{proof}

In the definition of Radon measures, compact sets are assumed to have finite measures. This property has an equivalent description:

\begin{lm}\label{lb806}
Let $\mu$ be a measure on $\fk B_X$. Then $\mu(K)<+\infty$ for all compact $K\subset X$ iff $\dps\int_Xfd\mu<+\infty$ for all $f\in C_c(X,\Rbb_{\geq0})$.
\end{lm}


\begin{proof}
Suppose that $\mu(K)<+\infty$ for each compact $K\subset X$. Then for each $f\in C_c(X,\Rbb_{\geq0})$, letting $K=\Supp(f)$ and $M=\Vert f\Vert_{l^\infty}$, we have $f\leq M\chi_K$, and hence $\int f\leq\int M\chi_K=M\mu(K)<+\infty$. Conversely, assume that $\int f<+\infty$ for every $f\in C_c(X,\Rbb_{\geq0})$. Let $K\subset X$ be compact. By Urysohn's lemma, there exists $f\in C_c(X,[0,1])$ such that $f|_K=1$. So $\chi_K\leq f$, and hence $\mu(K)=\int\chi_K\leq\int f<+\infty$.
\end{proof}


\begin{df}
A Borel measure $\mu:\fk B_X\rightarrow\ovl\Rbb_{\geq0}$ is called a \textbf{Radon measure} \index{00@Radon measure} if the following conditions are satisfied:
\begin{enumerate}[label=(\alph*)]
\item $\mu$ is outer regular on Borel sets. 
\item $\mu$ is inner regular on open sets. Equivalently (by Lem. \ref{lb777}), for each open $U\subset X$, we have
\begin{align}\label{eq314}
\mu(U)=\sup\Big\{\int_Xfd\mu:f\in C_c(U,[0,1])  \Big\}
\end{align}
\item $\mu(K)<+\infty$ if $K$ is a compact subset of $X$. Equivalently (by Lem. \ref{lb806}), for each $f\in C_c(X,\Rbb_{\geq0})$ we have
\begin{align}
\dps\int_Xfd\mu<+\infty
\end{align}
\end{enumerate}
\end{df}



\begin{eg}
A (finite) $\Rbb_{\geq0}$-linear combination of Radon measures on $X$ is a Radon measure.
\end{eg}

\begin{eg}\label{mc198}
Suppose that $\mu:\fk B_X\rightarrow[0,+\infty]$ is a Radon measure. Let $U$ be an open subset of $X$ (which is LCH by Prop. \ref{lb245}). By Pb. \ref{mc34}, we have $\fk B_U=\fk B_X|_U\subset\fk B_X$. The restriction of $\mu$ to $\fk B_U$ is clearly a Radon measure on $U$.
\end{eg}


\begin{eg}
Let $x_0\in X$. The Dirac measure $\delta_{x_0}$ is Radon when restricted to $\fk B_X$. 
\end{eg}

\begin{eg}
Assume that $\mc T_X$ is the discrete topology, i.e., $\mc T_X=2^X$. (So compact sets are exactly finite sets.) The counting measure is Radon.
\end{eg}




\begin{eg}
The Lebesgue measure $m$ on $\Rbb^N$ is Radon when restricted to $\fk B_{\Rbb^N}$. In fact, the outer and inner regularities were explained in Exp. \ref{lb799}. Since $m$ is finite on bounded measurable subsets (cf. Thm. \ref{lb800}), it is finite on compact sets.
\end{eg}

In application, it is often more convenient to consider the completion of a Radon measure:

\begin{exe}
Assume that $(\fk M,\mu)$ is the completion of a Radon measure on $X$. Show that $\mu$ is outer regular on any $E\in\fk M$.
\end{exe}

\begin{comment}
\begin{proof}
By Thm. \ref{lb708}, we can write $E=A\cup B$ where $A\in\fk B_X$, and $B\subset C$ where $C\in\fk B_X$ and $\mu(C)=0$. Since $(\fk B_X,\mu)$ is Radon, for each $\eps>0$ there exist open $U\supset A$ and $V\supset B$ such that $\mu(U)\leq \mu(A)+\eps/2$, and $\mu(V)\leq\eps/2$. So $\mu(U\cup V)\leq \mu(A)+\eps\leq\mu(E)+\eps$. Since $U\cup V$ is an open set containing $E$, we conclude that $\mu$ is outer regular on $E$.
\end{proof}
\end{comment}



One of the most important features of Radon measures is that they are determined by the integral of functions in $C_c(X,\Rbb_{\geq0})$.

\begin{pp}\label{lb791}
Let $\mu_1,\mu_2$ be Radon measures on $\fk B_X$. Suppose that for each $f\in C_c(X,\Rbb_{\geq0})$ we have $\dps\int_Xfd\mu_1=\int_Xfd\mu_2$. Then $\mu_1=\mu_2$.
\end{pp}

\begin{proof}
By \eqref{eq314}, we have $\mu_1(U)=\mu_2(U)$ when $U$ is open. By the outer regularity, for each $E\in\fk B_X$ we must have $\mu_1(E)=\mu_2(E)$.
\end{proof}



\subsection{Monotone convergence extension II: from $C_c(X,\Rbb_{\geq0})$ to $\LSC_+(X)$}\label{lb833}


Fix an LCH space $(X,\mc T_X)$.


\begin{df}
Let $\Fbb\in\{\Rbb,\Cbb\}$. A linear map $\Lambda:C_c(X,\Fbb)\rightarrow\Fbb$ is called a \textbf{positive linear functional} \index{00@Positive linear functional} if $\Lambda(C_c(X,\Rbb_{\geq0}))\subset\Rbb_{\geq0}$.
\end{df}


\begin{rem}\label{lb812}
There exist canonical bijections among:
\begin{itemize}
\item $\Rbb_{\geq0}$-linear maps $C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$
\item Positive linear functionals on $C_c(X,\Rbb)$.
\item Positive linear functionals on $C_c(X)=C_c(X,\Cbb)$.
\end{itemize}
\end{rem}
\begin{proof}
An $\Rbb_{\geq0}$-linear map $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ can be extended uniquely to a linear map $\Lambda:C_c(X,\Rbb)\rightarrow\Rbb$ due to Prop. \ref{lb751}. The latter can be extended to a linear functional on $C_c(X)$ by setting $\Lambda(f)=\Lambda(\Real f)+\im\Lambda(\Imag f)$ for all $C_c(X)$. (This is similar to the proof of Thm. \ref{lb779}. It is also the complexification of the $\Rbb$-linear map $f\in C_c(X)\mapsto \Lambda(\Real f)\in\Rbb$, cf. Pb. \ref{lb387}.)
\end{proof}


%% Record #9 2024/03/25 two lectures  22

\begin{rem}\label{lb784}
Let $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ be linear. Then $\Lambda$ is (monotonically) increasing, i.e., if $f,g\in C_c(X,\Rbb_{\geq0})$ and $f\leq g$, then $\Lambda(f)\leq\Lambda(g)$. This is because $g-f\in C_c(X,\Rbb_{\geq0})$ and $\Lambda(g)=\Lambda(f)+\Lambda(g-f)\geq\Lambda(f)$.
\end{rem}

\subsubsection{Toward the proof of the Riesz-Markov representation theorem}

As mentioned at the beginning of this chapter, our goal is to construct a Radon measure $\mu$ associated to a linear $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ in the same way that we constructed the Lebesgue measure from the Riemann integrals of continuous compactly supported functions on $\Rbb^N$. Thus, $\Lambda$ can be viewed as an ``abstract Riemann integral" on $X$. This correspondence between $\Lambda$ and $\mu$ is called the \textbf{Riesz-Markov representation theorem}. 

There are two main difficulties in the proof of Riesz-Markov. The first one is the construction of $\mu$. But we have already studied this part in detail in Sec. \ref{lb726}. The second one is to show that the Radon measure $\mu$ constructed from $\Lambda$  satisfies
\begin{align}\label{eq315}
\Lambda(f)=\int_Xfd\mu
\end{align}
for all $f\in C_c(X,\Rbb_{\geq0})$. In my opinion, a direct proof of \eqref{eq315} is usually very technical, and the idea of the proof is very isolated, making it difficult to connect with the main ideas in measure theory. (The readers can make their own judgment by reading Step X of the proof of Thm. 2.14 in \cite[Ch. 2]{Rud-R}, or the last part of the proof of Thm. 7.2 in \cite[Ch. 7]{Fol-R}.) 

The goal of this section is to prepare for a more conceptual proof of \eqref{eq315} for $f\in C_c(X,\Rbb_{\geq0})$. To motivate our proof, recall that in Prop. \ref{lb780}, we proved that the Riemann integral of $f$ equals the Lebesgue integral by sandwiching $f$ between step functions $g$ and $h$, and showed that the Riemann integrals of $g$ and $h$ agree with their Lebesgue integrals. But step functions are usually not continuous functions. Therefore, to generalize the proof of Prop. \ref{lb780}, we must first extend $\Lambda$ to a suitable larger class of positive functions.

Through laborious work, one can extend $\Lambda$ to a large class of Borel measurable functions  without resorting to measures. The value $\Lambda(f)$ of $f$ in this class is called the \textbf{Daniell integral} of $f$. \index{00@Daniell integral} Then one constructs the Radon measure satisfying \eqref{eq315}. This approach can be found e.g. in \cite[Sec. 9]{HS}, \cite[Sec. 11]{HR-1}, and \cite[Sec. 6.1]{Ped}. (A systematic treatment of Daniell integrals, not necessarily in the context of LCH spaces, can be found in \cite[Ch. 16]{Roy}.) 

We will partially adopt the idea of Daniell integrals, but will exclude many irrelevant results so that the proofs are as concise and clear as possible. In particular, we will only extend $\Lambda$ to positive lower semicontinuous functions. This will be sufficient for the purpose of proving \eqref{eq315}, because functions of the form $\sum_i a_i\chi_{U_i}$ (where $a_i\in\ovl\Rbb_{\geq0}$ and $U_i$ is open) will play the same role as that of step functions in the proof of Prop. \ref{lb780}. 

The method of extending $\Lambda$ to semicontinuous functions was already used by Riesz in \cite{Rie14} to simplify his original proof of the ``Riesz representation theorem for $C([a,b],\Rbb)$", see Subsec. \ref{lb923} for details. In \cite{Rie13}, a similar method was used by Riesz to prove the spectral theorem for bounded self-adjoint operators, cf. Sec. \ref{lb896} and \ref{lb1100}. This extension method is similar to that in Sec. \ref{lb891}, where we extend integrals (i.e., positive linear functionals) from simple functions to positive measurable functions. Since the monotone convergence theorems play a crucial role in all these three extension processes, we refer to this approach as the \textbf{monotone convergence extension}. \index{00@Monontone convergence extension} 

\begin{rem}\label{lb1011}
The main steps of monotone convergence extensions are as follows. Given a positive linear functional $\Lambda$ defined on an $\Rbb_{\geq0}$-linear space $\scr C$ of positive functions. We want to extend $\Lambda$ to a larger $\Rbb_{\geq0}$-linear space $\scr L$ of positive functions.
\begin{enumerate}
\item For each $f\in\scr L$, define $\Lambda(f)=\sup\{\Lambda(h):h\in \scr C,h\leq f\}$.
\item Prove the \textbf{monotone convergence theorem}: If $(f_\alpha)$ is an increasing net/sequence converging pointwise to $f$, then $f\in\scr L$ and $\Lambda(f)=\lim_\alpha\Lambda(f_\alpha)$.
\item Prove that every $f\in\scr L$ is the pointwise limit of an increasing net/sequence in $\scr C$.
\item Use Steps 2 and 3 to show the linearity of the extended $\Lambda$.
\end{enumerate}
These are not exactly the steps originally taken by Riesz and others in the history. The equivalent but more classical (and more intuitive) steps they took are as follows:
\begin{enumerate}[label=(\alph*)]
\item Prove that every $f\in\scr L$ is the pointwise limit of an increasing net/sequence $(f_\alpha)$ in $\scr C$.
\item Define $\Lambda(f)=\lim_\alpha \Lambda(f_\alpha)$.
\item Prove that the definition of $\Lambda(f)$ is independent of the choice of $(f_\alpha)$ approximating $f$.
\end{enumerate}
The linearity of the extended $\Lambda$ is follows immediately from (b). Note that Step (c) plays the same role as Step 2.
\end{rem}











\subsubsection{Extending positive linear functionals to $\LSC_+(X)$}\label{lb1013}

In this subsection, we fix an $\Rbb_{\geq0}$-linear map $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$.

Recall Subsec. \ref{lb803} for the basic facts about lower semicontinuous functions. By Rem. \ref{lb783}, \index{LSC@$\LSC_+(X)$, the set of lower semicontinuous $X\rightarrow[0,+\infty]$}
\begin{align}
\LSC_+(X)=\{\text{lower semicontinuous }f:X\rightarrow \ovl\Rbb_{\geq0}\}
\end{align}
is an $\ovl\Rbb_{\geq0}$-linear subspace of $[0,+\infty]^X$. It clearly contains $C_c(X,\Rbb_{\geq0})$ as an $\Rbb_{\geq0}$-linear subspace.


\begin{df}\label{lb793}
For each $f\in\LSC_+(X)$, define
\begin{subequations}\label{eq316}
\begin{align}\label{eq316a}
\Lambda(f)=\sup\{\Lambda(h):h\in C_c(X,\Rbb_{\geq0}),h\leq f \}
\end{align}
Equivalently, noting that $\Omega_f=f^{-1}(0,+\infty]$ is open (by the lower semicontinuity of $f$), define
\begin{align}\label{eq316b}
\Lambda(f)=\sup\{\Lambda(h):h\in C_c(\Omega_f,\Rbb_{\geq0}),h\leq f\}
\end{align}
\end{subequations}
This defines a map $\Lambda:\LSC_+(X)\rightarrow\ovl\Rbb_{\geq0}$ which (by Rem. \ref{lb784}) extends the original map $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$. We call this new $\Lambda$ the \textbf{canonical extension} of the original $\Lambda$. \index{00@Canonical extension of positive linear functionals on $C_c(X,\Rbb_{\geq0})$} The extension $\Lambda$ is clearly monotonically increasing, i.e., if $f,g\in\LSC_+(X)$ and $f\leq g$, then
\begin{align*}
\Lambda(f)\leq \Lambda(g)
\end{align*}
\end{df}


\begin{proof}[Proof of the equivalence]
Let $A$ and $B$ denote respectively the RHS of \eqref{eq316a} and \eqref{eq316b}. We need to prove $A=B$. Since $C_c(\Omega_f,\Rbb_{\geq0})$ is naturally a subspace of $C_c(X,\Rbb_{\geq0})$ (cf. Rem. \ref{lb457}), we have $A\geq B$. To prove $A\leq B$, we pick any $h\in C_c(X,\Rbb_{\geq0})$ satisfying $h\leq f$, and we shall prove that $\Lambda(h)\leq B$.

For each $\eps>0$, let $h_\eps=(h-\eps)^+=\max\{h-\eps,0\}$. Then $\Supp(h_\eps)$ is the closure of $h^{-1}(\eps,+\infty]$, which is contained in the closed set $h^{-1}[\eps/2,+\infty]$ and hence in $\Omega_f$. Therefore $h_\eps\in C_c(\Omega_f,\Rbb_{\geq0})$. To prove $\Lambda(h)\leq B$, it suffices to prove
\begin{align*}
\dps\lim_{\eps\rightarrow 0}\Lambda(h-h_\eps)=0
\end{align*}
We shall prove this by using the fact that $0\leq h-h_\eps\leq\eps \chi_K$ where $K=\Supp(h)$. If $\Lambda$ were defined on $\chi_K$ and $0\leq\Lambda(\chi_K)<+\infty$, then one could argue that $\Lambda(h-h_\eps)\leq\eps\Lambda(\chi_K)$ where the RHS converges to $0$ as $\eps\rightarrow0$. Unfortunately, we do not know whether $\chi_K$ is in the domain of $\Lambda$. To fix this issue, note that by Urysohn's lemma, there exists $\varphi\in C_c(X,[0,1])$ such that $\varphi|_K=1$. So $h-h_\eps\leq \eps\varphi$, and hence
\begin{align*}
0\leq \Lambda(h-h_\eps)\leq \Lambda(\eps\varphi)= \eps\Lambda(\varphi)
\end{align*}
where the RHS converges to $0$ as $\eps\rightarrow0$.
\end{proof}


\begin{eg}\label{lb794}
Let $U\subset X$ be open. By \eqref{eq316b} we have
\begin{align}
\Lambda(\chi_U)=\sup\big\{\Lambda(f):f\in C_c(U,[0,1])  \big\}
\end{align}
where the RHS will be the definition of the measure $\mu(U)$.
\end{eg}



We shall prove that the canonical extension $\Lambda$ is $\ovl\Rbb_{\geq0}$-linear using the same strategy in Subsec. \ref{lb785} where we proved that $\int_X:\mc L_+(X)\rightarrow\ovl\Rbb_{\geq0}$ is $\ovl\Rbb_{\geq0}$-linear. Therefore, we first need to prove:

\begin{thm}[\textbf{Monotone convergence theorem}] \index{00@Monotone convergence theorem for positive linear functionals}\label{lb789}
Let $(f_\alpha)_{\alpha\in I}$ be an increasing net of elements in $\LSC_+(X)$. (So $f_\alpha\leq f_\beta$ if $\alpha\leq\beta$.) Let $f$ be the pointwise limit $\lim_\alpha f_\alpha$. Then $f\in \LSC_+(X)$, and
\begin{align*}
\Lambda(f)=\lim_{\alpha\in I}\Lambda(f_\alpha)
\end{align*}
\end{thm}

The following proof is close in spirit to the proof of the monotone convergence Thm. \ref{lb760}.

\begin{proof}
Since $f$ is the pointwise supremum $\sup_\alpha f_\alpha$, by Pb. \ref{lb782}, we have $f\in\LSC_+(X)$. Since $f\geq f_\alpha$, we clearly have $\Lambda(f)\geq\lim_\alpha\Lambda(f_\alpha)$. To prove ``$\leq$", by \eqref{eq316b}, it suffices to choose any $g\in C_c(\Omega_f,\Rbb_{\geq0})$ (where $\Omega_f=f^{-1}(0,+\infty]$) satisfying $g\leq f$, and prove that $\Lambda(g)\leq\sup_\alpha\Lambda(f_\alpha)$.

Since $g\leq f$ and $f|_K>0$ where $K=\Supp(g)$, we have $\gamma g|_K<f|_K$ where $0<\gamma<1$. By the linearity of $\Lambda$ on $C_c(X,\Rbb_{\geq0})$, we have $\gamma\Lambda(g)=\Lambda(\gamma g)$. Thus, it suffices to prove that $\Lambda(\gamma g)\leq\sup_\alpha\Lambda(f_\alpha)$ for each $\gamma$. Thus, by replacing $g$ with $\gamma g$, it suffices to assume that $g|_K<f|_K$.

The proof will be finished by finding some $\alpha\in I$ such that $g|_K<f_\alpha|_K$ (and hence $g\leq f_\alpha$). This follows from a standard compactness argument: For each $x\in K$, since $g(x)<f(x)$, there exists $\alpha_x\in I$ such that $g(x)<f_{\alpha_x}(x)$. Since $g$ is continuous and $f_{\alpha_x}$ is lower semicontinuous, the function $f_{\alpha_x}-g$ is lower semicontinuous (e.g. by Pb. \ref{lb767}-(3)). Therefore $U_x=\{p\in X:f_{\alpha_x}(p)-g(p)>0\}$ is an open subset of $X$ containing $x$. Since $K$ is compact, there exist $x_1,\dots,x_n\in K$ such that $K\subset U_{x_1}\cup\cdots\cup U_{x_n}$. Since $I$ is directed, there exists $\alpha\in I$ that is $\geq \alpha_{x_1},\dots,\alpha_{x_n}$. Then $f_\alpha\geq f_{\alpha_{x_i}}>g$ on $U_{x_i}$. Therefore $f_\alpha|_K>g|_K$.
\end{proof}


The following lemma is similar to Prop. \ref{lb749}.

\begin{lm}\label{lb788}
Let $f\in\LSC_+(X)$ and $\Omega_f=f^{-1}(0,+\infty]$. Then there is an increasing net $(f_\alpha)$ in $C_c(\Omega_f,\Rbb_{\geq0})$ converging pointwise on $X$ to $f$.
\end{lm}

%In fact, the following proof shows that $(f_\alpha)$ can be chosen to be in $C_c(f^{-1}(0,+\infty],\Rbb_{\geq0})$. But we will not use this fact.


\begin{proof}
Let $\scr I$ be the set of all $g\in C_c(\Omega_f,\Rbb_{\geq0})$ such that $g\leq f$. Then $(\scr I,\leq)$ is a directed set, because if $g_1,g_2\in \scr I$ then $\max\{g_1,g_2\}\in \scr I$. Let us prove that the (clearly increasing) net $(g)_{g\in \scr I}$ converges pointwise to $f$. Equivalently, we shall prove for each $x\in X$ that $f(x)=\sup_{g\in\scr I}g(x)$. This is obvious when $x$ is such that $f(x)=0$. So we assume $f(x)>0$, i.e., $x\in\Omega_f$.

It suffices to prove that for every $A$ satisfying $0\leq A<f(x)$ there exists $g\in\scr I$ such that $g(x)\geq A$. Since $f$ is lower semicontinuous, $U=f^{-1}(A,+\infty]$ is a neighborhood of $x$ in $\Omega_f$. By Urysohn's lemma, there exists $g\in C_c(U,\Rbb_{\geq0})$ such that $0\leq g\leq A$ and $g(x)=A$. Then $g\in\scr I$.
\end{proof}

\begin{sexe}
Assume that $X$ is second countable. Let $f\in\LSC_+(X)$ and $\Omega_f=f^{-1}(0,+\infty]$. Prove that there exists an increasing sequence $(f_n)_{n\in\Zbb_+}$ in $C_c(\Omega_f,\Rbb_{\geq0})$ converging pointwise on $X$ to $f$.
\end{sexe}

\begin{proof}[Hint]
Let $\mc U$ be a countable topology basis of $\Omega_f$. Let $\scr I$ be the countable set of all $(U,V,A)$ where $U,V\in\mc U$, $U\Subset V$, $A\in\Qbb_{\geq0}$, and $f|_V>A$. Show that if $\scr I$ is a finite set then the problem is trivial. Write the elements of $\scr I$ as a sequence $(U_n,V_n,A_n)_{n\in\Zbb_+}$. For each $n\in\Zbb_+$, find $g_n\in C_c(V_n,\Rbb_{\geq0})$ such that $0\leq g_n\leq A_n$ and $g_n|_{\ovl{U_n}}=A_n$. Let $f_n=\max\{g_1,\dots,g_n\}$. 
\end{proof}


\begin{pp}\label{lb792}
The canonical extension $\Lambda:\LSC_+(X)\rightarrow\ovl\Rbb_{\geq0}$ is $\ovl\Rbb_{\geq0}$-linear.
\end{pp}

\begin{proof}
Choose any $f,g\in\LSC_+(X)$. By Lem. \ref{lb788}, there exist increasing nets $(f_\alpha)_{\alpha\in I}$ and $(g_\beta)_{\beta\in J}$ in $C_c(X,\Rbb_{\geq0})$ converging pointwise to $f$ and $g$ respectively. Then $(f_\alpha+g_\beta)_{(\alpha,\beta)\in I\times J}$ is increasing and converges pointwise to $f+g$. By the monotone convergence Thm. \ref{lb789}, we have
\begin{align*}
\Lambda(f)+\Lambda(g)=\lim_{\alpha,\beta}\Lambda(f_\alpha)+\lim_{\alpha,\beta}\Lambda(g_\beta)=\lim_{\alpha,\beta}\Lambda(f_\alpha+g_\beta)=\Lambda(f+g)
\end{align*}
Choose an increasing sequence $(c_n)$ in $\Rbb_{\geq0}$ converging to $c\in\ovl\Rbb_{\geq0}$. Then by Lem. \ref{lb790} and Thm. \ref{lb789}, $c\Lambda(f)=\lim_{\alpha,n}c_n\Lambda(f_\alpha)=\lim_{\alpha,n}\Lambda(c_nf_\alpha)=\Lambda(cf)$.
\end{proof}











\subsection{The Riesz-Markov representation theorem}\label{mc235}



Fix an LCH space $(X,\mc T_X)$.


\begin{thm}[\textbf{Riesz-Markov representation theorem}] \index{00@Riesz-Markov representation theorem}\label{lb796}
For every $\Rbb_{\geq0}$-linear $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ there exists a unique Radon measure $\mu:\fk B_X\rightarrow\ovl\Rbb_{\geq0}$ such that
\begin{align}\label{eq317}
\Lambda(f)=\int_Xfd\mu
\end{align}
for all $f\in C_c(X,\Rbb_{\geq0})$. Moreover, every Radon measure on $X$ arises from some $\Lambda$ in this way.
\end{thm}

We call $\mu$ the \textbf{Radon measure associated to $\Lambda$}. \index{00@Radon measure associated to $\Lambda$} Note that if \eqref{eq317} holds for all $f\in C_c(X,\Rbb_{\geq0})$, then for each $f\in C_c(X)$, since $\int_X|f|d\mu<+\infty$, the RHS of \eqref{eq317} can be defined, and \eqref{eq317} holds true by the $\Cbb$-linearity. 

\begin{proof}
The uniqueness follows from Prop. \ref{lb791}. Every Radon measure $\mu$ arises from the $\Lambda$ defined by $\Lambda(f)=\int_Xfd\mu$ for all $f\in C_c(X,\Rbb_{\geq0})$. Note that $\Lambda(f)<+\infty$ by Lem. \ref{lb806}.

We now fix an $\Rbb_{\geq0}$-linear $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$, and construct the Radon measure $\mu$ satisfying \eqref{eq317}.\\[-1ex]

Step 1. Extend $\Lambda$ canonically to  $\Lambda:\LSC_+(X)\rightarrow\ovl\Rbb_{\geq0}$ which is increasing (cf. Def. \ref{lb793}) and $\ovl\Rbb_{\geq0}$-linear (by Prop. \ref{lb792}). For each $U\in\mc T_X$, define
\begin{align*}
\mu(U)=\Lambda(\chi_U)
\end{align*}
So $\mu(U)=\sup\big\{\Lambda(f):f\in C_c(U,[0,1])  \big\}$ by Exp. \ref{lb794}. We need to check that $\mu:\mc T_X\rightarrow[0,+\infty]$ satisfies conditions (a)-(e) in Asmp. \ref{lb712}. Clearly $\mu(\emptyset)=\Lambda(\chi_{\emptyset})=\Lambda(0)=0$. The monotonicity of $\mu$ follows from that of $\Lambda$. 

Conditions (c) and (d) can be proved in the same way as in Pb. \ref{lb713}. But here we provide a different proof without using the partition of unity. Choose countably many open sets $U_1,U_2,\dots$, and let $U=\bigcup_n U_n$. So $\chi_U\leq\sum_n\chi_{U_n}$. By the monotone convergence Thm. \ref{lb789} and the linearity of $\Lambda$, we have $\Lambda(\sum_n\chi_{U_n})=\sum_n\Lambda(\chi_{U_n})$. Therefore
\begin{align*}
\mu(U)=\Lambda(\chi_U)\leq\Lambda\Big(\sum_n\chi_{U_n}\Big)=\sum_n\Lambda(\chi_{U_n})=\sum_n\mu(U_n)
\end{align*}
This proves the countable subadditivity. If $U_1,U_2\in\mc T_X$ are disjoint, then $\chi_U=\chi_{U_1}+\chi_{U_2}$ where $U=U_1\cup U_2$. So
\begin{align*}
\mu(U)=\Lambda(\chi_U)=\Lambda(\chi_{U_1}+\chi_{U_2})=\Lambda(\chi_{U_1})+\Lambda(\chi_{U_2})=\mu(U_1)+\mu(U_2)
\end{align*}
This proves the additivity. We have finished proving (c) and (d).

Finally, the $\mu$-regularity on any open subset $U\subset X$ (i.e., condition (e)) can be proved in the same way as Lem. \ref{lb714}: Clearly $\mu_*(U)\leq\mu(U)$. To prove $\mu_*(U)\geq\mu(U)$, it suffices to prove $\mu_*(U)\geq \Lambda(f)$ for each $f\in C_c(U,[0,1])$. Let $K=\Supp(f)$, which is in $U$. So $\mu_*(U)\geq\mu^*(K)$. Clearly $\mu^*(K)\geq\Lambda(f)$ (since $\mu(V)=\Lambda(\chi_V)\geq\Lambda(f)$ for any open $V$ containing $K$). Therefore $\mu_*(U)\geq\Lambda(f)$.

We have finished proving that $\mu$ satisfies Asmp. \ref{lb712}. Therefore, by Thm. \ref{lb724}, the outer measure $\mu^*:2^X\rightarrow\ovl\Rbb_{\geq0}$ (defined by $\mu^*(E)=\inf\{\mu(U):U\in\mc T_X,U\supset E\}$) restricts to a measure on $\fk B_X$ and is denoted by $(\fk B_X,\mu)$. 

Since $(\fk B_X,\mu)$ is \textit{defined to be} $(\fk B_X,\mu^*)$, it is clear that $\mu$ is outer regular on Borel sets. For each $U\in\mc T_X$, we have proved that $\mu(U)=\mu_*(U)$, i.e., that $\mu(U)$ can be approximated by $\mu^*(K)$ where $K\subset U$ is compact. Since $\mu^*(K)=\mu(K)$ (because $\mu$ is outer regular on Borel sets),  $\mu$ is inner regular on any open set $U$. To prove that $\mu$ is Radon, it remains to prove that $\int_Xfd\mu<+\infty$ for each $f\in C_c(X,\Rbb_{\geq0})$. This follows from $\int_Xfd\mu=\Lambda(f)$, to be proved in the next step.\\[-1ex]

Step 2. Let us prove \eqref{eq317} for every $f\in C_c(X,\Rbb_{\geq0})$. In fact, we shall prove the more general fact that \eqref{eq317} is true for all $f\in\LSC_+(X)$.

First, note that if $U$ is open, then $\Lambda(\chi_U)=\mu(U)=\int_X\chi_Ud\mu$. Therefore \eqref{eq317} holds whenever $f=\chi_U$. By linearity, and by the two monotone convergence theorems (i.e., Thm. \ref{lb760} and \ref{lb789}), Eq. \eqref{eq317} holds if $f$ is the pointwise limit $f=\sum_{n=1}^\infty a_n\chi_{U_n}$ where $a_n\in\ovl\Rbb_{\geq0}$ and $U_n\in\mc T_X$. We let $\scr S$ be the set of all such $f$.

Now we choose any $f\in\LSC_+(X)$. To prove \eqref{eq317}, by the two monotone convergence theorems, it suffices to find an increasing sequence $(f_n)_{n\in\Zbb_+}$ in $\scr S$ converging pointwise to $f$.

Choose any $\eps>0$. For each $k\in\Nbb$, take $E_k=f^{-1}(k\eps,(k+1)\eps]$ and $E_\infty=f^{-1}(+\infty)$. Motivated by the proof of Prop. \ref{lb749}, we define $g_\eps:X\rightarrow\ovl\Rbb_{\geq0}$ to be the pointwise limit
\begin{subequations}\label{eq318}
\begin{align}\label{eq318a}
g_\eps=\sum_{k\in\Nbb} k\eps\cdot\chi_{E_k}+\infty\cdot \chi_{E_\infty}
\end{align}
so that $\Lambda(g_\eps)$ can be viewed as an infinite Lebesgue sum. Then $\lim_{\eps\rightarrow0} g_\eps$ converges pointwise to $f$. Let $f_n=g_{1/2^n}$. Then $(f_n)$ is increasing and converges pointwise to $f$. To finish the proof, it remains to show that $g_\eps\in\scr S$ (and hence $f_n\in\scr S$). 

For each $k\in\Nbb$, let $U_k=f^{-1}(k\eps,+\infty]$. Then $U_k$ is open because $f$ is lower semicontinuous. One checks easily that
\begin{align}\label{eq318b}
g_\eps=\sum_{k\in\Zbb_+} \eps\cdot\chi_{U_k}
\end{align}
\end{subequations}
(See also Fig. \ref{lb795}.) This proves $g_\eps\in\scr S$.
\end{proof}

\begin{figure}[h]
	\centering
\begin{equation*}
\vcenter{\hbox{{
			\includegraphics[width=3cm]{fig8.png}}}}
\end{equation*}
	\caption{. $g_\eps$ is the sum of all horizontal bars}\label{lb795}
\end{figure}

\begin{thm}\label{lb797}
Choose an $\ovl\Rbb_{\geq0}$-linear $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$, and let $\mu$ be the Radon measure associated to $\Lambda$.  Extend $\Lambda$ canonically to $\Lambda:\LSC_+(X)\rightarrow\ovl\Rbb_{\geq0}$. Then for each $f\in\LSC_+(X)$ we have $\dps \Lambda(f)=\int_Xfd\mu$.
\end{thm}


\begin{proof}
This was proved in Step 2 of the proof of Thm. \ref{lb796}.
\end{proof}

\begin{co}[\textbf{Monotone convergence theorem}]\index{00@Monotone convergence theorem for Radon measures}\label{lb798}
Let $\mu$ be a Radon measure on $\fk B_X$. Let $(f_\alpha)_{\alpha\in I}$ be an increasing net in $\LSC_+(X)$. Let $f$ be the pointwise limit $\lim_\alpha f_\alpha$. Then $f\in \LSC_+(X)$, and
\begin{align*}
\int_Xfd\mu=\lim_{\alpha\in I}\int_Xf_\alpha d\mu
\end{align*}
\end{co}


\begin{proof}
This follows immediately from Thm. \ref{lb797} and the monotone convergence Thm. \ref{lb789}.
\end{proof}


For more traditional proofs of the Riesz-Markov representation theorem without resorting to the canonical extension of $\Lambda$, see \cite[Thm. 2.14]{Rud-R} and \cite[Thm. 7.2]{Fol-R}. See also \cite[Prop. 7.12]{Fol-R} for a direct proof of Cor. \ref{lb798} without extending $\Lambda$.


\subsection{Regularity and Lusin's theorem}


In this section, we fix an LCH space $(X,\mc T_X)$, and let $(\fk M,\mu)$ be the completion of a Radon measure on $X$. 


\begin{eg}
Let $p\in X$, and let $(\fk M,\mu)$ be the completion of the Dirac Radon measure $(\fk B_X,\delta_p)$. Choose any $E\subset X$. If $p\notin E$, then $E\subset X\setminus\{p\}$ and $X\setminus\{p\}$ is null. So $E\in\fk M$ and $E$ is null. If $p\in E$, then $E=\{p\}\sqcup (E\setminus\{p\})$ where $\{p\}$ is Borel and $E\setminus\{p\}\in\fk M$. So $E\in\fk M$ and $\mu(E)=\mu(\{p\})=1$. We conclude that $(\fk M,\mu)=(2^X,\delta_p)$.
\end{eg}


\subsubsection{Regularity=measurability for sets with finite (outer) measures}


\begin{thm}\label{lb804}
Let $E\in\fk M$. Then $\mu$ is outer regular on $E$. Moreover, if $\mu(E)<+\infty$, then $\mu$ is inner regular on $E$.
\end{thm}


\begin{proof}
Let $\mu^*$ and $\mu_*$ be as in \eqref{eq292}. From the Riesz-Markov representation Thm. \ref{lb796}, we can assume that $(\fk B_X,\mu)$ arises from some linear $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$. Now, recall that when we constructed the Radon measure $\mu$ from $\Lambda$ (cf. Step 1 of the proof of Thm. \ref{lb796}), we showed  that $\mu|_{\mc T_X}$ satisfies conditions (a)-(e) in Asmp. \ref{lb712} so that we can apply Thm. \ref{lb724} to show that $(\fk B_X,\mu^*)$ is a measure, and we \textit{defined} $(\fk B_X,\mu)$ to be $(\fk B_X,\mu^*)$.

Note that Thm. \ref{lb724} says that $(\fk M_\mu,\mu^*)$ is a complete measure where $\fk M_\mu$ contains $\fk B_X$. Therefore $(\fk M_\mu,\mu^*)$ extends the completion $(\fk M,\mu)$ of $(\mc B_X,\mu)$ (cf. Thm. \ref{lb708}). Thus, for each $E\in\fk M$, we have $\mu^*(E)=\mu(E)$. This proves that $E$ is outer $\mu$-regular. \footnote{An alternative proof: Write $E=A\cup B$ where $A\in\fk B_X$ and $B$ is a subset of a Borel null set $C$. Then use the fact that $A$ and $C$ are outer $\mu$-regular (according to the definition of Radon measures).}

Assume that $E\in\fk M$ satisfies $\mu(E)<+\infty$. So $\mu^*(E)<+\infty$. Since $E\in\fk M_\mu$, by Prop. \ref{lb723}, we have $\mu^*(E)=\mu_*(E)$ and hence $\mu(E)=\mu_*(E)$. This means that $\mu(E)$ can be approximated from below by $\mu^*(K)$ where $K\subset E$ is compact. Note that $\mu^*(K)=\mu(K)$ by the last paragraph. So $\mu$ is inner regular on $E$.
\end{proof}


\begin{eg}
From the proof of Thm. \ref{lb804}, if $(\fk B_X,\mu)$ is a Radon measure, and if we use Thm. \ref{lb724} to construct a new Borel measure, then this new Borel measure (which is the restriction of $\mu^*$ to $\fk B_X$) is equal to the original one $\mu$. We now show that if $\mu$ is not Radon, the new measure might be different from $\mu$.

We know that the counting measure is a Radon measure if $X$ is equipped with the discrete topology. Now, consider $X=\Rbb$ equipped with the \textit{Euclidean} topology. Let $(\fk B_X,\mu)$ be the counting measure which is not Radon. Then the new Borel measure constructed from Thm. \ref{lb724} is $(\fk B_X,\mu^*)$ and satisfies $\mu^*(E)=+\infty$ iff $E\neq\emptyset$. So $\mu^*(E)\neq\mu(E)$ if $E$ is a finite set.  \hfill\qedsymbol
\end{eg}

\begin{comment}
\begin{rem}
Rudin included Thm. \ref{lb804} as part of the statement of the Riesz-Markov representation theorem, see (c) and (d) of \cite[Thm. 2.14]{Rud-R}. In other words, Rudin proved Thm. \ref{lb804} in the course of proving Thm. \ref{lb796}. This also explains the nature of our proof of Thm. \ref{lb804}, i.e., that Thm. \ref{lb804} is a (rather direct) consequence of \textit{the proof} of Thm. \ref{lb796}.
\end{rem}
\end{comment}



As an application of Thm. \ref{lb804}, we  give a corollary similar to Cor. \ref{lb731}. (In fact, it shows that if $\fk M_\mu$ is as in the proof of Thm. \ref{lb804}, then for any $E\in\fin(2^X)$ satisfying $\mu^*(E)<+\infty$, we have $E\in\fk M_\mu$ iff $E\in\fk M$.) We first need a definition.

\begin{df}
Let $Y$ be a topological space. A subset $E\subset Y$ is called a \pmb{$G_\delta$}\textbf{ set} \index{00@$G_\delta$ set} (of $Y$) if $E$ is a countable intersection of open subsets of $Y$. $E$ is called an \pmb{$F_\sigma$}\textbf{ set} \index{00@$F_\sigma$ set} (of $Y$) if $E^c$ is a $G_\delta$ set, equivalently, if $E$ is a countable union of closed subsets of $Y$. $E$ is called a \pmb{$\sigma$}\textbf{-compact} set \index{00@$\sigma$-compact} if $E$ is a countable union of compact sets.\footnote{I wonder why $\sigma$-compact sets are not called $K_\sigma$ sets, or why $G_\delta$ sets and $F_\sigma$ sets are not called $\delta$-open sets and $\sigma$-closed sets.} If $Y$ is Hausdorff, a $\sigma$-compact set is clearly $F_\sigma$ in $Y$.
\end{df}

Note that the meanings of $G_\delta$ and $F_\sigma$ depend on the ambient space $Y$, but the meaning of $\sigma$-compactness does not. In this course, we will primarily use $\sigma$-compactness rather than $F_\sigma$-ness. But note that these two notions are often equivalent: 

\begin{sexe}
Assume that the LCH space $X$ is $\sigma$-compact (e.g. when $X$ is second countable, cf. Exp. \ref{lb831}). Prove that a subset $E$ of $X$ is $\sigma$-compact iff $E$ is an $F_\sigma$ subset of $X$. 
\end{sexe}


\begin{co}\label{lb830}
Let $E\subset X$ such that $E$ is contained in an open set with finite $\mu$-measure. Then the following are equivalent.
\begin{enumerate}
\item[(1)] $E\in\fk M$.
\item[(2)] For every $\eps>0$ there exist a compact set $K\subset X$ and an open set $U\subset X$ such that $K\subset E\subset U$ and $\mu(U\setminus K)<\eps$.
\item[(2')] There exist a $\sigma$-compact set $A\subset X$ and a $G_\delta$ set $B\subset X$ such that $A\subset E\subset B$ and $\mu(B\setminus A)=0$.  
\end{enumerate}
\end{co}

Note that the assumption that $E$ is contained in a finite-measure open set simply means that $\mu^*(E)<+\infty$.

\begin{proof}
(1)$\Rightarrow$(2): This is clear from Thm. \ref{lb804}. 

(2)$\Rightarrow$(2'): Assume (2). For each $n\in\Zbb_+$, one can choose an open $U_n\supset E$ and a compact $K_n\subset E$ such that $\mu(U_n\setminus K_n)<1/n$. Take $A=\bigcup_n K_n$ and $B=\bigcap_n U_n$. Since $B\setminus A\subset\bigcap_n (U_n\setminus K_n)$, we have $\mu(B\setminus A)\leq \mu(U_n\setminus K_n)<1/n$ for all $n$. Therefore $\mu(B\setminus A)=0$.

(2')$\Rightarrow$(1): This follows immediately from the fact that $A,B\in\fk B_X$ and $(\fk M,\mu)$ is the completion of $(\fk B_X,\mu)$.
\end{proof}


One can also prove (2')$\Rightarrow$(2) directly (by Prop. \ref{lb748}-(c)) without first proving (2')$\Rightarrow$(1). Therefore, the readers should regard (2) and (2') as two ways of expressing the same fact. (But note that we do not have (2')$\Rightarrow$(2) when $\mu^*(E)=+\infty$.)

\begin{rem}
Recall that from the definition of measure completion (cf. Thm. \ref{lb708}), we know that a set $E\subset X$ belongs to $\fk M$ iff one can find Borel sets $A,B$ such that $A\subset E\subset B$ and $\mu(B\setminus A)=0$. Now, Cor. \ref{lb830} tells us that if $E\in\fk M$ and $\mu(E)<+\infty$, then $A$ and $B$ can be chosen to be  $G_\delta$ and $\sigma$-compact, which are much more explicit than general Borel sets. 
\end{rem}




\begin{co}\label{lb834}
Let $E\subset X$. Then the following are equivalent.
\begin{enumerate}
\item[(1)] $E\in\fk M$, and $\mu(E)=0$.
\item[(2)] There is a $G_\delta$ set $B$ containing $E$ such that $\mu(B)=0$.
\end{enumerate}
\end{co}

\begin{proof}
``(2)$\Rightarrow$(1)" is clear due to the completeness of $\mu$. Assume (1). By Thm. \ref{lb804}, for each $n\in\Zbb_+$ there is an open $U_n\supset E$ such that $\mu(U_n)<1/n$. So $E$ is contained in the $G_\delta$-set $B=\bigcap_n U_n$. Since $\mu(B)\leq\mu(U_n)<1/n$ for all $n$, we have $\mu(B)=0$.
\end{proof}






\subsubsection{Approximation by continuous functions}

As an important application of Thm. \ref{lb804}, we prove Lusin's theorem, which says that any Radon-measurable function is ``almost continuous" on any measurable subset with finite measure. This result will be used in the future to show that $C_c(X)$ is dense in $L^p(X,\mu)$ if $1\leq p<+\infty$ (cf. Thm. \ref{lb866}).

Recall that $(\fk M,\mu)$ is the completion of a Radon measure on $X$. 

\begin{thm}[\textbf{Lusin's theorem}] \index{00@Lusin's theorem}\label{lb865}
Let $f:X\rightarrow\Cbb$ be measurable. Let $A\in\fk M$ such that $\mu(A)<+\infty$. Then for every $\eps>0$ there is a compact $K\subset A$ such that $\mu(A\setminus K)<\eps$, and that $f|_K:K\rightarrow\Cbb$ is continuous.
\end{thm}

It follows from the Tietze extension Thm. \ref{lb468} that there exists $g\in C_c(X)$ such that $g|_K=f|_K$, and that $\Vert g\Vert_{l^\infty(X)}\leq \Vert f\Vert_{l^\infty(X)}$.



\begin{proof}
By replacing $f$ with $f\chi_A$, we assume that $f$ vanishes outside $A$.

Case 1: $f=\chi_E$ where $E\in\fk M$ and $E\subset A$. Let $F=A\setminus E$. By Thm. \ref{lb804}, there exist compact $K_1\subset E$ and $K_2\subset F$ such that $\mu(E\setminus K_1)<\eps/2$ and $\mu(F\setminus K_2)<\eps/2$. Let $K=K_1\cup K_2$. Since $K_1\cap K_2=\emptyset$, we have $K_1=K\setminus K_2$ and $K_2=K\setminus K_1$. So $K_1,K_2$ are open subsets of $K$. Therefore, since $f|_{K_1}$ and $f|_{K_2}$ are constant functions, $f|_K$ is continuous by the local to global principle (Exe. \ref{lb184}). Clearly $\mu(A\setminus K)<\eps$.

Case 2: $f$ is a simple function $X\rightarrow\Cbb$ vanishing outside $A$. Then $f=a_1f_1+\cdots+a_nf_n$ where $a_i\in\Cbb$ and $f_i$ is as in Case 1. Thus, by Case 1, there exists a compact $K_i\subset A$ with $\mu(A\setminus K_i)<\eps/n$ such that $f_i|_{K_i}$ is continuous. So $f$ is continuous on $K=K_1\cap\cdots\cap K_n$, and $\mu(A\setminus K)<\eps$.

Case 3: $f\in\mc L(X,\Cbb)$ vanishes outside $A$, and $\Vert f\Vert_{l^\infty}<+\infty$. By considering $\Real(f)$ and $\Imag(f)$ separately, we assume that $f$ is real. By considering $f^+=\max\{f,0\}$ and $f^-=\min\{-f,0\}$ separately, we assume $f\geq0$. By Rem. \ref{lb807}, we can find an increasing sequence of simple functions $s_n:X\rightarrow\Rbb_{\geq0}$ converging uniformly to $f$. Since $s_n\leq f$, $s_n$ vanishes outside $A$. Therefore, by case 2, there is a compact $K_n\subset A$ such that $\mu(A\setminus K_n)<\eps/2^n$, and that $s_n|_{K_n}$ is continuous. Let $K=\bigcap_n K_n$, which is a compact subset of $A$ satisfying $\mu(A\setminus K)<\eps$. Since each $s_n$ is continuous on $K$, and since $(s_n)$ converges uniformly on $K$ to $f$, we conclude that $f$ is continuous on $K$.

Case 4: the general case. For each $n\in\Zbb_+$, let $E_n=|f|^{-1}(n,+\infty)$. Since $\bigcap_n E_n=\emptyset$ and $\mu(E_1)\leq\mu(A)<+\infty$, we have $\lim_n\mu(E_n)=0$. Choose $n$ such that $\mu(E_n)<\eps/2$. Let $F_n=A\setminus E_n$. By Case 3, there exists a compact $K\subset F_n$ such that $\mu(F_n\setminus K)<\eps/2$, and that $f|_K$ is continuous. We have $\mu(A\setminus K)<\eps$.
\end{proof}

The converse of Lusin's theorem is given in Pb. \ref{lb868} and Rem. \ref{lb870}. The readers should compare Lusin's theorem and its converse with Lebesgue's criterion for Riemann integrable functions (Thm. \ref{lb411}).








%% Record #10 2024/03/28 three lectures  25



\subsection{A criterion for Radon measures}\label{lb822}


The goal of this section is to give an extremely useful criterion for Radoness, namely, Thm. \ref{lb818}. We first show some elementary facts about $\sigma$-finiteness. (Recall Def. \ref{lb1031}.)


\begin{rem}\label{lb809}
Let $(\fk M,\mu)$ be a Radon measure (or its completion) on an LCH space $X$. The following conditions are equivalent.
\begin{enumerate}
\item[(1)] $\mu$ is a $\sigma$-finite measure on $\fk M$.
\item[(2)] There exists an increasing sequence of open sets $U_1\subset U_2\subset\cdots$ such that $X=\bigcup_n U_n$ and that $\mu(U_n)<+\infty$ for each $n$.
\end{enumerate}
\end{rem}

\begin{proof}
Clearly (2) implies (1). Assume (1). Then $X=E_1\cup E_2\cup\cdots$ where $E_n\in\fk M$ and $\mu(E_n)<+\infty$. By Thm. \ref{lb804}, $\mu$ is outer regular on $E_n$. So we can find an open $V_n\supset E_n$ such that $\mu(V_n)<+\infty$. Take $U_n=V_1\cup\cdots\cup V_n$.
\end{proof}





\begin{eg}\label{lb831}
Assume that $X$ is a second countable LCH space. Then $X$ is a countable union of precompact open subsets. In particular, every Radon measure is $\sigma$-finite on $X$.
\end{eg}

\begin{proof}
Since $X$ is LCH, $X$ is a union of precompact open sets. Since $X$ is second countable, $X$ is Lindel\"of (by Cor. \ref{lb265}). Therefore, $X$ is a countable union of precompact open sets (which have finite measures under any Radon measure).
\end{proof}


\begin{thm}\label{lb818}
Let $X$ be a second countable LCH space. Let $\mu:\fk B_X\rightarrow[0,+\infty]$ be a measure such that $\mu(K)<+\infty$ for every compact subset $K\subset X$. Then $\mu$ is a Radon measure.
\end{thm}


\begin{proof}
Step 1. By Lem. \ref{lb806}, we have $\int_Xfd\mu<+\infty$ for every $f\in C_c(X,\Rbb_{\geq0})$. Therefore, we have an $\Rbb_{\geq0}$-linear map
\begin{align*}
\Lambda: C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}\qquad\Lambda(f)=\int_Xfd\mu
\end{align*}
By Riesz-Markov, there is a unique Radon measure $\lambda$ on $X$ satisfying
\begin{align*}
\Lambda(f)=\int_Xfd\lambda
\end{align*}
for all $f\in C_c(X,\Rbb_{\geq0})$. We shall prove $\mu=\lambda$.\\[-1ex]

Step 2. Let us prove that $\mu(U)=\lambda(U)$ for any nonempty open $U\subset X$. Since $\lambda$ is inner regular on open sets, we know that $\lambda(U)$ is the supremum of $\int fd\lambda=\Lambda(f)=\int fd\mu$ for all $f\in C_c(U,[0,1])$. Suppose that we can prove that $\mu$ is inner regular on open sets, then by Lem. \ref{lb777},  $\mu(U)$ is also the supremum of $\int fd\mu$ where $f\in C_c(U,[0,1])$. This proves $\mu(U)=\lambda(U)$.

To prove that $\mu$ is inner regular on $U$, note that since $U$ is LCH (cf. Prop. \ref{lb245}) and second countable, by Exp. \ref{lb831}, $U$ is a countable union of precompact open subsets. Therefore, we have a sequence of compact subsets $(K_n)$ of $U$ whose union is $U$. By replacing each $K_n$ with $K_1\cup\cdots\cup K_n$ we assume that $(K_n)$ is increasing. Therefore $\mu(U)=\lim_n\mu(K_n)$. This proves that $\mu(U)$ can be approximated by the measures of compact subsets. So $\mu$ is inner regular on $U$.\\[-1ex]

Step 3. Let us prove that $\mu(E)=\lambda(E)$ whenever $E\in\fk B_X$ is contained in an open subset $U$ with finite $\lambda$-measure. Choose any $\eps>0$. By Cor. \ref{lb830}, there exist an open set $U\subset X$ with $\lambda(U)<+\infty$ and a compact set $K\subset E$ such that $\lambda(U\setminus K)<\eps$. By Step 2, we have $\mu(U)=\lambda(U)$ and $\mu(U\setminus K)=\lambda(U\setminus K)<\eps$. Hence $\mu(U\setminus E)<\eps$ and $\lambda(U\setminus E)<\eps$. Therefore $|\mu(U)-\mu(E)|<\eps$ and $|\lambda(U)-\lambda(E)|<\eps$, and hence $|\mu(E)-\lambda(E)|<2\eps$. Since $\eps$ is arbitrary, we get $\mu(E)=\lambda(E)$.\\[-1ex]


Step 4. Choose any $E\in\fk B$. By Exp. \ref{lb831}, we have $X=\bigcup_{n=1}^\infty U_n$ where each $U_n$ is open and precompact. Since $\lambda$ is Radon, we have $\lambda(U_n)<+\infty$. Let $E_1=E\cap U_1$ and $E_n=E\cap \big(U_n\setminus(U_1\cup\cdots\cup U_n)\big)$ if $n>1$. Then $E$ is a disjoint union of $(E_n)_{n\in\Zbb_+}$. By Step 3, we have $\mu(E_n)=\lambda(E_n)$ for all $n$. By the countable additivity of $\mu$ and $\lambda$, we get $\mu(E)=\lambda(E)$.
\end{proof}



\begin{rem}
The readers may wonder if there is a direct proof of Thm. \ref{lb818} without appealing to linear functionals and Riesz-Markov. Note that part of the above proof of Thm. \ref{lb818} shows that every open set $U$ is inner $\mu$-regular. Therefore, it remains to prove that every Borel set is outer $\mu$-regular. A  natural idea is to prove that the set of $\mu$-regular Borel sets form a $\sigma$-algebra. This idea actually works when $\mu$ is a finite measure, and also works when $\mu(X)=+\infty$ if one considers locally $\mu$-regular sets instead. 

We will present such a proof in Subsec. \ref{lb824}, and we encourage the readers to read through that subsection. This will help the readers understand why Thm. \ref{lb818} can also be proved by the Riesz-Markov representation Thm. \ref{lb796}: It is because the proof of Riesz-Markov relies on Thm. \ref{lb724}, and the proof of the latter theorem is similar to the approach in Subsec. \ref{lb824}.    \hfill\qedsymbol
\end{rem}







\begin{eg}\label{lb819}
Let $X$ be a second countable LCH space. Let $\mu$ be a Radon measure on $X$. Let $\varphi:X\rightarrow\ovl\Rbb_{\geq0}$ be a Borel function such that $\int_K\varphi d\mu<+\infty$ for every compact $K\subset X$. Then the Borel measure $\nu$ defined by $d\nu=\varphi d\mu$ (cf. Pb. \ref{lb328}) is finite on compact sets. Therefore, by Thm. \ref{lb818}, $\nu$ is Radon.
\end{eg}

\begin{eg}
Let $X$ be a compact metric space. Then, by Thm. \ref{lb252}, $X$ is second countable. Therefore, by Thm. \ref{lb818}, a Radon measure on $X$ is equivalently a finite Borel measure.
\end{eg}




\subsection{$\star$ Regularity beyond finite measures}

Fix an LCH space $(X,\mc T_X)$, and let $(\fk M,\mu)$ be the completion of a Radon measure on $X$. In this section, we prove a variant of Cor. \ref{lb830}. Since this result will not be used elsewhere in the course, readers may skip this section without concern.


\begin{thm}\label{lb808}
Assume that $\mu$ is $\sigma$-finite (on $X$). Let $E\subset X$. Then the following are equivalent.
\begin{enumerate}
\item[(1)] $E\in\fk M$.
\item[(2)] For every $\eps>0$ there exist a closed set $F\subset X$ and an open set $U\subset X$ such that $F\subset E\subset U$ and $\mu(U\setminus F)<\eps$. 
\end{enumerate}
\end{thm}



\begin{proof}
(2)$\Rightarrow$(1): Similar to the proof of Cor. \ref{lb830}, (2) implies that there is an $F_\sigma$ set $A$ and a $G_\delta$ set $B$ such that $A\subset E\subset B$ and $\mu(B\setminus A)=0$. \footnote{We didn't single out this property and call it (2') because we will not use this property in the future of this course, and also because without assuming $\mu^*(E)<+\infty$ as in Cor. \ref{lb830}, one cannot prove (2')$\Rightarrow$(2) directly without first proving (2')$\Rightarrow$(1).} Since $A,B$ are Borel and $(\fk M,\mu)$ is complete, we conclude $E\in\fk M$.


(1)$\Rightarrow$(2): Let $E\in\fk M$. To prove (2), it suffices to find an open $U$ containing $E$ such that $\mu(U\setminus E)<\eps/2$. Then, a similar argument gives an open set $V$ containing $E^c$ such that $\mu(V\setminus E^c)<\eps/2$. Write $V=X\setminus F$ where $F$ is closed. Then $F\subset E\subset U$ and $\mu(E\setminus F)<\eps/2$. So $\mu(U\setminus F)<\eps$.

Since every $\sigma$-finite measure is $\sigma$-finite on every measurable subset, we can write $E$ as a countable union $E=\bigcup_n E_n$ where $E_n\in\fk M$ and $\mu(E_n)<+\infty$. By Thm. \ref{lb804}, there exists an open $U_n$ containing $E_n$ such that $\mu(U_n)<\mu(E_n)+\eps/2^{n+1}$, and hence $\mu(U_n\setminus E_n)<\eps/2^{n+1}$. Let $U=\bigcup_nU_n$. Then $U\setminus E\subset\bigcup_n(U_n\setminus E_n)$, and hence $\mu(U\setminus E)<\eps/2$.
\end{proof}



\begin{comment}
A $\sigma$-compact set is clearly $F_\sigma$. In view of the similarity between Cor. \ref{lb830} and Thm. \ref{lb808}, one naturally wonders if the converse is true. The following is an answer:

\begin{sexe}
Assume that $X$ is $\sigma$-compact (which is automatic when $X$ is second countable). Let $A\subset X$. Prove that $A$ is $\sigma$-compact iff $A$ is $F_\sigma$.
\end{sexe}


\begin{srem}
In (2') of Thm. \ref{lb808}, one can choose $A$ to be $\sigma$-compact. (Recall that $\sigma$-compact sets are $F_\sigma$.) To see this, take $E\in\fk M$. Since $\mu$ is $\sigma$-finite, we can write $E$ as a countable union $E=\bigcup_n E_n$ where each $E_n\in\fk M$ has finite measure. By Cor. \ref{lb830}, there is a $\sigma$-compact subset $A_n$ of $E_n$ such that $\mu(E_n\setminus A_n)=0$. Then $A=\bigcup_n A_n$ is $\sigma$-compact, and $\mu(E\setminus A)=0$. Thus, for any $B$ as in (2') of Thm. \ref{lb808}, since $\mu(B\setminus E)=0$, we have $\mu(B\setminus A)=0$.
\end{srem}

\end{comment}

\subsection{Stieltjes integrals and Radon measures on $[a,b]$}

Let $-\infty<a<b<+\infty$. The original version of the Riesz-Markov representation was proved for $X=[a,b]$ by Riesz in 1909 without appeal to measure theory. This \textbf{Riesz representation theorem} says that the (positive) linear functionals on $C[a,b]$ can be realized by Stieltjes integrals. In this section, we will explain how this result follows from the Riesz-Markov representation theorem. 



\subsubsection{Stieltjes integrals}\label{lb1009}


Recall Subsec. \ref{lb384} for the meaning of partitions and their refinements. The set of partitions of $[a,b]$ is denoted by $\mc P[a,b]$. For simplicity, we define Stieltjes integrals using Darboux sums instead of Riemann sums.



Let $\rho:[a,b]\rightarrow\Rbb_{\geq0}$ be increasing (i.e. $\rho(x)\leq \rho(y)$ if $x\leq y$). Let $f:[a,b]\rightarrow\Rbb$ be bounded. For each partition 
\begin{align*}
\sigma=\big(\{a_0=a<a_1<\cdots<a_n=b\} \big)
\end{align*}
of $[a,b]$, define the \textbf{lower Darboux sum} and the \textbf{upper Darbox sum} to be
\begin{subequations}
\begin{gather}
\udl S(f,\sigma,\rho)=\sum_{i=1}^n(\inf f(a_{i-1},a_i])\cdot(\rho(a_i)-\rho(a_{i-1}))\\
\ovl S(f,\sigma,\rho)=\sum_{i=1}^n(\sup f(a_{i-1},a_i])\cdot(\rho(a_i)-\rho(a_{i-1}))
\end{gather}
\end{subequations}
Clearly $\udl S(f,\sigma,\rho)\leq \ovl S(f,\sigma,\rho)$, and $\udl S(f,\sigma,\rho)$ increases as $\sigma$ is refined, and $\ovl S(f,\sigma,\rho)$ decreases as $\sigma$ is refined. Let
\begin{align}\label{eq340}
A(f,\sigma)=\sup_i \diam f(a_{i-1},a_i]
\end{align}
Then
\begin{align}\label{eq336}
\ovl S(f,\sigma,\rho)-\udl S(f,\sigma,\rho)\leq A(f,\sigma)\cdot(\rho(b)-\rho(a))
\end{align}

Define the \textbf{lower Darboux integral} and the \textbf{upper Darboux integral} to be
\begin{align}
\udl\int_a^b fd\rho=\sup_{\sigma\in\mc P[a,b]}\udl S(f,\sigma,\rho)\qquad \ovl\int_a^b fd\rho=\inf_{\sigma\in\mc P[a,b]}\ovl S(f,\sigma,\rho)
\end{align}
Clearly $\udl S(f,\sigma,\rho)\leq \udl\int_a^b fd\rho\leq\ovl\int_a^b fd\rho\leq \ovl S(f,\sigma,\rho)$. 


\begin{df}
We say that a bounded function $f:[a,b]\rightarrow\Rbb$ is \textbf{Stieltjes integrable} with respect to $\rho$  if the lower integral $\udl\int_a^b fd\rho$ is equal to the upper integral $\ovl\int_a^b fd\rho$. When these two values are equal, we denote them by $\dps \int_a^bfd\rho$ and call it the \textbf{Stieltjes integral} \index{00@Stieltjes integral} of $f$ with respect to $\rho$.
\end{df}


\begin{thm}\label{lb893}
Let $\rho:[a,b]\rightarrow\Rbb_{\geq0}$ be increasing. Then each $f\in C([a,b],\Rbb)$ is Stieltjes integrable with respect to $\rho$, and
\begin{align}
\mc I_\rho:C([a,b],\Rbb)\rightarrow\Rbb\qquad\mc I_\rho(f)=f(a)\rho(a)+\int_a^bfd\rho
\end{align}
is a positive linear functional.
\end{thm}

The Stieltjes integral $\int_a^bfd\rho$ should be viewed as an integral on $(a,b]$ rather than on $[a,b]$. (This is compatible with the fact that $\int_a^bfd\rho+\int_b^cfd\rho=\int_a^cfd\rho$, because $(a,c]=(a,b]\sqcup(b,c]$ if $c>b$.) This is why we need the extra term $f(a)\rho(a)$ in the definition of $\mc I_\rho(f)$.

\begin{proof}
Define $\udl{\mc I}_\rho,\ovl{\mc I}_\rho:C([a,b],\Rbb)\rightarrow\Rbb$ by $\udl{\mc I}_\rho(f)=f(a)\rho(a)+\udl\int_a^b fd\rho$ and $\ovl{\mc I}_\rho(f)=f(a)\rho(a)+\ovl\int_a^b fd\rho$. It is easy to check that $\udl{\mc I}_\rho(cf)=c\udl{\mc I}_\rho(f)$, $\ovl{\mc I}_\rho(cf)=c\ovl{\mc I}_\rho(f)$, $\udl{\mc I}_\rho(f+g)\geq \udl{\mc I}_\rho(f)+\udl{\mc I}_\rho(g)$, $\ovl{\mc I}_\rho(f+g)\leq \ovl{\mc I}_\rho(f)+\ovl{\mc I}_\rho(g)$ if $f,g\in C([a,b],\Rbb)$ and $c\in\Rbb_{\geq0}$. Also $\udl{\mc I}_\rho(-f)=-\ovl{\mc I}_\rho(f)$. The linearity of $\mc I_\rho$ follows immediately if we can prove $\udl{\mc I}_\rho=\ovl{\mc I}_\rho$, and the positivity is obvious.

Since $f\in C([a,b],\Rbb)$ is continuous and $[a,b]$ is compact, $f$ is uniformly continuous. Therefore, for each $\eps>0$ there exists a partition $\sigma$ such that $A(f,\rho)\leq\eps$, and hence $\ovl{\mc I}_\rho(f)-\udl{\mc I}_\rho(f)\leq \eps(\rho(b)-\rho(a))$ by \eqref{eq336}. This finishes the proof since $\eps$ can be arbitrary.
\end{proof}


\begin{eg}
Let $\rho(x)=x-a$. For each $f\in C([a,b],\Rbb)$, $\int_a^bfd\rho$ is the Riemann integral of $f$.
\end{eg}


\begin{eg}
Let $c\in[a,b]$ and $\rho=\chi_{[c,b]}$. Let $f:[a,b]\rightarrow\Rbb$ be bounded and left continuous at $c$. Then $f$ is Stieltjes integrable with respect to $\rho$, and $\mc I_\rho(f)=f(c)$.
\end{eg}

\begin{eg}
If $f$ is Stieltjes integrable with respect to $\rho_1,\rho_2$, then $f$ is Stieltjes integrable with respect to $\rho=k_1\rho_1+k_2\rho_2$ (where $k_1,k_2\in\Rbb_{\geq0}$), and 
\begin{align*}
\mc I_\rho(f)=k_1\mc I_{\rho_1}(f)+k_2\mc I_{\rho_2}(f)
\end{align*}
\end{eg}


\begin{eg}
Let $\{c_1<\cdots<c_n\}\subset[a,b]$. Let $\rho=\id+\sum_{i=1}^n\chi_{[c_i,b]}$ where $\id:x\in[a,b]\mapsto x\in\Rbb$. Let $f:[a,b]\rightarrow\Rbb$ be continuous. Then by the above examples, we have
\begin{align*}
\mc I_\rho(f)=\int_a^bfdx+\sum_{i=1}^n f(c_i)
\end{align*}
\end{eg}





\subsubsection{The Riesz representation theorem}


A function $\rho:[a,b]\rightarrow\Rbb$ is called \textbf{right continuous} \index{00@Right continuous} if for each $p\in[a,b]$ we have $\lim_{x\rightarrow p^+}f(x)=f(p)$. This is equivalent to saying that for each $p\in[a,b]$ and each sequence $(x_n)$ in $[p,b]$ converging to $p$ we have $\lim_nf(x_n)=f(p)$.


The following lemma shows that $\rho$ can be recovered from $\mc I_\rho$ if $\rho$ is right continuous.

\begin{lm}\label{lb850}
Let $\rho:[a,b]\rightarrow\Rbb_{\geq0}$ be increasing. Assume $a\leq c<d\leq b$. Let $f\in C([a,b],[0,1])$ such that $f|_{[a,c]}=1$ and $f|_{[d,b]}=0$. Then
\begin{align}\label{eq337}
\rho(c)\leq\mc I_\rho(f)\leq \rho(d)
\end{align}
Therefore, if $\rho$ is right continuous, and if $(f_n)$ is a sequence in $C([a,b],[0,1])$ such that $f_n|_{[a,c]}=1$ and $f_n|_{[c+1/n,b]}=0$, then
\begin{align}\label{eq338}
\lim_{n\rightarrow\infty}\mc I_\rho(f_n)=\rho(c)
\end{align}
\end{lm}


\begin{proof}
Let $\sigma_1=\{a,c,b\}$ and $\sigma_2=\{a,d,b\}$. Then $\udl S(f,\sigma_1,\rho)=\rho(c)-\rho(a)$ and $\ovl S(f,\sigma_2,\rho)=\rho(d)-\rho(a)$. This proves $\rho(c)-\rho(a)\leq\int_a^bfd\rho\leq\rho(d)-\rho(a)$, and hence proves \eqref{eq337}. 

We now have $\rho(c)\leq\mc I_\rho(f_n)\leq\rho(c+1/n)$. Let $n\rightarrow\infty$. Then the right continuity of $\rho$ implies \eqref{eq338}.
\end{proof}





\begin{thm}[\textbf{Riesz representation theorem}]\index{00@Riesz representation theorem for $C([a,b],\Rbb_{\geq0})$}\label{lb847}
We have a bijection from the set of increasing right continuous functions $[a,b]\rightarrow\Rbb_{\geq0}$ to the set of positive linear functionals on $C([a,b],\Rbb)$ defined by
\begin{align}\label{eq339}
\rho\mapsto\mc I_\rho 
\end{align}
\end{thm}


\begin{proof}
By Lem. \ref{lb850}, the map \eqref{eq339} is injective. Let us prove that \eqref{eq339} is surjective. Choose any positive linear functional $\Lambda:C([a,b],\Rbb)\rightarrow\Rbb$. By the Riesz-Markov representation Thm. \ref{lb796}, there is a Radon measure $\mu$ on $[a,b]$ such that $\int_{[a,b]}fd\mu=\Lambda(f)$ for all $f\in C([a,b],\Rbb)$. Since $[a,b]$ is compact, $\mu$ is a finite measure. Define
\begin{align}\label{eq341}
\rho_\mu:[a,b]\rightarrow\Rbb_{\geq0}\qquad \rho_\mu(x)=\mu([a,x])
\end{align}
Clearly $\rho_\mu$ is increasing. If $(x_n)$ is a decreasing sequence in $[x,b]$ converging to $x$, then $\bigcap_{n\in\Zbb_+}[a,x_n]=[a,x]$. Therefore $\mu([a,x])=\lim_n \mu([a,x_n])$. This proves that $\rho_\mu$ is right continuous. \footnote{If $(x_n)$ is an increasing sequence in $[a,x)$ converging to $x$, then $\bigcup_n[a,x_n]=[a,x)$. Thus, $\rho$ might not be left continuous because $\mu([a,x))$ and $\mu([a,x])$ are possibly different.} Let us prove for each $f\in C([a,b],\Rbb)$ that $\mc I_{\rho_\mu}(f)=\Lambda(f)$, i.e., that
\begin{align}\label{eq344}
\mc I_{\rho_\mu}(f)=\int_{[a,b]}fd\mu
\end{align}
In the following, we write $\rho_\mu$ as $\rho$ for simplicity.

Since $f$ is uniformly continuous, for each $\eps>0$ there is a partition $\sigma=\{a_0<\cdots<a_n\}$ of $[a,b]$ such that $A(f,\sigma)$ (defined by \eqref{eq340}) satisfies $A(f,\sigma)\leq\eps$. In other words, if
\begin{align*}
m_i=\inf f(a_{i-1},a_i]\qquad M_i=\sup f(a_{i-1},a_i]
\end{align*}
then $M_i-m_i\leq\eps$ for all $i$. Thus, we have (cf. \eqref{eq336})
\begin{align}\label{eq342}
\big(f(a)\rho(a)+\ovl S(f,\sigma,\rho)\big)-\big(f(a)\rho(a)-\udl S(f,\sigma,\rho)\big)\leq \eps\big(\rho(b)-\rho(a)\big)
\end{align}
Our goal is to find bounded Borel functions $g,h:[a,b]\rightarrow\Rbb$ such that $g\leq f\leq h$ and
\begin{align}\label{eq343}
f(a)\rho(a)+\udl S(f,\sigma,\rho)=\int_{[a,b]}gd\mu\qquad f(a)\rho(a)+\ovl S(f,\sigma,\rho)=\int_{[a,b]}hd\mu
\end{align}
Then both $\int_{[a,b]}fd\mu$ and $\mc I_\rho(f)$ are between $f(a)\rho(a)+\udl S(f,\sigma,\rho)$ and $f(a)\rho(a)+\ovl S(f,\sigma,\rho)$. Therefore, by \eqref{eq342}, the difference of $\int_{[a,b]}fd\mu$ and $\mc I_\rho(f)$ is bounded by $2\eps(\rho(b)-\rho(a))$. This finishes the proof since $\eps$ can be arbitrary.

Define
\begin{gather}\label{eq358}
g=f(a)\chi_{\{a\}}+\sum_{i=1}^n m_i\cdot\chi_{(a_{i-1},a_i]}\qquad h=f(a)\chi_{\{a\}}+\sum_{i=1}^n M_i\cdot\chi_{(a_{i-1},a_i]}
\end{gather}
Then clearly $g\leq f\leq h$. Since 
\begin{align*}
\mu(\{a\})=\rho(a)\qquad \mu((a_{i-1},a_i])=\rho(a_i)-\rho(a_{i-1})
\end{align*}
\eqref{eq343} is clearly satisfied.
\end{proof}


\subsubsection{The second proof of the Riesz representation theorem}\label{lb923}

Since the statement of the Riesz representation Thm. \ref{lb847} does not involve measures, one naturally wonders whether it is possible to prove this theorem without resorting to measures. The answer is yes:


\begin{proof}[\textbf{\hypertarget{SecondRiesz}{Second proof} of Thm. \ref{lb847}}]
By Lem. \ref{lb850}, $\rho\mapsto\mc I_\rho$ is injective. By Prop. \ref{lb792}, $\Lambda$ can be extended (canonically) to an $\Rbb_{\geq0}$-linear map $\Lambda:\LSC_+([a,b])\rightarrow\ovl\Rbb_{\geq0}$ which is monotonically increasing (i.e. $f\leq g$ implies $\Lambda(f)\leq\Lambda(g)$). Let
\begin{align*}
\scr C_1=\{\text{bounded lower semicontinuous }f:[a,b]\rightarrow\Rbb_{\geq0}\}
\end{align*}
Then for each $f\in\scr C_1$ we have $f\leq\Vert f\Vert_{l^\infty}$, and hence $\Lambda(f)\leq \Vert f\Vert_{l^\infty}\cdot\Lambda(1)<+\infty$. Therefore, we have an increasing $\Rbb_{\geq0}$-linear $\Lambda:\scr C_1\rightarrow\Rbb_{\geq0}$. Let
\begin{align*}
\scr C_2=\Span_\Rbb\scr C_1=\{f^+-f^-:f^\pm\in\scr C_1\}
\end{align*}
Then by Prop. \ref{lb751}, $\Lambda$ can be extended uniquely to an $\Rbb$-linear functional $\Lambda:\scr C_2\rightarrow\Rbb$. 

This extension is increasing, i.e., if $f,g\in\scr C_2$ and $f\leq g$ then $\Lambda(f)\leq\Lambda(g)$. To prove this, it suffices to prove $\Lambda(h)\geq0$ where $h=g-f$. Write $h=h^+-h^-$ where $h^\pm\in\scr C_1$. Then $h^+\geq h^-$. Therefore, by the monotonicity of $\Lambda:\scr C_1\rightarrow\Rbb_{\geq0}$ we have $\Lambda(h^+)\geq\Lambda(h^-)$, and hence $\Lambda(h)\geq0$.

For each $x\in[a,b]$, the upper semicontinuous function $\chi_{[a,x]}$ belongs to $\scr C_2$. Therefore, we can define
\begin{align*}
\rho(x)=\Lambda(\chi_{[a,x]})
\end{align*}
Then $\rho:[a,b]\rightarrow\Rbb_{\geq0}$ is increasing. For each decreasing sequence $(x_n)$ in $[a,b]$ converging to $x$, the increasing sequence $(1-\chi_{[a,x_n]})_{n\in\Zbb_+}$ converges pointwise to $1-\chi_{[a,x]}$. Therefore, by the monotone convergence Thm. \ref{lb789}, we have $\lim_n (\Lambda(1)-\rho(x_n))=\Lambda(1)-\rho(x)$. This proves that $\rho$ is right continuous.

Finally, we show that $\Lambda=\mc I_\rho$ on $C([a,b],\Rbb)$. As in the first proof, for each $\eps>0$, choose a partition $\sigma=\{a_0<\cdots<a_n\}$ of $[a,b]$ such that $\diam f(a_{i-1},a_i]\leq\eps$ for all $i$.  Let $g,h$ be defined by \eqref{eq358}. Then $g\leq f\leq h$ and $g,h\in\scr C_2$. Therefore, by the monotonicity of $\Lambda:\scr C_2\rightarrow\Rbb_{\geq0}$ proved above, we have $\Lambda(g)\leq \Lambda(f)\leq\Lambda(h)$. By the definition of $\rho$, it is easy to see
\begin{gather*}
f(a)\rho(a)+\udl S(f,\sigma,\rho)=\Lambda(g)\qquad f(a)\rho(a)+\ovl S(f,\sigma,\rho)=\Lambda(h)
\end{gather*}
Therefore, since $\ovl S(f,\sigma,\rho)-\udl S(f,\sigma,\rho)\leq \eps(\rho(b)-\rho(a))$, we conclude that $|\mc I_\rho(f)-\Lambda(f)|\leq 2\eps(\rho(b)-\rho(a))$. Since $\eps$ is arbitrary, we get $\mc I_\rho(f)=\Lambda(f)$.
\end{proof}



\begin{rem}
The Riesz representation Thm. \ref{lb847} was proved by Riesz in 1909 (cf. \cite{Rie09,Rie11}) and also by Helly in 1912. Riesz's originally proof is quite complicated. In 1914, Riesz gave a simplified proof in \cite{Rie14}. The second proof we presented above is similar to the one in \cite{Rie14}. Before that, in 1913, Riesz used the same idea to prove the spectral theorem for bounded self-adjoint operators on Hilbert spaces, cf. \cite{Rie13}. We will discuss this topic in Sec. \ref{lb896} and \ref{lb1100}.

Riesz and Helly's interest in this theorem is closely related to their interest in the moment problem in $C([a,b],\Rbb)$. As mentioned in Sec. \ref{lb543}, the early solution of moment problems used a compactness argument which was later abstracted into the Banach-Alaoglu theorem. Now, since positive linear functionals on $C([a,b],\Rbb)$ take the explicit form of Stieltjes integrals with respect to increasing functions, the readers may ask whether the Banach-Alaoglu theorem for $C([a,b],\Rbb)^*$ also takes an explicit form. The answer is yes: the explicit formulation of the Banach-Alaoglu theorem for $C([a,b],\Rbb)^*$ in terms of increasing functions is called \textbf{Helly's selection theorem}. We will explain this in detail in Subsec. \ref{lb851}. \hfill\qedsymbol
\end{rem}











\subsubsection{Classification of Radon measures on $[a,b]$}

In view of the bijection between positive linear functionals and Radon measures, the following corollary is more or less an equivalent formulation of the Riesz representation Thm. \ref{lb847}.

\begin{co}\label{lb855}
There is a bijection $\mu\mapsto\rho_\mu$ from the set of Radon measures on $[a,b]$ to the set of increasing right continuous functions $[a,b]\rightarrow\Rbb_{\geq0}$ such that
\begin{gather}
\rho_\mu:[a,b]\rightarrow\Rbb_{\geq0}\qquad \rho_\mu(x)=\mu([a,x])
\end{gather}
The Radon measure $\mu$ is determined by $\rho_\mu$ by
\begin{align}\label{eq346}
\int_{[a,b]}fd\mu=f(a)\rho_\mu(a)+\int_a^bfd\rho_\mu
\end{align}
for each $f\in C([a,b],\Rbb)$.
\end{co}

\begin{proof}
Let $\Phi:\rho\mapsto\mc I_\rho$ be the bijection in the Riesz representation Thm. \ref{lb847}. By Riesz-Markov, $\mc I_\rho$ can be identified with its associated Radon measure $\mu_\rho$. This gives a bijection $\rho\mapsto\mu_\rho$ determined by
\begin{align}\label{eq345}
\mc I_\rho (f)=\int_{[a,b]}fd\mu_\rho
\end{align}
for all $f\in C([a,b],\Rbb)$.

Moreover, in the proof of Thm. \ref{lb847}, we have shown (cf. \eqref{eq344}) that $\mc I_{\rho_{\mu_\rho}}(f)=\int_{[a,b]}fd\mu_\rho$. This proves $\mc I_\rho=\mc I_{\rho_{\mu_\rho}}$ (by \eqref{eq345}), and hence $\rho=\rho_{\mu_\rho}$. Thus, $\mu\mapsto\rho_\mu$ is the inverse of the bijection $\rho\mapsto\mu_\rho$. So $\mu\mapsto\rho_\mu$ is bijective. Eq. \eqref{eq346} follows from \eqref{eq345}.
\end{proof}

\begin{comment}
\begin{rem}
One can also prove $\rho=\rho_{\mu_\rho}$ without using \textit{the proof} of Thm. \ref{lb847} (i.e., without using the intermediate step \eqref{eq344}): Choose any $c\in[a,b]$. Let $(f_n)$ be a sequence as in Lem. \ref{lb850}. Then $\lim_n\mc I_\rho(f_n)=\rho(c)$ by Lem. \ref{lb850}, and
\begin{align*}
\lim_n\int_{[a,b]}f_nd\mu_\rho=\int_{[a,b]}\chi_{[a,c]}d\mu_\rho=\mu_\rho([a,c])=\rho_{\mu_\rho}(c)
\end{align*}
by the dominated convergence theorem. By \eqref{eq345}, we have $\rho(c)=\rho_{\mu_\rho}(c)$.
\end{rem}
\end{comment}

%% Record #11 2024/04/01 two lectures  27

\begin{df}\label{lb857}
Let $\rho:[a,b]\rightarrow\Rbb_{\geq0}$ be increasing and right continuous. Let $(\fk M,\mu)$ be the completion of the Radon measure on $[a,b]$ associated to $\rho$ due to Cor. \ref{lb855}. (So $\mu|_{\fk B_{[a,b]}}$ is the unique Radon measure satisfying $\mu([a,x])=\rho(x)$ for all $x\in[a,b]$.) We call $\mu$ the \textbf{Lebesgue-Stieltjes measure} \index{00@Lebesgue-Stieltjes measure} associated to $\rho$. If $f:[a,b]\rightarrow\ovl\Rbb_{\geq0}$ (resp. $f:[a,b]\rightarrow\Cbb$) is $\fk M$-measurable (resp. $(\fk M,\mu)$-integrable), we say that $f$ is \textbf{Lebesgue-Stieltjes measurable} (resp. \textbf{integrable}), and define the \textbf{Lebesgue-Stieltjes integral} \index{00@Lebesgue-Stieltjes integral} of $f$ with respect to $\rho$ to be
\begin{align*}
\int_{[a,b]}fd\rho:=\int_{[a,b]}fd\mu
\end{align*}
\end{df}


If $f:[a,b]\rightarrow\Rbb$ is (bounded and) Stieltjes integrable, then $f$ is Lebesgue-Stieltjes integrable, and the Stieltjes integral $\int_a^bfd\rho$ satisfies
\begin{align}
\int_{[a,b]}fd\rho=f(a)\rho(a)+\int_a^bfd\rho
\end{align}
where the LHS is the Lebesgue-Stieltjes integral. (Thus, $\int_a^bfd\rho$ should be understood as $\int_{(a,b]}fd\rho$). See Pb. \ref{lb856}.



\subsection{$\star$ Application: Riesz's spectral theory}\label{lb896}





Fix a Hilbert space $\mc H$. 

\subsubsection{Introduction}

The goal of this section and the next one is to study Riesz's proof of spectral theorem for bounded self-adjoint operators on $\mc H$. Our approach largely follows Riesz's method from Ch. IV and V of \cite{Rie13}, with one minor modification: we use nets to simplify certain results that Riesz originally proved using sequences. The motivation for studying this topic is twofold.


First, Riesz's proof relies heavily on the method of \textbf{monotone convergence extension}, which we have previously encountered in Sec. \ref{lb891}, Sec. \ref{lb833}, and Subsec. \ref{lb923} and summarized in Rem. \ref{lb1011}. Although Riesz did not invent this method\footnote{Prior to Riesz, Young employed this method to provide an alternative construction of the Lebesgue integral. See \cite[Sec. 6.6]{Pes}.}, he was the first to apply it to Hilbert space theory, demonstrating its significance beyond integral theory.

Interestingly, Riesz's treatment of spectral theory in \cite{Rie13} later led him to find a simplified proof of his representation theorem for $C([a,b])^*$ in \cite{Rie14}, which is considerably simpler than his original proof in \cite{Rie09}. Our treatment in Subsec. \ref{lb923} is similar to that in \cite{Rie14}. Therefore, studying Riesz's spectral theory provides a valuable insight into the origins and the nature of the monotone convergence extension method.

Second, in his proof of the spectral theorem, Riesz simultaneously adopted both the linear operator perspective and the sesquilinear form perspective. While we noted in Sec. \ref{lb671} that the linear operator viewpoint is closely related to the completeness of Hilbert spaces, \uwave{Riesz's proof of the spectral theorem almost did not rely on the completeness of Hilbert spaces}. Nor does it rely on the weak compactness. Instead, the key property he employed--one that is equivalent to the Cauchy completeness--is the Riesz-Fr\'echet representation Thm. \ref{lb898}, or more precisely, its most important consequential result, Thm. \ref{lb627}. This property allowed him to transition seamlessly between the two perspectives.

Thus, this section, together with the following Sec. \ref{lb1100}, provides a significant application of the Riesz-Fr\'echet representation theorem and illustrates how this property played a crucial role in the early development of functional analysis. To summarize:
\begin{itemize}
\item The weak compactness of $\ovl B_{\mc H}(0,1)$ is crucial to Hilbert's proof of the Hilbert-Schmidt Thm. \ref{lb662}.
\item The Riesz-Fr\'echet theorem is the key property in Riesz's proof of the spectral theorem.
\end{itemize}




\subsubsection{Warm up}

Recall that for $A,B\in\fk L(\mc H)$, we say $A\leq B$ if $B-A\geq0$, i.e., if $\bk{A\xi|\xi}\leq\bk{B\xi|\xi}$ for all $\xi\in\mc H$.


Recall Subsec. \ref{lb1003} for the equivalence between the partially ordered set of closed linear subspaces of $\mc H$ and the one of the projections on $\mc H$. For projections $P,Q$, we have $P\leq Q$ iff $P(\mc H)\leq Q(\mc H)$. (In particular, $0\leq Q$. So all projections are $\geq0$.) If $P\leq Q$, then $Q-P$ is clearly also a projection, which is the projection associated to $Q(\mc H)\cap P(\mc H)^\perp$.

We will frequently use the \uwave{polarization identity} \eqref{eq238}. Recall that every $A\in\fk L(\mc H)$ gives a bounded sesquilinear form $\omega_A:\mc H\times\mc H\rightarrow\Cbb$ defined by $\omega_A(\xi|\eta)=\bk{A\xi|\eta}$, and that every bounded sesquilinear form equals $\omega_A$ for some $A$. (See Thm. \ref{lb627}.) Recall that
\begin{gather*}
A=A^*\qquad\Longleftrightarrow\qquad \omega_A(\xi|\xi)\in\Rbb~~\text{for all }\xi\in\mc H\\
A\geq0\qquad\Longleftrightarrow\qquad \omega_A(\xi|\xi)\geq0~~\text{for all }\xi\in\mc H
\end{gather*}
where the first line is due to Def. \ref{lb1004}, and the second line is by definition. 






\begin{df}
Let $(A_\alpha)$ be a net in $\fk L(\mc H)$, and let $A\in\fk L(\mc H)$. We say that $(A_\alpha)$ \textbf{converges strongly} \index{00@Strong convergence of a net of linear operators} to $A$ if $(A_\alpha)$ converges pointwise to $A$, i.e., $\lim_\alpha A_\alpha\xi=A\xi$ for all $\xi\in\mc H$. 

We say that $(A_\alpha)$ \textbf{converges weakly} \index{00@Weak convergence of a net of linear operators} to $A$ if  the net of functions $(\omega_{A_\alpha})$ converges pointwise to $\omega_A$, i.e., $\lim_\alpha\bk{A_\alpha\xi|\eta}=\lim_\alpha\bk{A\xi|\eta}$ for all $\xi,\eta\in\mc H$. By the polarization identity, this is equivalent to $\lim_\alpha\bk{A_\alpha\xi|\xi}=\bk{A\xi|\xi}$ for all $\xi\in\mc H$.

It is obvious that strong convergence implies weak convergence.  \hfill\qedsymbol
\end{df}


Thm. \ref{lb627}, the most important consequence of the Riesz-Fr\'echet Thm. \ref{lb898}, is mainly used in the following way.

\begin{lm}\label{lb1008}
Let $(A_\alpha)_{\alpha\in I}$ be a net in $\fk L(\mc H)$ satisfying $\sup_\alpha\Vert A_\alpha\Vert<+\infty$. Suppose that for each $\xi\in\mc H$, the net $(\bk{A_\alpha\xi|\xi})_{\alpha\in I}$ in $\Cbb$ is convergent. Then $(A_\alpha)$ converges weakly to some $A\in\fk L(\mc H)$. 

If, moreover, $(A^*_\alpha A_\alpha)$ converges weakly to $A^*A$, then $(A_\alpha)$ converges strongly to $A$.
\end{lm}

\begin{proof}
By the polarization identity, the net $(\omega_{A_\alpha})$ of functions on $\mc H\times\mc H$ converges pointwise to some function $\omega:\mc H\times\mc H\rightarrow\Cbb$, which is clearly sesquilinear. Since $\sup_\alpha\Vert A_\alpha\Vert$ is a finite number $M$, we must have $\Vert\omega\Vert\leq M$ and hence $\omega$ is bounded. Therefore, by Thm. \ref{lb627}, we have $\omega=\omega_A$ for some $A\in\fk L(\mc H)$. Thus $(A_\alpha)$ converges weakly to $A$.

Suppose that $(A^*_\alpha A_\alpha)$ converges weakly to $A^*A$. Then for each $\xi\in\mc H$, we have $\lim_\alpha\Vert A_\alpha\xi\Vert^2=\Vert A\xi\Vert^2$. Hence, by  Prop. \ref{lb635}, $(A_\alpha\xi)$ converges to $A\xi$.
\end{proof}


\subsubsection{Operator-valued Stieltjes integrals}

Let $-\infty<a\leq b<+\infty$.



\begin{df}
Let $E:[a,b]\rightarrow\fk L(\mc H)$ be an \textbf{increasing net of projections}, i.e., $E(\lambda)$ is a projection for each $\lambda$, and $E(\lambda)\leq E(\mu)$ if $\lambda\leq\mu$. We say that $E$ is \textbf{right-continuous} if for each $c\in[a,b)$, the limit $\lim_{\lambda\rightarrow c^+}E(\lambda)$ converges strongly (equivalently, weakly) to $E(c)$.
\end{df}

The equivalence of the strong and weak convergence above is due to the second part of Lem. \ref{lb1008}.




\begin{df}
Let $E:[a,b]\rightarrow\fk L(\mc H)$ be an increasing net of projections. Let $f\in C([a,b])$. For each tagged partition 
\begin{align*}
(\sigma,\lambda_\blt)=\big(\{a_0=a<a_1<\cdots<a_n=b\},(\lambda_1,\dots,\lambda_n) \big)
\end{align*}
(cf. Def. \ref{lb844}), define the Stieltjes sum
\begin{align*}
S(f,\sigma,\lambda_\blt,E)=\sum_{j=1}^n f(\xi_j)(E(\lambda_j)-E(\lambda_{j-1}))
\end{align*}
Similar to Def. \ref{lb1004}, we define the \textbf{operator-valued Stieltjes integral}
\begin{align}\label{eq570}
\int_a^b f(\lambda)dE(\lambda):=\lim_{(\sigma,\lambda_\blt)\in\mc Q([a,b])}S(f,\sigma,\lambda_\blt,E)
\end{align}
where the RHS converges weakly.
\end{df}

%By slightly modifying the following proof, one can show that for each $\xi\in\mc H$, the net $(S(f,\sigma,\lambda_\blt,E)\xi)_{(\sigma,\lambda_\blt)\in\mc Q([a,b])}$ in $\mc H$ is Cauchy. Therefore, the RHS of \eqref{eq570} converges strongly. We will not need this fact. 

\begin{proof}[Proof of convergence]
Let $\xi\in\mc H$. Let $C=\Vert f\Vert_{l^\infty}$. Writing $F_i=E(\lambda_i)-E(\lambda_{i-1})$ and noting that $F_iF_j=0$ if $i\neq j$, we have
\begin{align*}
&\big\Vert S(f,\sigma,\lambda_\blt,E)\xi\big\Vert^2=\sum_{i,j=1}^n\bigbk{f(\lambda_i)F_i\xi \big|f(\lambda_j)F_j\xi }\\
=&\sum_{i=1}^n\bigbk{|f(\lambda_i)|^2F_i\xi \big|\xi }\leq C^2\sum_{i=1}^n\bk{F_i\xi|\xi}=C^2\bk{(E(b)-E(a))\xi|\xi}\leq C^2\Vert\xi\Vert^2
\end{align*}
where we have used $\bk{F_i\xi|\xi}\geq0$ due to Rem. \ref{lb1006}. This shows that the operator norms of the net $(S(f,\sigma,\lambda_\blt,E))_{(\sigma,\lambda_\blt)\in\mc Q([a,b])}$ are uniformly bounded by $C$.

Since $f$ is uniformly continuous, for each $\eps>0$ there is $\delta>0$ such that $|f(s)-f(t)|\leq\eps$ whenever $|s-t|\leq\delta$. Choose any tagged partition $(\sigma,\lambda_\blt)$ such that each subinterval from $\sigma$ has length $\leq\delta$. Therefore, if a tagged partition
\begin{align*}
(\sgm,\mu_\blt)=\big(\{c_0=a<c_1<\cdots<c_k=b\},(\mu_1,\dots,\mu_k) \big)
\end{align*}
is finer than $(\sigma,\lambda_\blt)$, setting $G_j=E(\mu_j)-E(\mu_{j-1})$, we have
\begin{align*}
S(f,\sgm,\mu_\blt,E)=\sum_{j=1}^k f(c_j)G_j\qquad S(f,\sigma,\lambda_\blt,E)=\sum_{j=1}^k f(c_j')G_j
\end{align*}
where $c_j'$ is some number from $a_1,\dots,a_n$ such that $|c_j'-c_j|\leq\delta$. Therefore, noting that $G_iG_j=0$ if $i\neq j$, and that $\bk{G_i}$, we have
\begin{align*}
&\Big|\bigbk{(S(f,\sgm,\mu_\blt,E)-S(f,\sigma,\lambda_\blt,E))\xi\big|\xi}\Big|\leq \sum_{j=1}^k\Big|\bigbk{(f(c_j)-f(c_j'))G_j\xi\big|\xi}\Big|\\
\leq& \eps\sum_{j=1}^k\bk{G_j\xi|\xi}
=\eps\bk{(E(b)-E(a))\xi|\xi}\leq \eps\Vert\xi\Vert^2
\end{align*}
Thus $(\bk{S(f,\sigma,\lambda_\blt,E)\xi|\xi})_{(\sigma,\lambda_\blt)\in\mc Q([a,b])}$ is a Cauchy net in $\Cbb$. Therefore, by Lem. \ref{lb1008}, the RHS of \eqref{eq570} converges weakly.
\end{proof}


\begin{rem}\label{lb1021}
Suppose that $f\in C([a,b])$ is real valued. Then for each $\xi\in\mc H$, and setting $A=\int_a^b f(\lambda)dE(\lambda)$, it is easy to see that
\begin{align}\label{eq571}
\bk{A\xi|\xi}=\int_a^b f(\lambda)d\bk{E(\lambda)\xi|\xi}
\end{align}
where the RHS is the real-valued Stieltjes integral of $f$ with respect to the increasing function $\lambda\in[a,b]\mapsto \bk{E(\lambda)\xi|\xi}\in\Rbb_{\geq0}$, as defined in Subsec. \ref{lb1009}. In particular, since \eqref{eq571} is always real, we see that $A^*=A$. If $f\geq0$, then \eqref{eq571} is always positive, and hence $A\geq0$.
\end{rem}


\subsubsection{The spectral theorem}

Fix a self-adjoint $T\in\fk L(\mc H)$. Choose real numbers $a\leq b$ such that $a\leq T\leq b$, i.e., 
\begin{align*}
a\bk{\xi|\xi}\leq\bk{T\xi|\xi}\leq b\bk{\xi|\xi}\qquad\text{for all }\xi\in\mc H
\end{align*}
(For example, take $a=-\Vert T\Vert$ and $b=\Vert T\Vert$.) 


\begin{thm}[\textbf{Spectral theorem}]\label{lb895}
There exists a right-continuous increasing net of projections $E:[a,b]\rightarrow \fk L(\mc H)$, called \textbf{spectral projections}, \index{00@Spectral projections $E(\lambda)$} such that
\begin{align}\label{eq572}
T=a\cdot E(a)+\int_a^b\lambda \cdot dE(\lambda)
\end{align}
\end{thm}

As we shall see Rem. \ref{lb1023}, the RHS of \eqref{eq572} actually converges strongly to the LHS.

\begin{eg}
Assume that $\dim\mc H<+\infty$. Then by linear algebra (or by the Hilbert-Schmidt Thm. \ref{lb662}), $\mc H$ has an orthonormal basis $e_1,\dots,e_n$ such that each $e_i$ is an eigenvector with eigenvalue $\lambda_i\in[a,b]$ (i.e., $Te_i=\lambda_ie_i$). Then \eqref{eq572} holds if we let $E(\lambda)$ be the projection associated to $\Span\{e_i:1\leq i\leq n,\lambda_i\leq\lambda\}$.
\end{eg}


\subsection{$\star$ Monotone convergence extension III: proof of the spectral theorem}\label{lb1100}


We continue to let $T$ be a self-adjoint bounded linear operator on a Hilbert space $\mc H$, and $a\leq T\leq b$. We assume $a<b$ for simplicity so that the polynomial algebra $\Rbb[x]$ can be viewed as a subalgebra of $C([a,b],\Rbb)$; otherwise, we have $T=a$ (by the polarization identity) and the spectral theorem is trivial. Throughout this section, we use the following notations:
\begin{gather}
\begin{gathered}
\scr P=\{f\in C([a,b],\Rbb_{\geq0}):f\text{ is a polynomial}\}\\
\scr C_0=C([a,b],\Rbb_{\geq0})\\
\scr C_1=\{\text{bounded lower semicontinuous }f:[a,b]\rightarrow\Rbb_{\geq0}\} \\
\scr C_2=\Span_\Rbb\scr C_1=\{f^+-f^-:f^\pm\in\scr C_1\}
\end{gathered}
\end{gather}
Then $\scr P\subset\scr C_0\subset\scr C_1\subset\scr C_2$, and $\scr P,\scr C_0,\scr C_1$ are unital $\Rbb_{\geq0}$-subalgebras of $(\Rbb_{\geq0})^{[a,b]}$. Note that if $f,g$ belong to any of the above four spaces, by saying $f\leq g$ we mean $f|_{[a,b]}\leq g|_{[a,b]}$.

\begin{df}
Let $\scr A$ be a \textbf{unital \pmb{$\Rbb_{\geq0}$}-subalgebra} of $(\Rbb_{\geq0})^{[a,b]}$, namely, an $\Rbb_{\geq0}$-linear subspace of $(\Rbb_{\geq0})^{[a,b]}$ containing the constant function $1$ such that $fg\in\scr A$ whenever $f,g\in\scr A$.

Given such $\scr A$, a map $\pi:\scr A\rightarrow\fk L(\mc H)$ is called a \textbf{positive unital homomorphism} if it is $\Rbb_{\geq0}$-linear and satisfies the following conditions for all $f,g\in\scr A$:
\begin{align*}
\pi(f)\geq0\qquad  \pi(1)=1 \qquad \pi(fg)=\pi(f)\pi(g)
\end{align*}
\hfill\qedsymbol
\end{df}

\begin{rem}\label{lb1018}
If $\pi:\scr A\rightarrow\fk L(\mc H)$ is a positive unital homomorphism, if $\scr A$ is one of $\scr P,\scr C_0,\scr C_1$, and if $f,g\in\scr A$ satisfy $f\leq g$ (i.e., $f(x)\leq g(x)$ for all $x\in [a,b]$), then $g-f\in\scr A$. It then follows that $\pi(f)\leq\pi(g)$. Therefore, $\pi$ is increasing.
\end{rem}



\begin{thm}\label{lb1012}
The map $\pi_T:f\in\scr P\mapsto f(T) \in\fk L(\mc H)$ is a positive unital homomorphism, where $f(T)=a_0+a_1T+\cdots+a_nT^n$ if $f(x)=a_0+a_1x+\cdots+a_nx^n$. We call $\pi_T$ the \textbf{polynomial functional calculus} of $T$. \index{00@Polynomial functional calculus}
\end{thm}



Before we prove Thm. \ref{lb1012}, we explain how this theorem will help us prove the spectral Thm. \ref{lb895}. The key step is to construct the spectral projections. For that purpose, we use the idea of monotone convergence extension (cf. Rem. \ref{lb1011}) to extend $\pi_T$ to a positive unital homomorphism $\pi_T:\scr C_1\rightarrow\fk L(\mc H)$. By linearity, it is further extended to a unital homomorphism $\pi_T:\scr C_2\rightarrow\fk L(\mc H)$. Then for each $\lambda\in[a,b]$, we have $\chi_{[a,\lambda]}\in\scr C_2$. Then $E(\lambda)$ is defined to be $\pi_T(\chi_{[a,\lambda]})$.


\subsubsection{Polynomial functional calculus}


The goal of this subsection is to prove Thm. \ref{lb1012}. The only nontrivial part of this theorem is the positivity of $\pi_T(f)=f(T)$ when $f\in\scr P$.


Let $V$ be an inner product space.

\begin{lm}\label{lb888}
Let $(A_\alpha)$ be a net in $\fk L(V)$ satisfying $\sup_\alpha \Vert A_\alpha\Vert<+\infty$. Assume that $(A_\alpha)$ converges pointwise to $A\in\fk L(V)$. Let $(\xi_\beta)$ be a net in $V$ converging pointwise to $\xi\in V$. Then $\dps\lim_{\alpha,\beta}A_\alpha\xi_\beta=A\xi$.
\end{lm}



\begin{proof}
The fact that $C=\sup_\alpha \Vert A_\alpha\Vert$ is finite implies that $(A_\alpha)$ is an equicontinuous family of functions $V\rightarrow V$. Therefore, the lemma follows easily from (3)$\Rightarrow$(1) of Thm. \ref{lb277} (together with Prop. \ref{lb281}). But we can also check it directly:
\begin{align*}
\Vert A\xi-A_\alpha\xi_\beta\Vert\leq\Vert A\xi-A_\alpha\xi\Vert+\Vert A_\alpha\xi-A_\alpha\xi_\beta\Vert\leq \Vert A\xi-A_\alpha\xi\Vert+C\Vert\xi-\xi_\beta\Vert
\end{align*}
where the RHS converges to $0$.
\end{proof}


\begin{pp}\label{lb1010}
If $(A_\alpha)_{\alpha\in I}$ and $(B_\alpha)_{\alpha\in I}$ are nets in $\fk L(V)$ converges strongly to $A,B\in\fk L(V)$ respectively, and if $\sup_\alpha\Vert A_\alpha\Vert<+\infty$, then $\lim_{\alpha\in I}A_\alpha B_\alpha$ converges strongly to $AB$.
\end{pp}

\begin{proof}
For each $\xi\in V$, by Lem. \ref{lb888} we have $\lim_{(\alpha,\beta)\in I\times I}A_\alpha B_\beta\xi=AB\xi$. Thus the limit of the subnet $(A_\alpha B_\alpha\xi)_{\alpha\in I}$ also converges to $AB\xi$.
\end{proof}


\begin{co}\label{lb889}
Let $(A_\alpha)$ be a net in $\fk L(V)$ converging strongly to $A\in\fk L(V)$ and satisfying $\sup_\alpha\Vert A_\alpha\Vert<+\infty$. Then for each $f\in \Rbb[x]$, $\lim_\alpha f(A_\alpha)$ converges strongly to $f(A)$.
\end{co}

\begin{proof}
This is immediate from Prop. \ref{lb1010}.
\end{proof}







\begin{rem}\label{lb903}
The readers should notice the crucial role played by the condition $\sup_\alpha \Vert A_\alpha\Vert<+\infty$ in the proof of Cor. \ref{lb889}. As the proof of Lem. \ref{lb888} suggests, \uwave{this is a condition of equicontinuity which ensures the convergence of double limits}.
\end{rem}


\begin{proof}[\textbf{Proof of Thm. \ref{lb1012}}]
Let $c\in[a,b]$. It suffices to prove that $T-c$ satisfies the similar property, i.e., if $g\in\Rbb[x]$ satisfies $g|_{[a-c,b-c]}\geq0$ then $g(T-c)\geq0$. Therefore, replacing $T$ with $T-c$, we may assume at the beginning that $0\in[a,b]$.

Fix $f\in\scr P$. Let $(e_i)_{i\in I}$ be an orthonormal basis of $\mc H$. For each $J\in\fin(2^I)$, let $P_J$ be the projection of $\mc H$ onto $V_J=\Span\{e_j:j\in J\}$, namely, for each $\xi\in\mc H$ we have
\begin{align*}
P_J\xi=\sum_{j\in J}\bk{\xi|e_j}e_j
\end{align*}
Then $\lim_{J\in\fin(2^X)}P_J\xi=\xi$ by Thm. \ref{lb595}. Therefore, $\lim_J P_J TP_J$ converges strongly to $T$ by Prop. \ref{lb1010}. 

It suffices to prove that $f(P_JTP_J)\geq0$. Then, applying $\lim_J$ and noting Cor. \ref{lb889} and the strong convergence proved above, we immediately have
\begin{align*}
\bk{f(T)\xi|\xi}=\lim_{J\in\fin(2^I)}\bk{f(P_JTP_J)\xi|\xi}\geq0
\end{align*}
This will prove that $f(T)\geq0$.

Let $V_J=P_J(\mc H)$. Then $P_JTP_J$ is zero on $V_J^\perp$ and leaves the finite-dimensional subspace $V_J$ invariant. Let $T_J$ be the restriction $P_JTP_J\big|_{V_J}:V_J\rightarrow V_J$. Since $T^*=T$, we also have $T_J^*=T_J$ (because $\omega_T$ being Hermitian implies $\omega_{T_J}$ being Hermitian). Therefore, by linear algebra (or by the Hilbert-Schmidt Thm. \ref{lb662}), $V_J$ has a finite orthonormal basis  consisting of eigenvectors of $T_J$. By choosing an arbitrary orthonormal basis on $V_J^\perp$, we obtain an orthonormal basis $(v_1,\dots,v_n)\cup \fk W$ of $\mc H$ such that $P_JTP_J\cdot v_i=\lambda_iv_i$ for some $\lambda_i\in\Rbb$, and $P_JTP_J\cdot w=0$ for all $w\in\fk W$. 

Inserting $a\leq T\leq b$ into $\bk{-P_Jv_i|P_Jv_i}=\bk{-v_i|v_i}$, we see that $\lambda_i\in[a,b]$. Thus we have $f(P_JTP_J)v_i=f(\lambda_i)v_i$ and $f(P_JTP_J)w=f(0)w$ if $w\in\fk W$. It now follows easily from $f|_{[a,b]}\geq0$ and $\lambda_i,0\in[a,b]$ that $f(P_JTP_J)\geq0$.
\end{proof}


\subsubsection{Extending positive linear functionals}




\begin{thm}\label{lb1014}
Let $\Lambda:\scr C_0\rightarrow\Rbb_{\geq0}$ be $\Rbb_{\geq0}$-linear. Then $\Lambda$ can be extended uniquely to an $\Rbb_{\geq0}$-linear map $\Lambda:\scr C_1\rightarrow\Rbb_{\geq0}$ satisfying the following property:
\begin{itemize}
\item If $(f_\alpha)$ is an increasing net in $\scr C_1$ converging pointwise to $f\in\scr C_1$, then $\lim_\alpha \Lambda(f_\alpha)=\Lambda(f)$.
\end{itemize}
\end{thm}



\begin{proof}
The existence follows from the results in Subsec. \ref{lb1013}. The uniqueness follows from the fact that any $f\in\scr C_1$ is the pointwise limit of an increasing net in $\scr C_0$, namely, Lem. \ref{lb788}.
\end{proof}


Prop. \ref{lb1014} allows us to extend $\pi_T$ from $\scr C_0$ to $\scr C_1$. To extend $\pi_T$ from $\scr P$ to $\scr C_0$, we need the following analogous results:

\begin{lm}\label{lb1015}
For each $f\in\scr C_0$ there exists a \uwave{decreasing} sequence $(f_n)$ in $\scr P$ converging uniformly (on $[a,b]$) to $f$. 
\end{lm}




\begin{proof}
The sequence $(f+n^{-1})_{n\in\Zbb_+}$ is clearly decreasing and converging to $f$. However, it is not in $\scr P$. To remedy this issue, note that by the Weierstrass approximation Thm. \ref{lb441}, there exists $f_n\in \Rbb[x]$ such that $\Vert f_n-(f+n^{-1})\Vert_{l^\infty([a,b])}<1/100n$. Then $(f_n)$ is a decreasing sequence in $\scr P$ converging uniformly to $f$.
\end{proof}



\begin{thm}\label{lb1016}
Let $\Lambda:\scr P\rightarrow\Rbb_{\geq0}$ be $\Rbb_{\geq0}$-linear. Then $\Lambda$ can be extended uniquely to an $\Rbb_{\geq0}$-linear map $\Lambda:\scr C_0\rightarrow\Rbb_{\geq0}$ satisfying the following property:
\begin{itemize}
\item If $(f_\alpha)$ is a decreasing net in $\scr C_0$ converging uniformly (on $[a,b]$) to $f\in\scr C_0$, then $\lim_\alpha \Lambda(f_\alpha)=\Lambda(f)$.
\end{itemize}
\end{thm}

By Dini's theorem (cf. Thm. \ref{lb286}), there is no difference between uniform convergence and pointwise convergence in Lem. \ref{lb1014} and Thm. \ref{lb1016}. (We don't need this fact, though.)


The following proof of Thm. \ref{lb286} follows the steps in Rem. \ref{lb1011}.

\begin{proof}
The uniqueness follows from Lem. \ref{lb1015}. Let us prove the existence. For each $f\in\scr C_0$, define
\begin{align*}
\Lambda(f)=\inf\{\Lambda(p):p\in\scr P,p\geq f\}
\end{align*}
This gives a map $\Lambda:\scr C_0\rightarrow\Rbb_{\geq0}$ extending the original $\Lambda$. It is clear that $\Lambda(f)\leq\Lambda(g)$ if $f,g\in\scr C_0$ and $f\leq g$.

Let us prove the monotone convergence property. Let $(f_\alpha)$ be a decreasing net in $\scr C_0$ converging uniformly to $f$. Clearly $\Lambda(f_\alpha)\geq\Lambda(f)$, and hence $\lim_\alpha\Lambda(f_\alpha)\geq\Lambda(f)$. For each $\eps>0$, by the $\Rbb_{\geq0}$-linearity of $\Lambda|_{\scr P}$ we clearly have $\Lambda(f+\eps)=\Lambda(f)+\eps\Lambda(1)$ (even if $f\in\scr C_0$ is not necessarily in $\scr P$). Since $(f_\alpha-f)$  converges uniformly to $0$, there exists $\beta$ such that for all $\alpha\geq\beta$ we have $f_\alpha\leq f+\eps$, and hence $\Lambda(f_\alpha)\leq\Lambda(f)+\eps\Lambda(1)$. Hence $\lim_\alpha\Lambda(f_\alpha)\leq\Lambda(f)+\eps\Lambda(1)$. Letting $\eps\rightarrow0$, we get  $\lim_\alpha\Lambda(f_\alpha)\leq\Lambda(f)$. Thus $\lim_\alpha\Lambda(f_\alpha)=\Lambda(f)$.

The $\Rbb_{\geq0}$-linearity of the extended $\Lambda$ can be proved in the same way as in Prop. \ref{lb792} or \ref{lb1017}.
\end{proof}




\subsubsection{Extending functional calculi}


\begin{thm}\label{lb1019}
The polynomial functional calculus $\pi_T:\scr P\rightarrow\fk L(\mc H)$ can be extended uniquely to a positive unital homomorphism $\pi_T:f\in\scr C_0\mapsto f(T)\in\fk L(\mc H)$ satisfying the following property:
\begin{itemize}
\item If $(f_\alpha)$ is a decreasing net in $\scr C_0$ converging uniformly to $f\in\scr C_0$, then $\lim_\alpha f_\alpha(T)$ converges weakly to $f(T)$.
\end{itemize}
\end{thm}

This extended map $\pi_T:\scr C_0\rightarrow\fk L(\mc H)$ is called the \textbf{continuous functional calculus} \index{00@Continuous functional calculus} of $T$.

\begin{proof}
Step 1. The uniqueness follows from Lem. \ref{lb1015}. Let us prove the existence. For each $\xi\in\mc H$ and $f\in\scr P$, define
\begin{align*}
\Lambda_\xi(f)=\bk{f(T)\xi|\xi}\equiv\omega_{f(T)}(\xi|\xi)
\end{align*}
By Thm. \ref{lb1012}, we have $\Lambda_\xi(f)\geq0$. Therefore, we have an $\Rbb_{\geq0}$-linear map $\Lambda_\xi:\scr P\rightarrow\Rbb_{\geq0}$. Extend it to an $\Rbb_{\geq0}$-linear map $\Lambda_\xi:\scr C_0\rightarrow\Rbb_{\geq0}$ as in Thm. \ref{lb1016}.

For each $f\in\scr C_0$, define $\omega_{f(T)}:\mc H\times\mc H\rightarrow\Cbb$ by
\begin{align}
\omega_{f(T)}(\xi|\eta)=\frac 14\sum_{t=0,\frac \pi 2,\pi,\frac{3\pi}2}~ e^{\im t}\cdot\Lambda_{\xi+e^{\im t}\eta}(f)
\end{align}
By the polarization identity \eqref{eq238}, the above definition of $\omega_{f(T)}$ agrees with the usual one when $f=p\in\scr P$ (i.e. $\omega_{p(T)}(\xi|\eta)=\bk{p(T)\xi|\eta}$). Moreover, suppose that $(f_\alpha)$ is a decreasing net in $\scr C_0$ converging uniformly to $f$. Then by Thm. \ref{lb1016}, we have that $\lim_\alpha \Lambda_{\xi+e^{\im t}\eta}(f_\alpha)$ converges to $\Lambda_{\xi+e^{\im t}\eta}(f)$. Thus 
\begin{align}\label{eq573}
\lim_\alpha\omega_{f_\alpha(T)}(\xi|\eta)=\omega_{f(T)}(\xi|\eta)\qquad\text{for all }\xi,\eta\in\mc H
\end{align}


To show that $\omega_{f(T)}$ is a sesquilinear form, note that by Lem. \ref{lb1015}, we can pick a uniformly-bounded decreasing net $(p_\alpha)$ in $\scr P$ converging uniformly to $f$. Since each $\omega_{p_\alpha(T)}$ is sesquilinear, by \eqref{eq573}, $\omega_{f(T)}$ is also sesquilinear.

We now show that $\omega_{f(T)}$ is bounded. Choose $M\in\Rbb_{\geq0}$ such that $0\leq p_\alpha\leq M$ (on $[a,b]$) for all $\alpha$. Thus $0\leq p_\alpha^2\leq M^2$. By Thm. \ref{lb1012}, we have $p_\alpha^2(T)=p_\alpha(T)^2=p_\alpha(T)^*p_\alpha(T)$, and hence (noting Rem. \ref{lb1018})
\begin{align*}
0\leq p_\alpha(T)^*p_\alpha(T)\leq M
\end{align*}
Inserting this inequality into $\bk{-\xi|\xi}$, we get $0\leq\Vert p_\alpha(T)\xi\Vert^2\leq M^2\Vert\xi\Vert^2$. Thus $\Vert p_\alpha(T)\Vert\leq M$, and hence $\Vert\omega_{p_\alpha(T)}\Vert\leq M$. Since $\lim_\alpha\omega_{p_\alpha(T)}$ converges pointwise to $\omega_{f(T)}$, we also have $\Vert\omega_{f(T)}\Vert\leq M$.\\[-1ex]

Step 2. By Thm. \ref{lb627}, $\omega_{f(T)}$ is realized by some $f(T)\in\fk L(\mc H)$, i.e., $\bk{f(T)\xi|\eta}=\omega_{f(T)}(\xi|\eta)$ for all $\xi,\eta\in\mc H$. If $(f_\alpha)$ is a decreasing net in $\scr C_0$ converging uniformly to $f$, then by \eqref{eq573}, $\lim_\alpha f(T_\alpha)$ converges weakly to $f(T)$.

It remains to prove that $\pi_T:f\in\scr C_0\mapsto f(T)\in\fk L(\mc H)$ is a positive unital homomorphism. Clearly $f(T)\geq0$, because $\bk{f(T)\xi|\xi}=\Lambda_\xi(f)\geq0$. Since $f\in \scr C_0\mapsto \Lambda_\xi(f)=\bk{f(T)\xi|\xi}$ is $\Rbb_{\geq0}$-linear, by the polarization identity, we see that $f\in\scr C_0\mapsto f(T)$ is $\Rbb_{\geq0}$-linear.

Finally, we check that $f(T)g(T)=(fg)(T)$. We know that this is true when $f,g\in\scr P$. Now assume that $f\in\scr C_0$ and $g\in \scr P$. Let $(p_\alpha)$ be a decreasing net in $\scr P$ converging uniformly to $f$. Then $\lim_\alpha p_\alpha(T)$ converges weakly to $f(T)$. Since $(p_\alpha g)$ is decreasing and converges uniformly to $fg$, the limit $\lim_\alpha (p_\alpha g)(T)$ also converges weakly to $(fg)(T)$. Therefore, as $p_\alpha(T)g(T)=(p_\alpha g)(T)$, we have
\begin{align*}
&\bk{f(T)g(T)\xi|\eta}=\bk{g(T)\xi|f(T)\eta}=\lim_\alpha\bk{g(T)\xi|p_\alpha(T)\eta}=\lim_\alpha\bk{p_\alpha(T)g(T)\xi|\eta}\\
=&\lim_\alpha\bk{(p_\alpha g)(T)\xi|\eta}=\bk{(fg)(T)\xi|\eta}
\end{align*}


We have proved that $f(T)g(T)=(fg)(T)$ if $f\in\scr C_0,g\in\scr P$. Now, if $f,g\in\scr C_0$, we can choose a decreasing net $(q_\alpha)$ in $\scr P$ converging uniformly to $g$. So $f(T)q_\alpha(T)=(fq_\alpha)(T)$. By repeating the above argument, we again have that $f(T)g(T)=(fg)(T)$.
\end{proof}


\begin{thm}\label{lb1020}
The continuous functional calculus $\pi_T:\scr C_0\rightarrow\fk L(\mc H)$ can be extended uniquely to a positive unital homomorphism $\pi_T:f\in\scr C_1\mapsto f(T)\in\fk L(\mc H)$ satisfying the following property:
\begin{itemize}
\item If $(f_\alpha)$ is an increasing net in $\scr C_1$ converging pointwise to $f\in\scr C_1$, then $\lim_\alpha f_\alpha(T)$ converges weakly to $f(T)$.
\end{itemize}
\end{thm}

This extended map $\pi_T:\scr C_1\rightarrow\fk L(\mc H)$ is called the \textbf{lower semicontinuous functional calculus} \index{00@Lower semiontinuous functional calculus} of $T$.

\begin{proof}
The uniqueness follows from Lem. \ref{lb788}. To prove the existence, note that by Thm. \ref{lb1019}, for each $\xi\in\mc H$, we have a positive linear functional 
\begin{align*}
\Lambda_\xi:\scr C_0\rightarrow\Rbb_{\geq0}\qquad \Lambda_\xi(f)=\bk{f(T)\xi|\xi}\equiv\omega_{f(T)}(\xi|\xi)
\end{align*}
Extend it to an $\Rbb_{\geq0}$-linear map $\Lambda_\xi:\scr C_1\rightarrow\Rbb_{\geq0}$ as in Thm. \ref{lb1014}. Then, using a similar argument as in the proof of Thm. \ref{lb1019}, for each $f\in\scr C_1$ we can find a positive $f(T)\in\fk L(\mc H)$ such that $\bk{f(T)\xi|\xi}=\Lambda_\xi(f)$ for all $\xi\in\mc H$, and we can show that $\pi_T:f\in\scr C_1\mapsto f(T)\in\fk L(\mc H)$ is a positive unital homomorphism. We leave the details to the readers.
\end{proof}


Note that $C([a,b],\Rbb)\subset\scr C_2$.

\begin{thm}\label{lb1022}
The lower semicontinuous functional calculus $\pi_T:\scr C_1\rightarrow\fk L(\mc H)$ can be extended uniquely to an $\Rbb$-linear map $\pi_T:f\in\scr C_2\mapsto f(T)\in\fk L(\mc H)$. Moreover, it satisfies the following properties:
\begin{enumerate}[label=(\arabic*)]
\item For each $f,g\in\scr C_2$ we have $f(T)^*=f(T)$, $1(T)=1$, and $(fg)(T)=f(T)g(T)$.
\item Define $E:[a,b]\rightarrow\fk L(\mc H)$ by $E(\lambda)=\chi_{[a,\lambda]}(T)$. Then $E$ is a right-continuous increasing net of projections.
\item If $f\in C([a,b],\Rbb)$, then
\begin{align}\label{eq574}
f(T)=f(a)E(a)+\int_a^b f(\lambda)dE(\lambda)
\end{align}
\end{enumerate}
\end{thm}

This extended map $\pi_T:\scr C_2\rightarrow\fk L(\mc H)$ is called the \textbf{semicontinuous functional calculus} \index{00@Semiontinuous functional calculus} of $T$.


\begin{proof}
The existence and uniqueness of the $\Rbb_{\geq0}$-linear extension $\pi_T$ follows from  Prop. \ref{lb751}. Clearly $1(T)=1$. Choose any $f,g\in\scr C_2$, and write $f=f^+-f^-$ and $g=g^+-g^-$ where $f^\pm,g^\pm\in\scr C_1$. Then $f(T)=f^+(T)-f^-(T)$ is self-adjoint since both $f^+(T)$ and $f^-(T)$ are so. Since $\pi_T|_{\scr C_1}$ preserves the multiplication, we have
\begin{align*}
&f(T)g(T)=(f^+(T)-f^-(T))(g^+(T)-g^-(T))\\
=&f^+(T)g^+(T)-f^+(T)g^-(T)-f^-(T)g^+(T)+f^-(T)g^-(T)\\
=&(f^+g^+)(T)-(f^+g^-)(T)-(f^-g^+)(T)+(f^-g^-)(T)\\
=&(f^+g^+-f^+g^--f^-g^++f^-g^-)(T)=(fg)(T)
\end{align*}
This proves (1).


Since $f(T)\geq0$ whenever $f\in\scr C_1$, we have $E(\lambda)\geq0$ and, in particular, $E(\lambda)^*=E(\lambda)$. Since $\pi_T$ preserves the multiplication, we have $E(\lambda)^2=(\chi_{[a,\lambda]}^2)(T)=\chi_{[a,\lambda]}(T)=E(\lambda)$. Thus $E(\lambda)$ is a projection.  By Rem. \ref{lb1018}, $E$ is increasing. Note that $\chi_{(\lambda,b]}$ belongs to $\scr C_1$. For each $c\in[a,b)$, since $\lim_{\lambda\rightarrow c^+}\chi_{(\lambda,b]}$ increases and converges pointwise to $\chi_{(c,b]}$, by Thm. \ref{lb1020}, we have that $\lim_{\lambda\rightarrow c}\chi_{(\lambda,b]}(T)$ converges weakly to $\chi_{(c,b]}(T)$. Therefore $E$ is right-continuous. This proves (2).

Finally, for each $\xi\in\mc H$, let $\Lambda_\xi:\scr C_1\rightarrow\Rbb$ be $\Lambda_\xi(f)=\bk{f(T)\xi|\xi}$. Define $\rho_\xi(\lambda)$ to be $\Lambda_\xi(\chi_{[a,\lambda]})=\bk{E(\lambda)\xi|\xi}$. Then $\rho_\xi:[a,b]\rightarrow\Rbb_{\geq0}$ is increasing and right-continuous. From the \hyperlink{SecondRiesz}{Second proof} of the Riesz representation Thm. \ref{lb847} (cf. Subsec. \ref{lb923}), for each $f\in C([a,b],\Rbb)$ we have
\begin{align*}
\Lambda_\xi(f)=f(a)\rho_\xi(a)+\int_a^b f(\lambda)d\rho_\xi(\lambda)
\end{align*}
In view of Rem. \ref{lb1021}, we see that \eqref{eq574} holds when inserted in $\bk{-\xi|\xi}$. By the polarization identity, \eqref{eq574} is true. This proves (3).
\end{proof}


\begin{rem}\label{lb1023}
One can show that the integral on the RHS of \eqref{eq574} \uwave{converges strongly} to the LHS. Indeed, note that for any tagged partition $(\sigma,\lambda_\blt)$ of $[a,b]$ we have $S(f,\sigma,\lambda_\blt,E)^2=S(f^2,\sigma,\lambda_\blt,E)$. Therefore, applying Thm. \ref{lb1022} to $f^2$, we see that $\lim_{(\sigma,\lambda_\blt)} S(f,\sigma,\lambda_\blt,E)^2$ converges weakly to
\begin{align*}
&f^2(T)-f(a)^2E(a)=f^2(T)-f(a)^2\chi_{\{a\}}(T)=(f^2-f(a)^2\chi_{\{a\}})(T)\\
=&(f-f(a)\chi_{\{a\}})^2(T)=(f(T)-f(a)\chi_{\{a\}}(T))^2=(f(T)-f(a)E(a))^2
\end{align*}
Therefore, by the second part of Lem. \ref{lb1008}, $\lim_{(\sigma,\lambda_\blt)} S(f,\sigma,\lambda_\blt,E)$ converges strongly to $f(T)-f(a)E(a)$.
\end{rem}


The spectral Thm. \ref{lb895} now follows immediately from Thm. \ref{lb1022}.








\subsection{Problems and supplementary material}


\begin{prob}\label{lb867}
Let $(X,\mc T_X)$ be a topological space, and let $(\fk M,\mu)$ be a measure on $X$ such that $\fk B_X\subset\fk M$. Define the \textbf{support} $\Supp(\mu)$ of $\mu$ \index{00@Support of a measure} \index{Supp@$\Supp\mu$, the support of measure $\mu$} such that 
\begin{align*}
X\setminus\Supp(\mu)=\bigcup_{U\in\mc T_X,\mu(U)=0}U
\end{align*}
In other words, $x\in X$ belongs to $\Supp(\mu)$ iff every neighborhood $V$ of $x$ satisfies $\mu(V_x)>0$. Prove that $\mu(X\setminus\Supp(\mu))=0$ if one of the following is true:
\begin{enumerate}
\item[(a)]  $\mu$ is inner regular on open sets.
\item[(b)] $X$ is second countable.
\end{enumerate}
\end{prob}


\begin{sprob}\label{lb868}
Prove the converse of Lusin's theorem: Let $X$ be LCH, and let $(\fk M,\mu)$ be the completion of a $\sigma$-finite Radon measure on $X$. Let $f:X\rightarrow\Cbb$ such that for every $A\in\fk B_X$ satisfying $\mu(A)<+\infty$, and for every $\eps>0$, there exists a compact $K\subset A$ such that $\mu(A\setminus K)<\eps$ and $f|_K$ is continuous. Then $f$ is $\fk M$-measurable.
\end{sprob}


\begin{srem}\label{lb870}
Without assuming $\sigma$-finiteness, we have the following version of Lusin's theorem and its converse: A function $f:X\rightarrow\Cbb$ satisfies the description in Pb. \ref{lb868} iff $f$ is $\fk M_\mu$-measurable, where $\fk M_\mu$ is defined by Thm. \ref{lb724}, i.e., the set of all $E\subset X$ such that $\mu$ is regular on $E\cap\Omega$ for each open $\Omega$ with finite $\mu$-measure. (Equivalently, $\fk M_\mu$ is the saturation of $\fk M$, cf. Subsec. \ref{lb869}. Note that if $\mu|_{\fk B_X}$ is $\sigma$-finite then $\fk M_\mu=\fk M$ by Prop. \ref{lb737}.) We leave the proof to the readers.
\end{srem}








\subsubsection{$\star$ Approximation by upper and lower semicontinuous functions}

Let $X$ be an LCH space, and let $(\fk M,\mu)$ be the completion of a Radon measure on $X$.



\begin{df}
For each topological space $X$ (not necessarily LCH), we let \index{USC@$\USC(X,\Rbb_{\geq0})$, $\USC_c(X,\Rbb_{\geq0})$}
\begin{gather}
\USC(X,\Rbb_{\geq0})=\{\text{upper semicontinuous }f\in[0,+\infty)^X\}\label{eq320}\\
\USC_c(X,\Rbb_{\geq0})=\{f\in\USC(X,\Rbb_{\geq0}):\Supp(f)\text{ is compact}\}
\end{gather}
(We do not let $\USC_+(X)$ denote the RHS of \eqref{eq320} since, according to our usual conventions, $\USC_+(X)$ refers to the set of all upper semicontinuous $f:X\rightarrow[0,+\infty]$.)
\end{df}



\begin{prob}\label{lb802}
Let $f:X\rightarrow[0,+\infty]$ be measurable. Prove that
\begin{subequations}\label{eq319}
\begin{align}\label{eq319a}
\int_Xfd\mu=\inf\Big\{\int_X hd\mu:h\in\LSC_+(X),h\geq f  \Big\}
\end{align}
Prove that if $\int_Xfd\mu<+\infty$, then
\begin{align}\label{eq319b}
\int_Xfd\mu=\sup\Big\{\int_X gd\mu:g\in\USC_c(X,\Rbb_{\geq0}),g\leq f  \Big\}
\end{align}
\end{subequations}

\end{prob}

\begin{proof}[Hint]
Assume WLOG that $\int f<+\infty$. (Why?) If $f=\chi_E$ for some finite measure $E\in\fk M$, use the $\mu$-regularity. In general, write $f=\sum_{n\in\Zbb_+}s_n$ where each $s_n:X\rightarrow\Rbb_{\geq0}$ is simple. Approximate each $s_n$ from above and from below by some $h_n\in\LSC_+(X)$ and $g_n\in\USC_c(X,\Rbb_{\geq0})$ respectively. Take $h=\sum_{n=1}^\infty h_n$ and $g=\sum_{n=1}^N g_n$ for some large enough $N$.
\end{proof}

\begin{rem}
Lower semicontinuous functions are the function version of open sets. Upper semicontinuous functions with compact supports are the function version of compact sets. Therefore, Pb. \ref{lb802} can be viewed as the function version Thm. \ref{lb804}.
\end{rem}
\begin{prob}\label{lb801}
Let $(f_\alpha)_{\alpha\in I}$ be a decreasing net in $\USC(X,\Rbb_{\geq0})$ converging pointwise to $f:X\rightarrow\Rbb_{\geq0}$.  Assume that there exists a measurable $g:X\rightarrow\ovl\Rbb_{\geq0}$ such that $\int_Xgd\mu<+\infty$, and that $f_\alpha\leq g$ for all $\alpha$. Prove $\dps \int_Xfd\mu=\lim_\alpha\int_X f_\alpha d\mu$.
\end{prob}

\begin{proof}[Hint]
By Pb. \ref{lb802}, assume WLOG that $g\in\LSC_+(X)$. %Do not subtract arbitrarily, since $g(X)$ might contain $+\infty$. (It is dangerous to do subtraction when $+\infty$ is involved.) Use addition whenever possible.
\end{proof}

\begin{exe}
Let $K$ be a compact subset of $X$. Use Pb. \ref{lb801} to show that
\begin{align}\label{eq324}
\mu(K)=\inf\Big\{\int_Xfd\mu:f\in C_c(X,[0,1]),f|_K=1  \Big\}
\end{align}
by constructing a decreasing net in $C_c(X,[0,1])$ (bounded by some $\chi_U$ where $U\supset K$ is open and $\mu(U)<+\infty$) converging pointwise to $\chi_K$. 
\end{exe}

\begin{proof}[Note]
It is not necessary to prove \eqref{eq324} using Pb. \ref{lb801}. You can try to find a direct proof. However, the purpose of Pb. \ref{lb801} is to let you know how \eqref{eq324} can fit into a broader picture.
\end{proof}


\subsubsection{$\star$ The dual space $C_c(X)^*$}


Let $X$ be an LCH space.

\begin{prob}\label{lb814}
Let $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ be $\Rbb_{\geq0}$-linear. By Rem. \ref{lb812}, $\Lambda$ can be extended uniquely to a $\Cbb$-linear map $\Lambda:C_c(X)\rightarrow\Cbb$. Let $\mu$ be the Radon measure associated to $\Lambda$. Prove that the following four numbers are equal:
\begin{align*}
&\sup\{\Lambda(f):f\in C_c(X,\Rbb_{\geq0}),f\leq 1\}=\sup\{|\Lambda(f)|:f\in C_c(X,\Rbb),|f|\leq 1\}\\
=&\sup\{|\Lambda(f)|:f\in C_c(X),|f|\leq 1\}=\mu(X)
\end{align*}
These four identical numbers are called (unambiguously) the \textbf{operator norm} of $\Lambda$ and denoted by $\Vert\Lambda\Vert$.
\end{prob}


\begin{prob}\label{lb813}
Equip $C_c(X,\Rbb)$ with the $l^\infty$-norm. Let $\Lambda:C_c(X,\Rbb)\rightarrow\Rbb$ be a bounded linear map with operator norm $M$. Define $\Lambda^\pm:C_c(X,\Rbb_{\geq0})\rightarrow\ovl\Rbb$ sending each $f\in C_c(X,\Rbb_{\geq0})$ to
\begin{subequations}
\begin{gather}
\Lambda^+(f)=\sup\big\{\Lambda(h):h\in C_c(X,\Rbb_{\geq0}),h\leq f  \big\}\\
\Lambda^-(f)=\sup\big\{-\Lambda(h):h\in C_c(X,\Rbb_{\geq0}),h\leq f  \big\}
\end{gather}
\end{subequations}
Clearly $(-\Lambda)^\pm=\Lambda^\mp$. 
\begin{enumerate}
\item Prove that $\Lambda^+$ has range in $\Rbb_{\geq0}$, that $\Lambda^+:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ is $\Rbb_{\geq0}$-linear, and that $\Vert\Lambda^+\Vert\leq M$. (Replacing $\Lambda$ with $-\Lambda$, we see that $\Lambda^-$ satisfies the same property.)
\item Prove that
\begin{align}
\Lambda(f)=\Lambda^+(f)-\Lambda^-(f)
\end{align}
for all $f\in C_c(X,\Rbb_{\geq0})$. This is called the \textbf{Jordan decomposition} \index{00@Jordan decomposition} of $\Lambda$.
\end{enumerate}
\end{prob}


\begin{proof}[Hint]
1. For $f,g\in C_c(X,\Rbb_{\geq0})$, to prove $\Lambda^+(f+g)\leq\Lambda^+(f)+\Lambda^+(g)$, let $h\in C_c(X,\Rbb_{\geq0})$ such that $h\leq f+g$. Let $h_1=\min\{h,f\}$, and show that $0\leq h_1\leq f$ and $0\leq h-h_1\leq g$.

2. Prove $\Lambda+\Lambda^-\leq\Lambda^+$, and replace $\Lambda$ with $-\Lambda$.
\end{proof}

\begin{prob}
Let $\mu$ be a finite Radon measure on $X$. Let $A\in\fk B_X$ and $B=X\setminus A$. Define a linear map $\Lambda:C_c(X,\Rbb)\rightarrow\Rbb$ by
\begin{align*}
\Lambda(f)=\int_Af d\mu-\int_B fd\mu
\end{align*}
which is clearly bounded (with operator norm $\leq \mu(X)$). Prove that for every $f\in C_c(X,\Rbb_{\geq0})$ we have
\begin{align}
\Lambda^+(f)=\int_Af d\mu\qquad \Lambda^-(f)=\int_B fd\mu
\end{align}
\end{prob}

\begin{proof}[Hint]
To prove $\Lambda^+(f)\geq\int_Afd\mu$, find compact $K\subset A$ and $L\subset B$ such that $\mu(A\setminus K)$ and $\mu(B\setminus L)$ are small. Multiply $f$ by an Urysohn function associated to $K$ and $X\setminus L$.
\end{proof}




\begin{thm}[\textbf{Riesz-Markov representation theorem}] \index{00@Riesz-Markov representation theorem for $C_c(X)$} \label{lb821}
Any linear functional on $C_c(X)$ defined by $\Lambda_\mu:f\mapsto \int_Xfd\mu$ for some finite Radon measure $\mu$ is in $C_c(X)^*$. Moreover, such linear functionals span $C_c(X)^*$.
\end{thm}

A similar classification of $C_c(X,\Rbb)^*$ is left to the readers.

\begin{proof}
If $\mu$ is Radon and $\mu(X)<+\infty$, by Pb. \ref{lb814}, we know $\Vert\Lambda_\mu\Vert<+\infty$. So $\Lambda_\mu\in C_c(X)^*$.

We now show that $\Lambda\in C_c(X)^*$ can be written as a finite sum $\sum_i a_i\Lambda_{\mu_i}$ where $a_i\in\Cbb$ and $\mu_i$ is a finite Radon measure. For each $f\in C_c(X,\Rbb)$, let $\Lambda_1(f)=\Real\Lambda(f)$ and $\Lambda_2(f)=\Imag\Lambda(f)$. So $\Lambda_i\in C_c(X,\Rbb)^*$, and $\Lambda=\Lambda_1+\im\Lambda_2$ on $C_c(X,\Rbb)$. By Pb. \ref{lb813}, there exist $\Rbb_{\geq0}$-linear $\Lambda_i^\pm:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ with finite operator norms such that $\Lambda_i=\Lambda_i^+-\Lambda_i^-$ on $C_c(X,\Rbb_{\geq0})$. So $\Lambda=\Lambda_1^+-\Lambda_1^-+\im\Lambda_2^+-\im\Lambda_2^-$ on $C_c(X,\Rbb_{\geq0})$ and hence on $C_c(X)$ by the $\Cbb$-linearity. By the Riesz-Markov representation Thm. \ref{lb796}, each of the four positive linear functionals is represented by the integral of a Radon measure. The finiteness of these Radon measures is due to Pb. \ref{lb814}.
\end{proof}


\begin{rem}\label{lb820}
If $W$ is a normed vector space and $V$ is a linear subspace, then we have a canonical linear map $W^*\rightarrow V^*,\varphi\mapsto\varphi|_V$. It is easy to see (cf. Prop. \ref{lb500}) that this map is an isomorphism of Banach spaces if $V$ is dense in $W$, giving a canonical ismomorphism $V^*\simeq W^*$. In particular, if $V$ is an inner product space with completion $\mc H$, there is a canonical isomorphism $V^*\simeq\mc H^*$.

In particular, since $C_0(X)$ is the completion of $C_c(X)$ (cf. Pb. \ref{lb485}), the Riesz-Markov Thm. \ref{lb821} also characterizes the dual space of $C_0(X)$.  \hfill\qedsymbol
\end{rem}




\subsubsection{$\star$ An alternative proof of Thm. \ref{lb818}}\label{lb824}


Let $X$ be a (not necessarily LCH) Hausdorff space. Let $\mu:\fk M\rightarrow[0,+\infty]$ be a measure where $\fk M$ is a $\sigma$-algebra containing $\fk B_X$. Define $\mu^*,\mu_*:\fk M\rightarrow[0,+\infty]$ by
\begin{subequations}\label{eq325}
\begin{gather}
\mu^*(E)=\inf\big\{\mu(U):U\text{ is an open subset of $X$ containing }E \big\}\\
\mu_*(E)=\sup\big\{\mu(K):K\text{ is a compact subset of }E \big\}\label{eq325b}
\end{gather}
\end{subequations}
Clearly $\mu_*(E)\leq\mu(E)\leq\mu^*(E)$. Clearly $\mu^*(U)=\mu(U)$ if $U$ is open, and $\mu_*(K)=\mu(K)$ if $K$ is compact.

Note that the definition of $\mu_*(E)$ (using $\mu(K)$) is slightly different from that in \eqref{eq292b} (using $\mu^*(K)$), since we do not assume $\mu^*(K)=\mu(K)$. Therefore, you cannot directly use the results proved in Sec. \ref{lb726}. (But you can use the methods in that section.)

Recall from Def. \ref{lb811} that a set $E\in\fk M$ is \textbf{$\mu$-regular} iff $\mu^*(E)=\mu_*(E)$.

\begin{exe}
Let $E\in\fk M$ such that $\mu^*(E)<+\infty$. Prove that $\mu$ is regular on $E$ iff for each $\eps>0$ there exist an open $U\supset E$ and a compact $K\subset E$ such that $\mu(U\setminus K)<\eps$.
\end{exe}


\begin{prob}
Let $E_1,E_2,\dots\in\fk M$ be mutually disjoint. Suppose that $\mu$ is regular on each $E_n$. Prove that $\mu$ is regular on $E=\bigcup_n E_n$, and $\dps\mu(E)=\sum_n\mu(E_n)$.
\end{prob}

\begin{prob}
Let $E_1,E_2\in\fk M$ be $\mu$-regular with finite $\mu$-measures. Prove that $E_2\setminus E_1$ is $\mu$-regular.
\end{prob}

We say that $E\in\fk M$ is \textbf{locally $\mu$-regular} if for each \textit{$\mu$-regular} open $\Omega\subset X$ satisfying $\mu(\Omega)<+\infty$, the set $E\cap \Omega$ is $\mu$-regular. Let 
\begin{align}
\fk M^\mu=\{E\in\fk M:E\text{ is locally $\mu$-regular}\}
\end{align}


\begin{prob}\label{lb823}
Prove that $\fk M^\mu$ is a $\sigma$-algebra.
\end{prob}


We are ready to give an alternative proof of Thm. \ref{lb818}. 

\begin{thm}[=Thm. \ref{lb818}]
Let $X$ be a second countable LCH space. Let $\mu$ be a Borel measure on $X$ which is finite on compact subsets. Then $\mu$ is a Radon measure.
\end{thm}


\begin{proof}
As in the proof of Thm. \ref{lb818}, we can find a countable  increasing chain of compact subsets $K_1\subset K_2\subset\cdots$ of $U$ such that $U=\bigcup_nK_n$. So $\mu(U)=\lim_n\mu(K_n)$. This proves that $U$ is inner regular, and hence is regular. In particular, $\fk M^\mu$ contains all open sets.

It remains to prove that every Borel set is outer regular. By Pb. \ref{lb823}, $\fk M^\mu$ is a $\sigma$-algebra. So $\fk M^\mu$ contains any Borel set $E$. Let us prove that $E$ is outer regular.

Since $X$ is a countable union of open subsets, and since $\mu$ is finite on compact sets, $X$ is a countable union $X=\bigcup\Omega_n$ where each $\Omega_n$ is open and has finite $\mu$-measure. Since $E\in\fk M^\mu$, we know that $E_n:=E\cap \Omega_n$ is $\mu$-regular. Therefore, for each $\eps>0$ there is an open $U_n\subset X$ such that $\mu(U_n\setminus E_n)<\eps/2^n$. Let $U=\bigcup_n U_n$. Since $E=\bigcup_nE_n$, we have $U\setminus E\subset\bigcup_n U_n\setminus E_n$, and hence $\mu(U\setminus E)<\eps$. Therefore $\mu(U)\leq\mu(E)+\eps$.
\end{proof}



\subsubsection{$\star$ Stieltjes integrals and the Banach-Alaoglu theorem for $C([a,b],\Rbb)^*$}\label{lb851}


Let $-\infty<a<b<+\infty$. If $\rho:[a,b]\rightarrow\Rbb_{\geq0}$ is increasing, for each $f:[a,b]\rightarrow\Cbb$, the Stieltjes integral $\int_a^bfd\rho$ is understood as $\int_a^b\Real(f)d\rho+\im\int_a^b\Imag(f)d\rho$ whenever it can be defined. Recall that
\begin{align*}
\mc I_\rho(f)=f(a)\rho(a)+\int_a^bfd\rho
\end{align*}


\begin{prob}
Let $\rho:[a,b]\rightarrow\Rbb_{\geq0}$ be increasing. Prove that $\mc I_\rho:C[a,b]\rightarrow\Cbb$ has operator norm
\begin{align*}
\Vert\mc I_\rho\Vert=\rho(b)
\end{align*}
\end{prob}

\begin{lm}
Let $I\subset\Rbb$ be an interval. Suppose that $\rho:I\rightarrow\Rbb$ is increasing. Then $\rho$ is continuous outside countably many points. In particular, if $I=[a,b]$, then $\rho$ is Riemann integrable on $I$.
\end{lm}


\begin{proof}
Since $I$ is a countable union of compact subintervals, by restricting $\rho$ to each compact subinterval, it suffices to assume $I=[a,b]$. 

For each $x\in I$, let $\rho_-(x),\rho_+(x)$ be the left resp. right limit of $\rho$ at $x$, i.e., $\rho_\pm(x)=\lim_{t\rightarrow x^\pm}\rho(t)$. Then $\rho_-(x_1)\leq\rho_+(x_1)\leq\rho_-(x_2)\leq\rho_+(x_2)$ if $x_1<x_2$. Let $\Delta$ be the set of all $x\in I$ at which $\rho$ is not continuous. Then $x\in\Delta$ iff $\rho_-(x)<\rho_+(x)$. If $x_1<\cdots<x_n$ are in $\Delta$, then $\sum_{i=1}^n(\rho_+(x_i)-\rho_-(x_i))\leq \rho(b)-\rho(a)$. It follows that
\begin{align*}
\sum_{x\in\Delta}(\rho_+(x)-\rho_-(x))\leq\rho(b)-\rho(a)<+\infty
\end{align*}
Therefore, by Pb. \ref{lb413}, $\Delta$ is countable.
\end{proof}

\begin{co}
Let $I$ be an interval, and let $\rho:I\rightarrow\Rbb$ be increasing. There there is an increasing right continuous $\wtd\rho:I\rightarrow\Rbb$ such that $\rho$ equals $\wtd\rho$ outside a countable subset of $I$.
\end{co}

\begin{proof}
Let $\wtd\rho(x)=\lim_{t\rightarrow x^+}\rho(t)$. Then $\wtd\rho$ is right continuous, and $\wtd\rho(x)=\rho(x)$ if $\rho$ is continuous at $x$. 
\end{proof}

The following problem shows that the Stieltjes integral of a $C^1$ function can be calculated by a Riemann integral.

\begin{prob}\label{lb859}
Let $\rho:[a,b]\rightarrow\Rbb_{\geq0}$ be increasing. Let $g\in C^1[a,b]$. (Namely, $g:[a,b]\rightarrow\Cbb$ is continuous and has continuous differentials.) Prove the \textbf{integration by parts} \index{00@Integration by parts for Stieltjes integrals}
\begin{align}
\int_a^b gd\rho=g(b)\rho(b)-g(a)\rho(a)-\int_a^b g'\rho dx
\end{align}
\end{prob}


\begin{proof}[Hint]
Assume WLOG that $g\in C^1([a,b],\Rbb)$. Let $\sigma=\{a_0=a<a_1<\cdots<a_n=b\}$ be a partition of $[a,b]$. By the summation by parts (cf. Pb. \ref{lb845}, and set $g_k=g(a_k)$, $f_0=\rho(a)$, $f_i=\rho(a_i)-\rho(a_{i-1})$ when $i>0$), we have
\begin{align*}
\sum_{k=1}^n g(a_k)\big(\rho(a_k)-\rho(a_{k-1})\big)=\rho(b)g(b)-\rho(a)g(a)-\sum_{k=0}^{n-1}\rho(a_k)\big(g(a_{k+1})-g(a_k)\big)
\end{align*}
Apply the mean value theorem to $g(a_{k+1})-g(a_k)$.
\end{proof}


Recall that $m$ is the Lebesgue measure.
\begin{prob}\label{lb848}
Let $(\rho_n)_{n\in\Zbb_+}$ be a net of increasing functions $[a,b]\rightarrow\Rbb_{\geq0}$. Let $\rho:[a,b]\rightarrow\Rbb_{\geq0}$. Assume that the following are true:
\begin{enumerate}
\item[(1)] $\sup_n \rho_n(b)<+\infty$. 
\item[(2)] $(\rho_n)$ converges $m$-a.e. to $\rho$, and $\lim_n\rho_n(b)=\rho(b)$.
\end{enumerate}
Prove that $(\mc I_{\rho_n})$ converges weak-* (in $(C[a,b])^*$) to $\mc I_\rho$. In other words, prove for each $f\in C[a,b]$ that
\begin{align*}
\lim_{n\rightarrow\infty}\mc I_{\rho_n}(f)=\mc I_\rho(f)
\end{align*}
\end{prob}

\begin{proof}[Hint]
Use a density argument to reduce to the case that $f$ is a polynomial. Then use integration by parts and the dominated convergence theorem.
\end{proof}

In Pb. \ref{lb912}, we will describe a similar relationship between pointwise (or a.e.) convergence and the weak-* convergence in $L^p$ spaces.


The following problem is Problem 13 from Chapter 7 of Rudin's \textit{Principles of Mathematical Analysis} \cite{Rud-P}. We shall see the background of this problem, which was not given in Rudin's book. 

\begin{thm}[\textbf{Helly's selection theorem}]\label{lb846}
Let $(\rho_n)$ be a sequence of increasing functions $[a,b]\rightarrow[0,1]$. Then $(\rho_n)$ has a subsequence converging pointwise to an increasing $\rho:[a,b]\rightarrow[0,1]$.
\end{thm}



\begin{prob}
Prove Helly's selection Thm. \ref{lb846}.
\end{prob}

\begin{proof}[Hint]
Choose a subsequence $(\rho_{n_k})$ converging pointwise on $[a,b]\cap\Qbb$ to an increasing $\tau:[a,b]\cap\Qbb\rightarrow[0,1]$. Extend $\tau$ to an increasing right continuous function $\tau:[a,b]\rightarrow[0,1]$ by $\dps\tau(x)=\lim_{t\rightarrow x^+,t\in\Qbb\cap[a,b]}\tau(t)$. Let $\Delta$ be the (countable) set of all $x\in[a,b]$ at which $\tau$ is not continuous. Prove that $(\rho_{n_k})$ converges pointwise on $[a,b]\setminus\Delta$ to $\tau$. Conclude that $(\rho_{n_k})$ has a subsequence converging everywhere on $[a,b]$.
\end{proof}


Helly's selection theorem is a prototype of the Banach-Alaoglu Thm. \ref{lb519}. In a 1912 paper \cite{Hel12}, Helly proved this theorem and used it to study the moment problem in $C([a,b],\Rbb)$: Given $c_1,c_2,\dots\in\Rbb$ and $f_1,f_2,\dots\in C([a,b],\Rbb)$ such that there exists $M\in\Rbb_{\geq0}$ satisfying
\begin{align}
\Big|\sum_{i=1}^n\lambda_ic_i\Big|\leq M\Big\Vert \sum_{i=1}^n \lambda_if_n\Big\Vert_{l^\infty}\qquad(\forall n\in\Zbb_+,\lambda_1,\dots,\lambda_n\in\Rbb)
\end{align}
find a function of bounded variation $\rho:[a,b]\rightarrow\Rbb$ such that, for all $n$,
\begin{align}
\int_a^b f_nd\rho=c_n
\end{align}
A \textbf{function of bounded variation} (simply called a \textbf{BV function}) \index{00@Function of bounded variation} \index{00@BV function} $\rho:[a,b]\rightarrow\Rbb$ is a function that can be written as $\rho^+-\rho^-$ where $\rho^+,\rho^-:[a,b]\rightarrow\Rbb_{\geq0}$ are increasing. See Sec. \ref{lb543} for the relationship between the moment problems and the Banach-Alaoglu theorem. (F. Riesz has also studied this problem in 1911. His interest in the study of dual space of $C[a,b]$ is clearly related to moment problems. See \cite[Sec. 6.3]{Die-H} for a detailed history.)

\begin{co}[\textbf{Banach-Alaoglu theorem for $C([a,b],\Rbb)^*$}]
The closed unit ball of $C([a,b],\Rbb)^*$ is weak-* sequentially compact.
\end{co}

\begin{proof}
Let $(\Lambda_n)$ be a sequence in $C([a,b],\Rbb)^*$ such that $\sup_n\Vert\Lambda_n\Vert\leq 1$. By Pb. \ref{lb813}, each $\Lambda_n$ has Jordan decomposition $\Lambda_n=\Lambda_n^+-\Lambda_n^-$ where $\Lambda_n^\pm$ is positive and $\Vert\Lambda_n^\pm\Vert\leq 1$. By considering $\Lambda_n^\pm$ separately, it suffices to assume that $\Lambda_n$ is positive. 

By the Riesz representation Thm. \ref{lb847}, for each $n$ there is an increasing $\rho_n:[a,b]\rightarrow\Rbb_{\geq0}$ such that $\Lambda_n(f)=\mc I_{\rho_n}(f)$ for all $f\in C([a,b],\Rbb)$. By Helly's selection Thm. \ref{lb846}, $(\rho_n)$ has a subsequence $(\rho_{n_k})$ converging pointwise to an increasing $\rho:[a,b]\rightarrow\Rbb_{\geq0}$. By Pb. \ref{lb848}, $(\Lambda_{n_k})$ converges weak-* to $\mc I_\rho$. 
\end{proof}


Another prototype of the Banach-Alaoglu theorem is the compactness of the closed unit ball of $l^2(\Zbb_+)$ under the pointwise convergence topology, cf. Thm. \ref{lb530} and Pb. \ref{lb531}. We have seen in Sec. \ref{lb849} that it plays a crucial role in the Hilbert-Schmidt theorem. 

Understanding how abstract theorems like the Banach-Alaoglu theorem evolved from early explicit versions is important because it helps us understand the nature of mathematical development. We have emphasized this point throughout this course.


\subsubsection{$\star$ Stieltjes integrals}


Let $\rho:[a,b]\rightarrow\Rbb_{\geq0}$ be increasing and right continuous. Let $\mu_\rho$ be the Lebesgue-Stieltjes measure associated to $\rho$ (cf. Def. \ref{lb857}), i.e., the completion of the unique Radon measure whose value at each $[a,x]$ equals $\rho(x)$.

\begin{prob}\label{lb856}
Let $f:[a,b]\rightarrow\Rbb$ be a bounded function. Assume that $f$ is Stieltjes integrable with respect to an increasing right-continuous $\rho:[a,b]\rightarrow\Rbb$. Prove that $f$ is $\mu_\rho$-measurable, and
\begin{align*}
\int_{[a,b]}fd\mu_\rho=f(a)\rho(a)+\int_a^bfd\rho
\end{align*}
where $\int_a^bfd\rho$ is the Stieltjes integral.
\end{prob}

\begin{proof}[Hint]
To prove that $f$ is $\mu_\rho$-measurable, use the lower and upper Darboux sums to find bounded Borel functions $g,h:[a,b]\rightarrow\Rbb$ satisfying $g\leq f\leq h$ and $\int_{[a,b]}(h-g)d\mu_\rho=0$. Show that $f-g=0$ $\mu_\rho$-a.e.. (Where is the completeness of $\mu_\rho$ used?)
\end{proof}





\begin{prob}\label{lb1033}
Let $\mu,\nu$ be Radon measures on $\Rbb$. Use outer regularity to prove that $\mu=\nu$ iff $\mu(-\infty,x]=\nu(-\infty,x]$ for all $x\in\Rbb$. 
\end{prob}

\begin{rem}
In the following, we let 
\begin{align*}
d\rho=d\mu_\rho-\rho(a)\delta_a
\end{align*}
which is the unique (why?) Radon measure on $[a,b]$ sending each $[a,x]$ to $\rho(x)-\rho(a)$. (Recall that $\delta_a$ is the Dirac measure at $a$.) Thanks to Pb. \ref{lb856}, this notation is compatible with the symbol $d\rho$ in Stieltjes integral $\int_a^bfd\rho$ whenever $f$ is Stieltjes integrable.
\end{rem}



\begin{prob}\label{lb1034}
(Fundamental theorem of calculus for Radon-Nikodym derivatives). Let $g\in\mc L^1([a,b],m)$ be a Borel function and $g\geq0$. Use Pb. \ref{lb1033} to prove that the following are equivalent:
\begin{enumerate}
\item[(a)] $\rho$ is a continuous function. Moreover, $g$ is the Radon-Nikodym derivative of $d\rho$ with respect to $dm$ on $\fk B_{[a,b]}$ (cf. Pb. \ref{lb1035}), that is, on $\fk B_{[a,b]}$ we have
\begin{align}
d\rho=gdm
\end{align}
\item[(b)] For each $x\in[a,b]$, we have
\begin{align}\label{eq578}
\rho(x)-\rho(a)=\int_a^xgdm
\end{align}
\end{enumerate}
\end{prob}




\begin{rem}\label{lb1036}
In your future study of real analysis, you will encounter the \textbf{Lebesgue differentiation theorem}, which asserts that if \eqref{eq578} holds, then $\rho$ is differentiable and satisfies $\rho'=g$ outside an $m$-null subset of $[a,b]$. 

Now, thanks to Pb. \ref{lb1034}, we see that the Lebesgue differentiation theorem can be understood as claiming that the Radon-Nikodym derivative, when it exists, is equal to the usual derivative outside an $m$-null set. (This is one half of the \textbf{fundamental theorem of calculus for the Lebesgue integral}. The second half says that if $\rho$ is an ``absolutely continuous" function, then $d\rho$ has a Radon-Nikodym derivative with respect to $dm$.\footnote{This second half follows from a more general fact: if $\nu$ is a $\sigma$-finite measure on a measurable space $X$, and if $\mu$ is a complex measure/signed measure on $X$ that is ``absolutely continuous" with respect to $\nu$, then $\mu$ has a Radon-Nikodym derivative with respect to $\nu$. See \cite[Thm. 6.10]{Rud-R}.})  \hfill\qedsymbol
\end{rem}










\newpage

\section{Theorems of Fubini and Tonelli for Radon measures}




\subsection{Products of Radon measures}



Fix LCH spaces $X_1,\dots,X_N$. For each $1\leq i\leq N$, let $\Lambda_i:C_c(X_i,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$ be an $\Rbb_{\geq0}$-linear map, equivalently (cf. Rem. \ref{lb812}), a positive linear functional $\Lambda:C_c(X_i)\rightarrow\Cbb$. Let $(\fk M_i,\mu_i)$ be \textit{the completion of} the Radon measure associated to $\Lambda_i$.

Our goal of this section and the next one is to prove the Fubini theorem for integrals of Radon measures. In the special case that $N=2$, $X_i=\Rbb^{k_i}$, and $(\fk M_i,\mu_i)$ is the Lebesgue measure $m^{k_i}$, the theorem implies that
\begin{align}
\int_{\Rbb^{k_1}\times\Rbb^{k_2}}f(x_1,x_2)dm^{k_1+k_2}=\int_{\Rbb^{k_1}}\int_{\Rbb^{k_2}}f(x_1,x_2)dm^{k_2}dm^{k_1}
\end{align}
for any $f\in \mc L^1(\Rbb^{k_1}\times\Rbb^{k_2},m^{k_1+k_2})$. However, to prove such a theorem for Radon measures, the first task is to define the ``product Radon measure" $\mu_1\times\cdots\times\mu_N$ on $X_1\times\cdots\times X_N$ generalizing $m^{k_1+k_2}$. This will be achieved by defining the corresponding positive linear functional $\Lambda_1\otimes\cdots\otimes\Lambda_N$. 



\begin{lm}\label{lb825}
Let $X$ be an LCH space, and let $\Lambda:C_c(X)\rightarrow\Cbb$ be a positive linear functional. Then for each precompact open $U\subset X$, the restriction of $\Lambda$ to $C_c(U)$ is bounded (and hence continuous) with respect to the $l^\infty$-norm.
\end{lm}


\begin{proof}
Let $\mu$ be the associated Radon measure of $\Lambda$. Then for each $f\in C_c(U)$ we have $|\Lambda(f)|=|\int fd\mu|\leq\Vert f\Vert_{l^\infty}\cdot\mu(U)$. So $\Lambda|_{C_c(U)}$ has operator norm $\leq\mu(U)$ which is finite because $\mu$ is finite on the compact set $\ovl U$.
\end{proof}

\begin{exe}
Use Urysohn's lemma to give a direct proof of Lem. \ref{lb825} without using the associated Radon measure.
\end{exe}

\begin{proof}[Hint]
First show that the $\Rbb$-linear map $\Lambda|_{C_c(U,\Rbb)}$ has finite operator norm $\leq \Lambda(\varphi)$ where $\varphi\in C_c(X,[0,1])$ and $\varphi|_{\ovl U}=1$.
\end{proof}


\begin{thm}\label{lb826}
There exists a unique positive linear functional
\begin{align*}
\Lambda:C_c(X_1\times\cdots\times X_N)\rightarrow\Cbb
\end{align*}
satisfying that for each $f_i\in C_c(X_i)$, by viewing $f_1\cdots f_N$ as a function $X_1\times\cdots\times X_N\rightarrow\Cbb$ in the obvious way (i.e. sending $(x_1,\dots,x_N)$ to $f_1(x_1)\cdots f_N(x_N)$), we have
\begin{align}\label{eq327}
\Lambda(f_1\cdots f_N)=\Lambda_1(f_1)\cdots\Lambda_N(f_N)
\end{align}
\end{thm}

\begin{proof}
Uniqueness: Let $\Gamma$ satisfy the same properties as $\Lambda$. Let $X_\blt=X_1\times\cdots\times X_N$. By Lem. \ref{lb460}, it is easy to see that $C_c(X_\blt)$ is the union of all $C_c(U_\blt)$ where $U_\blt=U_1\times\cdots\times U_N$ for some precompact open $U_1\subset X_1,\dots,U_N\subset X_N$. Therefore, it suffices to restrict $\Lambda$ and $\Gamma$ to each $C_c(U_\blt)$ and show that they are equal. 

Let $\mc E=\{f_1\cdots f_N:f_i\in C_c(U_i)\}$. Then $\Lambda|_{\mc E}=\Gamma|_{\mc E}$. Note that $\Span_\Cbb\mc E$ is clearly a $*$-subalgebra of $C_0(U_\blt)$ vanishing nowhere and separating points of $U_\blt$. (This is because $C_c(U_i)$ vanishes nowhere and separates points of $U_i$, cf. Cor. \ref{lb474}.) Applying the Stone-Weierstrass Thm. \ref{lb828} to the LCH space $U_\blt$, we conclude that $\Span_\Cbb\mc E$ is dense in $C_c(U_\blt)$ (under the $l^\infty$-norm). Therefore, by Lem. \ref{lb825}, we see that $\Lambda$ equals $\Gamma$ on $C_c(U_\blt)$. This finishes the proof of the uniqueness.


For readers who prefer not to invoke the SW theorem for LCH spaces (whose proof relies on one-point compactifications), we provide a different proof that $\Span\mc E$ is dense in $C_c(U_\blt)$. Let $f\in C_c(U_\blt)$. Let $K_i\subset U_i$ be compact such that $\Supp f\subset K_\blt:=K_1\times\cdots\times K_N$. Choose any $\eps>0$. By the SW theorem for compact Hausdorff spaces (Thm. \ref{lb450}), or simply by Cor. \ref{lb471}, there exists $g$ in $\Span\{g_1\cdots g_N:g_i\in C(\ovl{U_i})\}$ such that $\Vert f-g\Vert_{l^\infty(\ovl U_\blt)}\leq\eps$, where $\ovl U_\blt=\ovl U_1\times\cdots\times\ovl U_N$. In particular, since $f|_{\ovl U_\blt\setminus K_\blt}=0$, we have $|g|\leq\eps$ on $\ovl U_\blt\setminus K_\blt$. By Urysohn's lemma, there exists $h_i\in C_c(U_i,[0,1])$ such that $h_i|_{K_i}=1$. Let $h=h_1\cdots h_N\cdot g$. Then clearly $g\in\Span\mc E$, and $|f-h|=|f-g|\leq\eps$ on $K_\blt$. Since $|h|\leq|g|\leq\eps$ on $\ovl U_\blt\setminus K_\blt$, we get $|f-h|=|-h|\leq\eps$ on $\ovl U_\blt\setminus K_\blt$. Thus $\Vert f-h\Vert_{l^\infty(U_\blt)}\leq\eps$.\\[-1ex]

Existence: By induction on $N$, it suffices to assume $N=2$. Choose any $f\in C_c(X_\blt)$, and let $K_i$ be the projection of $\Supp(f)$ to $X_i$. (So $K_1,K_2$ are compact, and $\Supp(f)\subset K_1\times K_2$.) For each net $(p_\alpha)_{\alpha\in I}$ converging in $X_1$ to $p$, the net of functions $(f(p_\alpha,\cdot)|_{K_2})_{\alpha\in I}$ in $C(K_2)$ converges uniformly to $f(p,\cdot)|_{K_2}$ due to Thm. \ref{lb274}. Therefore, by Thm. \ref{lb829}, we have
\begin{align*}
\lim_\alpha \int_{K_2}f(p_\alpha,\cdot)d\mu_2=\int_{K_2}f(p,\cdot)d\mu_2
\end{align*}
And we can clearly replace the $K_2$ under the integral with $X_2$. This proves that $x_1\in X_1\mapsto \int_{K_2}f(x_1,\cdot)d\mu_2$ is a continuous function on $X_1$ which clearly has compact support in $K_1$. Thus, we can define
\begin{align}
\Lambda(f)=\int_{X_1}\int_{X_2}f(x,y)d\mu_2(y)d\mu_1(x)
\end{align}
This defines a map $\Lambda:C_c(X)\rightarrow\Cbb$ which is clearly $\Cbb$-linear, positive, and satisfying \eqref{eq327}.
\end{proof}











\begin{df}\label{lb827}
The positive linear functional $\Lambda$ in Thm. \ref{lb826} is denoted by $\Lambda_1\otimes\cdots\otimes\Lambda_N$ and called the \textbf{tensor product} of $\Lambda_1,\dots,\Lambda_N$. \index{00@Tensor product of positive linear functionals} The completion of the associated Radon measure of $\Lambda$ is denoted by $\mu_1\times\cdots\times\mu_N$ and called the \textbf{Radon product} \index{00@Radon product} of $\mu_1,\dots,\mu_N$. We also write
\begin{align}
d(\mu_1\times\cdots\times\mu_N)=d\mu_1\times\cdots\times d\mu_N
\end{align}
\end{df}

\begin{rem}\label{lb841}
There is a definition of product measure $\mu_1\times\cdots\times\mu_N$ for general measure spaces $(X_1,\mu_1),\dots,(X_N,\mu_N)$. (See \cite[Ch. 8]{Rud-R} or \cite[Sec. 2.5]{Fol-R}.) Unfortunately, this product measure is in general not complete. However, when each $X_i$ is LCH \textit{and second countable} and each $\mu_i$ is Radon, this product measure is defined on a $\sigma$-algebra containing $\fk B_{X_1\times\cdots\times X_N}$, and its completion is equal to the Radon product in Def. \ref{lb827}. Without assuming second countability, this statement is not true.
\end{rem}

\begin{comment}
In view of the above remark, we define:
\begin{df}
The Radon product measure is called a \textbf{product measure} \index{00@Product measure} if $X_1,\dots,X_N$ are second countable.
\end{df}
\end{comment}


\begin{exe}
Prove that
\begin{gather*}
(\Lambda_1\otimes\Lambda_2)\otimes\Lambda_3=\Lambda_1\otimes\Lambda_2\otimes\Lambda_3=\Lambda_1\otimes(\Lambda_2\otimes\Lambda_3)\\
(\mu_1\times\mu_2)\times\mu_3=\mu_1\times\mu_2\times\mu_3=\mu_1\times(\mu_2\times\mu_3)
\end{gather*}
Generalize these relations to tensor products of more than three positive linear functionals, and Radon products of more than three Radon measures.
\end{exe}


\begin{eg}
Let $m^k$ be the Lebesgue measure of $\Rbb^k$. Then $m^{k_1+k_2}$, the Lebesgue measure of $\Rbb^{k_1+k_2}=\Rbb^{k_1}\times\Rbb^{k_2}$, equals the Radon product of $m^{k_1}$ and $m^{k_2}$.
\end{eg}


\subsection{Theorems of Fubini and Tonelli}



In this section, we fix LCH spaces $X$ and $Y$. Let $(\fk M,\mu)$ and $(\fk N,\nu)$ be the completions of Radon measures on $X$ and $Y$ respectively. Let $\mu\times\nu$ be the Radon product of $\mu$ and $\nu$ (which is the completion of a Radon measure on $X\times Y$).

Whenever the integrals can be defined, we adopt the abbreviations
\begin{gather*}
\int_X\int_Yfd\nu d\mu=\int_X\bigg(\int_Yf(x,y)d\nu(y)\bigg)d\mu(x)\\
\int_Y\int_Xfd\mu d\nu=\int_Y\bigg(\int_Xf(x,y)d\mu(x)\bigg)d\nu(y)
\end{gather*}
We let
\begin{subequations}\label{eq375}
\begin{gather}
\int_Y fd\nu:x\mapsto \int_Y f(x,y)d\nu(y)\\
\int_X fd\mu:y\mapsto \int_Y f(x,y)d\mu(x) 
\end{gather}
\end{subequations}
whenever $x\in X$ and $y\in Y$ are such that the integrals on the RHS can be defined.


\subsubsection{Tonelli's theorem without $\sigma$-finiteness}

\begin{thm}[\textbf{Tonelli's theorem}] \index{00@Tonelli's theorem}\label{lb832} 
Let $f\in\LSC_+(X\times Y)$. Then the functions $\int_Yfd\nu:X\rightarrow\ovl\Rbb_{\geq0}$ and $\int_Xfd\mu:Y\rightarrow\ovl\Rbb_{\geq0}$ are lower semicontinuous, and
\begin{align}\label{eq328}
\int_{X\times Y}fd(\mu\times\nu)=\int_X\int_Yfd\nu d\mu=\int_Y\int_Xf d\mu d\nu
\end{align}
\end{thm}

\begin{proof}
We first consider the special case that $f\in C_c(X\times Y)$. By the definition of Radon product, we know that $\int_{X\times Y}fd(\mu\times\nu)$ equals $(\Lambda_1\otimes\Lambda_2)(f)$ where  $\Lambda_1,\Lambda_2$ are the positive linear functionals inducing $\mu,\nu$ respectively. From the proof of Thm. \ref{lb826}, we know that $\int_Yf d\nu\in C_c(X)$. Note that the second term of \eqref{eq328} defines a positive linear functional $C_c(X\times Y)\rightarrow\Cbb$ sending $f_1f_2$ to $\Lambda_1(f_1)\Lambda_2(f_2)=\int_Xf_1d\mu\cdot\int_Yf_2d\nu$ where $f_1\in C_c(X)$ and $f_2\in C_c(Y)$. Therefore, by the uniqueness in Thm. \ref{lb826}, this positive linear functional equals $\Lambda$. This proves the first equality in \eqref{eq328} in the special case that $f\in C_c(X\times Y,\Rbb_{\geq0})$. The second half of \eqref{eq328} can be proved in the same way.


Now we consider the general case that $f\in\LSC_+(X\times Y)$. By Lem. \ref{lb788}, there is an increasing net $(f_\alpha)_{\alpha\in I}$ in $\LSC_+(X)$ converging pointwise to $f$.  We know that $(\int_Yf_\alpha d\nu)_{\alpha\in I}$ is an increasing net in $C_c(X,\Rbb_{\geq0})$. Therefore, its pointwise limit must be in $\LSC_+(X)$ (by Pb. \ref{lb782}), and must be equal to $\int_Yfd\nu$ by the monotone convergence Cor. \ref{lb798}. Therefore, $\int_Yfd\nu\in\LSC_+(X)$. By Cor. \ref{lb798} again, and by the special case already proved, we have
\begin{align*}
\int_{X\times Y}fd(\mu\times\nu)=\lim_\alpha\int_{X\times Y}f_\alpha d(\mu\times\nu)=\lim_\alpha\int_X\int_Yf_\alpha d\nu d\mu=\int_X\int_Yfd\nu d\mu
\end{align*}
This proves a half of the theorem. The other half can be proved in the same way.
\end{proof}


\begin{rem}
Thm. \ref{lb832} can be formulated (and proved) without the language of measure theory: For each $f\in\LSC_+(X\times Y)$, define $\Lambda_2(f):X\rightarrow\ovl\Rbb_{\geq0}$ sending $x\mapsto \Lambda_2(f(x,\cdot))$. By using Lem. \ref{lb825}, it is easy to check that $\Lambda_2(f)\in C_c(X,\Rbb_{\geq0})$ if $f\in C_c(X\times Y,\Rbb_{\geq0})$, and hence $\Lambda_2(f)\in\LSC_+(X)$ in general (by Pb. \ref{lb782}). The element $\Lambda_1(f)\in\LSC_+(Y)$ can be defined in the same way, and
\begin{align}
(\Lambda_1\otimes\Lambda_2)(f)=\Lambda_1(\Lambda_2(f))=\Lambda_1(\Lambda_2(f))
\end{align}
The key to the proof is (again) the monotone convergence theorem for nets, i.e., Thm. \ref{lb789}.

For example, take $X=Y=\Rbb$ and let $\Lambda_1,\Lambda_2$ be both the Riemann integrals of continuous compactly supported functions, extended canonically to positive lower semicontinuous functions. Then, for each continuous function $f:\Rbb\times\Rbb\rightarrow\Rbb_{\geq0}$, the functions $x\in\Rbb\mapsto \int_\Rbb f(x,y)dy$ and $y\in\Rbb\mapsto\int_\Rbb f(x,y)dx$ from $\Rbb$ to $\ovl\Rbb_{\geq0}$ (defined by improper Riemann integrals) are lower semicontinuous, and we have Tonelli's theorem for improper integrals
\begin{align}
\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}f(x,y)dydx=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} f(x,y)dxdy
\end{align}
Recall that in the last semester, we were only able to prove Fubini's theorems for the exchangeability of an improper integral and a definite integral. (See Thm. \ref{lb422}.) Now, we see that the exchangeability of two improper integrals for continuous positive functions can be easily proved without using the heavy machinery of measure theory and Lebesgue integrals. All we need is the method of extending positive linear functionals developed in Sec. \ref{lb833}.  \hfill\qedsymbol
\end{rem}



\subsubsection{Fubini-Tonelli with $\sigma$-finiteness}


\begin{thm}[\textbf{Tonelli's theorem}] \index{00@Tonelli's theorem}\label{lb835}
Assume that $\mu$ and $\nu$ are $\sigma$-finite. Let $f\in\mc L_+(X\times Y)$. Then the following are true.
\begin{enumerate}
\item[(a)] $f(x,\cdot)\in\mc L_+(Y)$ for almost every $x\in X$.
\item[(b)] Extend the function $\int_Yfd\nu$ (originally defined a.e. on $X$) to $X\rightarrow\ovl\Rbb_{\geq0}$ in an arbitrary way. Then $\int_Yfd\nu\in\mc L_+(X)$.
\item[(c)] We have
\end{enumerate}
\begin{align}
\int_{X\times Y}fd(\mu\times\nu)=\int_X\int_Yfd\nu d\mu
\end{align}
\end{thm}


It follows that $y\in Y\mapsto f(\cdot,y)$ satisfies similar conditions, and hence $\dps\int_X\int_Yfd\nu d\mu=\int_Y\int_Xf d\mu d\nu$.

\begin{proof}
Step 1. We let $\scr F$ be the set of all $f\in\mc L_+(X\times Y)$ satisfying conditions (a,b,c). We make the following observations:
\begin{enumerate}
\item[(i)] $\scr F$ is an $\ovl\Rbb_{\geq0}$-linear subspace of $\mc L_+(X\times Y)$.
\item[(ii)] By Thm. \ref{lb700} and the monotone convergence Thm. \ref{lb760}, if $(f_n)$ is an increasing sequence in $\scr F$, then its pointwise limit is also in $\scr F$.
\end{enumerate}
Since $\mu,\nu$ are $\sigma$-finite, by Rem. \ref{lb809}, there exist $\mu$-finite open sets $\Omega_1\subset\Omega_2\subset\cdots\subset X$ whose union is $X$, and there exist $\nu$-finite open sets $O_1\subset O_2\subset\cdots\subset Y$ whose union is $Y$. To show that each $f\in\mc L_+(X\times Y)$ belongs to $\scr F$, by (ii), it suffices to prove that $f\chi_{\Omega_n\times O_n}\in\scr F$ for each $n$.

Therefore, it suffices to choose any open $\Omega\subset X$ and $O\subset Y$ satisfying $\mu(\Omega)<+\infty$ and $\nu(O)<+\infty$, choose any $f\in\mc L_+(X\times Y)$ vanishing outside $\Omega\times O$, and prove that $f\in\scr F$.\\[-1ex]

Step 2. By Prop. \ref{lb749}, $f$ is the pointwise limit of an increasing sequence of simple functions in $\mc L_+(X\times Y,\Rbb_{\geq0})$. Therefore, by (ii), it suffices to prove that each simple $f:X\times Y\rightarrow\Rbb_{\geq0}$ vanishing outside $\Omega\times O$ belongs to $\scr F$. By (i), it suffices to assume that $f=\chi_E$ where $E\subset \Omega\times O$ and $E$ is $(\mu\times\nu)$-measurable.

By Tonelli's Thm. \ref{lb832}, if $E\subset X$ is open then $\chi_E\in\scr F$. Note that Thm. \ref{lb832} also implies
\begin{align}
(\mu\times\nu)(\Omega\times O)=\int_{X\times Y}\chi_{\Omega\times O}d(\mu\times\nu)=\int_X\int_Y\chi_{\Omega\times O}d\nu d\mu=\mu(\Omega)\nu(O)
\end{align}
Since $\mu(\Omega)<+\infty$ and $\nu(O)<+\infty$, we have $(\mu\times\nu)(\Omega\times O)<+\infty$. Therefore, by Thm. \ref{lb700} and the dominated convergence Thm. \ref{lb755}, we have $\chi_E\in\scr F$ if $E\subset\Omega\times O$ is  $G_\delta$ (since $E$ is the intersection of a \textit{decreasing} sequence of open subsets of $\Omega\times O$). 

Now we consider the general case that $E\subset\Omega\times O$ and $E$ is $\mu\times\nu$-measurable. By the regularity Cor. \ref{lb830}, we can find a $G_\delta$ set $B\subset\Omega\times O$ such that $E\subset B$ and $(\mu\times\nu)(B\setminus E)=0$. Since $\chi_B\in\scr F$, and since all the integrals involved for $\chi_B$ are finite (since this is true for $\chi_{\Omega\times O}$), if we can show that $\chi_{B\setminus E}\in\scr F$, then  $\chi_E=\chi_B-\chi_{B\setminus E}$ clearly belongs to $\scr F$.\\[-1ex]

%% Record #12 2024/04/08 two lectures  29

Step 3. Therefore, it suffices choose any $E\subset \Omega\times O$ such that $E$ is $(\mu\times\nu)$-measurable and $(\mu\times\nu)$-null, and prove $\chi_E\in\scr F$. By Cor. \ref{lb834}, there is a $G_\delta$ set $A\subset \Omega\times O$ such that $(\mu\times\nu)(A)=0$ and $E\subset A$. We have proved in Step 2 that $\chi_A\in\scr F$. In fact, the proof in Step 2 actually shows (a',b',c) where
\begin{enumerate}
\item[(a')] $\chi_A(x,\cdot)\in\mc L_+(Y)$ for all $x\in X$.
\item[(b')] $\int_Y\chi_A d\nu\in\mc L_+(X)$.
\end{enumerate}
(They are true when $A$ is open, due to Tonelli's Thm. \ref{lb832}. By the dominated convergence theorem, they are also true when $A$ is $G_\delta$ in $\Omega\times O$.)

Since (c) holds for $\chi_A$, and since $A$ is null, we have
\begin{align}\label{eq329}
0=\int_{X\times Y}\chi_Ad(\mu\times\nu)=\int_X\int_Y\chi_Ad\nu d\mu
\end{align}
By Prop. \ref{lb752}, the function $x\in X\mapsto\int_Y\chi_A(x,\cdot)d\nu$ is $0$ outside a $\mu$-null set $\Delta\subset X$. By Prop. \ref{lb752} again, for each $x\in X\setminus\Delta$, the function $\chi_A(x,\cdot)$ on $Y$ is $0$ a.e.. Since $\chi_E\leq\chi_A$, we conclude that for each $x\in X\setminus\Delta$, $\chi_E(x,\cdot)$ is $0$ a.e. on $Y$. (However, when $x\in\Delta$, it is not known whether $\chi_E(x,\cdot)$ is measurable.) This proves that $\chi_E$ satisfies (a,b). Since $\chi_E\leq\chi_A$, \eqref{eq329} clearly holds if $A$ is replaced by $E$. This proves that $\chi_E$ satisfies (c). Hence $\chi_E\in\scr F$.
\end{proof}


\begin{co}
Assume that $\mu$ and $\nu$ are $\sigma$-finite, and let $f:X\times Y\rightarrow\Cbb$ be measurable. Then $f\in\mc L^1(X\times Y,\mu\times\nu)$ iff $\dps\int_X\int_Y|f|d\nu d\mu<+\infty$ iff $\dps\int_Y\int_X|f|d\mu d\nu<+\infty$.
\end{co}

\begin{proof}
Apply Tonelli's Thm. \ref{lb835} to $|f|$.
\end{proof}

\begin{eg}
Let $X=Y=[0,1]$ and $\mu=\nu=m$. Let $A\subset[0,1]$ be non-measurable. Let $E=\{0\}\times A$. Then $E$ is an $m^2$-null subset of $[0,1]^2$. So $\chi_E:[0,1]^2\rightarrow\Rbb_{\geq0}$ is Lebesgue measurable. However, $\chi_E(x,\cdot):[0,1]\rightarrow\Rbb_{\geq0}$ is not measurable when $x=0$. This shows that the phrase ``for almost every $x\in X$" in statement (a) of Tonelli's Thm. \ref{lb835} cannot be replaced by ``for every $x\in X$".
\end{eg}



\begin{thm}[\textbf{Fubini's theorem}] \index{00@Fubini's theorem for Radon measures}\label{lb836}
Assume that $\mu$ and $\nu$ are $\sigma$-finite. Let $f\in\mc L^1(X\times Y,\mu\times\nu)$. Then the following are true.
\begin{enumerate}
\item[(a)] $f(x,\cdot)\in\mc L^1(Y,\nu)$ for almost every $x\in X$.
\item[(b)] Extend the function $\int_Yfd\nu$ (originally defined a.e. on $X$) to $X\rightarrow\Cbb$ in an arbitrary way.  Then $\int_Yfd\nu\in\mc L^1(X,\mu)$.
\item[(c)] We have
\end{enumerate}
\begin{align}
\int_{X\times Y}fd(\mu\times\nu)=\int_X\int_Yfd\nu d\mu
\end{align}
\end{thm}

\begin{proof}
By considering $\Real(f)$ and $\Imag(f)$ separately, it suffices to assume that $f$ is real. Apply Tonelli's Thm. \ref{lb835} to $f^\pm=\max\{\pm f,0\}$, and notice Prop. \ref{lb752}-(b) (which is needed to prove that $\int_Yf^\pm(x,\cdot)d\nu<+\infty$ for almost every $x\in X$). We leave the details to the readers.
\end{proof}


Thm. \ref{lb835} and Thm. \ref{lb836} are often jointly referred to as the \textbf{Fubini-Tonelli theorem}. \index{00@Fubini-Tonelli theorem} 






\subsection{Discussion on Fubini-Tonelli}



\subsubsection{Some easy consequences}

Let $(\fk M,\mu)$ and $(\fk N,\nu)$ be completions of Radon measures on LCH spaces $X$ and $Y$ respectively. Let $\mu\times\nu$ be the Radon product.

\begin{pp}\label{lb837}
Assume that $\mu$ and $\nu$ are $\sigma$-finite. Let $A\subset X$ and $B\subset Y$ be measurable. Then $A\times B$ is $(\mu\times\nu)$-measurable, and
\begin{align}\label{eq331}
(\mu\times\nu)(A\times B)=\mu(A)\cdot\nu(B)
\end{align}
\end{pp}

Compare this proposition with the fact that if $A,B$ are Borel, then $A\times B$ is Borel and hence measurable, cf. Pb. \ref{lb838}.

\begin{proof}
Eq. \eqref{eq331} follows immediately from Tonelli's Thm. \ref{lb835} once one can prove that $A\times B$ is measurable. Since $X$ and $Y$ can be written as countable unions $X=\bigcup_n E_n$ and $Y=\bigcup_k F_k$ where each $E_n$ and $F_k$ are measurable and have finite measures, it suffices to prove that $(A\cap E_n)\times (B\cap F_k)$ is measurable for each $n,k$.

In other words, it suffices to prove that $A\times B$ is measurable under the extra assumption that $\mu(A)<+\infty$ and $\nu(B)<+\infty$. By Cor. \ref{lb830}, for each $\eps>0$ there exist open sets $U\supset A$ and $V\supset B$, and compact sets $K\subset A$ and $L\subset B$, such that $\mu(U\setminus K)<\eps$ and $\nu(V\setminus L)<\eps$. Thus $U\times V$ is open and contains $A\times B$, $K\times L$ is compact and is contained in $A\times B$. Moreover, since
\begin{align*}
(U\times V)\setminus (K\times L)= ((U\setminus K)\times V)\cup (U\times (V\setminus L))
\end{align*}
and since $(U\setminus K)\times V$ and $(U\times (V\setminus L))$ are open and hence measurable, we have
\begin{align*}
(\mu\times\nu)((U\times V)\setminus (K\times L))\leq \mu(U\setminus K)\nu(V)+\mu(U)\nu(V\setminus L)\leq\eps(\mu(U)+\nu(V))
\end{align*}
Moreover, when applying Cor. \ref{lb830}, we can choose $U,V$ such that $\mu(U)\leq \mu(A)+1$ and $\nu(V)\leq \nu(B)+1$. Thus, the open set $(U\times V)\setminus (K\times L)$ has measure $\leq \eps(\mu(A)+\nu(B)+2)$. Since $\eps$ is arbitrary, by Cor. \ref{lb830}, we conclude that $A\times B$ is measurable. 
\end{proof}


\begin{eg}\label{lb839}
The projection $\pi:X\times Y\rightarrow X$ is continuous, and hence is Borel. This does not imply that $\pi$ is $(\mu\times\nu)$-measurable (where $X$ is equipped with the $\sigma$ algebra $\fk M$). However, if $\mu$ and $\nu$ are $\sigma$-finite, then $\pi$ is $(\mu\times\nu)$-measurable because for each $A\in\fk M$, the set $\pi^{-1}(A)=A\times Y$ is measurable by Prop. \ref{lb837}.
\end{eg}


\begin{eg}
Assue that $\mu$ is $\sigma$-finite. Let $f:X\rightarrow\Rbb_{\geq0}$ be $\mu$-measurable. Let $R_f$ be the region between the graph of $f$ and the $X$-axis, i.e., 
\begin{align}
R_f=\big\{(x,y)\in X\times\Rbb:0\leq y\leq f(x)\big\}
\end{align}
Then $R_f$ is an $(\mu\times m)$-measurable subset of $X\times\Rbb$ (where $m$ is the Lebesgue measure), and
\begin{align}\label{eq330}
(\mu\times m)(R_f)=\int_X fd\mu
\end{align}
\end{eg}

Compare this example with Pb. \ref{lb838}.

\begin{proof}
It suffices to prove that $R_f$ is measurable. Then \eqref{eq330} follows from Tonelli's Thm. \ref{lb835}. By Exp. \ref{lb839}, the projections $\pi_1:X\times \Rbb\rightarrow X$ and $\pi_2:X\times\Rbb\rightarrow\Rbb$ are measurable. Therefore, $\Phi=(f\circ\pi_1)\vee\pi_2:X\times\Rbb\rightarrow\Rbb^2$ is measurable by Prop. \ref{lb699}. Since $E=\{(s,t)\in\Rbb^2:0\leq t\leq s\}$ is closed, $R_f=\Phi^{-1}(E)$ is measurable.
\end{proof}

\begin{comment}
\begin{sexe}
Extend $\mu,\nu,\mu\times\nu$ to $\sigma$-algebras $\fk M_\mu,\fk M_\nu,\fk M_{\mu\times\nu}$ respectively, cf. Thm. \ref{lb724}. (In other words, $(\fk M_\mu,\mu)$ is the saturation of $(\fk M,\mu)$. $\fk M_\nu$ and $\fk M_{\mu\times\nu}$ are similar.) Prove that if $A\in\fk M_\mu$ and $B\in\fk M_\nu$ then $A\times B\in\fk M_{\mu\times\nu}$.
\end{sexe}
\end{comment}



\subsubsection{Other approaches to Fubini-Tonelli}

We have mentioned in Rem. \ref{lb841} that there is a general notion of product measure space which (after completion) agrees with the Radon product when the LCH spaces are second countable. The general definition is as follows. Suppose that $(X,\fk M,\mu)$ and $(Y,\fk N,\nu)$ are measure spaces. Let $\fk M\otimes\fk N$ be the $\sigma$-algebra generated by all $E\times F$ where $E\in\fk M$ and $F\in\fk N$. Using Carath\'eodory's Thm. \ref{lb740}, one can naturally construct a measure $\mu\wht\times\nu:\fk M\otimes\fk N\rightarrow[0,+\infty]$ satisfying $(\mu\wht\times\nu)(E\times F)=\mu(E)\nu(F)$. 

Assuming that $\mu$ and $\nu$ are $\sigma$-finite, Tonelli's Thm. \ref{lb835} and Fubini's Thm. \ref{lb836} can be proved for $(\fk M\otimes\fk N)$-measurable functions on $X\times Y$ with one improvement: the statement ``for almost every $x\in X$" in Thm. \ref{lb836}-(a) can be replaced by ``for every $x\in X$". However, $(\fk M\otimes\fk N,\mu\wht\times\nu)$ is in general not complete. If we consider its completion instead, then we still need ``for almost every $x\in X$" in Thm. \ref{lb836}-(a). The readers are referred to \cite[Sec. 2.5]{Fol-R} for details.


Alternatively, one can first prove $\int_X\int_Yf=\int_Y\int_Xf$ for $\sigma$-finite measures, and then define the measure on $\fk M\otimes\fk N$ by using $(\mu\wht\times\nu)(A)=\int_X\int_Y\chi_A$. This approach was adopted by Rudin. See \cite[Ch. 8]{Rud-R}. Of course, this approach does not define $\mu\wht\times\nu$ when $\mu$ or $\nu$ is not $\sigma$-finite. But you won't lose anything if you only care about $\sigma$-finite measures.

When $X,Y$ are LCH spaces and $(\fk M,\mu),(\fk N,\nu)$ are completions of Radon measures, the Radon product $\mu\times\nu$ extends the completion of $\mu\wht\times\nu$ when $\mu,\nu$ are $\sigma$-finite, and agrees with the completion of $\mu\wht\times\nu$ when $X,Y$ are second countable. See \cite[Sec. 7.4]{Fol-R}. \footnote{Folland used the word ``Radon product" in a different way. Since Folland focused on Borel measurable sets and functions, his Radon product is the Radon measure associated to $\Lambda_1\otimes\Lambda_2$ (defined on $\fk B_{X\times Y}$). Therefore, our Radon product is the completion of Folland's Radon product.}

In many approaches to the Fubini-Tonelli theorem, one uses either Carath\'eodory's theory (cf. \cite[Ch. 6, Sec. 3.1]{SS-R}), or monotone classes (cf. \cite{Rud-R}), or both (cf. \cite{Fol-R}, \cite[Sec. 1.7]{Tao}, or \cite[Sec. 44]{Yu}). We used neither of these, but used regularity instead. It is clear that regularity runs through our treatment of measure theory from beginning to end.









\subsection{Failure of Tonelli's theorem without LSC and $\sigma$-finiteness; a Borel set not inner regular}

We have proved two versions of Tonelli's theorem, i.e., Thm. \ref{lb832} and \ref{lb835}. The first one assumes that the functions are lower semicontinuous, and the second one assumes that $X,Y$ are $\sigma$-finite. The readers should compare them with the two monotone convergence theorems, i.e., Cor. \ref{lb798} and Thm. \ref{lb760}. The first one assumes lower semicontinuity but can be applied to nets. The latter can be applied only to sequences. \uwave{The relationship between a general Radon measure and a $\sigma$-finite one is similar to the relationship between a net and a sequence.}

In the following, let us see a class of (counter)examples that can be interpreted both by the failure of Fubini-Tonelli without $\sigma$-finiteness and lower semicontinuity, and by the failure of the  monotone convergence theorem for nets of functions without lower semicontinuity. 


Let $(\fk M,\mu)$ be the completion of a Radon measure on an LCH space $X$. Let $Y$ be a set, equipped with the discrete topology $2^Y$, and let $\nu:2^Y\rightarrow\ovl\Rbb_{\geq0}$ be the counting measure. Then $\nu$ is a complete Radon measure on $Y$ which is $\sigma$-finite iff $Y$ is countable.

For each $E\subset X\times Y$ and $y\in Y$, let $E_y\subset X$ such that
\begin{align}\label{eq334}
E_y\times\{y\}=E\cap(X\times\{y\})
\end{align}
It is clear that $E$ is open iff each $E_y$ is open. Tonelli's Thm. \ref{lb832} implies that if $E$ is open then
\begin{align}\label{eq335}
(\mu\times\nu)(E)=\sum_y\mu(E_y)
\end{align}
Let $f:X\times Y\rightarrow\ovl\Rbb_{\geq0}$. For each $y\in Y$, define $f_y:X\rightarrow\ovl\Rbb_{\geq0}$ be $f_y(x)=f(x,y)$. It follows from \eqref{eq334} that $f$ is lower semicontinuous iff $f_y$ is lower semicontinuous for each $y\in Y$.

\begin{comment}
\begin{sexe}
Let $E\subset X\times Y$. Use Cor. \ref{lb830} to prove that the following are equivalent.
\begin{enumerate}
\item[(1)] $E$ is $(\mu\times\nu)$-measurable and has finite measure.
\item[(2)] $E_y=\emptyset$ except for countably many $y\in Y$. Moreover, for all $y\in Y$, $E_y$ is $\mu$-measurable, and $\sum_{y\in Y}\mu(E_y)<+\infty$.
\end{enumerate}
\end{sexe}
\end{comment}




We now assume that $\mu$ is $\sigma$-finite and $f$ is Borel. Consider the relation
\begin{align}\label{eq332}
\sum_{y\in Y} \int_Xf_yd\mu=\int_X\Big(\sum_{y\in Y}f_y\Big)d\mu
\end{align}
which holds by Tonelli's Theorems if $Y$ is countable or if $f$ is lower semicontinuous. Let $I=\fin(2^Y)$. For each $\alpha\in I$, let $g_\alpha:X\rightarrow\ovl\Rbb_{\geq0}$ be defined by $g_\alpha=\sum_{y\in \alpha}f_\alpha$. Then \eqref{eq332} is equivalent to
\begin{align}\label{eq333}
\lim_{\alpha\in I}\int_Xg_\alpha d\mu=\int_X\Big(\lim_{\alpha\in I}g_\alpha \Big)d\mu
\end{align}
which holds when $f$ is lower semicontinuous by the monotone convergence Cor. \ref{lb798}. When $Y=\Zbb_+$, $(g_\alpha)$ has a subnet $(g_{\alpha_n})_{n\in\Zbb_+}$ where $\alpha_n=\{1,\dots,n\}$. Since any increasing net in $\ovl\Rbb_{\geq0}$ converges in $\ovl\Rbb_{\geq0}$, and since any of its subnet converges to the same value, we see that \eqref{eq333} is equivalent to
\begin{align*}
\lim_{n\rightarrow\infty}\int_Xg_{\alpha_n} d\mu=\int_X\Big(\lim_{n\rightarrow\infty}g_{\alpha_n} \Big)d\mu
\end{align*}
which holds by the monotone convergence Thm. \ref{lb760}.


We now give an example where $Y$ is uncountable, $f$ is not lower semicontinuous, and \eqref{eq332} fails (equivalently, \eqref{eq333} fails).


\begin{eg}\label{lb840}
Let $X=[0,1]$ and $\mu$ is the Lebesgue measure $m$. Let $Y=[0,1]$, equipped with the discrete topology and the counting measure (denoted by $\nu$). Define $f:X\times Y\rightarrow\Rbb_{\geq0}$ by $f(x,y)=\delta_{x,y}$. Namely, $f$ is the characteristic function $\chi_\Delta$ where $\Delta$ is the diagonal line $\{(x,x):x\in[0,1]\}$. $\Delta$ clear has open complement. So $\Delta$ is closed. Therefore $f$ is upper semicontinuous (and hence is Borel). We have
\begin{align*}
\sum_{y\in Y} \int_Xf_ydm=\sum_{y\in Y}0=0\neq 1=\int_X 1dm= \int_X\Big(\sum_{y\in Y}f_y\Big)dm
\end{align*}


Moreover, the above two iterated integrals are not equal to $\int_{X\times Y}fd(m\times\nu)=(m\times\nu)(\Delta)$. Let us prove that
\begin{align*}
\int_{X\times Y}fd(m\times\nu)=+\infty
\end{align*}
By the outer regularity (cf. Thm. \ref{lb804}), it suffices to prove that $(m\times\nu)^*(\Delta)=+\infty$, i.e., any an open set $E$ containing $\Delta$ has infinite measure. Let $E_y$ be as in \eqref{eq334}, which is nonempty for each $y$. So $m(E_y)>0$. Since $Y$ is uncountable, we have $\sum_y m(E_y)=+\infty$ by Pb. \ref{lb413}. So $(m\times\nu)(E)=+\infty$ by \eqref{eq335}. \hfill\qedsymbol
\end{eg}

\begin{rem}\label{lb842}
In Exp. \ref{lb840}, we proved that the closed set $\Delta$ satisfies $(m\times\nu)^*(\Delta)=(m\times\nu)(\Delta)=+\infty$. Note that every compact subset $K$ of $\Delta$ is a finite set (since its image under the projection $X\times Y\rightarrow Y$ is compact under the discrete topology, and hence is finite). Hence $K$ is $(m\times\nu)$-null. Therefore $(m\times\nu)_*(\Delta)=0$. This gives an example of Borel subset with infinite Radon measure which is not inner regular.
\end{rem}


\begin{exe}
The condition $\int_{X\times Y}fd(\mu\times\nu)<+\infty$ in Fubini's Thm. \ref{lb836} is similar to the condition that $|f_n|\leq g$ and $\int g<+\infty$ in the dominated convergence Thm. \ref{lb755}. Find a counterexample that can be explained by both perspectives.
\end{exe}






\newpage


\section{Completeness and duality in measure theory}\label{mc238}


\begin{df}
Let $V$ be a vector space over $\Fbb\in\{\Rbb,\Cbb\}$. A \textbf{seminorm} \index{00@Seminorm} on $V$ is a function $\Vert\cdot\Vert:V\rightarrow\Rbb_{\geq0}$ satisfying:
\begin{itemize}
\item (Subadditivity) If $u,v\in V$, then $\Vert u+v\Vert\leq\Vert u\Vert+\Vert v\Vert$.
\item (Absolute homogeneity) If $v\in V$ and $\lambda\in\Fbb$ then $\Vert \lambda v\Vert=|\lambda|\cdot\Vert v\Vert$.
\end{itemize}
\end{df}


The relationship between seminorms and norms is similar to that between positive sesquilinear forms and inner products. In particular, we have the following generalization of Prop. \ref{lb589}.

\begin{pp}\label{lb854}
Let $\Vert\cdot\Vert$ be a seminorm on $V$. Then $\scr N=\{v\in V:\Vert v\Vert=0\}$ is a linear subspace of $V$. There is a canonical norm $\Vert\cdot\Vert_U$ on $U=V/\scr N$  such that
\begin{align*}
\Vert v+\scr N\Vert_U=\Vert v\Vert\qquad(\forall v\in V)
\end{align*}
\end{pp}

\begin{proof}
It is easy to check that $\scr N$ is a linear subspace. If $u+\scr N=v+\scr N$, then $v-u\in\scr N$. So $\Vert v\Vert\leq\Vert u\Vert+\Vert v-u\Vert=\Vert u\Vert$, and similarly $\Vert u\Vert\leq\Vert v\Vert$. This proves that $\Vert\cdot\Vert_U:U\rightarrow\Rbb_{\geq0}$ is well-defined. We leave it to the readers to check that $\Vert\cdot\Vert_U$ is a norm.
\end{proof}



\subsection{The definition of $L^p$ spaces}

Let $(X,\fk M,\mu)$ be a measure space.


\subsubsection{The space $L^p(X,\mu)$ where $1\leq p<+\infty$}

We fix a number $p$ satisfying $1\leq p<+\infty$.

\begin{df}
For each $f\in\mc L(X,\Cbb)$, define \index{Lp@$L^p$ (semi)norm}
\begin{align}
\Vert f\Vert_{L^p}\equiv \Vert f\Vert_p=\Big(\int_X|f|^pd\mu\Big)^{\frac 1p}
\end{align}
In particular, we will not let $\Vert f\Vert_p$ denote $\Vert f\Vert_{l^p}$ unless otherwise stated.
\end{df}

\begin{thm}
Assume that $f,g\in\mc L(X,\Cbb)$ or $f,g\in\mc L_+(X)$. We have \textbf{Minkowski's inequality}  \index{00@Minkowski's inequality}
\begin{align}
\Vert f+g\Vert_p\leq\Vert f\Vert_p+\Vert g\Vert_p
\end{align}
and, if $1<p,q<+\infty$ and $p^{-1}+q^{-1}=1$, \textbf{H\"older's inequality} \index{00@H\"older's inequality}
\begin{align}
\Big|\int_X fgd\mu\Big|\leq \Vert f\Vert_p\cdot\Vert g\Vert_q
\end{align}
\end{thm}

\begin{proof}
Since $\Vert f+g\Vert_p\leq \Vert (|f|+|g|)\Vert_p$ and $|\int fg|\leq\int|fg|$, by replacing $f,g$ with $|f|,|g|$, it suffices to assume $f,g\in\mc L_+(X)$. By Prop. \ref{lb749}, there exist increasing sequences in $\mc S(X,\Rbb_{\geq0})$ converging to $f$ and $g$ respectively. By the monotone convergence theorem, it suffices to prove the two inequalities for elements in $\mc S(X,\Rbb_{\geq0})$.

Let's prove H\"older's inequality for $f,g\in\mc S_+(X)$ assuming that $1<p,q<+\infty$. The proof of Minkowski's inequality is similar and is left to the readers. 

We assume WLOG that $\Vert f\Vert_p\cdot\Vert g\Vert_q<+\infty$, otherwise, the inequality is obvious. If $\Vert f\Vert_p=+\infty$, then $\Vert g\Vert_q=0$. So $\int |g|^p=0$. By Prop. \ref{lb752}, we have $g=0$ a.e., and hence $fg=0$ a.e.. So $\int fg=0$ by Prop. \ref{lb752}. Similarly, if $\Vert g\Vert_q=+\infty$, then $\int fg=0$. The inequality holds. 

So we can assume that $\Vert f\Vert_p$ and $\Vert g\Vert_q$ are both finite. By Prop. \ref{lb752}, $f<+\infty$ and $g<+\infty$ outside a null set $\Delta$. Replacing $f,g$ with $f\chi_{\Delta^c},g\chi_{\Delta^c}$, it suffices to assume $f,g\in\mc S(X,\Rbb_{\geq0})$.  Write $f$ and $g$ as finite sums $f=\sum_i a_i\chi_{E_i}$ and $g=\sum_j b_j\chi_{F_j}$ where $a_i,b_j\in\Rbb_{>0}$, $E_1,E_2,\dots\in\fk M$ are pairwise disjoint, and $F_1,F_2,\dots\in\fk M$ are pairwise disjoint. Since $a_i\chi_{E_i}\leq f$, we have $a_i^p\mu(E_i)\leq\int |f|^p<+\infty$ and hence $\mu(E_i)<+\infty$. Similarly, we have $\mu(F_j)<+\infty$. Let $G_{i,j}=E_i\cap F_j$. So $f=\sum_{i,j}a_i\chi_{G_{i,j}}$ and $g=\sum_{i,j}b_j\chi_{G_{i,j}}$ and $fg=\sum_{i,j}a_ib_j\chi_{G_{i,j}}$. By H\"older's inequality for finite sums (Thm. \ref{lb853}) we have
\begin{align*}
&\int_Xfg=\sum_{i,j}a_ib_j\mu(G_{i,j})=\sum_{i,j}a_i\mu(G_{i,j})^{\frac 1p}\cdot b_j\mu(G_{i,j})^{\frac 1q}\\
\leq& \Big(\sum_{i,j} a_i^p\mu(G_{i,j})\Big)^{\frac 1p}\cdot \Big(\sum_{i,j} b_j^q\mu(G_{i,j})\Big)^{\frac 1q}=\Vert f\Vert_p\cdot\Vert g\Vert_q
\end{align*}
\end{proof}



\begin{df}
We let \index{Lp@$\mc L^p(X,\mu)$}
\begin{align}
\mc L^p(X,\mu)=\{f\in\mc L(X,\Cbb):\Vert f\Vert_p<+\infty\}
\end{align}
Then, by Minkowski's inequality, $\mc L^p(X,\mu)$ is a linear subspace of $\Cbb^X$ with seminorm $\Vert\cdot\Vert_p$. Thus, by Prop. \ref{lb854}, $L^p(X,\mu)$ \index{Lp@$L^p(X,\mu)$} is a normed vector space with norm $\Vert\cdot\Vert_{L^p}=\Vert\cdot\Vert_p$ if we define
\begin{align}
L^p(X,\mu)=\mc L^p(X,\mu)\big/\{f\in\mc L^p(X,\mu):\Vert f\Vert_p=0\}
\end{align}
By Prop. \ref{lb752}, we have $\Vert f\Vert_p=0$ iff $f=0$ a.e.. So
\begin{align*}
L^p(X,\mu)=\mc L^p(X,\mu)\big/\{f\in\mc L(X,\Cbb):f=0\text{ $\mu$-a.e.}\}
\end{align*}
\end{df}

In other words, elements in $L^p(X,\mu)$ are measurable functions $f:X\rightarrow\Cbb$, and two elements $f,g$ are viewed as the same iff $f=g$ a.e..


\begin{rem}
The $L^2$ norm on $L^2(X,\mu)$ is clearly induced by the inner product
\begin{align}\label{eq348}
\bk{f|g}=\int_X fg^*d\mu\qquad(\forall f,g\in L^2(X,\mu))
\end{align}
where $fg^*$ is integrable by H\"older's inequality. We shall always understand $L^2(X,\mu)$ as an inner product space whose inner product is defined by \eqref{eq348}.
\end{rem}



\subsubsection{The space $L^\infty(X,\mu)$}



\begin{df}
For each $f\in\mc L(X,\Cbb)$, define \index{Lp@$L^\infty$ (semi)norm}
\begin{align}
\Vert f\Vert_{L^\infty}\equiv\Vert f\Vert_\infty=\inf\big\{a\in\ovl\Rbb_{\geq0}:\mu\{x\in X:|f(x)|>a\}=0\big\}
\end{align}
(Note that the set inside the $\inf$ is nonempty since it contains $+\infty$.) Clearly
\begin{align*}
\Vert f\Vert_{L^\infty}\leq\Vert f\Vert_{l^\infty}
\end{align*}
Unless otherwise stated, we will not let $\Vert f\Vert_\infty$ denote $\Vert f\Vert_{l^\infty}$.
\end{df}

We give some elementary facts about $L^\infty$.

\begin{pp}\label{lb860}
Let $f\in\mc L(X,\Cbb)$ and $\lambda=\Vert f\Vert_{L^\infty}$. Then
\begin{align}
\big\{a\in\ovl\Rbb_{\geq0}:\mu\{|f|>a\}=0\big\}=[\lambda,+\infty]
\end{align}
In particular, $\lambda=\Vert f\Vert_{L^\infty}$ is the smallest number in $\ovl\Rbb_{\geq0}$ such that $\{x\in X:|f(x)|>\lambda\}$ is null. Moreover, if we let
\begin{align*}
A=\{|f|\leq\lambda\}
\end{align*}
then $X\setminus A$ is null, and for any measurable $B\subset A$ satisfying $\mu(X\setminus B)=0$, we have
\begin{align}
\Vert f\chi_B\Vert_{l^\infty}=\Vert f\Vert_{L^\infty}
\end{align}
\end{pp}

\begin{proof}
Let $E=\big\{a\in\ovl\Rbb_{\geq0}:\mu\{|f|>a\}=0\big\}$. Clearly, if $a\in E$ and $b\geq a$ then $b\in E$. Therefore, $E$ equals $(\lambda,+\infty]$ or $[\lambda,+\infty]$. Pick a decreasing sequence $(a_n)$ in $E$ converging to $\lambda$. Then $\{|f|>\lambda\}$ is the union of $\{|f|>a_n\}$, which is null. This proves $\lambda\in E$, and hence $E=[\lambda,+\infty]$.

That $\lambda\in E$ means that $X\setminus A$ is null. Let $\kappa=\Vert f\chi_B\Vert_{l^\infty}$. Since $|f|_B|\leq\lambda$, we have $\kappa\leq\lambda$. The set $\{|f|>\kappa\}$ is a measurable subset of $X\setminus B$, which is null. Therefore, $\kappa$ belongs to $E=[\lambda,+\infty]$, and hence $\kappa\geq\lambda$.
\end{proof}

\begin{co}\label{lb964}
Choose countably many $f_1,f_2,\dots\in\mc L(X,\Cbb)$. There there exists $A\in\fk M$ such that $\mu(X\setminus A)=0$ and $\Vert f_n\chi_A\Vert_{l^\infty}=\Vert f_n\Vert_{L^\infty}$ for each $n$.
\end{co}

\begin{proof}
By Prop. \ref{lb860}, $A=\bigcap_n A_n$ satisfies the desired property if we let $A_n=\{|f_n|\leq \lambda_n\}$ and $\lambda_n=\Vert f_n\Vert_{L^\infty}$.
\end{proof}


\begin{pp}\label{lb861}
Let $f,g\in\mc L(X,\Cbb)$. The following are true.
\begin{enumerate}
\item[(a)] If $f=g$ a.e., then $\Vert f\Vert_{L^\infty}=\Vert g\Vert_{L^\infty}$.
\item[(b)] We have $f=0$ a.e. iff $\Vert f\Vert_{L^\infty}=0$.
\end{enumerate}
\end{pp}


\begin{proof}
Suppose that $f=g$ a.e.. Then $\{|f|>a\}$ is null iff $\{|g|>a\}$ is null. So $\Vert f\Vert_{L^\infty}=\Vert g\Vert_{L^\infty}$.

In particular, if  $f=0$ a.e., then $\Vert f\Vert_{L^\infty}=\Vert 0\Vert_{L^\infty}=0$. Conversely,  if $\Vert f\Vert_{L^\infty}=0$, then by Prop. \ref{lb860}, $\{x\in X:|f(x)|>0\}$ is null. So $f=0$ a.e..
\end{proof}










Thanks to Cor. \ref{lb964}, we can prove many properties of $L^\infty$ with the help of $l^\infty$. Let us see some examples.




\begin{pp}\label{lb877}
Let $(f_n)$ be a sequence in $\mc L(X,\Cbb)$. Then the following are equivalent.
\begin{enumerate}
\item[(1)] $\dps\lim_{n\rightarrow\infty}\Vert f_n\Vert_{L^\infty}=0$.
\item[(2)] There exists $A\in\fk M$ such that $\mu(X\setminus A)=0$ and $\dps\lim_{n\rightarrow\infty}\Vert f_n\chi_A\Vert_{l^\infty}=0$. 
\end{enumerate}
\end{pp}



\begin{proof}
Assume (1). By Cor. \ref{lb964}, there exists $A\in\fk M$ such that $X\setminus A$ is null and $\Vert f_n\Vert_{L^\infty}=\Vert f_n\chi_A\Vert_{l^\infty}$. Thus (2) holds. Assume (2). By Prop. \ref{lb861} we have $\Vert f_n\Vert_{L^\infty}=\Vert f_n\chi_A\Vert_{L^\infty}\leq \Vert f_n\chi_A\Vert_{l^\infty}$. So (1) is true.
\end{proof}


\begin{pp}\label{lb862}
For every $a\in\Cbb$ and $f,g\in\mc L(X,\Cbb)$ we have
\begin{align*}
\Vert f+g\Vert_{L^\infty}\leq\Vert f\Vert_{L^\infty}+\Vert g\Vert_{L^\infty}\qquad\Vert af\Vert_{L^\infty}=|a|\cdot\Vert f\Vert_{L^\infty}
\end{align*}
\end{pp}
\begin{proof}
By Cor. \ref{lb964}, there exists $A\in\fk M$ with null complement such that $\Vert f\Vert_{L^\infty}=\Vert f\chi_A\Vert_{l^\infty}$, $\Vert g\Vert_{L^\infty}=\Vert g\chi_A\Vert_{l^\infty}$, and $\Vert f+g\Vert_{L^\infty}=\Vert(f+g)\chi_A\Vert_{l^\infty}$. Therefore
\begin{align*}
\Vert f+g\Vert_{L^\infty}=\Vert f\chi_A+g\chi_A\Vert_{l^\infty}\leq \Vert f\chi_A\Vert_{l^\infty}+\Vert g\chi_A\Vert_{l^\infty}=\Vert f\Vert_{L^\infty}+\Vert g\Vert_{L^\infty}
\end{align*}
Similarly, let $B\in\fk M$ with null complement such that $\Vert af\Vert_{L^\infty}=\Vert af\chi_B\Vert_{l^\infty}$ and $\Vert f\Vert_{L^\infty}=\Vert f\chi_B\Vert_{l^\infty}$. Then
\begin{align*}
\Vert af\Vert_{L^\infty}=\Vert af\chi_B\Vert_{l^\infty}=a\Vert f\chi_B\Vert_{l^\infty}=a\Vert f\Vert_{L^\infty}
\end{align*}
\end{proof}



\begin{rem}
H\"older's inequality clearly holds when $p=1,q=+\infty$. Namely, if $f,g\in \mc L(X,\Cbb)$, since $|fg|\leq |f|\cdot\Vert g\Vert_\infty$ a.e., we have $\int|fg|\leq \int|f|\cdot\Vert g\Vert_\infty$, i.e.
\begin{align*}
\Vert fg\Vert_{L^1}\leq\Vert f\Vert_{L^1}\cdot\Vert g\Vert_{L^\infty}
\end{align*}
\end{rem}

\begin{df}
We let
\begin{gather*}
\mc L^\infty(X)=\{f\in\mc L(X,\Cbb):\Vert f\Vert_{l^\infty}<+\infty\}
\end{gather*}
Then, by Prop. \ref{lb861} and \ref{lb862}, we can define the normed vector space \index{L@$L^\infty(X,\mu)$}
\begin{align}
L^\infty(X,\mu)=\mc L^\infty(X)/\{f\in\mc L^\infty(X):f=0\text{ a.e.}\}
\end{align}
with the (well-defined) norm $\Vert \cdot\Vert_{L^\infty}$.
\end{df}




\begin{thm}\label{lb876}
$L^\infty(X,\mu)$ is a Banach space.
\end{thm}


\begin{proof}
Let $(f_n)$ be a Cauchy sequence in $L^\infty(X,\mu)$. Choose $f_n\in\mc L^\infty(X)$ representing the corresponding element in $L^\infty(X,\mu)$. Then $\lim_{m,n\rightarrow\infty}\Vert f_m-f_n\Vert_{L^\infty}=0$. By Cor. \ref{lb964}, there is $A\in\fk M$ with null complement such that $\Vert (f_m-f_n)\chi_A\Vert_{l^\infty}$ equals $\Vert f_m-f_n\Vert_{L^\infty}$, and hence converges to $0$. By the completeness of $l^\infty(X)$, $(f_n\chi_A)_{n\in\Zbb_+}$ converges uniformly to some $f\in l^\infty(X)$. By Cor. \ref{lb701}, $f\in\mc L^\infty(X)$. Thus
\begin{align*}
\Vert f-f_n\Vert_{L^\infty}=\Vert (f-f_n)\chi_A\Vert_{L^\infty}\leq \Vert (f-f_n)\chi_A\Vert_{l^\infty(X)}= \Vert f-f_n\Vert_{l^\infty(A)}\rightarrow0
\end{align*}
where Prop. \ref{lb861} is used in the first equality.
\end{proof}


\begin{exe}\label{lb864}
Let $1\leq p\leq +\infty$. Let $\ovl\mu$ be the completion of $\mu$. Use Pb. \ref{lb778} or Prop. \ref{lb863} to prove that the map
\begin{align*}
L^p(X,\mu)\rightarrow L^p(X,\ovl\mu)\qquad f\mapsto f
\end{align*}
is an isomorphism of normed vector spaces.
\end{exe}


%% Record #13 2024/04/11 three lectures  32


\subsection{Approximation in $L^p$ spaces}


In this section, we provide two useful dense subspaces of an $L^p$ space.

\subsubsection{Approximation by continuous functions}

\begin{thm}\label{lb866}
Let $X$ be LCH. Let $\mu$ be the completion of a Radon measure on $X$. Let $1\leq p<+\infty$. Then $C_c(X)$ is dense in $L^p(X,\mu)$. More precisely, the (non-necessarily injective) map $f\in C_c(X)\mapsto f\in L^p(X,\mu)$ has dense range.
\end{thm}

Note that by Exe. \ref{lb864}, the theorem will be no different if we deal with the original Radon measure rather than its completion.

\begin{proof}
Let $f\in L^p(X,\mu)$. We shall show that $f$ can be approximated by elements of $C_c(X)$. 

We first consider the special case that $M=\Vert f\Vert_{l^\infty}<+\infty$ and that $f$ is zero outside some $A\in\fk M$ such that $\mu(A)<+\infty$. By the regularity Thm. \ref{lb804}, $A$ is contained in an open set with finite measure. By replacing $A$ with this larger open set, we may assume that $A$ is open. 

By Lusin's Thm. \ref{lb865}, for every $\eps>0$, there is a compact $K\subset A$ such that $\mu(A\setminus K)<\eps$ and $f|_K$ is continuous. Since $A$ is open and hence is LCH (cf. Prop. \ref{lb245}), by the Tietze extension Thm. \ref{lb468}, there exists $g\in C_c(X)$ compactly supported in $A$ such that $g|_K=f|_K$ and $\Vert g\Vert_{l^\infty}\leq M$. Thus $|f-g|\leq 2M$, and hence
\begin{align*}
\int_X |f-g|^p=\int_{A\setminus K}|f-g|^p\leq (2M)^p\cdot\mu(A\setminus K)\leq (2M)^p\cdot\eps
\end{align*}
Therefore $\Vert f-g\Vert_p\leq 2M\cdot\eps^{\frac 1p}$. Since $\eps$ can be arbitrary, we conclude that $f$ can be approximated by elements of $C_c(X)$.
 

Now we treat the general case. Let $E_n=\{x\in X:1/n\leq|f(x)|\leq n\}$. Then $(E_n)$ is increasing and $\bigcup_n E_n=X$. Moreover, since $n^{-1}\chi_{E_n}\leq |f|$, we have $n^{-p}\mu(E_n)\leq\Vert f\Vert_p^p$ and hence $\mu(E_n)<+\infty$. Since $|f-f\chi_{E_n}|\leq |f|$ and $\int|f|^p<+\infty$,  we have $\lim_n \int |f-f\chi_{E_n}|^p=0$ by the dominated convergence theorem. By the above special case, $f\chi_{E_n}$ can be approximated by elements of $C_c(X)$. This finishes the proof.
\end{proof}


Note that $C_c(X)$ is in general not dense in $L^\infty(X)$ becasue the uniform limit of a sequence of continuous functions is continuous.


\subsubsection{Applications of continuous function approximation}

 
\begin{df}
Fix any $\theta\in\Rbb$. A subset $E\subset\Sbb^1$ is called \textbf{Lebesgue measurable} if it is of the form $\exp(\im F)$ where $F$ is a Lebesgue measuarble subset of $[\theta-\pi,\theta+\pi)$. In that case, we defined the \textbf{Lebesgue measure} $m(E)$ to be $m(F)$. It is easy see that this definition is independent of the choice of $\theta$. Since $(\Sbb^1,m)$ is equivalent to $([-\pi,\pi),m)$, the Lebesgue measure on $\Sbb^1$ is the completion of a Radon measure.
\end{df}



\begin{co}\label{lb878}
Let $e_n\in C[-\pi,\pi]$ be defined by $e_n(x)=e^{\im nx}$. Let $1\leq p<+\infty$. Then $(e_n)_{n\in\Zbb}$ spans a dense linear subspace of $L^p([-\pi,\pi],\frac m{2\pi})$. In particular, $(e_n)_{n\in\Zbb}$ is an orthonormal basis of $L^2([-\pi,\pi],\frac m{2\pi})$.
\end{co}



\begin{proof}


Clearly $L^p([-\pi,\pi],\frac m{2\pi})$ can be identified naturally with $L^p(\Sbb^1,\frac m{2\pi})\simeq L^p([-\pi,\pi),\frac m{2\pi})$. By Thm. \ref{lb866}, $C(\Sbb^1)$ is dense in $L^p(\Sbb^1,\frac m{2\pi})$. By Stone-Weierstrass, $V=\Span\{e_n:n\in\Zbb\}$ is $l^\infty$-dense in $C(\Sbb^1)$. Therefore $V$ is $L^p$-dense in $C(\Sbb^1)$ since
\begin{align*}
\Vert f\Vert_p^p=\frac 1{2\pi}\int_{[-\pi,\pi]} |f|^pdm\leq \Vert f\Vert_{l^\infty}^p
\end{align*}
shows that $l^\infty$-convergence implies $L^p$-convergence. Therefore, $V$ is dense in $L^p([-\pi,\pi],\frac m{2\pi})$. 

It is obvious that $(e_n)$ is an orthonormal sequence in $L^2([-\pi,\pi],\frac m{2\pi})$. Therefore, the density proved above shows that $(e_n)$ is an orthonormal basis of $L^2([-\pi,\pi],\frac m{2\pi})$.
\end{proof}



\begin{co}[\textbf{Riemann-Lebesgue}]
Let $f\in L^1(\Rbb,m)$. Then 
\begin{align}
\lim_{t\rightarrow+\infty}\int_\Rbb f(x)e^{\im tx}dm=\lim_{t\rightarrow-\infty}\int_\Rbb f(x)e^{\im tx}dm=0
\end{align}
\end{co}

\begin{proof}
By Thm. \ref{lb866}, for each $\eps>0$ there exists $g\in C_c(\Rbb)$ such that $\Vert f-g\Vert_{L^1}\leq\eps$. Then $|\int_\Rbb (f-g)e^{\im tx}dm|\leq \eps$. Therefore, if we can show that $\lim_{t\rightarrow\pm\infty}\int_\Rbb ge^{\im tx}dm=0$, then $\limsup_{t\rightarrow\pm\infty}\int_\Rbb fe^{\im tx}dm\leq\eps$ for all $\eps>0$, finishing the proof.

That $\lim_{t\rightarrow\pm\infty}\int_\Rbb ge^{\im tx}dm=0$ follows from the Riemann-Lebesgue lemma for Riemann integrals, Thm. \ref{lb871}. But we can also prove it without using the method of Riemann integrals. Since $\int g(x)e^{\im tx}dx=\int \lambda g(\lambda x)e^{\im t\lambda x}dx$ (where $\lambda\in\Rbb_{>0}$), by replacing $g$ with $g(\lambda x)$, it suffices to assume that $\Supp g\subset[-\pi,\pi]$ and prove
\begin{align}
\lim_{t\rightarrow\pm\infty}\int_{-\pi}^\pi g(x)e^{\im tx}dx=0
\end{align}
In fact, we can prove this for every $g\in C(\Sbb^1)$. By Stone-Weierstrass, it suffices to prove this relation if $g:x\in[-\pi,\pi]\mapsto e^{\im nx}$ for some $n$. Then $\int_{-\pi}^\pi g(x)e^{\im tx}dx$ can be calculated using the fundamental theorem of calculus, and one easily checks that it converges to $0$ as $t\rightarrow\pm\infty$.
\end{proof}


\begin{co}
Let $1\leq p<+\infty$. Let $\mu$ be a Radon measure on $\Rbb$. Then $\Span_\Cbb\{\chi_{[x,y]}:-\infty<x\leq y<+\infty\}$ is a dense subspace of $L^p(\Rbb,\mu)$.
\end{co}

\begin{proof}
Choose any $f\in L^p(\Rbb,\mu)$. By Thm. \ref{lb866}, for each $\eps>0$ there exists $g\in C_c^\infty(\Rbb)$ such that $\Vert f-g\Vert_{L^p}\leq\eps$. Choose $-\infty<a<b<+\infty$ such that $\Supp g\subset[a,b]$. Then there exists a step function $h$ on $[a,b]$ such that $\Vert g-h\Vert_{l^\infty}\leq\eps(b-a)^{-\frac 1p}$, and hence $\Vert g-h\Vert_{L^p}\leq \eps$. Clearly $h$ belongs to $\Span_\Cbb\{\chi_{[x,y]}:-\infty<x\leq y<+\infty\}$, and $\Vert f-h\Vert_{L^p}\leq 2\eps$.
\end{proof}




\subsubsection{The separability of $L^p$ spaces}


The following theorem is a further application of Thm. \ref{lb866}.

\begin{thm}\label{lb872}
Let $X$ be a second countable LCH space. Let $(\fk M,\mu)$ be a Radon measure (or its completion) on $X$. Let $1\leq p<+\infty$. Then $L^p(X,\mu)$ is separable. 
\end{thm}

In the next section, we will see that $L^p(X,\mu)$ is complete. Therefore, if $X$ is second countable LCH, then the Hilbert space $L^2(X,\mu)$ has a countable orthonormal basis (Cor. \ref{lb616}) and hence is isomorphic to $l^2(\Zbb)$ or $l^2(\{1,\dots,n\})$ (Thm. \ref{lb873}).

\begin{proof}
Step 1. We consider the special case that $X$ is compact (and second countable). Then $\mu(X)<+\infty$. By Thm. \ref{lb866}, $C(X)$ is dense in $L^p(X,\mu)$. Therefore, it suffices to prove that $C(X)$ is separable under the $L^p$-seminorm, i.e., there is a countable subset $\mc E\subset C(X)$ such that for each $f\in C(X)$ there is a sequence $(f_n)$ in $\mc E$ satisfying $\lim_n \Vert f-f_n\Vert_p=0$. Since
\begin{align*}
\Vert f-f_n\Vert_p^p=\int_X |f-f_n|^pd\mu\leq\Vert f-f_n\Vert_{l^\infty}^p\cdot\mu(X)
\end{align*}
it suffices to find a countable $\mc E\subset C(X)$ which is $l^\infty$-dense in $C(X)$. But we have already proved this before: Thm. \ref{lb482} says that a compact Hausdorff space is second countable iff its space of continuous functions is ($l^\infty$-)separable.\\[-1ex]

Step 2. We consider the general case. Since $X$ is second countable, $X$ is Lindel\"of. Therefore, $X$ is a countable union of precompact open subsets. So $X$ is $\sigma$-compact, i.e., we have compact $K_1,K_2,\dots\subset X$ such that $X=\bigcup_n K_n$. By replacing $K_n$ with $K_1\cup\cdots\cup K_n$ we assume $K_1\subset K_2\subset\cdots\subset X$. 

The restriction $\mu_n:=\mu|_{\fk B_{K_n}}$ is a finite Borel measure on the second countable compact Hausdorff space $K_n$. Therefore, $\mu_n$ is a Radon measure on $K_n$ by Thm. \ref{lb818}. Thus, by Step 1, $L^p(K_n,\mu_n)$ has a countable dense subset $\mc E_n$. Note that we can view $L^p(K_n,\mu_n)$ as a subset of $L^p(X,\mu)$. So $\mc E=\bigcup_n \mc E_n$ is a countable subset of $L^p(X,\mu)$. 



Let us prove that $\mc E$ is dense in $L^p(X,\mu)$. Choose any $f\in L^p(X,\mu)$. By Prop. \ref{lb863}, we may assume that $f$ is Borel. So each $f\chi_{K_n}$ is Borel. The dominated convergence theorem implies that $\lim_n \Vert f-f\chi_{K_n}\Vert_p^p=0$. Since $\mc E_n$ is dense in $L^p(K_n,\mu_n)$, the Borel function $f|_{K_n}:K_n\rightarrow\Cbb$ can be $L^p$-approximated by elements of $\mc E_n$. So $f\chi_{K_n}:X\rightarrow\Cbb$ can be approximated by elements of $\mc E_n$. Thus $f$ can be approximated by elements of $\mc E$.
\end{proof}


\begin{comment}
\begin{rem}
In the above proof, we have used the criterion Thm. \ref{lb818} to show that $\mu$ restricts to a Radon measure on the second countable compact set $K_n$. Since Thm. \ref{lb818} is a deep result, one may wonder if Thm. \ref{lb872} can be proved without using Thm. \ref{lb818}. The answer is yes. We sketch such a proof below.

First, consider the special case that $\mu(X)<+\infty$. By Thm. \ref{lb866}, $C_c(X)$ is dense in $L^p(X,\mu)$. By Pb. \ref{lb484}, $C_c(X)$ is $l^\infty$-separable, and hence is $L^p$-separable (by the finiteness of $\mu(X)$). Therefore $L^p(X,\mu)$ is separable. Second, consider the general case. Since $X$ is second countable, we can write $X$ as a countable union $X=\bigcup_n U_n$ where $U_1\subset U_2\subset\cdots$ are open and precompact subsets of $X$. So $\mu(U_n)<+\infty$. The restriction $\mu_n=\mu|_{\fk B_{U_n}}$ is Radon. (This is easy to check by using the openness of $U_n$, and does not rely on the second countability. So Thm. \ref{lb818} is not needed here.) Therefore, $L^p(U_n,\mu_n)$ is separable. Similar to Step 2 of the proof of Thm. \ref{lb872}, one concludes that $L^p(X,\mu)$ is separable. \hfill\qedsymbol
\end{rem}

\end{comment}


\begin{rem}
The importance of Thm. \ref{lb872} has been discussed in Rem. \ref{lb569}: Let $(X,\mu)$ be a measure space. Assume that $L^p(X,\mu)$ is separable (where $1\leq p<+\infty$). Then, equivalently, the closed unit ball of the dual space $L^p(X,\mu)^*$ is weak-* metrizable by Thm. \ref{lb523}. A deep theorem originally due to Riesz (cf. Thm. \ref{lb899}) says that $L^p(X,\mu)^*$ is naturally isomorphic to $L^q(X,\mu)$ where $p^{-1}+q^{-1}=1$. (In the case that $p=1$, one should assume that $\mu$ is $\sigma$-finite.) Thus, when $L^p(X,\mu)$ is separable, we can use sequences (rather than nets) to study the weak-* topology and the weak-* compactness of norm-bounded subsets of $L^q(X,\mu)$. 
\end{rem}



\subsubsection{Approximation by simple functions}


Thm. \ref{lb866} can only be applied to (completions of) Radon measures. For a general measure space, we have the following approximation:

\begin{thm}\label{lb874}
Let $(X,\fk M,\mu)$ be a measure space. Let $1\leq p\leq+\infty$. Then 
\begin{align}\label{eq349}
L^p(X,\mu)\cap \mc S(X,\Cbb)
\end{align}
is a dense subset of $L^p(X,\mu)$.
\end{thm}

\begin{rem}
The set \eqref{eq349} has an explicit description: If $1\leq p<+\infty$, a function $f:X\rightarrow\Cbb$ belongs to \eqref{eq349} iff $f$ is equivalent to a finite sum $g=\sum_i a_i\chi_{E_i}$ where $a_i\in\Cbb$ and each $E_i\in\fk M$ has finite measure. The word ``equivalent" means that $f=g$ a.e.. If $p=+\infty$, then $f$ belongs to \eqref{eq349} iff $f$ is equivalent to an element of $\mc S(X,\Cbb)$.
\end{rem}




\begin{proof}[Proof of Thm. \ref{lb874}]
By approximating $\Real( f)$ and $\Imag(f)$ separately, we can assume that $f$ is real. By considering $f^+$ and $f^-$ separately, we assume $f\geq0$. By Prop. \ref{lb749}, there is an increasing sequence $(s_n)$ in $\mc S(X,\Rbb_{\geq0})$ converging pointwise to $f$. Therefore, when $p<+\infty$, we have $\lim_n \Vert f-s_n\Vert_p^p=0$ by the dominated convergence theorem (since $|f-s_n|^p\leq |f|^p$). If $p=+\infty$, by Prop. \ref{lb860}, we can replace $f$ with an equivalent function whose $l^\infty$-norm is finite. Then, by Rem. \ref{lb807}, we can assume that $(s_n)$ converges uniformly to $f$. This proves $\lim_n\Vert f-s_n\Vert_{L^\infty}=0$.
\end{proof}

In Pb. \ref{lb912} and \ref{lb910}, we will give applications of Thm. \ref{lb874} to the study of weak-* convergence in $L^p$ spaces.





\subsection{The Riesz-Fischer theorem}\label{mc89}


Let $(X,\fk M,\mu)$ be a measure space. 


%\hypertarget{current}{}

\subsubsection{From $L^p$-$L^q$ duality to completeness}\label{mc88}


In this section, we shall show that $L^p(X,\mu)$ is complete. This result was first proved by Riesz and Fischer for $L^2([a,b],m)$, and was later generalized by Riesz to $L^p([a,b],m)$ (where $1<p<+\infty$) in \cite{Rie10}. To motivate our proof of Thm. \ref{lb875}, we first discuss Riesz's approach in \cite{Rie10}. See also \cite[Sec. IV.4]{Ber65} for a relevant discussion.



A main goal of \cite{Rie10} was to study the moment problem in $L^p$ spaces. Therefore, the ideas of dual spaces and weak(-*) compactness (which are crucial to Riesz's treatment of moment problems, cf. Sec. \ref{lb543}) are important for us to understand Riesz's proof of the completeness of $L^p([a,b],m)$. Let us assume, as Riesz did, that $1<p<+\infty$. We shall first explain how Riesz proved $L^q([a,b],m)^*=L^p([a,b],m)$; the completeness of $L^p([a,b],m)$ then follows from the general fact that the dual of a normed vector space is complete (Thm. \ref{lb540}).



The main difficulty of proving $(L^q)^*\simeq L^p$ lies in proving that any bounded linear functional $\Lambda\in L^q([a,b],m)^*$ can be realized by some $f\in L^p([a,b],m)$. Motivated by the \hyperlink{SecondRiesz}{second proof} of the Riesz representation Thm. \ref{lb847} (cf. Subsec. \ref{lb923}), one may define $F(x)=\Lambda(\chi_{[a,x]})$, hoping that $\Lambda(g)=\int gdF$. Thus, the natural candidate for the function $f$ representing $\Lambda$ should be the (a.e.-)derivative $f=F'$ since, at least formally, we have $\Lambda(g)=\int gdF=\int gF'dm$. 

In fact, in \cite{Rie10}, by using the fundamental theorem of calculus for Lebesgue integrals (cf. \cite[Ch. 7]{Rud-R}), Riesz succeeded in showing that $f:=F'$ exists a.e., that $f\in L^p([a,b],m)$, and that  $dF=fdm$. (See also Pb. \ref{lb1034} and the subsequent Rem. \ref{lb1036} for a related discussion.) This finishes the proof. (This method can also be found in the English textbook \cite[Sec. 36]{RN}.)

The modern proof of $L^p\simeq (L^q)^*$ for an arbitrary measure space $(X,\fk M,\mu)$ follows basically the same ideas, except that $F'$ should be replaced by the Radon-Nikodym derivative:  Assume for simplicity that $\mu$ is a finite measure. Define $\nu:\fk M\rightarrow\Cbb$ by $\nu(E)=\Lambda(\chi_E)$. This is a (so called) \textbf{complex measure}, which plays the role of $F$ in Riesz's treatment. One then shows that $L^2(X,\mu)$ is complete, and hence that $L^2\simeq(L^2)^*$ (due to the Riesz-Fr\'echet representation Thm. \ref{lb898}). The duality $L^2\simeq(L^2)^*$ allows one to show that $d\nu=fd\mu$ for some measurable function $f:X\rightarrow\Cbb$ (called the \textbf{Radon-Nikodym derivative} \index{00@Radon-Nikodym derivative} of $\nu$ with respect to $\mu$, cf. Pb. \ref{lb1035}), and that $f\in L^p(X,\mu)$. Therefore, one has $\Lambda(g)=\int fgd\mu$ when $g\in L^q(X,\mu)$ is a characteristic function. By using the density property Thm. \ref{lb874}, one obtains $\Lambda(g)=\int fgd\mu$ for all $g\in L^q(X,\mu)$, concluding the proof of $L^p\simeq(L^q)^*$. See e.g. \cite[Ch. 6]{Rud-R} for details.%\footnote{Riesz's method relies on Lebesgue's differentiation theorem (cf. \cite[Ch. 7]{Rud-R}) but not on the completeness of $L^p$ spaces. However, the Radon-Nikodym theorem relies on the completeness of $L^2$.}


Once $L^p\simeq(L^q)^*$ has been proved, one can use the completeness of dual spaces to conclude that $L^p$ is complete.\footnote{The structure of Riesz's proof in \cite{Rie10} is as follows. He first derived the basic properties for $F(x)=\Lambda(\chi_{[a,x]})$ and $F'$. Then, he proved that $\ovl B_{L^p([a,b],m)}(0,1)$ is weakly compact and that $L^p([a,b],m)\simeq L^q([a,b],m)^*$. Both proofs used $F$. The completeness of $L^p([a,b],m)$ was derived as an immediate consequence of the weak compactness. From a modern perspective, Riesz's method can be viewed as first proving $L^p\simeq(L^q)^*$, then proving the weak compactness in a similar spirit as we proved the Banach-Alaoglu Thm. \ref{lb519}, and finally derived completeness from weak compactness.} In fact, combining the proof of $L^p\simeq(L^q)^*$ with the completeness of dual spaces, one can see\footnote{Indeed, viewing $(f_n)$ as a sequence in $(L^q)^*$, then it converges weak-* to $\Lambda\in (L^q)^*$ defined by $\Lambda(g)=\lim_n\int_a^b f_ngdm$. Then $\Lambda(g)=\int_a^b gF'dm$ where $F(x)=\Lambda(\chi_{[a,x]})=\lim_n\int_a^x f_ndm$. One then shows that $(f_n)$ converges in the operator norm of $(L^q)^*$ to $\Lambda$, cf. the proof of Thm. \ref{lb1025}. So $(f_n)$ converges in $L^p$ to $F'$.} that if $(f_n)$ is a Cauchy sequence in $L^p([a,b],m)$, then $(f_n)$ converges in $L^p$ to the a.e. derivative $F'\in L^p([a,b],m)$ of $F$, where
\begin{align}\label{eq575}
F(x)=\lim_{n\rightarrow\infty}\int_a^x f_ndm
\end{align}
and the RHS of \eqref{eq575} converges uniformly with respect to $x$. That is to say, \uwave{in the original proof of the completeness of $L^p$-spaces, the $L^p$-limit of the Cauchy sequence can be explicitly constructed.} In particular, given $(c_n)_{n\in\Zbb}\in l^2(\Zbb)$, the function $f\in L^2([-\pi,\pi],\frac{m}{2\pi})$ with Fourier series $(c_n)_{n\in\Zbb}$ is
\begin{subequations}\label{eq576}
\begin{align}
f\xlongequal{\text{a.e.}}F'
\end{align}
where $\dps F(x)=\sum_{n=-\infty}^\infty\int_{-\pi}^x c_ne^{\im nt}dm(t)$. WLOG, subtract $F$ by a constant. Then
\begin{align}
F(x)=c_0x+\sum_{n\in\Zbb\setminus\{0\}}(n\im)^{-1}c_n e^{\im nx}
\end{align}
\end{subequations}
The constructions \eqref{eq576} and \eqref{eq575} were used by Riesz and Fischer, respectively, in their original proof of the Riesz-Fischer theorem in 1907. See Rem. \ref{lb1024} for further discussion.


The modern proof of the completeness of $L^p$-spaces, which applies to arbitrary measures rather than just the Lebesgue measure, is more abstract in the sense that the construction of the $L^p$-limit of a given Cauchy sequence is not entirely explicit. To help us understand the modern proof, let us recall how we proved in Thm. \ref{lb540} that a dual space is complete. I shall redo the proof by using a Fatou-type argument that Riesz used in  \cite[\S 7]{Rie10}. This argument is very helpful for us to understand \hyperlink{RF Step 1}{Step 1} of the proof of the Riesz-Fischer Thm. \ref{lb875}.

\begin{thm}\label{lb1025}
Let $V$ be a normed vector space. Then $V^*$ is complete.
\end{thm}

\begin{proof}
Let $(\varphi_n)$ be a Cauchy sequence in $V^*$. As in the proof of Thm. \ref{lb540}, one easily sees that $(\varphi_n)$ converges pointwise to a linear functional $\varphi:V\rightarrow\Fbb$, and that $\Vert\varphi\Vert\leq\sup_n\Vert\varphi_n\Vert<+\infty$. Thus, $(\varphi_n)$ converges weak-* to an element $\varphi\in V^*$.

The following argument is crucial: Note that for each $n\in\Zbb_+$, $\lim_m(\varphi_n-\varphi_m)$ converges weak-* to $\varphi_n-\varphi$. Therefore, by \uwave{Fatou's lemma} for weak(-*) convergence (cf. Prop. \ref{lb770}), 
\begin{align}\label{eq455}
\Vert\varphi_n-\varphi\Vert\leq\liminf_m\Vert\varphi_n-\varphi_m\Vert
\end{align}
Since $(\varphi_n)$ is Cauchy, the RHS of \eqref{eq455} is small enough for sufficiently large $n$. Thus $\lim_n\Vert\varphi_n-\varphi\Vert=0$.
\end{proof}



The above argument reminds us of Step 2 of the proof of Thm. \ref{lb636}. In fact, that proof suggests an idea of proving the Riesz-Fischer Thm. \ref{lb875}: Assume for simplicity that $1<p<+\infty$. Let $(f_n)$ be a Cauchy sequence in $L^p(X,\mu)$. It suffices to prove that $(f_n)$ (viewed as a sequence in $L^q(X,\mu)^*$) has a subsequence converging weak-* to some $f\in L^p(X,\mu)$. Then Fatou's lemma implies that $(f_n)$ converges in norm to $f$.


In the following proof of Thm. \ref{lb875}, we will roughly follow this idea, except that we choose a subsequence of $(f_n)$ converging a.e. (rather than weak-*) to some $f\in L^p(X,\mu)$.  In fact, a.e. convergence shares many similarities with weak-* convergence, one of which is that they both satisfy Fatou's lemma. See Pb. \ref{lb912} for another important relationship between a.e. and weak-* convergence.

\subsubsection{The Riesz-Fischer theorem}



\begin{thm}[\textbf{Riesz-Fischer theorem}] \index{00@Riesz-Fischer theorem}\label{lb875}
Let $1\leq p<+\infty$. Then $L^p(X,\mu)$ is a Banach space. Moreover, if $(f_n)$ is a sequence in $L^p(X,\mu)$, $f$ is in $L^p(X,\mu)$, and $\lim_n\Vert f-f_n\Vert_p=0$, then $(f_n)$ has a subsequence converging a.e. to $f$.
\end{thm}

It follows that $L^2(X,\mu)$ is a Hilbert space under the inner product \eqref{eq348}.

\begin{proof}
\hypertarget{RF Step 1}{Step 1}. Let $(f_n)$ be a Cauchy sequence in $L^p(X,\mu)$. We claim that $(f_n)$ has a subsequence $(g_k)=(f_{n_k})$ converging pointwise outside a null set $\Delta$. 

Suppose the claim is true. Let $f:X\rightarrow\Cbb$ be defined by $f(x)=\lim_kg_k(x)$ if $x\in X\setminus\Delta$, and $f(x)=0$ if $x\in\Delta$. Then $f$ is measurable. Since $(g_k)$ is $L^p$-Cauchy, for each $\eps>0$ there exists $K\in\Zbb_+$ such that for each $k,l\geq K$ we have $\Vert g_k-g_l\Vert_p\leq\eps$. By Fatou's lemma (Thm. \ref{lb768}), we get
\begin{align*}
\int_X |g_k-f|^p\leq\liminf_l\int_X|g_k-g_l|^p\leq \eps^p
\end{align*}
for all $k\geq K$. In particular, $\Vert f\Vert_p\leq \Vert f-g_k\Vert_p+\Vert g_k\Vert_p<+\infty$. This proves that $f\in L^p(X,\mu)$ and that $(g_k)$ converges to $f$ in $L^p$. Therefore, $(f_n)$ converges in $L^p$ to $f$ since $(f_n)$ is $L^p$-Cauchy (cf. Thm. \ref{lb79}). This proves the completeness.



If $(f_n)$ converges in $L^p$ to $\wtd f\in L^p(X,\mu)$, then $f$ and $\wtd f$ are the same element in $L^p(X,\mu)$. So $\Vert f-\wtd f\Vert_p=0$, and hence $f=\wtd f$ a.e.. This proves that the subsequence $(g_k)$ converges to $\wtd f$ a.e.. This proves the second half of the theorem.\\[-1ex]

Step 2. Let us prove the claim. By Pb. \ref{lb566}-1, the Cauchy sequence $(f_n)$ has a subsequence $(g_k)_{k\in\Zbb_+}$ such that $\sum_{k=1}^\infty\Vert g_{k+1}-g_k\Vert_p<+\infty$. Set $h_k=|g_{k+1}-g_k|$. Then $\sum_k\Vert h_k\Vert_p<+\infty$. Suppose we can prove that $H:=\sum_k h_k$ is finite a.e.. Then $\sum_k (g_{k+1}-g_k)$ converges absolutely a.e., and hence converges a.e.. In other words, $\lim_k g_k$ converges a.e.. This proves the claim.

Let us prove that $H<+\infty$ a.e.. We first consider the special case that $\mu$ is $\sigma$-finite on $X$. Then $X$ is a countable union of measurable subsets $E_1,E_2,\dots$ with finite measures. It suffices to prove that $H|_{E_n}$ is finite a.e.. Let $g=\chi_{E_n}$. Then $\Vert g\Vert_q<+\infty$ where $p^{-1}+q^{-1}=1$. By the monotone convergence Thm. \ref{lb760} and H\"older's inequality,
\begin{align*}
\int_{E_n} H=\int_X Hg=\sum_k \int_X h_kg\leq\sum_k \Vert h_k\Vert_p\cdot\Vert g\Vert_q<+\infty
\end{align*}
Therefore, by Prop. \ref{lb752}, we have $H|_{E_n}<+\infty$ a.e..

In the general case, by Lem. \ref{mc87}, the set $Y=\bigcup_k \{x\in X:h_k(x)>0\}$ is $\sigma$-finite. The above special case implies that $H|_Y$ is finite a.e.. Since $H$ is zero outside $Y$, we get $H<+\infty$ a.e..
\end{proof}


\begin{lm}\label{mc87}
Let $f\in L^p(X,\mu)$ where $1\leq p<+\infty$. Then $\Omega_f:=\{x\in X:f(x)\neq 0\}$ is $\sigma$-finite.
\end{lm}
\begin{proof}
We have $\Omega_f=\bigcup_n E_n$ where $E_n=\{x\in X:|f(x)|\geq n^{-1}\}$. Then $n^{-p}\mu(E_n)=\int_{E_n} n^{-p}\leq\int_{E_n}|f|^p\leq \Vert f\Vert_p^p<+\infty$.
\end{proof}

The idea in Step 2 of the proof of the Riesz-Fischer Thm. \ref{lb875} can be used to prove a generalized Minkowski's inequality. See Pb. \ref{mc49}. 


\begin{comment}
The proof of the Riesz-Fischer Thm. \ref{lb875} gives a useful criterion for a.e. convergence.
\begin{co}
Let $1\leq p<+\infty$. Let $(f_n)$ be a sequence in $L^p(X,\mu)$ satisfying $\sum_n\Vert f_n\Vert_p<+\infty$. Then $\sum_n f_n$ converges both a.e. and in the $L^p$-norm to some $f\in L^p(X,\mu)$.
\end{co}

\begin{proof}
Step 2 of the proof of Thm. \ref{lb875} shows that $\sum_nf_n$ converges a.e. to some measurable function $f$. Step 1 shows that $f\in L^p(X,\mu)$, and that $\sum_nf_n$ converges in the $L^p$-norm to $f$.
\end{proof}
\end{comment}

\begin{rem}
The use of Fatou's lemma in the proof of Thm. \ref{lb875} is very typical: If $(f_n)$ is a sequence of measurable functions converging pointwise to $f$, one can use the $L^p$-norms of $(f_n)$ to give an upper bound for the $L^p$-norm of $f$.
\end{rem}


\begin{rem}
Thm. \ref{lb875} clearly also holds when $p=+\infty$. Indeed, we have proved in Thm. \ref{lb876} that $L^\infty(X,\mu)$ is complete. If $(f_n)$ is a sequence converging in $L^\infty(X,\mu)$ to $f\in L^\infty(X,\mu)$, then by Prop. \ref{lb877}, $(f_n)$ converges uniformly to $f$ outside a null set. In particular, $(f_n)$ converges a.e. to $f$. There is no need to choose a subsequence.
\end{rem}



\begin{co}[\textbf{Riesz-Fischer}]\label{lb879}
Let $e_n\in C(\Sbb^1)$ be defined by $e_n(x)=e^{\im nx}$. Then we have a unitary map
\begin{align}\label{eq350}
L^2\big([-\pi,\pi],\frac m{2\pi}\big)\xlongrightarrow{\simeq}l^2(\Zbb)\qquad f\mapsto \wht f
\end{align}
where $\wht f:\Zbb\rightarrow\Cbb$ is the Fourier series of $f$, i.e.,
\begin{align}
\wht f(n)=\frac 1{2\pi}\int_{[-\pi,\pi]}fe_{-n}dm
\end{align}
\end{co}

\begin{proof}
$L^2([-\pi,\pi],\frac m{2\pi})$ is a Hilbert space by Thm. \ref{lb875} and has an orthonormal basis $(e_n)_{n\in\Zbb}$ by Cor. \ref{lb878}. Therefore, by Thm. \ref{lb873}, \eqref{eq350} defines a unitary map.
\end{proof}




\begin{rem}\label{lb1024}
Cor. \ref{lb879} is in fact the original theorem proved by Riesz and by Fischer in 1907. At that time, it was already known that $(e_n)$ is an orthonormal basis of $L^2[-\pi,\pi]$. (This was proved by Fatou in 1906, and Fatou's lemma was proved in the same paper as an auxiliary result. See \cite[Ch. 6]{Haw}. \footnote{Fatou's idea was to first show that if $f\in L^2[-\pi,\pi]$, then $\lim_{r\rightarrow 1^-}\sum_n r^{|n|}\wht f(n)e_n$ converges a.e. to $f$. (A proof of this result can be found in \cite[Ch. 4 Sec. 3]{SS-R}.) Then Fatou's lemma can be applied to show that $\Vert f\Vert_2^2\leq\sum_n |\wht f(n)|^2$. This, together with Bessel's inequality, implies Parseval's identity. The latter is equivalent to that $\{e_n\}$ is an orthonormal basis.}) Therefore, to show that the map \eqref{eq350} is unitary, it remains to prove one the following (clearly) equivalent conditions:
\begin{enumerate}
\item[(1)] If $\varphi\in l^2(\Zbb)$, then there exists $f\in L^2[-\pi,\pi]$ such that $\frac 1{2\pi}\int fe_{-n}=\varphi(n)$ for all $n$. 
\item[(2)] If $(f_n)$ is a sequence in $L^2[-\pi,\pi]$ such that $\lim_{m,n\rightarrow\infty}\int|f_m-f_n|^2=0$, then there exists $f\in L^2[-\pi,\pi]$ such that $\lim_n|f-f_n|^2=0$.
\end{enumerate}
Note that (1) simply says that the map \eqref{eq350} is surjective, and (2) simply says that $L^2[-\pi,\pi]$ is complete. Riesz proved (1) by using the construction \eqref{eq575}. Fischer proved (2) by using \eqref{eq576}. (It is noteworthy that the vague idea of completeness in $L^2$ spaces already appeared in Fischer's treatment.) See \cite[Sec. IV.3]{Ber65}  and \cite[Ch. 6]{Haw} for a detailed account of the relevant history.
%It is noteworthy that Fischer's formulation of the theorem in the form of (2) indicates that (in 1907) Fischer already had the vague idea of understanding $L^2$-spaces in terms of completeness. However, the real power of completeness in function spaces had to wait until Riesz's 1913 study of the spectral theory of bounded self-adjoint operators in Hilbert spaces, and his 1918 study of compact operators.  \hfill\qedsymbol
\end{rem}


\subsection{Introduction to dualities in $L^p$ spaces}


Let $(X,\fk M,\mu)$ be a measure space.


\begin{pp}\label{lb897}
\begin{subequations}
Let $1\leq p,q\leq +\infty$ and $p^{-1}+q^{-1}=1$. Assume that $\mu$ is $\sigma$-finite if $p=+\infty,q=1$. Then there is a linear isometry
\begin{align}
\Psi:L^p(X,\mu)\rightarrow L^q(X,\mu)^*\qquad f\mapsto\Psi(f)
\end{align}
such that for each $g\in L^q(X,\mu)$, we have
\begin{align}
\bk{\Psi(f),g}=\int_X fgd\mu
\end{align}
\end{subequations}
where $fg$ is integrable by H\"older's inequality. 
\end{pp}


\begin{proof}
Let $f\in L^p(X,\mu)$. H\"older's inequality shows that $|\bk{\Psi(f),g}|\leq\Vert f\Vert_p\cdot\Vert g\Vert_q$. Therefore $\Psi(f)$ is bounded and has operator norm $\Vert \Psi(f)\Vert\leq \Vert f\Vert_p$. In particular, if $f=0$ in $L^p(X,\mu)$, then $\Psi(f)=0$. Thus, we may assume that $\Vert f\Vert_p>0$, and we shall prove that $\Vert \Psi(f)\Vert=\Vert f\Vert_p$. 

Case 1: $1<p<+\infty$. Similar to the proof of Thm. \ref{lb369}, we let $g:X\rightarrow\Cbb$ be $g=\frac{\ovl f}{|f|}\cdot |f|^{p-1}$ on
\begin{align*}
\Omega_f=\{x\in X:f(x)\neq 0\}
\end{align*}
and let $g=0$ on $\Omega_f^c$. Then $g$ is measurable, and one checks that $\Vert g\Vert_q^q=\int |f|^{pq-q}=\int |f|^p=\Vert f\Vert_p^p$. So $g\in L^q(X,\mu)$. Moreover, 
\begin{align*}
\bk{\Psi(f),g}=\int |f|^p=\Vert f\Vert_p^p=\Vert f\Vert_p\cdot\Vert f\Vert_p^{p-1}=\Vert f\Vert_p\cdot\Vert g\Vert_q
\end{align*}
Since $\Vert g\Vert_q>0$, we must have $\Vert\Psi(f)\Vert\geq\Vert f\Vert_p$.

Case 2: $p=1,q=+\infty$. Let $g:X\rightarrow\Cbb$ be defined by $g=\frac{\ovl f}{|f|}$ on $\Omega_f$ (which is not null since $\int|f|>0$), and $g=0$ on $\Omega_f^c$. So $\Vert g\Vert_\infty=1$. And $\bk{\Psi(f),g}=\int|f|=\Vert f\Vert_1=\Vert f\Vert_1\cdot\Vert g\Vert_\infty$. So again $\Vert\Psi(f)\Vert\geq\Vert f\Vert_p$.

Case 3: $p=+\infty,q=1$, and $\mu$ is $\sigma$-finite. We know $0<\Vert f\Vert_\infty<+\infty$, and we want to prove $\Vert\Psi(f)\Vert\geq\Vert f\Vert_\infty$. Let us prove that if $0<a<\Vert f\Vert_\infty$ then $\Vert\Psi(f)\Vert\geq a$. The reason for considering such $a$ is that by the definition of $\Vert f\Vert_\infty$, the set
\begin{align*}
A=\{x\in X:|f(x)|>a\}
\end{align*}
is not null. Let us first consider the special case that $\mu(A)<+\infty$. \footnote{When proving a result about $\sigma$-finite measures, it is always a good idea to first prove it for finite measures.} Let $g$ be $\ovl f/|f|$ on $A$, and $g=0$ on $A^c$. Then $\Vert g\Vert_1=\mu(A)<+\infty$ and hence $g$ is a nonzero element of $L^1(X,\mu)$. Moreover, $\bk{\Psi(f),g}=\int_A|f|\geq a\mu(A)=a\Vert g\Vert_1$. This proves $\Vert\Psi(f)\Vert\geq a$.

Now we consider the case $\mu(A)=+\infty$. Since $\mu$ is $\sigma$-finite, $A$ is a countable union of finite-measure subsets. So there exists a measurable $B\subset A$ such that $0<\mu(B)<+\infty$. Let $g=\ovl f/|f|$ on $B$ and $g=0$ on $B^c$. Then the same argument as above proves $\Vert\Psi(f)\Vert\geq a$.
\end{proof}

%% Record #14 2024/04/15 two lectures  34

\begin{eg}
Let $\fk M=2^X$ and $\mu:\fk M\rightarrow\ovl\Rbb_{\geq0}$ be $\mu(\emptyset)=0$ and $\mu(E)=+\infty$ if $E\subset X$ is nonempty. Then $L^\infty(X,\mu)$ is nontrivial, but $L^1(X,\mu)=0$. So the canonical map $\Psi:L^\infty(X,\mu)\rightarrow L^1(X,\mu)^*$ is not an isometry.
\end{eg}

\begin{co}
Let $1\leq p,q\leq +\infty$ and $p^{-1}+q^{-1}=1$. Assume that $\mu$ is $\sigma$-finite if $p=+\infty,q=1$. Let $f\in L^p(X,\mu)$. Then $f=0$ a.e. iff $\int_Xfgd\mu=0$ for all $g\in L^q(X,\mu)$.
\end{co}

\begin{proof}
Let $\Psi$ be the linear isometry in Prop. \ref{lb897}. Then $f=0$ a.e. iff $\Vert f\Vert_p=0$ iff $\Psi(f)=0$.
\end{proof}



\begin{thm}[\textbf{Riesz representation theorem for $L^p$ spaces}] \label{lb899}
Assume that $1<p\leq +\infty$ and $p^{-1}+q^{-1}=1$. (So $1\leq q<+\infty$.) Moreover, assume that if $p=+\infty$ then $\mu$ is $\sigma$-finite. Then the canonical linear isometry $\Psi:L^p(X,\mu)\rightarrow L^q(X,\mu)^*$ in Prop. \ref{lb897} is surjective, and hence is an isomorphism of Banach spaces.
\end{thm}

\begin{proof}
When $p=q=2$, by Riesz-Fischer, $L^2(X,\mu)$ is a Hilbert space. Therefore, the theorem follows from the Riesz-Fr\'echet representation Thm. \ref{lb898}. If $p\neq 2$, the proof is more difficult and will not be given in the notes. See \cite[Sec. 6.2]{Fol-R} or \cite[Ch. 6]{Rud-R} for a proof. \footnote{In \cite{Rud-R}, Rudin assumed that $\mu$ is $\sigma$-finite for all $p$.}
\end{proof}

Although we will not prove Thm. \ref{lb899} for $p\neq 2$, we can make the following definition:
\begin{df}\label{lb900}
Let $1<p\leq +\infty$ and $1\leq q<+\infty$ satisfy $p^{-1}+q^{-1}=1$. Assume that if $p=+\infty$ then $\mu$ is $\sigma$-finite. If $(f_\alpha)$ is a net in $L^p(X,\mu)$ and $f\in L^p(X,\mu)$, we say that $(f_\alpha)$ \textbf{converges weak-*} \index{00@Weak-* convergence in $L^p$ spaces} to $f$ if $\dps\lim_\alpha\int_X f_\alpha g d\mu=\int_Xf gd\mu$ for all $g\in L^q(X,\mu)$. 
\end{df}

In other words, the \textbf{weak-* topology on} \pmb{$L^p(X,\mu)$} is the pullback of the weak-* topology on $L^q(X,\mu)^*$ via the bijection $\Psi:L^p(X,\mu)\rightarrow L^q(X,\mu)^*$ in Thm. \ref{lb899}.









%% Record #15 2024/04/18 three lectures  37











\subsection{Problems and supplementary material}

We assume Riesz's representation Thm. \ref{lb899} for $L^p$ spaces, although its full proof is not given in the notes.

\begin{prob}\label{lb951}
Let $1\leq p\leq+\infty$ and $(X,\fk M,\mu)$ is a $\sigma$-finite measure space. Let $p^{-1}+q^{-1}=1$. Let $f:X\rightarrow\Cbb$ be measurable. Prove that $f\in \mc L^p(X,\mu)$ iff $\dps\sup_{g\in\ovl B_{\mc L^q(X,\mu)}(0,1)}\int_X |fg|d\mu<+\infty$.
\end{prob}

\begin{proof}[Hint]
To prove ``$\Leftarrow$", choose an increasing sequence $(E_n)$ of measurable sets whose union is $X$ such that $\mu(E_n)<+\infty$ and $\Vert f\chi_{E_n}\Vert_{l^\infty}<+\infty$ for all $n$. Prove $\sup_n\Vert f\chi_{E_n}\Vert_p<+\infty$.
\end{proof}

\begin{comment}
\begin{prob}\label{lb950}
Let $(X,\mu)$ be a $\sigma$-finite measure space, let $1\leq p<+\infty$, and let $\{f_1,f_2,\dots\}$ be a densely-spanning countable subset of $L^p(X,\mu)$. Prove that $Z=\{x\in X:f_n(x)=0\text{ for all $n$}\}$ is a null set.
\end{prob}

\begin{df}\label{lb947}
Let $1\leq p<+\infty$. Let $(X,\fk M,\mu)$ be a measure space. Let $\mc V$ be a separable Banach space over $\Cbb$. For each measurable $f:X\rightarrow\mc V$, define
\begin{align*}
\Vert f\Vert_{L^p}\equiv\Vert f\Vert_p:=\big\Vert |f|\big\Vert_p=\Big(\int_X|f|^pd\mu\Big)^{\frac 1p}
\end{align*}
Let
\begin{gather*}
\mc L^p(X,\mu,\mc V)=\{f\in\mc L(X,\mc V):\Vert f\Vert_p<+\infty\}\\
L^p(X,\mu,\mc V)=\mc L^p(X,\mu,\mc V)/\{f\in\mc L^p(X,\mu,\mc V):f=0\text{ a.e.}\}
\end{gather*}
\end{df}

\begin{sexe}
Prove that $\Vert \cdot\Vert_p$ is a seminorm on $\mc L^p(X,\mu,\mc V)$, and is a norm on $L^p(X,\mu,\mc V)$. Prove that $\mc L^p(X,\mu,\mc V)$ is a Banach space by mimicking the proof of the Riesz-Fischer Thm. \ref{lb875}. Prove that
\begin{align}
\Big\{\sum_{i=1}^n v_i\chi_{E_i}:v_i\in\mc V,E_i\in\fk M,\mu(E_i)<+\infty \Big\}
\end{align}
is dense in $L^p(X,\mu,\mc V)$ by mimicking the proof of Pb. \ref{lb948}-3.
\end{sexe}
\end{comment}

















\subsubsection{The weak-* topology of $L^p$ spaces}\label{lb911}

Let $(X,\fk M,\mu)$ be a measure space.  Let $1\leq p,q\leq+\infty$ and $p^{-1}+q^{-1}=1$.

\begin{exe}
Let $(f_n)$ be a sequence in $L^p(X,\mu)$. Assume that $(f_n)$ converges a.e. to $f:X\rightarrow\Cbb$. Assume that there exists $g\in L^p(X,\mu)$ such that $\lim_n\Vert f_n-g\Vert_p=0$. Prove that $f=g$ a.e. using the Riesz-Fischer Thm. \ref{lb875}.
\end{exe}


Assume that $p>1$. Assume that $\mu$ is $\sigma$-finite if $p=+\infty,q=1$.Then we have a canonical isomorphism of Banach spaces $L^p(X,\mu)\simeq L^q(X,\mu)^*$ (cf. Thm. \ref{lb899}). By Prop. \ref{lb770}, the norm function $\Vert\cdot\Vert_p$ is lower weak-* semicontinuous on $L^p(X,\mu)$. Namely, if $(f_\alpha)$ is a net in $L^p(X,\mu)$ converging weak-* to $f\in L^p(X,\mu)$, then $\lim_\alpha\int_X|f_\alpha|^pd\mu\geq\int_X |f|^pd\mu$. A comparison of this inequality with Fatou's lemma (Thm. \ref{lb768}) suggests that there is a close relationship between pointwise convergence and weak-* convergence. We now study this relationship. 

The following Pb. \ref{lb912} is close in spirit to Pb. \ref{lb848}. According to \cite[Ch.6, p.175]{Haw}, when $p=2$, part 2 of Pb. \ref{lb912} was given by Riesz in 1907 in the same papers that he proved the Riesz-Fischer Cor. \ref{lb879}.


\begin{prob}\label{lb912}
Assume that $p>1$, and $\mu$ is $\sigma$-finite if $p=+\infty,q=1$. Let $(f_n)$ be a bounded sequence in $L^p(X,\mu)$. (``Bounded" means $\sup_n\Vert f_n\Vert_p<+\infty$.) Let $f:X\rightarrow\Cbb$ be measurable.
\begin{enumerate}
\item Assume $f\in L^p(X,\mu)$. Prove that $(f_n)$ converges weak-* to $f$ iff for each $A\in\fk M$ satisfying $\mu(A)<+\infty$ we have
\begin{align}\label{eq355}
\lim_{n\rightarrow\infty}\int_A f_nd\mu=\int_Afd\mu
\end{align}
\item Assume that $(f_n)$ converges a.e. to $f$. Prove that $f\in L^p(X,\mu)$. Use part 1 to prove that $(f_n)$ converges weak-* to $f$.
\item Let $m$ be the Lebesgue measure. Construct a sequence $(f_n)$ in $L^1([0,1],m)$ satisfying that $\sup_n\Vert f_n\Vert\leq 1$, that $(f_n)$ converges pointwise to $0$, and that $(f_n)$ does not converge weakly to $0$ (i.e., it is not true that $\lim_n \int f_ngdm=0$ for all $g\in L^\infty([0,1],m)$). 
\item Construct a sequence $(g_n)$ in $L^2([0,1],m)$ such that $\sup_n\Vert g_n\Vert<+\infty$, that $(g_n)$ converges weakly to $0$, and that $(g_n)$ does not converge a.e. to $0$.
\end{enumerate}
\end{prob}

\begin{proof}[Hint]
1. Use the density of simple functions in $L^q(X,\mu)$ (Thm. \ref{lb874}).

2. Case $1<p<+\infty$: Use Fatou's lemma to prove $f\in L^p(X,\mu)$.

Proof of \eqref{eq355}: Method 1: Use convergence in measure (cf. Pb. \ref{lb757}, or use Egorov's Thm. \ref{lb965}) and H\"older's inequality. Method 2: Use Pb. \ref{lb1030}.
\end{proof}



Now we assume that $\mu$ is a Radon measure (or its completion) on an LCH space $X$. By Thm. \ref{lb866}, we know that if $1\leq p<+\infty$, then $C_c(X)$ is $L^p$-dense in $L^\infty(X,\mu)$. This is not true when $p=+\infty$. However, we shall show that $C_c(X)$ is weak-* dense in $L^\infty(X,\mu)$. To prove this result, we need some preparation.


\begin{df}
Let $V$ be a vector space over $\Fbb\in\{\Rbb,\Cbb\}$. Let $\fk S$ be a set of linear functional $V\rightarrow\Fbb$ separating points of $V$ (i.e., if $v\in V$ satisfies $\bk{v,\varphi}=0$ for all $\varphi\in \fk S$ then $v=0$). Then $V$ can be viewed as a subset of $\Fbb^{\fk S}$. The \pmb{$\sigma(V,\fk S)$}\textbf{-topology} \index{00@$\sigma(V,\fk S)$-topology} on $V$ is defined to be the subspace topology inherited from the product topology of $\Fbb^{\fk S}$. Therefore, if $(v_\alpha)$ is a net in $V$ and $v\in V$, then $(v_\alpha)$ converges under $\sigma(V,\fk S)$ to $v$ iff
\begin{align}
\lim_\alpha\bk{v_\alpha,\varphi}=\bk{v,\varphi}\qquad(\forall \varphi\in\fk S)
\end{align}
Moreover, by the definition of product topology in terms of basis (cf. Def. \ref{lb454}), we know that the sets
\begin{align}\label{eq356}
V_{v_0,A,\eps}=\{v\in V:|\bk{v-v_0,\varphi}|<\eps\text{ for all }\varphi\in A\}
\end{align}
(where $v_0\in V$, $A\in\fin (2^{\fk S})$, and $\eps\in\Rbb_{>0}$) form a basis for the $\sigma(V,\fk S)$-topology.
\end{df}

\begin{eg}
Let $V$ be a normed vector space. Then the $\sigma(V,V^*)$-topology is the weak topology on $V$. The $\sigma(V^*,V)$-topology is the weak-* topology on $V^*$. 
\end{eg}

\begin{sprob}
Let $V$ be a normed vector space. Let $E\subset V$ and $\fk S\subset V^*$. Suppose that $\fk S$ is bounded (i.e. $\sup_{\varphi\in\fk S}\Vert\varphi\Vert<+\infty$), and $\Span E$ is norm-dense in $V$. Prove that $E$ separates points of $V^*$. Prove that the $\sigma(V^*,V)$-topology and the $\sigma(V^*,E)$-topology are equal when restricted to $\fk S$. 
\end{sprob}

\begin{proof}[Note]
The content of this problem is not very new; compare it with Prop. \ref{lb520} (setting $W=\Fbb$). Note that Thm. \ref{lb530} is a special case of this problem.
\end{proof}


\begin{sprob}\label{lb910}
Let $\mu$ be a $\sigma$-finite Radon measure (or its completion) on an LCH space $X$. 
\begin{enumerate}
\item Let $\fk S_0\subset\fk S\subset L^\infty(X,\mu)$. Assume that $\fk S$ is $L^\infty$-bounded. Prove that $\fk S_0$ is weak-* dense in $\fk S$ iff for any $f\in\fk S$, any finitely many Borel subsets $A_1,\dots,A_n\subset X$ with finite measures, and every $\eps>0$, there exists $g\in\fk S_0$ such that $|\int_{A_i}f-\int_{A_i}g|<\eps$ for all $1\leq i\leq n$.
\item Prove that $\ovl B_{C_c(X)}(0,1)$ is weak-* dense in $\ovl B_{L^\infty(X,\mu)}(0,1)$. Conclude that, in particular, $C_c(X)$ is weak-* dense in $L^\infty(X,\mu)$.
\item Assume that $X$ is second countable. Prove that for each $f\in L^\infty(X,\mu)$ there exists a sequence $(f_n)$ in $C_c(X)$ such that $\sup_n\Vert f_n\Vert_{l^\infty(X)}\leq\Vert f\Vert_{L^\infty}$ and that $(f_n)$ converges weak-* in $L^\infty(X,\mu)$ to $f$.
\end{enumerate}
\end{sprob}


\begin{proof}[Hint]
1. Use the basis \eqref{eq356} and the density of simple functions (Thm. \ref{lb874}).

2. Use part 1, Lusin's theorem, and the Tietze extension Thm. \ref{lb468}.

3. $L^1(X,\mu)$ is separable (Thm. \ref{lb872}). Therefore, the weak-* topology on $\ovl B_{L^\infty(X,\mu)}(0,1)$ is (compact and) metrizable, cf. Thm. \ref{lb523}. 
\end{proof}

\begin{rem}\label{mc54}
The weak-* density of $C_c(X)$ in $L^\infty(X,\mu)$ does not directly imply the weak-* density of $\ovl B_{C_c(X)}(0,1)$ in $\ovl B_{L^\infty(X,\mu)}(0,1)$. That's why we need to first treat $\ovl B_{C_c(X)}(0,1)$ in Pb. \ref{lb910}-2. However, the situation becomes much better if one considers norm-density: Suppose that $\mc V$ is a normed vector space with a (norm-)dense linear subspace $\mc U$, then $\ovl B_{\mc U}(0,1)$ is dense in $\ovl B_{\mc V}(0,1)$. Indeed, if $(u_n)$ is a sequence in $\mc U$ converging to $v\in\ovl B_{\mc U}(0,1)$, then the sequence $(v_n)$ in $\ovl B_{\mc U}(0,1)$ converges to $v$ where $v_n=\frac{\Vert v\Vert}{\Vert u_n\Vert}\cdot u_n$.
\end{rem}


\begin{sexe}
In part 3 of Pb. \ref{lb910}, give a more explicit construction of $(f_n)$ without citing the big Thm. \ref{lb523}, and without first proving part 2.

 More precisely: Choose a sequence of Borel sets $A_1,A_2,\dots\subset X$ with finite measures such that $\chi_{A_1},\chi_{A_2},\dots$ span a dense subspace of $L^1(X,\mu)$. (Why can we do so?) For each $n$, find $f_n$ such that $|\int_{A_i}f-\int_{A_i}f_n|$ is small for all $1\leq i\leq n$. Show that $(f_n)$ converges weak-* to $f$.

If $X$ is $[a,b]$, $\Rbb$, or $\Rbb^N$, can you give a more explicit choice of $A_1,A_2,\dots$ ?  \hfill\qedsymbol
\end{sexe}













\subsubsection{$\star$ $L^p$ spaces and Fubini-Tonelli}

Let $1\leq p<+\infty$. Let $X,Y$ be LCH spaces. Let $\mu,\nu$ be the completions of $\sigma$-finite Radon measures on $X,Y$ respectively. Let $\mu\times\nu$ be the Radon product (cf. Def. \ref{lb827}). 

\begin{prob}\label{lb939}
Let
\begin{align*}
\scr A=\Span_\Cbb\{fg:f\in\mc L^p(X,\mu),g\in\mc L^p(Y,\mu)\}
\end{align*}
Prove that $\scr A\subset \mc L^p(X\times Y,\mu\times\nu)$, and that $\scr A$ is a dense linear subspace of $L^p(X\times Y,\mu\times\nu)$.
\end{prob}

\begin{proof}[Note]
It is a non-trivial fact that a measurable function on $X$ can be viewed as a measurable function on $X\times Y$. This fact relies on the fact that the projection $X\times Y\rightarrow X$ is measurable, cf. Exp. \ref{lb839}.
\end{proof}

\begin{proof}[Hint]
Use (e.g.) Stone-Weierstrass to show that $\Span\{fg:f\in C_c(X),g\in C_c(Y)\}$ is $l^\infty$-dense in $C_c(X\times Y)$. 
\end{proof}



\begin{comment}


\begin{exe}
Can you prove Pb. \ref{lb939} without assuming that $\mu$ and $\nu$ are $\sigma$-finite? Hint: Let $f\in\mc L^p(X,\mu)$ and $g\in\mc L^p(Y,\mu)$. Then $\Omega_f=\{x\in X:f(x)\neq 0 \}$ and $\Gamma_g=\{y\in Y:g(y)\neq 0\}$ must be $\sigma$-finite. (Why?) So they are contained in $\sigma$-finite open subsets of $X,Y$ respectively. Use this fact to prove $fg\in\mc L^p(X\times Y,\mu\times\nu)$.
\end{exe}



\end{comment}





The following problem aims to interpret Minkowski's integral inequality from the perspective of vector-valued integrals/Bochner integrals. To begin with, note that for each measurable $f:X\times Y\rightarrow\Cbb$, 
by Tonelli's Thm. \ref{lb832}, the function
\begin{align}
x\in X\qquad\mapsto \qquad \Vert f(x,\cdot)\Vert_{L^p(Y)}= \Big(\int_Y |f(x,y)|^pd\nu(y)\Big)^{\frac 1p}\in\ovl\Rbb_{\geq0}
\end{align}
can be defined for almost every $x$. Extend this function to the whole domain $X$, which is measurable by Tonelli's Thm. \ref{lb832}.

\begin{prob}\label{mc49}
Let $q$ satisfy $p^{-1}+q^{-1}=1$. Assume that $f:X\times Y\rightarrow\Cbb$ is measurable, and 
\begin{align}
\int_X \Vert f(x,\cdot)\Vert_{L^p(Y)}d\mu(x)<+\infty
\end{align}
In particular, by Prop. \ref{lb752}, $\Vert f(x,\cdot)\Vert_{L^p(Y)}<+\infty$ for almost every $x$. Replacing $f$ by $\chi_{A\times Y}$ where $A\subset X$ is a measurable set with null complement, we assume that $\Vert f(x,\cdot)\Vert_{L^p(Y)}<+\infty$ for every $x$.
\begin{enumerate}
\item Prove that for a.e. $y\in Y$, the function $f(\cdot,y):x\in X\mapsto f(x,y)$ is $\mu$-integrable. Prove that the function $\int_X fd\mu$ (sending $y\in Y$ to $\int_X f(\cdot,y)d\mu$) is $\nu$-measurable, and is in $L^p(Y,\nu)$. 

\item Let $\varphi:X\rightarrow L^p(Y,\nu)$ such that for each $x\in X$,  $\varphi(x)$ and $f(x,\cdot)$ are the same element in $L^p(Y)$. Prove that $\varphi$ is weakly integrable  and its integral $\int_X\varphi d\mu$ equals $\int_X fd\mu$, cf. Def. \ref{lb773}. In other words, prove for each $g\in L^q(Y,\nu)$ that
\begin{align}\label{eq376}
\int_X \bk{\varphi(x),g}=\Bigbk{\int_X fd\mu,g}
\end{align} 
\item By Pb. \ref{lb772}, we have $\Vert\int_X\varphi d\mu\Vert\leq\int_X \Vert\varphi(x)\Vert d\mu(x)$. Use this fact to conclude \textbf{Minkowski's integral inequality} \index{00@Minkowski's integral inequality}
\begin{align}
\bigg(\int_Y\bigg|\int_X f(x,y)d\mu(x) \bigg|^pd\nu(y)\bigg)^{\frac 1p}\leq \int_X \bigg(\int_Y \big|f(x,y)\big|^pd\nu(y)\bigg)^{\frac 1p}  d\mu(x)
\end{align}
\item Assume that $Y$ is second countable. Prove that $\varphi$ is Bochner integrable (cf. Pb. \ref{lb949}). 
\end{enumerate}
\end{prob}

\begin{proof}[Hint]
Part 1. For each $g\in L^q(Y,\nu)$, apply Fubini's theorem to $f(x,y)g(y)$ to show that $f(\cdot,y)g(y)$ is $\mu$-integrable for a.e. $y\in Y$, and $y\in Y\mapsto \int_X f(\cdot,y)g(y)d\mu$ is $\nu$-integrable. By choosing $g$ to be suitable characteristic functions, show that $f(\cdot,y)$ is $\mu$-integrable for a.e. $y\in Y$, and $\int_Xfd\mu$ is $\nu$-measurable. (Compare this method with Step 2 of the proof of the Riesz-Fischer Thm. \ref{lb875}.) The same conclusions hold for $|f|$. Prove $\sup\int_Y|\int_Xf(x,y)d\mu(x) |\cdot|g(y)|d\nu(y)<+\infty$ where the $\sup$ is over all $g\in \ovl B_{L^q(Y,\nu)}(0,1)$. Conclude from Pb. \ref{lb951} that $\int_Xfd\mu$ belongs to $L^p(Y,\nu)$. 


Part 2. Use Fubini's theorem.

Part 4. By Thm. \ref{lb872}, $L^p(Y,\nu)$ is separable. So $\varphi$ is measurable iff $\varphi$ is weakly measurable (cf. Pb. \ref{lb702}). 
\end{proof}






\begin{comment}
\begin{prob}
Solve the problems:
\begin{enumerate}
\item Let $f\in \mc L^p(X\times Y,\mu\times\nu)$. Prove that $\Vert f\Vert_{L^p(Y)}$ is finite for almost every $x\in X$. Prove that $\Vert f\Vert_{L^p(X\times Y)}$ equals the $L^p(X)$-seminorm of the function $\Vert f\Vert_{L^p(Y)}$ (from $X$ to $\Rbb_{\geq0}$). Prove that if $\Vert f\Vert_{L^p(X\times Y)}=0$, then $\Vert f\Vert_{L^p(Y)}$ is zero for almost every $x\in X$. 
\item Assume that $Y$ is second-countable so that (by Thm. \ref{lb872}) the Banach space $L^p(Y,\nu)$ is separable. Use part 1 to prove that there is an isomorphism of normed vector spaces (i.e., a surjective linear isometry)
\begin{align*}
\Phi:L^p(X\times Y,\mu\times\nu)\xrightarrow{\simeq} L^p(X,\mu,L^p(Y,\nu))
\end{align*}
(where the RHS is defined by Def. \ref{lb947}) such that for every $f\in L^p(X\times Y,\mu\times\nu)$, there exists a null set $\Delta_f\subset X$ such that for each $x\in X\setminus\Delta_f$, the elements $\Phi(f)(x)$ and $f(x,\cdot)$ are identical in $L^p(Y,\nu)$.
\end{enumerate}

\end{prob}

\end{comment}







\subsubsection{Essential ranges and spectra}

Let $(X,\fk M,\mu)$ be a measure space.  

\begin{df}\label{mc31}
Let $Y$ be a measurable space. Let $\varphi:X\rightarrow Y$ be measurable. The \textbf{pushforward measure} \index{00@Pushforward measure} \index{zz@$\varphi_*\mu$, the pushforward measure of $\mu$ under $\varphi$} $\varphi_*\mu:\fk N\rightarrow[0,+\infty]$ is defined by
\begin{align}
(\varphi_*\mu)(E)=\mu(\varphi^{-1}(E))\qquad(\forall E\in\fk N)
\end{align}
Then we have
\begin{align}\label{eq422}
\int_Y fd\varphi_*\mu=\int_X(f\circ\varphi) d\mu
\end{align}
for all $f=\chi_E$ where $E\in\fk N$, and hence for all $f\in\mc L_+(Y)$ by the monotone convergence theorem. 
\end{df}

\begin{rem}
If the $\sigma$-algebra of a set $Y$ is not assigned and $\varphi:X\rightarrow Y$ is an arbitrary map, we let $\varphi_*\mu$ be defined on the \textbf{pushforward $\sigma$-algebra} \index{00@Pushforward $\sigma$-algebra} \index{zz@$\varphi_*\fk M$, the pushforward $\sigma$-algebra}
\begin{align}
\varphi_*\fk M=\{E\in 2^Y:\varphi^{-1}(E)\in\fk M\}
\end{align}
\end{rem}


\begin{eg}
The Lebesgue measure on $\Sbb^1$ (together with its $\sigma$-algebra) is the pushforward of the Lebesgue measure on $[\theta-\pi,\theta+\pi)$. 
\end{eg}




Recall Pb. \ref{lb867} for the meaning of support of a measure.

\begin{df}\label{lb916}
Let $Y$ be a topological space. Let $\varphi:X\rightarrow Y$ be measurable. The \textbf{essential range} \index{00@Essential range $\Ess(\varphi)$} $\Ess(\varphi)$ of $\varphi$ (with respect to the measure $\mu$) is defined to be $\Supp(\varphi_*\mu)$, which is clearly a subset of the closure $\ovl{\varphi(X)}$.
\end{df}

\begin{prob}
Let $f\in\mc L(X,\Cbb)$. Prove that $\Vert f\Vert_{L^\infty}$ is the supremum of the essential range of $|f|:X\rightarrow\Rbb_{\geq0}$.
\end{prob}



\begin{proof}[Hint]
A subspace of $\mc H$ is dense iff any vector orthogonal to this subspace must be zero (Cor. \ref{lb882}).
\end{proof}



\begin{prob}\label{lb914}
Solve the following problems.
\begin{enumerate}
\item Assume that $\mu$ is $\sigma$-finite. Prove that there exists a measurable $h:X\rightarrow(0,+\infty)$ such that the measure $\nu:\fk M\rightarrow[0,+\infty]$ defined by $d\nu=hd\mu$ is finite.
\item Let $h\in\mc L(X,\Rbb_{\geq0})$ such that $\{x\in X:h(x)=0\}$ is $\mu$-null. Define a measure $\nu:\fk M\rightarrow[0,+\infty]$ by $d\nu=hd\mu$. Prove that $E\in\fk M$ is $\mu$-null iff $E$ is $\nu$-null. Use this to show:
\begin{enumerate}
\item The essential range of $\varphi$ in Def. \ref{lb916} defined by $\mu$ is equal to the one defined by $\nu$, and hence that
\begin{align}
L^\infty(X,\mu)=L^\infty(X,\nu)
\end{align}
\item If $(\ovl{\fk M},\mu)$ and $(\wht{\fk M},\mu)$ are the completions of $(\fk M,\mu)$ and $(\fk M,\nu)$ respectively, then $\ovl{\fk M}=\wht{\fk M}$.
\end{enumerate}
\end{enumerate} 
\end{prob}


\subsubsection{Miscellaneous problems}





\begin{sprob}
Let $f\in L^2([-\pi,\pi],\frac m{2\pi})$, viewed as an $2\pi$-periodic function on $\Rbb$. Assume that all Fourier coefficients $\wht f(n)$ of $f$ are non-zero. For each $t\in\Rbb$, let $f_t(x)=f(x-t)$. Prove that $\Span_\Cbb\{f_t:t\in\Rbb\}$ is dense in $L^2([-\pi,\pi],\frac m{2\pi})$.
\end{sprob}


\begin{proof}[Hint]
By Cor. \ref{lb882}, it suffices to show that any $g\in L^2([-\pi,\pi],\frac m{2\pi})$ orthogonal to every $f_t$ is zero. Translate this problem to a problem in $l^2(\Zbb)$.
\end{proof}




\newpage







\section{From the implicit function theorem to differential manifolds}

We let $x^i$ \index{xi@$x^i$, the coordinate function} denote the canonical coordinate function $x^i:\Rbb^n\rightarrow\Rbb$ sending $(a_1,\dots,a_n)$ to $a_i$. 

\subsection{Introduction}

The goal of this chapter is to study the implicit function theorem. Consider, for example, a $C^\infty$-function $f:\Rbb^3\rightarrow\Rbb$. Let
\begin{align*}
Z(f)=\{(x,y,z)\in\Rbb^3:f(x,y,z)=0\}
\end{align*}
be the set of zeros of $f$. Assume that $\partial_zf$ is nowhere zero on $Z(f)$. Then the implicit function theorem asserts that the equation $f(x,y,z)=0$ can be locally solved for $z$ in terms of $x,y$, i.e., $z=g(x,y)$ for some function $g$.

\begin{eg}
Let $f(x,y,z)=x^2+y^2+z^2-1$. Then $\partial_zf=2z$ is nowhere zero on $\{z\neq 0\}$. Then $f(x,y,z)=0$ can be locally solved for $z$ on this region: On $\{z>0\}$ we have $z=\sqrt{1-x^2-y^2}$, and on $\{z<0\}$ we have $z=-\sqrt{1-x^2-y^2}$. On the other hand, $\partial_zf$ is zero at $(1,0,0)$. Accordingly, on any neighborhood $U$ of $(1,0,0)$ we can not find a function $g$ satisfying $z=g(x,y)$. This is because any line orthogonal to the $xy$-plane and close to $(1,0,0)$ (but not containing $(1,0,0)$) has two intersection points with $Z(f)\cap U$. 
\end{eg}

\begin{rem}\label{lb924}
Roughly speaking, the general form of the implicit function theorem says the following. Let
\begin{align*}
(x,y)=(x^1,\dots,x^d,y^1,\dots,y^k)
\end{align*}
be the be standard coordinates of $\Rbb^d\times\Rbb^k$. Let $f=(f^1,\dots,f^k)$ be a real-valued $C^r$-map $\Omega\rightarrow \Rbb^k$ (where $r\geq1$) defined  on an open $\Omega\subset\Rbb^d\times\Rbb^k$. (So each component $f^i$ is a $C^r$-function $\Omega\rightarrow\Rbb$.) Suppose that the $k\times k$ Jacobian matrix
\begin{align*}
\Jac_y f=(\partial_{y^j}f^i)_{1\leq i,j\leq k}
\end{align*}
is invertible at $p\in\Rbb^d\times\Rbb^k$. (Equivalently, assume that the Jacobian $\Jbf_y(f)=\det\Jac_y f$ (cf. \eqref{eq359}) is nonzero at $p$.) Then, near $p$, the equations $f^1=\cdots=f^k=0$ can be \textbf{solved for $y$ in terms of $x$}, i.e., 
\begin{align}\label{eq368}
y^1=g^1(x),\dots,y^k=g^k(x)
\end{align}
for some $C^r$-functions $g^1,\dots,g^k$.
\end{rem}

We will see that the attempt to formulate the implicit function theorem rigorously leads naturally to the notion of differential manifolds.



\subsection{The inverse function theorem}


In this section, we prove a seemingly special but actually equivalent version of the implicit function theorem. Let $\Omega\subset\Rbb^n$ be open. Let $\varphi=(\varphi^1,\dots,\varphi^n)$ be an $C^r$ map from $\Omega$ to $\Rbb^n$ (where $r\geq1$). Here, $\varphi^i:\Omega\rightarrow\Rbb$ is the $i$-th component of $\varphi$. Assume that $\Jac\varphi$ is invertible at $p\in\Omega$, equivalently, that $\Jbf(\varphi)_p\neq0$. Define $f=(f^1,\dots,f^n):\Rbb^n\times\Rbb^n\rightarrow\Rbb^n$ by
\begin{gather*}
f^i(x,y)=\varphi^i(x)-y^i
\end{gather*}
Then $\Jac_xf$ equals $\Jac\varphi$, which is invertible at $p$. Thus, the implicit function theorem implies that the set of equations $y^1=\varphi^1(x),\dots,y^n=\varphi^n(x)$ have $C^r$ solutions
\begin{align*}
x^1=\psi^1(y),\dots,x^n=\psi^n(y)
\end{align*}
near $p$. Therefore, $\varphi$ has a local inverse map $\psi=(\psi^1,\dots,\psi^n)$.

Let us make the above conclusions rigorous.




\begin{df}
Let $U\subset\Rbb^n$ and $V\subset\Rbb^m$ be open. A map $f:U\rightarrow V$ is called a \pmb{$C^r$}\textbf{-diffeomorphism} \index{00@$C^r$-diffeomorphism} (where $r\in\Nbb\cup\{\infty\}$) if $f$ is bijective, and if both $f$ and $f^{-1}$ are $C^r$-maps (cf. Def. \ref{lb925}).  Thus, $f$ is a $C^0$-diffemorphism iff $f$ is a homeorphism. A $C^\infty$-diffeomorphism is simply called a \textbf{diffeomorphism}. \index{00@Diffeomorphism}
\end{df}

\begin{rem}
It is clear that if $f$ is a $C^{r+1}$-diffeomorphism, then both $f$ and $f^{-1}$ are $C^r$-diffeomorphisms. Moreover, if $g:\Gamma\rightarrow U$ is also a $C^r$-diffeomorphism, then by Prop. \ref{lb927}, $f\circ g:\Omega\rightarrow V$ is a $C^r$-diffeomorphism.
\end{rem}


\begin{rem}\label{lb928}
If $U\subset\Rbb^n$ and $V\subset\Rbb^m$ are nonempty open and $f:U\rightarrow V$ is a $C^r$-diffeomorphism where $r\geq1$. Then $m=n$.
\end{rem}

\begin{proof}
Let $g=f^{-1}$. By Thm. \ref{lb926}, $C^1$-functions are differentiable. Therefore, since $f\circ g=\id_V$ and $g\circ f=\id_U$, by the Chain rule (Thm. \ref{lb578}), for each $p\in U$ and $q=f(p)$ we have $d f|_p\cdot d g|_q=\idt|_{\Rbb^m}$ and $dg|_q\cdot df|_p=\idt|_{\Rbb^n}$. So $d g|_q$ is the inverse linear map of $df|_p$. Therefore $m=n$.
\end{proof}

Rem. \ref{lb928} is also true when $r=0$ (i.e., when $f$ is a homeomorphism). However, in this case the proof is more difficult. One needs tools from algebraic topology, and the relevant theorem is called \textbf{invariance of domain}.



\begin{thm}[\textbf{Inverse function theorem}]\index{00@Inverse function theorem}\label{lb929}
Let $\Omega\subset\Rbb^n$ be open. Let $\varphi:\Omega\rightarrow\Rbb^n$ be $C^r$ (where $r\in\{1,2,\dots,\infty\}$). Let $p\in\Omega$. Assume that the linear map $d\varphi|_p:\Rbb^n\rightarrow\Rbb^n$ is invertible. Then there exist neighborhoods $U\subset\Omega$ of $p$ and $V\subset\Rbb^n$ of $\varphi(p)$ such that $\varphi$ restricts to a $C^r$-diffeomorphism $\varphi:U\xrightarrow{\simeq} V$.
\end{thm}

\begin{lm}\label{lb931}
Let $\varphi$ be as in Thm. \ref{lb929}. Then there exist neighborhoods $U\subset\Omega$ of $p$ and $V\subset\Rbb^n$ of $\varphi(p)$ such that $\varphi$ restricts to a bijection $U\rightarrow V$.
\end{lm}


\begin{proof}
Step 1. By replacing $\varphi$ with $\varphi(x+p)-\varphi(p)$, it suffices to assume that $p=0$ and $\varphi(p)=0$. Let $A=d\varphi|_p$, which is invertible. Then, by chain rule, we have $d(A^{-1}\varphi)|_p=\idt$. Therefore, by replacing $\varphi$ with $A^{-1}\circ\varphi$, it suffices to assume
\begin{align*}
p=0\qquad \varphi(p)=0\qquad d\varphi|_0=\idt
\end{align*}
Note that $\varphi$ is differentiable by Thm. \ref{lb926}. Write
\begin{align*}
\varphi(x)=x+R(x)
\end{align*}
Then $R(0)=0$ and $dR|_0=0$. Since $R$ is $C^1$, the map $x\in\Omega\mapsto \Vert dR|_x\Vert$ is continuous where $\Vert dR|_x\Vert$ is the operator norm of $dR|_x$.  Therefore, for each $0<\eps<1$ there exists $\delta$ such that
\begin{align*}
U:=B_{\Rbb^n}(0,\delta)
\end{align*}
satisfies $\ovl U\subset\Omega$, and that the operator norm $\Vert dR|_x\Vert$ satisfies
\begin{align}\label{eq361}
\Vert dR|_x\Vert\leq\eps\qquad(\forall x\in \ovl U)
\end{align}


For each $y\in\Rbb^n$, define
\begin{align*}
T_y:\Omega\rightarrow\Rbb^n\qquad T_y(x)=y-R(x)
\end{align*}
Then $T_y(x)=x$ iff $y=\varphi(x)$. 
\begin{itemize}
\item Claim: There exists $\kappa>0$ such that for any $y\in B_{\Rbb^n}(0,\kappa)$, $T_y$ restricts to a contraction $\ovl U\rightarrow \ovl U$.
\end{itemize}
Suppose the claim is true. By the contraction Thm. \ref{lb555}, $T_y$ has a unique fixed point in the compact (and hence complete) set $\ovl U$. So there is a unique $x\in \ovl U$ such that $y=\varphi(x)$. This proves that $\varphi(\ovl U)$ contains $V=B_{\Rbb^n}(0,\kappa)$. Since $\varphi$ is continuous, $\varphi^{-1}(V)$ is an open subset of $U$ containing $0$. Therefore, by shrinking $U$ to $\varphi^{-1}(V)$, we get a surjective map $\varphi|_U:U\rightarrow V$ which is also injective by the uniqueness of the fixed points of $T_y$. This finishes the proof of the lemma.\\[-1ex]



Step 2. Let us prove the claim. By the finite-increment Thm. \ref{lb584}, and by \eqref{eq361}, $\eps$ is a Lipschitz constant of $R$. Therefore, for each $x_1,x_2\in \ovl U$ we have
\begin{align}\label{eq362}
\Vert R(x_1)-R(x_2)\Vert\leq \eps\Vert x_1-x_2\Vert
\end{align}
Therefore, for every $y\in\Rbb^n$, we have $\Vert T_y(x_1)-T_y(x_2)\Vert \leq\eps\Vert x_1-x_2\Vert$. This shows that $T|_{\ovl U}$ has Lipschitz constant $\eps<1$. To show that $T_y|_{\ovl U}$ is a contraction of $\ovl U$ when $\Vert y\Vert$ is sufficiently small, it remains to prove $T_y(\ovl U)\subset \ovl U$.

Since $R(0)=0$, by \eqref{eq362}, we have $\Vert R(x)\Vert\leq\eps\Vert x\Vert$. Therefore, if $\Vert x\Vert\leq\delta$, then
\begin{align*}
\Vert T_y(x)\Vert\leq\Vert y\Vert+\Vert R(x)\Vert\leq \Vert y\Vert+\eps\delta
\end{align*}
Let
\begin{align*}
\kappa=(1-\eps)\delta
\end{align*}
It follows that if $\Vert y\Vert<\kappa$, then for each $x\in \ovl U$ we have $\Vert T_y(x)\Vert<\delta$. This proves $T_y(\ovl U)\subset\ovl U$.
\end{proof}


\begin{proof}[\textbf{Proof of Thm. \ref{lb929}}]
Step 1. By assumption, the Jacobian $\Jbf(\varphi)$ is non-zero at $p=0$. Therefore, after shrinking $\Omega$ to a neighborhood of $p$, we can assume that $\Jbf(\varphi)$ is nowhere zero on $\Omega$, i.e., $\Jac\varphi$ is invertible everywhere on $\Omega$. By Lem. \ref{lb931}, for each $x\in\Omega$, $\varphi$ restricts to a bijection from a neighborhood of $x$ to a neighborhood of $\varphi(x)$. So $\varphi(x)$ is an interior point of $\varphi(\Omega)$. Therefore, $\varphi:\Omega\rightarrow \Rbb^n$ is an open map. By Lem. \ref{lb931} again, there exist $U\in\Nbh_\Omega(p)$ and $V\in\Nbh_{\Rbb^n}(\varphi(p))$ such that we have a continuous bijection $\varphi|_U:U\rightarrow V$. Since this map is open, it is a homeomorphism.

In the following, we always understand $\varphi$ as defined on $U$. Let $\psi:V\rightarrow U$ be the inverse map of $\varphi$, which is a homeomorphism. We claim that $\psi$ is differentiable and
\begin{align}\label{eq363}
d\psi|_y=(d\varphi|_{\psi(y)})^{-1}\qquad\text{ for all }y\in V
\end{align}
Suppose this claim is true. Let us show that $\psi$ is $C^k$ by induction on $k\in\Nbb$ satisfying $k\leq r$. Clearly $\psi$ is $C^0$. Suppose that $\psi$ is $C^{k-1}$ where $1\leq k\leq r$. Proving that $\psi$ is $C^k$ means proving that $\Jac \psi: y\in V\mapsto\Jac\psi|_y\in\Rbb^{n\times n}$ is $C^{k-1}$. By \eqref{eq363}, this map is the composition of $(\Jac\varphi)^{-1}:U\rightarrow\Rbb^{n\times n}$ and the $C^{k-1}$-map $\psi$. Since a composition of $C^{k-1}$-maps is $C^{k-1}$ (cf. Prop. \ref{lb927}), it suffices to prove that $(\Jac\varphi)^{-1}:U\rightarrow\Rbb^{n\times n}$ is $C^{k-1}$. But this follows immediately from the fact that $\Jac\varphi$ is $C^k$, and from Cramer's rule (which expresses each entry of $(\Jac\varphi)^{-1}$ in terms of those of $\Jac\varphi$). So $\psi$ is $C^k$, finishing the proof.\\[-1ex]

Step 2. Let us prove \eqref{eq363}. Similar to the proof of Lem. \ref{lb931}, by a suitable translation, we assume WLOG that $y=0$ and $\psi(y)=0$; by replacing $\psi$ with $A^{-1}\circ\psi$ where $A=d\varphi|_0$, we assume $d\varphi|_0=\idt$. We shall prove that $d\psi|_0=\idt$. 

Write $\varphi(x)=x+R(x)$ for each $x\in U$. Then $R(0)=0$ and $dR|_0=0$. For each $y\in V$, we have $y=\varphi\circ\psi(y)=\psi(y)+R\circ\psi(y)$, and hence
\begin{align*}
\psi(y)=y-R\circ\psi(y)
\end{align*}
Therefore, proving $d\psi|_0=\idt$ amounts to proving $d(R\circ\psi)|_0=0$, i.e., proving
\begin{align*}
\lim_{y\rightarrow0}\frac{R\circ\psi(y)}{\Vert y\Vert}=0
\end{align*}
Since we know $dR|_0=0$, i.e., $\lim_{x\rightarrow0}R(x)/\Vert x\Vert=0$, and since $\psi$ is continuous and $\psi(0)=0$, we have $\dps\lim_{y\rightarrow0}\frac{R\circ\psi(y)}{\Vert\psi(y)\Vert}=0$. Therefore, to prove the above limit, it suffices to prove
\begin{align*}
\limsup_{y\rightarrow0}\frac{\Vert\psi(y)\Vert}{\Vert y\Vert}<+\infty
\end{align*}
Since $\psi:V\rightarrow U$ is a homeomorphism (with inverse $\varphi$) sending $0$ to $0$, the above inequality is equivalent to $\dps \limsup_{x\rightarrow0}\frac{\Vert x\Vert}{\Vert \varphi(x)\Vert}<+\infty$, and hence is equivalent to
\begin{align*}
\liminf_{x\rightarrow0}\frac{\Vert \varphi(x)\Vert}{\Vert x\Vert}>0
\end{align*}
But this follows from the fact that for sufficiently small $\Vert x\Vert$ we have $\Vert R(x)\Vert\leq \frac 12 \Vert x\Vert$, and hence
\begin{align*}
\Vert \varphi(x)\Vert=\Vert x+R(x)\Vert\geq \Vert x\Vert-\Vert R(x)\Vert\geq\frac 12\Vert x\Vert
\end{align*}
\end{proof}

\begin{co}\label{lb954}
Let $r\in\Zbb_+\cup\{\infty\}$. Let $\Omega$ be an open subset of $\Rbb^n$. Let $\varphi:\Omega\rightarrow \Rbb^n$ be a map satisfying the following conditions:
\begin{enumerate}
\item[(a)] $\varphi$ is an injective $C^r$-map.
\item[(b)] $\Jac\varphi$ is invertible at every point of $U$.
\end{enumerate}
Then $\varphi(\Omega)$ is an open subset of $\Rbb^n$, and $\varphi$ restricts to a $C^r$-diffeomorphism $\varphi:\Omega\xrightarrow{\simeq}\varphi(\Omega)$.
\end{co}

\begin{proof}
For each open $U\subset\Omega$, if $p\in U$ then (by the inverse function Thm. \ref{lb929}) $\varphi(U)$ contains an open ball centered at $\varphi(p)$. This proves that $\varphi(U)$ is an open subset of $\Rbb^n$. Therefore, $\varphi(U)$ is open, and the injective continuous map $\varphi:\Omega\rightarrow\varphi(\Omega)$ is open, and hence is a homeomorphism. By the inverse function Thm. \ref{lb929}, for each $q\in\varphi(\Omega)$, $\varphi^{-1}$ is $C^r$ on a neighborhood of $q$. This proves that $\varphi^{-1}$ is $C^r$, and hence that $\varphi:\Omega\rightarrow\varphi(\Omega)$ is a $C^r$-diffeomorphism.
\end{proof}


\begin{eg}\label{lb969}
The \textbf{polar coordinates}
\begin{gather*}
(0,+\infty)\times (0,2\pi)\rightarrow \Rbb^2\setminus(\Rbb_{\geq0}\times 0) \qquad (r,\theta)\mapsto (x,y)\\
x=r\cos\theta\qquad y=r\sin\theta 
\end{gather*}
are a bijective $C^\infty$-map with nowhere zero Jacobian determinant
\begin{align*}
\Jbf_{(r,\theta)}(x,y)=r
\end{align*}
Therefore, by Cor. \ref{lb954}, this map is a diffeomorphism.
\end{eg}


\begin{eg}
The \textbf{cylindrical coordinates}
\begin{gather*}
(0,+\infty)\times (0,2\pi)\times\Rbb\rightarrow (\Rbb^2\setminus(\Rbb_{\geq0}\times 0))\times\Rbb \qquad (r,\theta,z)\mapsto (x,y,z)\\
x=r\cos\theta\qquad y=r\sin\theta\qquad z=z 
\end{gather*}
are an bijective $C^\infty$-map with nowhere zero Jacobian
\begin{align*}
\Jbf_{(r,\theta,z)}(x,y,z)=r
\end{align*}
Therefore, it is a diffeomorphism.
\end{eg}


\begin{eg}
The \textbf{spherical coordinates}
\begin{gather*}
(0,+\infty)\times (0,\pi)\times(0,2\pi)\rightarrow(\Rbb^2\setminus(\Rbb_{\geq0}\times 0))\times\Rbb\qquad(r,\varphi,\theta)\mapsto(x,y,z)\\
x=r\sin\varphi\cos\theta\qquad y=r\sin\varphi\sin\theta\qquad z=r\cos\varphi
\end{gather*}
are a bijective $C^\infty$-map with nowhere zero Jacobian
\begin{align*}
\Jbf_{r,\varphi,\theta}(x,y,z)=r^2\sin\varphi
\end{align*}
Therefore, it is a diffeomorphism.
\end{eg}








\subsection{Submanifolds of $\Rbb^n$}

The following is the preliminary version of the implicit function theorem.
\begin{co}\label{lb932}
Let $d,k\in\Nbb$. Let $\Omega$ be an open subset of $\Rbb^d\times\Rbb^k$. Let
\begin{align*}
(x,y)=(x^1,\dots,x^d,y^1,\dots,y^k)
\end{align*}
be the standard coordinates of $\Rbb^d\times\Rbb^k$. Let $f=(f^1,\dots,f^k):\Omega\rightarrow\Rbb^k$ be a $C^r$-map where $r\in\Zbb_+\cup\{\infty\}$. Assume that
\begin{align*}
\Jac_yf\equiv(\partial_{y^j}f^i)_{1\leq i,j\leq k}\equiv 
\begin{pmatrix}
\partial_{y^1} f^1 & \cdots & \partial_{y^k} f^1\\
 & \vdots & \\
\partial_{y^1} f^k & \cdots & \partial_{y^k} f^k
\end{pmatrix}
\end{align*}
is invertible at $p\in\Omega$. Then there exist a neighborhood $U\subset\Omega$ of $p$ and an open $V\subset\Rbb^d\times\Rbb^k$ such that we have a $C^r$-diffeomorphism
\begin{align}
(x^1,\dots,x^d,f^1,\dots,f^k):U\xrightarrow{\simeq}V
\end{align}
\end{co}


\begin{proof}
By the inverse function Thm. \ref{lb929}, it suffices to prove that $\Jac (x,f)\equiv\Jac_{x,y}(x,f)$ is invertible at $p$. We calculate that
\begin{align*}
\Jac (x,f)=\begin{pmatrix}
\Jac_xx & \Jac_y x\\
\Jac_xf & \Jac_y f
\end{pmatrix}
=\begin{pmatrix}
1_{d\times d} & 0_{d\times k}\\
\Jac_xf & \Jac_yf
\end{pmatrix}
\end{align*}
whose determinant is $\det\Jac_yf$ and is nonzero at $p$. So $\Jac(x,f)|_p$ is invertible.
\end{proof}

At this point, it is still not clear how to interpret the fact that $f(x,y)=0$ can be solved for $y$ in terms of $x$. We first need to introduce the notion of submanifolds. To motivate the definition, let us take a closer look at Cor. \ref{lb932}:


\begin{rem}\label{lb935}
Assume the setting of Cor. \ref{lb932}. Define the \textbf{zero set} \index{00@Zero set $Z(f)$} \index{Zf@$Z(f)$, the zero set of $f$}
\begin{align}\label{eq377}
Z(f)=\{q\in\Omega:f^1(q)=\dots=f^k(q)=0\}
\end{align}
Recall $x=(x^1,\dots,x^d)$ and $f=(f^1,\dots,f^k)$. Then we clearly have a commutative diagram
\begin{equation}\label{eq364}
\begin{tikzcd}[column sep=large]
Z(f)\cap U \arrow[r,"{(x,0)}"] \arrow[d, hook] & (\Rbb^d\times 0)\cap V \arrow[d, hook] \\
U \arrow[r,"{(x,f)}","\simeq"']                 & (\Rbb^d\times\Rbb^k)\cap V=V            
\end{tikzcd}
\end{equation}
where the two vertical arrows are the inclusion maps, and the bottom arrow is a $C^r$-diffeomorphism. The top arrow is surjective since the inverse image of $(\Rbb^d\times 0)\cap V$ under $(x,f)$ is $Z(f)\cap U$. Therefore $(x,0):Z(f)\cap U\rightarrow (\Rbb^d\times 0)\cap V$ is bijective, and hence is a homeomorphism (since $(x,f)$ is a homeomorphism). The commutative diagram \eqref{eq364} tells us that $(x,f)$ implements an equivalence of the inclusions $Z(f)\cap U\hookrightarrow U$ and $(\Rbb^d\times 0)\cap V\hookrightarrow V$.
\end{rem}

%% Record #16 2024/04/22 two lectures  39

According to the following definition, $Z(f)$ is a $C^r$-submanifold of $\Rbb^d\times\Rbb^k$.


\begin{df}\label{lb933}
Let $M\subset\Rbb^n$ and $r\in\Zbb_+\cup\{\infty\}$. We say that $M$ is an \textbf{(embedded)} \pmb{$C^r$}\textbf{-submanifold} \index{00@Submanifold} of $\Rbb^n$ if for every $p\in M$ there exist $U\in\Nbh_{\Rbb^n}(p)$,  $0\leq d\leq n$, and $C^r$-functions $\varphi^1,\dots,\varphi^d,f^1,\dots,f^k:U\rightarrow\Rbb$ (where $k=n-d$) satisfying the following conditions:
\begin{itemize}
\item[(a)] Set $\varphi=(\varphi^1,\dots,\varphi^d)$ and $f=(f^1,\dots,f^k)$. Then $(\varphi,f)$ gives a $C^r$-diffeomorphism $U\xrightarrow{\simeq} V$ where $V$ is an open subset of $\Rbb^n=\Rbb^d\times\Rbb^k$.
\item[(b)] The following diagram commutes (cf. also Fig. \ref{lb938}):
\begin{equation}\label{eq365}
\begin{tikzcd}[column sep=large]
M\cap U \arrow[r,"{(\varphi,0)}"] \arrow[d, hook] & (\Rbb^d\times 0)\cap V \arrow[d, hook] \\
U \arrow[r,"{(\varphi,f)}","\simeq"']                 & (\Rbb^d\times\Rbb^k)\cap V=V            
\end{tikzcd}
\end{equation}
Moreover, the top arrow $(\varphi,0)$ is bijective. (Equivalently, the inverse image of $(\Rbb^d\times 0)\cap V$ under $(\varphi,f)$ is $M\cap U$.)
\end{itemize}
It follows that the top arrow  $(\varphi,0):M\cap U\rightarrow (\Rbb^d\times 0)\cap V$ is a homeomorphism.
\end{df}

\begin{figure}[h]
	\centering
\begin{equation*}
\vcenter{\hbox{{
			\includegraphics[height=2.2cm]{fig11.png}}}}
\end{equation*}
	\caption{. The figure for the commutative diagram \eqref{eq365}.}\label{lb938}
\end{figure}

\begin{pp}\label{lb934}
Assume the setting of Def. \ref{lb933}. Then $\varphi(M\cap U)$ is an open subset of $\Rbb^d$. Moreover, for each $h\in C^r(U,\Rbb)$, there exists a unique $g:\varphi(M\cap U)\rightarrow\Rbb$ such that
\begin{align}\label{eq366}
h|_{M\cap U}=g\circ \varphi|_{M\cap U}
\end{align}
Moreover, any $g$ satisfying \eqref{eq366} is $C^r$. We say that $h$ is a \pmb{$C^r$}\textbf{-function of}  $\varphi^1,\dots,\varphi^d$ when restricted to $M\cap U$.
\end{pp}
Note that by \eqref{eq365}, we clearly have
\begin{align}\label{eq367}
(\Rbb^d\times 0)\cap V=\varphi(M\cap U)\times 0
\end{align}

\begin{proof}
By \eqref{eq367}, $\varphi(M\cap U)$ is open. The uniqueness of $g$ is obvious. 
Let us prove the existence. Since  $h\circ (\varphi,f)^{-1}$ is a $C^r$-function on $V$, its restriction to $\varphi(M\cap U)\times 0$ is also $C^r$, and hence can be viewed as $g$ for some $g\in C^r(\varphi(M\cap U),\Rbb)$ (if we identify $\varphi(M\cap U)\times 0$ with $\varphi(M\cap U)$ in a canonical way). By the commutative diagram \eqref{eq365}, the pullback of $g$ under $(\varphi,0)$ equals $g\circ(\varphi,f)|_{M\cap U}=h|_{M\cap U}$. This proves \eqref{eq366}.
\end{proof}



With the help of Prop. \ref{lb934}, we now give a rigorous formulation of the implicit function theorem as described in Rem. \ref{lb924}:

\begin{rem}
Assume the setting of Cor. \ref{lb932}. Then by Rem. \ref{lb935} and Prop. \ref{lb934}, for each $1\leq i\leq k$, $y^i$ is a $C^r$-function of $x=(x^1,\dots,x^d)$ when restricted to $Z(f)\cap U$. Namely, there exists $g^i\in C^r(x(Z(f)\cap U),\Rbb)$ such that
\begin{align}
y^i|_{Z(f)\cap U}=g^i\circ (x^1,\dots,x^d)|_{Z(f)\cap U}
\end{align}
Therefore, the fact that $f(x^1,\dots,x^d,y^1,\dots,y^k)=0$ can be solved (on $U$) for $y$ in terms of $x$ should be interpreted to mean that on $Z(f)\cap U$, the functions $y^1,\dots,y^k$ can be expressed as $C^r$-functions of $x^1,\dots,x^d$. In particular, the formula $y^i=g^i(x)$ in \eqref{eq368} should be interpreted as a relation of functions, not points.
\end{rem}


We return to the setting of Def. \ref{lb933}. We have seen that $\varphi=(\varphi^1,\dots,\varphi^d)$ enjoys the following properties:
\begin{itemize}
\item $\varphi$ is a homeomorphism from $M\cap U$ to an open subset of $\Rbb^d$.
\item Every $C^r$-function on $U$, when restricted to $M\cap U$, is a $C^r$-function of $\varphi^1,\dots,\varphi^d$.
\end{itemize}
These properties, especially the second one, gives a rigorous formulation of the implicit function theorem. Therefore, such $\varphi$ should have a name: We call the pair $(M\cap U,\varphi)$ a \textbf{(coordinate) chart} on $M$.

In the next section, we will see that a general $C^r$-manifold (not necessarily a subset of $\Rbb^n$) is defined in terms of its charts. To motivate the axiomatic definition of charts, we make the following observation:
\begin{lm}\label{lb937}
Let $\Omega\subset\Rbb^n$ be open. Let $\psi=(\psi^1,\dots,\psi^{d'}):\Omega\rightarrow\Rbb^{d'}$ and $g=(g^1,\dots,g^{k'}):\Omega\rightarrow\Rbb^{k'}$ be $C^r$-maps where $d'+k'=n$. Assume that $\Omega,\psi,g$ and $(\psi,g)(\Omega)$ satisfy the same conditions that $U,\varphi,f$ and $V=(\varphi,f)(U)$ satisfy in Def. \ref{lb933}. Then $(U,\varphi|_{M\cap U})$ and $(\Omega,\psi|_{M\cap \Omega})$ are \pmb{$C^r$}\textbf{-compatible}, which means that
\begin{align}\label{eq369}
\psi|_{M\cap U\cap\Omega}\circ(\varphi|_{M\cap U\cap\Omega})^{-1}:\varphi(M\cap U\cap\Omega)\rightarrow\psi(M\cap U\cap\Omega)
\end{align}
is a $C^r$-diffeomorphism of open subsets of $\Rbb^d$ and $\Rbb^{d'}$. In particular, we have $d=d'$ if $M\cap U\cap\Omega\neq\emptyset$.
\end{lm}



\begin{proof}
Write $W=M\cap U\cap\Omega$. Since $\varphi|_{M\cap U}$ gives a homeomorphism from $M\cap U$ to an open subset of $\Rbb^d$, $\varphi(W)$ must be open in $\Rbb^d$. Similarly, $\psi(W)$ is open. Let $\wtd\varphi=\varphi|_W$ and $\wtd\psi=\psi|_W$. Then $\wtd\varphi:W\rightarrow\varphi(W)$ and $\wtd\psi:W\rightarrow\psi(W)$ are homeomorphisms. This proves that \eqref{eq369} is a homeomorphism of open subsets of $\Rbb^d$ and $\Rbb^{d'}$.

Let $\vartheta=(\vartheta^1,\dots,\vartheta^{d'})$ be the map \eqref{eq369}. (So $\vartheta^i:\varphi(W)\rightarrow\Rbb$.) Then $\wtd\psi^i=\vartheta^i\circ \wtd\varphi$. By Prop. \ref{lb934}, there is a unique $g^i:\varphi(W)\rightarrow\Rbb$ satisfying $\wtd\psi^i=g^i\circ\wtd\varphi$, and such $g^i$ is $C^r$. This proves that $\vartheta^i=g^i$, and hence $\vartheta^i$ is $C^r$. Thus, we have proved that $\wtd\psi\circ\wtd\varphi^{-1}$ is $C^r$. Similarly, $\wtd\varphi\circ\wtd\psi^{-1}$ is also $C^r$. This proves that \eqref{eq369} is a $C^r$-diffeomorphism.
\end{proof}



\subsection{Differential manifolds and their submanifolds}


Let $r\in\Zbb_+\cup\{\infty\}$.

\subsubsection{$C^r$-manifolds}


\begin{df}\label{lb936}
Let $M$ be a nonempty Hausdorff space. A set $\fk U=\big\{(U_\alpha,\varphi_\alpha)_{\alpha\in\scr A}\big\}$ is called a \pmb{$C^r$-}\textbf{atlas} \index{00@Atlas} of $M$ if the following conditions hold:
\begin{itemize}
\item $M$ is equipped with an open cover $M=\bigcup_{\alpha\in\scr A}U_\alpha$.
\item Each $U_\alpha$ is equipped with a homeomorphism $\varphi_\alpha:U_\alpha\rightarrow\varphi_\alpha(U_\alpha)$ where $\varphi_\alpha(U_\alpha)$ is an open subset of $\Rbb^{d_\alpha}$ for some $d_\alpha\in\Nbb$.
\item For each $\alpha,\beta\in\scr A$, $\varphi_\alpha$ and $\varphi_\beta$ are  \pmb{$C^r$}\textbf{-compatible} \index{00@$C^r$-compatible} in the sense that the following map is a $C^r$-diffeomorphism of (clearly open) subsets of $\Rbb^{d_\alpha}$:
\begin{align}
\varphi_\beta\circ\varphi_\alpha^{-1}:\varphi_\alpha(U_\alpha\cap U_\beta)\xrightarrow{\simeq}\varphi_\beta(U_\alpha\cap U_\beta)
\end{align}
\end{itemize}
The pair $(M,\fk U)$ (or simply $M$) is called a \pmb{$C^r$}\textbf{-manifold}. \index{00@@$C^r$-manifold}  The $C^r$-atlas of a $C^r$-manifold is simply called an \textbf{atlas}.
\end{df}

\begin{cv}
Unless otherwise stated, we assume that a $C^r$-manifold is second countable.
\end{cv}

\begin{df}
A $C^\infty$-manifold is also called a \textbf{differential manifold} or a \textbf{smooth manifold}. \index{00@Differential manifold} \index{00@Smooth manifold}
\end{df}

\begin{df}
In Def. \ref{lb936}, we say that $U_\alpha$ is \pmb{$d_\alpha$}\textbf{-dimensional}. \index{00@Dimension of a manifold} If $p\in U_\alpha$, we also say that $M$ has \textbf{dimension} \pmb{$d_\alpha$} at $p$  and write
\begin{align*}
\dim_p M=d_\alpha
\end{align*}
(By Rem. \ref{lb928}, $\dim_p M$ is well-defined and independent of the choice of $U_\alpha$ containing $p$.) If $\dim_pM$ is independent of $p$, we say that $M$ is \textbf{equidimensional}. \index{00@Equidimensional} If $\dim_pM=d$ for all $p\in M$, we say that $M$ has \textbf{dimension} $d$ and write
\begin{align*}
\dim M=d
\end{align*}
\end{df}


\begin{pp}\label{lb982}
Let $M$ be a $C^r$-manifold. Then for each $d\in\Nbb$, $U_d=\{x\in M:\dim_xM=d\}$ is both closed an open in $M$. In particular, if $M$ is connected, then $M$ is equidimensional.
\end{pp}

\begin{proof}
Clearly $U_d=\{x\in M:\dim_xM=d\}$ is open. So $X\setminus U_d=\bigcup_{k\neq d}U_k$ is also open. So $U_d$ is closed. If $M$ is connected, there exists $d$ such that $U_d$ is nonempty. Then we must have $M=U_d$.
\end{proof}


\begin{df}
Let $M$ be a $C^r$-manifold with atlas $\fk U$. A \pmb{$C^r$}\textbf{-chart} (or simply a \textbf{chart}) \index{00@Chart} on $(M,\fk U)$ is defined to be a pair $(V,\psi)$ satisfying the following conditions:
\begin{itemize}
\item $V$ is an open subset of $M$.
\item $\psi:V\rightarrow\psi(V)$ is a homeomorphism where $\psi(V)$ is an open subset of $\Rbb^d$ for some $d\in\Nbb$.
\item Each $(U,\varphi)\in\fk U$ is $C^r$-compatible with $(V,\psi)$, i.e., the following map is a $C^r$-diffeomorphism:
\begin{align*}
\psi\circ\varphi^{-1}:\varphi(U\cap V)\xrightarrow{\simeq}\psi(U\cap V)
\end{align*}
\end{itemize}
The inverse map $\psi^{-1}:\psi(V)\rightarrow V$ is called a \textbf{local parametrization} of $M$. \index{00@Local parametrization} If $V=M$, we call $\psi^{-1}$ a \textbf{(global) parametrization} of $M$, \index{00@Parametrization} and call $\psi$ a set of \textbf{coordinates} \index{00@Coordinates on a manifold} on $M$.
\end{df}


\begin{rem}
Let $\ovl{\fk U}$ be the set of all $C^r$-charts on a $C^r$-manifold $(M,\fk U)$. The following are easy to check:
\begin{enumerate}[label=(\alph*)]
\item $\ovl{\fk U}$ is also a $C^r$-atlas. Moreover, every $C^r$-atlas extending $\fk U$ must be contained in $\ovl{\fk U}$. We call $\ovl{\fk U}$ the \textbf{maximal atlas} \index{00@Maximal atlas} (or the \textbf{$C^r$-structure}) \index{00@$C^r$-structure} of $(M,\fk U)$. 
\item Let $\fk V$ be another $C^r$-atlas on $M$. Then $\fk U$ is \textbf{$C^r$-compatible} \index{00@$C^r$-compatible} with $\fk V$ (i.e. each member of $\fk U$ is $C^r$-compatible with each member of $\fk V$) iff $\ovl {\fk U}=\ovl{\fk V}$.
\end{enumerate}
$C^\infty$-structures are also called \textbf{differential structures} or \textbf{smooth structures}. \index{00@Differential structure} \index{00@Smooth structure} Thus, we view $(M,\fk U)$ and $(M,\fk V)$ as the same $C^r$-manifold if $\fk U$ and $\fk V$ have the same $C^r$-structure.
\end{rem}


\begin{eg}
A single point is a $0$-dimensional smooth manifold. Conversely, suppose that $M$ is a $C^r$-manifold, $p\in M$, and $\dim_pM=0$. Then there is a chart containing $p$ giving a homoemorphism between a neighborhood $U$ of $p$ and $\Rbb^0=\{0\}$. So $U=\{p\}$, and hence $p$ is an isolated point of $M$.
\end{eg}



\begin{eg}
Any open subset $\Omega\subset\Rbb^n$, together with the canonical atlas $\{(\Omega,x^1,\dots,x^n)\}$, is an $n$-dimensional $C^\infty$-manifold.
\end{eg}


\begin{eg}\label{lb941}
Let $M$ be a $C^r$-submanifold of $\Rbb^n$. Then $M$ has a canonical $C^r$-structure so that $M$ is a $C^r$-manifold. The $C^r$-structure is defined as follows. 

Assume that $U\subset \Rbb^n$ is open, and $\varphi^1,\dots,\varphi^d,f^1,\dots,f^k:U\rightarrow\Rbb$ are $C^r$-functions satisfying the conditions (a) and (b) of Def. \ref{lb933}. Then all such $(M\cap U,\varphi|_{M\cap U})$ form a $C^r$-chart of $M$; the $C^r$-compatibility of these charts are due to Lem. \ref{lb937}. If $p\in U$ then $\dim_pM=d$. \hfill\qedsymbol
\end{eg}


\begin{eg}\label{lb953}
Let $M,N$ be $C^r$-manifolds. Then $M\times N$ is a $C^r$-manifold whose charts are of the form $(U\times V,\varphi\times\psi)$ where $(U,\varphi)$ is a chart of $M$ and $(V,\psi)$ is a chart of $N$. We call $M\times N$ the \textbf{product} \pmb{$C^r$}\textbf{-manifold} \index{00@Product manifold} of $M,N$. 
\end{eg}



\subsubsection{$C^r$-maps}

\begin{df}
Let $M,N$ be $C^r$-manifolds. We say that $F:M\rightarrow N$ is a \pmb{$C^r$}\textbf{-map/function} \index{00@$C^r$-map/function} if $F$ is continuous, and if for every charts $(U,\varphi)$ of $M$ and $(V,\psi)$ of $N$, the following map is $C^r$:
\begin{align}\label{eq370}
\psi\circ F\circ\varphi^{-1}:\varphi(U\cap F^{-1}(V))\rightarrow \psi(V)
\end{align} 
If $F$ is bijective, and if both $F$ and $F^{-1}$ are $C^r$, we say that $F$ is a \pmb{$C^r$}\textbf{-diffeomorphism}. We let \index{Cr@$C^r(M,N)$} 
\begin{gather}
C^r(M,N)=\{C^r\text{-maps }M\rightarrow N\}
\end{gather}
A $C^\infty$-map is also called a \textbf{smooth map/function} \index{00@Smooth map/function}. A $C^\infty$-diffeomorphism is simply called a \textbf{diffeomorphism}.  \hfill\qedsymbol
\end{df}

\begin{rem}\label{lb946}
Suppose that $M$ and $N$ are equipped with atlases $\fk U,\fk V$ respectively. It is easy to see that a continuous map $F:M\rightarrow N$ is $C^r$ iff for each $(U,\varphi)\in\fk U$ and $(V,\psi)\in\fk V$, the map \eqref{eq370} is $C^r$. In particular, if $N=\Rbb^n$, then $F$ is $C^r$ iff $F\circ\varphi^{-1}:\varphi(U)\rightarrow\Rbb^n$ is $C^r$ for all $(U,\varphi)\in\fk U$. 
\end{rem}

\begin{exe}\label{lb940}
Let $F:M\rightarrow N$ and $G:N\rightarrow P$ be $C^r$-maps of $C^r$-manifolds. Prove that $G\circ F:M\rightarrow P$ is $C^r$.
\end{exe}

\begin{eg}\label{lb943}
Every open subset $\Omega$ of a $C^r$-manifold is a $C^r$-submanifold in a canonical way: Its charts are $(U\cap\Omega,\varphi|_{U\cap\Omega})$ where $(U,\varphi)$ is a chart of $M$. We call $\Omega$ an \textbf{open ($C^r$-)submanifold} of $M$. \index{00@Open submanifold}
\end{eg}

The following proposition is close in spirit to Rem. \ref{lb946}. 

\begin{pp}\label{lb944}
Let $F:M\rightarrow N$ be a continuous map of $C^r$-manifolds. Let $\fk U$ and $\fk V$ be open covers of $M$ and $N$ respectively. Then $F$ is $C^r$ iff for each $U\in \fk U$ and $V\in\fk V$, the map
\begin{align}\label{eq374}
F|_{U\cap F^{-1}(V)}:U\cap F^{-1}(V)\rightarrow V
\end{align}
is $C^r$, where $U$ and $V$ are viewed as open $C^r$-submanifolds of $M$ and $N$ respectively.
\end{pp}

\begin{proof}
``$\Rightarrow$" is obvious by Exe. \ref{lb940}. Assume that the RHS of ``$\Leftarrow$" is true. In the special case that each $U\in\fk U$ and $V\in\fk V$ are charts $(U,\varphi),(V,\psi)$, we know that $F$ is $C^r$ by Rem. \ref{lb946}. In the general case, choose atlases $\fk U',\fk V'$ of $M,N$ respectively. Then for each $U\in \fk U,\Omega\in\fk U',V\in\fk V,\Gamma\in\fk V'$, since \eqref{eq374} is $C^r$, by ``$\Rightarrow$", the restriction
\begin{align*}
F:U\cap \Omega\cap F^{-1}(V\cap\Gamma)\rightarrow V\cap\Gamma
\end{align*}
is $C^r$. Therefore, by the proved special case, the original map $F:M\rightarrow N$ is $C^r$.
\end{proof}

The following proposition generalizes Prop. \ref{lb934} and points out the role played by coordinate charts in the implicit function theorem:

\begin{pp}\label{lb947}
Let $M$ be a $C^r$-manifold. Let $(U,\varphi)$ be a chart of $M$ where $\varphi=(\varphi^1,\dots,\varphi^d):U\rightarrow\Rbb^d$. Let $h\in C^r(U,\Rbb)$. Then there exists a unique $g:\varphi(M\cap U)\rightarrow\Rbb$ such that 
\begin{align}\label{eq371}
h|_{M\cap U}=g\circ \varphi|_{M\cap U}
\end{align}
Moreover, any $g$ satisfying \eqref{eq371} is $C^r$. We say that $h$ is a \pmb{$C^r$}\textbf{-function of}  $\varphi^1,\dots,\varphi^d$ when restricted to $M\cap U$.
\end{pp}

\begin{proof}
The uniqueness is obvious. To prove the existence, noting that $\varphi^{-1}:\varphi(M\cap U)\rightarrow M\cap U$ is $C^r$, we let $g=h\circ \varphi^{-1}:\varphi(M\cap U)\rightarrow\Rbb$. So $g$ is $C^r$ by Exe. \ref{lb940}.
\end{proof}







\subsubsection{Submanifolds}

\begin{df}
Let $N$ be a $C^r$-manifold, and let $M\subset N$. We say that $M$ is  an \textbf{(embedded)} \pmb{$C^r$}\textbf{-submanifold} \index{00@Submanifold} of $N$ if for every $p\in M$, there exists a chart $(U,\varphi^1,\dots,\varphi^n)$ of $N$ such that $p\in U$, and that $\varphi(M\cap U)$ is a $C^r$-submanifold of $\varphi(U)$ (equivalently, $\varphi(M\cap U)$ is a $C^r$-submanifold of $\Rbb^n$).
\end{df}

\begin{eg}
An open $C^r$-submanifold (Exp. \ref{lb943}) is a $C^r$-submanifold.
\end{eg}

\begin{rem}\label{mc29}
Let $M$ be a subset of a $C^r$-manifold $N$. Let $\fk U$ be a collection of open subsets of $N$ covering $M$. Suppose that for each $U\in\fk U$, $M\cap U$ is a $C^r$-submanifold of $U$ (equivalently, $M\cap U$ is a $C^r$-submanifold of $N$). Then $M$ is a $C^r$-submanifold of $N$.  
\end{rem}


\begin{rem}\label{lb945}
The readers can easily check that the following gives an equivalent definition that $M$ is a $C^r$-submanifold of $N$: For each $p\in M$, there exist $U\in\Nbh_N(p)$, $d,k\in\Nbb$, and $C^r$-functions $\varphi^1,\dots,\varphi^d,f^1,\dots,f^k:U\rightarrow\Rbb$ satisfying the following conditions:
\begin{enumerate}
\item[(a)] $(\varphi,f)=(\varphi^1,\dots,\varphi^d,f^1,\dots,f^k)$ gives a $C^r$-diffeomorphism $U\xrightarrow{\simeq} V$ where $V$ is an open subset of $\Rbb^d\times\Rbb^k$.
\item[(b)] The following diagram commutes:
\begin{equation}\label{eq373}
\begin{tikzcd}[column sep=large]
M\cap U \arrow[r,"{(\varphi,0)}"] \arrow[d, hook] & (\Rbb^d\times 0)\cap V \arrow[d, hook] \\
U \arrow[r,"{(\varphi,f)}","\simeq"']                 & (\Rbb^d\times\Rbb^k)\cap V=V            
\end{tikzcd}
\end{equation}
Moreover, the top arrow $(\varphi,0)$ is bijective. (Equivalently, the inverse image of $(\Rbb^d\times 0)\cap V$ under $(\varphi,f)$ is $M\cap U$.)
\end{enumerate}
Similar to Exp. \ref{lb941}, $M$ has a canonical $C^r$-structure such that for every $U,\varphi,f$ described as above, $(M\cap U,\varphi|_{M\cap U})$ is a chart of $M$. Therefore, the top horizontal arrow $(\varphi,0):M\cap U\rightarrow(\Rbb^d\times 0)\cap V$ is a $C^r$-diffeomorphism since $\varphi:M\cap U\rightarrow\varphi(M\cap U)$ is a diffeomorphism.
\end{rem}




\begin{rem}\label{lb942}
Let $V$ be an open subset of $\Rbb^d\times\Rbb^k$. Then $(\Rbb^d\times 0)\cap V$ is a $C^\infty$-submanifold of $V$. This is the standard model of submanifold, since every $C^r$-submanifold is, by definition, locally equivalent to this one. Therefore, to prove that a property is true for all submanifolds, suppose that it suffices to check this property locally, and suppose that the truth value of this property is unchanged under a diffeomorphism, then it suffices to check this property for the standard model
\begin{align}\label{eq372}
(\Rbb^d\times 0)\cap V\hookrightarrow (\Rbb^d\times\Rbb^k)\cap V=V
\end{align}
\end{rem}



%% Record #17 2024/04/29 two lectures  41



As an application of Rem. \ref{lb942}, we prove:


\begin{pp}\label{lb952}
Let $M$ be a $C^r$-submanifold of a $C^r$-manifold $N$. Then the inclusion map $\iota:M\hookrightarrow N$ is $C^r$.
\end{pp}

\begin{proof}
The brief reason is that it suffices to check the $C^r$-ness locally. Therefore, since the model example \eqref{eq372} is clearly $C^r$, we conclude that $\iota:M\hookrightarrow N$ is $C^r$. 

The detailed argument is as follows. By Prop. \ref{lb944}, it suffices to prove that for each $p\in M$ there exists $U\in\Nbh_N(p)$ such that the inclusion $M\cap U\rightarrow N$ is $C^r$. This is equivalent to proving that $M\cap U\rightarrow U$ is $C^r$. By the commutative diagram \eqref{eq373}, one can choose $U\in\Nbh_N(p)$ such that $\iota:M\cap U\rightarrow U$, composed with a $C^r$-diffeomorphism on the source and a $C^r$-diffeomorphism on the target, is equal to the map \eqref{eq372}. Since \eqref{eq372} is clearly $C^r$, the map $M\cap U\rightarrow U$ is $C^r$.
\end{proof}



The following proposition gives a further application of Rem. \ref{lb942}.

\begin{pp}\label{lb955}
Let $X,N$ be $C^r$-manifolds. Let $M$ be a $C^r$-submanifold of $N$. Let $\iota:M\hookrightarrow N$ be the inclusion map. Let $F:X\rightarrow M$ be a map. Then $F:X\rightarrow M$ is $C^r$ iff $\iota\circ F:X\rightarrow N$ is $C^r$.
\end{pp}

\begin{proof}
Since $M$ is equipped with the subspace topology, it is clear that $F:X\rightarrow M$ is continuous iff $\iota\circ F:X\rightarrow N$ is continuous. Thus, in the following, we assume that $F,\iota\circ F$ are continuous. Since $\iota$ is $C^r$, if $F$ is $C^r$ then $\iota\circ F$ is clearly also $C^r$.

Now we assume that $\iota\circ F$ is $C^r$. Suppose we can prove that $M$ has an open cover $\fk W$ such that for each $W\in\fk W$, the restriction $F:F^{-1}(W)\rightarrow W$ is $C^r$. Then $F$ is $C^r$ by Prop. \ref{lb944}.

To prove the desired property, we note that by Rem. \ref{lb945}, $M$ has an open cover whose members are of the form $M\cap U$ where $U$ is as in Rem. \ref{lb945}. We let $\varphi,f$ be as in Rem. \ref{lb945}. We shall show that $F:F^{-1}(U)\rightarrow M\cap U$ is $C^r$. Since the top vertical arrow $(\varphi,0)$ in the commutative diagram \eqref{eq373} is a $C^r$-diffeomorphism, it suffices to prove that $\wtd F=(\varphi,0)\circ F:F^{-1}(U)\rightarrow (\Rbb^d\times 0)\cap U$ is $C^r$. Since $\iota \circ F:F^{-1}(U)\rightarrow U$ is $C^r$, and since the bottom vertical arrow $(\varphi,f):U\rightarrow V$ in \eqref{eq373} is a $C^r$-diffeomorphism, their composition $G:F^{-1}(U)\rightarrow V$ is $C^r$. Since the projection $\pi:\Rbb^d\times\Rbb^k\rightarrow\Rbb^d\simeq\Rbb^d\times 0$ is $C^r$, and since $\wtd F=\pi\circ G$, we conclude that $\wtd F$ is $C^r$.
\end{proof}


We leave it to the readers as an exercise to check the following easy fact:

\begin{exe}\label{lb959}
Let $M$ and $N$ be $C^r$-manifolds. Let $P,Q$ be $C^r$-submanifolds of $M,N$ respectively. Then $P\times Q$, as a subset of the product manifold $M\times N$, is a $C^r$-submanifold, and its $C^r$-structure is equal to the product $C^r$-structure of those of $P$ and $Q$.
\end{exe}

In other words, viewing $P\times Q$ as a submanifold of $M\times N$ is compatible with viewing $P\times Q$ as a product manifold. The process of passing to submanifolds commutes with the process of taking product.




\subsection{The implicit function theorem}


Let $r\in\Zbb_+\cup\{\infty\}$. Our final version of the implicit function theorem is as follows.

\begin{thm}[\textbf{Implicit function theorem}] \index{00@Implicit function theorem}\label{lb950}
Let $d,k\in\Nbb$. Let $(x,y)=(x^1,\dots,x^d,y^1,\dots,y^k)$ be the standard coordinates of $\Rbb^d\times\Rbb^k$. Let $\Omega$ be an open subset of $\Rbb^d\times\Rbb^k$, and let $M\subset\Omega$. Assume that there exists a $C^r$-map $f=(f^1,\dots,f^k):\Omega\rightarrow\Rbb^k$ satisfying the following conditions:
\begin{itemize}
\item $M\cap\Omega$ equals the zero set $Z(f)\equiv\eqref{eq377}$.
\item $\Jac_yf\equiv(\partial_{y^j}f^i)_{1\leq i,j\leq k}$ is invertible at some point $p\in M$. 
\end{itemize} 
Then there exists $U\in\Nbh_\Omega(p)$ such that $M\cap U$ is a $C^r$-submanifold of $\Rbb^d\times\Rbb^k$, and that $(M\cap U,x|_{M\cap U})$ is a (global) chart on $M\cap U$.
\end{thm}

Note that $\dim M\cap U=d$, and $x(M\cap U)$ is an open subset of $\Rbb^d$.

\begin{proof}
This is clear from Cor. \ref{lb932}; the fact that $(M\cap U,x|_{M\cap U})$ is a chart is due to Rem. \ref{lb935} and Exp. \ref{lb941}.
\end{proof}



\begin{co}\label{lb957}
Assume the setting of Thm. \ref{lb950}. Then, by Prop. \ref{lb947}, every $C^r$-function on $M\cap U$ is a $C^r$-function of $x^1,\dots,x^d$. In particular, for each $1\leq i\leq k$ there exists a unique $g^i:x(M\cap U)\rightarrow\Rbb$ (which is automatically $C^r$) such that
\begin{align}\label{eq378}
y^i|_{M\cap U}=g^i\circ (x^1,\dots,x^d)|_{M\cap U}
\end{align}
Consequently, the inverse map of the diffeomorphism $x|_{M\cap U}$ is
\begin{gather}\label{eq379}
\begin{gathered}
\id\vee g:x(M\cap U)\xrightarrow{\simeq} M\cap U\\
a=(a_1,\dots,a_d)\mapsto (a_1,\dots,a_d,g^1(a),\dots,g^k(a))
\end{gathered}
\end{gather}
\end{co}

As we will see in Exp. \ref{lb958}, \eqref{eq379} means that $M\cap U$ is the graph (manifold) of the $C^r$-map $g:x(M\cap U)\rightarrow \Rbb^k$.

\begin{proof}
Since $y^i:U\rightarrow\Rbb$ is smooth, and since the inclusion $M\cap U\hookrightarrow U$ is $C^r$ (by Prop. \ref{lb952}), their composition $y^i|_{M\cap U}$ is also $C^r$. This proves the existence of $g^i$ satisfying \eqref{eq378}. To see \eqref{eq379}, apply \eqref{eq378} to any point $(a_1,\dots,a_d,b_1,\dots,b_k)$ of $M\cap U$ to conclude $b_j=g^j(a)$.
\end{proof}




\begin{rem}
In Cor. \ref{lb957}, let $a=(p_1,\dots,p_d)$ if $p=(p_1,\dots,p_n)$. Recall that $\Jac_yf|_p$ is invertible. Then $\Jac g|_q$ can be solved by
\begin{align}\label{eq380}
\Jac_x f|_p+(\Jac_yf|_p)\cdot \Jac g|_a=0
\end{align}
\end{rem}
\begin{proof}
Let $x=(x^1,\dots,x^d)$ now be the standard coordinates of $\Rbb^d$. The range of the map $\id\vee g$ in \eqref{eq379} is inside $Z(f)$. So the function $f\circ (\id\vee g)$ is zero, i.e., $f(x,g(x))=0$. By the chain rule, we see that $\Jac f(x,g(x))|_a$ equals the LHS of \eqref{eq380}.
\end{proof}



\subsection{Examples}

\begin{co}\label{lb956}
Let $M\subset\Rbb^n$. Suppose that for each $p\in M$ there exist $\Omega\in\Nbh_{\Rbb^n}(p)$ and a  $C^r$-map $f=(f^1,\dots,f^{k_p}):\Omega\rightarrow\Rbb^{k_p}$ (where $0\leq k_p\leq m$) satisfying the following statements:
\begin{itemize}
\item $M\cap \Omega$ equals the zero set $Z(f)$.
\item $d f|_p:\Rbb^n\rightarrow\Rbb^{k_p}$ is surjective. 
\end{itemize}
Then $M$ is a $C^r$-submanifold of $\Rbb^n$. Moreover, if $p\in M$ and $k_p$ are as above, then $\dim_p M=n-k_p$.
\end{co}


\begin{proof}
Since $\Jac f|_p$ is surjective, one can find $d_p=n-k_p$ rows of $\Jac f|_p$ forming a $d_p\times d_p$ invertible matrix. Therefore, the Jacobian of $f$ over the corresponding $d_p$ variables is invertible at $p$. Thus, by the implicit function Thm. \ref{lb950}, there exists $U\in\Nbh_\Omega(p)$ such that $M\cap U$ is a submanifold of $\Rbb^n$. Moreover, $\dim M\cap U=d_p$ since (by Thm. \ref{lb950}) $M\cap U$ has a global chart consisting of $d_p$ variables. 

We have proved that $M$ is locally a $C^r$-submanifold of $\Rbb^n$. By Rem. \ref{mc29}, $M$ is (globally) a $C^r$-submanifold of $\Rbb^n$.
\end{proof}



\begin{eg}\label{lb958}
Let $F:M\rightarrow N$ be a $C^r$-map of $C^r$-manifolds. Define the \textbf{graph} of $F$ \index{00@Graph of a map} to be
\begin{align}
\fk G(F)=\{(p,q)\in M\times N:q=F(p)\}
\end{align}
Then $\fk G(F)$ is a $C^r$-submanifold of the product manifold $M\times N$ (cf. Exp. \ref{lb953}), and hence is a $C^r$-submanifold of any open subset of $M\times N$ containing $\fk G(F)$. 

Moreover, the (clearly $C^r$) projection $\pi_M:M\times N\rightarrow M$ restricts to a $C^r$-diffeomorphism
\begin{align}
\pi_M|_{\fk G(F)}:\fk G(F)\xrightarrow{\simeq} M
\end{align}
Therefore, its inverse map
\begin{align}
\id_M\vee F:M\rightarrow\fk G(F)\qquad p\mapsto (p,F(p))
\end{align}
is also a $C^r$-diffeomorphism.  \hfill\qedsymbol
\end{eg}


\begin{proof}
Suppose we can prove that $\fk G(F)$ is a submanifold. Since $\fk G(F)\hookrightarrow M\times N$ is $C^r$ (Prop. \ref{lb952}), its composition with $\pi_M:M\times N\rightarrow M$ (which is $\pi_M|_{\fk G(F)}$) is $C^r$. The map $\id_M\vee F:M\rightarrow M\times N$ is clearly $C^r$. Thus, by Prop. \ref{lb955}, $\id_M\vee F:M\rightarrow\fk G(F)$ is $C^r$. This proves that $\pi_M|_{\fk G(F)}$ is a $C^r$-diffeomorphism.

To check that $\fk G(F)$ is a submanifold, by Rem. \ref{mc29}, it suffices to check that for each $(p,q)\in\fk G(F)$ there exist $U\in\Nbh_M(p)$ and $V\in\Nbh_N(q)$ such that $\fk G(F)\cap (U\times V)$ is a submanifold of $U\times V$. Therefore, by shrinking $M,N$ and applying diffeomorphisms, it suffices to assume that $M,N$ are open subsets of $\Rbb^d,\Rbb^k$ respectively. Let $(x,y)=(x^1,\dots,x^d,y^1,\dots,y^k)$ be the standard coordinates of $\Rbb^d\times\Rbb^k$. (So $x$ is just the projection $\pi_M$.) Let $f=(f^1,\dots,f^k):M\times N\rightarrow \Rbb^k$ be defined by $f^i=y^i-F^i\circ x$. Then $\Jac_yf=1$ everywhere on $M\times N$. Since $Z(f)=\fk G(F)$, by Cor. \ref{lb956}, $\fk G(F)$ is a $C^r$-submanifold of $M\times N$.
\end{proof}


\begin{eg}\label{lb960}
Let $n\in\Nbb$. Then the \pmb{$n$}\textbf{-sphere} \index{Sn@$\Sbb^n$} 
\begin{align}
\Sbb^n=\{p\in\Rbb^{n+1}:\Vert p\Vert=1\}
\end{align}
is an $n$-dimensional $C^\infty$-submanifold of $\Rbb^{n+1}$ and has an atlas $\fk U=\{(U_k^+,\varphi_k^+),(U_k^-,\varphi_k^-):0\leq k\leq n\}$ where
\begin{gather*}
U_k^\pm=\{p\in\Sbb^n: \pm x^k(p)>0\}\qquad \varphi^\pm_k=\pi_k|_{U_k^\pm}:U_k^\pm\xlongrightarrow{\simeq}B_{\Rbb^n}(0,1)
\end{gather*}
and $\pi_k:\Rbb^{n+1}\rightarrow\Rbb^n$ sends $(a_0,\dots,a_n)$ to $(a_0,\dots,a_{k-1},a_{k+1},\dots,a_n)$.
\end{eg}

\begin{proof}
$U_0^\pm$ is the graph of the $C^\infty$ function $B_{\Rbb^n}(0,1)\rightarrow \Rbb,q\mapsto \pm\sqrt{1-\Vert q\Vert^2}$. Therefore, by Exp. \ref{lb958}, $U_0^\pm$ is a $C^\infty$-submanifold of $B_{\Rbb^n}(0,1)\times\Rbb$, and $\varphi_0^\pm:U_0^\pm\xrightarrow{\simeq}B_{\Rbb^n}(0,1)$ is a diffeomorphism. Similarly, each $U_k^\pm$ is a $C^\infty$-submanifold of $\Rbb^{n+1}$, and $\varphi_k^\pm:U_k^\pm\xrightarrow{\simeq}B_{\Rbb^n}(0,1)$ is a diffeomorphism. Since all such $U_k^\pm$ form an open cover of $\Sbb^n$, we conclude from Rem. \ref{mc29} that $\Sbb^n$ is a $C^\infty$-submanifold of $\Rbb^{n+1}$.
\end{proof}


\begin{eg}
By Exp. \ref{lb960}, $\Sbb^1$ is a smooth submanifold of $\Rbb^2$. Therefore, by Exe. \ref{lb959}, the torus $\Sbb^1\times\Sbb^1$ is a smooth submanifold of $\Rbb^2\times\Rbb^2$, and the cylinder $\Sbb^1\times\Rbb$ is a smooth submanifold of $\Rbb^2\times\Rbb^1$.
\end{eg}








It is not always convenient to prove that a subset $M\subset\Rbb^n$ is a submanifold by showing that $M$ is locally a graph. In that case, one should use Cor. \ref{lb956} instead.

\begin{eg}
The order-$n$ \textbf{special linear group}
\begin{align}
\SL(n,\Rbb)=\{A\in\Rbb^{n\times n}:\det A=1\}
\end{align}
is a smooth submanifold of $\Rbb^{n\times n}$ of dimension $n^2-1$.
\end{eg}

\begin{proof}
Let $f:A\in\Rbb^{n\times n}\mapsto \det(A)\in\Rbb$. By Cor. \ref{lb956}, it suffices to show that $\Jac f$ is non-zero at any $B\in\SL(n,\Rbb)$. Since $\det B\neq 0$, $B$ has a non-zero minor, say the $k\times l$ minor $M_{k,l}=\det (B_{i,j})_{i\neq k,j\neq l}$. The partial derivative of $f$ over the $k\times l$ entry at $B$ is $(-1)^{k+l}M_{k,l}$, which is nonzero.
\end{proof}


Cor. \ref{lb956} is useful for checking that a subset of $\Rbb^n$ is a submanifold. However, it is not useful for finding local parametrizations. Suppose that $M$ is a submanifold of $\Rbb^n$, $U$ is an open subset of $\Rbb^d$, and $\Phi:U\rightarrow \Rbb^n$ is an injective $C^r$-map whose range is $M$. Under what assumptions is $\Phi$ a parametrization of $M$, i.e., a $C^r$-diffeomorphism from $U$ to $M$? We will answer this question in the next chapter.







\newpage


\section{Differential calculus on manifolds}


Starting from this chapter, we will be mainly concerned with $C^\infty$-manifolds. However, all the results proved for $C^\infty$-manifolds can be proved in the same way for $C^r$-manifolds (where $r\geq1$). Therefore, the reader is free to replace ``$\infty$" with ``$r$" in all definitions and properties.


\subsection{Preliminaries in linear algebra}\label{lb966}

We review some basic facts in linear algebra. Let $\Fbb$ be a field. For simplicity, take $\Fbb\in\{\Rbb,\Cbb\}$. Let $V$ be a finite-dimensional vector space over $\Fbb$. Suppose that $V$ has basis $e_1,\dots,e_m$. Then the dual space $V^*$ has a unique basis $\wch e^1,\dots,\wch e^m$ (called the \textbf{dual basis} \index{00@Dual basis} of $e_1,\dots,e_m$) determined by \index{e@$\wch e^i$, dual basis}
\begin{align}\label{eq504}
\bk{e_i,\wch e^j}=\delta_i^j=\left\{
\begin{array}{ll}
1&\text{if }i=j\\
0&\text{if }i\neq j
\end{array}
\right.
\end{align} 
Then for each $\xi\in V$ we have
\begin{align}\label{eq394}
\xi=\sum_i\bk{\xi,\wch e^i}e_i
\end{align}
since both sides are equal to $\bk{\xi,\wch e^j}$ when evaluated with $\wch e^j$. %Therefore, If $W$ is a vector space and $T\in\Lin(V,W)$, then for each $\xi\in V$ we have
%\begin{align}
%T\xi=\sum_i Te_i\cdot \bk{\wch e^i,\xi}
%\end{align} 
Similar to \eqref{eq504}, for each $\psi\in V^*$ we have
\begin{align}\label{eq400}
\psi=\sum_i \bk{\psi,e_i}\wch e^i
\end{align}




Let $T:V\rightarrow W$ be a linear map where $W$ is finite-dimensional with basis $f_1,\dots,f_n$. The \textbf{matrix representation} \index{00@Matrix representation} $A$ of $T$ under the bases $e_\blt,f_\star$ is the unique $n\times m$ matrix such that the following relation holds:
\begin{align}\label{eq386}
T(e_1,\dots,e_m)=(f_1,\dots,f_n)A
\end{align}
There are two ways to understand this relation. One can view both sides as matrix multiplications, where the LHS is $1\times 1$ times $1\times m$, and the RHS is $1\times n$ times $n\times m$. Write 
\begin{align}
A=(A^i_j)_{
\begin{subarray}{c}
1\leq i\leq n\\
1\leq j\leq m
\end{subarray}
}
\end{align}
where $A^i_j$ is the $i\times j$ entry of $A$. Then \eqref{eq386} means that for each $1\leq j\leq m$,
\begin{align}\label{eq387}
Te_j=\sum_{i=1}^n f_i\cdot A^i_j
\end{align}
From \eqref{eq387}, it is clear that
\begin{align}
A^i_j=\bk{Te_j,\wch f^i}
\end{align}
This justifies our convention that the row index $i$ of $A^i_j$ is written as a superscript.

Alternatively, one can view $(e_1,\dots,e_m)$ as a linear map
\begin{align}\label{eq388}
e_\blt=(e_1,\dots,e_m):\Fbb^m\xrightarrow{\simeq} V
\end{align}
sending the $j$-th standard basis vectors of $\Fbb^m$ to $e_j$. It is a linear isomorphism, called the \textbf{canonical isomorphism associated to the basis $e_1,\dots,e_m$}. The linear isomorphism $f_\star=(f_1,\dots,f_n):\Fbb^n\xrightarrow{\simeq} W$ is understood in a similar way. Then \eqref{eq386} is a relation of linear maps: when the LHS (resp. RHS) of \eqref{eq386} acts on the $j$-th standard basis vector of $\Fbb^m$, it becomes the LHS (resp. RHS) of \eqref{eq387}. (Therefore, the two views on \eqref{eq386} are consistent.) Equivalently, \eqref{eq386} can be interpreted as the commutative diagram
\begin{equation}
\begin{tikzcd}
V \arrow[r,"T"] \arrow[from=d,"e_\blt","\simeq"'] & W \arrow[from=d,"f_\star"',"\simeq"] \\
\Fbb^m \arrow[r,"A"]           & \Fbb^n          
\end{tikzcd}
\end{equation}



The \textbf{transpose} \index{00@Transpose of a linear map} \index{Tt@$T^\tr$, the transpose of $T$} of $T:V\rightarrow W$ is the linear $T^\tr:W^*\rightarrow V^*$ defined by
\begin{align}
T^\tr w'=w'\circ T
\end{align}
for each $w'\in W^*$. Therefore, for each $v\in V$ and $w'\in W^*$ we have
\begin{gather*}
\bk{Tv,w'}=\bk{v,T^\tr w'}
\end{gather*}
Then, assuming \eqref{eq386}, we have
\begin{align}\label{eq401}
\left(
\begin{array}{c}
\wch f^1\\
\vdots\\
\wch f^n
\end{array}
\right)\circ T
=A\left(
\begin{array}{c}
\wch e^1\\
\vdots\\
\wch e^m
\end{array}
\right)
\end{align}
where the LHS is the multiplication of an $n\times 1$ matrix and a $1\times 1$ matrix, and the RHS is the multiplication of an $n\times m$ matrix and an $m\times 1$ matrix. In other words, for each $1\leq i\leq n$ we have
\begin{align}\label{eq458}
T^\tr \wch f^i=\sum_{j=1}^m A_j^i\wch e^j
\end{align}
This relation holds true because both sides equal $\bk{Te_j,\wch f^i}=A^i_j$ when evaluated with $e_j$.

\eqref{eq401} also means that $A^\tr$ is the matrix representation of $T^\tr$ under the basis $\wch f$ and $\wch e$, i.e.,
\begin{align}\label{eq460}
T^\tr(\wch f^1,\dots,\wch f^n)=(\wch e^1,\dots,\wch e^m)A^\tr
\end{align}
However, in differential calculus, it would be more convenient if the superscript $i$ of $\wch f^i$ is always a row index. Therefore, we write the dual basis as a column (as in \eqref{eq401}) rather than as a row. %(This is consistent with our convention in linear algebra of writing a vector of $\Fbb^n$ as a column vector.)

\subsection{Tangents spaces and cotangent spaces}\label{lb997}


Throughout this section, we let $M$ be a smooth manifold. 

We shall first define tangent vectors in a general and abstract way. Then, we shall show that if $\gamma$ is a smooth path in $\Rbb^n$, the derivative $\gamma'(t)$, as an abstract vector, is equal to the usual derivative. To avoid conflict of notations, we denote the latter by $\Jac\gamma|_t$, which is an $n\times 1$ matrix (at each $t$).



\begin{df}\label{lb961}
A $C^\infty$-map $\gamma:(a,b)\rightarrow M$ is called a \textbf{(smooth) path}. Let $p\in M$. Define
\begin{align}
T_pM=\big\{\text{smooth path }\gamma\in M^{(-\eps,\eps)}:\eps>0,\gamma(0)=p  \big\}\big/\sim
\end{align}
where $\sim$ is the equivalence relation such that $\gamma_1\sim\gamma_2$ iff there exists a chart $(U,\varphi)$ containing $p$ such that
\begin{align}\label{eq381}
\Jac(\varphi\circ\gamma_1)|_0=\Jac(\varphi\circ\gamma_2)|_0
\end{align}
We call $T_pM$ the \textbf{tangent space} of $M$ at $p$. \index{00@Tangent space} \index{TpM@$T_pM,TM$} The elements in $T_pM$ are call \textbf{tangent vectors}. \index{00@Tangent vectors} If $I$ is an open interal and $\gamma:I\rightarrow M$ is a smooth path in $M$, for each $t_0\in I$, the equivalence class of the path $t\mapsto \gamma(t+t_0)$ in $T_pM$ is denoted by \index{zz@$\gamma'$, the derivative of a path $\gamma$ in a manifold}
\begin{align}
\gamma'(t_0)\equiv \frac {d\gamma}{dt}\big|_{t_0}
\end{align}
and is called the \textbf{derivative} of $\gamma$ at $t_0$. Define the \textbf{tangent bundle} \index{00@Tangent bundle} 
\begin{align}
TM=\bigsqcup_{p\in M}T_pM
\end{align}
If $U\subset M$ is open, we understand $TU$ as a subset of $TM$. A function $X:M\rightarrow TM$ is called a \textbf{vector field} \index{00@Vector field} if for each $p\in X$, the element $X(p)\equiv X_p$ belongs to $T_pM$. 
\end{df}

\begin{rem}
Suppose that \eqref{eq381} is true, then for each chart $(V,\psi)$ containing $p$ we also have
\begin{align}
\Jac(\psi\circ\gamma_1)|_0=\Jac(\psi\circ\gamma_2)|_0
\end{align}
because of the chain rule
\begin{align}\label{eq383}
\Jac(\psi\circ\gamma_i)|_0=\Jac(\psi\circ\varphi^{-1})|_{\varphi(p)}\cdot\Jac(\varphi\circ\gamma_i)|_0
\end{align}
\end{rem}



\begin{thm}\label{lb962}
Let $p\in M$. For each chart $(U,\varphi)=(U,\varphi^1,\dots,\varphi^n)$ containing $p$, there is a bijection $d\varphi|_p$ (abbreviated to $d\varphi$) defined by
\begin{gather}\label{eq382}
d\varphi:T_pM\rightarrow\Rbb^n\qquad d\varphi\cdot \gamma'(0)=\Jac(\varphi\circ\gamma)|_0
\end{gather}
where $\gamma$ is a smooth path in $M$ satisfying $\gamma(0)=p$. Moreover, for any other chart $(V,\psi^1,\dots,\psi^n)$ containing $p$, the following diagram commutes:
\begin{equation}\label{eq384}
\begin{tikzcd}[row sep=large]
             & T_pM \arrow[ld,"d\varphi"'] \arrow[rd,"d\psi"] &   \\
\Rbb^n \arrow[rr,"{\Jac(\psi\circ\varphi^{-1})\big|_{\varphi(p)}}"',"\simeq"] &                         & \Rbb^n
\end{tikzcd}
\end{equation}
\end{thm}

Note that by the chain rule Thm. \ref{lb578}, the Jacobian of any diffeomorphism (and in particular $\psi\circ\varphi^{-1}$) is invertible everywhere.


\begin{proof}
Let $\gamma_1,\gamma_2$ be two paths in $M$ satisfying $\gamma_i(0)=p$. Then $\gamma_1\sim\gamma_2$ means $\gamma_1'(0)=\gamma_2'(0)$. This happens (by Def. \ref{lb961}) iff $\Jac(\varphi\circ\gamma_1)|_0\equiv d\varphi\cdot\gamma_1'(0)$ equals $\Jac(\varphi\circ\gamma_2)|_0\equiv d\varphi\cdot\gamma_2'(0)$. So we have a well-defined injective map \eqref{eq382}. If $\xi\in\Rbb^n$, then $\Jac(\varpi\circ\gamma)|_0=\xi$ if we let
\begin{align}
\gamma(t)=\varphi^{-1}(\varphi(p)+t\xi)
\end{align}
This proves that $\varphi_*$ is bijective. By \eqref{eq383}, the diagram \eqref{eq384} commutes.
\end{proof}

\begin{df}\label{lb963}
By Thm. \ref{lb962}, we can define an $\Rbb$-vector space structure on $T_pM$ such that for any chart $(U,\varphi)$ containing $p$, the map $d\varphi:T_pM\rightarrow\Rbb^n$ is an isomorphism of vector spaces. That this linear structure is independent of the choice of $(U,\varphi)$ is due to the commutativity of the diagram \eqref{eq384}. Let $e_1,\dots,e_n$ be the standard basis of $\Rbb^n$. For each $1\leq i\leq n$, define the tangent field \index{zz@$\partial_{\varphi^i}=\frac\partial{\partial\varphi^i}$}
\begin{gather*}
\partial_{\varphi^i}\equiv\frac\partial{\partial\varphi^i}:U\rightarrow TM\qquad \partial_{\varphi^i}|_p:=(d\varphi|_p)^{-1}e_i
\end{gather*}
So the inverse of $d\varphi|_p:T_pM\rightarrow\Rbb^n$ is the canonical isomorphism associated to the basis $\partial_{\varphi^1}|_p,\dots,\partial_{\varphi^n}|_p$ (cf. \eqref{eq388}).
\end{df}

\begin{cv}
Unless otherwise stated, for each $p\in\Rbb^n$, we identify $T_p\Rbb^n$ with $\Rbb^n$ via the map $dx=d(x^1,\dots,x^n):T_p\Rbb^n\xrightarrow{\simeq}\Rbb^n$ where $x=(x^1,\dots,x^n)$ is the standard coordinate of $\Rbb^n$. Under this identification, if $\gamma$ is a path in $\Rbb^n$, then it is clear that 
\begin{align}
\gamma'(t)=\Jac\gamma|_t
\end{align}
Moreover, let $e_1,\dots,e_n$ be the standard basis of $\Rbb^n$. Then
\begin{align}\label{eq391}
\partial_{x^i}=e_i
\end{align}
\end{cv}

%% Record #18 2024/05/06 two lectures  43

\begin{df}
The \textbf{cotangent bundle} \index{00@Cotangent bundle} \index{TM@$T^*M,T^*_pM$} is defined to be
\begin{align*}
T^*M=\bigsqcup_{p\in M} T^*_pM
\end{align*}
where $T^*_pM$ is the (real) dual space $(T_pM)^*$ of $T_pM$, called the \textbf{cotangent space} of $M$ at $p$. The elements in $T^*_pM$ are called \textbf{cotangent vectors} \index{00@Cotangent vectors} at $p$. A function
\begin{align*}
\omega:M\rightarrow T^*M
\end{align*} 
satisfying $\omega|_p\in T_p^*M$ for all $p\in M$ is called a \pmb{$1$}\textbf{-form} on $M$. \index{00@$1$-form}
\end{df}




\subsection{Differentials of smooth maps}\label{lb973}

Fix a smooth manifold $M$.

\begin{thm}\label{lb967}
Let $F:M\rightarrow N$ be a $C^\infty$-map of smooth manifolds. Then for each $p\in M$ and $q=F(p)$, there is a unique linear map $dF|_p$ (abbreviated to $dF$) described by
\begin{gather}\label{eq385}
dF:T_pM\rightarrow T_qN\qquad dF\cdot \gamma'(0)=(F\circ\gamma)'(0)
\end{gather}
for each smooth path $\gamma$ in $M$ satisfying $\gamma(0)=p$. We call $dF$ the \textbf{differential} \index{00@Differential of a map} \index{dF@$dF$, the differential of the map} of $F$.

Moreover, if $(U,\varphi^1,\dots,\varphi^m)$ and $(V,\psi^1,\dots,\psi^n)$ are charts of $M,N$ containing $p,q$ respectively, then the matrix representation of $dF|_p$ under the bases $\partial_{\varphi^1},\dots,\partial_{\varphi^m}$ and $\partial_{\psi^1},\dots,\partial_{\psi^n}$ is $\Jac(\psi\circ F\circ\varphi^{-1})|_{\varphi(p)}$, i.e. (cf. \eqref{eq386}), 
\begin{align}\label{eq389}
dF|_p\cdot\Big(\frac\partial{\partial\varphi^1},\dots,\frac\partial{\partial\varphi^m}\Big)_p=\Big(\frac\partial{\partial\psi^1},\dots,\frac\partial{\partial\psi^n}\Big)_q\cdot\Jac(\psi\circ F\circ\varphi^{-1})\big|_{\varphi(p)}
\end{align}
\end{thm}

Note that if $N$ is an open subset of $\Rbb^n$ and $F$ is a diffeomorphism, under the identification $T_qN=\Rbb^n$, the meaning of $dF$ in \eqref{eq385} coincides with the one in \eqref{eq382}. If $M$ is also an open subset of $\Rbb^m$, under the identification $T_pM=\Rbb^m$, the meaning of $dF|_p$ agrees with the one in Def. \ref{lb576}, namely, it equals the Jacobian $\Jac F|_p$.

It is also common to write $dF$ as $F_*$.

\begin{proof}
The uniqueness is obvious since the elements of $T_pM$ can be written in the form $\gamma'(0)$. To prove the existence, we let $(U,\varphi)$ and $(V,\psi)$ be the charts of $M$ and $N$ containing $p,q$ respectively. Then we can define $dF|_p$ to be the linear map satisfying \eqref{eq389}. More precisely, we let $dF|_p:T_pM\rightarrow T_qN$ be the unique linear map such that the following diagram commutes:
\begin{equation}
\begin{tikzcd}[row sep=large, column sep=4cm]
T_pM \arrow[r,"dF|_p"] \arrow[d,"d\varphi|_p"',"\simeq"] & T_qN \arrow[d,"d\psi|_q","\simeq"'] \\
\Rbb^m \arrow[r,"{\Jac(\psi\circ F\circ\varphi^{-1})\big|_{\varphi(p)}}"]           & \Rbb^n         
\end{tikzcd}
\end{equation}
Note that $d\varphi|_p$ is the inverse of the canonical isomorphism associated to the basis $\partial_\varphi=(\partial_{\varphi^1},\dots,\partial_{\varphi^m})$, and $d\psi|_q$ is similar. We shall show that $dF|_p$ satisfies \eqref{eq385}. 

Choose any path $\gamma$ in $M$ satisfying $\gamma(0)=p$. Then by \eqref{eq382},
\begin{align*}
d\psi|_q\cdot (F\circ\gamma)'(0)=\Jac(\psi\circ F\circ\gamma)|_0
\end{align*}
The arrows $\downarrow_\rightarrow\uparrow$ send $\gamma'(0)$ first to $\Jac (\varphi\circ\gamma)|_0$, and then (by the chain rule) to
\begin{align*}
\Jac(\psi\circ F\circ\varphi^{-1})|_{\varphi(p)}\cdot \Jac (\varphi\circ\gamma)|_0=\Jac (\psi\circ F\circ \gamma)|_0
\end{align*}
and finally to 
\begin{align*}
(d\psi|_q)^{-1}\Jac (\psi\circ F\circ \gamma)|_0=(F\circ\gamma)'(0)
\end{align*}
Therefore, the top horizontal arrow $dF|_p$, which equals $\downarrow_\rightarrow\uparrow$, sends $\gamma'(0)$ to $(F\circ\gamma)'(0)$.
\end{proof}

\begin{rem}
The differential of the identity map $\id:M\rightarrow M$ at $p$ is clearly the identity map of $T_pM$. Let $F:M\rightarrow N$ and $G:N\rightarrow P$ be smooth maps of $C^\infty$-manifolds. From the definition of differentials, for each $p\in M$, we clearly have the \textbf{chain rule} \index{00@Chain rule for maps of manifolds}
\begin{align}\label{eq390}
d(G\circ F)|_p=dG|_{F(p)}\cdot dF|_p
\end{align}
This seems at odds with our proof of Thm. \ref{lb578}, where the chain rule does not follow directly from the definition of differentials. In fact, there is nothing strange here. The difficulty of the proof of \eqref{eq390} lies in proving that the vector space structures on the tangent spaces are well-defined (Thm. \ref{lb962}), and that the differentials of smooth maps are well-defined (Thm. \ref{lb967}). In the proofs of both theorems we have used the (classical) chain rule Thm. \ref{lb578}.
\end{rem}

\begin{eg}\label{lb968}
Let $\gamma:I\rightarrow M$ be a smooth path in $M$, which can be viewed as a smooth map of manifolds. Let $t:(a,b)\rightarrow\Rbb$ be the standard coordinate so that (by \eqref{eq391}) $\frac\partial{\partial t}\equiv\partial_t$ is the standard basis of $\Rbb$. Then for each $t_0\in I$, the differential $d\gamma|_{t_0}:\Rbb\simeq T_{t_0}\Rbb\rightarrow T_{\gamma(t_0)}M$ clearly satisfies
\begin{align*}
\gamma'(t_0)=d\gamma|_{t_0}\cdot\partial_t
\end{align*}
\end{eg}

\begin{co}\label{mc154}
Let $(U,\varphi^1,\dots,\varphi^n)$ and $(V,\psi^1,\dots,\psi^n)$ be charts of $M$ containing $p\in M$. Then
\begin{align}
\Big(\frac\partial{\partial\varphi^1},\dots,\frac\partial{\partial\varphi^n}\Big)_p=\Big(\frac\partial{\partial\psi^1},\dots,\frac\partial{\partial\psi^n}\Big)_p\cdot\Jac (\psi\circ\varphi^{-1})\big|_{\varphi(p)}
\end{align}
In other words, for each $1\leq j\leq n$ we have
\begin{align}\label{eq393}
\frac\partial{\partial\varphi^j}\Big|_p=\sum_{i=1}^n \partial_j (\psi^i\circ\varphi^{-1})\big|_{\varphi(p)}\cdot\frac\partial{\partial\psi^i}\Big|_p
\end{align}
\end{co}
\begin{proof}
Apply Thm. \ref{lb967} to the identity map of $M$.
\end{proof}



If $f\in C^\infty(U,\Rbb)$, it is customary to write
\begin{align}\label{eq392}
\frac{\partial f}{\partial\varphi^j}\Big|_p:=\partial_j (f\circ\varphi^{-1})\big|_{\varphi(p)}
\end{align}
The reason is that if $U\subset\Rbb^n$ and $\varphi$ is the standard coordinate of $\Rbb^n$, then \eqref{eq392} is the usual partial derivative. Therefore, \eqref{eq393} reads
\begin{align}\label{eq396}
\frac\partial{\partial\varphi^j}\Big|_p=\sum_{i=1}^n \frac{\partial \psi^i}{\partial\varphi^j}\Big|_p\cdot\frac\partial{\partial\psi^i}\Big|_p
\end{align}
often abbreviated to $\dps\frac\partial{\partial\varphi^j}=\sum_{i=1}^n \frac{\partial \psi^i}{\partial\varphi^j}\cdot\frac\partial{\partial\psi^i}$. One immediately notices the similarity between this relation and \eqref{eq394}. In the next section, we will make this similarity and the notation \eqref{eq392} rigorous by interpreting $\frac{\partial f}{\partial\varphi^i}|_p$ as the evaluation of $\partial_{\varphi^i}|_p\in T_pM$ and a vector in $T^*_pM$.


The following example shows that $\partial f/\partial\varphi^i$ can simply be calculated by expressing $f$ as a function of $\varphi^1,\dots,\varphi^n$ and taking the $i$-th partial derivative.

\begin{eg}\label{lb974}
Let $M$ be the set of all $(x,y,z)\in\Rbb^3$ satisfying
\begin{align*}
z=x^2+y^2\qquad x>0,y>0,z<1
\end{align*}
Then $M$ is the graph of the function $z=x^2+y^2$ defined on $D=\{(x,y):x>0,y>0,x^2+y^2<1\}$. Therefore, by Exp. \ref{lb958}, $M$ is a $2$-dimensional submanifold of $\Rbb^3$, and $(M,x,y)$ is a global chart on $M$. By the polar coordinates (Exp. \ref{lb969}), $(M,r,\theta)$ is a global chart on $M$ where
\begin{gather*}
(r,\theta):M\xrightarrow{\simeq}\Delta=(0,1)\times(0,\pi/2)\\
r(a,b,c)=\sqrt c\qquad \theta(a,b,c)=\arcsin(b/\sqrt c)
\end{gather*}
Similarly, $M$ is also the graph of $x=\sqrt{z-y^2}$ on $\Omega=\{(y,z):y>0,y^2<z<1\}$. So $M$ has a global chart $(M,y,z)$ where
\begin{gather*}
(y,z):M\xrightarrow{\simeq}\Omega\\
y(a,b,c)=b\qquad z(a,b,c)=c
\end{gather*}
For each $p=(a,b,a^2+b^2)\in M$, express $\partial_r|_p$ and $\partial_\theta|_p$ in terms of $\partial_y|_p$ and $\partial_z|_p$.
\end{eg}


\begin{proof}
We have the following relations of functions on $M$:
\begin{align*}
y=r\sin\theta\qquad z=r^2
\end{align*}
It can also be interpreted as giving the formula for the diffeomorphism
\begin{gather*}
(y,z)\circ(r,\theta)^{-1}:\Delta\xrightarrow{\simeq}\Omega\qquad (u,v)\mapsto (v\sin u,v^2)
\end{gather*}
We calculate that
\begin{align*}
&\frac\partial{\partial r}\Big|_p=\frac{\partial y}{\partial r}\Big|_p\cdot \frac\partial{\partial y}\Big|_p+\frac{\partial z}{\partial r}\Big|_p\cdot \frac\partial{\partial z}\Big|_p=\sin\theta\big|_p\cdot \frac\partial{\partial y}\Big|_p+2r\big|_p\cdot \frac\partial{\partial z}\Big|_p\\
=&\frac b{\sqrt{a^2+b^2}}\cdot \frac\partial{\partial y}\Big|_p+2\sqrt{a^2+b^2}\cdot \frac\partial{\partial z}\Big|_p
\end{align*}
Similarly, we compute
\begin{align*}
\frac\partial{\partial \theta}\Big|_p=\frac{\partial y}{\partial \theta}\Big|_p\cdot \frac\partial{\partial y}\Big|_p+\frac{\partial z}{\partial \theta}\Big|_p\cdot \frac\partial{\partial z}\Big|_p=r\cos\theta\big|_p\cdot \frac\partial{\partial y}\Big|_p=a\cdot \frac\partial{\partial y}\Big|_p
\end{align*}
\end{proof}



\subsection{Smooth vector fields and $1$-forms}\label{lb998}

Fix a $C^\infty$-manifold $M$. Let $r\in\Nbb\cup\{\infty\}$.


\begin{cv}
Let $X:M\rightarrow TM$ be a vector field. Let $f:M\rightarrow\Rbb$. Then $fX$ denotes the vector field
\begin{align}
f\cdot X:M\rightarrow TM\qquad p\mapsto f(p)X(p)
\end{align}
If $\omega:M\rightarrow T^*M$ is a $1$-form, then the $1$-form $f\cdot \omega:M\rightarrow T^*M$ is understood in a similar way.
\end{cv}

\begin{df}\label{lb970}
Let $X:M\rightarrow TM$ be a vector field. It is clear that for any chart $(U,\varphi^1,\dots,\varphi^n)$, $X|_U$ can be written uniquely as \footnote{This is because for each $p\in U$, $\partial_{\varphi^1}|_p,\dots,\partial_{\varphi^n}|_p$ form a basis of $T_pM$.}
\begin{align}\label{eq395}
X|_U=\sum_{i=1}^n X^i\partial_{\varphi^i}
\end{align}
where $X^i:U\rightarrow \Rbb$. Let $r\in\Nbb\cup\{\infty\}$. We say that $X$ is a  \pmb{$C^r$}\textbf{-vector field} (resp. \textbf{Borel vector field}) \index{00@$C^r$-vector field} \index{00@Borel vector form} if one of the following equivalent statements hold:
\begin{enumerate}
\item[(1)] For every chart $(U,\varphi^1,\dots,\varphi^n)$, the functions $X^1,\dots,X^n$ satisfying \eqref{eq395} are $C^r$ (resp. Borel).
\item[(2)] There exists an atlas $\fk U$ of $M$ such that for any $(U,\varphi^1,\dots,\varphi^n)\in\fk U$, the functions $X^1,\dots,X^n$ satisfying \eqref{eq395} are $C^r$ (resp. Borel).
\end{enumerate}
\end{df}

\begin{proof}[Proof of equivalence]
The equivalence is due to the smoothness of the function $\partial\psi^i/\partial\varphi^j$ in the change-of-coordinate formula \eqref{eq396}.
\end{proof}


\begin{df}
Let $\omega:M\rightarrow T^*M$ be a $1$-form. We say that $\omega$ is a \pmb{$C^r$ $1$}\textbf{-form} (resp. \textbf{Borel} \pmb{$1$}\textbf{-form}) \index{00@$C^r$ $1$-form} \index{00@Borel $1$-form} if for every open $U\subset M$ and every $C^r$ (resp. Borel) vector field $X:U\rightarrow TM$, the function
\begin{gather}
\omega(X)\equiv\bk{\omega,X}:U\rightarrow\Rbb\qquad p\mapsto \bk{\omega|_p,X|_p}
\end{gather}
is $C^r$ (resp. Borel).
\end{df}


Following our usual convention,  a $C^0$ (resp. $C^\infty$) vector field/$1$-form is also called a continuous (resp. smooth) vector field/$1$-form.


\begin{eg}
Let $(U,\varphi)$ be a chart on $M$. Then each $\partial_{\varphi^j}$ is a smooth vector field on $U$.
\end{eg}

We shall show that $C^r$ (resp. Borel) $1$-forms can be described in a similar way as in Def. \ref{lb970}. Therefore, we need to consider the $1$-forms that are dual to the vector fields $\partial_{\varphi^1},\dots,\partial_{\varphi^n}$. We shall define them using differentials of maps, and then show that they are the dual basis of $\partial_{\varphi^1},\dots,\partial_{\varphi^n}$.




\subsubsection{Differentials of functions as $1$-forms}


\begin{df}\label{mc215}
Let $f\in C^\infty(M,\Rbb)$. Then for each $p\in M$, we have a linear map $df|_p:T_pM\rightarrow T_{f(p)}\Rbb\simeq\Rbb$. This gives a $1$-form
\begin{align*}
df:M\rightarrow T^*M\qquad p\in M\mapsto df|_p\in T_p^*M
\end{align*}
called the \textbf{differential} \index{df@$df$, the differential of the function $f$} of the function $f$. For each vector field $X:M\rightarrow TM$, we define $Xf\equiv X(f)$ \index{Xf@$X(f)$} to be the function
\begin{align*}
Xf=\bk{X,df}:M\rightarrow\Rbb\qquad p\mapsto\bk{X|_p,df|_p}
\end{align*}
%More precisely, if we let $t$ be the standard coordinate of $\Rbb$ so that $\partial_t$ is the standard basis of $T_{f(p)}\Rbb$, then
%\begin{align*}
%(Xf)(p)\cdot \partial_t|_p=df|_p\cdot X|_p
%\end{align*}
\end{df}

\begin{rem}
By \eqref{eq385}, we have a more explicit description of $df$: For each smooth path $\gamma$ in $M$ satisfying $\gamma(0)=p$, we have 
\begin{align}\label{eq403}
\bk{df|_p,\gamma'(0)}=(f\circ\gamma)'(0)
\end{align}
Therefore, if $X|_p=\gamma'(0)$, then
\begin{align*}
Xf|_p= (f\circ\gamma)'(0)
\end{align*}
This means that $Xf|_p$ is the ``derivative of $f$ in the direction $X|_p$".
\end{rem}


\begin{pp}\label{lb971}
Let $f\in C^\infty(M,\Rbb)$. Then $df$ is a smooth $1$-form. Moreover, for each chart $(U,\varphi^1)$ and each $p\in M$, we have
\begin{align}\label{eq397}
\frac\partial{\partial\varphi^j}f\Big|_p=\partial_j (f\circ\varphi^{-1})\Big|_{\varphi(p)} 
\end{align}
\end{pp}
This proposition explains the notation \eqref{eq392}. Moreover, \eqref{eq397} can be abbreviated to the following relation of functions on $U$:
\begin{align}\label{eq398}
\boxed{~\partial_{\varphi^j}f=\big(\partial_j(f\circ\varphi^{-1})\big)\circ\varphi~}
\end{align}

\begin{proof}
Note that the identification of $T_{f(p)}\Rbb$ with $\Rbb$ is implemented by $dt$ where $t$ is the standard coordinate of $\Rbb$. By Thm. \ref{lb967}, we have
\begin{align*}
df|_p\cdot(\partial_{\varphi^1},\dots,\partial_{\varphi^n})|_p=\partial_t|_{F(p)}\cdot \Jac(f\circ\varphi^{-1})|_{\varphi(p)}
\end{align*}
where both sides are $1\times n$ matrices. Their $1\times j$ entries are the LHS and the RHS of \eqref{eq397}. This proves \eqref{eq397}. If $X:U\rightarrow TM$ is a smooth vector field, then $X=\sum_{j=1}^n X^j\partial_{\varphi^j}$ for some $X^1,\dots,X^n\in C^\infty(U,\Rbb)$. Then, by the linearity, we have
\begin{align}
Xf=\sum_{j=1}^n X^j\cdot \partial_{\varphi^j}f
\end{align}
Since $\partial_{\varphi^j}f$ is smooth (because the RHS of \eqref{eq398} is smooth), $Xf$ is smooth.
\end{proof}

\begin{co}\label{lb972}
Let $(U,\varphi^1,\dots,\varphi^n)$ be a chart on $M$. Then $d\varphi^1,\dots,d\varphi^n$ are smooth $1$-forms on $U$. Moreover, for each $p\in M$, $d\varphi^1|_p,\dots,d\varphi^n|_p$ are the dual basis of $\partial_{\varphi^1}|_p,\dots,\partial_{\varphi^n}|_p$.
\end{co}

\begin{proof}
By Prop. \ref{lb971}, each $d\varphi^i$ is smooth, and for each $p\in U$ we have
\begin{align*}
\bk{d\varphi^i,\partial_{\varphi^j}}|_p=\partial_{\varphi^j}\varphi^i|_p=\partial_j (\varphi^i\circ\varphi^{-1})|_{\varphi(p)}=\partial_j x^i|_{\varphi(p)}
\end{align*}
where $x^1,\dots,x^n$ are the standard coordinates of $\Rbb^n$. So the above expression equals $\delta_j^i$.
\end{proof}


\begin{co}\label{mc97}
Let $\omega:M\rightarrow T^*M$ be a $1$-form. Then the following are equivalent.
\begin{enumerate}
\item[(1)]  $\omega$ is $C^r$ (resp. Borel).
\item[(2)] For any chart $(U,\varphi^1,\dots,\varphi^n)$ on $M$, the functions $\omega_1,\dots,\omega_n:U\rightarrow\Rbb$ satisfying
\begin{align*}
\omega=\sum_{i=1}^n \omega_id\varphi^i
\end{align*}
are $C^r$ (resp. Borel).
\end{enumerate}
\end{co}

\begin{proof}
Assume (1). Then $\omega|_U$ is $C^r$ (resp. Borel), and hence $\omega_i=\bk{\omega|_U, \partial_{\varphi^i}}$ is $C^r$ (resp. Borel). This proves (2).

Assume (2). Choose any open $V\subset M$ and any $C^r$ (resp. Borel) vector field $X:V\rightarrow TM$. Let us prove that $\bk{X,\omega}$ is $C^r$ (resp. Borel). We discuss the Borel case; the $C^r$-case is similar. (However, the Borel case relies on the second countability, and the $C^r$ case does not.) Since $M$ is second countable, $M$ has an atlas $\fk U$ containing countably many members. Therefore, it suffice to prove that for each $(U,\varphi)\in\fk U$, the restriction of $\bk{X,\omega}$ to $U\cap V$ is Borel.  To see this, we write $X|_{U\cap V}=\sum_i X^i\partial_{\varphi^i}$ where each $X^i:U\cap V\rightarrow\Rbb$ is Borel. Then $\bk{X,\omega}|_{U\cap V}=\sum_iX^i\omega_i|_{U\cap V}$ is Borel.
\end{proof}




\begin{co}\label{lb987}
Let $(U,\varphi^1,\dots,\varphi^n)$ be a chart on $M$. Let $f\in C^\infty(U,\Rbb)$. Then
\begin{align}\label{eq399}
df=\sum_{j=1}^n \frac{\partial f}{\partial\varphi^j}d\varphi^j
\end{align}
where both sides are understood as $1$-forms on $U$.
\end{co}

\begin{proof}
Choose $p\in U$. By \eqref{eq400} and the fact that $d\varphi|_p$ is the dual basis of $\partial_\varphi|_p$ (Cor. \ref{lb972}), we have
\begin{align*}
df|_p=\sum_j \bk{df,\partial_{\varphi^j}}|_p\cdot d\varphi^j|_p=\sum_j\partial_{\varphi^j}f|_p\cdot d\varphi^j|_p
\end{align*}
\end{proof}

\begin{co}[\textbf{Leibniz rule}]
Let $f,g\in C^\infty(M,\Rbb)$. \index{00@Leibniz rule for functions on manifolds} Then the following holds as a relation of $1$-forms:
\begin{align}\label{eq554}
d(fg)=gdf+fdg
\end{align}
\end{co}
\begin{proof}
It suffices to choose any chart $(U,\varphi)$ and use \eqref{eq399} to check $d(fg)=gdf+fdg$ on $U$. Then this relation holds since (by \eqref{eq398}) one has $\partial_{\varphi^i}(fg)=g\partial_{\varphi^i}f+f\partial_{\varphi^i}g$.
\end{proof}


Notice the similarity between \eqref{eq399} and the following relation (cf. \eqref{eq396}) of vector fields on $U$ (where $\psi^1,\dots,\psi^n$ are coordinates on $U$)
\begin{align}
\frac\partial{\partial\psi^j}=\sum_{i=1}^n\frac{\partial\varphi^i}{\partial\psi^j}\frac\partial{\partial\varphi^i}
\end{align}
However, unlike $\eqref{eq399}$, the symbol $\frac\partial{\partial f}$ does not make sense unless when $f$ is a coordinate of an atlas $(U,f,\varphi^2,\dots,\varphi^n)$. Moreover, unlike $df$, the meaning of $\frac\partial{\partial f}$ depends not only on $f$ but also on the other coordinates $\varphi^2,\dots,\varphi^n$ of the atlas: 

\begin{eg}
$\Rbb^2$ has two coordinates: $(x,y)$ and $(x,x+y)$. However, the vector fields $\frac{\partial}{\partial x}$ defined by these two sets of coordinates are different. To clarify the subtlety, we write $(x,x+y)$ as $(u,v)$. Then $\partial_x$ (defined by the coordinates $(x,y)$) is not equal to $\partial_u$ since $x=u,y=v-u$ implies
\begin{align*}
\frac\partial{\partial u}=\frac{\partial x}{\partial u}\frac\partial{\partial x}+\frac{\partial y}{\partial u}\frac\partial{\partial y}=\frac\partial{\partial x}-\frac\partial{\partial y}
\end{align*}
\end{eg}

As mentioned in Sec. \ref{lb973}, $\partial_{\varphi^i}f=\eqref{eq398}$ is calculated by expressing $f$ as a function of $\varphi^1,\dots,\varphi^n$ and taking the $i$-th derivative. Here is another example:

\begin{eg}
Assume the setting of Exp. \ref{lb974}. Let $g:\Rbb^2\times\Rbb_{>0}\rightarrow\Rbb$ be $g=2xy\sqrt z$ (where $(x,y,z)$ are the standard coordinates of $\Rbb^3$). Let $f=g|_M$, which is a smooth function on $M$. Fix $p=(a,b,a^2+b^2)$. Express $df|_p$ in terms of $dr|_p$ and $d\theta|_p$.
\end{eg}


\begin{proof}
We have $f=r^3\sin(2\theta)$ as a relation of functions on $M$. Therefore 
\begin{align*}
&df\big|_p=\frac{\partial f}{\partial r}\Big|_p\cdot dr|_p+\frac{\partial f}{\partial \theta}\Big|_p\cdot d\theta|_p=3r^2\sin(2\theta)\big|_p\cdot dr|_p+2r^3\cos(2\theta)\big|_p\cdot d\theta|_p\\
=&6ab\cdot dr|_p+2(a^2-b^2)\sqrt{a^2+b^2}\cdot d\theta|_p
\end{align*}
\end{proof}


\subsubsection{The cotangent map $F^*$}

Let $F:M\rightarrow N$ be a smooth map of $C^\infty$-manifolds. 

\begin{df}\label{mc91}
Define $F^*$ associating to each $p\in M$ the linear map
\begin{align}
F^*|_p:T^*_{F(p)}N\rightarrow T^*_pM 
\end{align}
defined to be the transpose $(dF|_p)^\tr$. We call $F^*$ the \textbf{cotangent map} \index{00@Cotangent map $F^*$} \index{F@$F^*$, the cotangent map} of $F$. If $w'\in T^*_{f(p)}N$, we call $F^*|_p w'$ the \textbf{pullback} of the cotangent vector $w'$ by $F$. \index{00@Pullback of a cotangent vector} If $F$ is a diffeomorphism, we also write $(F^{-1})^*$ as the \textbf{pushforward} $F_*$, i.e.,
\begin{align}
F_*|_p\equiv (F^{-1})^*|_{F(p)}:T_p^*M\rightarrow T_{F(p)}^*N
\end{align}

If $\omega:N\rightarrow T^*N$ is a $1$-form on $N$, the \textbf{pullback} \index{00@Pullback of $1$-form} of $\omega$ by $F$ is defined to be \index{F@$F^*\omega$, the pullback of the form $\omega$}
\begin{align}
F^*\omega:M\rightarrow T^*M\qquad p\mapsto F^*(\omega|_{F(p)})
\end{align}
which is a $1$-form on $M$.  \hfill\qedsymbol
\end{df}


\begin{pp}\label{lb985}
Let $\omega:N\rightarrow T^*N$ be a $C^r$ (resp. Borel) $1$-form. Then $F^*\omega$ is a $C^r$ (resp. Borel) $1$-form on $M$. Moreover, if $f\in C^\infty(N,\Rbb)$, then
\begin{align}\label{eq402}
F^*df=d(f\circ F)
\end{align}
\end{pp}

\begin{proof}
We first prove \eqref{eq402}. Choose any smooth path $\gamma$ in $M$ such that $\gamma(0)=p$. Then
\begin{align*}
\bk{F^*df,\gamma'(0)}=\bk{df,dF\cdot\gamma'(0)}\xlongequal{\eqref{eq385}} \bk{df,(F\circ\gamma)'(0)}\xlongequal{\eqref{eq403}}(f\circ F\circ\gamma)'(0)
\end{align*} 
Similarly, by \eqref{eq403}, we have $\bk{d(f\circ F),\gamma'(0)}=(f\circ F\circ\gamma)'(0)$. This proves \eqref{eq402}.

We now show that if $\omega$ is Borel then $F^*\omega$ is Borel. A similar argument shows that if $\omega$ is $C^r$ then $F^*\omega$ is $C^r$. Since $M$ is second countable and hence Lindel\"of, it suffices to choose any chart $(V,\psi)$ on $N$ and prove that $F^*\omega|_{F^{-1}(V)}$ is Borel. Then we can write $\omega|_V=\sum_i \omega_id\psi^i$ where $\omega_i:V\rightarrow\Rbb$ is Borel. Since $F^*d\psi^i=d(\psi^i\circ F)$ is smooth (by Prop. \ref{lb971}), $F^*\omega|_{F^{-1}(V)}=\sum_i (\omega_i\circ F)\cdot F^*d\psi^i$ is Borel.
\end{proof}

\begin{rem}
If $(U,\varphi^1,\dots,\varphi^m)$ and $(V,\psi^1,\dots,\psi^n)$ are charts of $M,N$ respectively such that $U\subset F^{-1}(V)$, then by \eqref{eq402} and \eqref{eq399}, we have
\begin{align}\label{eq404}
F^*d\psi^i=\sum_{j=1}^m \frac{\partial(\psi^i\circ F)}{\partial\varphi^j}d\varphi^j
\end{align}
recalling that $\dps \frac{\partial(\psi^i\circ F)}{\partial\varphi^j}=\big(\partial_j(\psi^i\circ F\circ\varphi^{-1})\big)\circ\varphi$, cf. \eqref{eq398}. This gives a very useful method of calculating $F^*$: Suppose that $\omega$ is a $1$-form on $V$. Write $\omega=\sum_i\omega_id\psi^i$ where $\omega_i:V\rightarrow\Rbb$. Then $\dps F^*d\omega=\sum_i (\omega_i\circ F)\cdot F^*d\psi^i$ where the RHS can be calculated by \eqref{eq404}. 
\end{rem}

On the other hand, when doing proofs, it is sometimes easier to use the matrix representation of $F^*$ rather than using \eqref{eq404}. The matrix representation is easy to find:

\begin{co}\label{mc98}
Let $p\in M$ and $q=F(p)$. Let $(U,\varphi^1,\dots,\varphi^m)$ and $(V,\psi^1,\dots,\psi^n)$ be charts of $M,N$ containing $p,q$ respectively. Then
\begin{align}
\left(
\begin{array}{c}
F^*d\psi^1\\
\vdots\\
F^*d\psi^n
\end{array}
\right)_p
=\Jac\big(\psi\circ F\circ\varphi^{-1}\big)\Big|_{\varphi(p)}\cdot \left(
\begin{array}{c}
d\varphi^1\\
\vdots\\
d\varphi^m
\end{array}
\right)_p
\end{align}
\end{co}

\begin{proof}
This follows from \eqref{eq404}. Alternatively, it also follows from Thm. \ref{lb967} and the fact that the matrix representation of the transpose $T^\tr$ of a linear operator $T$ is equal to the transpose of the matrix representation of $T$, cf. \eqref{eq401}.
\end{proof}


\subsection{The geometric implicit and inverse function theorems}


Let $M,N$ be $C^\infty$-manifolds. 


\begin{df}
We say that $F:M\rightarrow N$ is a \textbf{(smooth) embedding} \index{00@Embedding of manifolds} if $F(M)$ is a $C^\infty$-submanifold of $N$, and if the restriction $F:M\rightarrow F(M)$ is a diffeomorphism of $C^\infty$-manifolds.
\end{df}
In particular, an embedding must be injective.

\begin{pp}\label{lb975}
Let $F:M\rightarrow N$ be a smooth embedding. Then for each $p\in M$, the differential $dF|_p:T_pM\rightarrow T_{F(p)}N$ is injective. 
\end{pp}

\begin{proof}
Let $\wtd F:M\rightarrow Q:=F(M)$ be the restriction of $F$. Let $q=F(p)$. Then $F=\iota \circ\wtd F$ where $\iota:Q\rightarrow N$ is the inclusion. Hence $dF|_p=d\iota|_q\cdot d\wtd F|_p$. Since $\wtd F$ is a diffeomorphism, $d\wtd F|_p$ is bijective. Therefore, it suffices to prove that $d\iota|_q$ is injective. By Rem. \ref{lb942}, there exists $U\in\Nbh_q(N)$ such that the restriction of the inclusion $\iota:Q\cap U\rightarrow U$ is equivalent to $(\Rbb^d\times 0)\cap V\hookrightarrow (\Rbb^d\times\Rbb^k)\cap V=V$ for some open $V\subset\Rbb^d\times\Rbb^k$ containing $0$. The differential of this map (which can be calculated by the Jacobian) is clearly injective.
\end{proof}


\begin{cv}\label{lb977}
Suppose that $M$ is a smooth submanifold of $N$. By Prop. \ref{lb975}, for each $p\in M$, the linear map $d\iota|_p:T_pM\rightarrow T_pN$ is injective. Unless otherwise stated, we identify $T_pM$ with $d\iota(T_pM)$ through $d\iota$ so that $T_pM$ is a linear subspace of $T_pN$. In particular, if $N=\Rbb^n$, then $T_pM$ is naturally a linear subspace of $\Rbb^n$.
\end{cv}


In the following, we use tangent spaces and the differentials of smooth maps to generalize some of the results proved in the last chapter. 

\subsubsection{The geometric implicit function theorem}

The following theorem \index{00@Geometric implicit function theorem} is a more geometric version of Cor. \ref{lb956}.

\begin{thm}\label{lb976}
Let $F:M\rightarrow N$ be smooth. Let $q\in N$. Assume that for each $p\in F^{-1}(q)$, $F$ is a \textbf{submersion} \index{00@Submersion} at $p$, i.e., the linear map $dF|_p:T_pM\rightarrow T_qN$ is surjective. Then $F^{-1}(q)$ is a smooth submanifold of $M$. Moreover, for each $p\in F^{-1}(q)$, viewing $T_pF^{-1}(q)$ as a linear subspace of $T_pM$, we have
\begin{align}\label{eq406}
T_pF^{-1}(q)=\Ker (dF|_p)
\end{align}
In particular, we have
\begin{align}\label{eq405}
\dim_p F^{-1}(q)=\dim_pM-\dim_qN
\end{align}
\end{thm}

\begin{proof}
One may shrink $N$ to a neighborhood of $q$ so that $N$ is diffeomorphic to an open subset of $\Rbb^k$. Thus, by composing $F$ with a diffeomorphism on the target, we may assume WLOG that $N$ is just an open subset of $\Rbb^k$. Moreover, by translating $N$, we assume $q=0$.

We shall show that for each $p$ there is $U\in\Nbh_M(p)$ such that $F^{-1}(q)\cap U$ is a smooth submanifold of $M\cap U$, and that \eqref{eq405} holds. Thus, we may shrink $M$ to a neighborhood of $p$ so that $M$ is diffeomorphic to an open subset of $\Rbb^n$. Then, by composing $F$ with a diffeomorphism on the source, we assume WLOG that $M$ is an open subset of $\Rbb^n$. Then we can write $F=(F^1,\dots,F^k)$ where $F^1,\dots,F^k:M\rightarrow\Rbb$ are smooth, and $F^{-1}(q)=Z(F)$. Since $dF$ is surjective everywhere on $Z(F)$, by Cor. \ref{lb956}, we conclude that $Z(F)$ is an $(n-k)$-dimensional smooth submanifold of $M$.

It remains to prove \eqref{eq406}. For each smooth path $\gamma$ in $F^{-1}(q)$ satisfying $\gamma(0)=p$, since $F\circ\gamma$ is constant, we have $dF|_p\cdot\gamma'(0)=(F\circ\gamma)'(0)=0$. This proves $T_pF^{-1}(q)\subset\Ker (dF|_p)$. Since $T_pF^{-1}(q)$ and $\Ker (dF|_p)$ both have dimension $n-k$, they must be equal.
\end{proof}


\begin{sexe}
Let $F:M\rightarrow N$ be a smooth map. Let $S$ be a smooth submanifold of $N$. Assume that $F$ is a submersion at every $p\in F^{-1}(S)$. Prove that $F^{-1}(S)$ is a smooth submanifold of $M$. For each $p\in F^{-1}(S)$ and $q=F(p)$, prove that
\begin{align}
T_pF^{-1}(S)=(dF|_p)^{-1}(T_qS)
\end{align}
Conclude that
\begin{align}
\dim_p F^{-1}(S)=\dim_p M-\dim_qN+\dim_qS
\end{align}
\end{sexe}

\begin{proof}[Hint]
Reduce to the case that $N$ is a neighborhood of $0\in\Rbb^d\times\Rbb^k$ and $S=(\Rbb^d\times 0)\cap N$. Let $\pi:\Rbb^d\times\Rbb^k\rightarrow\Rbb^k$ be the projection. Let $G=\pi\circ F:M\rightarrow \Rbb^k$. Then $F^{-1}(S)=G^{-1}(0)$. Apply Thm. \ref{lb976} to $G$.
\end{proof}



\begin{eg}\label{lb978}
The \textbf{orthogonal group}
\begin{align*}
O(n)=\{A\in\Rbb^{n\times n}:A^\tr A=1\}
\end{align*}
is a smooth submanifold of $\Rbb^{n\times n}$ of dimension $n(n-1)/2$.
\end{eg}

\begin{proof}
Let $M=\Rbb^{n\times n}$. The map $A\in M\mapsto A^\tr A$ has range in
\begin{align*}
N=\{B\in \Rbb^{n\times n}:B=B^\tr\}
\end{align*}
Note that $N$ is a linear subspace of $\Rbb^{n\times n}$. Therefore, by Prop. \ref{lb955}, the above map restricts to a smooth map
\begin{align*}
\Phi:M\rightarrow N\qquad A\mapsto A^\tr A
\end{align*}
and $O(n)$ equals $\Phi^{-1}(1)$. Moreover, $N$ is linearly isomorphic to the linear space of upper triangular real matrices of order $n$. So $N$ has dimension $n+(n-1)+\cdots+1=n(n+1)/2$. Therefore, if we can prove that $d\Phi|_A:T_AM\rightarrow T_1N$ is surjective for every $A\in O(n)$, then by Thm. \ref{lb976}, $O(n)$ is a smooth submanifold of $M$ of dimension $n^2-n(n+1)/2=n(n-1)/2$, finishing the proof.

By Conv. \ref{lb977}, we view $T_1N$ as a linear subspace of $\Rbb^{n\times n}$, i.e., $T_1N=N$. Therefore, restricting the codomain of $\Jac \Phi|_A:\Rbb^{n\times n}\rightarrow \Rbb^{n\times n}$ to $N$ gives $d\Phi|_A$. To calculate this linear map, we first calculate the differential of
\begin{align*}
\Rbb^{n\times n}\times\Rbb^{n\times n}\rightarrow\Rbb^{n\times n}\qquad (A,B)\mapsto A^\tr B
\end{align*}
If $B=B(t)$ is a path and $A$ is fixed, then $\partial_t(A^\tr B(t))=A^\tr B'(t)$. If $A=A(t)$ is a path and $B$ is fixed, then $\partial_t(A(t)^\tr B)=(A'(t))^\tr B$. The chain rule then implies
\begin{align*}
\partial_t (A(t)^\tr A(t))=(A'(t))^\tr A(t)+A(t)^\tr A'(t)
\end{align*}
Applying the chain rule Cor. \ref{lb581} to $A(t)^\tr A(t)=\Phi\circ A(t)$ gives $\partial_t (A(t)^\tr A(t))=\Jac \Phi|_{A(t)}(A'(t))$.
Therefore, $\Jac\Phi|_A$ sends each $B\in\Rbb^{n\times n}$ to 
\begin{align}\label{eq407}
\Jac\Phi|_A(B)=B^\tr A+A^\tr B
\end{align}


Let $A\in O(n)$. To prove that $d\Phi|_A$ is surjective, we need to prove that for each  $C\in N$ there exists $B\in\Rbb^{n\times n}$ such that $B^\tr A+A^\tr B=C$. In fact, if we take $B=AC/2$, then since $A^\tr A=1$, we have $AA^\tr=1$, and hence
\begin{align*}
B^\tr A+A^\tr B=C^\tr A^\tr A/2+A^\tr AC/2=C
\end{align*}
\end{proof}

\begin{eg}
Assume the setting of Exp. \ref{lb978}. By \eqref{eq407}, the kernel of $\Jac\Phi|_1$ is the \textbf{orthogonal Lie algebra}
\begin{align}
\fk{so}(n)=\{A\in\Rbb^{n\times n}:A^\tr+A=0\}
\end{align}
Therefore, by Thm. \ref{lb976}, the tangent space of $O(n)$ at $1$ is $\fk{so}(n)$. 
\end{eg}




\subsubsection{The geometric inverse function theorem}



\begin{thm}[\textbf{Inverse function theorem}] \index{00@Inverse function theorem}\label{lb980}
Let $F:M\rightarrow N$ be smooth. Let $p\in M$ and $q=F(p)$. Assume that $dF|_p:T_pM\rightarrow T_qN$ is a linear isomorphism.  Then there exist $U\in\Nbh_M(p)$ and $V\in\Nbh_N(q)$ such that $F$ restricts to a diffeomorphism $F:U\xrightarrow{\simeq} V$.
\end{thm}

It follows, in particular, that $q$ is an interior point of $F(M)$.

\begin{proof}
There exist $\Omega\in\Nbh_M(p)$ and $D\in\Nbh_N(q)$ such that $\Omega$ and $D$ are both diffeomorphic to open subsets of Euclidean spaces. By replacing $N$ by $D$ and $M$ by $\Omega\cap F^{-1}(D)$, and by composing $F$ with diffeomorphisms, we may assume that $M,N$ are open subsets of Euclidean spaces. Then the theorem follows immediately from the inverse function Thm. \ref{lb929}.
\end{proof}




\begin{comment}
\begin{eg}
$A=\{(x,y)\in\Rbb^2:xy=0\}$ is not a smooth submanifold of $\Rbb^2$.
\end{eg}


\begin{proof}
Assume that $A$ is a smooth submanifold. The path $\gamma(t)=(t,0)$ is a smooth path in $\Rbb^2$. Therefore, by Prop. \ref{lb955}, $\gamma$ is a smooth path in $A$. Since $\gamma'(0)=(1,0)$, we conclude that $(1,0)\in T_0A$. Similarly, by considering the path $(0,t)$, we see that $(0,1)\in T_0A$. This proves that $\dim T_0A=2$. Let $\iota:A\rightarrow\Rbb^2$ be the inclusion. We know that (by Prop. \ref{lb975}) $d\iota|_0:T_0A\rightarrow T_0\Rbb^2$ is injective, and hence is bijective. Therefore, by the inverse function Thm. \ref{lb980}, $\iota(A)$ contains a neighborhood of $0$. This is impossible.
\end{proof}
\end{comment}



\begin{eg}
$A=\{(x,y)\in\Rbb^2:y=x^2\text{ or }y=-x^4\}$ is not a smooth submanifold of $\Rbb^2$.
\end{eg}

\begin{proof}
Assume that $A$ is a smooth submanifold of $\Rbb^2$. Clearly $\dim_pA=1$ whenever $p\in A$ and $p\neq 0$. Therefore, by Prop. \ref{lb982}, we have $\dim_0A=1$. Since $\gamma(t)=(t,t^2)$ is a smooth path in $\Rbb^2$, by Prop. \ref{lb955}, $\gamma$ is a smooth path in $A$. Since $\gamma'(0)=(1,0)$, we conclude that $T_0A$ is spanned by $(1,0)$.

Let $\pi:(x,y)\in\Rbb^2\mapsto x\in\Rbb$. Then $d\pi|_0$ sends $(1,0)$ to $1$. Therefore, if we let $\iota:A\rightarrow\Rbb^2$ be the inclusion and let $\varphi=\pi\circ\iota$, then $d\varphi|_0=d\pi_0\cdot d\iota|_0:T_0A\rightarrow\Rbb$ is a linear isomorphism. Therefore, by the inverse function Thm. \ref{lb980}, $\varphi$ must be injective on a neighborhood of $0$. But this is clearly impossible.
\end{proof}


Using a similar idea, one can prove that $B:=A\cap(\Rbb_{\geq0}\times\Rbb)$ is not a smooth submanifold of $\Rbb^2$ by using the smooth path $\gamma(t)=(t,t^2)$ defined on the \textbf{manifold with boundary} $[0,+\infty)$. See Exp. \ref{mc16}.


\begin{co}\label{lb981}
Let $F:M\rightarrow N$ be an smooth injective map. Assume that $dF|_p:T_pM\rightarrow T_{F(p)}N$ is bijective for each $p\in M$. Then $F(M)$ is an open subset of $N$, and $F$ restricts to a diffeomorphism $F:M\xrightarrow{\simeq}F(M)$.
\end{co}

\begin{proof}
This can be proved by Thm. \ref{lb980} in the same way that Cor. \ref{lb954} can be proved by the inverse function Thm. \ref{lb929}.
\end{proof}

By slightly adapting Cor. \ref{lb981}, we get a useful criterion for parametrizations of manifolds:

\begin{thm}\label{lb983}
Assume $\dim M=n$. Let $F:M\rightarrow N$ be a smooth injective map. Then $F$ is a smooth embedding iff the following two conditions are satisfied:
\begin{enumerate}
\item[(a)] $F$ is an \textbf{immersion} at each $p\in M$, which means that $dF|_p:T_pM\rightarrow T_{F(p)}N$ is injective.
\item[(b)] $F(M)$ is an $n$-dimensional smooth submanifold of $N$. 
\end{enumerate}
\end{thm}


\begin{proof}
Let $S=F(M)$. Suppose that $F$ is a smooth embedding. Then (b) clearly holds, and (a) follows from Prop. \ref{lb975}.

Conversely, assume that $F$ satisfies (a) and (b). By Prop. \ref{lb955}, $F$ restricts to a smooth map $\wtd F:M\rightarrow S$. Let $\iota:S\hookrightarrow N$ be the inclusion. By assumption, $dF=d(\iota\circ \wtd F)=d\iota\cdot d\wtd F$ is injective at any point of $M$. Since $d\iota$ is injective everywhere, $d\wtd F:T_pM\rightarrow T_{F(p)}S$ must be injective for every $p\in S$. Since $\dim T_pM=n=\dim T_{F(p)}S$, the map $d\wtd F:T_pM\rightarrow T_{F(p)}S$ is a linear isomorphism. Therefore, by Cor. \ref{lb981}, $\wtd F:M\rightarrow S$ is a diffeomorphism.
\end{proof}

%% Record #19 2024/05/09 three lectures  46

\begin{eg}
Let $D=(0,\pi)\times(0,2\pi)$. Let $R>0$. By Thm. \ref{lb976} (applied to the function $f(x,y,z)=x^2+y^2+z^2-R^2$), the sphere $R\Sbb^2$ (with radius $R$) is a $2$-dimensional submanifold of $\Rbb^3$. Since $\Omega=\Rbb^3\setminus (\Rbb_{\geq0}\times 0\times\Rbb)$ is open, $M:=R\Sbb^2\cap\Omega$ is a $2$-dimensional submanifold of $\Rbb^3$. The \textbf{spherical coordinates}
\begin{gather*}
F:D\rightarrow \Rbb^3\qquad (\varphi,\theta)\mapsto (x,y,z)\\
x=R\sin\varphi\cos\theta\qquad y=R\sin\varphi\sin\theta\qquad z=R\cos\varphi
\end{gather*}
have injective differential everywhere on $D$, since $(\Jac F)^\tr\Jac F=\diag(R^2,R^2(\sin\varphi)^2)$ is everywhere invertible. Since $F$ restricts to a bijection $D\rightarrow M$, by Thm. \ref{lb983}, $F:D\rightarrow M$ is a diffeomorphism. In other words, $F$ gives a (smooth) parametrization of $M$.
\end{eg}



\subsection{Lagrange multipliers; reproving H\"older and Minkowski}\label{lb991}





\begin{pp}\label{lb984}
Let $M$ be a smooth manifold. Let $f\in C^\infty(M,\Rbb)$. Assume that $p\in M$ is a \textbf{local extreme point} \index{00@Local extreme point} of $f$, i.e., there exists $U\in\Nbh_M(p)$ such that $f(p)=\sup f(U)$ or $f(p)=\inf f(U)$. Then $df|_p=0$.
\end{pp}


\begin{proof}
By shrinking $M$ to a neighborhood of $p$ and performing a diffeomorphism, we may assume that $M$ is an open subset of $\Rbb^n$. Since $f$ attains its local extrema at $p=(p_1,\dots,p_n)$, the function $t\mapsto (p_1+t,p_2,\dots,p_n)$ attains its local extrema at $t=0$. So $\partial_1f(p)=0$. Similarly, $\partial_2f(p)=\cdots=\partial_nf(p)=0$. So $df$ (which equals $\sum_i\partial_i fdx^i$ by Cor. \ref{lb987}) is zero at $p$.
\end{proof}


We shall generalize the above proposition to submanifolds. First, we need an elementary result in linear algebra:


\begin{lm}\label{lb986}
Let $T:\mc V\rightarrow\mc W$ be a linear map of finite-dimensional vector spaces. For each linear subspace $\mc U\subset\mc V$, let
\begin{align}
\mc U^\perp=\{v'\in \mc V^*:\bk{v',u}=0\text{ for all }u\in\mc U\}
\end{align}
Then
\begin{align}
(\Ker T)^\perp=T^\tr(\mc W^*)
\end{align}
where the RHS is the range of $T^\tr:\mc W^*\rightarrow\mc V^*$.
\end{lm}

\begin{proof}
Since any linear functional on $T(\mc V)$ can be extended to a linear functional on $\mc W$, we clearly have $T^\tr(\mc W^*)=T^\tr(T(\mc V)^*)$. Therefore, by replacing $\mc W$ with $T(\mc V)$, we may assume that $T$ is surjective. So $T^\tr$ is injective. Thus $\dim T^\tr(\mc W^*)=\dim\mc W$, and $\dim\Ker T=\dim\mc V-\dim\mc W$ by the rank-nullity theorem. Therefore $\dim(\Ker T)^\perp=\dim\mc W$. If $w'\in\mc W^*$ and $v\in\Ker T$, then $\bk{T^\tr w',v}=\bk{w',Tv}=0$. This proves $(\Ker T)^\perp\supset T^\tr(\mc W^*)$. Comparing the two dimensions, we get $(\Ker T)^\perp=T^\tr(\mc W^*)$.
\end{proof}




\begin{thm}[\textbf{Lagrange multipliers}]\index{00@Lagrange multipliers}\label{lb988}
Let $F:M\rightarrow N$ be a smooth map of $C^\infty$-manifolds. Let $q\in N$. Assume that $F$ is a submersion at any point of $F^{-1}(q)$. Let $f\in C^\infty(M,\Rbb)$. Assume that $p\in F^{-1}(q)$ is a local extreme point of $f|_{F^{-1}(q)}$. Then
\begin{align}\label{eq408}
df|_p\in F^*(T_q^*N)
\end{align}
In other words, if $(V,\psi^1,\dots,\psi^k)$ is a chart of $N$ containing $q$, then there exist $\lambda_1,\dots,\lambda_k\in\Rbb$ such that
\begin{align}\label{eq409}
df|_p=\lambda_1 d(\psi^1\circ F)|_p+\cdots+\lambda_k d(\psi^k\circ F)|_p
\end{align}
\end{thm}

\begin{proof}
By Thm. \ref{lb976}, $P=F^{-1}(q)$ is a smooth submanifold of $M$, and $T_pP=\Ker(dF|_p)$. Thus, by Lem. \ref{lb986} we have
\begin{align*}
(T_pP)^\perp=F^*(T_q^*N)
\end{align*}
Let $\iota:P\rightarrow M$ be the inclusion map. Then $p$ is a local extreme point of $f\circ\iota$. Therefore, by Prop. \ref{lb984}, $d(f\circ\iota)$ (which equals $\iota^*df$ by Prop. \ref{lb985}) is zero at $p$. Since $\iota_p:T_pP\rightarrow T_pM$ is the inclusion map, that $\iota^*df|_p=0$ means that the restriction of $df|_p$ to the subspace $T_pP$ is zero, i.e., $df|_p\in(T_pP)^\perp$. This proves \eqref{eq408}. The relation \eqref{eq409} follows from $d(\psi^j\circ F)=F^*d\psi^j$ due to Prop. \ref{lb985}.
\end{proof}

\begin{rem}\label{lb989}
Let $\Omega$ be an open subset of $\Rbb^n$. Let $F=(F^1,\dots,F^k):\Omega\rightarrow\Rbb^k$ be smooth. Recall that $Z(F)=\{p\in\Omega:f^1(p)=\cdots=f^k(p)\}$ is the zero set of $F$. Assume that $\rank\Jac F|_p=k$ for every $p\in Z(F)$. Let $f\in C^\infty(\Omega)$. We now fix $p\in Z(F)$, assuming that $p$ is a local extreme point of $f|_{Z(F)}$. Then Thm. \ref{lb988} says that there exist $\lambda_1,\dots,\lambda_k\in\Rbb$ (called the \textbf{Lagrange multipliers}) satisfying the system of linear equations
\begin{subequations}\label{eq410}
\begin{gather}
\partial_i f(p)=\lambda_1\partial_i F^1(p)+\cdots+\lambda_k \partial_i F^k(p)\qquad (\forall 1\leq i\leq k)
\end{gather}
Note that we also have
\begin{gather}
F^1(p)=0\qquad\cdots\qquad F^k(p)=0 
\end{gather}
\end{subequations}
Therefore, if we define the \textbf{Lagrangian function} $L:\Omega\times\Rbb^k\rightarrow\Rbb$ by
\begin{align}
L(x,\lambda^1,\dots,\lambda^k)=f(x)-\lambda^1 F^1(x)-\cdots-\lambda^k F^k(x)
\end{align}
(where $(x,\lambda^1,\dots,\lambda^k)$ is the standard coordinates of $\Rbb^n\times\Rbb^k$), then solving \eqref{eq410} amounts to finding the zeros of the equations
\begin{gather}
\partial_{x^1}L=\cdots=\partial_{x^n}L=\partial_{\lambda^1}L=\cdots=\partial_{\lambda^k}L=0
\end{gather}
Namely, the problem of finding the local extrema of $f$ under the constraints $F^1=\cdots=F^k=0$ is transformed to the problem of finding the local extrema of $L$ without constraints.
\end{rem}


\begin{eg}\label{lb990}
Let $1<p,q<+\infty$ and $p^{-1}+q^{-1}=1$. Let $f,h:\Rbb^n\rightarrow\Rbb$ be $f=a_1x^1+\cdots+a_nx^n$ (where $a_1,\dots,a_n\in\Rbb_{\geq0}$) and $h=(x^1)^q+\cdots+(x^n)^q-1$. Then $Z(h)$ is a compact subset of $\Rbb^n$, and at any point of $Z(h)$, one of $\partial_1h,\dots,\partial_n h$ is nonzero. Use Lagrange multipliers to prove
\begin{align*}
\sup f(Z(h))=\Vert a_\blt\Vert_p\equiv(a_1^p+\cdots+a_n^p)^{\frac 1p}
\end{align*}
\end{eg}

\begin{proof}
Assume WLOG that one of $a_1,\dots,a_n$ is nonzero, otherwise the problem is trivial. Let $b_\blt=(b_1,\dots,b_n)\in Z(h)$ be a maximal point of $f|_{Z(h)}$. Since changing $b_i$ to $|b_i|$ does not lower the value $f(b_\blt)$, we may assume that $b_i\geq0$. Since $b_\blt$ is a local extreme point of $f|_{Z(h)}$, by Rem. \ref{lb989}, there exists $\lambda\in\Rbb$ such that $\partial_i f(b_\blt)=\lambda\partial_i h(b_\blt)$ for all $i$, namely,
\begin{align*}
a_i=\lambda q b_i^{q-1}
\end{align*}
Since $\sum_i b_i^q=1$, we have
\begin{align*}
f(b_\blt)=\sum_i a_ib_i=\sum_i \lambda qb_i^q=\lambda q
\end{align*}
The proof will be completed by showing $\lambda=q^{-1}\Vert a_\blt\Vert_p$. Since $f(b_\blt)=\sup f(Z(h))>0$, we have $\lambda>0$. So $b_i=(a_i/\lambda q)^{1/(q-1)}$. Thus
\begin{align*}
1=\sum_i(a_i/\lambda q)^{\frac q{q-1}}=\sum_i(a_i/\lambda q)^p=\Vert a_\blt\Vert_p^p/(\lambda q)^p
\end{align*}
and hence $\lambda=q^{-1}\Vert a_\blt\Vert_p$.
\end{proof}

\begin{rem}
With the help of Exp. \ref{lb990}, we can give a more conceptual proof of Thm. \ref{lb853} on H\"older's and Minkowski's inequalities. Let $a_\blt,b_\blt\in (\Rbb_{\geq0})^n$, and let $g=b_1x^1+\cdots+b_nx^n$. Using the notations in Exp. \ref{lb990}, we have
\begin{align*}
\Vert a_\blt+b_\blt\Vert_p= \sup\big((f+g)(Z(h))\big)\leq \sup f(Z(h))+\sup g(Z(h))=\Vert a_\blt\Vert_p+\Vert b_\blt\Vert_p
\end{align*} 
This proves Minkowski's inequality. Assume for simplicity that $b_i>0$ for some $i$. Then $\Vert b_\blt\Vert_q^{-1}b_\blt=\Vert b_\blt\Vert_q^{-1}(b_1,\dots,b_n)$ belongs to $Z(h)$. So $f(\Vert b_\blt\Vert_q^{-1}b_\blt)\leq \sup f(Z(h))=\Vert a\Vert_p$ and hence $f(b_\blt)\leq \Vert a\Vert_p\cdot\Vert b\Vert_q$. This proves H\"older's inequality.
\end{rem}




\newpage



\section{Manifolds with boundary}


\subsection{The upper half space $\Hbb^n$}



\begin{df}\label{mc14}
Let $M$ be a smooth manifold. Let $A\subset M$. A map $F:A\rightarrow\Rbb^n$ is called \textbf{smooth} \index{00@Smooth map/function} if for every $p\in A$ there exist $U_p\in\Nbh_M(p)$ and $\wtd F\in C^\infty(U_p,\Rbb^n)$ such that $\wtd F|_{A\cap U_p}=F|_{A\cap U_p}$. The set of smooth maps $A\rightarrow\Rbb^k$ is denoted by $C^\infty(A,\Rbb^n)$.
\end{df}

\begin{rem}
From the definition, it is clear that the smoothness of $F:A\rightarrow\Rbb^n$ can be checked locally. Namely, if $A$ is covered by a family $\fk U$ of open subsets of $M$ such that $F|_{M\cap U}$ is smooth for every $U\in\fk U$, then $F$ is smooth.
\end{rem}


\begin{eg}
Suppose that $A$ is a submanifold of $M$.  Then the new definition of smooth functions on $A$ agrees with the usual one (defined by the smooth structure of $A$ as a smooth manifold).
\end{eg}

\begin{proof}
Let $f:A\rightarrow \Rbb^n$. Then $A$ is covered by a family $\fk U$ of open subsets of $M$ such that for each $U\in\fk U$, the inclusion $A\cap U\hookrightarrow U$ is equivalent to $(\Rbb^d\times 0)\cap V\hookrightarrow V$ where $V$ is an open subset of $\Rbb^d\times\Rbb^k$, cf. Rem. \ref{lb945}. It is clear that the two meanings of smooth functions on the subset $(\Rbb^d\times 0)\cap V$ of $V$ are the same.
\end{proof}



\begin{df}
The $n$-dimensional \textbf{upper half space} \index{00@Upper half space $\Hbb^n$} \index{Hn@$\Hbb^n$} is defined to be \footnote{Our convention is different from most textbooks where $\Hbb^n$ is defined to be $\{(x_1,\dots,x_n):x_n\geq0\}$. The advantage of our convention is that it makes the description of the orientation on the boundary $\partial\Hbb^n$ slightly simpler.}
\begin{align*}
\Hbb^n=\{(x_1,\dots,x_n)\in\Rbb^n:x_1\geq0\}
\end{align*}
The interior and the boundary of $\Hbb^n$ are defined to be
\begin{gather*}
\Int\Hbb^n= \{(x_1,\dots,x_n)\in\Rbb^n:x_1>0\}\\
\partial\Hbb^n=\Hbb^n\setminus\Int\Hbb^n=\{0\}\times\Rbb^{n-1}
\end{gather*}
If $U$ is an open subset of $\Hbb^n$, we let
\begin{align*}
\Int U=U\cap\Int\Hbb^n\qquad\partial U=U\cap\partial\Hbb^n
\end{align*}
We understand $\Hbb^0$ as $\{0\}\equiv\Rbb^0$.
\end{df}

\begin{df}
Let $U\subset\Hbb^m$ and $V\subset\Hbb^n$ be open and let $F:U\rightarrow V$ be a map. We say that $F$ is \textbf{smooth} if it is smooth as a map $U\rightarrow\Rbb^n$. We say that $F$ is a \textbf{diffeomorphism} if $F:U\rightarrow V$ is bijective, and if both $F$ and $F^{-1}:V\rightarrow U$ are smooth. 
\end{df}

The following lemma generalizes Rem. \ref{lb928}.


\begin{lm}\label{lb993}
Let $U,V$ be nonempty open subsets of $\Hbb^m,\Hbb^n$ respectively. Let $F:U\rightarrow V$ be a diffeomorphism. Then $m=n$, and 
\begin{align}\label{eq411}
F(\Int U)=\Int V\qquad F(\partial U)=\partial V
\end{align}
\end{lm}



\begin{proof}
Let $p\in \Int U$ and $q=F(p)$. We shall show that $q\in\Int U$. Then Rem. \ref{lb928} immediately implies that $m=n$. 

Suppose that $q\in\partial U$. Since $F^{-1}$ is smooth, there exists $\Delta\in\Nbh_{\Rbb^n}(q)$ such that $\Delta\cap\Hbb^n\subset V$, and that $F^{-1}|_{\Delta\cap\Hbb^n}=G|_{\Delta\cap\Hbb^n}$ for some $G\in C^\infty(\Delta,\Rbb^m)$. Since $F$ is continuous, $F^{-1}(\Delta)=F^{-1}(\Delta\cap\Hbb^n)$ is open in $U$. Let $D=F^{-1}(\Delta)\cap\Int(U)$, which is an element of $\Nbh_{\Rbb^n}(p)$. Then $G\circ F$ can be defined on $D$. It is clear that $G\circ F|_D=\id_D$. Thus $\Jac G|_q\cdot\Jac F|_p=1$. 

Since $G$ is continuous, $\Delta'=G^{-1}(D)$ is an open subset of $\Delta$ containing $q$. Then $F\circ G$ can be defined on the open set $\Delta'$, and $F\circ G|_{\Delta'\cap\Hbb^n}=\id$. Therefore $\Jac (F\circ G)=1$ since the right partial derivative of $F\circ G$ with respect to the first variable is $1$. Thus $\Jac F|_p\cdot\Jac G|_q=1$. This proves that $\Jac F|_p$ is invertible. By the inverse function Thm. \ref{lb929}, $V$ contains an open ball centered at $q$. This contradicts $q\in\partial \Hbb^n$.

We have proved $m=n$ and $F(\Int U)\subset \Int V$. Applying the same result to $F^{-1}$, we then have $F(\Int U)=\Int V$, and $F(\partial U)=V\cap\partial\Hbb^n$ also follows immediately.
\end{proof}


\begin{df}\label{lb992}
Let $U\subset\Hbb^n$ be open. Let $F\in C^\infty(U,\Rbb^k)$. Then $\partial_i F^k(p)$ is defined in the obvious way when $p\in\Int U$, or when $p\in\partial U$ and $i>1$. If $p\in\partial U$,  $\partial_1 F(p)$ is defined to be the right partial derivative
\begin{align*}
\partial_1 F(p)=\lim_{t\rightarrow 0^+}\frac{F(p+t e_1)-F(p)}{t}
\end{align*}
where $e_1=(1,0,\dots,0)\in\Rbb^n$. Equivalently, $\partial_1 F(p)$ can be defined to be $\partial_1\wtd F(p)$ where $\wtd F\in C^\infty(D,\Rbb^k)$ satisfies that $D\in\Nbh_{\Rbb^n}(p)$ and that $\wtd F|_{D\cap U}=F|_{D\cap U}$. 
\end{df}


\begin{rem}\label{lb994}
Let $U\subset \Hbb^m$ and $V\subset\Hbb^n$ be open, and let $F\in C^\infty(U,V)$. By Def. \ref{lb992}, for each $p\in U$, $\Jac F|_p$ is defined as an $n\times m$ matrix. Now assume that $F$ is a diffeomorphism and $p\in\partial U$. By Lem. \ref{lb993}, we know that $m=n$ and that $q=F(p)$ belongs to $\partial V$. Moreover, \eqref{eq411} implies that $\partial_1 F|_p\geq0$, and that the first component of $\partial_i F|_p$ is zero if $i>0$. The partial derivative of $F^{-1}$ at $q$ satisfies a similar property. This implies
\begin{subequations}
\begin{align}
\Jac F|_p(\Hbb^n)=\Hbb^n\qquad \Jac F|_p(\partial\Hbb^n)=\partial\Hbb^n
\end{align}
and hence also
\begin{align}
\Jac F|_p(\Int\Hbb^n)=\Int\Hbb^n
\end{align}
\end{subequations}
\end{rem}


\begin{thm}[\textbf{Inverse function theorem for $\Hbb^n$}]\label{mc8}
Let $\Omega,\Gamma$ be nonempty open subsets of $\Hbb^n$. Let $F:\Omega\rightarrow \Gamma$ be smooth and satisfying $F(\partial \Omega)\subset\partial \Gamma$. Let $p\in\Omega$ and $q=F(p)$. Assume that $\Jac F|_p$ is invertible. Then there exist $U\in\Nbh_\Omega(p)$ and $V\in\Nbh_\Gamma(q)$ such that $F$ restricts to a diffeomorphism $F:U\rightarrow V$.
\end{thm}

\begin{proof}
When $p\in\Int\Omega$, the inverse function Thm. \ref{lb929} shows that $F(\Int\Omega)$ contains an open ball centerd at $q$. So we must have $q\in\Int\Gamma$. The theorem then follows immediately from Thm. \ref{lb929}.

Let us consider the more difficult case that $p\in\partial\Omega$ and hence $q\in\partial\Gamma$. By Def. \ref{mc14}, there exists $D\in\Nbh_{\Rbb^n}(p)$ such that $D\cap\Hbb^n$ is a (clearly open) subset of $\Omega$, and that $F$ can be extended to a smooth map $F:D\rightarrow\Rbb^n$. By the inverse function Thm. \ref{lb929}, after shrinking $D$ to a neighborhood of $p$ in $\Rbb^n$, besides having that $D\cap\Hbb^n\subset\Omega$, we also have that $\Delta:=F(D)$ is open in $\Rbb^n$, and that $F:D\rightarrow \Delta$ is a diffeomorphism. 

By assumption, we have $F(D\cap\partial\Hbb^n)\subset \Delta\cap\partial\Hbb^n$. We want ``$\subset$" to be ``$=$". For that purpose, note that since $D\cap\partial\Hbb^n$ is a smooth submanifold of $\Delta$, the diffeomorphism $F:D\rightarrow\Delta$ restricts to a smooth injective immersion $D\cap\partial\Hbb^n\rightarrow \Delta$, and hence restricts to a smooth injective immersion $D\cap\partial\Hbb^n\rightarrow \Delta\cap\partial\Hbb^n$. Since both sides have dimension $n-1$, the differential of this restricted map must be invertible everywhere. Therefore, by Cor. \ref{lb981}, $F(D\cap\partial\Hbb^n)$ is an open subset of $\Delta\cap\partial\Hbb^n$. Choose open $\Delta'\subset \Delta$ such that $\Delta'\cap\partial\Hbb^n=F(D\cap\partial\Hbb^n)$, and let $D'=F^{-1}(\Delta')$. Then $F|_{D'}:D'\rightarrow \Delta'$ is a diffeomorphism, and
\begin{align}\label{eq473}
F(D'\cap\partial\Hbb^n)=\Delta'\cap\partial\Hbb^n
\end{align}
Let $(x^1,\dots,x^n)$ be the standard coordinates of $\Rbb^n$. Then \eqref{eq473} means that for each $\xi\in D'$, we have $x^1(\xi)=0$ iff $x^1\circ F(\xi)=0$. Note that we also have
\begin{align}\label{eq474}
D'\cap\Hbb^n\subset\Omega
\end{align}

Shrink $D'$ to an open ball centered at $p$, and shrink $\Delta'$ to $F(D')$. Then
\begin{align*}
F|_{D'}:D'\xlongrightarrow{\simeq} \Delta'
\end{align*}
is a still a diffeomorphism, and for each $\xi\in D'$ we still have $x^1(\xi)=0$ iff $x^1\circ F(\xi)=0$ (i.e., \eqref{eq473} is still true). Let
\begin{align*}
U=D'\cap\Hbb^n\qquad V=\Delta'\cap\Hbb^n
\end{align*}
Then $U\in\Nbh_{\Omega}(p)$ and $V\in\Nbh_{\Hbb^n}(q)$ by \eqref{eq474}. Suppose we can show that $F(U)=V$. Then $F$ clearly restricts to a diffeomorphism $U\rightarrow V$, and we have $V\in\Nbh_\Gamma(q)$ since $V=F(U)\subset F(\Omega)\subset\Gamma$. This will finish the proof.



Since $F(\Omega)\subset\Gamma\subset\Hbb^n$, we clearly have $F(U)\subset V$. To prove $F(U)=V$, it suffices to prove $F(D'\setminus\Hbb^n)\subset \Delta'\setminus\Hbb^n$. In other words, we need to prove that if $\xi\in D'$ satisfies $x^1(\xi)<0$ then $x^1\circ F(\xi)<0$. Note that $x^1\circ F(D'\setminus\Hbb^n)$ must intersect $\Rbb_{<0}$, otherwise we have $F(D'\setminus\Hbb^n)\subset\Hbb^n$ and hence $\Delta'\equiv F(D')\subset \Hbb^n$, which is impossible because $q\in\Delta'\cap\partial\Hbb^n$ is not an interior point of $\Delta'$ with respect to $\Rbb^n$. By \eqref{eq473}, if $x^1(\xi)<0$ then $x^1\circ F(\xi)\neq0$. Therefore $x^1\circ F(D'\setminus\Hbb^n)\subset \Rbb\setminus\{0\}$. Since the half-ball $D'\setminus\Hbb^n$ is connected, so is $x^1\circ F(D'\setminus\Hbb^n)$. So we must have $x^1\circ F(D'\setminus\Hbb^n)\subset\Rbb_{<0}$.
\end{proof}



\subsection{Smooth manifolds with boundary}


\begin{df}
Let $M$ be a nonempty Hausdorff space. Let $\fk U=\big\{(U_\alpha,\varphi_\alpha)_{\alpha\in\scr A}\big\}$ be a \textbf{(smooth) atalas}   \index{00@Atlas} on $M$. Namely, $\fk U$ satisfies the following conditions:
\begin{itemize}
\item Each $U_\alpha$ is open, and  $M=\bigcup_{\alpha\in\scr A}U_\alpha$.
\item Each $\varphi_\alpha:U_\alpha\rightarrow\varphi_\alpha(U_\alpha)$ is a homeomorphism where $\varphi_\alpha(U_\alpha)$ is an open subset of $\Hbb^{d_\alpha}$ for some $d_\alpha\in\Nbb$.
\item For each $\alpha,\beta\in\scr A$, $\varphi_\alpha$ and $\varphi_\beta$ are  \pmb{$C^\infty$}\textbf{-compatible} in the sense that the following map is a diffeomorphism of (clearly open) subsets of $\Hbb^{d_\alpha}$:
\begin{align}
\varphi_\beta\circ\varphi_\alpha^{-1}:\varphi_\alpha(U_\alpha\cap U_\beta)\xrightarrow{\simeq}\varphi_\beta(U_\alpha\cap U_\beta)
\end{align}
\end{itemize}
The pair $(M,\fk U)$ (or simply $M$) is called \pmb{$C^\infty$}\textbf{/smooth manifold with boundary}, \index{00@@Manifold with boundary} or simply a \textbf{smooth} \pmb{$\partial$}\textbf{-manifold}. \index{00@$\partial$-manifold} Unless otherwise stated, we assume that smooth $\partial$-manifolds are second countable.
\end{df}


\begin{rem}
A manifold with boundary means a manifold \textit{possibly} with boundary. In fact, a smooth manifold (without boundary) is also a smooth $\partial$-manifold. This is because $\Rbb^n$ is diffeomorphic to $\Int\Hbb^n$, and hence any open subset of $\Rbb^n$ is diffeomorphic to an open subset of $\Hbb^n$.
\end{rem}

\begin{df}
Let $M$ be a smooth $\partial$-manifold with atlas $\fk U$. A \textbf{(smooth) chart} \index{00@Chart} on $(M,\fk U)$ is defined to be a pair $(V,\psi)$ where $V$ is an open subset of $M$, $\psi:V\rightarrow\psi(V)$ is a homeomorphism where $\psi(V)$ is an open subset of $\Hbb^d$ for some $d\in\Nbb$, and $(V,\psi)$ is $C^\infty$-compatible with any member of $\fk U$. We call $\psi^{-1}:\psi(V)\rightarrow V$ a \textbf{parametrization} \index{00@Parametrization} of $V$, and call $\psi$ a \textbf{coordinate} \index{00@Coordiante on a manifold with boundary} of $V$. The set of all smooth charts is called the \textbf{maximal atlas} \index{00@Maximal atlas} of $(M,\fk U)$, also called the \textbf{smooth structure} \index{00@Smooth structure} of $(M,\fk U)$.
\end{df}


\begin{df}
Let $M$ be a smooth $\partial$-manifold. Let $p\in M$. Choose any chart $(U,\varphi^1,\dots,\varphi^{d_p})$ containing $p$. We let
\begin{align*}
\dim_p M=d_p
\end{align*}
and call $\dim_pM$ the \textbf{dimension} \index{00@Dimensional of a manifold with boundary} of $M$ at $p$. By Lem. \ref{lb993}, $\dim_pM$ is well-defined and independent of the choice of charts containing $p$.

Suppose that we can find $d\in\Nbb$ such that $\dim_pM=d$ for all $p$, we call $M$ \textbf{equidimensional}, write $\dim M=d$, and call $d$ the \textbf{dimension} of $M$. \hfill\qedsymbol
\end{df}

\begin{rem}\label{mc122}
Similar to Prop. \ref{lb982}, if $M$ is a $\partial$-manifold, then for each $h\in\Nbb$, the set $U_d=\{p\in M:\dim_pM=d\}$ is both closed and open in $M$. In particular, if $M$ is connected, then $M$ is equidimensional.
\end{rem}


\begin{df}\label{mc23}
Let $M$ be a smooth $\partial$-manifold. Let $p\in M$. We say that $p$ is a \textbf{boundary point} of $M$ if for some chart (and hence for every chart, cf. Lem. \ref{lb993}) $(U,\varphi^1,\dots,\varphi^n)$ containing $p$, we have $\varphi(p)\in\partial\Hbb^n$. We say that $p$ is an \textbf{interior point} of $M$ if $p$ is not a boundary point. The set of boundary points and the set of interior points are denoted by $\partial M$ and $\Int M$ \index{M@$\partial M$} respectively \index{IntM@$\Int M$} and called the \textbf{(manifold) boundary} and the \textbf{(manifold) interior} \index{00@Boundary $\partial M$} \index{00@Interior $\Int M$} of $M$. It is clear that $M$ is a smooth manifold iff $\partial M=\emptyset$.
\end{df}

\begin{cv}
One should not confuse manifold interiors with \textbf{topological interiors} (defined in Def. \ref{lb187}). Unless otherwise stated, the interior of a $\partial$-manifold denotes the manifold interior. (But see Exe. \ref{mc24} for an important case where the two interiors are equal.)
\end{cv}



\begin{df}
Let $M$ be a smooth $\partial$-manifold. Then $\partial M$ has a canonical smooth structure so that $\partial M$ is a smooth manifold (without boundary). If $\fk U$ is a chart on $M$, then
\begin{align}
\fk U|_{\partial M}=\{(U\cap\partial M,\varphi^2|_{U\cap M},\dots,\varphi^d|_{U\cap M}):(U,\varphi^1,\dots,\varphi^d)\in\fk U \}
\end{align}
is a chart on $\partial M$. It is clear that if $p\in\partial M$ then $\dim_pM\geq 1$ and
\begin{align}
\dim_p M=\dim_p\partial M+1
\end{align}
\end{df}

\begin{eg}
Let $-\infty<a<b\leq+\infty$. Then $[a,b)$, together with the coordinate $x\in[a,b)\mapsto x-a$, is a $1$-dimensional smooth $\partial$-manifold. Its boundary is $\{a\}$.
\end{eg}

\begin{eg}
Let $M$ be a smooth $\partial$-manifold. Then every open $\Omega\subset M$ is a smooth $\partial$-manifold in a canonical way, i.e., for each chart $(U,\varphi)$ of $M$, the restriction $(\Omega\cap U,\varphi|_{\Omega\cap U})$ is a chart of $\Omega$. Moreover, we clearly have
\begin{align}\label{eq416}
\partial \Omega=\Omega\cap(\partial M)
\end{align}
\end{eg}


\begin{eg}
Let $M,N$ be smooth $\partial$-manifolds where $\partial N=\emptyset$. Then $M\times N$ has a canonical structure of a smooth $\partial$-manifold such that if $(U,\varphi^1,\dots,\varphi^m)$ and $(V,\psi^1,\dots,\psi^n)$ are charts of $M,N$ respectively, then $(U\times V,\varphi^1,\dots,\varphi^m,\psi^1\dots,\psi^n)$ is a chart of $M\times N$. Moreover, we have
\begin{align}
\partial(M\times N)=(\partial M)\times N
\end{align}
\end{eg}


\begin{df}
Let $M,N$ be smooth $\partial$-manifolds. We say that a map $F:M\rightarrow N$ is \textbf{smooth} \index{00@Smooth map/function} if one of the following (clearly) equivalent conditions hold:
\begin{enumerate}
\item[(1)] For every charts $(U,\varphi)$ of $M$ and $(V,\psi)$ of $N$, the following map is $C^\infty$:
\begin{align}\label{eq412}
\psi\circ F\circ\varphi^{-1}:\varphi(U\cap F^{-1}(V))\rightarrow \psi(V)
\end{align}
\item[(2)] There exist atlases $\fk U$ on $M$ and $\fk V$ on $N$ such that for every $(U,\varphi)\in\fk U$ and $(V,\psi)\in\fk V$, the map \eqref{eq412} is smooth.
\end{enumerate}
It is clear that a composition of smooth maps is smooth, and that the smoothness of a map can be checked locally (in the sense of Prop. \ref{lb944}).
\end{df}


\subsection{Basic properties}


Fix a smooth $\partial$-manifold $M$.


\subsubsection{Tangent spaces}

\begin{df}
We call a smooth map $\gamma:[a,b)$ a \textbf{(smooth right)  path starting from $a$}. Let $p\in M$. Define \index{TpM@$T_p^+M$}
\begin{align}
T_p^+M=\big\{\text{smooth path }\gamma\in M^{[0,\eps)}:\eps>0,\gamma(0)=p  \big\}\big/\sim
\end{align}
where $\sim$ is the equivalence relation such that $\gamma_1\sim\gamma_2$ for some chart (and hence for every chart) $(U,\varphi)$ containing $p$ such that
\begin{align}
\Jac(\varphi\circ\gamma_1)|_0=\Jac(\varphi\circ\gamma_2)|_0
\end{align}
We call $T_p^+M$ the \textbf{tangent cone} of $M$ at $p$. \index{00@Tangent cone} It is clear that
\begin{gather*}
T_p\Int M=T_p^+M\qquad\text{ if }p\in\Int M\\
T_p\partial M\subset T_p^+M\qquad\text{ if }p\in\partial M
\end{gather*}
If $I$ is an open or right-open interval and $\gamma:I\rightarrow M$ is a smooth path in $M$, for each $t_0\in I$, the equivalence class of the path $t\mapsto \gamma(t+t_0)$ in $T_p^+M$ is denoted by \index{zz@$\gamma'$, the derivative of a path $\gamma$ in a manifold}
\begin{align}
\gamma'(t_0)\equiv \frac {d\gamma}{dt}\big|_{t_0}
\end{align}
and is called the \textbf{derivative} of $\gamma$ at $t_0$. 
\end{df}



\begin{thm}\label{lb996}
Let $p\in M$. For each chart $(U,\varphi)=(U,\varphi^1,\dots,\varphi^n)$ containing $p$, there is a bijection $d\varphi|_p$ (abbreviated to $d\varphi$) defined by
\begin{gather}\label{eq413}
d\varphi:T_p^+M\rightarrow\Hbb^n\qquad d\varphi\cdot \gamma'(0)=\Jac(\varphi\circ\gamma)|_0
\end{gather}
where $\gamma:[0,?]\rightarrow M$ is a smooth right path satisfying $\gamma(0)=p$. Moreover, for any other chart $(V,\psi^1,\dots,\psi^n)$ containing $p$, the following diagram commutes:
\begin{equation}\label{eq414}
\begin{tikzcd}[row sep=large]
             & T_p^+M \arrow[ld,"d\varphi"'] \arrow[rd,"d\psi"] &   \\
\Hbb^n \arrow[rr,"{\Jac(\psi\circ\varphi^{-1})\big|_{\varphi(p)}}"',"\simeq"] &                         & \Hbb^n
\end{tikzcd}
\end{equation}
where $\Jac(\psi\circ\varphi^{-1})|_{\varphi(p)}:\Hbb^n\rightarrow\Hbb^n$ is an $\Rbb_{\geq0}$-linear isomorphism by Rem. \ref{lb994}. 

Therefore, $T_p^+M$ has a unique $\Rbb_{\geq0}$-linear structure such that for each chart $(U,\varphi^1,\dots,\varphi^n)$ containing $p$, the map $d\varphi|_p:T_p^+M\rightarrow\Hbb^n$ is an $\Rbb_{\geq0}$-linear isomorphism.
\end{thm}

\begin{proof}
Similar to Thm. \ref{lb962}.
\end{proof}


To define the tangent space at a boundary point, we need the following algebraic result:
\begin{lm}\label{lb995}
Let $K$ be an $\Rbb_{\geq0}$-linear space isomorphic to $\Hbb^n$. Define the \textbf{(full) dual space}
\begin{align}
K^*=\{\Rbb_{\geq0}\text{-linear maps }K\rightarrow\Rbb\}
\end{align}
Then $K^*$ is an $n$-dimensional $\Rbb$-linear subspace of $\Rbb^K$, and the canonical $\Rbb_{\geq0}$-linear map $K\rightarrow K^{**}$ (sending each $v\in K$ to $\bk{v,\cdot}:\varphi\in K^*\mapsto\bk{v,\varphi}$) is injective. Identify $K$ with its image in $K^{**}$ under this map. Then $K$ is a positive cone (i.e., an $\Rbb_{\geq0}$-linear subspace) in $K^{**}$, and $K^{**}=\Span_\Rbb K$.
\end{lm}

\begin{proof}
It suffices to assume that $K=\Hbb^n$. Then by using Prop. \ref{lb751}, one easily sees that $K^*=\Rbb^n$. The remaining statements are easy to prove.
\end{proof}


\begin{df}\label{mc167}
Let $p\in \partial M$. Then
\begin{align}
T_p^*M=(T_p^+M)^*\qquad T_pM=(T_p^+M)^{**}
\end{align}
are called respectively the \textbf{cotangent space}  and the \textbf{tangent space}  of $M$ at $p$. \index{00@Cotangent space} \index{TM@$T^*M,T^*_pM$} \index{00@Tangent space} \index{TpM@$T_pM,TM$} By Lem. \ref{lb995}, $T^+_pM$ is canonically a positive spanning cone in $T_pM$, and
\begin{align}
\dim T_pM=\dim_pM
\end{align}
We say that $\xi\in T_pM$ is \textbf{inward-pointing} (resp. \textbf{outward-pointing}) \index{00@Inward-pointing vector} \index{00@Outward-pointing vector} if $\xi\in T_p^+M\setminus T_p\partial M$ (resp. $\xi\in T_pM\setminus T_p^+M$). 

We let 
\begin{align*}
T_pM:=T_p^+M\qquad\text{ if }p\in\Int M
\end{align*}
The \textbf{tangent bundle} \index{00@Tangent bundle} resp. \textbf{cotangent bundle} \index{00@Cotangent bundle} is again defined to be
\begin{align*}
TM=\bigsqcup_{p\in M}T_pM\qquad T^*M=\bigsqcup_{p\in M}T_p^*M
\end{align*}
Vector fields $M\rightarrow TM$ and $1$-forms $M\rightarrow T^*M$ are defined in the same way as those of manifolds without boundaries.  \hfill\qedsymbol
\end{df}

\begin{rem}
Assume the setting of Thm. \ref{lb996}. Then by (e.g.) Prop. \ref{lb751}, we can extend \eqref{eq413} uniquely to a linear isomorphism $d\varphi|_p:T_pM\rightarrow\Rbb^n$. Then we have a commutative diagram
\begin{equation}
\begin{tikzcd}[row sep=large]
             & T_pM \arrow[ld,"d\varphi"'] \arrow[rd,"d\psi"] &   \\
\Rbb^n \arrow[rr,"{\Jac(\psi\circ\varphi^{-1})\big|_{\varphi(p)}}"',"\simeq"] &                         & \Rbb^n
\end{tikzcd}
\end{equation}
\end{rem}




\begin{cv}
Let $x=(x^1,\dots,x^n)$ be the standard coordinates of $\Hbb^n$. Then, for each $p\in\Hbb^n$, we use the isomorphism $dx|_p$ to identify $T_p^+\Hbb^n$ with $\Hbb^n$ and identify $T_p\Hbb^n$ with $\Rbb^n$.
\end{cv}



\begin{rem}
All the definitions and properties in Sec. \ref{lb997}, \ref{lb973}, \ref{lb998} can be generalized to smooth manifolds with boundaries. Some of them need to be slightly modified. For example:
\begin{itemize}
\item If $F:M\rightarrow N$ is smooth, then $dF|_p:T_pM\rightarrow T_qN$ can be defined satisfying Thm. \ref{lb967}, except that \eqref{eq385} should be replaced by the following statement: We have a unique linear map $dF|_p:T_pM\rightarrow T_qN$ which restricts to an $\Rbb_{\geq0}$-linear map
\begin{align}\label{eq420}
dF:T_p^+M\rightarrow T_q^+N\qquad dF\cdot \gamma'(0)=(F\circ\gamma)'(0)
\end{align}
for each smooth right path $\gamma:[0,?)\rightarrow M$ satisfying $\gamma(0)=p$.
\end{itemize}
We leave the generalizations of other definitions, properties, and their proofs to the readers.
\end{rem}


\subsubsection{Submanifolds with boundary}

Let us give the definition and  some of the basic properties of $\partial$-submanifolds. We will be only concerned with $\partial$-submanifolds of a manifold. 

\begin{df}\label{mc13}
Let $N$ be a smooth manifold, and let $M\subset N$. We say that $M$ is a \textbf{$C^\infty$/smooth submanifold of $N$ with boundary} (or a \textbf{$C^\infty$/smooth $\partial$-submanifold of $N$}) \index{00@Smooth submanifold with boundary} if \index{00@$\partial$-submanifold} for every $p\in M$ there exist $U\in\Nbh_N(p)$, $d,k\in\Nbb$, and $C^\infty$-functions $\varphi^1,\dots,\varphi^d,f^1,\dots,f^k:U\rightarrow\Rbb$ satisfying the following conditions:
\begin{enumerate}
\item[(a)] $(\varphi,f)=(\varphi^1,\dots,\varphi^d,f^1,\dots,f^k)$ gives a $C^\infty$-diffeomorphism $U\xrightarrow{\simeq} V$ where $V$ is an open subset of $\Rbb^d\times\Rbb^k$.
\item[(b)] The following diagram commutes:
\begin{equation}\label{eq415}
\begin{tikzcd}[column sep=large]
M\cap U \arrow[r,"{(\varphi,0)}"] \arrow[d, hook] & (\Hbb^d\times 0)\cap V \arrow[d, hook] \\
U \arrow[r,"{(\varphi,f)}","\simeq"']                 & (\Rbb^d\times\Rbb^k)\cap V=V            
\end{tikzcd}
\end{equation}
Moreover, the top arrow $(\varphi,0)$ is bijective. (Equivalently, the inverse image of $(\Hbb^d\times 0)\cap V$ under $(\varphi,f)$ is $M\cap U$.)
\end{enumerate}
Similar to Exp. \ref{lb941}, $M$ has a unique structure of a smooth $\partial$-manifold such that for any $U,\varphi^1,\dots,\varphi^d$ described as above, $(M\cap U,\varphi^1,\dots,\varphi^d)$ is a chart on $M$. It is also clear that $\partial M$ is a smooth submanifold of $N$.
\end{df}

\begin{df}
Let $M$ be a smooth $n$-dimensional $\partial$-manifold. If $D$ is a smooth $n$-dimensional $\partial$-submanifold of $\Rbb^n$, and if $F:D\rightarrow M$ is a diffeomorphism, we say that $F$ is a \textbf{parametrization} \index{00@Parametrization} of $M$.
\end{df}







\begin{rem}\label{mc1}
The property of being a $\partial$-submanifold can be checked locally. Namely, suppose that $M\subset N$ where $N$ is a smooth manifold. Let $\fk U$ be a collection of open subsets of $N$ covering $M$. Then $M$ is a smooth $\partial$-submanifold of $N$ iff $M\cap U$ is a smooth $\partial$-submanifold of $U$ for every $U\in\fk U$. Moreover, if $M$ is a smooth $\partial$-submanifold of $N$, then by \eqref{eq416} we have 
\begin{align}\label{eq417}
\partial M=\bigcup_{U\in\fk U}\partial (M\cap U)
\end{align}
Therefore, proving that $\partial M$ equals a set $P$ is equivalent to proving that $\partial(M\cap U)=P\cap U$ for every $U\in\fk U$.
\end{rem}


\begin{exe}\label{mc5}
Let $N$ be a smooth manifold. Let $M$ be a smooth submanifold of $N$. Let $P$ be a smooth $\partial$-submanifold of $M$. Prove that $P$ is a smooth $\partial$-submanifold of $N$. Prove that the smooth structure of $P$ as a smooth $\partial$-submanifold of $M$ is equal to the smooth structure of $P$ as a smooth $\partial$-submanifold of $N$.
\end{exe}






\begin{df}\label{mc15}
Let $M$ be a smooth $\partial$-manifold. Let $A\subset M$. A map $F:A\rightarrow\Rbb^n$ is called \textbf{smooth} \index{00@Smooth map/function} if for every $p\in A$ there exist $U_p\in\Nbh_M(p)$ and $\wtd F\in C^\infty(U_p,\Rbb^n)$ such that $\wtd F|_{A\cap U_p}=F|_{A\cap U_p}$. The set of smooth maps $A\rightarrow\Rbb^k$ is denoted by $C^\infty(A,\Rbb^n)$.
\end{df}

\begin{exe}\label{mc26}
Let $M$ be a smooth $\partial$-manifold. Let $A$ be a smooth $\partial$-submanifold of $M$. Let $F:A\rightarrow\Rbb^n$. Prove that $F$ is smooth with respect to the smooth structure of $A$ as a $\partial$-manifold (as described in Def. \ref{mc13}) iff $F$ is smooth with respect to $A$ as a subset of $M$ (cf. Def. \ref{mc15}).
\end{exe}



\begin{pp}\label{mc17}
Let $M$ be a smooth $\partial$-submanifold of a smooth manifold $N$. Then the inclusion map $\iota:M\hookrightarrow N$ is smooth. Moreover, suppose that $X$ is a smooth $\partial$-manifold and $F:X\rightarrow M$ is a map. Then $F$ is smooth iff $\iota\circ F:X\rightarrow N$ is smooth.
\end{pp}

\begin{proof}
Similar to Prop. \ref{lb952} and \ref{lb955}.
\end{proof}



\begin{eg}\label{mc16}
$A=\{(x,y)\in\Rbb_{\geq0}\times\Rbb:y=x^2\text{ or }y=-x^4\}$ is not a smooth submanifold of $\Rbb^2$.
\end{eg}

\begin{proof}
$A\setminus \{0\}$ is a smooth $1$-dimensional submanifold of $\Rbb^2$. Assume that $A$ is a smooth submanifold of $\Rbb^2$, then by Prop. \ref{lb982} we have $\dim_0 A=1$. Let $\iota:A\rightarrow\Rbb^2$ be the inclusion map, which is smooth. Let $\gamma:[0,+\infty)\rightarrow A$ be $\gamma(t)=(t,t^2)$. Since $\iota\circ\gamma:[0,+\infty)\rightarrow\Rbb^2$ is smooth, by Prop. \ref{mc17}, $\gamma$ is smooth. Note that $d\iota|_0:T_0A\rightarrow\Rbb^2$ is the inclusion map, and  $d\iota|_0$ sends $\gamma'(0)$ to $(\iota\circ\gamma)'(0)=(1,0)$ by \eqref{eq420}. Therefore, $T_0A$, as a $1$-dimensional subspace of $\Rbb^2$, is spanned by $(1,0)$. 

Let $\pi:\Rbb^2\rightarrow\Rbb$ be the projection onto the first component. Then $d(\pi\circ\iota)=d\pi\cdot d\iota$ sends $(1,0)$ to $(1,0)$. Therefore, by the geometric inverse function Thm. \ref{lb980}, $\pi\circ\iota$ is injective on a neighborhood of $0$ in $A$. But this is clearly impossible.
\end{proof}


\begin{exe}\label{mc24}
Let $N$ be an $n$-dimensional smooth manifold. Let $M$ be an $n$-dimensional smooth $\partial$-submanifold of $N$. Prove that the manifold interior of $M$ (cf. Def. \ref{mc23}) is equal to the topological interior $\Int_N(M)$ of $M$ with respect to $N$ (cf. Def. \ref{lb187}).
\end{exe}

\begin{sexe}
Let $A=\Rbb_{\geq0}\times\Rbb_{\geq0}$. Prove that $A$ is not a smooth $\partial$-submanifold of $\Rbb^2$. 
\end{sexe}
\begin{proof}[Hint]
If $A$ is a smooth $\partial$-submanifold, let $\iota:A\rightarrow\Rbb^2$ be the inclusion map. Show that $\dim A=2$. To find a contradiction, either study the shape of $d\iota (T^+_0A)$, or use Exe. \ref{mc24} to show that $\partial A=[0,+\infty)\times[0,+\infty)$ and then show that $\partial A$ is not a smooth submanifold of $\Rbb^2$.
\end{proof}









\subsection{The geometric implicit and inverse function theorems}

In this section, we let $M,N$ be a smooth $\partial$-manifolds.


\begin{df}
Assume that $\partial N=\emptyset$. We say that $F:M\rightarrow N$ is a \textbf{(smooth) embedding} \index{00@Embedding of $\partial$-manifolds} if $F(M)$ is a smooth $\partial$-submanifold of $N$, and if $F$ restricts to a diffeomorphism of smooth $\partial$-manifolds $F:M\rightarrow F(M)$.
\end{df}

\begin{pp}
Assume that $\partial N=\emptyset$, and $F:M\rightarrow N$ is a smooth embedding. Then for each $p\in M$, the differential $dF|_p:T_pM\rightarrow T_{F(p)}N$ is injective. Therefore, if $M$ is a smooth $\partial$-submanifold of $N$ and $F$ is the inclusion map, unless otherwise stated, we identify $T_pM$ with $dF|_p(T_pM)$ via the map $dF|_p$.
\end{pp}


\begin{proof}
Similar to Prop. \ref{lb975}.
\end{proof}









\subsubsection{The geometric implicit function theorem}


The following \textbf{geometric implicit function theorem} \index{00@Geometric implicit function theorem} is similar to Thm. \ref{lb976}.

\begin{thm}\label{lb999}
Assume that $\partial M=\partial N=\emptyset$. Let $F:M\rightarrow N\times\Rbb$ be smooth. Let $q\in N$ and $P=F^{-1}(\{q\}\times\Rbb_{\geq0})$. Assume that $F$ is a \textbf{submersion} at every $p\in P$, i.e., $dF|_p:T_pM\rightarrow T_{F(p)}(N\times\Rbb)$ is surjective. Then $P$ is a smooth $\partial$-submanifold of $M$, and 
\begin{align}
\partial P=F^{-1}(\{q\}\times\{0\})
\end{align}
Moreover, if we write $F=F'\vee F''\equiv (F',F'')$ where $F':M\rightarrow N$ and $F'':M\rightarrow\Rbb$, then for each $p\in P$, we have
\begin{align}\label{eq418}
T_pP=\Ker (dF'|_p)
\end{align}
In particular, we have
\begin{align}\label{eq419}
\dim_pP=\dim_pM-\dim_qN
\end{align}
\end{thm}

\begin{proof}
It suffices to find a $V\in\Nbh_N(q)$ diffeomorphic to an open subset of $\Rbb^k$ and show that $P$ is a smooth $\partial$-submanifold of $F^{-1}(V\times\Rbb)$. Therefore, by shrinking $N$ to $V$ and $M$ to $F^{-1}(V\times\Rbb)$, it suffices to assume that $N$ is an open subset of $\Rbb^k$ and $q=0$. Thus we can write $F=(F^1,\dots,F^{k+1})$ where each $F^i:M\rightarrow\Rbb$ is smooth. 

It suffices to assume that $N$ is an open subset of $\Rbb^k$ and $q=0$. We shall show that for each $p\in P$ there exists $U\in\Nbh_M(p)$ such that $P\cap U$ is a smooth $\partial$-submanifold of $U$. Therefore, by shrinking $M$ to a neighborhood of $p$, we may assume that $M$ is an open subset of $\Rbb^{n+1}$.  By assumption, $\Jac F|_p$ is surjective. Therefore $n\geq k$. 

Let $d=n-k$, and let $(x^1,\dots,x^{k+1},y^1,\dots,y^d)$ be the standard coordinates of $\Rbb^{n+1}$. Moreover, by changing the order of these coordinates, we may assume that $\Jac_{(x^1,\dots,x^{k+1})}F|_p$ is invertible. Therefore, by Cor. \ref{lb932}, we have a diffeomorphism
\begin{align*}
(F,y)\equiv(F^1,\dots,F^{k+1},y^1,\dots,y^d):U\xlongrightarrow{\simeq} V
\end{align*}
where $U\in\Nbh_M(p)$ and $V\in\Nbh_{\Rbb^{k+d+1}}(0)$. Therefore, similar to Rem. \ref{lb935}, we have a commutative diagram
\begin{equation}
\begin{tikzcd}[column sep=4cm]
P\cap U \arrow[r,"{(0,\dots,0,F^{k+1},y^1,\dots,y^d)}"] \arrow[d, hook] & (0_k\times \Hbb^{d+1})\cap V \arrow[d, hook] \\
U \arrow[r,"{(F^1,\dots,F^k,F^{k+1},y^1,\dots,y^d)}","\simeq"']                 & (\Rbb^{k+d+1})\cap V=V            
\end{tikzcd}
\end{equation}
The top arrow is surjective (since the inverse image of $(0_k\times \Hbb^{d+1})\cap V$ under the bottom arrow is $P\cap U$) and hence is bijective. This proves that $P\cap U$ is a smooth $\partial$-submanifold of $U$, and that $(F^{k+1},y^1,\dots,y^d)$ is a coordinate on $P\cap U$. Therefore, a point $p'\in U\cap P$ belongs to $\partial P\cap U$ iff its first coordinate $F^{k+1}(p')$ is zero, i.e., iff $p'\in F^{-1}(\{q\}\times\{0\})$. Thus $\partial P\cap U=F^{-1}(\{q\}\times\{0\})\cap U$. It also proves that $\dim_pP=d+1$. Since $\dim_pM=n+1$ and $\dim_qN=k$, we have \eqref{eq419}. 

Clearly $F'=(F^1,\dots,F^k)$ and $F''=F^{k+1}$. If $\gamma:[0,\eps)$ is a smooth right path in $P$ satisfying $\gamma(0)=p$, then by \eqref{eq420} we have $dF'|_p\cdot \partial_t\gamma(0)=\partial_t(F'\circ\gamma)(0)$ where the RHS is zero since $F'\circ\gamma$ is always $0$. This proves $T_p^+P\subset\Ker(dF'|_p)$, and hence (by the linearity) $T_pP\subset\Ker(dF'|_p)$. Since $\Jac F|_p=\Jac(F^1,\dots,F^{k+1})$ is surjective, $\Jac F'|_p=\Jac(F^1,\dots,F^k)$ is a surjective $k\times(n+1)$ matrix. Therefore $\Ker(dF'|_p)$ has dimenion $n+1-k=d+1=\dim_pP$. This proves \eqref{eq418}.

Since the above discussion holds for every $p\in P$, We have finished proving that $P$ is a smooth $\partial$-submanifold of $N$ with boundary $F^{-1}(\{q\}\times\{0\})$. 
\end{proof}


\begin{sexe}\label{mc3}
Assume that $\partial M=\partial N=\emptyset$. Let $F:M\rightarrow N$ be a smooth map. Let $S$ be a smooth $\partial$-submanifold of $N$. Assume that $F$ is a submersion at every $p\in F^{-1}(S)$. Prove that $F^{-1}(S)$ is a smooth $\partial$-submanifold of $M$, and
\begin{align}
\partial F^{-1}(S)=F^{-1}(\partial S)
\end{align}
For each $p\in F^{-1}(S)$ and $q=F(p)$, prove that
\begin{align}
T_pF^{-1}(S)=(dF|_p)^{-1}(T_qS)
\end{align}
Conclude that
\begin{align}
\dim_p F^{-1}(S)=\dim_p M-\dim_qN+\dim_qS
\end{align}
\end{sexe}


\begin{proof}[Hint]
Reduce to the case that $N$ is a neighborhood of $0\in\Rbb^k\times\Rbb^d$ and $S=(0_k\times\Hbb^d)\cap N$. If $q\in\partial S$ then $d\geq1$. Let $\pi:\Rbb^k\times\Hbb^d\rightarrow\Rbb^{k+1}$ send $(a_1,\dots,a_{k+d})$ to $(a_1,\dots,a_{k+1})$. Apply Thm. \ref{lb999} to $\pi\circ F$.
\end{proof}


\begin{eg}\label{mc11}
Let $0<R<+\infty$. By Thm. \ref{lb999}, $\ovl B_{\Rbb^n}(0,R)$ is a smooth $n$-dimensional $\partial$-submanifold of $\Rbb^n$ with boundary $R\Sbb^n$. Similarly, $\{p\in\Rbb^n:\Vert p\Vert\geq R\}$ is a smooth $n$-dimensional $\partial$-submanifold of $\Rbb^n$ with boundary $R\Sbb^n$.
\end{eg}


\begin{eg}\label{mc2}
Let $0<r<R<+\infty$. Let $M=\{p\in\Rbb^n:r\leq\Vert p\Vert\leq R\}$. Then $M$ is a smooth $n$-dimensional $\partial$-submanifold of $\Rbb^n$ with boundary $r\Sbb^n\cup R\Sbb^1$.
\end{eg}


\begin{proof}
If $\Vert p\Vert=r$, choose $U\in\Nbh_{\Rbb^n}(p)$ inside $R\Sbb^n$. Then by Thm. \ref{lb999}, $U\cap M$ is a smooth $n$-dimensional $\partial$-submanifold of $U$ with boundary $r\Sbb^1\cap U$. Similarly, if $\Vert p\Vert=R$, choose $U\in\Nbh_{\Rbb^n}(p)$ outside $r\Sbb^n$. Then $U\cap M$ is a smooth $n$-dimensional $\partial$-submanifold of $U$ with boundary $R\Sbb^1\cap U$. If $r<\Vert p\Vert<R$, choose $U\in\Nbh_{\Rbb^n}(p)$ between $r\Rbb^n$ and $R\Sbb^n$. Then $U\cap M=U$ is clearly a smooth $n$-dimensional submanifold of $U$. This finishes the proof since what we need to prove can be checked locally, cf. Rem. \ref{mc1}.
\end{proof}

\begin{rem}
Exp. \ref{mc2} can also be proved by applying Exe. \ref{mc3} to the map $f:\Rbb^n\rightarrow\Rbb$ and the $\partial$-submanifold $[r,R]$ of $\Rbb$. However, this shortcut proof does not apply directly to the case $M=\ovl B_{\Rbb^n}(0,R)\setminus \Omega$ where $\Omega$ is an open ball (or even an open ellipsoid) inside $B_{\Rbb^n}(0,R)$ whose center is not $0$. On the other hand, the above proof of Exp. \ref{mc2} (by using Thm. \ref{lb999} together with Rem. \ref{mc1}) still works.
\end{rem}


\begin{eg}\label{mc4}
Let $-1<a<1$. Let 
\begin{align}
M=\{p\in\Rbb^{n+1}:(p_1)^2+\cdots+(p_n)^2+(p_{n+1})^2=1,p_{n+1}\geq a\}
\end{align}
Then $M$ is a smooth $n$-dimensional $\partial$-submanifold of $\Rbb^{n+1}$ with boundary
\begin{align}\label{eq421}
\partial M=\{p\in\Rbb^{n+1}:(p_1)^2+\cdots+(p_n)^2+(p_{n+1})^2=1,p_n=a\}
\end{align}
\end{eg}


\begin{proof}
Let $F=(F^1,F^2):\Rbb^{n+1}\rightarrow\Rbb^2$ where $F^1=(x^1)^2+\cdots+(x^{n+1})^2-1$ and $F^2=x^{n+1}-a$. Then
\begin{align*}
\Jac F=\begin{pmatrix}
2x^1&\cdots &2x^n&2x^{n+1}\\
0&\cdots&0&1
\end{pmatrix}
\end{align*} 
is surjective on $U=\Rbb^{n+1}\setminus (0_n\times\Rbb)$. Therefore, by Thm. \ref{lb999}, $M\cap U$ is a smooth $\partial$-submanifold of $U$ whose boundary is the RHS of \eqref{eq421}. If $p\in M\setminus U$, then $p=(0,\dots,0,1)$. Then there exists $V\in\Nbh_{\Rbb^{n+1}}(p)$ such that $M\cap V=\Sbb^n\cap V$. So $M\cap V$ is a smooth submanifold of $V$ (without boundary). This finishes the proof.
\end{proof}


%In Exp. \ref{mc4}, we have a direct way to see that $\Jac F$ is surjective on $\Rbb^{n+1}\setminus(0_k\times\Rbb)$ without explicitly calculating $\Jac F$: One can show that $\Jac F$ is surjective at $\{p:F^1(p)=F^2(p)=0\}$ iff the tangent space of $\{F^1=0\}$ at $p$ is not contained in the ($n-1$ dimensional) tangent space of $\{F^2=0\}$ at $p$. Let us prove this equivalence in a more general setting. 

One can also solve Exp. \ref{mc4} without computing the Jacobian:

\begin{co}\label{mc6}
Let $\Omega$ be a smooth manifold (without boundary). Let $M$ be a smooth $d$-dimensional submanifold of $\Omega$. Let $f\in C^\infty(\Omega,\Rbb)$ and $Z(f)=\{p\in\Omega:f(p)=0\}$. Assume that for each $p\in M\cap Z(f)$, the tangent space $T_pM$ (as a subspace of $T_p\Omega$) is not contained in $\Ker(df|_p)$. Then
\begin{align*}
P=\{p\in M:f(p)\geq0\}
\end{align*}
is a smooth $d$-dimensional $\partial$-submanifold of $M$ with boundary
\begin{align*}
\partial P=M\cap Z(f)
\end{align*}
\end{co}

It follows from Exe. \ref{mc5} that $P$ is also a smooth $d$-dimensional $\partial$-submanifold of $\Omega$.

\begin{proof}
By Rem. \ref{mc1}, it suffices to show that for each $p\in P$ there exists $U\in\Nbh_M(p)$ such that $P\cap U$ is a smooth $d$-dimensional $\partial$-submanifold of $U$ with boundary $U\cap Z(f)$. This is clearly true when $f(p)>0$. So we assume $f(p)=0$, i.e., $p\in Z(f)$. 

Let $g=f|_M$. Let $\iota:M\hookrightarrow\Omega$ be the inclusion. So $g=f\circ\iota$, and hence $dg|_p=df|_p\cdot d\iota|_p$. In other words, $dg|_p:T_pM\rightarrow\Rbb$ is the restriction of $df|_p:T_p\Omega\rightarrow\Rbb$ to $T_pM$. By assumption, $df|_p$ does not vanish on $T_pM$. So $dg|_p\neq0$. Thus, there exists $U\in\Nbh_M(p)$ such that $dg$ is nowhere zero on $U$. Therefore, by Thm. \ref{lb999}, $\{q\in U:f(q)\geq0\}$ is a smooth $d$-dimensional $\partial$-submanifold of $U$ with boundary $U\cap Z(f)$. This finishes the proof.
\end{proof}


\begin{proof}[\textbf{Second proof of Exp. \ref{mc4}}]
Let $f=x^{n+1}-a:\Rbb^{n+1}\rightarrow\Rbb$. Then for each $p\in\Rbb^{n+1}$, $\Ker(df|_p)$ is the orthogonal complement of $(0,\dots,0,1)$. If $p\in\Sbb^n\cap Z(f)$, the tangent space $T_pS^n$ is not orthogonal to $(0,\dots,0,1)$, and hence is not contained in $\Ker(df|_p)$. This finishes the proof thanks to Cor. \ref{mc6}.
\end{proof}

%% Record #20 2024/05/11 three lectures  49



\subsubsection{$\star$ Transversal intersections}


Now, one may wonder if the two methods of proving Exp. \ref{mc4} are equivalent. One can also consider a similar situation: Let $\Omega$ be an open subset of $\Rbb^n$. Let $F=(F^1,\dots,F^k)$ and $G=(G^1,\dots,G^d)$ be smooth maps on $\Omega$ that are submersions at every point of $\Omega$. So $M=Z(G)$ is a smooth submanifold of $\Omega$. In order to prove that $M\cap Z(F)$ is a smooth submanifold of $\Omega$, one can either show that $\Jac(F^1,\dots,F^k,G^1,\dots,G^d)$ is surjective everywhere on $M\cap Z(F)$, or show that $d(F|_M):TM\rightarrow\Rbb^k$ is surjective everywhere on $M\cap Z(F)$. The following exercise shows that these two methods are equivalent.

\begin{exe}\label{mc7}
Let $\Omega$ be a smooth manifold. Let $F=(F^1,\dots,F^k):\Omega\rightarrow\Rbb^k$ be smooth. Assume that $\Jac F$ is surjective everywhere on $\Omega$. Let $M$ be a smooth $\partial$-submanifold of $\Omega$. Let $\wtd F=F|_M$.
\begin{enumerate}
\item Let $p\in M\cap Z(F)$. Prove that $d\wtd F|_p:T_pM\rightarrow\Rbb^k$ is surjective iff $T_pM+\Ker (dF|_p)=T_p\Omega$. %In this case, we say that $F$ and $M$ \textbf{intersect transversally} at $p$.
\item Assume that $M=Z(G)$ where $G=(G^1,\dots,G^d):\Omega\rightarrow\Rbb$ is smooth and is a submersion at every point of $Z(G)$. Let $p\in M\cap Z(F)$. Prove that $d\wtd F|_p:T_pM\rightarrow\Rbb^k$ is surjective iff $\Jac (F^1,\dots,F^k,G^1,\dots,G^d)|_p$ is surjective. 
\end{enumerate}
\end{exe}

\begin{rem}
If $p$ is as in Part 2 Exe. \ref{mc7}, we say that $M$ and $Z(G)$ intersect transversally at $p$. More generally, assume that $M_1,M_2$ are smooth submanifolds of a smooth manifold $\Omega$. Let $p\in M_1\cap M_2$. We say that $M_1$ and $M_2$ \textbf{intersect transversally at $p$} \index{00@Intersect transversally} if $T_pM_1+T_pM_2=T_p\Omega$. We say that $M_1,M_2$ \textbf{intersect transversally} and write $M_1\pitchfork M_2$ if they intersect transversally at every point of $M_1\cap M_2$.
\end{rem}

To solve Part 2 of Exe. \ref{mc7}, you may first need to prove the following fact:

\begin{exe}
Let $\mc U,\mc V,\mc W$ be finite-dimensional vector spaces over a field $\Kbb$. Let $F:\mc U\rightarrow\mc V$ and $G:\mc U\rightarrow \mc W$ be surjective linear maps. Let $T:\mc U\rightarrow\mc V\oplus\mc W$ send each $\xi\in\mc U$ to $F\xi\oplus G\xi$. Prove that $\mc U=\Ker(F)+\Ker(G)$ iff $T$ is surjective.
\end{exe}

\begin{proof}[Hint]
Assume WLOG that $\mc U=\Kbb^n$, $\mc V=\Kbb^k$, $\mc W=\Kbb^d$. Then $(\Ker(F)+\Ker(G))^\perp=\Ker(F)^\perp\cap\Ker(G)^\perp$.
\end{proof}


\subsubsection{The geometric inverse function theorem}

Recall that $M,N$ are smooth $\partial$-manifolds.

\begin{thm}[\textbf{Inverse function theorem}]\index{00@Inverse function theorem}\label{mc9}
Let $F:M\rightarrow N$ be smooth and satisfying $F(\partial M)\subset\partial N$. Let $p\in M$ and $q=F(p)$. Assume that $dF|_p:T_pM\rightarrow T_qN$ is a linear isomorphism.  Then there exist $U\in\Nbh_M(p)$ and $V\in\Nbh_N(q)$ such that $F$ restricts to a diffeomorphism $F:U\xrightarrow{\simeq} V$.
\end{thm}

\begin{proof}
This follows immediately from Thm. \ref{mc8}.
\end{proof}

\begin{co}\label{mc10}
Let $F:M\rightarrow N$ be a smooth injective map satisfying $F(\partial M)\subset\partial N$. Assume that $dF|_p:T_pM\rightarrow T_{F(p)}N$ is bijective for each $p\in M$. Then $F(M)$ is an open subset of $N$, and $F$ restricts to a diffeomorphism $F:M\xrightarrow{\simeq}F(M)$.
\end{co}


\begin{proof}
This follows from Thm. \ref{mc9} in the same way that Cor. \ref{lb981} follows from Thm. \ref{lb980} and Cor. \ref{lb954} follows from Thm. \ref{lb929}.
\end{proof}


Without the assumption $F(\partial M)\subset\partial N$, Cor. \ref{mc10} is clearly false: Consider $M=[0,2\pi)$, $N=\Sbb^1$, and $F(t)=e^{\im t}$.

\begin{thm}\label{mc12}
Assume $\dim M=n$ and $\partial N=\emptyset$. Let $F:M\rightarrow N$ be a smooth injective map. Then $F$ is a smooth embedding iff the following two conditions are satisfied:
\begin{enumerate}
\item[(a)] $F$ is an \textbf{immersion} at each $p\in M$, which means that $dF|_p:T_pM\rightarrow T_{F(p)}N$ is injective.
\item[(b)] $F(M)$ is an $n$-dimensional smooth $\partial$-submanifold of $N$, and $F(\partial M)\subset\partial F(M)$.
\end{enumerate}
\end{thm}


\begin{proof}
This follows from Cor. \ref{mc10} in the same way that Thm. \ref{lb983} follows from Cor. \ref{lb981}.
\end{proof}


\begin{eg}
Let $0<a<1$ and $M=\{p=(p_1,\dots,p_{n+1})\in\Sbb^n:p_{n+1}\geq a\}$. By Exp. \ref{mc4}, $M$ is a smooth $\partial$-submanifold of $\Rbb^{n+1}$ with boundary $\partial M=r\Sbb^{n-1}\times \{a\}$ where $r=\sqrt{1-a^2}$. Define $F:\ovl B_{\Rbb^n}(0,r)\rightarrow\Rbb^{n+1}$ by $F(q)=(q,\sqrt{1-\Vert q\Vert^2})$. Then $F$ is smooth because it is smooth on the open set $B_{\Rbb^n}(0,\frac {r+1}2)$. By Exp. \ref{mc11}, $D:=\ovl B_{\Rbb^n}(0,r)$ is a smooth $n$-dimensional $\partial$-submanifold of $\Rbb^n$ with boundary $r\Sbb^{n-1}$. So $D$ and $M$ have the same dimension, $F$ is injective, $F(D)=M$, and $F(\partial D)=\partial M$. For each $q\in D$, $\Jac F|_q$ is clearly injective. Therefore, by Thm. \ref{mc12}, $F$ restricts to a parametrization $F:D\xrightarrow{\simeq}M$.
\end{eg}


The above example shows that Thm. \ref{mc12} is very useful for finding parametrizations of $\partial$-submanifolds. In the next section, we will show that condition (b) of Thm. \ref{mc12} is redundant if we assume moreover that $M$ is compact.



\subsection{Immersions and embeddings}



Fix smooth $\partial$-manifolds $M,N$.


The goal of this section is to answer the following question: What happens if we remove the condition (b) in Thm. \ref{mc12}?


\begin{df}
Let $F:M\rightarrow N$ be smooth. We say that $F$ is an \textbf{immersion at $p\in M$} \index{00@Immersion} if $dF|_p:T_pM\rightarrow T_{F(p)}N$ is injective. We say that $F$ is an \textbf{immersion} if it so at every point of $M$.
\end{df}

\begin{eg}\label{mc19}
Assume $\partial N=\emptyset$. Suppose that $F:M\rightarrow N$ is a smooth embedding. Then by the proof of Prop. \ref{lb975}, $F$ is an immersion.
\end{eg}


\begin{thm}\label{mc20}
Assume that $\partial N=\emptyset$. Let $F:M\rightarrow N$ be smooth. Let $p\in M$. Then the following are equivalent:
\begin{enumerate}
\item[(1)] $F$ is an immersion at $p$.
\item[(2)] There exists $U\in\Nbh_M(p)$ such that the restriction $F|_U:U\rightarrow N$ is a smooth embedding.
\end{enumerate}
\end{thm}

\begin{proof}
Assume (2). Then (1) follows from Exp. \ref{mc19} (applied to $F|_U:U\rightarrow N$).

Assume (1). Let $q=F(p)$. If we can find $U\in\Nbh_M(p)$ and $V\in\Nbh_N(q)$ such that $U\subset F^{-1}(V)$ and that $F|_U:U\rightarrow V$ is an embedding, then $F(U)$ is a smooth $\partial$-submanifold of $V$, and hence is a smooth $\partial$-submanifold of $N$. Then $F|_U$ clearly restricts to a diffeomorphism $F|_U:U\rightarrow F(U)$. 

From the above discussion, we may shrink $M$ and $N$ to neighborhoods of $p,q$ such that $F(M)\subset N$, and that $M,N$ are open subsets of $\Hbb^m,\Rbb^n$ respectively. Moreover, by Def. \ref{mc14}, we may assume that $F$ can be extended to a smooth map $F:\wtd M\rightarrow\Rbb^n$ where $\wtd M$ is an open subset of $\Rbb^m$ and
\begin{align*}
\Hbb^m\cap\wtd M=M  \tag{$\star$}\label{eq483}
\end{align*}
We may also assume that $p=0$. Since $\Jac F|_p$ is injective, we must have $m\leq n$. Moreover, one can find $m$ components of $F=(F^1,\dots,F^n)$ whose Jacobian at $0$ is invertible. By composing $F$ with an invertible linear map on the left, we assume WLOG that $\Jac F'$ is invertible at $0$ where $F'=(F^1,\dots,F^m)$ and $F''=(F^{m+1},\dots,F^n)$.

Let $k=n-m$. Let $(x^1,\dots,x^m,y^1,\dots,y^k)$ be the standard coordinates of $\Rbb^n$. Let $G:\wtd M\times\Rbb^k\rightarrow\Rbb^n$ be
\begin{align*}
G(x^1,\dots,x^m,y^1,\dots,y^k)=F(x^1,\dots,x^m)+\sum_{j=1}^k y^je_{m+j}
\end{align*}
where $e_1,\dots,e_n$ are the standard basis of $\Rbb^n$. Then
\begin{align*}
\Jac G=\begin{pmatrix}
\Jac_x F'& 0_{m\times k}\\
\Jac_x F''& 1_{k\times k}
\end{pmatrix}
\end{align*}
is invertible at $0$. Therefore, by the inverse function Thm. \ref{lb929}, $G$ restricts to a diffeomorphism $G|_\Omega:\Omega\rightarrow\Delta$ where $\Omega\subset\wtd M,\Delta\subset N$ are open and $0\in\Omega$. We then have a commutative diagram
\begin{equation}
\begin{tikzcd}[column sep=2cm]
(M\times 0_k)\cap\Omega \arrow[r,"F|_{M\cap\Omega}"] \arrow[d, hook] & F(M\cap\Omega) \arrow[d, hook] \\
\Omega \arrow[r,"G","\simeq"']                 & \Delta                
\end{tikzcd}
\end{equation}
where $M$ and $M\times 0_k$ are identified in the obvious way. The top arrow is clearly surjective, and hence is bijective by the commutativity of the diagram. By \eqref{eq483} and $\Omega\subset\wtd M$, we have $(M\times 0_k)\cap\Omega=(\Hbb^m\times 0_k)\cap\Omega$. Therefore, by Def. \ref{mc13}, $F(M\cap\Omega)$ is a smooth $\partial$-submanifold of $N$ with (smooth) parametrization $F:M\cap\Omega=(\Hbb^m\times 0_k)\cap\Omega\rightarrow F(M\cap\Omega)$. This proves that $F:M\cap\Omega\rightarrow N$ is a smooth embedding.
\end{proof}

A smooth injective immersion is not necessarily an embedding: 

\begin{eg}\label{mc127}
Consider the map $F:\Rbb\rightarrow \Rbb^2$ in Fig. \ref{mc18}. Then $A:=F(\Rbb)$ is not a smooth submanifold of $\Rbb^2$. Otherwise, similar to the proof of Exp. \ref{mc16}, one can find smooth right paths $\gamma_1,\gamma_2:[0,+\eps)\rightarrow A$ such that $\gamma_1(0)=\gamma_2(0)=p$, and that $\gamma_1'(0)$ and $\gamma_2'(0)$ are linearly independent. So $\dim T_pA=2$. This is impossible, since $A\setminus\{p\}$ is a smooth submanifold of $\Rbb^2$ of dimension $1$.\begin{figure}[h]
	\centering
\begin{equation*}
\vcenter{\hbox{{
			\includegraphics[height=1.2cm]{fig12.png}}}}
\end{equation*}
	\caption{. A smooth injective immersion which is not an embedding.}\label{mc18}
\end{figure}
\end{eg}

\begin{eg}\label{mc128}
Let $M=\{t\in\Rbb:0<t<1\}\times\{0,1\}$. Let $F:M\rightarrow\Rbb^2$ send $(t,0)$ to $(t,\sin(t^{-1}))$ and send $(t,1)$ to $(0,2t-1)$. Then $F(M)$, the topologist's sine curve, has no path connected neighborhood at $0\in\Rbb^2$, and hence is not a smooth manifold. So $F$ is not a smooth embedding, although $F$ is an injective immersion.
\end{eg}


\begin{rem}
Thm. \ref{mc20}, Exp. \ref{mc127}, and Exp. \ref{mc128} tell us that any immersion must be a local embedding, but not necessarily a global embedding. Therefore, they seem at odds with our familiar principle that one can check locally whether a subset is a smooth $\partial$-submanifold. The issue here is that Thm. \ref{mc20} concerns the locality on the domains but not on the codomains. In fact, the correct locality principle for embedding should be as follows:  %This principle follows easily from the following Thm. \ref{mc21}.
\end{rem}


\begin{pp}\label{mc129}
Let $F:M\rightarrow N$ be a smooth injective map where $\partial N=\emptyset$. Suppose that $\fk V$ is a collection of open subsets of $N$ covering $F(M)$. Then $F$ is a smooth embedding iff for each $V\in\fk V$, $F|_{F^{-1}(V)}:F^{-1}(V)\rightarrow N$ is a smooth embedding (equivalently, $F|_{F^{-1}(V)}:F^{-1}(V)\rightarrow V$ is a smooth embedding).
\end{pp}


\begin{proof}
Let $S=F(M)$. Since for each $V\in \fk V$, $S\cap V$ is a smooth $\partial$-submanifold of $N$, $S$ must be a smooth $\partial$-submanifold of $N$. Let $\wtd F:M\rightarrow S$ be the restriction of $F$, which is bijective and smooth (by Prop. \ref{mc17}). For each $V\in\fk V$, since  $F|_{F^{-1}(V)}:F^{-1}(V)\rightarrow N$ is a smooth embedding, $\wtd F|_{F^{-1}(V)}:F^{-1}(V)\rightarrow S\cap V$ must be a diffeomorphism of smooth $\partial$-manifolds. Therefore $\wtd F^{-1}:S\rightarrow M$ is smooth on $S\cap V$ for each $V\in\fk V$. Therefore $\wtd F^{-1}$ is smooth, and hence $\wtd F$ is a diffeomorphism. Thus $F$ is a smooth embedding.
\end{proof}





Thm. \ref{mc12} gives a useful criterion for a smooth injective immersion to be a smooth embedding. We now give another one:


\begin{thm}\label{mc21}
Assume that $\partial N=\emptyset$. Let $F:M\rightarrow N$ be a smooth injective map. Then $F$ is a smooth embedding iff the following two conditions are satisfied:
\begin{enumerate}
\item[(a)] $F$ is an immersion.
\item[(b)] $F$ is a \textbf{topological embedding}, \index{00@Topological embedding} which means that $F:M\rightarrow F(M)$ is a homeomorphism where $F(M)$ is equipped with the subspace topology (inherited from $N$).
\end{enumerate}
\end{thm}

We have seen topological embeddings before: In Sec. \ref{lb473}, we used topological embeddings of compact Hausdorff spaces into $[0,1]^{\scr I}$ to prove the Stone-Weierstrass theorem.

Note that by Thm. \ref{lb236}, condition (b) is automatically satisfied if $M$ is compact.

\begin{proof}
If $F$ is a smooth embedding, then by Exp. \ref{mc19}, $F$ satisfies (a) and (b). Conversely, assume (a) and (b). Then by (a) and Thm. \ref{mc20}, for each $p\in M$ there exists $U_p\in\Nbh_M(p)$ such that $F|_{U_p}:U_p\rightarrow N$ is a smooth embedding. By (b), $F(U_p)$ is open in $S:=F(M)$. Thus $F(U_p)=S\cap V_p$ for some $V_p\in\Nbh_N(F(p))$. Now, $\fk V=\{V_p:p\in M\}$ is a collection of open subsets of $N$ containing $S$. Moreover, for each $p\in M$, $F|_{F^{-1}(V_p)}:F^{-1}(V_p)\rightarrow N$ is a smooth embedding since $F^{-1}(V_p)=U_p$. Therefore, by Prop. \ref{mc129}, $F$ is a smooth embedding.
\end{proof}




As an application of Thm. \ref{mc21}, we have:

\begin{thm}\label{mc22}
Let $M,N,S$ be smooth $\partial$-manifolds where $\partial N=\partial S=\emptyset$. Let $\kappa:N\rightarrow S$ be a smooth embedding. Let $F:M\rightarrow N$ be a map. The following are true.
\begin{enumerate}
\item[(a)] $F:M\rightarrow N$ is smooth iff $\kappa\circ F:M\rightarrow S$ is smooth.
\item[(b)] $F:M\rightarrow N$ is an immersion iff $\kappa\circ F:M\rightarrow S$ is an immersion.
\item[(c)] $F:M\rightarrow N$ is a smooth embedding iff $\kappa\circ F:M\rightarrow S$ is a smooth embedding. 
\end{enumerate}
\end{thm}



\begin{proof}
(a) is due to Prop. \ref{mc17}. (b) is due to the fact that $d\kappa_q:T_qN\rightarrow T_{\kappa(q)}S$ is injective for every $q\in N$. It is easy to show (e.g. by using net convergence) that $F$ is a topological embedding iff $\kappa\circ F$ is a topological embedding. Therefore, (c) follows from (b) and Thm. \ref{mc21}. 
\end{proof}


The following corollary is a variant of Part (c) of Thm. \ref{mc22}. Part of this corollary can be checked directly without using Thm. \ref{mc22}, cf. Exe. \ref{mc5}. The most nontrivial part of this corollary ``$\Leftarrow$".

\begin{co}
Let $S$ be a smooth manifold. Let $N$ be a smooth submanifold of $S$. Let $M\subset N$. Then $M$ is a smooth $\partial$-submanifold of $N$ iff $M$ is a smooth $\partial$-submanifold of $S$. Moreover, if these two equivalent statements are true, the smooth structure of $M$ as a smooth $\partial$-submanifold of $N$ is equal to the smooth structure of $M$ as smooth $\partial$-submanifold of $S$.
\end{co}


\begin{proof}
To avoid conflict of notations, if $Y$ is a smooth manifold and $X\subset Y$ is a smooth $\partial$-submanifold, we let  $\scr C^\infty_{X,Y}$ denote the smooth structure of $X$ as a smooth $\partial$-submanifold of $Y$. Therefore, if $\Omega$ is a smooth $\partial$-manifold and $F:\Omega\rightarrow Y$ is a smooth embedding, then $F$ restricts to a diffeomorphism $\Omega\xrightarrow{\simeq}(F(\Omega),\scr C^\infty_{F(\Omega),Y})$.

Let $\kappa:N\hookrightarrow S$ be the inclusion map, which is a smooth embedding. Let also $F:M\hookrightarrow N$ be the inclusion map. We first assume that $M$ is a smooth $\partial$-submanifold of $N$. Then $F:(M,\scr C^\infty_{M,N})\rightarrow N$ is a smooth embedding. By Thm. \ref{mc22}, $\iota\circ F:(M,\scr C^\infty_{M,N})\rightarrow S$ is a smooth embedding. Therefore, the range of $\iota\circ F$ (which is $M$) is a smooth $\partial$-submanifold of $S$, and (by the first paragraph) $\iota\circ F$ restricts to a diffeomorphism $(M,\scr C^\infty_{M,N})\xrightarrow{\simeq} (M,\scr C^\infty_{M,S})$. This proves $\scr C^\infty_{M,N}=\scr C^\infty_{M,S}$.

Conversely, assume that $M$ is a smooth $\partial$-submanifold of $S$. Then $\iota\circ F:(M,\scr C^\infty_{M,S})\rightarrow S$ is a smooth embedding. By Thm. \ref{mc22}, $F:(M,\scr C^\infty_{M,S})\rightarrow N$ is a smooth embedding. Therefore, its range $M$ is a smooth $\partial$-submanifold of $N$. 
\end{proof}



\subsection{Smooth Urysohn's lemma and partitions of unity}

We fix a smooth $\partial$-manifold $M$. The goal of this section is to generalize the results in Sec. \ref{lb464} to smooth functions on $M$. Let \index{Cc@$C^\infty_c$}
\begin{align}
C^\infty_c(M,\Rbb^k)=C_c(M,\Rbb^k)\cap C^\infty(M,\Rbb^k)
\end{align}
If $U\subset M$ is open, then $C^\infty_c(U,\Rbb^k)$ is naturally a linear subspace of $C^\infty_c(M,\Rbb^k)$. More precisely, $C^\infty_c(U,\Rbb^k)$ can be viewed as the set of all $f\in C_c^\infty(M,\Rbb^k)$ satisfying $\Supp(f)\subset U$. See Rem. \ref{lb457} for details. We also let
\begin{gather}
C_c^\infty(M,[0,1])=\{f\in C_c^\infty(M,\Rbb):f(M)\subset[0,1]\}\\
C_c^\infty(M,\Rbb_{\geq0})=\{f\in C_c^\infty(M,\Rbb):f(M)\subset \Rbb_{\geq0}\}
\end{gather}
Note that the notation $C_c^\infty(M,[0,1])$ does not imply that $f\in C_c^\infty(M,[0,1])$ satisfies $f^{(n)}(M)\subset[0,1]$ for $n\geq1$.

\begin{thm}[\textbf{Smooth Urysohn's lemma}] \index{00@Smooth Urysohn's lemma}\label{mc25}
Let $K$ be a compact subset of $M$. Then there exists $f\in C_c^\infty(M,[0,1])$ such that $f|_K=1$. We call $f$ a \textbf{smooth Urysohn function} with respect to $K$ and $M$.
\end{thm}


Similar to Thm. \ref{lb711}, one can apply smooth Urysohn's lemma to any open subset $U\subset M$ containing $K$ to conclude that there exists $f\in C_c^\infty(M,[0,1])$ such that $f|_K=1$ and $\Supp(f)\subset U$.



\begin{proof}
We first treat the special case that $K=\{p\}$. Then it suffices to find $U\in\Nbh_M(p)$ and $f\in C_c^\infty(U,[0,1])$ satisfying $f(p)=1$. Therefore, we may assume that $M$ is small enough such that $M$ is an open subset of $\Hbb^n$. We may assume moreover that $M=I_1\times\cdots\times I_n$, where $I_2,\dots,I_n$ are open intervals in $\Rbb$, and $I_1$ is either $(a,b)$ (where $0\leq a<b\leq +\infty$) or $[0,b)$ (where $0<b\leq+\infty$). Write $p=(p_1,\dots,p_n)$. By Prop. \ref{lb440}, there exists $\varphi_j\in C_c^\infty(I_j,[0,1])$ such that $\varphi_j(p_j)=1$. Then $f=\varphi_1\cdots\varphi_n$ belongs to $C_c^\infty(M,[0,1])$ and satisfies $f(p)=1$.

Now, we consider the general case. By the first paragraph, for each $p\in K$, there exists $g_p\in C_c^\infty(M,[0,1])$ such that $g_p(p)=1$. Let $U_p=g_p^{-1}(\Rbb_{>0})$. Then $U_p\in\Nbh_M(p)$. Since $K$ is compact, there exist $p_1,\dots,p_n\in K$ such that $K\subset U_{p_1}\cup\cdots\cup U_{p_n}$. Let $g=g_{p_1}+\cdots+g_{p_n}$. Then $h\in C_c^\infty(M,\Rbb_{\geq0})$ and $g|_K>0$. Let $\lambda=\inf g(K)$, which is $>0$. By scaling $g$, we may assume that $\lambda\geq1$. We have thus constructed $g\in C_c^\infty(M,\Rbb_{\geq0})$ satisfying $g|_K\geq1$.

If we let $f=\min\{g,1\}$, then we have $f\in C_c(M,\Rbb_{\geq0})$ and $f|_K=1$, but $f$ is not necessarily smooth. To fix this issue, we replace the function $x\mapsto\min\{x,1\}$ by $h\in C_c^\infty(\Rbb,[0,1])$ satisfying $h|_{(-\infty,0]}=0$ and $h|_{[1,+\infty)}=1$. Then $f=h\circ g$ is a desired smooth Urysohn function. Such $h$ exists: Fix an arbitrary $0<a<+\infty$, and let $\varphi:\Rbb\xrightarrow{\simeq}(-a,a)$ be an increasing diffeomorphism (e.g. $\varphi(x)=\arctan(x)$ if $a=\pi/2$). By Prop. \ref{lb440}, there exists $\wtd h\in C^\infty((-a,a),[0,1])$ such that $\wtd h|_{(-a,\varphi(0)]}=0$ and $\wtd h|_{[\varphi(1),a)}=1$. Then $h=\wtd h\circ\varphi$ satisfies the requirement.
\end{proof}



\begin{thm}\label{mc27}
Let $K$ be a compact subset of $M$. Let $\fk U=(U_1,\dots,U_n)$ be a finite set of open subsets of $X$ covering $K$. Then there exist $h_i\in C_c^\infty(U_i,\Rbb_{\geq0})$ (for all $1\leq i\leq n$) satisfying the following conditions:
\begin{enumerate}[label=(\arabic*)]
\item$0\leq \dps \sum_{i=1}^nh_i\leq 1$ on $M$. 
\item  $\dps\sum_{i=1}^nh_i\big|_K=1$.
\end{enumerate}
Such $h_1,\dots,h_n$ are called a \textbf{smooth partition of unity of $K$ subordinate to $\fk U$}. \index{00@Smooth partition of unity}
\end{thm}

\begin{proof}
This follows from smooth Urysohn's lemma in the same way that Thm. \ref{lb466} follows from Urysohn's lemma for LCH spaces (Thm. \ref{lb711}).
\end{proof}

Similar to the situation in Sec. \ref{lb464}, we can use smooth partitions of unity to prove the smooth Tietze extension theorem. We have mentioned the usefulness of this theorem briefly in Rem. \ref{lb479}.

\begin{sthm}[\textbf{Smooth Tietze extension theorem}] \index{00@Smooth Tietze extension theorem}\label{mc30}
Let $K$ be a compact subset of $M$. Let $F:K\rightarrow\Rbb^k$ be a smooth map (in the sense of Def. \ref{mc15}). Then for each $\gamma>1$, there exists $\wtd F\in C_c^\infty(M,\Rbb^k)$ such that $\wtd F|_K=F$ and $\Vert \wtd F\Vert_{l^\infty(M,\Rbb^k)}\leq\gamma\Vert F\Vert_{l^\infty(K,\Rbb^k)}$.
\end{sthm}

For example, if $\partial M=\emptyset$ and $K$ is a compact smooth $\partial$-submanifold of $M$, then by Exe. \ref{mc26}, any smooth function on $K$ can be extended to a compactly supported smooth function on $M$ without increasing the $l^\infty$-norm.

\begin{proof}
%This is similar to the proof of Exp. \ref{lb478}. 
Let $\lambda=\Vert F\Vert_{l^\infty(K,\Rbb^k)}$. By Def. \ref{mc15}, for each $p\in K$ there exists $U_p\in\Nbh_M(p)$ and $G_p\in C^\infty(U_p,\Rbb^k)$ such that $G_p|_{K\cap U_p}=F|_{K\cap U_p}$. By shrinking $U_p$, we may assume that for each $x\in U_p$ we have $\Vert G_p(x)\Vert\leq\gamma\lambda$. Since $K$ is compact, there exists $E\in\fin(2^K)$ such that $K\subset\bigcup_{p\in E}U_p$. By Thm. \ref{mc27}, there exists a smooth partition of unity of $K$ subordinate to $(U_p)_{p\in E}$ which we denote by $(h_p)_{p\in E}$. Then $h_pG_p\in C_c^\infty(U_p,\Rbb^k)$ can be viewed as a compactly supported smooth map on $M$. Let $\wtd F=\sum_{p\in E}h_pG_p$. Then $\wtd F\in C_c^\infty(M,\Rbb^k)$. 

For each $x\in K$, since $\sum_{p\in E}h_p(x)=1$, we have
\begin{align*}
\wtd F(x)-F(x)=\sum_{p\in E}(h_p(x)G_p(x)-h_p(x)F(x))
\end{align*}
On the RHS, if $h_p(x)>0$, then $x\in U_p$, and hence $G_p(x)=F(x)$. This proves $\wtd F|_K=F|_K$. For each $x\in U_p$, we have $\Vert h_p(x)G_p(x)\Vert\leq\gamma\lambda h_p(x)$. Therefore, for each $x\in M$, we have
\begin{align*}
\Vert \wtd F(x)\Vert\leq \gamma\lambda\sum_{p\in E}h_p(x)\leq \gamma\lambda
\end{align*}
since $0\leq\sum_p h_p(x)\leq 1$. This proves $\Vert \wtd F\Vert_{l^\infty(M,\Rbb^k)}\leq \gamma\lambda$.
\end{proof}


\subsection{Application to smooth approximations and embeddings}

Fix a smooth $\partial$-manifold $M$. In this section, we give some elementary applications of the smooth partitions of unity and smooth Urysohn's lemma. At the end of this semester, we will use smooth partitions of unity to prove the Stokes theorem.

\subsubsection{Approximation by smooth functions}

\begin{thm}\label{mc28}
$C_c^\infty(M)\equiv C_c^\infty(M,\Cbb)$ is dense in $C_c(M)$ under the $l^\infty$-norm.
\end{thm}

%It follows that $\ovl B_{C_c^\infty(M)}(0,1)$ is dense in $\ovl B_{C_c(M)}(0,1)$: For each $f\in\ovl B_{C_c(M)}(0,1)$, choose a sequence $(f_n)$ in $C_c^\infty(M)$ converging uniformly to $f$. Then $\lambda_n=\Vert f_n\Vert_{l^\infty}$ converges to $\lambda=\Vert f\Vert_{l^\infty}$, and hence the sequence $(g_n)$ in 


\begin{proof}[First proof]
Clearly $C_c^\infty(M)$ is a $*$-subalgebra of $C_c(M)$. By the smooth Urysohn's lemma, for each $x\in M$ there exists $f\in C_c^\infty(M)$ such that $f(x)=1$; for every distinct $x,y\in M$ there exists $g\in C_c^\infty(M)$ such that $g(x)=1$ and $g(y)=0$. Therefore, by the Stone-Weierstrass Thm. \ref{lb828} for LCH spaces, $C_c^\infty(M)$ is dense in $C_c(M)$.
\end{proof}


Since polynomials are dense in $C[0,1]$, it is not surprising that Thm. \ref{mc28} can be proved by the Stone-Weierstrass theorem. But let us give a more elementary but longer proof of Thm. \ref{mc28} without using the Stone-Weierstrass theorem:

\begin{proof}[Second proof]
By treating the real and the imaginary parts separately, it suffices to prove that $C_c^\infty(M,\Rbb)$ is dense in $C_c(M,\Rbb)$. Let $f\in C_c(M,\Rbb)$. We shall use the strategy in the proof of Lem. \ref{lb469}. Namely, we shall first locally approximate $f$ by smooth functions (which is easy since we can choose constant functions), and then use smooth partitions of unity to obtain a global smooth approximation.

Let $K=\Supp(f)$. Let $\eps>0$. For each $p\in K$, since $f$ is continuous at $x$, there exists $U_p\in\Nbh_M(p)$ such that $\diam f(U_p)\leq\eps$. By the compactness of $K$, there exists $E\in\fin(2^K)$ such that $(U_p)_{p\in E}$ is an open cover of $K$ in $M$. Let $(h_p)_{p\in E}$ be a smooth partition of unity of $K$ subordinate to this open cover. Let $g=\sum_{p\in E}f(p)h_p$. Then $g\in C_c^\infty(M,\Rbb)$. Let us prove that $\Vert f-g\Vert_{l^\infty}\leq\eps$.

Suppose $x\in K$. Then $\sum_{p\in E}h_p(x)=1$, and hence
\begin{align*}
\Vert f(x)-g(x)\Vert=\Big\Vert \sum_{p\in E}h_p(x)\cdot \big(f(x)-f(p)\big)  \Big\Vert\leq\sum_{p\in E}h_p(x)\Vert f(x)-f(p)\Vert
\end{align*}
On the RHS, if $h_p(x)\neq 0$, then $x\in U_p$, and hence $\Vert f(x)-f(p)\Vert\leq\eps$. So the RHS is $\leq\sum_{p\in E}h_p(x)\eps=\eps$. Therefore $\Vert f(x)-g(x)\Vert\leq\eps$. 

Suppose $x\in M\setminus K$. Then $f(x)=0$. Therefore, if $h_p(x)>0$, then $x\in U_p$, and hence $\diam f(U_p)\leq\eps$ implies that $\Vert f(p)\Vert\leq\eps$. Therefore
\begin{align*}
\Vert f(x)-g(x)\Vert=\Vert g(x)\Vert\leq\sum_{p\in E}h_p(x)\Vert f(p)\Vert\leq\sum_{p\in E}h_p(x)\cdot\eps\leq\eps 
\end{align*}
where the last inequality is due to $\sum_{p\in E}h_p(x)\leq 1$.
\end{proof}



\begin{thm}\label{mc53}
Let $1\leq p<+\infty$. Let $\mu$ be a Radon measure (or its completion) on $M$. Then $C_c^\infty(M)$ is dense in $L^p(M,\mu)$ under the $L^p$-norm.
\end{thm}

\begin{proof}
By Thm. \ref{lb866}, $C_c(M)$ is $L^p$-dense in $L^p(M,\mu)$. Therefore, it suffices to prove that any $f\in C_c(M)$ can be $L^p$-approximated by elements in $C_c^\infty(M)$. By Lem. \ref{lb460}, there exists a precompact open $U\subset M$ containing the compact set $\Supp(f)$. By Thm. \ref{mc28}, there exists a sequence $(f_n)$ in $C_c^\infty(U)$ (and hence in $C_c^\infty(M)$) converging uniformly to $f$. Then
\begin{align*}
\Vert f-f_n\Vert_p^p=\int_M|f-f_n|^pd\mu=\int_U|f-f_n|^pd\mu\leq \Vert f-f_n\Vert_{l^\infty(U)}^p\cdot \mu(U)
\end{align*}
where $\dps\lim_{n\rightarrow\infty}\text{RHS}=0$ since $\ovl U$ is compact and hence $\mu(U)<+\infty$.
\end{proof}


\begin{srem}\label{mc55}
By Thm. \ref{mc28} (and Rem. \ref{mc54}), $\ovl B_{C_c^\infty(M)}$ is $l^\infty$-dense in $\ovl B_{C_c(M)}(0,1)$. Therefore, by Pb. \ref{lb910}-2, $\ovl B_{C_c^\infty(M)}$ is weak-* dense in $\ovl B_{L^\infty(M,\mu)}(0,1)$ for any Radon measure $\mu$ (or its completion) on $M$.
\end{srem}


When $M$ is $\Rbb^n$ and $\mu$ is the Lebesgue measure, one can use convolutions to give an explicit construction of smooth approximations. See Rem. \ref{mc58}.

%% Record #21 2024/05/13 Two lectures  51


\subsubsection{$\star$ Embedding compact $\partial$-manifolds into $\Rbb^n$}




\begin{thm}\label{mc99}
Assume that $M$ is a compact smooth $\partial$-manifold. Then there exists a smooth embedding $F:M\rightarrow\Rbb^n$ for some $n\in\Nbb$.
\end{thm}


\begin{proof}
It suffices to find a finite set $\scr F\subset C^\infty(M,\Rbb)$ satisfying the following two conditions:
\begin{enumerate}
\item[(a)] $\scr F$ separates points of $M$.
\item[(b)] If we enumerate the elements in $\scr F$ as $f^1,\dots,f^n$ and write $F=(f^1,\dots,f^n)$, then $\Jac F$ is injective everywhere.
\end{enumerate}
Then, by (a), $F$ is a continuous injective map, and hence is a topological embedding because $M$ is compact. By (b), $F$ is an immersion. Then by Thm. \ref{mc21}, $F:M\rightarrow\Rbb^n$ is a smooth embedding. Moreover, note that if $\scr F$ satisfies (a) resp. (b), then any finite subset of $C^\infty(M,\Rbb)$ containing $\scr F$ also satisfies (a) resp. (b).

Let us construct the $\scr F$ satisfying (a) and (b). For each $p$ there exist open precompact $U,V\subset M$ containing $p$ such that $\ovl U\subset V$, and that $V$ admits a coordinate. Therefore, by the compactness of $M$, there exists a finite index set $\scr A$ and families of precompact open sets $(U_\alpha)_{\alpha\in\scr A}$ and $(V_\alpha)_{\alpha\in\scr A}$ such that $\ovl U_\alpha\subset V_\alpha$, that $(V_\alpha,\varphi_\alpha)=(V_\alpha,\varphi_\alpha^1,\dots,\varphi_\alpha^{n_\alpha})$ is a chart on $M$, and that $\bigcup_{\alpha\in\scr A}U_\alpha=M$. By smooth Urysohn's lemma, there exists $f_\alpha\in C_c^\infty(M,[0,1])$ compactly supported in $V_\alpha$ such that $f_\alpha|_{\ovl U_\alpha}=1$. Then for each $\alpha\in\scr A$ and  $1\leq i\leq n_\alpha$, we have $\varphi^i_\alpha f_\alpha\in C_c^\infty(V_\alpha,\Rbb)\subset C_c^\infty(M,\Rbb)$. 

If we let $\scr F$ be any finite subset of $C_c^\infty(M,\Rbb)$ contain all $\varphi_\alpha^if_\alpha$, and if we let $F$ be as in (b), then $dF$ is injective at any point of any $U_\alpha$. Therefore $\scr F$ satisfies (b). Now, we let $\scr F$ also contain all $f_\alpha$. Let us prove that $\scr F$ satisfies (a). Let $x,y\in M$ be distinct. Choose any $U_\alpha$ containing $x$.Then $f_\alpha(x)=1$. If $f_\alpha(y)<1$, then clearly $\scr F$ separates $x,y$. If $f_\alpha(y)=1$, then $x,y\in V_\alpha$, and hence one can find $i$ such that $\varphi^i_\alpha$ separates $x,y$. So $f_\alpha\varphi^i_\alpha$ separates $x,y$. Therefore $\scr F$ separates $x,y$.
\end{proof}







\newpage


\section{The change of variables formula}


\subsection{Introduction}


The goal of this chapter is to prove the \textbf{change of variables formula} (cf. Thm. \ref{mc42}): Let $\Phi:\Omega\xrightarrow{\simeq}\Delta$ be a $C^1$-diffeomorphism of open subsets of $\Rbb^n$. Then for every Lebesgue integrable $f:\Delta\rightarrow\Cbb$, the function $f\circ\Phi:\Omega\rightarrow\Cbb$ is Lebesgue integrable, and 
\begin{align}\label{eq435}
\int_\Delta fdm=\int_\Omega (f\circ\Phi)|\Jbf\Phi| dm
\end{align}
As a consequence, if $E\subset\Omega$ is a Borel set, by letting $f=\chi_{\Phi(E)}$, we see that 
\begin{align}\label{eq436}
m(\Phi(E))=\int_E |\Jbf\Phi|dm
\end{align} 

Our proof of this theorem will be based on the method introduced by J. Schwartz in \cite{Sch54}. This method is also used in many textbooks; see \cite[Sec. 15.12]{Apo}, \cite[Thm. 2.47]{Fol-R}, \cite[Sec. 45]{Yu} for instance. In this introductory section, we briefly explain the main ideas in this method.


Since Radon measures are determined by their integrals of compactly supported continuous functions (Prop. \ref{lb791}), it suffices to prove \eqref{eq435} for $f\in C_c(\Delta,\Rbb)$. Note that such $f$ can be approximated uniformly by \textbf{step functions}, i.e., finite sums $\sum_i a_i\chi_{E_i}$ where each $E_i$ is a \textbf{cube} (i.e. $E=I_1\times\cdots\times I_n$ where $I_1,\dots,I_n$ are bounded intervals having the same length). Therefore, it suffices to prove \eqref{eq436} whenever $E$ is a cube.

If $\Phi$ is an invertible matrix $A$, then \eqref{eq436} reads \begin{align*}
m(A(E))=|\det A|m(E)
\end{align*}
and is not hard to prove. In the general case, one can decompose $E$ into a finite disjoint union of smaller cubes $E_1\cup E_2\cup\cdots$ such that on each $E_i$, $\Jac\Phi$ is almost a constant. Therefore, by shrinking $\Omega$ to an open set slightly larger than $E_i$ (and shrinking $\Delta$ accordingly), it suffices to assume that $\Jac\Phi|_x\approx A$ for all $x\in\Omega$, where $A$ is an invertible matrix. Then, to prove \eqref{eq436}, it suffices to prove for any cube $E\subset\Omega$ that
\begin{align}\label{eq437}
m(\Phi(E))\approx m(A(E))\equiv |\det A|m(E)
\end{align}


The most natural idea of proving \eqref{eq437} is to prove that $\Phi(E)$ can be approximated by $A(E)$. For example, one can try to find parallelepipeds $P_1,P_2$ such that
\begin{align*}
P_1\subset \Phi(E)\subset P_2
\end{align*}
that $P_1$ is similar to but slightly smaller than the parallelepiped $A(E)$, and that $P_2$ is similar to but slightly larger than $A(E)$. However, as pointed out in \cite{Sch54}, it is very hard to find such $P_1$, because the interior of $\Phi(E)$ is difficult to control.

Fortunately, the slightly larger $P_2$ is easier to find. In \cite{Sch54}, this task was achieved by a clever application of the $l^\infty$-norm on $\Rbb^n=l^\infty(\{1,\dots,n\},\Rbb)$. %(More precisely, one should consider the norm $\Vert v\Vert:=\Vert Av\Vert_\infty$ for each $v:\{1,\dots,n\}\rightarrow\Rbb$. An open ball under this norm is precisely a parallelepiped $A(Q)$ for some open cube $Q$.) 
This is the most brilliant part in \cite{Sch54}. Since we will provide the details in Subsec. \ref{mc63}, we do not explain this part here.

Let us admit that such $P_2$ can be found, and explain how to finish proving the change of variables formula. Due to the existence of $P_2$,  one can find $\gamma\in\Rbb$ slightly larger than $1$ such that
\begin{align}\label{eq438}
m(\Phi(E))\leq \gamma m(A(E))\equiv \gamma|\det A|m(E)
\end{align}
for any open cube $E\subset\Omega$. This will imply that \eqref{eq438} holds for all open subset $E\subset\Omega$, since open sets can be approximated by open cubes (cf. Prop. \ref{mc61} for a precise statement). Since $\Jac\Phi^{-1}\approx A^{-1}$, we can replace the $\Phi$ in \eqref{eq438} with $\Phi^{-1}$ and replace $E$ with the open set $\Phi(E)$ to get
\begin{align*}
m(E)\leq \gamma|\det A|^{-1}m(\Phi(E))
\end{align*}
and hence $\gamma|\det A|m(E)\leq \gamma^2 m(\Phi(E))$. Therefore
\begin{align*}
m(\Phi(E))\leq \gamma|\det A|m(E)\leq \gamma^2 m(\Phi(E))
\end{align*}
This proves the approximation \eqref{eq437}.












\subsection{Preliminaries in measure theory}

Let $X,Y$ be topological spaces. In this section, we discuss some useful notions in measure theory in order to prepare for the proof of the change of variables formula. Some of these concepts can be applied to abstract measure spaces. However, to simplify discussions, we will only be concerned with Borel measures and their completions.



\subsubsection{Pullback measures}

Recall Def. \ref{mc31} for the definition of pushforward measures.


\begin{df}\label{mc32}
Let $\nu:\fk B_Y\rightarrow[0,+\infty]$ be a Borel measure on $Y$. Let $\Phi:X\rightarrow Y$ be a homeomorphism. The \textbf{pullback} \index{00@Pullback measure} measure $\Phi^*\nu:\fk B_X\rightarrow[0,+\infty]$ is defined to be the pushforward of $\nu$ under $\Phi^{-1}$, i.e.
\begin{align}
\Phi^*\nu=(\Phi^{-1})_*\nu
\end{align}
Namely, for each $E\in\fk B_X$ we have
\begin{align}
(\Phi^*\nu)(E)=\nu(\Phi(E))
\end{align}
Equivalently (by \eqref{eq422}), if we define \index{zz@$\Phi^*f$, the pullback of the function $f$ via $\Phi$} the \textbf{bullback function} \index{00@Pullback function}
\begin{align}
\Phi^*f=f\circ\Phi
\end{align}
then for each Borel function $f:Y\rightarrow[0,+\infty]$ we have
\begin{align}\label{eq423}
\int_Yfd\nu=\int_X \Phi^*f\cdot d(\Phi^*\nu)
\end{align}
If $\mu=\Phi^*\nu$, we also write $d\mu=\Phi^*d\nu$, i.e.
\begin{align}
\Phi^*d\nu\xlongequal{\mathrm{def}} d(\Phi^*\nu)
\end{align}
\end{df}

\begin{rem}
In Def. \ref{mc32}, we have
\begin{align}\label{eq429}
\Phi^*(fd\nu)=(\Phi^*f)\cdot\Phi^*d\nu
\end{align}
where the LHS is the measure of $fd\nu$ under $\Phi$.
\end{rem}

\begin{proof}
Choose any Borel $g\in Y\rightarrow[0,+\infty]$. Then $\int_X \Phi^*g\cdot\Phi^*(fd\nu)=\int_Y g\cdot fd\nu=\int_X \Phi^*g\cdot\Phi^*f\cdot\Phi^*d\nu$.
\end{proof}





\begin{rem}\label{mc44}
In Def. \ref{mc32}, suppose that $X,Y$ are LCH spaces and $\nu$ is a Radon measure. Then $\Phi^*\nu$ is clearly a Radon measure on $X$. Moreover, by Prop. \ref{lb791}, $\Phi^*\nu$ is the unique Radon measure such that \eqref{eq423} holds for all $f\in C_c(Y,\Rbb_{\geq0})$.
\end{rem}



\subsubsection{Comparing measures}


\begin{df}\label{mc35}
Let $\mu,\nu$ be Borel measures on $X$. We write\index{zz@$\mu\leq\nu$}
\begin{align}
\mu\leq\nu
\end{align}
if one of the following conditions hold:
\begin{enumerate}
\item[(1)] For each $E\in\fk B_X$ we have $\mu(E)\leq\nu(E)$.
\item[(2)] For each Borel $f:X\rightarrow[0,+\infty]$ we have $\int_Xfd\mu\leq\int_Xfd\nu$. 
\end{enumerate}
Moreover, if $X$ is LCH and $\mu,\nu$ are Radon measures, then each of the following conditions is equivalent to $\mu\leq\nu$:
\begin{enumerate}
\item[(3)] For each open $U\subset X$ we have $\mu(U)\leq\nu(U)$.
\item[(4)] For each compact $K\subset X$ we have $\mu(K)\leq\nu(K)$.
\item[(5)] For each $f\in C_c(X,\Rbb_{\geq0})$ we have $\int_Xfd\mu\leq\int_Xfd\nu$.
\end{enumerate}
\end{df}


\begin{proof}[Proof of equivalence]
Clearly (2) implies (1). Assume (1). Then (2) holds for simple functions, and hence for all $f\in\mc L_+(X)$ by Prop. \ref{lb749} and the monotone convergence Thm. \ref{lb760}. This proves (1)$\Leftrightarrow$(2).

Clearly (2)$\Rightarrow$(5). By the inner regularity on open sets (cf. \eqref{eq314}) we have (5)$\Rightarrow$(3). Since Radon measures are outer regular on Borel sets, we have (3)$\Rightarrow$(1). Thus, (3) and (5) are both equivalent to (1) and (2).

Clearly (1)$\Rightarrow$(4). By the inner regularity on open sets, we have (4)$\Rightarrow$(3).
\end{proof}


\begin{rem}
Let $A\in\fk B_X$. Then by Def. \ref{lb707} and Pb. \ref{mc34}, we have
\begin{align}
\fk B_A=\fk B_X|_A\subset\fk B_X
\end{align}
Therefore, we can define the \textbf{restriction} $\mu|_A$ \index{00@Restriction of measure} unambiguously to be the restriction of $\mu$ to $\fk B_X|_A=\fk B_A$ as in Rem. \ref{mc33}. Moreover, if $\nu:\fk B_X\rightarrow[0,+\infty]$ is a Borel measure and $\mu\leq\nu$, then clearly $\mu|_A\leq\nu|_A$ by Def. \ref{mc35}-(1). In this chapter, we will be only concerned with the case that $A$ is open.
\end{rem}

\begin{pp}\label{mc36}
Let $\mu,\nu$ be Radon measures on an LCH space $X$. Let $\fk U$ be an open cover of $X$. Then the following are equivalent:
\begin{enumerate}
\item[(1)] $\mu\leq\nu$.
\item[(2)] $\mu|_U\leq\nu|_U$ for every $U\in\fk U$.
\end{enumerate}
\end{pp}

Since a similar equivalence holds for ``$\geq$", we conclude that $\mu=\nu$ iff $\mu|_U=\nu|_U$ for every $U\in\fk U$.


\begin{proof}
(1)$\Rightarrow$(2) is clearly true. Assume (2). Let $f\in C_c(X,\Rbb_{\geq0})$. Let us prove that $\int_X fd\mu\leq\int f_Xd\nu$. In the special case that $\Supp(f)\subset U$ for some $U\in\fk U$, by \eqref{eq351} we have $\int_Xfd\mu=\int_Ufd\mu|_U\leq\int_Ufd\nu|_U=\int_Xfd\nu$. Now consider the general case. Let $\fk V$ be a finite subset of $\fk U$ covering $\Supp(f)$. By choosing a partition of unity of $\Supp(f)$ subordinate to $\fk V$ (cf. Thm. \ref{lb466}), we can write $f$ as a finite sum $\sum_i f_i$ where $f_i\in C_c(U_i,\Rbb_{\geq0})$ for each $i$. By the proved special case, we have $\int_X f_id\mu\leq\int_Xf_id\nu$. Therefore $\int_X fd\mu\leq\int f_Xd\nu$. This proves (1).
\end{proof}

We now give a criterion for $\mu\leq\nu$ on open subsets of $\Rbb^n$.

\begin{df}
We say that $Q\subset\Rbb^n$ is an \textbf{($n$-dimensional) cube} if $Q=I_1\times\cdots\times I_n$ where $I_1,\dots,I_n\subset\Rbb$ are bounded intervals having the same length. Unless otherwise stated, a cube in $\Rbb^n$ always means an $n$-dimensional cube.
\end{df}


\begin{pp}\label{mc37}
Let $\Omega\subset\Rbb^n$ be open. Let $\mu,\nu$ be Radon measures on $\Omega$. Then the following are equivalent.
\begin{enumerate}
\item[(1)] $\mu\leq\nu$.
\item[(2)] For each cube $Q\subset\Rbb^n$ we have $\mu(Q)\leq\nu(Q)$.
\end{enumerate}
\end{pp}



\begin{proof}
Clearly (1)$\Rightarrow$(2). Let us assume (2) and prove (1). By Prop. \ref{mc36}, it suffices to prove that for each $x\in\Omega$ there exists $U\in\Nbh_\Omega(x)$ such that $\mu|_U\leq\nu|_U$. Therefore, after shrinking $\Omega$ to an open cube with compact closure in $\Omega$, we may assume WLOG that $\Omega$ is an open cube, and that $\mu(\Omega)<+\infty$. Choose any $f\in C_c(\Omega,\Rbb_{\geq0})$. Then $f$ is uniformly continuous on $\Supp(f)$ and hence on $\Omega$. Therefore, for each $\eps>0$, we can write $\Omega$ as a finite disjoint union of cubes $\Omega=\bigsqcup_i Q_i$ such that $M_i-m_i\leq\eps$ where $M_i=\sup f(Q_i)$ and $m_i=\inf f(Q_i)$. Let
\begin{align*}
g=\sum_i M_i\chi_{Q_i}\qquad h=\sum_i m_i\chi_{Q_i}
\end{align*}
Then $g\leq f\leq h$ and $h-g\leq \eps$. Thus $0\leq f-g\leq \eps$, and hence $\int_\Omega fd\mu-\int_\Omega gd\mu\leq \mu(\Omega)\eps$. By (2), we have $\int_\Omega gd\mu\leq\int_\Omega gd\nu$. Therefore
\begin{align*}
\int_\Omega fd\mu\leq\int_\Omega gd\mu+\mu(\Omega)\cdot\eps\leq\int_\Omega gd\nu+\mu(\Omega)\cdot\eps\leq \int_\Omega fd\nu+\mu(\Omega)\cdot\eps
\end{align*}
Since $\eps$ is arbitrary, we get $\int_\Omega fd\mu\leq\int_\Omega fd\nu$. This proves (1).
\end{proof}


\subsubsection{Approximation by cubes}

\begin{rem}
We now give an alternative proof of the direction (2)$\Rightarrow$(1) in Prop. \ref{mc37}. By the following Prop. \ref{mc61}, every open $U\subset\Omega$ is a countable disjoint union of cubes. Therefore, if we assume (2), then $\mu(U)\leq\nu(U)$ for open $U\subset\Omega$, and hence $\mu\leq\nu$.
\end{rem}



\begin{pp}\label{mc61}
Let $\Omega\subset\Rbb^n$ be open. Then $\Omega$ is a countable disjoint union of cubes.
\end{pp}

\begin{proof}
By Prop. \ref{mc38}, it suffices to prove that any box $B$ is a countable disjoint union of cubes. When the side lengths of $B$ are integer multiples of $2^{-k}$ for some $k\in\Zbb_+$, then $B$ is clearly a finite disjoint union of cubes. In general, it is not hard to write $B$ as a countable disjoint union $\bigsqcup_j B_j$ where each $B_j$ is a box whose side lengths are integer multiples of $2^{k_j}$ for some $k_j\in\Zbb_+$. This finishes the proof.
\end{proof}

\begin{co}\label{mc62}
Let $E\subset\Rbb^n$. The following are equivalent:
\begin{enumerate}
\item[(1)] $E$ is a Lebesgue null set.
\item[(2)] For each $\eps>0$, $E$ is contained in a countable disjoint union of cubes $E\subset\bigcup Q_n$ such that $\sum_n m(Q_n)\leq\eps$.
\end{enumerate}
\end{co}

\begin{proof}
Suppose that (2) is true. Then $E\subset\bigcap A_n$ where $A_n\in\fk B_{\Rbb^n}$ and $m(A_n)\leq 1/n$. So $\bigcap A_n$ is null.  Since the Lebesgue measure is complete, $E$ is null. This proves (1). 

Assume (1). By Cor. \ref{lb830}, for each $\eps>0$, there exists an open $U\subset\Rbb^n$ containing $E$ such that $m(U)\leq\eps$. By Prop. \ref{mc61}, $U=\bigsqcup_n Q_n$ where each $Q_n$ is a cube. So $\sum_n m(Q_n)=m(U)\leq\eps$. This proves (2).
\end{proof}





\subsection{The main theorem}

For each open $\Omega\subset\Rbb^n$, we let $m_\Omega$ denote the Lebesgue measure on $\Omega$.
\begin{thm}\label{mc39}
Let $\Omega,\Delta\subset\Rbb^n$ be open. Let $\Phi:\Omega\xrightarrow{\simeq}\Delta$ be a $C^1$-diffeomorphism. Then
\begin{align}\label{eq424}
\Phi^* dm_\Delta=|\Jbf\Phi|dm_\Omega
\end{align}
as measures on $\fk B_\Omega$. Equivalently, for each Borel measurable $f:\Delta\rightarrow\ovl\Rbb_{\geq0}$ we have
\begin{align}\label{eq425}
\int_\Delta fdm=\int_\Omega (f\circ\Phi)|\Jbf\Phi| dm
\end{align}
\end{thm}



Note that by \eqref{eq423}, the LHS of \eqref{eq425} equals $\int_\Omega (f\circ\Phi)\cdot\Phi^*dm$. Thus \eqref{eq424} is clearly equivalent to \eqref{eq425}. Also, note that $\Jbf(\Phi):x\in\Omega\mapsto\det\Jac\Phi|_x$ is continuous, and is nowhere zero since
\begin{align*}
\Jbf(\Phi^{-1})|_{\Phi(x)}\cdot\Jbf(\Phi)|_x=\det\Jac(\Phi^{-1})|_{\Phi(x)}\cdot\det\Jac(\Phi)|_x=\det(1)=1
\end{align*}



Thm. \ref{mc39} will be proved in the next section. Assuming Thm. \ref{mc39}, we have:

\begin{co}\label{mc40}
Let $\Omega,\Delta\subset\Rbb^n$ be open. Let $\Phi:\Omega\xrightarrow{\simeq}\Delta$ be a $C^1$-diffeomorphism. Then $\Phi$ sends Lebesgue null sets to Lebesgue null sets, and $\Phi$ sends Lebesgue measurable sets to Lebesgue measurable sets.
\end{co}

\begin{proof}
Since the Lebesgue measure $m$ is the completion of $m$ on the Borel $\sigma$-algebras, to prove that $\Phi$ sends Lebesgue null sets to Lebesgue null sets, it suffices to prove that if $E\subset\Omega$ is Borel and null, then the (automatically Borel) set $\Phi(E)$ is null. Using Thm. \ref{mc39}, we compute
\begin{align*}
m_\Delta(\Phi(E))=(\Phi^*m_\Delta)(E)=\int_\Omega\chi_E \cdot\Phi^*dm_\Delta=\int_\Omega\chi_E|\Jbf\Phi|dm_\Omega
\end{align*}
If $m(E)=0$, then the Borel function $\chi_E|\Jbf\Phi|$ is zero $m$-a.e. So the RHS above is zero. This proves that $\Phi(E)$ is $m$-null.

Now, we assume that $E\subset\Omega$ is Lebesgue measurable. Then $E=A\cup B$ where $A$ is Borel and $B$ is $m$-null. So $\Phi(E)=\Phi(E)\cup\Phi(B)$ where $\Phi(E)$ is Borel and $\Phi(B)$ is $m$-null. So $\Phi(E)$ is Lebesgue measurable.
\end{proof}


\begin{co}\label{mc101}
Let $M$ be a $C^r$ $\partial$-submanifold of $\Rbb^n$ where $r\geq1$. Assume that for each $p\in M$ we have $\dim_pM<n$. Then $m^n(M)=0$.
\end{co}
\begin{proof}
There exists a family of charts $\fk U$ on $\Rbb^n$ covering $M$ such that for each $(U,\varphi)\in\fk U$, $\varphi$ sends $M\cap U$ into $\Rbb^{n-1}\times 0$. Since $\Rbb^{n-1}\times 0$ is null, by Cor. \ref{mc40}, $M\cap U$ is null. Since $M$ is second countable and hence Lindel\"of, we may assume that $\fk U$ is countable. So $M$ is a countable union of null sets. Therefore $M$ is null.
\end{proof}






\begin{rem}\label{mc41}
In Cor. \ref{mc40}, if we let $\fk M_\Omega$ and $\fk M_\Delta$ denote the $\sigma$-algebra of Lebesgue measurable sets in $\Omega$ and $\Delta$ respectively, then the maps $\Phi$ and $\Phi^{-1}$ are measurable with respect to $\fk M_\Omega$ and $\fk M_\Delta$. It follows from Def. \ref{mc31} that the pushforward measure $(\Phi^{-1})_*m_\Delta$ can be defined on $\fk M_\Omega$. We also write this measure as
\begin{align*}
(\fk M_\Omega,\Phi^*m_\Delta)
\end{align*}
\end{rem}

\begin{co}
$(\fk M_\Omega,\Phi^*m_\Delta)$ is the completion of the Radon measure $(\fk B_\Omega,\Phi^*m_\Delta)$.
\end{co}

\begin{proof}
Since $(\fk B_\Delta,m_\Delta)$ is Radon, so is $(\fk B_\Omega,(\Phi^{-1})_*m_\Delta)$. By Thm. \ref{mc39}, $(\fk B_\Omega,(\Phi^{-1})_*m_\Delta)$ equals $(\fk B_\Omega,\mu)$ where $d\mu=|\Jbf\Phi|m_\Omega$. Since $|\Jbf\Phi|$ is nowhere zero, by Pb. \ref{lb914}-2, the completion of $(\fk B_\Omega,\mu)$ and the completion of $(\fk B_\Omega,m_\Omega)$ have the same $\sigma$-algebra, which must be $\fk M_\Omega$.
\end{proof}



\begin{thm}\label{mc42}
Let $\Omega,\Delta\subset\Rbb^n$ be open. Let $m_\Omega$ and $m_\Delta$ be defined respectively on $\fk M_\Omega,\fk M_\Delta$ (as in Rem. \ref{mc41}).  Let $\Phi:\Omega\xrightarrow{\simeq}\Delta$ be a $C^1$-diffeomorphism. Then
\begin{align}\label{eq426}
\Phi^*dm_\Delta=|\Jbf\Phi|dm_\Omega
\end{align}
as measures on $\fk M_\Omega$. Equivalently, for each Lebesgue measurable $f:\Delta\rightarrow\ovl\Rbb_{\geq0}$ we have
\begin{align}\label{eq427}
\int_\Delta fdm=\int_\Omega (f\circ\Phi)|\Jbf\Phi| dm
\end{align}
\end{thm}

\begin{proof}
By Thm. \ref{mc39}, the LHS and the RHS of \eqref{eq426} are equal on $\fk B_\Omega$. The RHS is zero on Lebesgue null sets. By Cor. \ref{mc40}, the LHS is also zero on Lebesgue null sets. So \eqref{eq426} holds on $\fk M_\Omega$. The equivalence of \eqref{eq426} and \eqref{eq427} is similar o the equivalence in Thm. \ref{mc39}.
\end{proof}

\begin{co}
Let $\Omega,\Delta\subset\Rbb^n$ be open. Let $\Phi:\Omega\xrightarrow{\simeq}\Delta$ be a $C^1$-diffeomorphism. Suppose that $f:\Delta\rightarrow\Cbb$ is Lebesgue integrable. Then $(f\circ\Phi)|\Jbf\Phi|$ is Lebesgue integrable on $\Omega$, and \eqref{eq427} holds.
\end{co}


\begin{proof}
Apply Thm. \ref{mc42} to $(\Real f)^\pm$ and $(\Imag f)^\pm$.
\end{proof}

\begin{eg}
Let $\Gamma$ be the parallelepiped in $\Rbb^n$ spanned by $n$ linearly independent column vectors forming an (invertible) matrix $A$. Then $m(\Gamma)=|\det A|$.
\end{eg}

\begin{proof}
We have $\Gamma=A([0,1]^n)$. Since $\Jac A=A$ and hence $\Jbf(A)=\det A$, we have
\begin{align*}
&m(\Gamma)=m(A([0,1]^n))=A^*m([0,1]^n)=\int_{\Rbb^n}\chi_{[0,1]^n}\cdot A^*dm\\
=&\int_{\Rbb^n}\chi_{[0,1]^n}|\det A|dm=|\det A|
\end{align*} 
\end{proof}


\begin{eg}\label{mc43}
$\dps\int_{-\infty}^{+\infty}e^{-x^2}dx=\sqrt\pi$
\end{eg}

\begin{proof}
Let $f:\Rbb^2\rightarrow\Rbb_{\geq0}$ be $f(x,y)=e^{-x^2-y^2}$. By Tonelli's Thm. \ref{lb832}, it suffices to prove $\int_{\Rbb^2}fdm=\pi$. Let $\Omega=(0,+\infty)\times(0,2\pi)$, let $\Delta=\Rbb^2\setminus(\Rbb_{\geq0}\times 0)$, and let $\Phi:\Omega\rightarrow\Delta$ be the polar coordinates, i.e., $\Phi(r,\theta)=(r\cos\theta,r\sin\theta)$. Then, by Exp. \ref{lb969}, $\Phi$ is a diffeomorphism of open subsets of $\Rbb^2$. Since $\Rbb^2\setminus\Delta$ is a Lebesgue null set, it suffices to prove $\int_\Delta fdm=\pi$. Since $\Jbf\Phi=r$, by the change of variables Thm. \ref{mc39}, and by Tonelli's Thm. \ref{lb832}, we have
\begin{align*}
&\int_\Delta fdm=\int_\Omega (f\circ\Phi)|\Jbf\Phi|dm(r,\theta)=\int_{\Rbb_{>0}}\int_{(0,2\pi)} re^{-r^2}d\theta dr=2\pi\int_{\Rbb_{>0}}re^{-r^2}dr\\
=&-\pi e^{-r^2}\Big|_{r=0}^{+\infty} =\pi
\end{align*}
where the monotone convergence theorem is used to show $\int_{\Rbb_{>0}}re^{-r^2}dr=\lim_{a\searrow 0,b\nearrow+\infty}\int_a^b re^{-r^2}dr$, and the fundamental theorem of calculus is used to calculate $\int_a^b re^{-r^2}dr$.
\end{proof}



\subsection{Proof of the main theorem}

In this section, we prove Thm. \ref{mc39}. Unless otherwise stated, we work with Borel $\sigma$-algebras instead of their completions under Radon measures. In particular, the Lebesgue measure $m$ is defined on $\fk B_{\Rbb^n}$.

In this section, we will encounter two types of Borel measures on an open subset $\Omega\subset\Rbb^n$. The first type is $\Phi^*m_\Delta$ as in the statement of Thm. \ref{mc39}. This is a Radon measure since the pullback of any Radon measure under a homeomorphism is clearly Radon. The second type is $\mu$ defined by $d\mu=hdm_\Omega$ where $h\in C(\Omega,\Rbb_{>0})$. Then for each compact $K\subset\Omega$, since $\Vert h\Vert_{l^\infty(K)}<+\infty$, we have $\mu(K)=\int_K hdm_{\Omega}<+\infty$. Therefore, by Thm. \ref{lb818}, $\mu$ is a Radon measure.


We let $\GL(\Rbb^n)$ be the set of invertible linear operators on $\Rbb^n$.


\subsubsection{The linear case}


\begin{lm}\label{mc48}
Thm. \ref{mc39} holds if $\Omega=\Delta=\Rbb^n$ and $\Phi$ is an invertible linear map. 
\end{lm}

\begin{proof}
We can view $\Phi$ as an invertible matrix. Then $\Jbf\Phi=\det\Phi$. We need to prove 
\begin{align}\label{eq428}
\Phi^*dm=|\det\Phi|dm
\end{align}
Let $\scr E$ be the set of all $\Phi\in\GL(\Rbb^n)$ satisfying \eqref{eq428}. We need to show that $\scr E=\GL(\Rbb^n)$.

We first note that $\idt\in\scr E$. Moreover, if $\Phi,\Psi\in\scr E$, then since $\det$ is multiplicative, we have
\begin{align*}
&(\Phi\circ\Psi)^*dm=\Psi^*\Phi^*dm=\Psi^*(|\det\Phi|dm)=|\det\Phi|\Psi^*dm\\
=&|\det\Psi\cdot\det\Phi|dm=|\det(\Phi\circ\Psi)|dm
\end{align*}
Therefore $\Phi\circ\Psi\in\scr E$. We have thus proved that $\scr E$ is closed under matrix multiplication. In other words, $\scr E$ is a subsemigroup of $\GL(\Rbb^n)$.

It is well known (cf. \cite{Axl}) that any $\Phi\in\GL(\Rbb^n)$ is a composition of elementary matrices. Therefore is remains to prove that the three types of elementary matrices are in $\scr E$.

Case 1: $\Phi$ multiplies the $i$-th row of a column vector by $\lambda\in\Rbb\setminus\{0\}$. Let us prove \eqref{eq428} in the special case that $i=1$; the general case is similar. Since both sides of \eqref{eq428} are Radon measures, it suffices to choose any $f\in C_c(\Rbb^n)$ and show that the integral of $f$ with respect to these two measures are equal. Note that $|\det\Phi|=|\lambda|$. When $n=1$, this follows from Prop. \ref{lb396}. For a general $n$, we compute
\begin{align*}
&\int_{\Rbb^n} f\cdot\Phi^*dm=\int_{\Rbb^n} (f\circ\Phi^{-1})dm=\int_{-\infty}^{+\infty}\cdots\int_{-\infty}^{+\infty}f(\lambda^{-1} x_1,x_2,\dots,x_n)dx_1\cdots dx_n\\
=&|\lambda|\cdot \int_{-\infty}^{+\infty}\cdots\int_{-\infty}^{+\infty}f(x_1,x_2,\dots,x_n)dx_1\cdots dx_n=\int_{\Rbb^n}f\cdot |\lambda|dm
\end{align*}
This finishes the proof.

Case 2: $\Phi$ exchanges the $i$-th row and the $j$-th row. For simplicity we assume $i=1,j=2$. The $\Phi^{-1}=\Phi$, and $|\det\Phi|=1$. For each $f\in C_c(\Rbb^n)$, we have
\begin{align*}
&\int_{\Rbb^n} f\cdot\Phi^*dm=\int_{\Rbb^n} (f\circ\Phi^{-1})dm=\int_{\Rbb^n} f(x_2,x_1,x_3,\dots,x_n)dm\\
=&\int_{-\infty}^{+\infty}\cdots\int_{-\infty}^{+\infty}f(x_2,x_1,x_3,\dots,x_n)dx_2 dx_1 dx_3\cdots dx_n=\int_{\Rbb^n}fdm
\end{align*}

Case 3: $\Phi$ adds $\lambda$ times the $j$-th row of a column vector to the $i$-th row, where $\lambda\in\Rbb$ and $i\neq j$. Assume for simplicity that $i=1,j=2$. So $\Phi(a_1,a_2,\dots,a_n)=(a_1+\lambda a_2,a_2,\dots,a_n)$. Then $|\det\Phi|=1$, and
\begin{align*}
\int_{\Rbb^n} f\cdot\Phi^*dm=\int_{\Rbb^n} (f\circ\Phi^{-1})dm=\int_{-\infty}^{+\infty}\cdots\int_{-\infty}^{+\infty}f(x_1-\lambda x_2,x_2,\dots,x_n)dx_1\cdots dx_n
\end{align*}
When computing the innermost integral, $x_2$ is a constant. So $\int f(x_1-\lambda x_2,x_2,\dots,x_n)dx_1=\int f(x_1,x_2,\dots,x_n)dx_1$. Therefore, the RHS above equals $\int_{\Rbb^n}fdm$.
\end{proof}



\subsubsection{The general case}\label{mc63}

\begin{lm}\label{mc47}
Suppose that for any $\Omega,\Delta,\Phi$ as in Thm. \ref{mc39}, we have
\begin{align}\label{eq430}
\Phi^*dm_\Delta\leq |\Jbf\Phi|dm_\Omega
\end{align}
on $\fk B_\Omega$. Then Thm. \ref{mc39} holds true.
\end{lm}

\begin{proof}
By assumption, \eqref{eq430} also holds when $\Phi$ is replaced by $\Psi=\Phi^{-1}$, i.e.,
\begin{align*}
\Psi^*dm_\Omega\leq |\Jbf(\Psi)|dm_\Delta
\end{align*}
Since $\Phi\circ\Psi=\id$, by the chain rule Thm. \ref{lb578}, for each $p\in\Delta$ we have $1=\Jac\Phi|_{\Psi(p)}\cdot\Jac\Psi|_p$ and hence $1=\Jbf\Phi|_{\Psi(p)}\cdot\Jbf\Psi|_p$. Therefore $((\Jbf\Phi)\circ\Psi)\cdot\Jbf\Psi:\Delta\rightarrow\Rbb$ is the constant function $1$. Hence
\begin{align*}
&dm_\Delta=\Psi^*\Phi^*dm_\Delta\leq \Psi^*(|\Jbf\Phi|dm_\Omega)\xlongequal{\eqref{eq429}}|(\Jbf\Phi)\circ\Psi|\cdot \Psi^*dm_\Omega\\
\leq&|(\Jbf\Phi)\circ\Psi|\cdot|\Jbf\Psi|dm_\Delta=dm_\Delta
\end{align*}
Therefore $dm_\Delta=\Psi^*(|\Jbf\Phi|dm_\Omega)$. Applying $\Phi^*$ to both sides gives $\Phi^*dm_\Delta=|\Jbf\Phi|dm_\Omega$.
\end{proof}


To prove Inequality \eqref{eq430}, we first give a rough upper bound for $\Phi^*dm_\Delta$.


\begin{lm}\label{mc46}
Let $\Omega,\Delta,\Phi$ as in Thm. \ref{mc39}. Instead of the Euclidean norm, consider the $l^\infty$-norm
\begin{align}
\Vert (a_1,\dots,a_n)\Vert_\infty=\max\{|a_1|,\dots,|a_n|\}
\end{align}
on $\Rbb^n$ and the corresponding operator norm on $\fk L(\Rbb^n)$. If $C\in\Rbb_{\geq0}$ satisfies $\Vert\Jac\Phi|_x\Vert\leq C$ for all $x\in\Omega$, then
\begin{align*}
\Phi^*dm_\Delta\leq C^n\cdot dm_\Omega
\end{align*}
\end{lm}



\begin{proof}
By Prop. \ref{mc37}, it suffices to prove that
\begin{align}\label{eq431}
m(\Phi(Q))\leq C^n m(Q)
\end{align}
for any cube $Q$ in $\Omega$. We first consider the case that $Q$ is open. Let $p$ be the center of $Q$, and let $L$ be the side length of $Q$. In other words, 
\begin{align*}
Q=\{x\in\Rbb^n:\Vert x-p\Vert_\infty<L/2\}
\end{align*}
We have $m(Q)=L^n$. Let $q=\Phi(p)$. Then $R=\{y\in\Rbb^n:\Vert y-q\Vert_\infty<LC/2\}$ is the open cube with center $q$ and side length $CL/2$. So $m(R)=C^nL^n$. Therefore, to prove \eqref{eq431}, it suffices to prove $\Phi(Q)\subset R$.

Choose any $x\in Q$. By the finite increment Thm. \ref{lb584} (and also Rem. \ref{mc45}), for each $x\in Q$ we have
\begin{align}
\Vert \Phi(x)-q\Vert_\infty\leq C\Vert x-p\Vert_\infty<CL/2
\end{align}
So $\Phi(x)\in R$. This proves $\Phi(Q)\subset R$, and hence \eqref{eq431} holds when $Q$ is open.

Now, we do not assume that $Q$ is open. But we can find a decreasing sequence $(Q_k)_{k\in\Zbb_+}$ of open cubes in $\Omega$ such that $\bigcap_kQ_k=\ovl Q$. Therefore $m(\Phi(Q_k))\leq C^nm(Q_k)$. Taking $\lim_{k\rightarrow\infty}$, we get $m(\Phi(Q))\leq m(\Phi(\ovl Q))\leq C^n m(\ovl Q)$. Since $\ovl Q\setminus Q$ is a Lebesgue null set, we have $m(\ovl Q)=m(Q)$. This proves \eqref{eq431}.
\end{proof}

\begin{rem}\label{mc60}
From the above proof, it is clear that the inequality \eqref{eq431} holds if $\Phi:\Omega\rightarrow\Delta$ is only a $C^1$-map, not necessarily a $C^1$-diffeomorphism. This fact can be used to show that a $C^1$-map sends Lebesgue null sets to Lebesgue null sets; see Pb. \ref{mc59}.
\end{rem}




\begin{proof}[\textbf{Proof of Thm. \ref{mc39}}]
Suppose we can prove that for each $\gamma>1$,
\begin{align}\label{eq432}
\Phi^*dm_\Delta\leq \gamma|\Jbf\Phi|dm_\Omega
\end{align}
Then for every $f\in C_c(\Omega,\Rbb_{\geq0})$ we have $\int_\Omega f\cdot \Phi^*dm\leq \gamma\int_\Omega f\cdot |\Jbf\Phi|dm$. Since $\gamma$ is arbitrary, we get $\int_\Omega f\cdot \Phi^*dm\leq \int_\Omega f\cdot |\Jbf\Phi|dm$, and hence $\Phi^*dm_\Delta\leq |\Jbf\Phi|dm_\Omega$. This will finish the proof thanks to Lem. \ref{mc47}.

Let us fix $\gamma>1$ and prove \eqref{eq432}. By Prop. \ref{mc36}, it suffices to prove that for every $p\in\Omega$ there exists $U\in\Nbh_\Omega(p)$ such that \eqref{eq432} holds when restricted to $U$. Thus, fixing $p\in\Omega$, we shall show that after shrinking $\Omega$ to a neighborhood of $p$ and shrinking $\Delta$ to $\Phi(\Omega)$, then \eqref{eq432} holds true.

We let $A=\Jac\Phi|_p$ and $\wtd\Phi=A^{-1}\Phi:\Omega\rightarrow D$ where $D=A^{-1}(\Delta)$. Then $\wtd\Phi$ is a $C^1$-diffeomorphism, and $\Phi=A\circ\wtd\Phi$, and $\Jac\wtd\Phi|_p=1$. Since $\Jac\wtd\Phi$ and $\Jac\Phi$ are continuous, we may shrink $\Omega$ to a neighborhood of $p$ and shrink $D,\Delta$ to $\wtd\Phi(\Omega),\Phi(\Omega)$ such that for all $x\in\Omega$ we have:
\begin{itemize}
\item The operator norm $\Vert\Jac\wtd\Phi|_x\Vert$ defined with respect to the $l^\infty$-norm of $\Rbb^n$ is $\leq\sqrt[2n]\gamma$.
\item $|\Jbf\Phi|_p|\leq\sqrt\gamma\cdot |\Jbf\Phi|_x|$.
\end{itemize}
Therefore, by Lem. \ref{mc46}, we have $\wtd\Phi^*dm_D\leq \sqrt\gamma\cdot dm_\Omega$. By Lem. \ref{mc48}, we have 
\begin{align*}
A^*dm_\Delta=|\det A|dm_D=|\Jbf\Phi|_p|dm_D
\end{align*}
Therefore
\begin{align*}
\Phi^*dm_\Delta=\wtd\Phi^*A^*dm_\Delta=|\Jbf\Phi|_p|\cdot \wtd\Phi^*dm_D\leq \sqrt\gamma|\Jbf\Phi|\cdot \wtd\Phi^*dm_D\leq\gamma|\Jbf\Phi|dm_\Omega
\end{align*}
This finishes the proof.
\end{proof}



\subsection{Problems and supplementary material}


Part 1 of the following problem is a variant of Prop. \ref{mc36}.


\begin{prob}\label{mc106}
Let $X$ be a second countable topological space. Let $\fk U$ be an open cover of $X$. 
\begin{enumerate}
\item Suppose that $\mu,\nu:\fk B_X\rightarrow\ovl\Rbb_{\geq0}$ are Borel measures. Prove that $\mu\leq\nu$ if and only if $\mu|_U\leq\nu|_U$ for every $U\in\fk U$.
\item Suppose that for each $U\in\fk U$ a Borel measure $\mu_U$ on $U$ is chosen. Suppose that for each $U,V\in\fk U$ we have $\mu_U|_{U\cap V}=\mu_V|_{U\cap V}$. Prove that there exists a unique Borel measure $\mu$ on $X$ such that $\mu|_U=\mu_U$ for all $U\in\fk U$.
\item In part 2, assume moreover that $X$ is LCH, and that $\mu_U$ is a Radon measure for each $U\in\fk U$. Prove that $\int_Xfd\mu<+\infty$ for all $f\in C_c(X,\Rbb_{\geq0})$, and hence (by Lem. \ref{lb806} and Thm. \ref{lb818}) that $\mu$ is a Radon measure on $X$.
\end{enumerate}
\end{prob}


\begin{sprob}\label{mc59}
Let $\Omega,\Delta\subset\Rbb^n$ be open. Let $\Phi:\Omega\rightarrow\Delta$ be a $C^1$-map (whose Jacobian $\Jbf\Phi$ is possibly zero at some points of $\Omega$). Prove that $\Phi$ maps Lebesgue null sets to Lebesgue null sets.
\end{sprob}

\begin{proof}[Hint]
See Rem. \ref{mc60}, and use Cor. \ref{mc62}.
\end{proof}



\subsubsection{$\star$ Convolutions and smooth approximations}

Let $1\leq p,q\leq+\infty$ and $p^{-1}+q^{-1}=1$. Let $f,g:\Rbb^N\rightarrow\Cbb$ be functions. For each $x\in\Rbb^N$, let $\tau_xg:\Rbb^N\rightarrow\Cbb$ be defined by $\tau_xg(y)=g(y-x)$. $\tau_xf$ is defined in a similar way. 

Given $\varphi:\Rbb^N\rightarrow\Cbb$, for each $\eps>0$, let $\varphi_\eps:\Rbb^N\rightarrow\Cbb$ be defined by
\begin{align}
\varphi_\eps(x)=\eps^{-N}\varphi(x/\eps)
\end{align}


\begin{prob}
For each $y\in\Rbb^N$, show that the function $x\in\Rbb^N\mapsto f(x)g(y-x)$ is Lebesgue integrable iff $x\in\Rbb^N\mapsto f(y-x)g(x)$ is Lebesgue integrable. When either of them is true, show that
\begin{align}
\int_{\Rbb^N}f(x)g(y-x)dm(x)=\int_{\Rbb^N}f(y-x)g(x)dm(x)
\end{align}
In other words, $\int f(x)\tau_xgdx$ and $\int g(x)\tau_xfdx$ are equal at $y$ whenever they can be defined. The above expression is denoted by $(f*g)(y)$ and called the \textbf{convolution} \index{00@Convolution} of $f$ and $g$ at $y$.  
\end{prob}



\begin{prob}\label{mc51}
Let $f\in L^1(\Rbb^N,m)$ and $g\in L^p(\Rbb^N,m)$. 
\begin{enumerate}
\item Prove that $(f*g)(y)$ can be defined for $m$-a.e. $y\in\Rbb^N$.
\item Extend $f*g$ to an everywhere defined function on $\Rbb^N$. Prove that $f*g$ is Lebesgue measurable, and
\begin{align}\label{eq433}
\Vert f*g\Vert_{L^p}\leq \Vert f\Vert_{L^1}\cdot\Vert g\Vert_{L^p}
\end{align}
\end{enumerate}
\end{prob}


\begin{proof}[Hint]
Use Pb. \ref{mc49} for the case $p<+\infty$. The case $p=+\infty$ should be treated separately.
\end{proof}

\begin{prob}\label{mc50}
Let $\varphi\in L^1(\Rbb^N,m)$ satisfy
\begin{align}\label{eq434}
\int_{\Rbb^N}\varphi dm=1
\end{align}
Using the change of variables Thm. \ref{mc42}, it is easy to check that $\int_{\Rbb^N}\varphi_\eps=1$ and $\Vert \varphi\Vert_{L^1}=\Vert\varphi_\eps\Vert_{L^1}$.
\begin{enumerate}
\item Let $E\subset\Rbb^N$ be any Lebesgue measurable set such that $0\in\Int_{\Rbb^N}(E)$. Prove that $\dps\lim_{\eps\rightarrow0} \int_{\Rbb^N\setminus E} |\varphi_\eps| dm=0$. 
\item Let $1\leq p<+\infty$ and $g\in L^p(\Rbb^N,m)$. Prove that $\dps\lim_{\eps\rightarrow0}\Vert\varphi_\eps*g-g\Vert_p=0$.
\end{enumerate}
\end{prob}

\begin{proof}[Hint]
Generalize the arguments in Sec. \ref{mc52}. Approximate $\varphi$ and $g$ by elements in $C_c(\Rbb^N)$ under suitable norms. Use Eq. \eqref{eq433} in the proof of Part 2.
\end{proof}


\begin{prob}\label{mc57}
Let $\varphi\in L^1(\Rbb^N,m)$ satisfy \eqref{eq434}. Let $g\in \ovl B_{L^\infty(\Rbb^N,m)}(0,1)$.
\begin{enumerate}
\item Let $f,h\in L^1(\Rbb^N,m)$. Let
\begin{align*}
\wch f(x)=f(-x)
\end{align*}
Note that $f*g\in L^\infty(\Rbb^N,m)$ and $\wch f*h\in L^1(\Rbb^N,m)$ by Pb. \ref{mc51}. Prove that
\begin{align}
\bk{f*g,h}=\bk{g,\wch f*h}
\end{align}
where $\bk{\cdot,\cdot}:L^\infty\times L^1\rightarrow\Cbb$ is the canonical pairing (defined by Prop. \ref{lb897}).
\item Use Part 1 to prove that $\dps\lim_{\eps\rightarrow0}\varphi_\eps*g$ converges weak-* in $\ovl B_{L^\infty(\Rbb^N,m)}(0,1)$ to $g$.
\end{enumerate}
\end{prob}




\begin{prob}\label{mc56}
Let $r\in\Nbb\cup\{\infty\}$. Choose $f$ in $C_c^r(\Rbb^N):=C^r(\Rbb^N)\cap C_c(\Rbb^N)$. Let $g\in L^p(\Rbb^N,m)$. By Pb. \ref{mc51}-2 we have $f*g\in L^p(\Rbb^N,m)$.
\begin{enumerate}
\item Prove that $f*g$ is a continuous function.
\item Assume $r\geq 1$. Let $1\leq j\leq N$. Prove that $\partial_j(f*g)$ exists everywhere and equals $(\partial_jf)*g$. (Note that by Part 1, $(\partial_jf)*g$ is continuous.)
\item Conclude that $f*g\in C^r(\Rbb^N)\cap L^p(\Rbb^N,m)$. 
\end{enumerate}
\end{prob}

\begin{proof}[Hint]
Consider the map $y\in\Rbb^N\mapsto\tau_{-y} f\in C_c(\Rbb^N)$ whose codomain is equipped with the $L^q$-norm. Show that this map is continuous. Show that if $r\geq1$, its partial derivative under $\partial_j$ exists and is equal to $y\mapsto \tau_{-y}\partial_jf$. Show that
\begin{align}
(f*g)(y)=\bk{\tau_{-y}f,\wch g}
\end{align}
where $\bk{\cdot,\cdot}$ is the canonical bilinear pairing $L^q\times L^p\rightarrow\Cbb$.
\end{proof}



\begin{rem}\label{mc58}
Suppose that $1\leq p<+\infty$ and $g\in L^q(\Rbb^N,m)$.  By Thm. \ref{mc53}, we can find a net $(g_\alpha)$ in $C^\infty(\Rbb^N)\cap L^q(\Rbb^N,m)$ converging under the $L^q$-norm to $g$. Now, the convolution operation provides an explicit construction of $(g_\alpha)$: Choose any $\varphi\in C_c^\infty(\Rbb^N)$ such that $\int_{\Rbb^N}\varphi dm=1$. Then by Pb. \ref{mc50} and Pb. \ref{mc56}, $(\varphi_\eps *g)_{\eps\in\Rbb_{>0}}$ is a net in $C^\infty(\Rbb^N)\cap L^q(\Rbb^N,m)$ converging to $g$ under the $L^p$-norm.

Similarly, if $g\in \ovl B_{L^\infty(\Rbb^N,m)}(0,1)$, by Pb. \ref{mc57} and Pb. \ref{mc56}, $(\varphi_\eps *g)_{\eps\in\Rbb_{>0}}$ is a net in the unit ball of $C^\infty(\Rbb^N)\cap L^\infty(\Rbb^N,m)$ converging weak-* to $g$. Compare this with Rem. \ref{mc55}.  \hfill\qedsymbol
\end{rem}

\newpage







\section{Tensor products of vector spaces}


In this chapter, we fix a field $\Fbb$. For simplicity, the reader can assume that $\Fbb\in\{\Rbb,\Cbb\}$. Unless otherwise stated, all vectors spaces are over $\Fbb$. Recall from Sec. \ref{mc74} that if $V,W$ are vector spaces then $\Lin(V,W)$ is the set of linear maps $V\rightarrow W$. When $\dim V<+\infty$, both $V^\vee$ and $V^*$ denote the algebraic dual space $\Lin(V,\Fbb)$. However, if $V$ is infinite dimensional, we only let $V^\vee$ denote $\Lin(V,\Fbb)$ since $V^*$ possibly has a different meaning, e.g., $V^*=\fk L(V,\Fbb)$ if $V$ is a normed vector space.



\subsection{Introduction}\label{mc75}




\subsubsection{Linear products of vector spaces}

Suppose that $\scr A$ is a unital $\Fbb$-algebra, e.g., the set of $\Fbb$-polynomials, the algebra $C(X,\Fbb)$ (where $X$ is a compact space and $\Fbb\in\{\Rbb,\Cbb\}$), $\Fbb^X$ (where $X$ is a set), or $\Fbb^{n\times n}$ (the algebra of $n\times n$ matrices). Then we have a product map
\begin{align*}
\scr A\times\scr A\rightarrow\scr A\qquad (f,g)\mapsto fg
\end{align*}
To call this map a ``product" means that it should satisfy the \textbf{associativity}
\begin{align*}
(fg)h=f(gh)
\end{align*}
and that it satisfies the distributive law, i.e., it is \textbf{bilinear}.

Now, suppose that $U,V$ are linear subspaces of $\scr A$, and let $U\odot V=\Span\{fg:f\in U,g\in V\}$. Then the above product map restricts to 
\begin{align*}
U\times V\rightarrow U\odot V\qquad (f,g)\mapsto fg
\end{align*}
which is clearly bilinear. Similarly, let $W$ be also a linear subspace of $\scr A$. Then we can define $V\odot W$ and get a bilinear map
\begin{align*}
V\times W\rightarrow V\odot W\qquad (g,h)\mapsto gh
\end{align*}
If we let $U\odot V\odot W=\Span\{fgh:f\in U,g\in V,h\in W\}$, then
\begin{align*}
(U\odot V)\odot W=U\odot (V\odot W)=U\odot V\odot W
\end{align*}
which can be interpreted as the associativity.



Motivated by the above discussion, we make the following definition:
\begin{df}
Let $V_1,\dots,V_N$ be vector spaces. A \textbf{linear product} \index{00@Products of vector spaces} (or simply a \textbf{product}) $\odot$ of $V_1,\dots,V_N$ is a vector space $V_1\odot\cdots\odot V_N$ together with a multilinear map
\begin{align}\label{eq439}
\odot: V_1\times\cdots\times V_N\rightarrow V_1\odot\cdots\odot V_N\qquad (v_1,\dots,v_N)\mapsto v_1\odot\cdots\odot v_N
\end{align}
The \textbf{multilinearity} (or \pmb{$N$}\textbf{-linearity}) \index{00@Multilinear map} means that for each $1\leq i\leq N$ and each fixed $v_1\in V_1,\dots,v_{i-1}\in V_{i-1},v_{i+1}\in V_{i+1},\dots,v_N\in V_N$, the map $v_i\in V_i\mapsto v_1\otimes\cdots\otimes v_N$ is linear.

We say that a linear product \eqref{eq439} is a \textbf{surjective product} \index{00@Surjective product of vector spaces} if the codomain $V_1\odot\cdots\odot V_N$ is spanned by the range.   \hfill\qedsymbol
\end{df}


A typical product $\odot$ is surjective. However, we do not assume surjectivity in the definition of products so that it can be applied to more general situations.


\begin{eg}
Let $V$ be a nonzero vector space. Then the canonical pairing $\bk{\cdot,\cdot}:V\times V^\vee\rightarrow\Fbb$ is a surjective product.
\end{eg}


\subsubsection{Homomorphisms of linear products}\label{mc76}

Let $\scr A$ and $\scr B$ be unital $\Fbb$-algebras. A  \textbf{unital homomorphism} \index{00@Unital homomorphism of algebras}  $\Phi:\scr A\rightarrow\scr B$ is defined to be a linear map satisfying $\Phi(fg)=\Phi(f)\Phi(g)$ and $\Phi(1_{\scr A})=1_{\scr B}$ for all $f,g\in\scr A$.

We shall use homomorphisms of algebras to motivate the definition of homomorphisms of products of vector spaces. However, for that purpose, it is not convenient to view $U,V$ as subspaces of $\scr A$. Instead, we should understand $U,V$ as vector spaces together with linear maps $\varphi:U\rightarrow\scr A$ and $\psi:V\rightarrow\scr A$. This gives a product
\begin{gather*}
U\odot V=\Span\{\varphi(u)\psi(v):u\in U,v\in V\}\\
\odot: U\times V\rightarrow U\odot V\qquad (u,v)\mapsto \varphi(u)\cdot\psi(v)
\end{gather*}
Moreover, the linear maps $\wtd\varphi=\Phi\circ\varphi:U\rightarrow\scr B$ and $\wtd\psi=\Phi\circ\psi:V\rightarrow\scr B$ give a product
\begin{gather*}
U\boxdot V=\Span\{\wtd\varphi(u)\wtd\psi(v):u\in U,v\in V\}\\
\boxdot:U\times V\rightarrow U\boxdot V\qquad (u,v)\mapsto \wtd\varphi(u)\cdot\wtd\psi(v)
\end{gather*}
Then $\Phi$ restricts to a linear map $U\odot V\rightarrow U\boxdot V$, and for every $u\in U,v\in V$ we have
\begin{align*}
\Phi(u\odot v)=u\boxdot v
\end{align*}
This motivates the following definition:


\begin{df}
Let $\odot$ and $\boxdot$ be products of vector spaces $V_1,\dots,V_N$. A \textbf{homomorphism of product} \index{00@Homomorphism of products of vector spaces} $\Phi:\odot\rightarrow\boxdot$ is defined to be a linear map satisfying
\begin{gather}
\begin{gathered}
\Phi:V_1\odot\cdots\odot V_N\rightarrow V_1\boxdot\cdots\boxdot V_N\\
\Phi(v_1\odot\cdots\odot v_N)=v_1\boxdot\cdots\boxdot v_N
\end{gathered}
\end{gather}
for all $v_1\in V_1,\dots,v_N\in V_N$. If $\Phi$ is also bijective, then $\Phi^{-1}$ is a homomorphism from $\boxdot$ to $\odot$. In this case, we say that $\Phi$ is an \textbf{isomorphism of products}, \index{00@Isomorphism of products of vector spaces} and that $\odot$ and $\boxdot$ are isomorphic, and we write $\odot\simeq\boxdot$.  
\end{df}

\begin{rem}\label{mc66}
Suppose that $\odot$ is surjective. Then it is clear that there exists at most one homomorphism $\Phi:\odot\rightarrow\boxdot$. In particular, there exists precisely one endomorphism on $\odot$ (i.e., homomorphism $\odot\rightarrow\odot$), which is the identity map on $V_1\odot\cdots\odot V_N$.
\end{rem}







\subsection{Tensor products of vector spaces}



\begin{df}
Let $V_1,\dots,V_N$ be vector spaces. A product $\otimes:V_1\times\cdots\times V_N\rightarrow V_1\otimes\cdots\otimes V_N$ is called a \textbf{tensor product} \index{00@Tensor product} if the following condition is satisfied:
\begin{enumerate}
\item[(a)] $\otimes$ is surjective, i.e., its range spans the codomain.
\item[(b)] For any product $\odot:V_1\times\cdots\times V_N\rightarrow V_1\odot\cdots\odot V_N$ there exists a homomorphism of products $\Phi:\otimes\rightarrow\odot$.
\end{enumerate}
Note that such $\Phi$ must be unique by the surjectivity of $\otimes$. If $V_1,\dots,V_N$ are all $V$, we write the tensor product as $V^{\otimes N}$. We understand
\begin{align*}
V^{\otimes 0}=\Fbb
\end{align*}
\end{df}

%% Record #22 2024/05/16 Three lectures  54

\begin{eg}
Let $\otimes:V_1\times\cdots\times V_N\rightarrow V_1\otimes\cdots\otimes V_N$ be a tensor product of vector spaces. Let $\sigma:\{1,\dots,N\}\rightarrow\{1,\dots,N\}$ be a bijection. Then
\begin{gather}
V_1\times\cdots\times V_N\rightarrow V_{\sigma(1)}\otimes\cdots\otimes V_{\sigma(n)}\qquad (v_1,\dots,v_N)\mapsto v_{\sigma(1)}\otimes\cdots\otimes v_{\sigma(N)}
\end{gather}
is clearly a tensor product.
\end{eg}


\begin{eg}\label{mc65}
Let $X_1,\dots,X_N$ be sets, equipped with the discrete topology. Let $X=X_1\times\cdots\times X_N$. Let $\pi:X\rightarrow X_i,(x_1,\dots,x_N)\rightarrow x_i$ be the projection. Then
\begin{gather}\label{eq440}
\begin{gathered}
C_c(X_1,\Fbb)\times\cdots\times C_c(X_N,\Fbb)\rightarrow C_c(X,\Fbb)\\
(f_1,\dots,f_N)\rightarrow (f_1\circ\pi_1)\cdots (f_N\circ\pi_N)
\end{gathered}
\end{gather}
is a tensor product of $C_c(X_1,\Fbb),\dots,C_c(X_N,\Fbb)$. Here, $C_c(X_i,\Fbb)$ is the set of $f\in\Fbb^{X_i}$ such that $\{x\in X_i:f(x_i)\neq 0\}$ is a finite set. $C_c(X,\Fbb)$ is understood in a similar way.
\end{eg}

Note that we often abbreviate $f_i\circ\pi_i$ to $f_i$ so that $f_i$ is also viewed as a function on $X$. Then the product \eqref{eq440} sends $(f_1,\dots,f_N)$ to the usual product of functions $f_1\cdots f_N$. We have used this convention in Thm. \ref{lb826}.

\begin{proof}
For each $x\in X$, $\chi_{\{x\}}$ is clearly in the range of the product \eqref{eq440}. Therefore \eqref{eq440} is a surjective product.

Write $V_i=C_c(X_i,\Fbb)$. Let $\otimes$ denote \eqref{eq440}, and let $\odot:V_1\times\cdots\times V_N\rightarrow W$ be another product (i.e., a multilinear map). Then for each $x=(x_1,\dots,x_N)\in X$, we have $\chi_{\{x\}}=\chi_{\{x_1\}}\otimes\cdots\otimes\chi_{\{x_N\}}$. Moreover, $\{\chi_{\{x\}}:x\in X\}$ is a basis of $C_c(X,\Fbb)$. Therefore, we have a unique linear map
\begin{gather*}
\Phi:C_c(X,\Fbb)\rightarrow W\qquad \Phi(\chi_{\{x\}})=\chi_{\{x_1\}}\odot\cdots\odot\chi_{\{x_N\}}
\end{gather*}
From this definition, it is clear that $\Phi(f_1\otimes\cdots\otimes f_N)=f_1\odot\cdots\odot f_N$ holds if for each $i$, $f_i=\chi_{\{x_i\}}$ for some $x_i\in X_i$. By the (multi-)linearity, this relation holds for all $f_i$. More precisely, since $f_i=\sum_{x_i\in X_i}f(x_i)\chi_{\{x_i\}}$, and since $f_1\otimes\cdots\otimes f_N$ equals $\sum_{x\in X}f_1(x_1)\cdots f_N(x_n)\cdot \chi_{\{x\}}$ (because it sends each $x$ to $f_1(x_1)\cdots f_N(x_n)$), we have
\begin{align*}
&\Phi(f_1\otimes\cdots\otimes f_N)=\Phi\Big(\sum_{x\in X}f_1(x_1)\cdots f_N(x_n)\cdot \chi_{\{x\}}\Big)\\
=&\sum_{x\in X}f_1(x_1)\cdots f_N(x_n)\cdot\Phi(\chi_{\{x\}})=\sum_{x\in X}f_1(x_1)\cdots f_N(x_n)\cdot \chi_{\{x_1\}}\odot\cdots\odot\chi_{\{x_N\}}\\
=&\Big(\sum_{x_1\in X_1}f_1(x_1)\chi_{\{x_1\}}\Big)\odot\cdots\odot\Big(\sum_{x_N\in X_N}f_N(x_N)\chi_{\{x_N\}}\Big)=f_1\odot\cdots\odot f_N
\end{align*}
This proves that $\Phi:\otimes\rightarrow\odot$ is a homomorphism of products.
\end{proof}


\begin{thm}\label{mc67}
Let $V_1,\dots,V_N$ be vector spaces. Then there exists a tensor product $\otimes:V_1\times\cdots\times V_N\rightarrow V_1\otimes\cdots\otimes V_N$. Moreover, if $\odot:V_1\times\cdots\times V_N\rightarrow V_1\odot\cdots\odot V_N$ is also a tensor product, then $\otimes$ and $\odot$ are isomorphic. 
\end{thm}

\begin{proof}
Since each $V_i$ has a basis indexed by some set $X_i$ (cf. Pb. \ref{mc64}), $V_i$ is linearly isomorphic to $C_c(X_i,\Fbb)$. Therefore, we may assume WLOG that $V_i=C_c(X_i,\Fbb)$. Then the existence of a tensor product $\otimes$ is due to Exp. \ref{mc65}. 

Suppose that $\odot$ is another tensor product. By the definition of tensor products, there exists homomorphisms of tensor products $\Phi:\otimes\rightarrow\odot$ and $\Psi:\odot\rightarrow\otimes$. Therefore $\Psi\circ\Phi:\otimes\rightarrow\otimes$ must be a homomorphism, and hence is the identity map (on $V_1\otimes\cdots\otimes V_N$) by Rem. \ref{mc66}. Similarly, $\Phi\circ\Psi$ is the identity map. So $\Phi$ is an isomorphism.
\end{proof}



The fact that $\{\chi_{\{x\}}:x\in X\}$ is a basis of $C_c(X,\Fbb)$ is crucial to the proof that Exp. \ref{mc65} is a tensor product. By slightly generalizing this observation, we have:

\begin{thm}\label{mc68}
Let $V_1,\dots,V_N$ be vector spaces. For each $1\leq i\leq N$, assume that $(e_i(x_i))_{x_i\in X_i}$ is a basis of $V_i$. Let $\otimes:V_1\times\cdots\times V_N\rightarrow V_1\otimes\cdots\otimes V_N$ be a product. Then the following are equivalent:
\begin{enumerate}
\item[(1)] $\otimes$ is a tensor product.
\item[(2)] $\dps \big(e_1(x_1)\otimes\cdots\otimes e_N(x_N)\big)_{x_1\in X_1,\dots,x_N\in X_N}$ is a basis of $V_1\otimes\cdots\otimes V_N$.
\end{enumerate}
\end{thm}


\begin{proof}
Let $X=X_1\times\cdots\times X_N$. We may assume WLOG that $V_i=C_c(X_i,\Fbb)$ and that $e_i(x_i)=\chi_{\{x_i\}}$. Let $\boxtimes$ denote the tensor product in Exp. \ref{mc65}. Then $(\chi_{\{x\}})_{x\in X}$ is a basis of $C_c(X,\Fbb)$. By the definition of tensor products, there is a unique linear map $\Phi:C_c(X,\Fbb)\rightarrow V_1\otimes\cdots\otimes V_N$ sending each $f_1\boxtimes\cdots\boxtimes f_N$ to $f_1\otimes\cdots\otimes f_N$. Take $f_i=\chi_{\{x_i\}}=e_i(x_i)$, we see that $\Phi$ sends each $\chi_{\{x\}}$ to $e_1(x_1)\otimes\cdots\otimes e_N(x_N)$. Therefore, $\Phi$ is a linear isomorphism (and hence an isomorphism of products) iff  (2) is true.

If $\Phi$ is an isomorphism, then $\otimes$ is a tensor product (since $\boxtimes$ is so). This proves (2)$\Rightarrow$(1). Conversely, suppose that $\otimes$ is a tensor product, by Thm. \ref{mc67}, there exists an isomorphism $\wtd\Phi:\boxtimes\rightarrow\otimes$. Since there exists at most one homomorphism from a surjective product to a product (Rem. \ref{mc66}), we must have $\Phi=\wtd\Phi$. Therefore $\Phi$ is an isomorphism. This proves (1)$\Rightarrow$(2).
\end{proof}

\begin{co}\label{mc81}
Let $V_1,\dots,V_N$ be finite dimensional vector spaces. Let $\otimes:V_1\times\cdots\times V_N\rightarrow V_1\otimes\cdots\otimes V_N$ be a \uwave{surjective} product. Then $\otimes$ is a tensor product iff
\begin{align}\label{eq441}
\dim(V_1\otimes\cdots\otimes V_N)=\dim V_1\cdots\dim V_N
\end{align}
\end{co}


\begin{proof}
For each $i$, let $n_i=\dim V_i$, and let $e_i(1),\dots,e_i(n_i)$ be a basis of $V_i$. Since $\otimes$ is surjective, $\big(e_1(k_1)\otimes\cdots\otimes e_N(k_N)\big)_{k_1,\dots,k_N}$ spans $V_1\otimes\cdots\otimes V_N$. So it is a basis iff $\dim(V_1\otimes\cdots\otimes V_N)=n_1\cdots n_N$. In other words, condition (2) of Thm. \ref{mc68} is equivalent to \eqref{eq441}.
\end{proof}












\subsection{Associativity and unitality}


\begin{thm}\label{mc71}
Let $U_1,\dots,U_M$ and $V_1,\dots,V_N$ be vector spaces. Let
\begin{gather*}
\odot:U_1\times\cdots\times U_M\rightarrow \scr U:=U_1\odot\cdots\odot U_M\\
\boxdot:V_1\times\cdots\times V_N\rightarrow \scr V:=V_1\boxdot\cdots\boxdot V_N\\
\oast:\scr U\times\scr V\rightarrow \scr U\oast\scr W
\end{gather*}
be tensor products. Then
\begin{gather}\label{mc69}
\begin{gathered}
U_1\times\cdots\times U_M\times V_1\times\cdots\times V_N\rightarrow (U_1\odot\cdots\odot U_M)\oast(V_1\boxdot\cdots\boxdot V_N) \\
(u_1,\dots,u_M,v_1,\dots,v_N)\mapsto (u_1\odot\cdots\odot u_M)\oast (v_1\boxdot\cdots\boxdot v_N)
\end{gathered}
\end{gather}
is a tensor product. Consequently, if 
\begin{gather}
\otimes:U_1\times\cdots\times U_M\times V_1\times\cdots\times V_N\rightarrow U_1\otimes\cdots\otimes U_M\otimes V_1\otimes\cdots\otimes V_N
\end{gather}
is a tensor product, then there is a unique linear isomorphism $\Phi$ satisfying
\begin{gather}
\begin{gathered}
\Phi:(U_1\odot\cdots\odot U_M)\oast(V_1\boxdot\cdots\boxdot V_N)\xlongrightarrow{\simeq}U_1\otimes\cdots\otimes U_M\otimes V_1\otimes\cdots\otimes V_N\\
(u_1\odot\cdots\odot u_M)\oast(v_1\boxdot\cdots\boxdot v_N)\mapsto u_1\otimes\cdots\otimes u_M\otimes v_1\otimes\cdots\otimes v_N
\end{gathered}
\end{gather}
\end{thm}

\begin{proof}
Using Thm. \ref{mc68}, it is easy to check that \eqref{mc69} is a tensor product.
\end{proof}


\begin{rem}
Roughly speaking, Thm. \ref{mc71} says that one can freely add or remove parentheses in tensor products. In particular, writing all the tensor symbols as $\otimes$, we have linear isomorphisms
\begin{gather}
\begin{gathered}
(V_1\otimes V_2)\otimes V_3\xlongrightarrow{\simeq} V_1\otimes V_2\otimes V_3\xlongleftarrow{\simeq} V_1\otimes (V_2\otimes V_3)\\
(v_1\otimes v_2)\otimes v_3\mapsto v_1\otimes v_2\otimes v_3\mapsfrom v_1\otimes (v_2\otimes v_3)
\end{gathered}
\end{gather}
\end{rem}



The following proposition says that in a tensor product, one can freely remove $\Fbb$.

\begin{pp}\label{mc70}
Let $V$ be a vector space. Then
\begin{subequations}
\begin{gather}
\Fbb\times V\rightarrow V\qquad (\lambda,v)\mapsto \lambda v\\
V\times \Fbb\rightarrow V\qquad (v,\lambda)\mapsto \lambda v
\end{gather}
\end{subequations}
are tensor products. Consequently, if 
\begin{gather}
\otimes_L: \Fbb\times V\rightarrow \Fbb\otimes_LV\qquad \otimes_R: V\times\Fbb\rightarrow V\otimes_R\Fbb 
\end{gather}
are tensor products, then there exist unique linear isomorphisms satisfying
\begin{gather}
\begin{gathered}
\Fbb\otimes_L V\xlongrightarrow{\simeq} V\xlongleftarrow{\simeq} V\otimes_R\Fbb\\
\lambda\otimes_Lv\mapsto \lambda v \mapsfrom v\otimes_R\lambda
\end{gathered}
\end{gather}
\end{pp}

\begin{proof}
Obvious from Thm. \ref{mc68}.
\end{proof}

\begin{co}\label{mc72}
Let $N\in\Zbb_+$. Let $\Fbb^{\otimes N}$ be a tensor product of $N$ pieces of $\Fbb$. Then there is a unique linear isomorphism satisfying
\begin{gather}
\Fbb^{\otimes N}\xlongrightarrow{\simeq}\Fbb\qquad \lambda_1\otimes\cdots\otimes\lambda_N\mapsto \lambda_1\cdots\lambda_N
\end{gather}
\end{co}

\begin{proof}
This follows from Prop. \ref{mc70}, Thm. \ref{mc71}, and induction on $N$. Alternatively, it also follows from applying Thm. \ref{mc68} to the product $\Fbb^N\rightarrow\Fbb$ sending $(\lambda_1,\dots,\lambda_N)\mapsto\lambda_1\cdots\lambda_N$.
\end{proof}



\begin{rem}\label{mc73}
Readers encountering tensor products for the first time may feel uncomfortable with the fact that tensor products are not unique, but only unique up to isomorphisms. Here is a method to overcome this psychological barrier, which we will consistently adopt in the rest of this course.

For any vector spaces $V_1,\dots,V_N$ such that each $V_i$ is not defined to be a tensor product of vector spaces, and that $V_i\neq\Fbb$, we choose an arbitrary tensor product $V_1\times\cdots\times V_N\rightarrow V_1\otimes\cdots\otimes V_N$. However, if some of $V_1,\dots,V_N$ are equal to $\Fbb$, we define their tensor product to be the tensor product of those $V_1,\dots,V_N$ not equal to $\Fbb$; if some of $V_1,\dots,V_N$ are already tensor products, we define their tensor product by ``removing the parentheses". Moreover, a tensor product of several pieces of $\Fbb$ is defined to be $\Fbb$ as in Cor. \ref{mc72}, namely,
\begin{gather}
\Fbb^{\otimes N}=\Fbb\qquad \lambda_1\otimes\cdots\otimes\lambda_N=\lambda_1\cdots\lambda_N
\end{gather}

For example, once the tensor products $V_1\otimes V_2\otimes V_3\otimes V_4$ and $V_2\otimes V_3$ have been chosen, we \textit{define} the tensor product of $V_1,\Fbb,\Fbb,V_2\otimes V_3,\Fbb,V_4$ to be
\begin{gather*}
V_1\times\Fbb\times\Fbb\times (V_2\otimes V_3)\times\Fbb\times V_4\rightarrow V_1\otimes V_2\otimes V_3\otimes V_4\\
(v_1,\alpha,\beta,v_2\otimes v_3,\gamma,v_4)\mapsto \alpha\beta\gamma\cdot(v_1\otimes v_2\otimes v_3\otimes v_4)
\end{gather*}
That this is a tensor product follows from Thm. \ref{mc71} and Prop. \ref{mc70} (which imply that any tensor product $V_1\boxtimes\Fbb\boxtimes\Fbb\boxtimes (V_2\otimes V_3)\boxtimes\Fbb\boxtimes V_4$ is canonically isomorphic to $V_1\otimes V_2\otimes V_3\otimes V_4$). Alternatively, it also follows directly from Thm. \ref{mc68}.

In this way, we have well-defined tensor products for any given set of vector spaces over $\Fbb$. Moreover, we automatically have the strict associativity law
\begin{gather}
\begin{gathered}
(V_1\otimes V_2)\otimes V_3=V_1\otimes V_2\otimes V_3=V_1\otimes (V_2\otimes V_3)\\
(v_1\otimes v_2)\otimes v_3=v_1\otimes v_2\otimes v_3=v_1\otimes (v_2\otimes v_3)
\end{gathered}
\end{gather}
(These three spaces are identical, not just isomorphic!) Similarly, we have
\begin{align*}
\Fbb\otimes V=V=V\otimes\Fbb\qquad \lambda\otimes v=\lambda v=v\otimes\lambda
\end{align*}
which means that $\Fbb$ is a ``unit" with respect to the tensor product operation $\otimes$. \hfill\qedsymbol
\end{rem}


\begin{rem}
We continue the discussion in Rem. \ref{mc73}. The readers may wonder how to determine if a vector space is already a tensor product of some vector spaces. For example, suppose that for each $N\in\Zbb_+$ and for any nonempty finite sets $X_1,\dots,X_N$, if their cardinalities are all $\leq 5$ we \textit{define} the tensor product of $\Fbb^{X_1},\dots,\Fbb^{X_N}$ to be $\Fbb_1^{X_1\times\cdots\times X_N}$ as in Exp. \ref{mc65}, i.e.,
\begin{align*}
f_1\otimes\cdots\otimes f_N=f_1\cdots f_N
\end{align*}
On the other hand, if one of these sets have more than $5$ elements, we define the tensor product to be $\Fbb_1^{X_1\times\cdots\times X_N}$ but satisfying
\begin{align*}
f_1\otimes\cdots\otimes f_N=-f_1\cdots f_N
\end{align*}

Now choose finite sets $A,B,C$ with cardinalities $3,4,5$ respectively. Then the tensor product of $\Fbb^B$ and $\Fbb^C$ is $\Fbb^{B\times C}$ with $g\otimes h=gh$. What is the tensor product of $\Fbb^A$ and $\Fbb^{B\times C}$? Clearly it should be $\Fbb^{A\times B\times C}$. However, the product map depends on whether we view $\Fbb^{B\times C}$ as the tensor product of $\Fbb^B$ and $\Fbb^C$: If yes, then as mentioned in Rem. \ref{mc73}, we should remove the parenthesis. Therefore, for any $f\in\Fbb^A,g\in\Fbb^B,h\in\Fbb^C$ we have $f\otimes (gh)=f\otimes (g\otimes h)=f\otimes g\otimes h=fgh$. If no, then $f\otimes gh=-fgh$ since $\card(B\times C)>5$.

The above conflict can be easily avoided by a trick of renaming the vector spaces (and their elements): We denote the tensor product of $\Fbb^{X_1},\dots,\Fbb^{X_N}$ defined in the first paragraph by the longer name $(\Fbb^{X_1\times\cdots\times X_N};X_1,\dots,X_N)$.\footnote{Alternatively, we may fix a point $x_i\in X_i$, and define the tensor product to be $\Fbb^{X_1\times\cdots\times X_N}\times \{x_1\}\times\cdots\times\{x_N\}$.} This space is isomorphic to $\Fbb^{X_1\times\cdots\times X_N}$ in the obvious way, but is not \textit{equal} to the latter. Then, the tensor product of $\Fbb^A$ and $\Fbb^{B\times C}$ satisfies $f\otimes (gh)=-fgh$, whereas the tensor product of $\Fbb^A$ and $(\Fbb^{B\times C};B,C)=\Fbb^B\otimes\Fbb^C$ satisfies $f\otimes (g\otimes h)=fgh$. 

Similarly, the tensor product of $\Fbb$ and $V$ is equal to $V$ with $\lambda\otimes v=\lambda v$. However, if we want to consider a different tensor product without causing conflicts, we can choose a vector space isomorphic but not equal to $\Fbb$. For example, consider the space $\Fbb$ but with a longer name $(\Fbb,\heartsuit)$. Then we can define a tensor product $(\Fbb,\heartsuit)\otimes V$ not necessarily equal to $\Fbb\otimes V=V$.  \hfill\qedsymbol
\end{rem}



\begin{rem}
In Sec. \ref{mc75}, we motivated the definition of (tensor) products by considering linear maps of vector spaces into a unital $\Fbb$-algebra $\scr A$. Now, it is natural to ask if the tensor product can be realized in this way. The answer is basically yes.

Suppose that  there is a math problem studying the tensor products of vector spaces in a family $(V_i)_{i\in I}$ indexed by a set $I$. Define the \textbf{tensor algebra} \index{00@Tensor algebra}
\begin{align}
\scr A=\Fbb\oplus\bigg(\bigoplus_{n\in\Zbb_+}\bigoplus_{i_1,\dots,i_n\in  I} V_{i_1}\otimes\cdots\otimes V_{i_n}\bigg)
\end{align}
whose multiplication operation is the unique bilinear map $\cdot:\scr A\times\scr A\rightarrow\scr A$ restricting to the tensor product maps
\begin{gather*}
(V_{i_1}\otimes\cdots\otimes V_{i_n})\times (V_{j_1}\otimes\cdots\otimes V_{j_m})\longrightarrow V_{i_1}\otimes\cdots\otimes V_{i_n}\otimes V_{j_1}\otimes\cdots\otimes V_{j_m}\\
\Fbb\times (V_{i_1}\otimes\cdots\otimes V_{i_n})\longrightarrow V_{i_1}\otimes\cdots\otimes V_{i_n}\\
(V_{i_1}\otimes\cdots\otimes V_{i_n})\times\Fbb\longrightarrow V_{i_1}\otimes\cdots\otimes V_{i_n}\\
\Fbb\times\Fbb\longrightarrow \Fbb^{\otimes 2}=\Fbb
\end{gather*}
for all $n,k\in\Zbb_+$ and $i_1,\dots,i_n,j_1,\dots,j_m\in I$. Then $\scr A$ is a unital $\Fbb$-algebra whose unit element is $1\in\Fbb$. Moreover,  if $W_1,\dots,W_n$ are tensor products of members of $(V_i)_{i\in I}$, it is clear that the tensor product $W_1\times\cdots\times W_n\rightarrow W_1\otimes\cdots\otimes W_n$ can be realized by the multiplication in $\scr A$ as in Subsec. \ref{mc76}.

Finally, note that if for each $V_{i_1},\dots,V_{i_n}$ we define another tensor product $V_{i_1}\boxtimes\cdots\boxtimes V_{i_n}$, and if we use these tensor products to define a similar tensor algebra $\scr B$, then there is a canonical unital isomorphism of $\Fbb$-algebras $\scr A\rightarrow\scr B$ restricting to the isomomorphism of products $V_{i_1}\otimes\cdots\otimes V_{i_n}\xrightarrow{\simeq}V_{i_1}\boxtimes\cdots\boxtimes V_{i_n}$. In other words, an isomorphism of tensor products can be understood by a unital isomorphism of unital $\Fbb$-algebras. 

I hope the above discussion can help convince the readers that different but isomorphic tensor products can be viewed as essentially the same, and that in practice it is not necessary to know how the tensor products are explicitly constructed.\hfill\qedsymbol
\end{rem}









\subsection{Tensor products of linear maps}


\begin{rem}\label{mc79}
Let $V_1,\dots,V_N$ and $W$ be vector spaces. Then we have a linear isomorphism
\begin{subequations}\label{eq484}
\begin{gather}\label{eq484a}
\Lin(V_1\otimes\cdots\otimes V_N,W)\quad\xlongrightarrow{\simeq}\quad\{\text{$N$-linear maps }V_1\times\cdots\times V_N\rightarrow W\}
\end{gather}
where each $T\in\Lin(V_1\otimes\cdots\otimes V_N,W)$ corresponds to the $N$-linear map
\begin{align}
\wtd T:V_1\times\cdots\times V_N\rightarrow W\qquad (v_1,\cdots,v_N)\mapsto T(v_1\otimes\cdots\otimes v_N)
\end{align}
\end{subequations}
Recall that for any set $X$, $W^X$ has a natural linear structure. The linear structure of the RHS of \eqref{eq484a} is inherited from that of $(V_1\times\cdots\times V_N)^W$.
\end{rem}

\begin{proof}
The map $T\mapsto \wtd T$ is clearly injective. If $S$ is an $N$-linear map, i.e., a linear product of $V_1,\dots,V_N$, then by the definition of tensor products, we have a homomorphism of products $T:V_1\otimes\cdots\otimes V_N\rightarrow W$. So $T$ is a linear map sending $v_1\otimes\cdots\otimes v_N$ to $S(v_1,\dots,v_N)$. Then clearly $S=\wtd T$.
\end{proof}



The following theorem is the main result of this section. 

\begin{thm}\label{mc82}
Let $V_1,\dots,V_N$ and $W_1,\dots,W_N$ be vector spaces. Then there is an injective linear map
\begin{gather}\label{eq446}
\Phi:\Lin(V_1,W_1)\otimes\cdots\otimes\Lin(V_N,W_N)\longrightarrow \Lin(V_1\otimes\cdots\otimes V_N,W_1\otimes\cdots\otimes W_N)
\end{gather}
such that for each $T_i\in\Lin(V_i,W_i)$, the linear map $\Phi(T_1\otimes\cdots\otimes T_N)$ is described by
\begin{gather}\label{eq445}
\begin{gathered}
\Phi(T_1\otimes\cdots\otimes T_N):V_1\otimes\cdots\otimes V_N\rightarrow W_1\otimes\cdots\otimes W_N\\
v_1\otimes\cdots\otimes v_N\mapsto T_1v_1\otimes\cdots\otimes T_Nv_N
\end{gathered}
\end{gather}
Moreover, if $V_1,\dots,V_N$ are finite dimensional, then $\Phi$ is a linear isomorphism.
\end{thm}


In the remaining part of the notes, we are mainly interested in the case that each $V_i$ and $W_i$ are finite dimensional. In this case, by Cor. \ref{mc81}, the domain and the codomain of $\Phi$ have the same dimension. Therefore, to show that $\Phi$ is an isomorphism, it suffices to show that $\Phi$ is surjective. Thus, Step 2 of the following proof can be skipped.


\begin{proof}
Step 1. For each $i$ and $T_i\in\Lin(V_i,W_i)$, the map
\begin{gather*}
S:V_1\times\cdots\times V_N\rightarrow W_1\otimes\cdots\otimes W_N\\
(v_1,\dots,v_N)\mapsto T_1v_1\otimes\cdots\otimes T_Nv_N
\end{gather*}
is clearly multilinear. Therefore, by Rem. \ref{mc79}, $S$ can be viewed as a linear map $V_1\otimes\cdots\otimes V_N\rightarrow W_1\otimes\cdots\otimes W_N$ which we denote by $\Psi(T_1,\cdots, T_N)$. Then $\Psi(T_1,\cdots, T_N)$ clearly satisfies \eqref{eq445}, i.e., it sends $v_1\otimes\cdots\otimes v_N$ to $T_1v_1\otimes\cdots\otimes T_Nv_N$. (Alternatively, one can first use \eqref{eq445} to define $\Psi(T_1,\cdots, T_N)$ on a basis as described in Thm. \ref{mc68}-(2), and then extend it by linearity to the whole space. Then $\Psi(T_1,\cdots, T_N)$ satisfies \eqref{eq445}.)

The map
\begin{gather*}
\Psi:\Lin(V_1,W_1)\times\cdots\times\Lin(V_N,W_N)\rightarrow \Lin(V_1\otimes\cdots\otimes V_N,W_1\otimes\cdots\otimes W_N)
\end{gather*}
defined above is clearly $N$-linear. Therefore, by Rem. \ref{mc79}, $\Psi$ gives rise to a linear map $\Phi$ as described in \eqref{eq446} and \eqref{eq445}. \\[-1ex]

$\star$ Step 2. Let us show that $\Phi$ is injective. For each $i$, let $(T_i^{\alpha_i})_{\alpha_i\in \mc A_i}$ be a basis of $\Lin(V_i,W_i)$. We write $(\alpha_1,\dots,\alpha_N)$ as $\alpha$, and let $\mc A=\mc A_1\times\cdots\times \mc A_N$. Then by Thm. \ref{mc68},
\begin{align*}
\mc E=(T_\blt^\alpha)_{\alpha\in\mc A}\equiv(T_1^{\alpha_1}\otimes\cdots\otimes T_N^{\alpha_N})_{\alpha\in\mc A}
\end{align*}
is a basis of the domain of $\Phi$. To show that $\Phi$ is injective, it is equivalent to showing that
\begin{align*}
\Phi(\mc E)=(\Phi(T_\blt^\alpha))_{\alpha\in\mc A}=(\Phi(T_1^{\alpha_1}\otimes\cdots\otimes T_N^{\alpha_N}))_{\alpha\in\mc A}
\end{align*}
is linearly independent. This means showing that if $(\lambda_\alpha)_{\alpha\in\mc A}$ has finitely many nonzero terms, and if
\begin{align}\label{eq448}
\sum_\alpha \lambda_\alpha\cdot T_1^{\alpha_1}v_1\otimes\cdots\otimes T_N^{\alpha_N}v_N=0
\end{align}
for all $i$ and $v_i\in V_i$, then $\lambda_\alpha=0$ for all $\alpha$. Moreover, by linearity, it suffices to assume \eqref{eq448} for all $v_i$ in a basis of $V_i$. From this description and from Thm. \ref{mc68}, it is clear that by induction on $N$, it suffices to treat the case that $N=2$.



Let $\Gamma=\sum_{\alpha\in\mc A} \lambda_{\alpha_1,\alpha_2}\Phi(T_1^{\alpha_1}\otimes T_2^{\alpha_2})$ where all but finitely many $\lambda_\alpha$ are zero. Suppose that $\Gamma=0$. For each $v_1\in V_1,v_2\in V_2$ we have
\begin{align}\label{eq447}
\sum_\alpha \lambda_{\alpha_1,\alpha_2} T_1^{\alpha_1}v_1\otimes T_2^{\alpha_2}v_2=0
\end{align}
For each $\psi\in W_2^\vee$, the map $W_1\times W_2\rightarrow W_1$ sending $(w_1,w_2)\mapsto \bk{\psi,w_2}w_1$ is bilinear, and hence gives a linear map
\begin{align*}
\wtd\psi: W_1\otimes W_2\rightarrow W_1\qquad w_1\otimes w_2\mapsto \bk{\psi,w_2}w_1
\end{align*}
Applying $\wtd\psi$ to \eqref{eq447} gives
\begin{align*}
\sum_\alpha \lambda_{\alpha_1,\alpha_2}\bk{\psi,T_2^{\alpha_2}v_2}\cdot T_1^{\alpha_1}v_1=0
\end{align*}
Therefore, the linear map
\begin{align*}
\sum_{\alpha_1\in\mc A_1}\Big(\sum_{\alpha_2\in\mc A_2} \lambda_{\alpha_1,\alpha_2}\bk{\psi,T_2^{\alpha_2}v_2}\Big)\cdot T_1^{\alpha_1}
\end{align*}
is zero. By the linear independence of $(T_1^{\alpha_1})_{\alpha_1\in\mc A_1}$, we conclude that for each $\alpha_1\in\mc A_1$, the vector
\begin{align*}
\sum_{\alpha_2\in\mc A_2} \lambda_{\alpha_1,\alpha_2}T_2^{\alpha_2}v_2
\end{align*}
is zero when evaluated with any $\psi\in W_2^\vee$. Since $W_2^\vee$ separates points of $W_2$ (by an easy application of Zorn's lemma), we conclude that $\sum_{\alpha_2}\lambda_{\alpha_1,\alpha_2} T_2^{\alpha_2}$ is zero. Therefore $\lambda_{\alpha_1,\alpha_2}=0$ for each $\alpha_2$ (and each $\alpha_1$) because $(T_2^{\alpha_2})_{\alpha_2\in\mc A_2}$ is linearly independent.\\[-1ex]


Step 3. Assume that each $V_i$ is finite dimensional. Let us prove that $\Phi$ is surjective in the special case that $N=2$. The general case follows either from a similar argument or from induction on $N$. Let $e_1,\dots,e_m$ and $f_1,\dots,f_n$ be bases of $V_1,V_2$ respectively. By Thm. \ref{mc68}, $(e_i\otimes f_j)_{1\leq i\leq m,1\leq j\leq n}$ is a basis of $V_1\otimes V_2$. Let $\Gamma:V_1\otimes V_2\rightarrow W_1\otimes W_2$ be linear. For each $i,j$, let $\xi_{i,j}=\Gamma(e_i\otimes f_j)$, and let $\Gamma_{i,j}:V_1\otimes V_2\rightarrow W_1\otimes W_2$ be the unique linear map sending $e_i\otimes f_j$ to $\xi_{i,j}$ and sending the other basis elements to $0$. Then $\Gamma=\sum_{i,j}\Gamma_{i,j}$. Therefore, it suffices to check that each $\Gamma_{i,j}$ is in the range of $\Phi$.

So we fix $1\leq i\leq m$ and $1\leq j\leq n$. Write $\xi_{i,j}$ as a finite sum $\xi_{i,j}=\sum_{k,l}w_k\otimes \omega_l$ where $w_k\in W_1$ and $\omega_l\in W_2$. For each $k,l$, let $A_k:V_1\rightarrow W_1$ be the unique linear map sending $e_i$ to $w_k$ and sending the other basis elements to $0$, and let $B_l:V_2\rightarrow W_2$ be the unique linear map sending $f_j$ to $\omega_l$ and sending the other basis elements to $0$. Then
\begin{align*}
\Gamma_{i,j}=\sum_{k,l}\Phi(A_k\otimes B_l)
\end{align*}
since both sides send $e_i\otimes f_j$ to $\sum_{k,l}w_k\otimes\omega_l$ and send the other basis elements to $0$. This finishes the proof.
\end{proof}



\begin{cv}
We use the notations in Thm. \ref{mc82}. Unless otherwise stated, we identify $T_1\otimes\cdots\otimes T_N$ with $\Phi(T_1\otimes\cdots\otimes T_N)$ so that $T_1\otimes\cdots\otimes T_N$ is the unique linear map satisfying
\begin{gather}
\begin{gathered}
T_1\otimes\cdots\otimes T_N:V_1\otimes\cdots\otimes V_N\rightarrow W_1\otimes\cdots\otimes W_N\\
v_1\otimes\cdots\otimes v_N\mapsto Tv_1\otimes\cdots\otimes Tv_N
\end{gathered}
\end{gather}
\end{cv}





\begin{co}\label{mc80}
Let $V,W$ be vector spaces. Assume that $\dim V<+\infty$. Then there is a linear isomorphism 
\begin{align}\label{eq442}
W\otimes V^*\xlongrightarrow{\simeq} \Lin(V,W)\qquad w\otimes\varphi\mapsto T_{w,\varphi}
\end{align}
where for each $v\in V$ we have
\begin{align}
T_{w,\varphi}v=\bk{\varphi,v}\cdot w
\end{align}
\end{co}




\begin{proof}
We have a canonical linear isomorphism $W\simeq \Lin(\Fbb,W)$ where each $w\in W$ corresponds to the linear map $\lambda\in\Fbb\mapsto\lambda w$. Therefore, by Thm. \ref{mc82}, we have canonical isomorphisms
\begin{align*}
W\otimes V^*\simeq \Lin(\Fbb,W)\otimes\Lin(V,\Fbb)\simeq\Lin(\Fbb\otimes V,W\otimes \Fbb)=\Lin(V,W)
\end{align*}
We leave it to the readers to check that the composition of these isomorphisms sends $w\otimes\varphi$ to $T_{w,\varphi}$.
\end{proof}

\begin{exe}
Let $V,W$ be finite dimensional vector spaces with bases $(e_i)_{i\in I}$ and $(f_j)_{j\in J}$ respectively. Identify $W\otimes V^*$ with $\Lin(V,W)$ via the linear isomorphism \eqref{eq442}. Let $T\in\Lin(V,W)$. Let 
\begin{subequations}
\begin{align}
T_i^j=\bk{Te_i,\wch f^j}
\end{align}
Namely, $(T^j_i)_{i\in I,j\in J}$ is the matrix representation of $T$ under these two bases (cf. Sec. \ref{lb966}). Prove that
\begin{align}\label{eq444}
T=\sum_{i\in I,j\in J}T_i^j\cdot(f_j\otimes\wch e^i)
\end{align}
\end{subequations}
\end{exe}



\begin{co}\label{mc83}
Let $V_1,\dots,V_N$ be finite dimensional vector spaces. Then there is a canonical linear isomorphism
\begin{align}
V_1^*\otimes\cdots\otimes V_N^*\xlongrightarrow{\simeq}(V_1\otimes\cdots\otimes V_N)^*
\end{align}
such that if $\varphi_1\in V_1^*,\dots,\varphi_N\in V_N^*$, then $\varphi_1\otimes\cdots\otimes\varphi_N$ is the linear functional described by
\begin{gather}
\begin{gathered}
\varphi_1\otimes\cdots\otimes\varphi_N:V_1\otimes\cdots\otimes V_N\rightarrow\Fbb\\
v_1\otimes\cdots\otimes v_N\mapsto \varphi_1(v_1)\cdots\varphi_N(v_N)
\end{gathered}
\end{gather}
\end{co}

\begin{proof}
In Thm. \ref{mc82}, take $W_1=\cdots=W_N=\Fbb$.
\end{proof}


\begin{df}\label{mc84}
Let $V_1,\dots,V_N$ be finite dimensional vector spaces. The \textbf{canonical pairing}
\begin{align*}
\bk{\cdot,\cdot}:(V_1^*\otimes\cdots\otimes V_N^*)\times (V_1\otimes\cdots\otimes V_N)\rightarrow\Fbb
\end{align*}
is the bilinear map defined in terms of the standard pairing $W^*\otimes W\rightarrow\Fbb$ (where $W=V_1\otimes\cdots\otimes V_N$) and the isomorphism in Cor. \ref{mc83}. In other words, it is the unique bilinear map satisfying
\begin{align}\label{eq443}
\bk{\varphi_1\otimes\cdots\otimes\varphi_N,v_1\otimes\cdots\otimes v_N}=\varphi_1(v_1)\cdots\varphi_N(v_N)
\end{align}
for each $1\leq i\leq N$, $v_i\in V_i$, $\varphi_i\in V_i^*$.
\end{df}

\begin{rem}
Let $(e_{i,\alpha_i})_{\alpha_i\in\mc A_i}$ be a basis of the finite dimensional vector space $V_i$, and let $(\wch e_i^{\alpha_i})_{\alpha_i\in\mc A}$ be its dual basis. From \eqref{eq443}, it is clear that
\begin{align*}
\big(\wch e_1^{\alpha_1}\otimes\cdots\otimes \wch e_N^{\alpha_N} \big)_{\alpha_1\in\mc A_1,\dots,\alpha_N\in\mc A_N}
\end{align*}
is the dual basis of
\begin{align*}
\big(e_{1,\alpha_1}\otimes\cdots\otimes e_{N,\alpha_N} \big)_{\alpha_1\in\mc A_1,\dots,\alpha_N\in\mc A_N}
\end{align*}
\end{rem}








\begin{eg}
Let $V_1,V_2$ be finite dimensional vector spaces. Let $u_i,v_i\in V_i$ and $\varphi_i,\psi_i\in V_i^*$. Calculate the pairing of $\eta=2\varphi_1\otimes \varphi_2-\psi_1\otimes\psi_2$ and $\xi=(2u_1)\otimes (3u_2)+v_1\otimes v_2$.
\end{eg}

\begin{proof}
By multilinearity, we have $\xi=6u_1\otimes u_2+v_1\otimes v_2$. So
\begin{align*}
\bk{\eta,\xi}=&12\bk{\varphi_1\otimes\varphi_2,u_1\otimes u_2}+2\bk{\varphi_1\otimes\varphi_2,v_1\otimes v_2}\\
&-6\bk{\psi_1\otimes\psi_2,u_1\otimes u_2}-\bk{\psi_1\otimes\psi_2,v_1\otimes v_2}\\
=&12\varphi_1(u_1)\varphi_2(u_2)+2\varphi_1(v_1)\varphi_2(v_2)-6\psi_1(u_1)\psi_2(u_2)-\psi_1(v_1)\psi_2(v_2)
\end{align*}
\end{proof}

%% Record #23 2024/05/20 Two lectures  56

\begin{exe}
Suppose that for each $1\leq i\leq N$ we have linear maps of vector spaces $S_i:U_i\rightarrow V_i$ and $T_i:V_i\rightarrow W_i$. Prove that
\begin{align}
(T_1\circ S_1)\otimes\cdots\otimes (T_N\circ S_N)=(T_1\otimes\cdots\otimes T_N)\circ (S_1\otimes\cdots\otimes S_N)
\end{align} 
Prove that if $U_i=V_i$ and $S_i=\idt_{V_i}$, then
\begin{align}
\idt_{V_1}\otimes\cdots\otimes\idt_{V_N}=\idt_{V_1\otimes\cdots\otimes V_N}
\end{align}
Prove that if each $V_i,W_i$ are finite-dimensional, and if we identify $V_1^*\otimes\cdots V_N^*$ with $(V_1\otimes\cdots\otimes V_N)^*$ and identify $W_1^*\otimes\cdots W_N^*$ with $(W_1\otimes\cdots\otimes W_N)^*$ in the canonical way (cf. Cor. \ref{mc83}), then
\begin{align}
T_1^\tr\otimes\cdots\otimes T_N^\tr=(T_1\otimes\cdots\otimes T_N)^\tr
\end{align}
\end{exe}

\begin{exe}
Suppose that for each $1\leq i\leq N$, the linear map $T_i:V_i\rightarrow W_i$ is injective (resp. surjective). Prove that $T_1\otimes\cdots\otimes T_N:V_1\otimes\cdots\otimes V_N\rightarrow W_1\otimes\cdots\otimes W_N$ is injective (resp. surjective).
\end{exe}




\begin{srem}\label{mc86}
Let $p,q\in\Nbb$. Let $V$ be a finite dimensional vector space. An element $T\in V^{\otimes p}\otimes (V^*)^{\otimes q}$ is called a \textbf{tensor of type }\pmb{$(p,q)$}. \index{00@Tensor of type $(p,q)$} If $p=0$ (resp. $q=0$), we call $T$ a \textbf{covariant tensor of order $q$} \index{00@Covaraint tensor} (resp. \textbf{contravariant tensor of order $p$}). \index{00@Contravariant tensor}

Let $e_1,\dots,e_n$ be a basis of $V$ with dual basis $\wch e^1,\dots,\wch e^n$. Let
\begin{align}
T_{j_1,\dots,j_q}^{i_1,\dots,i_p}=\bk{T,\wch e^{i_1}\otimes\cdots\otimes\wch e^{i_p}\otimes e_{j_1}\otimes\cdots\otimes e_{j_q}}
\end{align}
where $V$ is viewed as the dual of $V^*$ so that (by Def. \ref{mc84}) we have a canonical pairing between $V^{\otimes p}\otimes (V^*)^{\otimes q}$ and $(V^*)^{\otimes p}\otimes V^{\otimes q}$. Then
\begin{align}
T=\sum_{i_1,\dots,i_p,j_1,\dots,j_q} T_{j_1,\dots,j_q}^{i_1,\dots,i_p} ~\cdot e_{i_1}\otimes\cdots\otimes e_{i_p}\otimes \wch e^{j_1}\otimes\cdots\otimes \wch e^{j_q}
\end{align}
since both sides send $\wch e^{i_1}\otimes\cdots\otimes\wch e^{i_p}\otimes e_{j_1}\otimes\cdots\otimes e_{j_q}$ to $T_{j_1,\dots,j_q}^{i_1,\dots,i_p}$. In physics and mechanics, the data $(T_{j_1,\dots,j_q}^{i_1,\dots,i_p})_{i_\blt,j_\star}$ is often called a tensor. \hfill\qquad
\end{srem}










\subsection{Symmetric products}


Let $\Fbb\in\{\Rbb,\Cbb\}$.

\begin{df}
Let $V$ be a vector space. A bilinear form $\omega:V\times V\rightarrow\Fbb$ is called \textbf{symmetric} \index{00@Symmetric bilinear form} if $\omega(u,v)=\omega(v,u)$ for all $u,v\in V$. Suppose that $\omega$ is a symmetric bilinear form and $\Fbb=\Rbb$, we say that $\omega$ is a \textbf{positive semidefinite bilinear form} (or simply a \textbf{positive bilinear form}) \index{00@Positive (symmetric) bilinear form} if $\omega(v,v)\geq0$ for all $v\in V$. A positive bilinear form $\omega$ is called a \textbf{positive definite bilinear form} \index{00@Positive definite bilinear form} (also called a \textbf{real inner product}) \index{00@Real inner product} if $\omega(v,v)>0$ for all nonzero $v\in V$.
\end{df}



\begin{rem}
If $\bk{\cdot|\cdot}$ is a sesquilinear form on a complex vector space $V$, and if $\bk{v|v}\geq0$ for all $v\in V$, then by Prop. \ref{lb588}, we have $\bk{u|v}=\ovl{\bk{v|u}}$ for all $u,v$. However, if $V$ is a real vector space, and if $\omega$ is a bilinear form on $V$ satisfying $\omega(v,v)\geq0$ for all $v\in V$, we do not necessarily have $\omega(u,v)=\omega(v,u)$; see Exp. \ref{mc85}. Therefore, we must include the symmetry condition $\omega(u,v)=\omega(v,u)$ in the definition of real positive bilinear forms.
\end{rem}

\begin{eg}\label{mc85}
Let $V=\Rbb^2$ whose elements are viewed as $2\times 1$ matrices. Let $-2<\lambda<2$ and $A=\begin{pmatrix}
1&\lambda\\
0&1
\end{pmatrix}$
Let $\omega:V\times V\rightarrow\Rbb$ be defined by $\omega(u,v)=u^\tr Av$. Then $\omega(v,v)>0$ for all nonzero $v\in V$. However, we do not have $\omega(u,v)=\omega(v,u)$ in general.
\end{eg}



In the following, we shall only consider finite dimensional vector spaces. By Rem. \ref{mc79}, a bilinear form $\omega:V\times V\rightarrow\Rbb$ can be viewed as an element of $(V\otimes V)^*\simeq V^*\otimes V^*$. Let us describe the elements of $V^*\otimes V^*$ that are symmetric bilinear forms. 

\begin{df}
For each $\varphi,\psi\in V$, define the \textbf{symmetric product} \index{00@Symmetric product} $\varphi\cdot\psi\in V\otimes V$ to be
\begin{align}
\varphi\cdot\psi=\frac 12(\varphi\otimes\psi+\psi\otimes\varphi)
\end{align}
\end{df}

\begin{pp}\label{mc92}
Let $V$ be finite dimensional. Let $\omega\in V^*\otimes V^*$. Then $\omega$ is a symmetric bilinear form iff it is a sum of symmetric products of elements of $V^*$. 

Moreover, suppose that $\omega$ is symmetric. Let $e_1,\dots,e_n$ be a basis of $V$ with dual basis $\wch e^1,\dots,\wch e^n$. Define the \textbf{Gram matrix} \index{00@Gram matrix} $G=[\omega(e_\blt\otimes e_\blt)]=(\omega(e_i\otimes e_j))_{1\leq i,j\leq n}$ by
\begin{align}
G_{i,j}=\omega(e_i\otimes e_j)
\end{align} 
Then $G$ is a symmetric matrix, and
\begin{align}\label{eq449}
\omega=\sum_{1\leq i,j\leq n}G_{i,j}\wch e^i\wch e^j\equiv \begin{pmatrix}
\wch e^1,\cdots,\wch e^n
\end{pmatrix}
G
\begin{pmatrix}
\wch e^1\\
\vdots\\
\wch e^n
\end{pmatrix}
\end{align}
\end{pp}

\begin{proof}
If $\varphi,\psi\in V^*$, then $\varphi\psi$ sends $u\otimes v\in V\otimes V$ to $\frac 12(\varphi(u)\psi(v)+\varphi(v)\psi(u))$. So clearly $\varphi\psi$ is a symmetric bilinear form. Thus, a sum of symmetric products of linear functionals is a symmetric bilinear form.

Conversely, let $\omega\in V^*\otimes V^*$ be a symmetric bilinear form. Let us prove \eqref{eq449}. Note that $\omega=\sum_{i,j}G_{i,j}\wch e^i\otimes \wch e^j$ since both sides send $e_i\otimes e_j$ to $G_{i,j}$. (See also Rem. \ref{mc86}.) Since $G_{i,j}=G_{j,i}$, we have
\begin{align*}
&\sum_{i,j}G_{i,j}\wch e^i\otimes\wch e^j=\sum_i G_{i,i}\wch e^i\otimes \wch e^i+\sum_{i<j}G_{i,j}\wch e^i\otimes\wch e^j+\sum_{i>j}G_{j,i}\wch e^i\otimes\wch e^j\\
=&\sum_i G_{i,i}\wch e^i\otimes \wch e^i+\sum_{i<j}G_{i,j}(\wch e^i\otimes\wch e^j+\wch e^j\otimes\wch e^i)
\end{align*}
which equals $\sum_i G_{i,i}\wch e^i\wch e^i+2\sum_{i<j}G_{i,j}\wch e^i\wch e^j$. A similar calculation, but with $\otimes$ replaced by the symmetric product, shows that
\begin{align*}
\sum_{i,j}G_{i,j}\wch e^i\wch e^j=\sum_i G_{i,i}\wch e^i\wch e^i+\sum_{i<j}G_{i,j}(\wch e^i\wch e^j+\wch e^j\wch e^i)
\end{align*}
where the RHS also equals $\sum_i G_{i,i}\wch e^i\wch e^i+2\sum_{i<j}G_{i,j}\wch e^i\wch e^j$. This proves \eqref{eq449}.
\end{proof}


Note that \eqref{eq449} is not a sum of linearly independent vectors since (for example) $\wch e^1\wch e^2$ and $\wch e^2\wch e^1$ are linearly dependent. Thus, when doing explicit calculations, we often write $\omega$ as
\begin{align}\label{eq450}
\omega=\sum_iG_{i,i}\wch e^i\wch e^i+2\sum_{i<j}G_{i,j}\wch e^i\wch e^j
\end{align}
which is equivalent to \eqref{eq449}.

\begin{eg}
Suppose that $V$ is real and $\omega$ is an inner product with orthonormal basis $e_1,\dots,e_n$, then
\begin{align}
\omega=\wch e^1\wch e^1+\cdots+\wch e^n\wch e^n
\end{align}
\end{eg}

\begin{eg}
Let $e_1,e_2,e_3$ be a basis of $V\simeq\Rbb^3$. By \eqref{eq450}, the Gram matrices of $\varphi=\wch e_2\wch e_3$ and $\psi=4\wch e^1\wch e^1-6\wch e^2\wch e^3$ are respectively
\begin{gather*}
\begin{pmatrix}
0&0&0\\
0&0&\frac 12\\
0&\frac 12 &0
\end{pmatrix}\qquad
\begin{pmatrix}
4&0&0\\
0&0&-3\\
0&-3&0
\end{pmatrix}
\end{gather*}
\end{eg}

\begin{eg}\label{mc113}
Let $V_1,\dots,V_N$ be finite-dimensional real vector spaces. Let $V=V_1\oplus\cdots\oplus V_N$. For each $i$, let $\omega_i$ be a symmetric bilinear form on $V_i$. Define the \textbf{direct sum} \index{00@Direct sum of inner products}
\begin{gather}
\begin{gathered}
\omega=\omega_1\oplus\cdots\oplus\omega_N\in (V\otimes V)^*\\
\omega\big((u_1\oplus\cdots\oplus u_n)\otimes(v_1\oplus\cdots\oplus v_n) \big)=\omega_1(u_1\otimes v_1)+\cdots+\omega_n(u_n\otimes v_n)
\end{gathered}
\end{gather} 
Then $\omega$ is positive (resp. positive definite) iff each $\omega_i$ is positive (resp. positive definite).
\end{eg}


\begin{comment}

\subsection{Tensor products of inner product spaces}


In this section, all vector spaces and inner products are over $\Rbb$. A real vector space $V$ is called a \textbf{(real) inner product space} if it is equipped with an real inner product $\bk{\cdot,\cdot}_V$.

\begin{thm}
Let $V_1,\dots,V_N$ be finite-dimensional inner product spaces. Then there is a unique inner product $\bk{\cdot,\cdot}$ on $V=V_1\otimes\cdots\otimes V_N$ such that for each $u_i,v_i\in V_i$ we have
\begin{align}\label{eq475}
\bk{u_1\otimes\cdots\otimes u_N,v_1\otimes\cdots\otimes v_N}=\bk{u_1,v_1}_{V_1}\cdots\bk{u_N,v_N}_{V_N}
\end{align}
We call $(V,\bk{\cdot,\cdot})$ the \textbf{tensor product} \index{00@Tensor product of inner product spaces} of the inner product spaces $V_1,\dots,V_N$. It satisfies the property that if $(e_i(x_i))_{x_i\in X_i}$ is an orthonormal basis of $V_i$, then
\begin{align}\label{eq476}
\big(e_1(x_1)\otimes\cdots\otimes e_N(x_N)\big)_{x_1\in X_1,\dots,x_N\in X_N}
\end{align}
is an orthonormal basis of $V$.
\end{thm}


\begin{proof}
The uniqueness of $\bk{\cdot,\cdot}$ satisfying \eqref{eq475} is obvious. To prove the existence, we choose any orthonormal basis $(e_i(x_i))_{x_i\in X_i}$ of $V_i$. Define $\bk{\cdot,\cdot}$ to be the unique inner product on $V$ such that \eqref{eq476} is an orthonormal basis. Then \eqref{eq475} holds when each $u_i,v_i$ is a member of $(e_i(x_i))_{x_i\in X_i}$. Therefore, by multilinearity, \eqref{eq475} holds in general.
\end{proof}


Similar to complex inner product spaces, if $T:V\rightarrow W$ is a linear map of finite-dimensional real inner product space, we can define the \textbf{adjoint operator} \index{00@Adjoint operator} $T^*:W\rightarrow V^*$ to be the unique linear map satisfying
\begin{align}
\bk{Tv,w}=\bk{v,T^*w}
\end{align}
for all $v\in V,w\in W$.


\begin{exe}
Let $T:V\rightarrow W$ be a linear map of finite-dimensional real inner product spaces. Let $(e_1,\dots,e_m)$ and $(f_1,\dots,f_n)$ be orthonormal bases of $V$ and $W$ respectively. Let $A\in\Rbb^{n\times m}$ such that
\begin{align*}
T(e_1,\dots,e_m)=(f_1,\dots,f_n)A
\end{align*}
Prove that
\begin{align}
T^*(e_1,\dots,e_m)=(f_1,\dots,f_n)A^\tr
\end{align}
\end{exe}




\begin{pp}
Let $T_i:V_i\rightarrow W_i$ be a linear map of finite-dimensional real inner product spaces, where $1\leq i\leq N$ and $N\in\Zbb_+$. Then the adjoint of $T_1\otimes\cdots\otimes T_N:V_1\otimes\cdots\otimes V_N\rightarrow W_1\otimes\cdots\otimes W_N$ is
\begin{align}\label{eq477}
(T_1\otimes\cdots\otimes T_N)^*=T_1^*\otimes\cdots\otimes T_N^*
\end{align}
\end{pp}

\begin{proof}
Choose $v_i\in V_i,w_i\in W_i$. Then
\begin{align*}
&\bk{(T_1\otimes\cdots\otimes T_N)(v_1\otimes\cdots\otimes v_N),w_1\otimes\cdots\otimes w_N}\\
=&\bk{T_1v_1\otimes\cdots\otimes T_Nv_N,w_1\otimes\cdots\otimes w_N}=\bk{v_1\otimes\cdots\otimes  v_N,T_1^*v_1\otimes\cdots\otimes T_N^*v_N}\\
=&\bk{v_1\otimes\cdots\otimes v_N,(T_1\otimes\cdots\otimes T_N)^*(w_1\otimes\cdots\otimes w_N)}
\end{align*}
Therefore, \eqref{eq477} holds when evaluated between vectors of the form $v_1\otimes\cdots\otimes v_N,w_1\otimes\cdots\otimes w_N$. By linearity, \eqref{eq477} holds in general.
\end{proof}
\end{comment}

















\newpage



\section{Integrals of functions on Riemannian manifolds}


\subsection{Covariant tensor fields}


Let $M,N$ be smooth $\partial$-manifolds.



\begin{df}
Let $k\in\Nbb$. The \textbf{bundle of covariant $k$-tensors} of $M$ is defined to be \index{zz@$\bigotimes^kT^*M$}
\begin{align*}
\bigotimes\nolimits^kT^*M:=\bigsqcup_{p\in M}(T_p^*M)^{\otimes k}
\end{align*}
A map $A:M\rightarrow\bigotimes^k T^*M$ is called a \textbf{covariant tensor field of order $k$} \index{00@Covariant tensor field} if for each $p\in M$ we have $A_p\in (T_p^*M)^{\otimes k}$. In particular, a covariant tensor field of order $0$ is precisely an element of $\Rbb^M$.
\end{df}




\begin{eg}
Let $(U,\varphi^1,\dots,\varphi^n)$ be a chart on $M$. Then
\begin{align}\label{eq451}
A|_U=\sum_{1\leq i_1,\dots,i_k\leq n}A_{i_1,\dots,i_k}d\varphi^{i_1}\otimes\cdots\otimes d\varphi^{i_k}
\end{align}
is a tensor field where $A_{i_1,\dots,i_k}:U\rightarrow\Rbb$. For each $p\in M$, the value $A|_p$ equals $\sum A_{i_1,\dots,i_k}(p)d\varphi^{i_1}\otimes\cdots\otimes d\varphi^{i_k}\big|_p$. Moreover, by Thm. \ref{mc68}, any tensor field $A:U\rightarrow\bigotimes^kT^*M$ can be uniquely written in the form \eqref{eq451}.
\end{eg}

\begin{rem}\label{mc90}
Let $(U,\varphi^1,\dots,\varphi^n)$ and $(U,\psi^1,\dots,\psi^n)$ be charts on $M$. Let $A=$\eqref{eq451}. Then, by Cor. \ref{lb987},
\begin{align}
A|_U=\sum_{
\begin{subarray}{c}
1\leq i_1,\dots,i_k\leq n\\
1\leq j_1,\dots,j_k\leq n
\end{subarray}}
A_{i_1,\dots,i_k}\cdot \frac{\partial\varphi^{i_1}}{\partial\psi^{j_1}}\cdots\frac{\partial\varphi^{i_k}}{\partial\psi^{j_k}}\cdot d\psi^{j_1}\otimes\cdots\otimes d\psi^{j_k}
\end{align}
\end{rem}

\begin{df}\label{mc152}
Let $r\in\Nbb\cup\{\infty\}$. Let $A:M\rightarrow\bigotimes^k T^*M$ be a covariant tensor field. We say that $A$ is a \textbf{\pmb{$C^r$}/Borel tensor field} \index{00@$C^r$ tensor field} if \index{00@Borel tensor field} one of the following equivalent statements hold:
\begin{enumerate}
\item[(1)] For every chart $(U,\varphi^1,\dots,\varphi^n)$, the functions $A_{i_1,\dots,i_k}$ defined by \eqref{eq451} are $C^r$/Borel.
\item[(2)] There exists an atlas $\fk U$ of $M$ such that for any $(U,\varphi^1,\dots,\varphi^n)\in\fk U$, the functions $A_{i_1,\dots,i_k}$ defined by \eqref{eq451} are $C^r$/Borel.
\end{enumerate}
In particular, a $C^r$/Borel covariant tensor field of order $0$ is precisely a $C^r$/Borel function $M\rightarrow\Rbb$.
\end{df}


\begin{proof}[Proof of equivalence]
The equivalence follows immediately from Rem. \ref{mc90} and (for Borel tensor fields, cf. the proof of Cor. \ref{mc97}) the second countability of $M$.
\end{proof}


\begin{df}
Let $F:M\rightarrow N$ be a smooth map. Let $A:N\rightarrow \bigotimes^k T^*N$ be a covariant tensor field. Define the \textbf{pullback tensor field} \index{00@Pullback tensor field $F^*A$}
\begin{gather*}
F^*A:M\rightarrow\bigotimes\nolimits^kT^*M\\
p\mapsto F^*A|_p=(F^*|_p\otimes\cdots\otimes F^*|_p)(A|_{F(p)})
\end{gather*}
where $F^*|_p:T^*_{F(p)}N\rightarrow T^*_pM$ was defined in Def. \ref{mc91}. (So $F^*|_p\otimes\cdots\otimes F^*|_p:T^*_{F(p)}N\otimes\cdots\otimes T^*_{F(p)}N\rightarrow T^*_pM\otimes\cdots\otimes T^*_pM$.)
\end{df}

\begin{eg}
If $k=0$, a covariant tensor field $A:N\rightarrow\bigotimes^0T^*N=\Rbb$ is a function. Then $F^*A$ is the pullback of the function $A$, i.e., $F^*A=A\circ F$.
\end{eg}


The pullback tensor field $F^*A$ can be calculated in the following way:

\begin{rem}
Let $F:M\rightarrow N$ be smooth. Let $(U,\varphi^1,\dots,\varphi^m)$ and $(V,\psi^1,\dots,\psi^n)$ be charts on $M$ and $N$ respectively such that $F(U)\subset V$. Let $A:V\rightarrow \bigotimes^k T^*N$ be a covariant tensor field. Write
\begin{align}
A|_V=\sum_{1\leq j_1,\dots,j_k\leq n}A_{j_1,\dots,j_k}d\psi^{j_1}\otimes\cdots\otimes d\psi^{j_k}
\end{align}
Then by \eqref{eq404}, we have
\begin{align}\label{eq457}
F^*A|_U=\sum_{
\begin{subarray}{c}
1\leq j_1,\dots,j_k\leq n\\
1\leq i_1,\dots,i_k\leq m
\end{subarray}}
(A_{j_1,\dots,j_k}\circ F)\cdot \frac{\partial(\psi^{j_1}\circ F)}{\partial\varphi^{i_1}}\cdots\frac{\partial(\psi^{j_k}\circ F)}{\partial\varphi^{i_k}}\cdot d\varphi^{i_1}\otimes\cdots\otimes d\varphi^{i_k}
\end{align}
\end{rem}



From the formula \eqref{eq457}, one immediately concludes:
\begin{pp}\label{mc94}
Let $F:M\rightarrow N$ be a smooth map. Let $A:N\rightarrow\bigotimes^kT^*N$ be a $C^r$/Borel tensor field. Then the tensor field $F^*A$ is also $C^r$/Borel.
\end{pp}






\subsection{Riemannian manifolds}


\begin{df}\label{mc93}
Let $M$ be a smooth $\partial$-manifold. A smooth covariant tensor field $\gk:M\rightarrow\bigotimes^2T^*M$ is called a \textbf{Riemannian metric (tensor)} if for each $p\in M$, $\gk|_p\in T_p^*M\otimes T_p^*M$ is a (symmetric) positive definite bilinear form. The pair $(M,\gk)$ (or simply $M$) is called a \textbf{Riemannian manifold with boundary}, \index{00@Riemann $\partial$-manifold} also called a \textbf{Riemannian \pmb{$\partial$}-manifold}. If $\partial M=0$, we simply call $(M,\gk)$ a \textbf{Riemannian manifold}.
\end{df}

By definition, a Riemannian $\partial$-manifold is smooth. If we only assume that $M$ and $\gk$ is $C^r$, we say that $M$ is a $C^r$ Riemannian $\partial$-manifold.




\begin{rem}\label{mc100}
Let $M$ be a smooth $\partial$-manifold, and let $\gk:M\rightarrow\bigotimes^2T^*M$ be smooth and symmetric. Let $(U,\varphi^1,\dots,\varphi^n)$ be a chart on $M$. Then by Prop. \ref{mc92}, for each $1\leq i,j\leq n$ we can find $\gk_{i,j}\in C^\infty(U,\Rbb)$ such that
\begin{align}\label{eq459}
\gk|_U=\sum_{1\leq i,j\leq n}\gk_{i,j}d\varphi^id\varphi^j\xlongequal{\eqref{eq449}}
\begin{pmatrix}
d\varphi^1,\dots,d\varphi^n
\end{pmatrix}
[\gk(\partial_\varphi\otimes\partial_\varphi)]
\begin{pmatrix}
d\varphi^1\\
\vdots\\
d\varphi^n
\end{pmatrix}
\end{align} 
where $[\gk(\partial_\varphi\otimes\partial_\varphi)]:M\rightarrow\Rbb^{n\times n}$ is the function of (symmetric) Gram matrices \index{zz@$[\gk(\partial_\varphi\otimes\partial_\varphi)]$}
\begin{align}
[\gk(\partial_\varphi\otimes\partial_\varphi)]=\big(\gk(\partial_{\varphi^i}\otimes\partial_{\varphi^j})\big)_{1\leq i,j\leq n}
\end{align}
\end{rem}

\begin{eg}
Let $x=(x^1,\dots,x^n)$ be the standard coordinates of $\Rbb^n$. Then \index{En@$\fk E^n$, or $\fk E$, the Euclidean metric tensor}
\begin{align*}
\fk E^n\equiv \fk E=(dx^1)^2+\cdots+(dx^n)^2=dx^1dx^1+\cdots+dx^ndx^n
\end{align*}
is the standard Riemannian metric on $\Rbb^n$, i.e., the \textbf{Euclidean metric tensor}. \index{00@Euclidean metric tensor} Unless otherwise stated, the metric tensor on $\Rbb^n$ is chosen to be the Euclidean metric tensor.
\end{eg}

\begin{rem}
In Def. \ref{mc93}, suppose that instead of assuming that the bilinear form $\gk|_p:T_pM\otimes T_pM\rightarrow\Rbb$ is positive definite, we only assume that it is symmetric and \textbf{non-degenerate} \index{00@Non-degenerate symmetric bilinear form} (i.e., if $\xi\in T_pM$ is nonzero, then the linear functional $\eta\in T_pM\mapsto \gk(\xi\otimes\eta)$ is nonzero), then $\gk$ is called a \textbf{Pseudo-Riemannian metric (tensor)}, \index{00@Pseudo-Riemannian metric} and $(M,\gk)$ is called a \textbf{pseudo-Riemannian $\partial$-manifold}. For example, if $d\geq1$, the \textbf{Minkowski space}
\begin{align*}
\Rbb^{1,d}=(\Rbb^{1+d},-(dx^0)^2+(dx^1)^2+\cdots+(dx^n)^2)
\end{align*} 
is an important pseudo-Riemannian manifold in physics.
\end{rem}


\begin{pp}\label{mc95}
Let $F:M\rightarrow N$ be a (smooth) immersion, i.e., $dF$ is injective everywhere. Let $\gk$ be a Riemannian metric on $N$. Then $F^*\gk$ is a Riemannian metric on $M$, called the \textbf{pullback Riemannian metric}. \index{00@Pullback Riemannian metric}
\end{pp}

\begin{proof}
By Prop. \ref{mc94}, $F^*\gk$ is a smooth tensor field. For each $p\in M$ and $\xi,\eta\in T_pM$ we have $F^*\gk(\xi,\eta)=\gk(dF\xi,dF\eta)$. Since $dF:T_pM\rightarrow T_{F(p)}M$ is injective, it is clear that $F^*\gk$ is (not only symmetric and positive but also) non-degenerate. Therefore, $F^*\gk$ is positive definite.
\end{proof}


\begin{df}\label{mc96}
Let $(N,\gk)$ be a Riemannian $\partial$-manifold. Assume that either  $M=\partial N$, or $\partial N=\emptyset$  and $M$ is a smooth $\partial$-submanifold of $N$. Let $\iota:M\hookrightarrow N$ be the inclusion map. Then by Prop. \ref{mc95}, 
\begin{align*}
\gk|_M:=\iota^*\gk
\end{align*}
is a Riemannian metric on $M$, called the \textbf{restriction of $\gk$}. \index{00@Restriction of Riemannian metric}. Unless otherwise stated, the Riemannian metric on $M$ is always assume to be $\gk|_M$. When $\partial N=\emptyset$  and $M$ is a smooth $\partial$-submanifold of $N$, we call $(M,\gk|_M)$ (or simply call $M$) a \textbf{Riemannian $\partial$-submanifold} \index{00@Riemannian $\partial$-submanifold} of $N$.
\end{df}

\begin{df}
Let $(M,\gk)$ and $(N,\wtd\gk)$ be Riemannian $\partial$-manifolds. A map $F:M\rightarrow N$ is called an \textbf{isometric diffeomorphism} \index{00@Isometric diffeomorphism of Riemannian $\partial$-manifolds} if $F$ is a diffeomorphism, and if $F^*\wtd\gk=\gk$. Note that if $F$ is an isometric diffeomorphism, then so is $F^{-1}$. In that case, we say that $M$ and $N$ are \textbf{isometrically diffeomorphic}, or that $M$ and $N$ are \textbf{isomorphic Riemannian $\partial$-manifolds}.
\end{df}


\begin{rem}
Assume that $(N,\gk)$ is a Riemannian manifold, $\Omega$ is a smooth $\partial$-manifold, and $F:\Omega\rightarrow N$ is a smooth embedding. Then $M=F(\Omega)$ is a smooth $\partial$-submanifold of $N$, and $F$ restricts to a diffeomorphism $\wtd F:\Omega\rightarrow M$. By Prop. \ref{mc95}, $F^*\gk$ is a Riemannian metric on $\Omega$. By Def. \ref{mc96}, $(M,\gk|_{M})$ is a Riemannian $\partial$-submanifold of $N$. Since $F^*\gk=\wtd F^*\iota^*\gk$ where $\iota:M\rightarrow N$ is the inclusion,
\begin{align*}
\wtd F:(\Omega,F^*\gk)\xlongrightarrow{\simeq} (M,\gk|_{M})
\end{align*}
is an isometric diffeomorphism. When $\Omega$ is an $n$-dimensional smooth $\partial$-submanifold of $\Rbb^n$, $\wtd F$ is a parametrization of the submanifold $M$. Thus, the study of $(M,\gk|_{M})$ is equivalent to the study of $(\Omega,F^*\gk)$ which is often easier. 
\end{rem}

Let us calculate $F^*\gk$ when $N$ is a Euclidean space.

\begin{pp}\label{mc102}
Let $\Omega$ be an $m$-dimensional smooth $\partial$-submanifold of $\Rbb^m$. Let $\Delta\subset\Rbb^n$ be open. Let $F:\Omega\rightarrow\Delta$ be a smooth embedding with image $M:=F(\Omega)$. Let $\gk$ be a Riemannian metric on $\Delta$ with Gram matrix $G=[\gk(\partial_x\otimes\partial_x)]$, i.e.,
\begin{align*}
\gk=\begin{pmatrix}
dx^1,\dots,dx^n
\end{pmatrix}G\begin{pmatrix}
dx^1\\
\vdots\\
dx^n
\end{pmatrix}
\end{align*}
Then the Gram matrix of the metric $F^*\gk$ on $\Omega$ with respect to $\partial_{x^1},\dots,\partial_{x^m}$ is
\begin{align}
[F^*\gk(\partial_x\otimes\partial_x)]=(\Jac F)^\tr\cdot (G\circ F)\cdot\Jac F
\end{align}
More precisely, for each $p\in M$ we have
\begin{align*}
[F^*\gk(\partial_x\otimes\partial_x)]\Big|_p=(\Jac F)^\tr|_p\cdot G|_{F(p)}\cdot \Jac F|_p
\end{align*}
\end{pp}


Of particular importance is the case that $\gk$ is the Euclidean metric tensor $\fk E=(dx^1)^2+\cdots+(dx^n)^2$. Then
\begin{align}
[F^*\fk E(\partial_x\otimes\partial_x)]=(\Jac F)^\tr(\Jac F)
\end{align}


\begin{proof}
By Cor. \ref{mc98}, we have
\begin{align*}
\begin{pmatrix}
F^*dx^1\\
\vdots\\
F^*dx^n
\end{pmatrix}
=\Jac F\cdot\begin{pmatrix}
dx^1\\
\vdots\\
dx^m
\end{pmatrix}
\end{align*}
Then, since $F^*G=G\circ F$, we have
\begin{align*}
&F^*\gk=\begin{pmatrix}
F^*dx^1,\dots,F^*dx^m
\end{pmatrix}(G\circ F)\begin{pmatrix}
F^*dx^1\\
\vdots\\
F^*dx^m
\end{pmatrix}\\
=&\begin{pmatrix}
dx^1,\dots,dx^m
\end{pmatrix}\cdot(\Jac F)^\tr (G\circ F)(\Jac F)\cdot\begin{pmatrix}
dx^1\\
\vdots\\
dx^m
\end{pmatrix}
\end{align*}
\end{proof}



Let $M$ be a smooth $\partial$-manifold. If there exists a Riemannian metric $\gk$ on $M$, then we can define integrals of functions on $M$. On the other hand, if $M$ is oriented, we can define integrals of differential forms on $M$. We will see that when $M$ is both oriented and equipped with a Riemannian metric, an integral of differential form can be transformed to an integral of a function, and vise versa. Now, the following theorem tells us that the existence of Riemannian metrics is automatic. Therefore, integrals of differential forms can always be understood by means of integrals of functions. 


\begin{thm}\label{mc109}
Let $M$ be a smooth $\partial$-manifold. Then there exists a Riemannian metric on $M$.
\end{thm}


\begin{proof}
Step 1. We consider the special case that $M$ is compact. Of course, by Thm. \ref{mc99}, $M$ can be viewed as a smooth $\partial$-submanifold of $\Rbb^n$. Then the restriction of the Euclidean metric tensor to $M$ gives a Riemannian metric on $M$. However, we shall give a different proof that can be generalized to noncompact manifolds.\footnote{It is true that every smooth $\partial$-manifold can be smoothly embedded into some $\Rbb^n$. However, its proof is more involved than proving the current theorem.}

For the convenience of the following discussion, let us call a smooth positive (but not necessarily positive definite) tensor field $\gk:M\rightarrow\bigotimes^2T^*M$ a \textbf{degenerate Riemannian metric}. We claim that for each $p\in M$, there exists a degenerate Riemannian metric $\gk_p$ which is non-degenerate on a neighborhood of $p$. Indeed, choose $U\in\Nbh_M(p)$ diffeomorphic to an open subset of the Euclidean space. Then $U$ has a Riemannian metric $\omega$ (defined e.g. by the pullback of the Euclidean metric tensor). By the smooth Urysohn's lemma, cf., Thm. \ref{mc25}, there exists $f\in C_c^\infty(U,[0,1])$ such that $f(p)=1$. Then $\gk_p=f\omega$ is a compactly supported degenerate Riemannian metric on $U$, and hence can be viewed as a degenerate Riemannian metric on $M$ which is non-degenerate on $f^{-1}(0,+\infty)$.

Now, a standard compactness argument gives $p_1,\dots,p_k\in M$ such that $\sum_{i=1}^k\gk_{p_i}$ is non-degenerate everywhere, and hence is a Riemannian metric on $M$. \\[-1ex]

Step 2. We consider the general case. The same argument as above shows that if $U\subset M$ is open and $K\subset U$ is compact, then there is a degenerate Riemannian metric $\gk$ on $M$ which is compactly supported in $U$ and non-degenerate on $K$.

Since $M$ is a union of precompact open sets, and since $M$ is second countable (and hence Lindel\"of), $M$ is a countable union of precompact open sets. Thus, we can find an increasing sequence of open precompact sets $U_1\subset U_2\subset\cdots \subset M$ such that $M=\bigcup_n U_n$. By Lem. \ref{lb460}, we can enlarge $U_2$ such that $U_2$ is still precompact, and that $\ovl U_1\Subset U_2$. Repeating this procedure, we obtain an increasing sequence of precompact open subsets $U_1\Subset U_2\Subset U_3\Subset\cdots\subset M$ whose union is $M$. 

Set $U_{-1}=U_0=\emptyset$. For each $n\in\Zbb_+$, since the compact set $K_n=\ovl U_n\setminus U_{n-1}$ is contained in the open set $V_n=U_{n+1}\setminus\ovl U_{n-2}$, there exists a degenerate Riemannian metric $\gk_n$ on $M$ which is compactly supported in $V_n$ and non-degenerate on $K_n$. The sum $\gk=\sum_{k\in\Zbb_+}\gk_k$ is clearly finite when restricted to each $U_n$. Moreover, since $M=\bigcup_nK_n$, $\gk$ is clearly non-degenerate. So $\gk$ is a Riemannian metric.
\end{proof}


The above proof actually shows:

\begin{pp}\label{mc155}
Let $X$ be a second countable LCH space. Then there exists a sequence of precompact open subsets $(U_n)_{n\in\Zbb_+}$ of $X$ such that $U_1\Subset U_2\Subset U_3\Subset\cdots$ and $X=\bigcup_n U_n$.
\end{pp}





\subsection{Volume measures}\label{mc182}



In this section, we fix a Riemannian $\partial$-manifold $(M,\gk)$. The goal of this section is to define the volume measure $\vol$ on $M$. We will be mainly interested in the Borel $\sigma$-algebra $\fk B_X$; the generalization to its completion is quite straightforward. Recall the notation for the Euclidean metric tensor
\begin{align*}
\fk E\equiv \fk E^n=(dx^1)^2+\cdots+(dx^n)^2
\end{align*}


For any Borel $\Omega\subset\Rbb^n$ , we let $m_\Omega:\fk B_\Omega\rightarrow[0,+\infty]$ be the restriction of the Lebesgue measure to $\fk B_\Omega$. Recall Rem. \ref{mc100} for the meaning of the notation $[\gk(\partial_\varphi\otimes\partial_\varphi)]$.






\begin{comment}
Suppose that $\omega$ is a symmetric bilinear form on a vector space $\mc V$ with basis $e_1,\dots,e_n$. Let us write the Gram matrix as
\begin{align}
[\omega(e_\blt\otimes e_\blt)]
\end{align}
According to this notation, if $(U,\varphi)=(U,\varphi^1,\dots,\varphi^n)$ is a chart on $M$, the function of Gram matrices with respect to $\partial_\varphi=(\partial_{\varphi^1},\dots,\varphi_{\varphi^n})$ is $[\gk(\partial_\varphi\otimes\partial_\varphi)]$. In other words, in view of \eqref{eq449}, we have
\begin{align}
\gk=(d\varphi^1,\dots,d\varphi^n)
\end{align}
\end{comment}

To motivate the definition of $\vol$, we first consider the case that $\gk$ is a constant Riemannian metric on $\Rbb^n$. Then $\vol$ should be a measure proportional to the $n$-dimensional Lebesgue measure $m|_{\fk B_{\Rbb^n}}$. Write $\vol=\lambda m$. We hope that if $(\xi_1,\dots,\xi_n)$ is an orthonormal basis of $\Rbb^n$ under $\gk$ (i.e. $\gk(\xi_i\otimes\xi_j)=\delta_{i,j}$), and if $\Delta=\{t_1\xi_1+\cdots+t_n\xi_n:0\leq t_1,\dots,t_n\leq 1\}$ is the parallelopiped spanned by $\xi_1,\dots,\xi_n$, then $\vol(\Delta)=1$. Write $(\xi_1,\dots,\xi_n)=(\partial_{x^1},\dots,\partial_{x^n})A$ where $A\in\Rbb^{n\times n}$. Then $\Delta=A([0,1]^n)$, and hence $m(\Delta)=|\det A|$ by the change of variables formula. Thus $\lambda=|\det A|^{-1}$, and hence $\dvol=|\det A|^{-1}dm$


Let $\wch\xi^1,\dots,\wch\xi^n$ be the dual basis. By \eqref{eq460}, we have $(dx^1,\dots,dx^n)=(\wch\xi^1,\dots,\wch\xi^n)A^\tr$. Thus
\begin{align*}
&\begin{pmatrix}
\wch\xi^1,\dots,\wch\xi^n
\end{pmatrix}
\begin{pmatrix}
\wch\xi^1\\
\vdots\\
\wch\xi^n
\end{pmatrix}
=\gk=\begin{pmatrix}
dx^1,\dots,dx^n
\end{pmatrix}
[\gk(\partial_x\otimes\partial_x)]
\begin{pmatrix}
dx^1\\
\vdots\\
dx^n
\end{pmatrix}\\
=&\begin{pmatrix}
\wch\xi^1,\dots,\wch\xi^n
\end{pmatrix}
A^\tr[\gk(\partial_x\otimes\partial_x)]A
\begin{pmatrix}
\wch\xi^1\\
\vdots\\
\wch\xi^n
\end{pmatrix}
\end{align*} 
where the first equality is due to the orthogonality of $\xi_1,\dots,\xi_n$. It follows that $A^\tr[\gk(\partial_x\otimes\partial_x)]A=\idt$ and hence $|\det A|^2\cdot\det[\gk(\partial_x\otimes\partial_x)]=1$. Therefore
\begin{align*}
\dvol=\sqrt{\det[\gk(\partial_x\otimes\partial_x)]}dm
\end{align*}



\subsubsection{The volume measure on $n$-dimensional $\partial$-submanifolds of $\Rbb^n$}




\begin{df}\label{mc103}
Let $\Omega$ be an $n$-dimensional smooth $\partial$-submanifold of $\Rbb^n$. Let $\gk$ be a Riemannian metric on $\Omega$. Then the \textbf{volume measure} $\vol_{\Omega,\gk}=\vol_\gk:\fk B_\Omega\rightarrow[0,+\infty]$ \index{00@Volume measure} on \index{V@$\vol_{M,\gk}\equiv\vol_M\equiv\vol_\gk$, the volume measure} $(\Omega,\gk)$ is defined to be
\begin{align}\label{eq467}
\tcboxmath{\dvol_\gk=\sqrt{\det[\gk(\partial_x\otimes\partial_x)]}~dm_\Omega}
\end{align}
(Note that $\det[\gk(\partial_x\otimes\partial_x)]$ is a smooth function $\Omega\rightarrow\Rbb^{n\times n}$.) In particular, if $\gk=(dx^1)^2+\cdots+(dx^n)^2$, then $\dvol_\gk=dm_\Omega$.
\end{df}

\begin{rem}\label{mc104}
Note that by Cor. \ref{mc101}, we have $\vol_\gk(\partial\Omega)=0$. Therefore, when integrating functions, it suffices to restrict the measure to $\Int\Omega$.
\end{rem}

\begin{eg}\label{mc110}
Let $\Omega\subset\Rbb^m$ be a smooth $m$-dimensional $\partial$-submanifold. Let $F:\Omega\rightarrow\Rbb^n$ be a smooth embedding. Then by Prop. \ref{mc102}, we have
\begin{align}
\dvol_{\Omega,F^*\fk E^n}=\sqrt{\det((\Jac F)^\tr(\Jac F))}~dm_\Omega
\end{align}
\end{eg}



The key to the construction of the volume measure on any Riemannian $\partial$-manifold is the following relationship between the pullbacks of measures and the pullbacks of Riemannian metrics.

\begin{thm}\label{mc105}
Let $\Omega$ and $\Delta$ be smooth $n$-dimensional $\partial$-submanifolds of $\Rbb^n$. Let $\Phi:\Omega\rightarrow\Delta$ be a diffeomorphism. Let $\gk$ be a Riemannian metric on $\Delta$. Then on $\fk B_\Omega$ we have
\begin{align}\label{eq461}
\Phi^*\dvol_\gk=\dvol_{\Phi^*\gk}
\end{align}
where $\vol_\gk$ and $\vol_{\Phi^*\gk}$ are the volume measures on $(\Delta,\gk)$ and $(\Omega,\Phi^*\gk)$ respectively.
\end{thm}

The following proof shows that if we let $\gk$ be $\fk E$, then \eqref{eq461} becomes exactly the change of variables formula $\Phi^* dm_\Delta=|\Jbf\Phi|dm_\Omega$ since, by \eqref{eq464},
\begin{align}
\dvol_{\Omega,\Phi^*\fk E}=|\Jbf\Phi|dm_\Omega
\end{align}

\begin{proof}
By Thm. \ref{mc104}, it suffices to prove \eqref{eq461} when restricted to $\Int\Omega$. (To check that $\partial\Omega$ is null under $\Phi^*\dvol_\gk$, note that by the inverse function theorem, $\Phi$ is locally a diffeomorphism, and hence sends Lebesgue null sets to Lebesgue null sets.) Therefore, replacing $\Omega,\Delta$ by $\Int\Omega,\Int\Delta$, we assume that both $\Omega,\Delta$ are open subsets of $\Rbb^n$. Let $G=[\gk(\partial_x\otimes\partial_x)]$ which is an element of $C^\infty(\Delta,\Rbb)$. Then by Prop. \ref{mc102}, we have
\begin{align*}
[\Phi^*\gk(\partial_x\otimes\partial_x)]=(\Jac\Phi)^\tr\cdot (G\circ\Phi)\cdot \Jac\Phi
\end{align*}
whose determinant is $\det(G\circ\Phi)\cdot (\Jbf\Phi)^2$. Therefore, by Def. \ref{mc103}, we have
\begin{align}\label{eq464}
\dvol_{\Phi^*\gk}=\sqrt{\det(G\circ\Phi)}\cdot |\Jbf\Phi|dm_\Omega
\end{align}
By Def. \ref{mc103}, we also have $\dvol_\gk=\sqrt{\det G}dm_\Delta$. Therefore, by the change of variables Thm. \ref{mc39}, we have
\begin{align*}
\Phi^*\dvol_\gk=\sqrt{\det(G\circ\Phi)}\cdot\Phi^*dm_\Delta=\sqrt{\det(G\circ\Phi)}\cdot |\Jbf\Phi|dm_\Omega
\end{align*}
This finishes the proof.
\end{proof}


\subsubsection{The volume measures on Riemannian $\partial$-manifolds}

By Def. \ref{mc103}, we can define the volume measure of a Riemannian $\partial$-manifold locally. To construct the volume measure globally, we need either Pb. \ref{mc106}, or Prop. \ref{mc36} and the next property.

\begin{pp}\label{mc107}
Let $X$ be an LCH space with open cover $\fk U$. For each $U\in\fk U$, assume that a Radon measure $\mu_U:\fk B_U\rightarrow[0,+\infty]$ is chosen. Assume that for each $U,V\in\fk U$ we have $\mu_U|_{U\cap V}=\mu_V|_{U\cap V}$. Then there exists a unique Radon measure $\mu:\fk B_X\rightarrow[0,+\infty]$ such that $\mu|_U=\mu_U$ for each $U\in\fk U$.
\end{pp}

\begin{proof}
The uniqueness follows from Prop. \ref{mc36}. Let us prove the existence. For each $f\in C_c(X,\Rbb_{\geq0})$, define $\Lambda(f)\in\Rbb_{\geq0}$ as follows. Since $K=\Supp(f)$ is compact, there exist $U_1,\dots,U_n\in\fk U$ covering $K$. For each $1\leq i\leq n$, choose a Borel set $A_i\subset U_i$ such that $\bigcup_i U_i=\bigsqcup_i A_i$. (For example, let $A_1=U_1$, and let $A_{i+1}=U_{i+1}\setminus(U_1\cup\cdots\cup U_i)$.) Then $f\chi_{A_i}$ can be viewed as a Borel function on $U_i$. We let
\begin{align*}
\Lambda(f)=\sum_{i=1}^n\int_{U_i} f\chi_{A_i}d\mu_{U_i}
\end{align*}

Let us check that $\Lambda(f)$ is well-defined. Suppose that $V_1,\dots,V_l\in\fk U$ cover $K$, $B_j\subset V_j$ is Borel, and $\bigcup_j V_j=\bigsqcup_j B_j$. Then
\begin{align*}
\sum_i\int_{U_i} f\chi_{A_i}d\mu_{U_i}=\sum_{i,j}\int_{U_i} f\chi_{A_i\cap B_j}d\mu_{U_i}\xlongequal{\eqref{eq351}}\sum_{i,j}\int_{U_i\cap V_j} f\chi_{A_i\cap B_j}d(\mu_{U_i}|_{U_i\cap V_j})
\end{align*}
and similarly
\begin{align*}
\sum_j\int_{V_j}f\chi_{B_j}d\mu_{V_j}=\sum_{i,j}\int_{U_i\cap V_j} f\chi_{A_i\cap B_j}d(\mu_{V_j}|_{U_i\cap V_j})
\end{align*}
These two expressions are equal since, by assumption, we have $\mu_{U_i}|_{U_i\cap V_j}=\mu_{V_j}|_{U_i\cap V_j}$. This proves that $\Lambda(f)$ is well-defined.

We now have a map $\Lambda:C_c(X,\Rbb_{\geq0})\rightarrow\Rbb_{\geq0}$. From its definition, it is obvious that $\Lambda$ is $\Rbb_{\geq0}$-linear. Therefore, by the Riesz-Markov representation theorem, there exists a unique Radon measure $\mu$ on $X$ satisfying $\Lambda(f)=\int_Xfd\mu$ for all $f\in C_c(X,\Rbb_{\geq0})$. Moreover, from the construction of $\Lambda$, if $U\in\fk U$, then for each $f\in C_c(U,\Rbb_{\geq0})$ we have $\Lambda(f)=\int_U fd\mu_U$, and hence
\begin{align*}
\int_U fd\mu|_U\xlongequal{\eqref{eq351}} \int_X fd\mu=\Lambda(f)=\int_Ufd\mu_U
\end{align*}
Since $\mu|_U:\fk B_U\rightarrow[0,+\infty]$ is obviously Radon (cf. Exp. \ref{mc198}), by the uniqueness Prop. \ref{lb791}, we have $\mu|_U=\mu_U$.
\end{proof}







Recall that if $\varphi$ is a diffeomorphism, we write the pullback  $(\varphi^{-1})^*\omega$ of a covariant tensor field $\omega$ as the pushforward $\varphi_*\omega$, cf. Def. \ref{mc91}.

\begin{thm}\label{mc108}
Let $(M,\gk)$ be a Riemannian $\partial$-manifold. Then there is a unique Radon measure $\vol_{M,\gk}\equiv\vol_M\equiv\vol_\gk$ on $M$,  \index{00@Volume measure} called  \index{V@$\vol_{M,\gk}\equiv\vol_M\equiv\vol_\gk$, the volume measure} the \textbf{volume measure}, satisfying the following property:
\begin{itemize}
\item For any chart $(U,\varphi)$ on $M$, the following relation holds on $\fk B_{\varphi(U)}$:
\begin{align}\label{eq462}
\varphi_*\big(\dvol_\gk|_U\big)=\dvol_{\varphi_*\gk}
\end{align}
where $\vol_{\varphi_*\gk}$ is the volume measure of $(\varphi(U),\varphi_*\gk)$ defined as in Def. \ref{mc103}.
\end{itemize}
Moreover, the volume measure satisfies the following properties:
\begin{enumerate}
\item[(a)] $\vol_\gk(\partial M)=0$.
\item[(b)] If $M$ is a smooth $n$-dimensional $\partial$-submanifold of $\Rbb^n$, then $\vol_\gk$ agrees with the volume measure defined in Def. \ref{mc103}.
\end{enumerate}
\end{thm}



\begin{proof}
Step 1. The uniqueness is obvious: Choose an open cover $\fk U$ of $M$ such that any $U\in\fk U$ is diffeomorphic to an open subset of $\Hbb^n$. Then by \eqref{eq462}, for each $U\in\fk U$, $\vol_\gk|_U$ is uniquely determined. Therefore, by Prop. \ref{mc36}, $\vol_\gk$ is uniquely determined.

Assume that $\vol_\gk$ exists. Since $M$ is second countable, we can assume that the above $\fk U$ is countable. Then by \eqref{eq462} and Rem. \ref{mc104}, for each $U\in\fk U$ we have $\vol_\gk(\partial M\cap U)=0$. Thus $\vol_\gk(\partial M)=0$.

Suppose that $M$ is an $n$-dimensional $\partial$-submanifold of $\Rbb^n$. Then $(\Int M,x)$ (where $x$ is the standard coordinates of $\Rbb^n$) is a chart on $M$. Then by \eqref{eq462} and Rem. \ref{mc104}, and by $\vol_\gk(\partial M)=0$, one easily sees that the two definitions agree.\\[-1ex]

Step 2. Let us prove the existence of $\vol_\gk$. Let $\fk U$ be the maximal atlas of $M$. For each $(U,\varphi)\in\fk U$, let $\mu_U:\fk B_U\rightarrow[0,+\infty]$ be
\begin{align*}
d\mu_U=\varphi^*\dvol_{\varphi_*\gk}
\end{align*}
Then $\mu_U$ is clearly a Borel measure finite on compact sets. Therefore, by Thm. \ref{lb818}, $\mu_U$ is a Radon measure. If we can prove that for any $(V,\psi)\in\fk U$ we have $\mu_U|_{U\cap V}=\mu_V|_{U\cap V}$, then Prop. \ref{mc107} or Pb. \ref{mc106} implies that there exists a Radon measure $\vol_\gk$ on $M$ such that $\vol_\gk|_U=\mu_U$ for every $(U,\varphi)\in\fk U$. Then \eqref{eq462} is clearly satisfied. This will finish the proof.

Choose any charts $(U,\varphi)$ and $(V,\psi)$. Let $\Omega=\varphi(U\cap V)$ and $\Delta=\psi(U\cap V)$. Then $\psi\circ\varphi^{-1}:\Omega\rightarrow\Delta$ is a diffeomorphism. We have
\begin{align*}
d\mu_U|_{U\cap V}=(\varphi^*\dvol_{\varphi_*\gk})|_{U\cap V}=\varphi^*(\dvol_{\varphi_*\gk}|_\Omega)=\varphi^*\dvol_{\Omega,\varphi_*\gk}
\end{align*} 
Similarly, we have $\mu_V|_{U\cap V}=\psi^*\dvol_{\Delta,\psi_*\gk}$ where the RHS is, by Thm. \ref{mc105}, equal to
\begin{align*}
((\psi\circ\varphi^{-1})\circ\varphi)^*\dvol_{\Delta,\psi_*\gk}=\varphi^*(\psi\circ\varphi^{-1})^*\dvol_{\Delta,\psi_*\gk}=\varphi^*\dvol_{\Omega,(\psi\circ\varphi^{-1})^*\psi_*\gk}
\end{align*}
The last term above equals $\varphi^*\dvol_{\Omega,\varphi_*\gk}$ because
\begin{align*}
(\psi\circ\varphi^{-1})^*\psi_*\gk=(\varphi\circ\psi^{-1})_*\psi_*\gk=\varphi_*\gk
\end{align*}
This finishes the proof.
\end{proof}

\begin{rem}\label{mc119}
Note that $m^0$ is the Dirac measure on $\Rbb^0=\{0\}$. Therefore, if $\dim M=0$, then $\vol_M$ is the counting measure on $M$.
\end{rem}


\begin{pp}\label{mc111}
Let $(M,\gk)$ be a Riemannian $\partial$-manifold. The following are true.
\begin{enumerate}
\item[(a)] Let $U\subset M$ be open whose Riemannian metric is (the restriction of) $\gk$. Then
\begin{align*}
\vol_{M,\gk}|_U=\vol_{U,\gk}
\end{align*}
\item[(b)] Let $P$ be a smooth $\partial$-manifold, and let $\Phi:P\rightarrow M$ be a diffeomorphism. Then
\begin{align}\label{eq463}
\Phi^*\dvol_\gk=\dvol_{\Phi^*\gk}
\end{align}
holds on $\fk B_P$, where $\vol_\gk$ and $\vol_{\Phi^*\gk}$ are the volume measures of $(M,\gk)$ and $(P,\Phi^*\gk)$ respectively.
\end{enumerate}
\end{pp}



\begin{proof}
Obvious from Thm. \ref{mc108}.
\end{proof}

Note that if we set $\pk=\Phi^*\gk$, then \eqref{eq463} is equivalent to
\begin{align}
\Phi_*\dvol_\pk=\dvol_{\Phi_*\pk}
\end{align}

%% Record #24 2024/05/23 Three lectures  59

\begin{exe}\label{mc185}
Let $(M,\gk)$ be a Riemannian $\partial$-manifold. Let $(\fk M,\vol_\gk)$ be the completion of the Radon measure $(\fk B_M,\vol_\gk)$.
\begin{enumerate}
\item Let $\fk U$ be an atlas of $M$. Let $E\subset M$. Prove that $E\in\fk M$ iff $\varphi(E\cap U)$ is Lebesgue measurable for every $(U,\varphi)\in\fk U$. Prove that $E$ is $(\fk M,\vol_\gk)$-null iff $\varphi(E\cap U)$ is a Lebesgue null set for every $(U,\varphi)\in\fk U$.
\item Prove that if $U\subset M$ is open, then $(\fk M|_U,\vol_\gk|_U)$ is the completion of $(\fk B_U,\vol_{U,\gk})$.
\item  Let $P$ be a smooth $\partial$-manifold, and let $\Phi:P\rightarrow M$ be a diffeomorphism. Prove that $\Phi^*\dvol_\gk=\dvol_{\Phi^*\gk}$ holds on $\fk P$, where $(\fk P,\vol_{\Phi^*\gk})$ is the completion of $(\fk B_P,\vol_{\Phi^*\gk})$.
\item Let $\wtd\gk$ be another Riemannian metric on $M$. Prove that the completions of $(\fk B_M,\vol_\gk)$ and $(\fk B_M,\vol_{\wtd\gk})$ have the same $\sigma$-algebra.
\end{enumerate}
We say that $E\subset M$ is \textbf{Lebesgue measurable} if $E\in\fk M$.\index{00@Lebesgue measurable subsets of a $\partial$-manifold} This notion is clearly independent of the choice of Riemannian metrics, and hence makes sense for any smooth $\partial$-manifold (due to Thm. \ref{mc109}).
\end{exe}


\begin{exe}
Let $(M,\gk)$ be a Riemannian $\partial$-manifold. Let $(U,\varphi)$ be a chart on $M$. Prove that
\begin{align}
\gk(\partial_\varphi\otimes\partial_\varphi)=\big(\varphi_*\gk(\partial_x\otimes\partial_x)\big)\circ\varphi
\end{align}
Conclude that
\begin{align}
\dvol_\gk=\sqrt{\det[\gk(\partial_\varphi\otimes\partial_\varphi)]}~\varphi^*dm_{\varphi(\Omega)}
\end{align}
\end{exe}




\subsection{Examples}

In this section, unless otherwise stated, all measures are defined on the Borel $\sigma$-algebras (rather than on their completions). 


\begin{cv}
Unless otherwise stated, if $M$ is a $\partial$-submanifold of $\Rbb^n$, the Riemannian metric on $M$ is chosen to be the restriction of the Euclidean metric $\fk E^n|_M$.
\end{cv}

\begin{df}
Let $(M,\gk)$ be a Riemannian $\partial$-manifold.
\begin{align*}
\Vol(M)\equiv\Vol_\gk(M):=\vol_M(M)
\end{align*}
is called the \textbf{volume} \index{00@Volume} of $M$. \index{Vol@$\Vol(M)$} If $\dim M=2$, then $\Vol(M)$ is called the \textbf{area} of $M$. If $\dim M=1$, $\Vol(M)$ is called the \textbf{length} of $M$.
\end{df}




\subsubsection{Basic examples}


\begin{eg}\label{mc112}
Let $\Omega$ be an $m$-dimensional smooth $\partial$-submanifold of $\Rbb^m$. Let $F:\Omega\rightarrow\Rbb^n$ be a smooth embedding with image $M:=F(\Omega)$, equipped with the standard metric $\fk E|_M$. Let $f:M\rightarrow\ovl\Rbb_{\geq0}$ be a Borel function. Then
\begin{align}\label{eq465}
\int_M f\dvol_M=\int_\Omega (f\circ F)\cdot\sqrt{\det((\Jac F)^\tr\Jac F)}~dm
\end{align}
\end{eg}

\begin{proof}
We have
\begin{align*}
\int_M f\dvol_{M,\fk E|_M}\xlongequal{\eqref{eq423}}\int_\Omega (f\circ F)F^*\dvol_{M,\fk E|_M}\xlongequal{\eqref{eq463}}\int_\Omega (f\circ F)\dvol_{\Omega,F^*\fk E}
\end{align*}
where the last term equals the RHS of \eqref{eq465} by Exp. \ref{mc110}.
\end{proof}





\begin{eg}
Let $I\subset\Rbb$ be an interval (equivalently, a connected $1$-dimensional smooth $\partial$-submanifold of $\Rbb$). Let $\gamma:I\rightarrow\Rbb^n$ be a smooth embedding. Let $C=\gamma(I)$. Let $f:C\rightarrow\ovl\Rbb_{\geq0}$ be Borel. Then
\begin{align}
\int_C f\dvol_C=\int_I (f\circ\gamma(t))\cdot\Vert\gamma'(t)\Vert dt
\end{align}
In particular, the length of the curve $C$ is 
\begin{align*}
\Vol(C)=\int_I \Vert\gamma'(t)\Vert dt
\end{align*}
\end{eg}

\begin{proof}
This is a special case of Exp. \ref{mc112}.
\end{proof}


\begin{rem}\label{mc143}
Suppose that $m,n\in\Zbb_+$ and $m\leq n$. Let $A\in\Rbb^{n\times m}$, i.e., $A$ is a real $n\times m$ matrix. By the Cauchy-Binet formula (cf. Cor. \ref{mc142}), we have
\begin{align}\label{eq478}
\det(A^\tr A)=\sum_{1\leq i_1<\cdots< i_m\leq n} \det(A_{1,\dots,m}^{i_1,\dots,i_m})^2
\end{align}
where $A_{1,\dots,m}^{i_1,\dots,i_m}$ is the $m\times m$ submatrix of $A$ defined by the $i_1,\dots,i_m$-th rows and all the $m$ columns of $A$. In particular, $A$ is injective iff the RHS of \eqref{eq478} is nonzero.  It is sometimes easier to calculate $(\Jac F)^\tr\Jac F$ using the formula \eqref{eq478}. Let us see an example:
\end{rem}

\begin{eg}
Let $\Omega$ be an $n$-dimensional smooth $\partial$-submanifold of $\Rbb^n$. Let $h\in C^\infty(\Omega,\Rbb)$. Define the \textbf{graph} $\fk G(h)=\{(p,q)\in\Omega\times\Rbb:q=h(p)\}$. The map 
\begin{align*}
F=\id\vee h:\Omega\rightarrow\Rbb^n\times\Rbb\qquad p\mapsto (p,(h(p)))
\end{align*}
is a topological embedding since it restricts to a continuous bijection $\Omega\rightarrow\fk G(h)$ whose inverse is the restriction of the projection $\Rbb^n\times\Rbb\rightarrow\Rbb^n$ to $\fk G(h)$. We compute
\begin{align*}
\Jac F=\begin{pmatrix}
1&0&\cdots&0\\
0&1&\cdots&0\\
&&\vdots&\\
0&0&\cdots&1\\
\partial_1h&\partial_2h&\cdots&\partial_nh
\end{pmatrix}
\end{align*}
which is an $(n+1)\times n$-matrix valued function with constant rank $n$. So $\Jac F$ is injective everywhere on $\Omega$, and hence $F$ is an immersion. Therefore, by Thm. \ref{mc21}, $F$ is a smooth embedding. In particular, $F(\Omega)=\fk G(h)$ is a smooth $\partial$-submanifold of $\Rbb^n\times\Rbb$. Using \eqref{eq478}, we easily calculate that
\begin{align}
\det((\Jac F)^\tr\Jac F)=1+(\partial_1h)^2+\cdots+\cdots+(\partial_nh)^2
\end{align}
Therefore, by Exp. \ref{mc112}, for each Borel $f:\fk G(h)\rightarrow[0,+\infty]$ we have
\begin{align}
\int_M f\dvol_M=\int_\Omega f(x,h(x))\sqrt{\Big(1+\sum_{i=1}^n(\partial_ih(x))^2\Big)}~dm(x)
\end{align}
\end{eg}





\begin{eg}\label{mc199}
Let $M$ be a smooth $n$-dimensional $\partial$-manifold. Let $\gk$ be a Riemannian metric on $M$. Let $\lambda>0$. Then
\begin{align*}
\dvol_{\lambda\gk}=\lambda^{\frac n2}\dvol_{\gk}
\end{align*}
\end{eg}

\begin{proof}
By Prop. \ref{mc36}, it suffices to check the relation locally. Therefore, we may assume that $M$ is an open subset of $\Hbb^n$. Then
\begin{align*}
\det[\lambda\gk(\partial_x\otimes\partial_x)]=\lambda^n\det[\gk(\partial_x\otimes\partial_x)]
\end{align*}
Therefore, by Def. \ref{mc103}, we have $\dvol_{\lambda\gk}=\lambda^{\frac n2}\dvol_{\gk}$.
\end{proof}





\begin{eg}\label{mc121}
Let $M$ be a $k$-dimensional Riemannian $\partial$-submanifold of $\Rbb^n$. Let $r>0$, and let $rM=\{rp:p\in M\}$. Then
\begin{align*}
\Vol(rM)=r^k\Vol(M)
\end{align*}
\end{eg}


\begin{proof}
Let $\Phi:M\rightarrow rM$ send each $p$ to $rp$, which is a diffeomorphism. Then $d\Phi$ sends each $v\in T_pM\subset\Rbb^n$ to $rv$. Thus $\Phi^*:T^*_{rp}rM\rightarrow T^*_pM$ is the multiplication by $r$. Let $\gk=\fk E^n|_M$ and $\pk=\fk E^n|_{rM}$ be the Riemannian metrics of $M$ and $rM$. Then $\Phi^*\pk=r^2\gk$. Therefore, by Prop. \ref{mc111}, we have $\Phi^*\dvol_{rM,\pk}=\dvol_{M,r^2\gk}$ where the RHS equals $r^k\dvol_{M,\gk}$ by Exp. \ref{mc199}.
\end{proof}


\subsubsection{Product manifolds}


\begin{df}\label{mc114}
Let $(M_1,\gk_1),\dots,(M_n,\gk_n)$ be Riemannian $\partial$-manifolds such that at most one of them has nonempty boundary. For each $1\leq i\leq n$, let $\pi_j:M_1\times\cdots\times M_n\rightarrow M_i$ be the projection. Then for each $p_i\in M_i$,
\begin{gather}\label{eq466}
\begin{gathered}
d\pi_1\oplus\cdots \oplus d\pi_n: T_{(p_1,\dots,p_n)}(M_1\times\cdots\times M_n)\xlongrightarrow{\simeq} T_{p_1}M_1\oplus\cdots\oplus T_{p_n}M_n\\
\xi\mapsto d\pi_1\xi\oplus\cdots\oplus d\pi_n\xi 
\end{gathered}
\end{gather}
is a linear isomorphism since this is true when $M_1,\dots,M_n$ are open subsets of Euclidean spaces or half spaces. Identify the domain and the codomain of \eqref{eq466}. By Exp. \ref{mc113}, $\gk_1|_{p_1}\oplus\cdots\oplus\gk_n|_{p_n}$ is a real inner product on $T_{p_1}M_1\oplus\cdots\oplus T_{p_n}M_n$. One checks easily (again by using local coordinates) that $(p_1,\dots,p_n)\in M_1\times\cdots\times M_n\mapsto \gk_1|_{p_1}\oplus\cdots\oplus\gk_n|_{p_n}$ gives a Riemannian metric on $M_1\times\cdots\times M_n$, called the \textbf{direct sum} of $\gk_1,\dots,\gk_n$ \index{00@Direct sum of Riemannian metrics} and is denoted by $\gk_1\oplus\cdots\oplus\gk_n$. We call
\begin{align*}
(M_1\times\cdots\times M_n,\gk_1\oplus\cdots\oplus\gk_n)
\end{align*}
the \textbf{product Riemannian $\partial$-manifold} \index{00@Product Riemannian $\partial$-manifold} of $(M_1,\gk_1),\dots,(M_n,\gk_n)$
\end{df}

\begin{cv}
Unless otherwise stated, in the setting of Def. \ref{mc114}, if $p_1\in M_1,\dots,p_n\in M_n$, we make the following identification
\begin{align}
T_{(p_1,\dots,p_n)}(M_1\times\cdots\times M_n)= T_{p_1}M_1\oplus\cdots\oplus T_{p_n}M_n
\end{align}
via the canonical linear isomorphism \eqref{eq466}.
\end{cv}


\begin{pp}\label{mc116}
Assume the setting of Def. \ref{mc114}. Then on $\fk B_{M_1\times\cdots\times M_n}$ we have
\begin{align}\label{eq468}
\dvol_{\gk_1\oplus\cdots\oplus\gk_n}=\dvol_{\gk_1}\times\cdots\times \dvol_{\gk_n}
\end{align}
where the RHS is the restriction of the Radon product (Def. \ref{lb827}) to the Borel $\sigma$-algebra.
\end{pp}


\begin{proof}
Since the boundaries are null sets, it suffices to assume that $M_1,\dots,M_n$ all have empty boundaries. By Prop. \ref{mc36}, it suffices to check \eqref{eq468} locally. Therefore, we may assume that each $M_i$ is an open subset of $\Rbb^{k_i}$. Note that the Riemannian metric $\gk_i$ on $M_i$ is not necessarily Euclidean.

Let $\gk=\gk_1\oplus\cdots\oplus\gk_n$, which is a Riemannian metric on $M:=M_1\times\cdots\times M_n$. Let $G_i$ (resp. $G$) be the Gram matrix of $\gk_i$ (resp. $G$) with respect to the standard basis of $\Rbb^{k_1}$ (resp. $\Rbb^{k_1+\cdots+k_n}$). Then $G=\diag(G_1,\dots,G_n)$ where $G_i:M_i\rightarrow\Rbb^{k_i\times k_i}$ is also viewed as a function on $M$ by the composition with the projection $\pi_i:M\rightarrow M_i$. Hence
\begin{align*}
\det G=\det G_1\cdots\det G_n
\end{align*}
By Def. \ref{mc103}, we have $\dvol_{\gk_i}=\sqrt{\det G_i}dm_{M_i}$ and $\dvol_\gk=\sqrt{\det G}dm_M$ where $dm_{M_i}$ (resp. $dm_M$) is the Lebesgue measure on $M_i$ (resp. $M$). This proves \eqref{eq468} thanks to the following Lem. \ref{mc115}.
\end{proof}



\begin{lm}\label{mc115}
Let $X_1,\dots,X_n$ be second countable LCH spaces. Let $\mu_i$ be a Radon measure on $X_i$. Let $h_i:X_i\rightarrow[0,+\infty]$ be a Borel function such that $\int_{K_i}h_id\mu_i<+\infty$ for any compact $K_i\subset X_i$. Let $\nu_i$ be the Borel measure on $X_i$ defined by $d\nu_i=h_id\mu_i$, which is a Radon measure by Thm. \ref{lb818}. Then on $\fk B_{X_1\times\cdots\times X_n}$ we have
\begin{align}\label{eq469}
d\nu_1\times\cdots\times d\nu_n=(h_1\cdots h_n)d\mu_1\times\cdots\times d\mu_n
\end{align}
where $h_1\cdots h_n$ sends each $(p_1,\dots,p_n)\in X_1\times\cdots\times X_n$ to $h_1(p_1)\cdots h_n(p_n)$.
\end{lm}

\begin{proof}
Choose any Borel $f:X_1\times\cdots\times X_n\rightarrow[0,+\infty]$. Then by Tonelli's Thm. \ref{lb835}, the integral of $f$ with respect to the two measures in \eqref{eq469} are equal.
\end{proof}


\begin{eg}\label{mc118}
Let $(M_1,\gk_1),\dots,(M_n,\gk_n)$ be Riemannian $\partial$-manifols, at most one of which has nonempty boundary. For each $1\leq i\leq n$, assume that $M_i$ is equidimensional and let $k_i=\dim M_i$. Let $M=M_1\times\cdots\times M_n$. Let $\varrho_1,\dots,\varrho_n\in C^\infty(M,\Rbb_{>0})$. Define a Riemannian metric $\gk$ on $M$ by
\begin{gather}
\gk=(\varrho_1\gk_1)\oplus\cdots\oplus(\varrho_n\gk_n)
\end{gather}
In other words, for each $p=(p_1,\dots,p_n)\in M$, we have
\begin{align*}
\gk|_p=(\varrho_1(p)\gk_1|_{p_1})\oplus\cdots\oplus(\varrho_n(p)\gk_n|_{p_n})
\end{align*}
Then on $\fk B_M$ we have
\begin{align}\label{eq470}
\dvol_\gk=\sqrt{\varrho_1^{k_1}\cdots\varrho_n^{k_n}}~\dvol_{\gk_1}\times\cdots\times\dvol_{\gk_n}
\end{align}
\end{eg}


\begin{proof}
As in the proof of Prop. \ref{mc116}, we may assume WLOG that each $M_i$ is an open subset of $\Rbb^{k_i}$. Let $G_i=[\gk_i(\partial_x\otimes\partial_x)]$ and $G=[\gk(\partial_x\otimes\partial_x)]$. Then
\begin{align*}
\det G=\varrho_1^{k_1}\cdots\varrho_n^{k_n}\cdot\det G_1\cdots\det G_n
\end{align*}
Then by Def. \ref{mc103}, we have $\dvol_{\gk_i}=\sqrt{\det G_i}~dm_{M_i}$ and
\begin{align*}
\dvol_\gk=\sqrt{\varrho_1^{k_1}\cdots\varrho_n^{k_n}\cdot\det G_1\cdots\det G_n}~dm_M
\end{align*}
By Lem. \ref{mc115}, we have
\begin{align*}
&\dvol_{\gk_1}\times\cdots\times\dvol_{\gk_n}=\sqrt{\det G_1\cdots\det G_n}~dm_{M_1}\times\cdots\times dm_{M_n}\\
=&\sqrt{\det G_1\cdots\det G_n}~dm_M
\end{align*}
on $\fk B_M$. This proves \eqref{eq470}.
\end{proof}


\subsubsection{Integrals with rotational symmetry}



\begin{eg}\label{mc117}
Let $M=\Rbb_{>0}\times\Sbb^{n-1}$ and
\begin{gather*}
\Phi:\Rbb_{>0}\times \Sbb^{n-1}\rightarrow \Rbb^n\setminus\{0\}\qquad r\times p\mapsto r\cdot p
\end{gather*}
which is clearly a smooth bijection. Then for each $(r,p)\in M$, we have
\begin{gather}\label{eq118}
\begin{gathered}
d\Phi|_{(r,p)}:\Rbb\oplus T_p\Sbb^{n-1}\rightarrow \Rbb^n\\
d\Phi|_{(r,p)}\cdot (1\oplus 0)=p\qquad  d\Phi|_{(r,p)}\cdot(0\oplus \xi)=r\xi
\end{gathered}
\end{gather}
where $T_p\Sbb^{n-1}$ is viewed as a linear subspace of $\Rbb^n$. So $d\Phi$ is everywhere invertible. Thus, by Cor. \ref{lb981}, $\Phi$ is a diffeomorphism.
\end{eg}

\begin{eg}
We continue the discussion in Exp. \ref{mc117}. Let $\gk_M$ be $\Phi^*\fk E^n$, the pullback of the Euclidean metric under $\Phi$. Then $\gk_M$ is a Riemannian metric on $M=\Rbb_{>0}\times\Sbb^{n-1}$. Let $\gk_{\Sbb^{n-1}}$ be the restriction of the Euclidean metric tensor $\fk E^n$ to $\Sbb^{n-1}$ (i.e., the standard Riemannian metric on $\Sbb^{n-1}$). From \eqref{eq118}, one easily computes that
\begin{align}
\gk_M|_{(r,p)}=\fk E^1\oplus r^2\gk_{\Sbb^{n-1}}|_p
\end{align}
Therefore, by Exp. \ref{mc118}, on $\fk B_M$ we have
\begin{align}\label{eq471}
\dvol_{\gk_M}=r^{n-1}\cdot dm^1\times\dvol_{\gk_{\Sbb^{n-1}}}
\end{align}
where $dm^1$ is the Lebesgue measure on $\Rbb$ and $r$ is the standard coordinate on $\Rbb$.
\end{eg}


\begin{eg}\label{mc120}
Let $n\in\Zbb_+$. Let $g:\Rbb_{>0}\rightarrow[0,+\infty]$ be Borel. Let $f:\Rbb^n\setminus\{0\}\rightarrow[0,+\infty]$ be defined $f(p)=g(\Vert p\Vert)$. Let $f(0)$ be an arbitrary element of $[0,+\infty]$ so that $f$ is a Borel function on $\Rbb^n$. Then
\begin{align}\label{eq472}
\int_{\Rbb^n}fdm^n=\Vol(\Sbb^{n-1})\int_{\Rbb_{>0}} r^{n-1}g(r)dm(r)
\end{align}
\end{eg}

Note that $\Sbb^0=\{1,-1\}$. So $\Vol(\Sbb^0)=2$ by Rem. \ref{mc119}.


\begin{proof}
Let $M$ and $\Phi$ be as in Exp. \ref{mc117}. By Prop. \ref{mc111}, $\Phi^*dm^n$ equals $\dvol_{\gk_M}$ where $\gk_M=\Phi^*\fk E^n$. Viewing $g$ also as a function on $\Rbb_{>0}\times\Sbb^{n-1}$ sending $(r,p)$ to $g(r)$, we have
\begin{align*}
&\int_{\Rbb^n}fdm^n=\int_{\Rbb^n\setminus\{0\}}fdm^n\xlongequal{\eqref{eq423}}\int_{\Rbb_{>0}\times\Sbb^{n-1}}(f\circ\Phi)\cdot\Phi^*dm^n\\
=&\int_{\Rbb_{>0}\times\Sbb^{n-1}}g\dvol_{\gk_M}\xlongequal{\eqref{eq471}}\int_{\Rbb_{>0}\times\Sbb^{n-1}}r^{n-1}g\cdot dm^1\times\dvol_{\Sbb^{n-1}}
\end{align*}
The last term equals the RHS of \eqref{eq472} by Tonelli's Thm. \ref{lb835}.
\end{proof}


\subsubsection{The volumes of balls and spheres}

We let
\begin{align*}
\mbb B^n=B_{\Rbb^n}(0,1)=\{p\in\Rbb^n:\Vert p\Vert<1\}
\end{align*}

\begin{eg}
Let $n\in\Zbb_+$. We have
\begin{align}
\Vol(\mbb B^n)=\frac 1n\Vol(\Sbb^{n-1})
\end{align}
\end{eg}


\begin{proof}
In Exp. \ref{mc120}, set $g=\chi_{(0,1)}$. Then \eqref{eq472} says that $\Vol(\mbb B^n)$ equals $\Vol(\Sbb^{n-1})\int_0^1 r^{n-1}dr$.
\end{proof}


\begin{eg}
We have
\begin{gather}
\Vol(\mbb B^n)=\left\{
\begin{array}{ll}
1&\text{ if }n=0\\
2&\text{ if }n=1\\[0.5ex]
\dps\frac{2\pi}{n}\Vol(\mbb B^{n-2})&\text{ if }n\geq2
\end{array}
\right.
\end{gather}
\end{eg}

\begin{proof}
The cases $n=0$ and $n=1$ are obvious. Assume $n\geq2$. Let $k=n-2$. Then $\mbb B^n$ is the set of all $(p,q)\in\mbb B^2\times\Rbb^k$ such that $\Vert p\Vert^2+\Vert q\Vert^2<1$. Thus $\mbb B^n=\bigcup_{p\in\mbb B^2}(\{p\}\times\sqrt{1-\Vert p\Vert^2}\mbb B^k)$. Therefore, since $\Vol(r\mbb B^k)=r^k\Vol(\mbb B^k)$ (cf. Exp. \ref{mc121}), we have
\begin{align*}
\Vol(\mbb B^n)=\int_{\mbb B^2}\Vol(\sqrt{1-\Vert p\Vert^2}\mbb B^k)dm^2(p)=\Vol(\mbb B^k)\cdot \int_{\mbb B^2}(1-x^2-y^2)^{\frac k2}dm^2(x,y)
\end{align*}
By using the polar coordinates $x=r\cos\theta,y=r\sin\theta$ and the change of variables formula, we see that the above expression equals $\Vol(\mbb B^k)$ times
\begin{align*}
\int_{0}^{2\pi}\int_0^1 (1-r^2)^{\frac k2}\cdot rdrd\theta=2\pi\int_0^1(1-r^2)^{\frac {n-2}2}\cdot rdr=-\frac{2\pi}n(1-r^2)^{\frac n2}\Big|_{r=0}^1=\frac{2\pi}{n}
\end{align*}
\end{proof}





\newpage


\section{Exterior powers of vector spaces}

In this chapter, we study the exterior powers $V,V^{\wedge 2},V^{\wedge 3},\dots$ of a vector space $V$. Our main interest is in the case that $V$ is real and finite-dimensional, e.g., $V$ is a tangent space or a cotangent space of a smooth $\partial$-manifold. 

The elements in $V^{\wedge N}$ are called \textbf{alternating tensors}; that they are called tensors is due to the fact that $V^{\wedge N}$ can be viewed as a linear subspace of $V^{\otimes N}$, cf. the proof of Thm. \ref{mc136}. However, we will not view $V^{\wedge N}$ as a subspace of $V^{\otimes N}$ since it is often misleading, especially when one also considers the dual space $V^*$ and its exterior power $(V^*)^{\wedge N}$. Instead, we will define $V^{\wedge N}$ in terms of a universal property similar to the definition of tensor products. 


Exterior powers are generalizations of determinants. In lower dimensions, exterior powers have a physical meaning. Let $V=\Rbb^3$ whose vectors are viewed as column vectors. Let $\mbf X=(X_1,X_2,X_3)^\tr\in\Rbb^3$ (where $X_i\in\Rbb$) be a constant electric field or a magnetic field. Then $\mbf X$ defines a bilinear map $\omega_{\mbf X}:V\times V\rightarrow\Rbb$ satisfying
\begin{align*}
\omega_{\mbf X}(\xi,\eta)=\det(\mbf X,\xi,\eta)
\end{align*}
which describes the electric flux or the magnetic flux of $X$ through the oriented parallelogram spanned by $\xi,\eta$. Then $\omega_X$ is \textbf{alternating}, i.e., $\omega_{\mbf X}(\xi,\eta)=-\omega_{\mbf X}(\eta,\xi)$. This means that we view the parallelograms spanned by $\xi,\eta$ and by $\eta,\xi$ as having opposite orientations, and that changing the orientation will change the sign of the flux. In the language of exterior powers, $\xi\wedge \eta$ is an element of $V\wedge V$, $\omega_{\mbf X}$ is an element of $V^*\wedge V^*$ where $V^*\wedge V^*$ can be viewed naturally as the dual space of $V\wedge V$, and $\bk{\omega_{\mbf X},\xi\wedge\eta}$ equals $\det(\mbf X,\xi,\eta)$.


Many methods in the theory of determinants can be generalized to exterior powers. For example, we have two ways of proving the existence of a determinant function $\det_n:\Fbb^{n\times n}\rightarrow \Fbb$. The first method is to prove it by induction on $n$ using cofactor expansions, assuming that $\det_{n-1}$ exists. The second method is to define $\det A$ for a matrix $A=(A_j^i)_{1\leq i,j\leq n}$ by $\det A=\sum_{\sigma\in\fk S_n}\sgn(\sigma)A^1_{\sigma(1)}\cdots A^n_{\sigma(n)}$. We shall see in the proofs of Thm. \ref{mc126} and \ref{mc136} that these two methods can be generalized to give two different proofs of the existence of exterior powers.

Therefore, in this chapter, we do not assume that any property about determinants has been proved. Instead, we shall develop the general theory of exterior powers, and show that many of the properties about determinants can be seen as special cases of some general properties about exterior powers. In particular, we do not assume the existence of the signature $\sgn(\sigma)$ of a permutation $\sigma$. Instead, we will define $\sgn(\sigma)$ in terms of determinants.


Throughout this chapter, we consider only fields $\Fbb$ such that $\mathrm{char}(\Fbb)\neq 2$, i.e., $1\neq -1$ in $\Fbb$.








\subsection{Exterior powers of vector spaces}


Let $\Fbb$ be a field satisfying $\mathrm{char}(\Fbb)\neq 2$. We fix an $\Fbb$-vector space $V$. We write
\begin{align*}
V^{\times N}=\underbrace{V\times\cdots\times V}_{N\text{ times}}
\end{align*}


\begin{df}
For any set $A$, a bijective map $A\rightarrow A$ is called a \textbf{permutation}.\index{00@Permutation} For each $N\in\Zbb_+$, the \textbf{symmetric group} \index{00@Symmetric group} of degree $N$ is \index{SN@$\fk S_N$, the symmetric group of degree $N$}
\begin{align}
\fk S_N=\{\text{permutations of }\{1,\dots,N\}\}
\end{align}
We say that $\sigma\in\fk S_N$ is a \textbf{transposition} \index{00@Transposition} if there exist $1\leq i<j\leq N$ such that $\sigma$ sends $i$ to $j$, sends $j$ to $i$, and fixes the other elements; we write such $\sigma$ as \index{ij@$(i~j)$, the transposition of $i$ and $j$}
\begin{align}
\sigma=(i~j)
\end{align}
In the special case that $j=i+1$, we call $(i~j)$ an \textbf{adjacent transposition}. \index{00@Adjacent transposition} The group structure is defined by
\begin{align*}
\sigma_1\cdot\sigma_2=\sigma_1\circ\sigma_2
\end{align*}
Note that the order of composition is from right to left.
\end{df}


\subsubsection{Definitions and basic properties}


\begin{df}
For each $N\in\Zbb_+$, let $T:V^{\times N}\rightarrow W$ be a linear product, i.e., an $N$-linear map. We say that $T$ is \textbf{alternating} \index{00@Alternating product} (also called \textbf{skew-symmetric}) \index{00@Skew-symmetric product} if for any transposition $\sigma\in\fk S_N$ and any $v_1,\dots,v_N\in V$, we have
\begin{align}\label{eq479}
T(v_{\sigma(1)},\dots,v_{\sigma(N)})=-T(v_1,\dots,v_N)
\end{align}
By definition, if $N=1$, any linear map is automatically alternating. We say that $T$ is a \textbf{surjective alternating product} if the range of $T$ spans the codomain $W$.
\end{df}

\begin{rem}\label{mc130}
Suppose that $T:V^{\times N}\rightarrow W$ is an alternating $N$-linear map. Suppose that two of $v_1,\dots,v_N\in N$ are equal, say $v_i=v_j$ where $1\leq i<j\leq N$. Then exchanging the $i$-th and the $j$-th component of $T(v_1,\dots,v_N)$ does not change its expression. So we must have $T(v_1,\dots,v_N)=0$.
\end{rem}


\begin{exe}
Show that any transposition is a composition of odd numbers of adjacent transposition. Conclude that if \eqref{eq479} holds for any adjacent transposition $\sigma$, then it holds for any transposition.
\end{exe}

\begin{df}\label{mc125}
Let $N\in\Zbb_+$. An alternating linear product \index{zz@$\bigwedge^NV\equiv V^{\wedge N}$}
\begin{gather}
\wedge:V^{\times N}\rightarrow V^{\wedge N}\qquad (v_1,\dots,v_N)\mapsto v_1\wedge\cdots\wedge v_N
\end{gather}
is called a \textbf{degree-$N$ exterior power} (also called \textbf{exterior product}) \index{00@Exterior power=Exterior product} of $V$ if the following conditions hold:
\begin{enumerate}
\item[(a)] $\wedge$ is a surjective product, i.e., it has dense range.
\item[(b)] For any alternating product $T:V^{\times N}\rightarrow W$ there exists a homomorphism of alternating products $\Phi:\wedge\rightarrow T$, i.e., a linear map $\Phi:V^{\wedge N}\rightarrow W$ satisfying for all $v_1,\dots,v_N\in V$ that
\begin{align}
\Phi(v_1\wedge\cdots\wedge v_N)=T(v_1,\dots,v_N)
\end{align}
\end{enumerate}
We write
\begin{align*}
\bigwedge\nolimits^NV\equiv V^{\wedge N}
\end{align*}
Due to the surjectivity, the homomorphism $\Phi:\wedge\rightarrow T$ must be unique if it exists. Moreover, if $\wedge$ exists, then similar to Rem. \ref{mc79}, there is a natural linear isomorphism
\begin{align}\label{eq487}
\Lin(V^{\wedge N},W)\qquad\xlongrightarrow{\simeq}\qquad  \{\text{Alternating products }V^{\times N}\rightarrow W\}
\end{align}
such that $\Phi$ corresponds to $T$. Also, if $V\neq 0$, we set
\begin{align}\label{eq494}
\bigwedge\nolimits^0V\equiv V^{\wedge 0}\equiv \Fbb
\end{align}
We also set $\bigwedge^N0=0$.
\end{df}

\begin{df}
Let $V^{\wedge N}$ be a degree-$N$ tensor product of $V$. Then $\xi\in V^{\wedge N}$ is called a \textbf{degree-$N$ alternating tensor}  of $V$. \index{deg@$\deg\xi$, the degree of an alternating tensor $\xi$} We write
\begin{align*}
\deg\xi=N
\end{align*} 
\end{df}


\begin{cv}
We adopt the following notation:
\begin{align}
v_1\wedge\cdots\wedge\wht{v_i}\wedge\cdots\wedge w_N=v_1\wedge\cdots\wedge v_{i-1}\wedge v_{i+1}\wedge\cdots\wedge v_N
\end{align}
\end{cv}


\begin{rem}
Similar to Thm. \ref{mc67}, two degree-$N$ exterior powers of $V$ are isomorphic. More precisely, if $\bigwedge^NV$ and $\bigsqcap^N V$ are two degree-$N$ exterior powers of $V$, then there is a (necessarily unique) linear isomorphism
\begin{gather*}
\Phi:\bigwedge\nolimits^NV\xlongrightarrow{\simeq} \bigsqcap\nolimits^NV\qquad\\
\Phi(v_1\wedge\cdots\wedge v_N)=v_1\sqcap\cdots\sqcap v_N
\end{gather*}
\end{rem}

\begin{cv}
The identity map $V\rightarrow V$ is clearly an exterior power. Unless otherwise stated, we assume that $\bigwedge^1V$ is equal to $V$.
\end{cv}

\begin{pp}\label{mc123}
Assume that $\dim V<N$. Then every alternating $N$-linear map $T:V^{\times N}\rightarrow W$ is zero. Consequently, $V^{\wedge N}=0$. 
\end{pp}


\begin{proof}
Let $e_1,\dots,e_n$ be a basis of $V$ where $n<N$. Then for each $v_1,\dots,v_N\in V$, $T(v_1,\dots,v_N)$ is a linear combination of expressions of the form $T(e_{i_1},\dots,e_{i_N})$. There must exist $1\leq a<b\leq N$ such that $e_{i_a}=e_{i_b}$. Thus $T(e_{i_1},\dots,e_{i_N})=0$ by Rem. \ref{mc130}.
\end{proof}



\subsubsection{Existence of exterior powers}



\begin{thm}\label{mc126}
Let $V$ be finite-dimensional. Then for each $N\in\Zbb_+$, there exists a finite-dimensional degree-$N$ exterior power $\bigwedge^NV$. 
\end{thm}

\begin{proof}
Let us prove it by induction on $\dim V$. When $\dim V=0$, this is obvious. When $\dim V=1$, this is due to Prop. \ref{mc123}. We now let $n\in\Zbb_+$ and assume that if $\dim V=n$ then $V^{\wedge N}$ exists and is finite-dimensional for all $N$. Now suppose $\dim V=n+1$. We may assume WLOG that $V=\Fbb\oplus U$ where $\dim U=n$. By assumption, the exterior powers of $U$ exist. If $N\leq 1$, then $V^{\wedge N}$ clearly exists. Assume $N\geq 2$. Define
\begin{subequations}\label{eq482}
\begin{gather}
\Gamma:V^{\times N}\rightarrow U^{\wedge (N-1)}\oplus U^{\wedge N}
\end{gather}
such that for any $a_i\in\Fbb$ and $u_i\in U$,
\begin{align}\label{eq482b}
\begin{aligned}
&\Gamma(a_1\oplus u_1,\dots,a_N\oplus u_N)\\
=&\Big(\sum_{i=1}^N (-1)^{i+1}a_i\cdot u_1\wedge\cdots\wedge\wht{u_i}\wedge\cdots\wedge u_N\Big)\oplus (u_1\wedge\cdots\wedge u_N)
\end{aligned}
\end{align}
\end{subequations}
It is easy to check that $\Gamma$ is alternating. Let $V^{\wedge N}$ be the span of the range of $\Gamma$ so that $\Gamma$ restricts to a surjective linear product $\Gamma:V^{\times N}\rightarrow V^{\wedge N}$. Clearly $V^{\wedge N}$ is finite-dimensional. Let us prove that $\Gamma$ is an exterior power.

Let $T:V^{\times N}\rightarrow W$ be an alternating $N$-linear map. One easily calculates that
\begin{align*}
&T(a_1\oplus u_1,\dots,a_n\oplus u_n)\\
=&\sum_{i=1}^N T(u_1,\dots,u_{i-1},a_i,u_{i+1},\dots,u_N)+T(u_1,\dots,u_N)\\
=&\sum_{i=1}^N(-1)^{i+1}a_i T(1,u_1,\dots,\wht{u_i},\dots,u_N)+T(u_1,\dots,u_N)
\end{align*}
Motivated by this formula, we consider the $(N-1)$-linear map
\begin{align*}
U^{\times(N-1)}\rightarrow W\qquad (u_1,\dots,u_{N-1})\mapsto T(1,u_1,\dots,u_{N-1})
\end{align*}
which gives rise to a linear map
\begin{align*}
\Phi_1:U^{\wedge(N-1)}\rightarrow W\qquad  u_1\wedge\cdots \wedge u_{N-1}\mapsto T(1,u_1,\dots,u_{N-1})
\end{align*}
Similarly, we have a linear map
\begin{align*}
\Phi_2:U^{\wedge N}\rightarrow W\qquad u_1\wedge\cdots\wedge u_N\mapsto T(u_1,\dots,u_N)
\end{align*}
Let $\Phi:U^{\wedge(N-1)}\oplus U^{\wedge N}\rightarrow W$ send $\xi\oplus\eta$ to $\Phi_1(\xi)+\Phi_2(\eta)$. Then by the above calculation of $T$, one easily sees that $\Phi\circ\Gamma=T$.
\end{proof}


\begin{rem}
The above proof should be compared with the (well-known) proof of the existence of the determinant function $\det_N:\Fbb^{N\times N}\rightarrow \Fbb$ by induction on $N$: Assuming that $\det_{N-1}$ exists, then $\det_N$ is defined in terms of $\det_{N-1}$ and the cofactor expansion along some row. Indeed, the expression
\begin{align*}
\sum_{i=1}^N (-1)^{i+1}a_i\cdot u_1\wedge\cdots\wedge\wht{u_i}\wedge\cdots\wedge u_N
\end{align*}
is similar to the cofactor expansion of an $N\times N$ matrix along the first row. 
\end{rem}






\subsubsection{Bases and dimensions of exterior powers}


The proof of Thm. \ref{mc126} implies:

\begin{thm}\label{mc131}
Assume that $V$ has basis $e_1,\dots,e_n$ where $n\geq1$. Then for each $N\in\Nbb$,
\begin{align}\label{eq485}
\Big(e_{i_1}\wedge\cdots \wedge e_{i_N}\Big)_{1\leq i_1<\cdots<i_N\leq n}
\end{align}
is a basis of $V^{\wedge N}$. In particular,
\begin{align}
\dim V^{\wedge N}={n\choose N}
\end{align}
\end{thm}

Note that $\emptyset$ is a basis of $\{0\}$. Thus, in the case that \eqref{eq485} is empty (i.e. $N>n$), we have $\dim V^{\wedge N}=0$. This is compatible with Prop. \ref{mc123}. When $N=0$ and $n>0$, we have $\dim V^{\wedge N}=1$, which is compatible with the convention \eqref{eq494}.

\begin{proof}
By Rem. \ref{mc130}, it is clear that \eqref{eq485} spans $V^{\wedge N}$. Let us prove by induction on $\dim V$ that \eqref{eq485} is linearly independent. The case $\dim V=1$ is obvious. Suppose the case $\dim V=n$ has been proved for all $N$. Now assume $\dim V=n+1$. Then, as in the proof of Thm. \ref{mc126}, we can assume WLOG that $V=\Fbb\oplus U$. Choose any $N\in\Nbb$. Let $\xi=1\in\Fbb$. Let $(e_1,\dots,e_n)$ be a basis of $U$. Let $\Gamma$ be defined by \eqref{eq482}. The proof of Thm. \ref{mc126} shows that after restricting the codomain of $\Gamma$ to its range, $\Gamma$ is the degree-$N$ exterior power of $V$. Therefore, we can view $V^{\wedge N}$ as a linear subspace of $U^{\wedge(N-1)}\oplus U^{\wedge N}$. Consider the following two collections of elements of $V^{\wedge N}$.
\begin{gather*}
A=\big(\xi\wedge e_{i_1}\wedge\cdots\wedge e_{i_{N-1}}\big)_{1\leq i_1<\cdots<i_{N-1}\leq n}\\
B=\big(e_{i_1}\wedge\cdots\wedge e_{i_N}\big)_{1\leq i_1<\cdots<i_N\leq n}
\end{gather*}
Then the elements of $A$ resp. $B$ can be viewed as in $U^{\wedge(N-1)}$ resp. in $U^{\wedge N}$. More precisely, by \eqref{eq482b} (whose LHS can be written as $(a_1\xi\oplus u_1)\wedge\cdots\wedge(a_N\xi\oplus u_N)$),
\begin{gather*}\label{eq486}
\begin{gathered}\tag{$\star$}
\xi\wedge e_{i_1}\wedge\cdots\wedge e_{i_{N-1}}=e_{i_1}\wedge\cdots\wedge e_{i_{N-1}}\qquad \in U^{\wedge(N-1)}\\
e_{i_1}\wedge\cdots\wedge e_{i_N}\qquad \in U^{\wedge N}
\end{gathered}
\end{gather*}
Thus $\Span(A)\cap\Span(B)=0$. Moreover, by \eqref{eq486}, and by case $n-1$, we know that the elements in $A$ (resp. in $B$) are linearly independent. Thus $A\sqcup B$ form a basis of $V^{\wedge N}$. This proves the case $n+1$.
\end{proof}


Of particular interest is the case that $N=\dim V$:

\begin{co}\label{mc133}
Let $V\neq 0$ be finite dimensional. Let $n=\dim V$. Then $\dim V^{\wedge n}=1$. Moreover, for any basis $e_1,\dots,e_n$ of $V$, we have $V=\Span\{e_1\wedge\cdots\wedge e_n\}$.
\end{co}
\begin{proof}
This is immediate from Thm. \ref{mc131}.
\end{proof}

\begin{df}
Let $n=\dim V$ and assume that $0<n<+\infty$. For each $\xi,\eta\in V^{\wedge n}$ such that $\eta\neq0$, we let
\begin{align}
\frac{~\xi~}{~\eta~}=\text{``the unique element $\lambda\in\Fbb$ such that $\lambda\eta=\xi$"}
\end{align}
It is clear that for each $\xi,\eta,\mu\in\dim V^{\wedge n}$ satisfying $\eta\neq0,\mu\neq0$ we have
\begin{align}
\frac{~\xi~}{~\eta~}\cdot\frac{~\eta~}{~\mu~}=\frac{~\xi~}{~\mu~}\qquad
\frac{~\eta~}{~\eta~}=1
\end{align}
\end{df}

\begin{df}\label{mc153}
Let $V$ be a real finite dimensional space with $n=\dim V>0$. Suppose that $V$ is real. For $\xi,\eta\in V^{\wedge n}\setminus\{0\}$, we say that $\xi$ and $\eta$ have the \textbf{same orientation}  if $\xi/\eta>0$; otherwise, we say that $\xi$ and $\eta$ have \textbf{opposite orientations}. The equivalence class $\mc O$ of vectors in $V^{\wedge n}\setminus\{0\}$ having the same orientation is called an \textbf{orientation}   \index{00@Orientation of a real vector space} of $V$. It is clear that $V$ has exactly two orientations. The pair $(V,\mc O)$ is called an \textbf{oriented vector space}. \index{00@Oriented vector space}

If $(e_1,\dots,e_n)$ is an (ordered) basis of $V$, the \textbf{orientation} of $(e_1,\dots,e_n)$ is defined to be the orientation of $e_1\wedge\cdots\wedge e_n$. We say that $(e_1,\dots,e_n)$ is a \textbf{(positive) basis} \index{00@Positive basis of an oriented vector space} of $(V,\mc O)$ if $e_1\wedge\cdots\wedge e_n$ belongs to $\mc O$. \hfill\qedsymbol
\end{df}




\begin{exe}
Let $V$ be an $n$-dimensional vector space where $n<+\infty$. Let $e_1,\dots,e_n$ be a basis of $V$. Let $\wedge:V^{\times N}\rightarrow V^{\wedge N}$ be an alternating $N$-linear map. Prove that the following are equivalent:
\begin{enumerate}
\item[(1)] $\wedge:V^{\times N}\rightarrow V^{\wedge N}$ is an exterior power of $V$.
\item[(2)] $(e_{i_1}\wedge\cdots\wedge e_{i_N})_{1\leq i_1<\cdots<i_N\leq n}$ is a basis of $V^{\wedge N}$.
\item[(3)] $(e_{i_1}\wedge\cdots\wedge e_{i_N})_{1\leq i_1<\cdots<i_N\leq n}$ spans $V^{\wedge N}$, and $\dim V^{\wedge N}={n\choose N}$.
\end{enumerate}
Compare this exercise with Thm. \ref{mc68}.
\end{exe}









\subsection{Exterior powers of linear maps}


In this section, all vector spaces are over a given field $\Fbb$ satisfying $\mathrm{char}(\Fbb)\neq 2$. Whenever we write $V^{\wedge N}$, we assume that $V^{\wedge N}$ exists (e.g. when $\dim V<+\infty$, cf. Thm. \ref{mc126}). As we will see in Thm. \ref{mc136}, this assumption is redundant.

Similar to the fact that a tensor product of linear maps can be viewed as a linear map between tensor products of vector spaces (Thm. \ref{mc82}), we have:
\begin{thm}
Let $T:V\rightarrow W$ be a linear map of vector spaces. Then there is a unique linear map $\bigwedge^N T\equiv T^{\wedge N}$ \index{zz@$\bigwedge^N T\equiv T^{\wedge N}$, the wedge product of linear maps} satisfying
\begin{gather}
T^{\wedge N}:V^{\wedge N}\rightarrow W^{\wedge N}\qquad v_1\wedge\cdots\wedge v_N\mapsto Tv_1\wedge\cdots\wedge Tv_N
\end{gather}
\end{thm}

\begin{proof}
The uniqueness is obvious. The proof of the existence is similar to that of Thm. \ref{mc82}: The map $S:V^{\times N}\rightarrow W^{\wedge N}$ sending $v_1\times\cdots\times v_N\mapsto Tv_1\wedge\cdots\wedge Tv_N$ is clearly $N$-linear and alternating. Therefore, by Def. \ref{mc125}, there exists a linear map $T^{\wedge N}:V^{\wedge N}\rightarrow W^{\wedge N}$ such that the exterior power map $\wedge^N:V^{\times N}\rightarrow V^{\wedge N}$ composed with $T^{\wedge N}$ is equal to $S$.
\end{proof}


\begin{pp}\label{mc134}
Let $T:V\rightarrow W$ and $S:U\rightarrow V$ be linear maps of  vector spaces. Then $(\idt_V)^{\wedge N}:V^{\wedge N}\rightarrow V^{\wedge N}$ is the identity map $\idt_{V^{\wedge N}}$, and
\begin{align}\label{eq481}
T^{\wedge N}\circ S^{\wedge N}=(T\circ S)^{\wedge N}
\end{align} 
If $T$ is invertible, then $T^{\wedge N}$ is invertible, and
\begin{align}\label{eq492}
(T^{\wedge N})^{-1}=(T^{-1})^{\wedge N}
\end{align}
\end{pp}

\begin{proof}
Both sides of \eqref{eq481} send $v_1\wedge\cdots\wedge v_N$ to $TSv_1\wedge\cdots\wedge TSv_N$. So \eqref{eq481} holds. A similar reasoning shows that $(\idt_V)^{\wedge N}$ equals $\idt_{V^{\wedge N}}$. If $T$ is invertible, then by \eqref{eq481} we have $T^{\wedge N}(T^{-1})^{\wedge N}=\idt_{W^{\wedge N}}$ and $(T^{-1})^{\wedge N}T^{\wedge N}=\idt_{V^{\wedge N}}$. This proves \eqref{eq492}.
\end{proof}


\begin{rem}\label{mc172}
Let $T:V\rightarrow W$ be a linear map. Suppose that $T$ is injective, then there is linear $S:W\rightarrow V$ such that $S\circ T=\idt_V$. Thus $S^{\wedge N}\circ T^{\wedge N}=\idt_{V^{\wedge N}}$. Therefore $T^{\wedge N}$ is injective. Similarly, if $T$ is surjective, then $T^{\wedge N}$ is also surjective. When $V,W$ are finite dimensional, the injectivity resp. surjectivity of $T^{\wedge N}$ can also be proved with the help of bases and Thm. \ref{mc131}.
\end{rem}






By Thm. \ref{mc131}, if $\dim V=n<+\infty$, then $\dim V^{\wedge n}=1$. In this case, $T^{\wedge n}$ is a scalar multiplication on $V^{\wedge n}\simeq\Fbb$. Thus, we can define:

\begin{df}
Let $V$ be a finite-dimensional nonzero vector space. Let $n=\dim V$. Then $\det T$, the \textbf{determinant of $T$}, \index{00@Determinant of a linear map} is defined to be the unique element of $\Fbb$ satisfying
\begin{align}
T^{\wedge n}=\det T\cdot\idt_{V^{\wedge n}}
\end{align} 
In particular, if $A\in\Fbb^{n\times n}$, then $\det A$ is defined by viewing $A$ as an element of $\Lin(\Fbb^n)$.
\end{df}

\begin{rem}
By Cor. \ref{mc133}, it is clear that for any basis $e_1,\dots,e_n$ of $V$ and any $T\in\Lin(V)$, we have
\begin{align}\label{eq493}
\det T=\frac{Te_1\wedge\cdots\wedge Te_n}{e_1\wedge\cdots\wedge e_n}
\end{align}
\end{rem}

\begin{co}\label{mc135}
Let $V$ be finite-dimensional and $S,T\in\Lin(V)$. Then
\begin{align*}
\det(\idt_V)=1\qquad \det(S\circ T)=\det S\cdot\det T
\end{align*}
If $T$ is invertible, then
\begin{align*}
(\det T)^{-1}=\det(T^{-1})
\end{align*}
\end{co}

\begin{proof}
This is immediate from Prop. \ref{mc134}.
\end{proof}



\begin{co}
Let $n\in\Zbb_+$. Then there exists a unique group homomorphism
\begin{align}
\sgn:\fk S_n\rightarrow\Zbb/2\Zbb=\{\pm1\}
\end{align}
(i.e., $\sgn(1)=1$ and $\sgn(\sigma_1\sigma_2)=\sgn(\sigma_1)\sgn(\sigma_2)$) such that $\sgn(\sigma)=-1$ for any transposition $\sigma$. Consequently, for any vector spaces $V,W$ and an alternating $n$-linear map $T:V^{\times n}\rightarrow W$, and for any $v_1,\dots,v_n\in V$ and $\sigma\in\fk S_n$, we have
\begin{align}\label{eq496}
T(v_{\sigma(1)},\dots,v_{\sigma(n)})=\sgn(\sigma)T(v_1,\dots,v_n)
\end{align}
\end{co}

For each $\sigma\in\fk S_n$, we call $\sgn(\sigma)$ the \textbf{signature} or \textbf{sign} of \index{sgn@$\sgn(\sigma)$} $\sigma$. We say that $\sigma$ is an \textbf{even} \index{00@Even permutation} (resp. \textbf{odd}) \index{00@Odd permutation} permutation if $\sgn(\sigma)=1$ (resp. $\sgn(\sigma)=-1$). 


\begin{proof}
The uniqueness is obvious since $\fk S_n$ is generated by transpositions. To prove the existence, let $U$ be an $n$-dimensional real vector space. Fix a basis $e_1,\dots,e_n$. For each $\sigma\in\fk S_n$, let $T_\sigma$ be the unique linear map sending $e_1,\dots,e_n$ to $e_{\sigma(1)},\dots,e_{\sigma(n)}$ respectively. Moreover, it is clear that $T_\sigma\in\GL(U)$ where $\GL(U)$ is the set of invertible linear maps on $U$. Then $\sigma\in\fk S_N\mapsto T_\sigma\in\GL(U)$ is clearly a group homomorphism. By Cor. \ref{mc135}, we have a homomorphism $\det:\GL(U)\rightarrow\Rbb\setminus\{0\}$. Therefore, we have a homomorphism $\sgn:\fk S_n\rightarrow\Rbb\setminus\{0\}$ defined by $\sgn(\sigma)=\det(T_\sigma)$.

By \eqref{eq493}, the signature of a transposition is clearly $-1$. Since $\fk S_n$ is generated by transpositions, we must have $\sgn(\fk S_n)\subset\{\pm1\}$. This proves that $\sgn$ is the desired group homomorphism.

\eqref{eq496} clearly holds when $\sigma$ is a transposition. Therefore, since we have proved that $\sgn$ is multiplicative, we see that \eqref{eq496} must be true for any $\sigma\in\fk S_n$ since we can write $\sigma$ as a product of transpositions.  
\end{proof}

We are ready to generalize Thm. \ref{mc126} to vector spaces that are not necessarily finite-dimensional. Even in the case that $V$ is finite-dimensional (which is the main case we are interested in), the following gives a different proof of the existence of $V^{\wedge N}$ than that of Thm. \ref{mc126}. Both proofs have their own value. Of course, since we will only apply exterior powers to finite-dimensional spaces when studying manifolds, the readers can safely skip the following proof.

%Since we will only use exterior powers of finite dimensional vector spaces in the study of manifolds, the readers can safely skip the following theorem and its proof.

\begin{thm}\label{mc136}
Let $N\in\Nbb$. Let $V$ be a vector space. Assume that $\mathrm{char}(\Fbb)=0$, i.e., $n\neq0$ in $\Fbb$ for all $n=1,2,\dots$. Then there exists an exterior power $V^{\wedge N}$.
\end{thm}

\begin{proof}
The case $N=0$ is obvious. So we assume $N\ge1$. Define an $N$-linear map
\begin{gather*}\label{eq495}
V^{\times N}\rightarrow V^{\otimes N}\qquad(v_1,\dots,v_N)\mapsto v_1\wedge\cdots\wedge v_N   \tag{$\star$}
\end{gather*}
where
\begin{subequations}
\begin{align}
v_1\wedge\cdots\wedge v_N=\sum_{\sigma\in\fk S_N}\sgn(\sigma)\cdot v_{\sigma(1)}\otimes\cdots\otimes v_{\sigma(N)}
\end{align}
This map is clearly alternating. Restricting the codomain of \eqref{eq495} to its range gives an alternating $N$-linear map
\begin{align}
\wedge:V^{\times N}\rightarrow V^{\wedge N}
\end{align}
\end{subequations}
 



Suppose that $T:V^{\times N}\rightarrow W$ is an alternating $N$-linear map. Then by Rem. \ref{mc79}, there is a linear $\wtd T:V^{\otimes N}\rightarrow W$ satisfying $\wtd T(v_1\otimes\cdots\otimes v_N)=T(v_1,\dots,v_N)$ for all $v_1,\dots,v_N\in V$. Therefore, 
\begin{align*}
\sgn(\sigma)\wtd T(v_{\sigma(1)}\otimes\cdots\otimes v_{\sigma (N)})=\sgn(\sigma)T(v_{\sigma(1)},\dots,v_{\sigma(N)})=T(v_1,\dots,v_N)
\end{align*}
where the last equality is due to \eqref{eq496}. Summing the LHS over all $\sigma$ and dividing it by $\card(\fk S_N)=N!$ (which is possible since $\mathrm{char}(\Fbb)=0$), we get
\begin{align*}
\frac 1{N!}\wtd T(v_1\wedge\cdots\wedge v_N)=T(v_1,\dots,v_N)
\end{align*}
This finishes the proof that $\wedge:V^{\times N}\rightarrow V^{\wedge N}$ is an exterior power of $V$.
\end{proof}

\begin{comment}
By Rem. \ref{mc79}, the $N$-linear map $(v_1,\dots,v_N)\mapsto \sgn(\sigma)\cdot v_{\sigma(1)}\otimes\cdots\otimes v_{\sigma(N)}$ gives rise to a unique linear map satisfying
\begin{gather*}
\Phi_\sigma:V^{\otimes N}\rightarrow V^{\otimes N}\qquad v_1\otimes\cdots\otimes v_N\mapsto \sgn(\sigma)\cdot v_{\sigma(1)}\otimes\cdots\otimes v_{\sigma(N)}
\end{gather*}
Therefore, setting  $\dps\Psi=\frac 1{N!}\sum_{\sigma\in\fk S_N}\Phi_\sigma$, we have that $v_1\wedge\cdots\wedge v_N=\Psi(v_1\otimes\cdots\otimes v_N)$, and  that $V^{\wedge N}$ is the range of $\Psi$.
\end{comment}

\begin{rem}
When $\dim V<+\infty$, the two proofs of the existence of $V^{\wedge N}$ is similar to the two proofs of the existence of the determinant functions: The proof of Thm. \ref{mc126} is similar to the inductive construction of $\det$ using cofactor expansions. On the other hand, the proof of Thm. \ref{mc136} is similar to the definition of $\det A$ (where $A\in\Fbb^{n\times n}$) by $\det A=\sum_{\sigma\in\fk S_n}\sgn(\sigma)A_1^{\sigma(1)}\cdots A_n^{\sigma(n)}$.
\end{rem}







\subsection{Exterior products of alternating tensors}

Fix a field $\Fbb$ satisfying $\mathrm{char}(\Fbb)=0$ (e.g. $\Fbb\in\{\Rbb,\Cbb\}$). All vectors spaces are over $\Fbb$. The following theorem is a generalization of the linear isomorphism \eqref{eq487}. 
\begin{thm}\label{mc132}
Let $k\in\Zbb_+$ and $n_1,\dots,n_k\in\Nbb$. Let $V_1,\dots,V_k$ be vector spaces. Let $W$ be a vector space. Then there is a linear isomorphism
\begin{subequations}
\begin{gather}\label{eq488}
\ALin_k(V_1^{\times n_1}\times\cdots\times V_k^{\times n_k},W)\quad\xlongrightarrow{\simeq}\quad \Lin_k(V_1^{\wedge n_1}\times\cdots\times V_k^{\wedge n_k},W)
\end{gather}
where the RHS is the space of $k$-linear maps, and the LHS is the space of $(n_1+\cdots+n_k)$-linear maps that are alternating on each $V_i^{\times n_i}$ (when the vectors in the other components are fixed). The linear structure of both sides are defined by that of $W^X$ for any set $X$. Moreover, if $T$ in the LHS of \eqref{eq488} corresponds to $\wtd T$ on the RHS, then for each $1\leq i\leq k$ and $v_i(1),\dots v_i(n_i)\in V_i$, we have
\begin{align}\label{eq490}
\begin{aligned}
&T(v_1(1),\dots,v_1(n_1),\dots,v_k(1),\dots,v_k(n_k))\\
=&\wtd T(v_1(1)\wedge\cdots\wedge v_1(n_1),\dots,v_k(1)\wedge\dots\wedge v_k(n_k))
\end{aligned}
\end{align}
\end{subequations}
\end{thm}

In the following, we give two proofs of this theorem. The first proof assumes that each $V_i$ is finite-dimensional. The second proof does not.


\begin{proof}[First proof]
In this proof, we assume that $\dim V_i<+\infty$ for each $V_i$ . Choose a basis of $V_i$. Then Thm. \ref{mc131} gives a canonical basis for each $V_i^{\wedge n_i}$. For each $T$ in the LHS of \eqref{eq488}, define $\wtd T$ to be an element of the RHS of \eqref{eq488} such that \eqref{eq490} holds for the chosen bases elements. Then, by skew-symmetry and  multilinearity, \eqref{eq490} holds in general.
\end{proof}



\begin{proof}[Second proof]
We prove this by induction on $k$. The case $k=1$ is due to \eqref{eq487}. Assume that case $k-1$ is true. Now, consider the case $k$. We note that for each vector spaces $A_1,\dots,A_k,B$ we have a linear isomorphism
\begin{align}\label{eq489}
\Lin_k(A_1\times A_2\times\cdots\times A_k,B)\simeq \Lin(A_1,\Lin_{k-1}(A_2\times\cdots\times A_k,B))
\end{align}
where each $k$-linear map belonging to the LHS corresponds to the linear map sending $\xi\in A_1$ to $T(\xi,\cdot)\in\Lin_{k-1}(A_2\times\cdots\times A_k,B)$. Using this isomorphism and the cases $1$ and $k-1$, we have 
\begin{align*}
&\Lin_k(V_1^{\wedge n_1}\times\cdots\times V_k^{\wedge n_k},W)\simeq \Lin(V^{\wedge n_1},\Lin_{k-1}(V_2^{\wedge n_2}\times\cdots\times V_k^{\wedge n_k},W))\\
\simeq&\ALin_1(V^{\times n_1},\Lin_{k-1}(V_2^{\wedge n_2}\times\cdots\times V_k^{\wedge n_k},W))\\
\simeq&\ALin_1(V^{\times n_1},\ALin_{k-1}(V_2^{\times n_2}\times\cdots\times V_k^{\times n_k},W))
\end{align*}
We have a linear isomorphism
\begin{align}
\begin{aligned}
&\ALin_1(V^{\times n_1},\ALin_{k-1}(V_2^{\times n_2}\times\cdots\times V_k^{\times n_k},W))\\
\simeq& \ALin_k(V_1^{\times n_1}\times\cdots\times V_k^{\times n_k},W)
\end{aligned}
\end{align}
defined similar to \eqref{eq489}. The composition of these isomorphisms gives an isomorphism \eqref{eq488}. By keeping track of these isomorphisms, one easily checks that \eqref{eq490} is true.
\end{proof}


The following ``\textbf{parentheses removal property}" of exterior products is an immediate consequence of Thm. \ref{mc132}.


\begin{co}\label{mc150}
Let $k\in\Zbb_+$ and $n_1,\dots,n_k\in\Nbb$. Let $V$ be a vector space. Then there is an (obviously unique) $k$-linear map
\begin{subequations}\label{eq491}
\begin{gather}
\wedge: V^{\wedge n_1}\times\cdots\times V^{\wedge n_k}\rightarrow V^{\wedge(n_1+\cdots+n_k)}\qquad(\xi_1,\dots,\xi_k)\mapsto \xi_1\wedge\cdots\wedge\xi_k
\end{gather}
such that for each $1\leq i\leq k$ and $v_i(1),\dots,v_i(n_i)\in V$, we have
\begin{align}\label{eq491b}
\begin{aligned}
&(v_1(1)\wedge\cdots\wedge v_1(n_1))\wedge\cdots\wedge (v_k(1)\wedge\cdots\wedge v_k(n_k))\\
=&v_1(1)\wedge\cdots\wedge v_1(n_1)\wedge\cdots\wedge v_k(1)\wedge\cdots\wedge v_k(n_k)
\end{aligned}
\end{align}
\end{subequations}
We call $\xi_1\wedge\cdots\wedge\xi_k$ the \textbf{exterior product} \index{00@Exterior product of alternating tensors} of the alternating tensors $\xi_1,\dots,\xi_k$.
\end{co}

If $n_i=0$ and $V\neq0$, then $V^{n_i}=\Fbb$, and hence $\xi_i\in\Fbb$. In this case, we understand
\begin{align}
\xi_1\wedge\cdots\wedge\xi_i\wedge\cdots\wedge\xi_k=\xi_i\cdot(\xi_1\wedge\cdots\wedge\wht{\xi_i}\wedge\cdots\wedge\xi_k)
\end{align}
where the RHS is the scalar multiplication of $\xi_1\wedge\cdots\wedge\xi_{i-1}\wedge\xi_{i+1}\wedge\cdots\wedge\xi_k$ by $\xi_i$.

\begin{proof}
Apply Thm. \ref{mc132} to the map
\begin{gather*}
T:V^{\times n_1}\times\cdots\times V^{\times n_k}\rightarrow\Fbb 
\end{gather*}
sending each $(v_1(1),\dots,v_1(n_1),\dots,v_k(1),\dots,v_k(n_k))$ to the RHS of \eqref{eq491b}.
\end{proof}





\begin{exe}
Let $\xi,\eta,\mu$ be alternating tensors of a vector space $V$. Prove that
\begin{subequations}\label{eq555}
\begin{gather}
(\xi\wedge\eta)\wedge\mu=\xi\wedge\eta\wedge\mu=\xi\wedge(\eta\wedge\mu)\\
\xi\wedge\eta=(-1)^{\deg\xi\cdot\deg\eta}~\eta\wedge\xi
\end{gather}
\end{subequations}
\end{exe}

\begin{pp}\label{mc223}
Let $F:V\rightarrow W$ be a linear map of vector spaces. Then for each $\xi\in V^{\wedge k}$ and $\eta\in V^{\wedge l}$ we have
\begin{align}\label{eq557}
F^{\wedge(k+l)}(\xi\wedge\eta)=(F^{\wedge k}\xi)\wedge (F^{\wedge l}\eta)
\end{align}
\end{pp}
\begin{proof}
\eqref{eq557} clearly holds when $\xi$ and $\eta$ are of the form $\xi=v_1\wedge\cdots\wedge v_k$ and $\eta=v_1'\wedge\cdots\wedge v_l'$ where each $v_i$ and $v'_j$ are in $V$. Thus \eqref{eq557} holds in general.
\end{proof}








\subsection{Exterior powers of dual spaces}


As in the previous sections, all vector spaces in this section are over a fixed field $\Fbb$ satisfying $\mathrm{char}(\Fbb)=0$. We shall show that if $V$ is a finite-dimensional vector space, then $(V^*)^{\wedge N}$ can be viewed naturally as the dual space of $V^{\wedge N}$. Many important conclusions can be drawn from this property. 

%% Record #25 2024/05/27 Two lectures  61

\subsubsection{Exterior powers of dual spaces}


\begin{df}\label{mc148}
Let $V,W$ be finite dimensional vector spaces. A bilinear map $\omega:V\times W\rightarrow \Fbb$ is called a \textbf{perfect pairing} \index{00@Perfect pairing} if the linear map
\begin{align}
\Theta:V\rightarrow W^*\qquad v\mapsto \omega(v,\cdot)
\end{align}
is a linear isomorphism. This is equivalent to saying that
\begin{align}\label{eq480}
\Gamma:W\rightarrow V^*\qquad w\mapsto\omega(\cdot,w)
\end{align}
is a linear isomorphism, since one checks easily that $\Gamma=\Theta^\tr$.
\end{df}
Thus, a perfect pairing of $V$ and $W$ realizes $V$ and $W$ as dual spaces of each other.

\begin{eg}\label{mc124}
Assume that $V$ is real and $\dim V<+\infty$, and let $\bk{\cdot,\cdot}:V\times V\rightarrow\Rbb$ be a real inner product. Then it induces a linear isomorphism \index{zz@$\Theta_V$, the Riesz isomorphism of $V$}
\begin{align}
\Theta_V:V\rightarrow V^*
\end{align}
called the \textbf{Riesz isomorphism}. \index{00@Riesz isomorphism} When no confusion arises, we abbreviate $\Theta_V$ to $\Theta$.
\end{eg}




\begin{pp}\label{mc137}
Let $V,W$ be vector spaces. Let $\omega:V\times W\rightarrow\Fbb$ be bilinear. Let $v_\blt=(v_1,\dots,v_n)$ be vectors in $V$. Let $w_\blt=(w_1,\dots,w_n)$ be vectors in $W$. Suppose that $v_\blt$ is \textbf{orthonormal to} $w_\blt$  \index{00@Orthonormal under a pairing} under $\omega$, i.e., for each $1\leq i,j\leq n$ we have
\begin{align*}
\omega(v_i,w_j)=\delta_{i,j}
\end{align*}
Then both $v_1,\dots,v_n$ and $w_1,\dots,w_n$ are linearly independent.

Suppose moreover that $V$ is spanned by $v_1,\dots,v_n$ and $W$ is spanned by $w_1,\dots,w_n$. Then $\omega$ is perfect pairing, $v_\blt$ is a basis of $V$, $w_\blt$ is a basis of $W$. Moreover, if $\Gamma$ is defined by \eqref{eq480}, then $(\Gamma w_1,\dots,\Gamma w_n)$ is the dual basis of $v_1,\dots,v_n$.
\end{pp}

%


\begin{proof}
Assume that $\xi=\sum a_iv_i$ is zero where $a_i\in\Fbb$. Then $a_i=\omega(\xi,w_i)=0$. This proves that $v_\blt$ is linearly independent. Similarly, $w_\blt$ is linearly independent. 

Now assume that $V$ is spanned by $v_\blt$ and $W$ is spanned by $w_\blt$. Then $v_\blt$ and $w_\blt$ are bases. Since $\bk{v_i,\Gamma w_j}=\omega(v_i,w_j)=\delta_{i,j}$, clearly $\Gamma w_j=\wch v^j$ where $\wch v^1,\dots,\dots \wch v^n$ are the dual basis of $v_\blt$. Therefore, $\Gamma$ sends a basis of $W$ to a basis of $V^*$. Equivalently, $\Gamma$ is a linear isomorphism. So $\omega$ is a perfect pairing.
\end{proof}




\begin{thm}\label{mc138}
Let $V$ be a vector space with dual space $\wch V=\Lin(V,\Fbb)$. Let $N\in\Nbb$. Then there exists a unique bilinear map
\begin{subequations}\label{eq497}
\begin{gather}
\bk{\cdot,\cdot}:V^{\wedge N}\times \wch V^{\wedge N}\rightarrow\Fbb
\end{gather}
satisfying
\begin{align}\label{eq497b}
\begin{aligned}
\bk{v_1\wedge\cdots\wedge v_N,\varphi_1\wedge\cdots\wedge\varphi_N}=\sum_{\sigma\in\fk S_N}\sgn(\sigma)\bk{v_1,\varphi_{\sigma(1)}}\cdots\bk{v_N,\varphi_{\sigma(N)}}
\end{aligned}
\end{align}
\end{subequations}
Moreover, if $V$ is finite-dimensional, then $\bk{\cdot,\cdot}$ is a perfect pairing.
\end{thm}
Note that since $\sgn(\sigma)=\sgn(\sigma^{-1})$, the RHS of \eqref{eq497} also equals
\begin{align}
\sum_{\sigma\in\fk S_N}\sgn(\sigma)\bk{v_{\sigma(1)},\varphi_1}\cdots\bk{v_{\sigma(N)},\varphi_N}
\end{align}


\begin{proof}
The uniqueness is obvious. Let us prove the existence. Let $T:V^{\times N}\times\wch V^{\times N}\rightarrow\Fbb$ send each $(v_1,\dots,v_N,\varphi_1,\dots,\varphi_N)$ to the RHS of \eqref{eq497b}. Then $T$ is clearly multilinear. Moreover, it is not hard to check (using the fact that $\sgn$ is multiplicative) that $T$ is alternating on the first $N$ variables and also on the last $N$ variables. Therefore, by Thm. \ref{mc132}, there exists a biliear map $\bk{\cdot,\cdot}$ described by \eqref{eq497}. This proves the existence.

Now assume that $n=\dim V<+\infty$, and let $e_1,\dots,e_n$ be a basis of $V$ with dual basis $\wch e^1,\dots,\wch e^n$. Using \eqref{eq497b}, one easily checks that for each $1\leq i_1<\cdots<i_N\leq n$ and $1\leq j_1<\cdots<j_N\leq n$ we have
\begin{align}\label{eq498}
\bk{e_{i_1}\wedge\cdots\wedge e_{i_N},\wch e^{j_1}\wedge\cdots\wedge \wch e^{j_N}}=\left\{
\begin{array}{ll}
1&\text{ if }i_1=j_1,\dots,i_N=j_N\\[0.5ex]
0&\text{ otherwise}
\end{array}
\right.
\end{align}
Therefore, by Prop. \ref{mc137}, $\bk{\cdot,\cdot}$ is a perfect pairing. Note that Prop. \ref{mc137} gives an alternative proof that $(e_{i_1}\wedge\cdots\wedge e_{i_N})_{1\leq i_1<\cdots<i_N\leq n}$ is a basis of $V^{\wedge N}$.
\end{proof}


\begin{rem}
Unless otherwise stated, for each finite-dimensional vector space $V$, we identify $(V^*)^{\wedge N}$ with the dual space $(V^{\wedge N})^*$ via the canonical linear isomorphism $(V^*)^{\wedge N}\xrightarrow{\simeq}(V^{\wedge N})^*$ induced by the perfect pairing in Thm. \ref{mc138}. In other words, under this identification, the canonical pairing between $V^{\wedge N}$ and $(V^{\wedge N})^*$ is determined by \eqref{eq497b}. 

Therefore, if $e_1,\dots,e_n$ is a basis of $V$, then by \eqref{eq498}, $(e_{i_1}\wedge\cdots\wedge e_{i_N})_{1\leq i_1<\cdots<i_N\leq n}$ is a basis of $V^{\wedge N}$ with dual basis $(\wch e^{i_1}\wedge\cdots\wedge \wch e^{i_N})_{1\leq i_1<\cdots<i_N\leq n}$ in $(V^*)^{\wedge N}$.  \hfill\qedsymbol
\end{rem}


\begin{sexe}
Assume that $V$ is not necessarily finite-dimensional. Use Prop. \ref{mc137} and Thm. \ref{mc138} to describe a basis of $V^{\wedge N}$ in terms of a given basis of $V$.
\end{sexe}


\begin{rem}
Let $n=\dim V<+\infty$. Let $e_1,\dots,e_n$ be a basis of $V$. Let $T\in\Lin(V)$. Then, by \eqref{eq498}, the formula $Te_1\wedge\cdots\wedge Te_n=(\det T)e_1\wedge\cdots\wedge e_n$ (cf. \eqref{eq493}) can be rewritten as
\begin{align}\label{eq499}
\det T=\bk{Te_1\wedge\cdots\wedge Te_n,\wch e^1\wedge\cdots\wedge \wch e^n}
\end{align}
By \eqref{eq497b}, we thus have
\begin{align}
\det T=\sum_{\sigma\in\fk S_n}\sgn(\sigma)\bk{Te_{\sigma(1)},\wch e^1}\cdots\bk{Te_{\sigma(n)},\wch e^n}
\end{align}
In the special case that $V=\Fbb^n$, $T=A\in\Fbb^{n\times n}$, and $e_1,\dots,e_n$ are the standard basis of $\Fbb^n$, noting that $\bk{Ae_j,\wch e^i}$ is the $(i\times j)$-th entry $A^i_j$, we get the well-known formula
\begin{align}\label{eq501}
\det A=\sum_{\sigma\in\fk S_n}\sgn(\sigma) A_{\sigma(1)}^1\cdots A_{\sigma(n)}^n=\sum_{\sigma\in\fk S_n}\sgn(\sigma) A^{\sigma(1)}_1\cdots A^{\sigma(n)}_n
\end{align}
It follows that Formula \eqref{eq497b} can also be written as
\begin{align}
\bk{v_1\wedge\cdots\wedge v_N,\varphi_1\wedge\cdots\wedge\varphi_N}=\det(\bk{v_i,\varphi_j})_{1,\leq i,j\leq N}
\end{align}
\end{rem}

\begin{comment}
\begin{sexe}
Assume that $\dim V<+\infty$. Let $0\leq k\leq n$ and $l=n-k$.
\begin{enumerate}
\item Use Thm. \ref{mc132} to prove that is a unique bilinear map 
\begin{subequations}
\begin{gather}
V^{\wedge k}\times (V^*)^{\wedge n}\rightarrow (V^*)^{\wedge l}\qquad \qquad (\mbf X,\Uppsi)\mapsto \upiota_{\mbf X}\Uppsi
\end{gather}
such that for every $v_1,\dots,v_k\in V$ and $\varphi_1,\dots,\varphi_n\in V^*$, 
\begin{gather}
\begin{gathered}
\upiota_{v_1\wedge\cdots\wedge v_k}(\varphi_1\wedge\cdots\wedge\varphi_n):V^{l}\rightarrow\Fbb\\
\xi_1\wedge\cdots\wedge \xi_l\mapsto \bk{v_1\wedge\cdots\wedge v_k\wedge \xi_1\wedge\cdots\wedge \xi_l,\varphi_1\wedge\cdots\wedge\varphi_n}
\end{gathered}
\end{gather}
We call $\upiota_{\mbf X}\Uppsi$ the \textbf{interior product} \index{00@Interior product} of $\Uppsi$ by $\mbf X$.
\end{subequations}
\item For interior products, the most important case is when $k=1$. Let $e_1,\dots,e_m$ be a basis of $V$ with dual basis $\wch e^1,\dots,\wch e^m$. Let $v=\sum_j v^je_j$ where $v^i\in\Fbb$. Let $1\leq i_1<\cdots<i_n\leq m$. Prove that
\begin{align}
\begin{aligned}
&\upiota_v(\wch e^{i_1}\wedge\cdots\wedge \wch e^{i_n})\\
=&\sum_{1\leq r\leq n}(-1)^{r+1}v^{i_r}\cdot  \wch e^{i_1}\wedge\cdots\wedge \wch e^{i_{r-1}}\wedge \wch e^{i_{r+1}}\wedge\cdots\wedge \wch e^{i_n}
\end{aligned}
\end{align}
\end{enumerate}
\end{sexe}
\end{comment}



\subsubsection{Applications}


Let $V,W$ be finite dimensional vector spaces.

\begin{pp}\label{mc139}
Let $T\in\Lin(V,W)$. Then, under the canonical identifications $(V^*)^{\wedge N}=(V^{\wedge N})^*$ and $(W^*)^{\wedge N}=(W^{\wedge N})^*$, we have
\begin{align}\label{eq500}
(T^{\wedge N})^\tr=(T^\tr)^{\wedge N}
\end{align}
as linear maps $(W^*)^{\wedge N}\rightarrow (V^*)^{\wedge N}$.
\end{pp}


\begin{proof}
Choose any $v_1,\dots,v_N\in V$ and $\varphi_1,\dots,\varphi_N\in W^*$. Then
\begin{align*}
&\bk{v_1\wedge\cdots\wedge v_N,(T^{\wedge N})^\tr(\varphi_1\wedge\cdots\wedge\varphi_N)}=\bk{T^{\wedge N}(v_1\wedge\cdots\wedge v_N),\varphi_1\wedge\cdots\wedge\varphi_N}\\
=&\bk{Tv_1\wedge\cdots\wedge Tv_N,\varphi_1\wedge\cdots\wedge\varphi_N}=\sum_{\sigma\in\fk S_N}\bk{Tv_1,\varphi_{\sigma(1)}}\cdots\bk{Tv_N,\varphi_{\sigma(N)}}\\
=&\sum_{\sigma\in\fk S_N}\bk{v_1,T^\tr\varphi_{\sigma(1)}}\cdots\bk{v_N,T^\tr\varphi_{\sigma(N)}}=\bk{v_1\wedge\cdots\wedge v_N,T^\tr\varphi_1\wedge\cdots\wedge T^\tr\varphi_N}\\
=&\bk{v_1\wedge\cdots\wedge v_N,(T^\tr)^{\wedge N}(\varphi_1\wedge\cdots\wedge\varphi_N)}
\end{align*}
where \eqref{eq497b} has been used.
\end{proof}



\begin{co}
For each $T\in\Lin(V)$ we have
\begin{align*}
\det T=\det(T^\tr)
\end{align*}
\end{co}

\begin{proof}
This is immediate from Prop. \ref{mc139} and the fact that the transpose of a scalar is the same scalar.
\end{proof}

The following theorem gives a basis-free interpretation of the minors of a matrix: It says that the $k\times k$ minors of a matrix can be viewed as the matrix representation of $T^{\wedge k}$.

\begin{thm}\label{mc140}
Let $T\in\Lin(V,W)$. Let $(f_1,\dots,f_n)$ be a basis of $W$ with dual basis $(\wch f^1,\dots,\wch f^n)$. Let $e_1,\dots,e_m\in V$. Let $A\in\Fbb^{n\times m}$ such that
\begin{align*}
T(e_1,\dots,e_m)=(f_1,\dots,f_n)A
\end{align*}
In other words, $A_j^i=\bk{Ae_j,\wch f^i}$. Let $k\leq \min\{m,n\}$. For each $1\leq j_1<\cdots<j_k\leq m$ and $1\leq i_1<\cdots<i_k\leq n$, let \index{A@$A_{i_1,\dots,i_k}^{j_1,\dots,j_k}$, the submatrix defined by the $i_1,\dots,i_k$-th rows and the $j_1,\dots,j_k$-th columns}
\begin{align}\label{eq502}
A_{j_1,\dots,j_k}^{i_1,\dots,i_k}=\text{the $i_1,\dots,i_k$-th rows and $j_1,\dots,j_k$-th columns of $A$}
\end{align}
which is a $k\times k$ submatrix of $A$. Then
\begin{align}
\bk{T^{\wedge k}(e_{j_1}\wedge\cdots\wedge e_{j_k}),\wch f^{i_1}\wedge\cdots\wedge \wch f^{i_k}}=\det\big(A_{j_1,\dots,j_k}^{i_1,\dots,i_k}\big)
\end{align}
Equivalently (by \eqref{eq498}),
\begin{align}
T^{\wedge k}(e_{j_1}\wedge\cdots\wedge e_{j_k})=\sum_{1\leq i_1<\cdots<i_k\leq n}\det\big(A_{j_1,\dots,j_k}^{i_1,\dots,i_k}\big)\cdot f_{i_1}\wedge\cdots\wedge f_{i_k}
\end{align}
\end{thm}

Note that we do not assume $e_1,\dots,e_m$ to be a basis of $V$.

\begin{proof}
We have
\begin{align*}
&\bk{T^{\wedge k}(e_{j_1}\wedge\cdots\wedge e_{j_k}),\wch f^{i_1}\wedge\cdots\wedge \wch f^{i_k}}=\bk{Te_{j_1}\wedge\cdots\wedge Te_{j_k},\wch f^{i_1}\wedge\cdots\wedge \wch f^{i_k}}\\
\xlongequal{\eqref{eq497b}}&\sum_{\sigma\in\fk S_k}\sgn(\sigma)\bk{Te_{j_{\sigma(1)}},\wch f^{i_1}}\cdots\bk{Te_{j_{\sigma(k)}},\wch f^{i_k}}\\
=&\sum_{\sigma\in\fk S_k}\sgn(\sigma)A_{j_{\sigma(1)}}^{i_1}\cdots A_{j_{\sigma(k)}}^{i_k}\xlongequal{\eqref{eq501}}\det\big(A_{j_1,\dots,j_k}^{i_1,\dots,i_k}\big)
\end{align*}
\end{proof}


\begin{co}\label{mc141}
Assume that $V$ is real. Let $f_1,\dots,f_n$ be a basis of $V$. Let $e_1,\dots,e_n\in V$. Assume
\begin{align*}
(e_1,\dots,e_n)=(f_1,\dots,f_n)A
\end{align*}
where $A\in\Rbb^{n\times n}$. Then 
\begin{align}
\frac{e_1\wedge\cdots\wedge e_n}{f_1\wedge\cdots\wedge f_n}=\det A
\end{align}
Consequently, if $e_1,\dots,e_n$ are a basis, then $e_1,\dots,e_n$ and $f_1,\dots,f_n$ have the same orientation iff $\det A>0$.
\end{co}


\begin{proof}
This follows immediately from Thm. \ref{mc140}
\end{proof}

\begin{co}\label{mc145}
Assume that $V$ is real. Let $e_1,\dots,e_n$ and $f_1,\dots,f_n$ be two bases of $V$ with dual basis $\wch e^1,\dots,\wch e^n$ and $\wch f^1,\dots,\wch f^n$ respectively. Then
\begin{align}\label{eq503}
\frac{e_1\wedge\cdots\wedge e_n}{f_1\wedge\cdots\wedge f_n}=\frac{\wch f^1\wedge\cdots\wedge\wch f^n}{\wch e^1\wedge\cdots\wedge\wch e^n}
\end{align}
In particular, $e_1,\dots,e_n$ and $f_1,\dots,f_n$ have the same orientation iff $\wch e^1,\dots,\wch e^n$ and $\wch f^1,\dots,\wch f^n$ have the same orientation.
\end{co}

\begin{proof}
We use the notations in Cor. \ref{mc141}. Then by \eqref{eq460} we have
\begin{align*}
(\wch f^1,\dots,\wch f^n)=(\wch e^1,\dots,\wch e^n)A^\tr
\end{align*}
Therefore, by Cor. \ref{mc141}, the RHS of \eqref{eq503} equals $\det A^\tr=\det A$.
\end{proof}


\begin{df}\label{mc156}
Let $V$ be real. Suppose that an orientation $\mc O$ of $V$ is chosen. The \textbf{dual orientation} $\mc O^*$ \index{00@Dual orientation} on $V^*$ is defined by the orientation of $\wch e^1\wedge\cdots\wedge \wch e^n$ if $e_1,\dots,e_n$ are a basis of $V$ and $e_1\wedge\cdots\wedge e_n$ belongs to $\mc O$. By Cor. \ref{mc145}, this definition is well-defined, i.e., independent of the choice of basis. It is also clear that the double dual orientation of $V^{**}$ is the same as the orientation $\mc O$ of $V$ if we identify $V$ with $V^{**}$ in the canonical way.
\end{df}



\begin{co}[\textbf{Cauchy-Binet formula}]\label{mc142} \index{00@Cauchy-Binet formula}
Let $n\geq m\geq1$ be integers. Let $A\in\Fbb^{m\times n}$ and $B\in\Fbb^{n\times m}$. Then, using the notation in \eqref{eq502}, we have 
\begin{align}\label{eq506}
\det(AB)=\sum_{1\leq i_1<\cdots<i_m\leq n}\det\big(A_{i_1,\dots,i_m}^{1,\dots,m}\big)\cdot\det\big(B_{1,\dots,m}^{i_1,\dots,i_m}\big)
\end{align}
\end{co}

As pointed out in Rem. \ref{mc143}, The Cauchy-Binet formula gives a simpler method of calculating $\det((\Jac F)^\tr\Jac F)$ in the formula for integrals of functions on manifolds.

\begin{proof}
Let $e_1,\dots,e_m$ be the standard basis of $\Fbb^m$. Let $\eps_1,\dots,\eps_n$ be the standard basis of $\Fbb^n$. Then by Thm. \ref{mc140}, we have
\begin{align*}\label{eq505}
B^{\wedge m}(e_1\wedge\cdots\wedge e_m)=\sum_{1\leq i_1<\cdots<i_m\leq n}\det\big(B_{1,\dots,m}^{i_1,\dots,i_m}\big)\eps_{i_1}\wedge\cdots\wedge\eps_{i_m}\tag{$\star$}
\end{align*}
By Thm. \ref{mc140} again, we have $A^{\wedge m}(\eps_{i_1}\wedge\cdots\wedge\eps_{i_m})=\det\big(A_{i_1,\dots,i_m}^{1,\dots,m}\big)e_1\wedge\cdots\wedge e_m$. Therefore
\begin{align*}
A^{\wedge m}B^{\wedge m}(e_1\wedge\cdots\wedge e_m)=\sum_{1\leq i_1<\cdots<i_m\leq n}\det\big(A_{i_1,\dots,i_m}^{1,\dots,m}\big)\det\big(B_{1,\dots,m}^{i_1,\dots,i_m}\big)e_1\wedge\cdots\wedge e_m
\end{align*}
By Prop. \ref{mc134}, we have $A^{\wedge m}B^{\wedge m}=(AB)^{\wedge m}=\det(AB)\idt_{(\Fbb^m)^{\wedge m}}$. This proves \eqref{eq506}.
\end{proof}

The above proof shows that the formula $(AB)^{\wedge k}=A^{\wedge k}B^{\wedge k}$ can be viewed as the abstract Cauchy-Binet formula.




\subsection{Exterior powers of inner product spaces; volume tensors}

We fix a finite-dimensional vector space $V$ over $\Rbb$, equipped with an inner product $\bk{\cdot,\cdot}\equiv\bk{\cdot,\cdot}_V$. Then for each orthonormal basis $e_1,\dots,e_n$ of $V$, and for each $\xi\in V$, we have
\begin{align}\label{eq507}
\xi=\sum_i\bk{\xi,e_i}e_i
\end{align}
since both sides equal $\bk{\xi,e_i}$ when evaluated with $e_i$ under the inner product.


The goal of this section is the study the relationship between $V^{\wedge N}$ and $(V^*)^{\wedge N}$ for the real inner product space $V$.


\subsubsection{The dual inner product on $V^*$}



Recall that by Exp. \ref{mc124}, we have the Riesz isomorphism $\Theta_V:V\rightarrow V^*$ sending $v\in V$ to $\bk{v,\cdot}$. Thus, for each $u,v\in V$, we have
\begin{align}\label{eq508}
\bk{u,\Theta_V v}=\bk{u,v}_V
\end{align}

\begin{df}\label{mc158}
Given the finite-dimensional real inner product space $V$, the \textbf{dual inner product} \index{00@Dual inner product} $\bk{\cdot,\cdot}_{V^*}$ on $V^*$ is defined to be the unique one such that the Riesz isomorphism $\Theta_V$ is an isometry.
\end{df}


\begin{pp}\label{mc146}
Let $e_1,\dots,e_n$ be a basis of $V$. Let $G=[\bk{e_\blt,e_\blt}_V]$ be the Gram matrix of the inner product with respect to $e_1,\dots,e_n$. Then $G$ is the matrix representation of $\Theta_V$ under $e_1,\dots,e_n$ and $\wch e^1,\dots,\wch e^n$, i.e.,
\begin{align}
\Theta_V(e_1,\dots,e_n)=(\wch e^1,\dots,\wch e^n)G
\end{align}
Equivalently,
\begin{align}\label{eq509}
\Theta_V e_j=\sum_i\wch e^i\cdot G_{i,j}
\end{align}
\end{pp}

In particular, if $e_1,\dots,e_n$ are an orthonormal basis, then
\begin{align}\label{eq512}
\Theta_Ve_j=\wch e^j
\end{align}


\begin{proof}
It suffices to check that both sides of \eqref{eq509} are equal when evaluated with $e_k$, i.e., that $\bk{e_k,\Theta_Ve_j}$ equals $\sum_i\bk{e_k,\wch e^i G_{i,j}}=G_{k,j}$. But this is obvious from \eqref{eq508}.
\end{proof}


\begin{co}\label{mc144}
Choose any orthonormal basis $e_1,\dots,e_n\in V$ with dual basis $\wch e^1,\dots,\wch e^n$ in $V^*$. Then the dual inner product is the unique one under which $\wch e^1,\dots,\wch e^n$ are orthonormal.
\end{co}


\begin{proof}
The uniqueness is obvious, since any inner product is determined by the fact that a given basis is orthonormal. Choose the dual inner product on $V^*$. Then by \eqref{eq512}, $\wch e^1=\Theta_Ve_1,\dots,\wch e^n=\Theta_Ve_n$ are orthonormal since $e_1,\dots,e_n$ are orthonormal and $\Theta_V$ is an isometry.
\end{proof}


\begin{co}
If we identify $V$ with $V^{**}$ in the obvious way, then the original inner product on $V$ is equal to the dual inner product on $V^{**}$ defined by the inner product of $V^*$ dual to that of $V$.
\end{co}

\begin{proof}
This is obvious from Cor. \ref{mc144}, because under the identification $V=V^{**}$, if $\wch e^1,\dots,\wch e^n\in V^*$ are the dual basis of $e_1,\dots,e_n\in V$, then $e_1,\dots,e_n$ are also the dual basis of $\wch e^1,\dots,\wch e^n$.
\end{proof}

In the following, we shall always view $V$ and $V^{**}$ as the same real inner product space.




\begin{pp}\label{mc147}
Equip $V^*$ with the dual inner product. Then the Riesz isomorphism $\Theta_{V^*}:V^*\rightarrow V^{**}=V$ is equal to the inverse $(\Theta_V)^{-1}$.
\end{pp}

\begin{proof}
Let $e_1,\dots,e_n$ be an orthonormal basis of $V$ with dual basis $\wch e^1,\dots,\wch e^n$ which are orthonormal by Cor. \ref{mc144}. By \eqref{eq512}, we have that $\Theta_Ve_j=\wch e^j$, and similarly that $\Theta_{V^*}\wch e^j=e_j$ (because $e_1,\dots,e_n\in V^{**}$ are the dual basis of $\wch e^1,\dots,\wch e^n$). So $\Theta_{V^*}$ is the inverse of $\Theta_V$.
\end{proof}


\begin{co}
Let $e_1,\dots,e_n$ be a basis of $V$. Let $G$ be the Gram matrix of $\bk{\cdot,\cdot}_V$ under $e_1,\dots,e_n$. Then $G^{-1}$ is the Gram matrix of $\bk{\cdot,\cdot}_{V^*}$ under $\wch e^1,\dots,\wch e^n$.
\end{co}

In particular, if $\dim V=1$, and if $\wch e^1\in V^*$ is dual to $e_1\in V$, then
\begin{align}\label{eq513}
\Vert e_1\Vert=1/\Vert\wch e^1\Vert
\end{align}

\begin{proof}
By Prop. \ref{mc146}, $G$ is the matrix representation of $\Theta_V$ under the chosen bases. Let $H$ be the Gram matrix of $\bk{\cdot,\cdot}_{V^*}$. Then $H$ is the matrix representation of $\Theta_{V^*}$ under the chosen bases. By Prop. \ref{mc147}, we have $\Theta_{V^*}=\Theta_V^{-1}$, and hence $H=G^{-1}$.
\end{proof}


\subsubsection{Exterior powers of inner product spaces}



\begin{thm}\label{mc149}
Let $N\in\Nbb$. Then there is a unique inner product $\bk{\cdot,\cdot}_{V^{\wedge N}}$ on $V^{\wedge N}$ (called the \textbf{canonical inner product} on $V^{\wedge N}$, also called the \textbf{exterior power} of $\bk{\cdot,\cdot}_V$) satisfying that for any $u_1,\dots,u_N,v_1,\dots,v_N\in V$,
\begin{align}\label{eq510}
\begin{aligned}
\bigbk{u_1\wedge\cdots\wedge u_N,v_1\wedge\cdots\wedge v_N}_{V^{\wedge N}}=&\sum_{\sigma\in\fk S_N}\sgn(\sigma)\bk{u_1,v_{\sigma(1)}}\cdots\bk{u_N,v_{\sigma(N)}}\\
\equiv &\det\big(\bk{u_i,v_j}\big)_{1\leq i,j\leq N}
\end{aligned}
\end{align}
If $e_1,\dots,e_n$ are an orthonormal basis of $V$, then
\begin{align}\label{eq511}
\big(e_{i_1}\wedge\cdots\wedge e_{i_N}\big)_{1\leq i_1<\cdots<i_N\leq n}
\end{align}
is an orthonormal basis of $V^{\wedge N}$. The Riesz isomorphism $\Theta_{V^{\wedge N}}$ is equal to 
\begin{gather}\label{eq521}
\begin{gathered}
\Theta_{V^{\wedge N}}=(\Theta_V)^{\wedge N}:V^{\wedge N}\xrightarrow{\simeq}(V^*)^{\wedge N}\\
e_{i_1}\wedge\cdots\wedge e_{i_N}\mapsto \wch e^{i_1}\wedge\cdots\wedge\wch e^{i_N}
\end{gathered}
\end{gather}
\end{thm}

Recall that $(V^*)^{\wedge N}$ is identified with the dual space of $V^{\wedge N}$ in the canonical way.

\begin{proof}
The uniqueness is obvious. To prove the existence, note that similar to the proof of Thm. \ref{mc138}, we can use Thm. \ref{mc132} to show that there is a bilinear form $\bk{\cdot,\cdot}_{V^{\wedge N}}$ satisfying \eqref{eq510}. It is clear that \eqref{eq511} is orthonormal to \eqref{eq511} under this bilinear form. This implies that $\bk{\cdot,\cdot}_{V^{\wedge N}}$ is an inner product with orthonormal basis \eqref{eq511}. (In general, if $W$ is a finite-dimensional real vector space, $\omega:W\times W\rightarrow\Rbb$ is bilinear, and $\xi_1,\dots,\xi_n$ are a basis of $W$ satisfying $\omega(\xi_i,\xi_k)=\delta_{i,j}$, then $\omega$ is an inner product with orthonormal basis $\xi_1,\dots,\xi_n$.)

Since the basis \eqref{eq511} is orthonormal, by \eqref{eq512}, the Riesz isomorphism $\Theta_{V^{\wedge N}}$ sends each $e_{i_1}\wedge\cdots\wedge e_{i_N}$ to the corresponding dual basis element $\wch e^{i_1}\wedge\cdots\wedge\wch e^{i_N}$. By \eqref{eq512}, $(\Theta_V)^{\wedge N}$ satisfies the same property (since $\Theta_Ve_{i_l}=\wch e^{i_l}$). Therefore $\Theta_{V^{\wedge N}}=(\Theta_V)^{\wedge N}$.
\end{proof}


\begin{pp}\label{mc234}
The dual inner product on $(V^*)^{\wedge N}$ defined by $\bk{\cdot,\cdot}_{V^{\wedge N}}$ agrees with the canonical inner product on $(V^*)^{\wedge N}$ defined by the exterior power of $\bk{\cdot,\cdot}_{V^*}$.
\end{pp}

\begin{proof}
Let $e_1,\dots,e_n$ be an orthonormal basis of $V$. Then one checks easily that
\begin{align}
\big(\wch e^{i_1}\wedge\cdots\wedge \wch e^{i_N}\big)_{1\leq i_1<\cdots<i_N\leq n}
\end{align}
is an orthonormal basis of $(V^*)^{\wedge N}$ under both inner products.
\end{proof}

\begin{rem}\label{mc175}
Let $(V,\mc O)$ be an oriented real inner product space with $\dim V=n$.  If we choose an ordered orthnormal basis $e_1,\dots,e_n$ of $V$ such that $e_1\wedge\cdots\wedge e_n$ represents $\mc O$, then by Def. \ref{mc156}, $\wch e^1\wedge\cdots\wedge\wch e_n$ represents the dual orientation $\mc O^*$. Therefore, by \eqref{eq521},
\begin{align*}
\text{the Riesz isomorphism $\Theta_V:V\rightarrow V^*$ is orientation-preserving}
\end{align*}
\end{rem}



\begin{sexe}
Let $V,W$ be finite-dimensional real inner product spaces. Let $T\in\Lin(V,W)$. Its \textbf{adjoint} \index{00@Adjoint operator} $T^*\in\Lin(W,V)$ is defined to be the unique one satisfying
\begin{align}
\bk{Tv,w}_W=\bk{v,T^*w}_V
\end{align}
for all $v\in V,w\in W$. Prove that
\begin{align}
T^*=\Theta_V^{-1}\cdot T^\tr\cdot \Theta_W
\end{align}
For each $N\in\Nbb$, prove that
\begin{align}
(T^{\wedge N})^*=(T^*)^{\wedge N}
\end{align}
\end{sexe}


\begin{df}\label{mc160}
Let $n=\dim V$. The two elements $\pm\xi\in V^{\wedge n}$ satisfying $\bigbk{\xi,\xi}_{V^{\wedge n}}=1$ are called the \textbf{volume tensors} \index{00@Volume tensors of an inner product space} of $V$. 
\end{df}

\begin{rem}
It is clear that if $V$ is oriented, then $V$ has exactly one volume tensor in this orientation $\mc O$. If $e_1,\dots,e_n$ are a positive orthonormal basis of $(V,\mc O)$, then $e_1\wedge\cdots\wedge e_n$ is the volume tensor of $V$ in $\mc O$, and $\wch e^1\wedge\cdots\wedge \wch e^n$ is the volume tensor of $V^*$ in the dual orientation $\mc O^*$.
\end{rem}


The following proposition provides a geometric meaning for the determinant of the Gram matrix with respect to a basis: it is the square norm of the top wedge power of that basis.

\begin{pp}\label{mc162}
Assume that $(V,\mc O)$ is oriented. Let $e_1,\dots,e_n$ be a positive basis of $(V,\mc O)$. Let $\mc O^*$ be the dual orientation. Let $G=[\bk{e_\blt,e_\blt}]$ be the Gram matrix of $\bk{\cdot,\cdot}_V$ under $e_1,\dots,e_n$. Then
\begin{align}\label{eq514}
\frac{e_1\wedge\cdots\wedge e_n}{\sqrt{\det G}}\qquad\text{and}\qquad \sqrt{\det G}\cdot \wch e^1\wedge\cdots\wedge \wch e^n
\end{align}
are the volume tensors of $(V,\mc O)$ and $(V^*,\mc O^*)$ respectively.
\end{pp}



\begin{proof}
The length of $e_1\wedge\cdots\wedge e_n$ is $\sqrt{\det G}$ since
\begin{align*}
\bk{e_1\wedge\cdots\wedge e_n,e_1\wedge\cdots\wedge e_n}\xlongequal{\eqref{eq510}} \det(\bk{e_i,e_j})_{1\leq i,j\leq N}=\det G
\end{align*}
Since $\wch e^1\wedge\cdots\wedge \wch e^n$ is dual to $e_1\wedge\cdots\wedge e_n$, its length is $1/\sqrt{\det G}$ by \eqref{eq513}. Therefore, both vectors in \eqref{eq514} have length $1$.
\end{proof}





\newpage



\section{Integrals of differential forms on oriented manifolds}


\begin{cv}\label{mc159}
Suppose that $(M,\gk)$ is a Riemannian $\partial$-manifold. Then for each $p\in M$, $\gk$ is a (real) inner product on $T_pM$. Thus $T_p^*M$ has a canonical inner product $\gk^*$, i.e., the dual inner product of $\gk$ (cf. Def. \ref{mc158}). Therefore, for each $k$ (where $k>0$ if $\dim M=0$), we have inner products on $\bwn^k T_pM$ and $\bwn^k T_p^*M$ defined to be the exterior powers of $\gk$ and $\gk^*$ respectively (cf. Thm. \ref{mc149}), which are dual to each other (cf. Prop. \ref{mc234}). We denote the inner product on $\bwn^k T_pM$ (resp. $\bwn^k T_p^*M$) also by $\bk{\cdot,\cdot}_\gk$ (resp. $\bk{\cdot,\cdot}_{\gk^*}$), abbreviated to $\bk{\cdot,\cdot}$ when no confusion arises. \index{00@Inner product on $\bwn^k T_p^*$}
\end{cv}


\subsection{Differential forms}


Let $M,N$ be smooth $\partial$-manifold.



\begin{df}
For each $n\in\Nbb$, let \index{zz@$\bigwedge^kT^*M$}
\begin{align}
\bwn^nT^*M=\bigsqcup_{p\in M}\bwn^nT_p^*M
\end{align}
A function $\omega:M\rightarrow \bwn^nT^*M$ is called a \textbf{differential $\pmb n$-form} (or simply a \textbf{$\pmb n$-form}) \index{00@Differential form} if for each $p\in M$ we have $\omega_p\in\bwn^nT_p^*M$. We say that $n$ is the \textbf{degree} of $\omega$ and write
\begin{align*}
\deg\omega=n
\end{align*}
In particular, a $0$-form is exactly a real function on $M$. 
\end{df}

\begin{df}
Let $\omega_1,\dots,\omega_k$ be $n_1,\dots,n_k$-forms on $M$. By Cor. \ref{mc150}, we can define an $(n_1+\cdots+n_k)$-form on $M$ by
\begin{gather}
\omega_1\wedge\cdots\wedge\omega_k:M\rightarrow \bwn^{n_1+\cdots+n_k}T^*M\qquad p\mapsto \omega_1|_p\wedge\cdots\wedge \omega_k|_p
\end{gather}
called the \textbf{exterior product} \index{00@Exterior product of differential forms} of $\omega_1,\dots\omega_k$.
\end{df}


\begin{df}
Let $F:M\rightarrow N$ be a smooth map. For each $n$-form $\omega:N\rightarrow\bwn^nT^*N$, the \textbf{pullback} \index{00@Pullback $k$-form} of $\omega$ by $F$ is
\begin{align}
F^*\omega:M\rightarrow \bwn^nT^*M\qquad p\mapsto \big(F^*|_p\big)^{\wedge n}\big(\omega|_{F(p)}\big)
\end{align}
If $F$ is a diffeomorphism with inverse $G:N\rightarrow M$, we also write
\begin{align*}
G_*\omega=F^*\omega
\end{align*}
and call $G_*\omega$ the \textbf{pushforward} \index{00@Pushforward $k$-form} of $\omega$ by $G$. 
\end{df}

\begin{df}\label{mc187}
Assume that either $S=\partial M$, or $\partial M=\emptyset$ and $S$ is a smooth $\partial$-submanifold of $M$. For each differential form $\omega:M\rightarrow\bwn^nT^*M$ on $M$, set
\begin{align*}
\omega|_S:=\iota^*\omega
\end{align*}
where $\iota:S\rightarrow M$ is the inclusion map. Then $\omega|_S:S\rightarrow\bwn^n T^*S$ is a differential form on $S$, called the \textbf{restriction of the differential form} $\omega$ to $S$. \index{00@Restriction of differential form}.
\end{df}


\begin{rem}
Suppose that $\omega_1,\dots,\omega_k$ are $n_1,\dots,n_k$-forms of $N$.  Then one easily checks that
\begin{align}\label{eq515}
F^*(\omega_1\wedge\cdots\wedge\omega_k)=(F^*\omega_1)\wedge\cdots\wedge (F^*\omega_k)
\end{align}
In particular, since every differential form is locally a sum of exterior products of $1$-forms, it suffices to calculate the pullbacks of $1$-forms in order to calculate the pullback of a $k$-form. For example:
\end{rem}


\begin{eg}\label{mc151}
Let $F:M\rightarrow N$ be smooth. Suppose that $(U,\varphi^1,\dots,\varphi^m)$ and $(V,\psi^1,\dots,\psi^n)$ are charts of $M,N$ satisfying $F(U)\subset V$, and suppose that $\omega$ is a $k$-form on $N$ such that
\begin{align}
\omega|_V=\sum_{1\leq i_1<\cdots<i_k\leq n}\omega_{i_1,\dots,i_k}d\psi^{i_1}\wedge\cdots\wedge d\psi^{i_k}
\end{align}
where each $\omega_{i_1,\dots,i_k}:V\rightarrow\Rbb$ is a function (i.e., a $0$-form). Then $F^*\omega|_{F^{-1}(V)}$ equals $\sum F^*\omega_{i_1,\dots,i_k}\cdot F^*d\psi^{i_1}\wedge\cdots\wedge F^*d\psi^{i_k}$, and hence, by \eqref{eq404},
\begin{align*}
F^*\omega\big|_U=\sum_{
\begin{subarray}{c}
1\le i_1<\dots<i_k\leq n\\
1\leq j_1,\cdots,j_k\leq m
\end{subarray}
}(\omega_{i_1,\dots,i_k}\circ F)\cdot \frac{\partial(\psi^{i_1}\circ F)}{\partial\varphi^{j_1}}\cdots \frac{\partial(\psi^{i_k}\circ F)}{\partial\varphi^{j_k}}\cdot d\varphi^{j_1}\wedge\cdots\wedge d\varphi^{j_k}\Big|_U
\end{align*}
\end{eg}

Eq. \eqref{eq515} is very useful for calculating pullbacks of differential forms. However, when doing proofs, it is sometimes easier to use the following formula:

\begin{pp}\label{mc180}
Assume the setting of Exp. \ref{mc151}. Let $\Jac_\varphi(\psi\circ F):U\rightarrow \Rbb^{n\times m}$ whose $(i\times j)$-th entry is $\partial_{\varphi^j}(\psi^i\circ F)$, namely, for each $p\in U$ we let \index{Jac@$\Jac_\varphi(\psi\circ F)$}
\begin{gather}\label{eq518}
\begin{gathered}
\Jac_\varphi(\psi\circ F):U\rightarrow\Rbb^{n\times m}\\
p\mapsto\Jac_\varphi(\psi\circ F)\big|_p=\Jac(\psi\circ F\circ\varphi^{-1})\big|_{\varphi(p)}
\end{gathered}
\end{gather}
For each $i_1<\cdots<i_k$ and $j_1<\cdots<j_k$, let $\Jac_\varphi(\psi\circ F)^{i_1,\dots,i_k}_{j_1,\dots,j_k}:U\rightarrow\Rbb^{k\times k}$ be the submatrix defined the $i_1,\dots,i_k$-th rows and the $j_1,\dots,j_k$-th columns of $\Jac_\varphi(\psi\circ F)$. Then
\begin{align}\label{eq516}
\begin{aligned}
&F^*(d\psi^{i_1}\wedge\cdots\wedge d\psi^{i_k})\big|_U\\
=&\sum_{1\leq j_1<\cdots<j_k\leq m}\det \left(\Jac_\varphi(\psi\circ F)^{i_1,\dots,i_k}_{j_1,\dots,j_k}\right)\cdot d\varphi^{j_1}\wedge\cdots\wedge d\varphi^{j_k}
\end{aligned}
\end{align}
\end{pp}

\begin{proof}
By Cor. \ref{mc98}, for each $p\in U$, the transpose of $\Jac_\varphi(\psi\circ F)|_p$ is the matrix representation of $F^*|_p:T_{F(p)}^*N\rightarrow T^*_pM$ under the bases $d\psi^1|_{F(p)},\dots,d\psi^n|_{F(p)}$ and $d\varphi^1|_p,\dots,d\varphi^m|_p$. Therefore, \eqref{eq516} follows from Thm. \ref{mc140}.
\end{proof}

Note that $\Jac_\varphi(\psi\circ F)$ is smooth. Therefore, if $M=N$ and hence $(U,\varphi)$ and $(V,\psi)$ are charts on $M$, then \eqref{eq516} implies that on $U\cap V$, each $d\psi^{i_1}\wedge\cdots\wedge d\psi^{i_k}$ is an $C^\infty(U\cap V,\Rbb)$-linear combination of $d\varphi^{j_1}\wedge\cdots\wedge d\varphi^{j_k}$ for all $j_1<\cdots<j_k$. Therefore, similar to $C^r$/Borel tensor fields (cf. Def. \ref{mc152}), we have two equivalent ways to define $C^r$/Borel differential forms:

\begin{df}\label{mc174}
Let $r\in\Nbb\cup\{\infty\}$. Let $\omega:M\rightarrow\bwn^kT^*M$ be a $k$-form. We say that $\omega$ is a \textbf{$\pmb C^r$/Borel $\pmb k$-form} \index{00@$C^r$ differential form} if \index{00@Borel differential form} one of the following equivalent statements hold:
\begin{enumerate}
\item[(1)] For every chart $(U,\varphi^1,\dots,\varphi^n)$, the functions $\omega_{i_1,\dots,i_k}$ defined by
\begin{align}\label{eq517}
\omega|_U=\sum_{1\leq i_1<\cdots<i_k\leq n}\omega_{i_1,\dots,i_k}d\varphi^{i_1}\wedge\cdots\wedge d\varphi^{i_k}
\end{align}
are $C^r$/Borel.
\item[(2)] There exists an atlas $\fk U$ of $M$ such that for any $(U,\varphi^1,\dots,\varphi^n)\in\fk U$, the functions  $\omega_{i_1,\dots,i_k}$ defined by \eqref{eq517} are $C^r$/Borel.
\end{enumerate}
In particular, a $C^r$/Borel $0$-form is precisely a $C^r$/Borel function $M\rightarrow\Rbb$.
\end{df}


\begin{rem}
In a similar way, one can define a \textbf{(contravariant) alternating tensor field} \index{00@Alternating tensor field} $\fk X:M\rightarrow\bwn^k TM=\bigsqcup_{p\in M}\bwn^k T_pM$ to be a function satisfying $\fk X|_p\in\bwn^kT_pM$ for all $p\in M$. One can also define \textbf{$\pmb {C^r}$/Borel} contravariant alternating tensor fields in a similar way as in Def. \ref{mc174}.
\end{rem}





\begin{pp}\label{mc176}
Let $(M,\gk)$ be Riemannian. For each alternating tensor field $\fk X:M\rightarrow\bwn^kTM$, let $\Theta_M\fk X:M\rightarrow\bwn^kT^*M$ send each $\fk X|_p$ to $\Theta_{\bwn^kT_pM}\fk X|_p$ where $\Theta_{\bwn^kT_pM}:\bwn^kT_pM\rightarrow\bwn^kT_p^*M$ is the Riesz isomorphism. Then $\fk X$ is $C^r$ (resp. Borel) iff $\Theta_M\fk X$ is $C^r$ (resp. Borel).
\end{pp}

Note that $\Theta_{\bwn^kT_pM}=(\Theta_{T_pM})^{\wedge k}$ by Thm. \ref{mc149}. We abbreviate $\Theta_M$ to $\Theta$ when no confusion arises, \index{zz@$\Theta_M$} and call $\Theta_M$ the \textbf{Riesz isomorphism} of $(M,\gk)$. \index{00@Riesz isomorphisms of Riemannian $\partial$-manifolds}

\begin{proof}
It suffices to check the claim locally. Let $(U,\varphi^1,\dots,\varphi^n)$ be a chart on $M$. Let $G=[\gk(\partial_\varphi\otimes\partial_\varphi)]:U\rightarrow\Rbb^{n\times n}$ be the function of Gram matrices. By Prop. \ref{mc146}, $G$ is the matrix representation of the Riesz isomorphism, i.e., $\Theta(\partial_{\varphi^1},\dots,\partial_{\varphi^n})=(d\varphi^1,\dots,d\varphi^n)G$. Thus, by Thm. \ref{mc140}, for each $i_1<\cdots<i_k$ we have
\begin{align*}
\Theta_M(\partial_{\varphi^{i_1}}\wedge\cdots\wedge\partial_{\varphi^{i_k}})=\sum_{j_1<\cdots<j_k} f_{j_1,\dots,j_k}d\varphi^{j_1}\wedge\cdots\wedge d\varphi^{j_k}
\end{align*}
where each $f_{j_1,\dots,j_k}$ is a minor of $G$ and hence is smooth. Therefore $\Theta_M(\partial_{\varphi^{i_1}}\wedge\cdots\wedge\partial_{\varphi^{i_k}})$ is smooth. Similarly, since $G^{-1}$ is smooth, its minors are smooth, and hence each $\Theta_M^{-1}(d\varphi^{j_1}\wedge\cdots\wedge d\varphi^{j_k})$ is smooth. The claim of the proposition now follows immediately. 
\end{proof}






\subsection{Oriented manifolds}



Fix a smooth equidimensional $\partial$-manifold $M$. If $\omega:M\rightarrow \bwn^kT^*M$ is a differential form, we say that $\omega$ is \textbf{nowhere zero} if $\omega|_p\neq0$ for each $p\in M$.




\begin{df}
Assume that $\dim M=n$. We call a nowhere zero differential $n$-form $\omega:M\rightarrow \bwn^nT^*M$ an \textbf{orientation form}. \index{00@Orientation form} Two orientation forms $\omega$ and $\eta$ on $M$ are said to have the \textbf{same orientation} \index{00@Orientation of a $\partial$-manifold} if $\omega/\eta>0$ everywhere on $M$. An equivalence class $\mc O$ of \uwave{continuous} orientation forms having the same orientation is called an \textbf{orientation} of $M$. The data $(M,\mc O)$ is called a \textbf{smooth oriented $\pmb\partial$-manifold}. If $\omega$ is a continuous orientation form on $M$ whose equivalence class is $\mc O$, we let $-\mc O$ denote the equivalence class of $-\omega$ and call it the \textbf{negative orientation} or \textbf{opposite orientation} of $\mc O$. An orientation form $\omega$ is called \textbf{positive} (with respect to $\mc O$) if $\omega$ represents $\mc O$.

In the special case that $\dim M=0$, an orientation $\mc O$ on $M$ is understood to be a map $\mc O:M\rightarrow\{\pm1\}$.\hfill\qedsymbol
\end{df}

Note that a $\partial$-manifold $M$ does not necessarily have an orientation. We say that $M$ is \textbf{orientable} \index{00@Orientable $\partial$-manifold} if there exists an orientation on $M$.

\begin{cv}
Let $M$ be a smooth oriented $\partial$-manifold. By writing
\begin{align*}
N=-M
\end{align*}
we mean that $N$ is the same smooth $\partial$-manifold as $M$, but that the orientation of $N$ is the negative of that of $M$.
\end{cv}


\begin{df}
Let $(M,\mc O)$ be a smooth oriented $\partial$-manifold. Then for each $p\in M$, $T_p^*M$ has an orientation defined by $\omega|_p$ where $\omega$ is any continuous orientation form of $(M,\mc O)$. This in turn defines an orientation on $T_pM$ as in Def. \ref{mc156}. The orientations of $T_pM$ and $T_p^*M$ are both denoted by $\mc O_p$ \index{Op@$\mc O_p$, the orientation $\mc O$ at $p$}, called the \textbf{orientation of $\pmb M$ at $\pmb p$}. \index{00@Orientation at a point}
\end{df}


\begin{rem}
Let $\dim M=n$. Let $r\in\Nbb\cup\{\infty\}$. Let $\omega:M\rightarrow\bwn^nT^*M$ be an orientation form. Choose an arbitrary Riemannian metric $\gk$ on $M$ (which exists by Thm. \ref{mc109}), which gives a Riesz isomorphism $\Theta:\bwn^nTM\rightarrow\bwn^nT^*M$. Then by Prop. \ref{mc176}, $\omega$ is $C^r$ iff $\fk X:=\Theta^{-1}\omega$ is $C^r$. By Rem. \ref{mc175}, for each $p\in M$, $\omega|_p$ belongs to an orientation of $T^*_pM$ iff $\Theta^{-1}\omega|_p$ belongs to the dual orientation of $T_pM$. Therefore, an orientation $\mc O$ on $M$ can be described equivalently by a nowhere zero continuous alternating tensor field $\fk X:M\rightarrow\bwn^nTM$. In fact, this alternating tensor field can be smooth, cf. Cor. \ref{mc166}.
\end{rem}

Most people prefer to define orientations in terms of differential forms but not contravariant alternating tensor fields because the former has applications beyond orientations. However, contravariant alternating tensor fields are more intuitive than orientation forms: it describes a frame (i.e. a basis of tangent vectors) moving continuously (or smoothly) along the manifold. 

Many of the following properties about orientations can be studied both by differential forms and by contravariant alternating tensor fields. We use the former to study orientations because this approach is used by many authors, and also because some of the byproducts (e.g., the volume forms) are useful in the future. The readers can try to prove these properties by using contravariant alternating tensor fields.



\begin{pp}\label{mc164}
Suppose that $(M,\mc O)$ is connected and oriented. Then $M$ has exactly two orientations, which are $\mc O$ and $-\mc O$.
\end{pp}

\begin{proof}
Let $\omega$ be an orientation form representing $\mc O$. Let $\eta$ be another orientation form. Then $\eta/\omega$ is a continuous nowhere zero function on $M$, which must be either always positive or always negative since $M$ is connected. So either $\eta$ belongs to $\mc O$ or $\eta$ belongs to $-\mc O$.
\end{proof}

Proving the that $M$ is orientable is not easy. However, suppose we already know that $M$ is orientable, then it is relatively easier to determine the orientation. Let $n=\dim M$. By restricting to each connected component, we assume WLOG that $M$ is connected. Then, by Prop. \ref{mc164}, $M$ has two orientations. To determine which one is the correct one, it suffices to pick any $p\in M$, and find the element in $\bwn^nT_pM$ or in $\bwn^nT^*_pM$ that represents the orientation.


%% Record #26 2024/05/30 Three lectures  64


\begin{df}\label{mc157}
Let $(M,\mc O)$ be oriented and $\dim M=n$. Let $\Omega\subset M$. Assume that either $\Omega$ is open in $M$, or $\partial M=\emptyset$ and $\Omega$ is an $n$-dimensional smooth $\partial$-submanifold of $M$. Then $\mc O$ restricts to an orientation $\mc O|_\Omega$ on $\Omega$ such that for any continuous orientation form $\omega$ on $M$ in the orientation $\mc O$, $\omega|_\Omega=\iota^*\omega$ (where $\iota:\Omega\rightarrow M$ is the inclusion map) is an orientation form on $\Omega$ in $\mc O|_\Omega$. We call $\mc O|_\Omega$ the \textbf{restriction of the orientation} $\mc O$ to $\Omega$. \index{00@Restriction of orientation} Unless otherwise stated, the orientation of $\Omega$ is always chosen to be $\mc O|_\Omega$. 
\end{df}

\begin{eg}
Suppose that $\Omega$ is an $n$-dimensional smooth $\partial$-submanifold of $\Rbb^n$. The canonical orientation on $\Omega$ is the one of $dx^1\wedge\cdots\wedge dx^n$. 
\end{eg}
 
\begin{eg}\label{mc219}
Let $(M_1,\mc O_1),\dots,(M_k,\mc O_k)$ be smooth oriented equidimensional $\partial$-manifolds. Assume that at most one of $M_1,\dots,M_k$ has nonempty boundary. Then there is a unique orientation $O$ on $M=M_1\times\cdots\times M_k$ satisfying the following property: For each $i$, let $\pi_i:M\rightarrow M_i$ be the projection, and choose any continuous (positive) orientation form $\omega_i$ of $(M_i,\mc O_i)$. Then $\omega=(\pi_1^*\omega_1)\wedge\cdots\wedge(\pi_k^*\omega_k)$ is a continuous (positive) orientation form of $(M,\mc O)$. We call $\mc O$ the \textbf{product} of $\mc O_1,\dots,\mc O_k$ and write it as $\mc O_1\times\cdots\times \mc O_k$. We call $(M_1\times\cdots\times M_k,\mc O_1\times\cdots\times\mc O_k)$ the \textbf{product of the smooth oriented $\pmb\partial$-manifolds} \index{00@Product of orientated manifolds} $(M_1,\mc O_1),\dots,(M_k,\mc O_k)$.
\end{eg}

\begin{exe}
Let $M,N$ be smooth oriented $\partial$-manifolds of dimensions $m,n$ respectively. Assume that $\partial M=\emptyset$ or $\partial N=\emptyset$. Note that $M\times N$ can be identified with $N\times M$ as smooth $\partial$-manifolds. Prove that
\begin{align}
M\times N=(-1)^{mn}N\times M
\end{align}
i.e., $M\times N$ and $N\times M$ have the same orientation iff $mn$ is even.
\end{exe}


\begin{df}
Let $F:M\rightarrow N$ be a diffeomorphism of smooth $\partial$-manifolds with dimension $n$. Let $G$ be its inverse. Let $\mc O$ be an orientation of $M$. Choose any continuous positive orientation form $\omega$ of $(M,\mc O)$. Then $G^*\omega=F_*\omega$ defines an orientation
\begin{align*}
G^*\mc O\equiv F_*\mc O
\end{align*}
on $N$, called the \textbf{pullback orientation} \index{00@Pullback orientation} of $\mc O$ by $G$, also called the \textbf{pushforward orientation} \index{00@Pushforward orientation} of $\mc O$ by $F$.
\end{df}


\begin{eg}
If $M$ can be covered by a single chart $(U,\varphi^1,\dots,\varphi^n)$, then $M$ is orientable, since the pullback of the standard orientation on $\Rbb^n$ by $\varphi$ is an orientation on $M$.
\end{eg}


\begin{df}
Let $F:(M,\mc O_M)\rightarrow (N,\mc O_N)$ be a smooth immersion where $\dim M=\dim N=n$. (Then $dF$ is invertible everywhere.) We say that $F$ is \textbf{orientation preserving} (resp. \textbf{reversing}) \index{00@Orientation preserving/reversing} if $F^*\mc O_N=\mc O_M$ (resp. $F^*\mc O_N=-\mc O_M$).
\end{df}



\begin{df}\label{mc163}
Let $(U,\varphi^1,\dots,\varphi^n)$ be a chart on $M$. The \textbf{chart orientation} \index{00@Chart orientation} of $(U,\varphi)$ (or simply, the chart orientation of $U$) is defined to be the pullback of the standard orientation $dx^1\wedge\cdots\wedge dx^n$ on $\varphi(U)$ by $\varphi$. In other words, it is the orientation of $d\varphi^1\wedge\cdots\wedge d\varphi^n$ (since $\varphi^*dx^i=d\varphi^i$). For each $p$, $\mc O_p$ is the orientation of $d\varphi^1\wedge\cdots\wedge d\varphi^n$ and also of $\partial_{\varphi^1}\wedge\cdots\wedge\partial_{\varphi^n}$.
\end{df}





\subsection{Gluing orientations}


Fix a smooth equidimensional $\partial$-manifold $M$.

\subsubsection{Volume forms and the locality principle}




\begin{thm}\label{mc165}
Assume that $(M,\gk,\mc O)$ is an $n$-dimensional oriented Riemannian $\partial$-manifold. Then there exists a unique smooth orientation form $\varpi_\gk:M\rightarrow\bwn^nT^*M$ in $\mc O$ such that for each $p\in M$, $\varpi_\gk|_p$ is the volume tensor of $(T_p^*M,\gk^*)$ in $\mc O_p$ (cf. Def. \ref{mc160}). We call $\varpi_\gk$ the \textbf{volume form} \index{00@Volume form} of $M$.
\end{thm}


In other words, $\varpi_\gk$ satisfies that for each $p\in M$, $\varpi_\gk|_p$ is in $\mc O_p$, and
\begin{align}
\bk{\varpi_\gk,\varpi_{\gk}}=1
\end{align}
where the inner product of $\bwn^nT^*_pM$ is defined as in Conv. \ref{mc159}. 

We shall prove Thm. \ref{mc165} together with the following locality principle:


\begin{thm}\label{mc161}
Let $\fk U$ be an open cover of $M$ such that for each $U\in\fk U$, an orientation $\mc O_U$ is chosen. Suppose that for each $U,V\in\fk U$, $\mc O_U$ and $\mc O_V$ are \textbf{orientation-compatible} \index{00@Orientation compatible} in the sense that $\mc O_U|_p=\mc O_V|_p$ for each $p\in U\cap V$. Then there exists a unique orientation $\mc O$ on $M$ such that the restriction $\mc O|_U$ equals $\mc O_U$ for each $U\in\fk U$.
\end{thm}

Note that if $U\cap V=\emptyset$, then any orientation on $U$ is compatible with any orientation on $V$.

\begin{proof}[\textbf{Proof of Thm. \ref{mc165} and \ref{mc161}}]
The uniqueness in Thm. \ref{mc165} is obvious since the volume tensors of $(T_p^*M,\gk^*,\mc O_p)$ are unique. The uniqueness in Thm. \ref{mc161} is also clear since $\mc O$ is determined by $\mc O_p$ for each $p\in M$. 

Let $M$ satisfy the assumptions in Thm. \ref{mc161}. By Thm. \ref{mc109}, there is a Riemannian metric $\gk$ on $M$. Let us fix this metric. We claim that there exists a smooth orientation form $\varpi_\gk:M\rightarrow\bwn^nT^*M$ satisfying the following properties:
\begin{itemize}
\item For each $U\in\fk U$, $\varpi_\gk|_U$ is in the orientation $\mc O_U$.
\item For each $p\in M$, $\varpi_\gk|_p$ has length $1$.
\end{itemize}
Then $\varpi_\gk$ gives an orientation $\mc O$ on $M$ restricting to $\mc O_U$ for each $U$, and $\varpi_\gk$ is clearly the volume form of $(M,\gk,\mc O)$. Hence Thm. \ref{mc161} is proved. Thm. \ref{mc165} is also proved by choosing $\fk U=\{M\}$.

Let us prove the claim. Define $\varpi_\gk:M\rightarrow\bwn^nT^*M$ in the following way. For each $p\in M$, choose $U\in\fk U$ containing $p$, and let $\varpi_\gk|_p$ be the unique volume tensor of $(T^*M,\gk^*)$ in the orientation $\mc O_U|_p$. This definition is independent of the choice of $U$ by the assumption on orientation-compatibility. We only need to show that $\omega$ is smooth. 

Choose $p\in M$. Let us prove that $\omega$ is smooth on a neighborhood $V$ of $p$. Choose $U\in\fk U$ containing $p$. Choose a chart $(V,\varphi^1,\dots,\varphi^n)$ on $M$ such that $p\in V\subset U$ and $V$ is connected. By Prop. \ref{mc164}, $V$ has exactly two orientations: the chart orientation $\scr O_V$ (cf. Def. \ref{mc163}) or its inverse. Note that $\mc O_U|_V$ is also an orientation on $V$. Therefore, $\scr O_V=\pm\mc O_U|_V$. Thus $\pm d\varphi^1\wedge\cdots \wedge d\varphi^n$ is a smooth positive orientation form of $(V,\mc O_U|_V)$.  Then by Prop. \ref{mc162}, we have
\begin{align}\label{eq520}
\tcboxmath{\varpi_\gk|_V=\pm\sqrt {\det[\gk(\partial_\varphi\otimes\partial_\varphi)]}\cdot d\varphi^1\wedge\cdots\wedge d\varphi^n}
\end{align}
where $[\gk(\partial_\varphi\otimes\partial_\varphi)]:V\rightarrow \Rbb_{\geq0}$ is the Gram matrix function of $\gk$ under $\partial_{\varphi^1},\dots,\partial_{\varphi^n}$. Since  $\gk:M\rightarrow \bigotimes\nolimits^2T^*M$ is smooth,  $[\gk(\partial_\varphi\otimes\partial_\varphi)]$ is smooth. Therefore $\varpi_\gk|_V$ is smooth.
\end{proof}

From the above proof we clearly have:
\begin{co}\label{mc229}
Let $(M,\gk,\mc O_M)$ be a smooth oriented Riemannian $\partial$-manifold. Let $\varpi_\gk$ be its volume form. Let $(V,\varphi^1,\dots,\varphi^n)$ be a chart on $M$ whose chart orientation is $\pm\mc O_M|_V$. Then $\varpi_\gk$ satisfies \eqref{eq520}.
\end{co}




\begin{co}\label{mc166}
Assume that $\mc O$ is an orientation of $M$. Then there is a smooth positive orientation form $\omega$ of $(M,\mc O)$. 
\end{co}

\begin{proof}
By Thm. \ref{mc109}, there is a Riemannian metric $\gk$ on $M$. Then the volume form of $(M,\gk,\mc O)$ is a smooth positive orientation form on $(M,\mc O)$. 
\end{proof}








\subsubsection{Applications of the locality principle}


We shall apply the locality principle to an atlas $\fk U$ of $M$. Then we need to know when two charts in $\fk U$ are orientation-compatible. Suppose that $(U,\varphi^1,\dots,\varphi^n)$ and $(V,\psi^1,\dots,\psi^n)$ are two charts on $M$. Recall from Cor. \ref{mc154} that on $U\cap V$ we have
\begin{align*}
(\partial_{\varphi^1},\dots,\partial_{\varphi^n})=(\partial_{\psi^1},\dots,\partial_{\psi^n})\cdot\Jac_\varphi\psi
\end{align*}
where $\Jac_\varphi\psi:U\cap V\rightarrow\Rbb^{n\times n}$ is defined by \eqref{eq518}, i.e., its $i\times j$ entry is $\partial_{\varphi^j}\psi^i=(\partial_j(\psi^i\circ\varphi^{-1}))\circ\varphi$. Therefore, by Cor. \ref{mc141} and \ref{mc145}, we have
\begin{align}\label{eq519}
\frac{\partial_{\varphi^1}\wedge\cdots\wedge\partial_{\varphi^n}}{\partial_{\psi^1}\wedge\cdots\wedge\partial_{\psi^n}}=\frac{d\psi^1\wedge\cdots\wedge d\psi^n}{d\varphi^1\wedge\cdots\wedge d\varphi^n}=\det\Jac_\varphi\psi
\end{align}
Hence we have:

\begin{pp}\label{mc169}
Let $(U,\varphi^1,\dots,\varphi^n)$ and $(V,\psi^1,\dots,\psi^n)$ be charts on $M$, equipped with the chart orientations $\mc O_U,\mc O_V$ (Def. \ref{mc163}). Then the following are equivalent.
\begin{enumerate}
\item[(1)] $\mc O_U$ and $\mc O_V$ are \textbf{orientation-compatible}, i.e., for each $p\in U\cap V$ we have $\mc O_U|_p=\mc O_V|_p$.
\item[(2)] At each $p\in U\cap V$, $d\varphi^1\wedge\cdots\wedge d\varphi^n$ and $d\psi^1\wedge\cdots\wedge d\psi^n$ have the same orientation.
\item[(3)] At each $p\in U\cap V$, $\partial_{\varphi^1}\wedge\cdots\wedge\partial_{\varphi^n}$ and $\partial_{\psi^1}\wedge\cdots\wedge\partial_{\psi^n}$ have the same orientation.
\item[(4)] $\Jbf_\varphi\psi:=\det\Jac_\varphi\psi$ is always $>0$ on $U\cap V$.
\end{enumerate}
\end{pp}


\begin{proof}
(2) is simply a restatement of (1). So they are clearly equivalent. By \eqref{eq519}, the conditions (2), (3), (4) are equivalent.
\end{proof}

\begin{df}
Let $(M,\mc O)$ be oriented. A chart $(U,\varphi^1,\dots,\varphi^n)$ on $M$ is called a \textbf{positively oriented} (or simply \textbf{positive}) \index{00@Positive chart/positively oriented chart} if the chart orientation on $U$ is equal to $\mc O|_U$, equivalently, if $\varphi|_U:U\rightarrow\Rbb^n$ is orientation preserving. An atlas $\fk U$ such that all $(U,\varphi)$ in $\fk U$ are positive is called a \textbf{positively oriented atlas} (or simply a \textbf{positive atlas}). \index{00@Positive atlas/positively oriented atlas}
\end{df}


\begin{co}\label{mc168}
Suppose that $\fk U$ is an atlas such that any two members of $\fk U$ are orientation-compatible. Then there is a unique orientation $\mc O$ on $M$ such that $\fk U$ is a positive atlas of $(M,\mc O)$.

Conversely, if $(M,\mc O)$ is oriented and $\dim M>1$, then all positive charts form a positive atlas $\fk U$. In particular, any two members of $\fk U$ are orientation-compatible. 
\end{co}

Note that $[0,1]$ (with the standard orientation) does not have a positive atlas.

\begin{proof}
The first part follows immediately from Thm. \ref{mc161}. If $(M,\mc O)$ is oriented and $n>1$, to show that the set $\fk U$ of all positive charts form an atlas, it suffices to show that they cover $M$. This is easy: For any $p\in M$, choose a chart $(U,\varphi^1,\dots,\varphi^n)$ where $U$ is connected. Then the chart coordinate of $U$ is either $\mc O|_U$ or $-\mc O|_U$. Thus, replacing $\varphi^n$ by $-\varphi^n$ if necessary, we get a positive chart $(U,\varphi^1,\dots,\varphi^n)$ covering $p$. (Here, we have used the fact that $n>1$. If $n=1$, then $(U,-\varphi^1)$ is not a chart since its range is not in $\Hbb^1$.)
\end{proof}



\begin{exe}
Let $(U,\varphi^1,\dots,\varphi^n)$ and $(V,\psi^1,\dots,\psi^n)$ be two charts on $M$. Assume that $U$ and $V$ are both connected. Let $\mc O_U$ and $\mc O_V$ be orientations of $U$ and $V$ respectively. Suppose that there exist distinct $p,q\in U\cap V$ such that $\mc O_U|_p=\mc O_V|_p$ and $\mc O_U|_q=-\mc O_V|_q$. Prove that $M$ is not orientable. Use this fact to give a heuristic explanation of why the M\"obius strip (defined by gluing two pieces of open rectangles) is not orientable.
\end{exe}



\subsection{Boundary and hypersurface orientations}

Fix a smooth equidimensional $\partial$-manifold $M$. Recall Def. \ref{mc167} for the meaning of inward-pointing and outward-pointing vectors. 

\begin{rem}\label{mc173}
Let $W$ be a finite dimensional real vector space, and let $V$ be a linear subspace of $W$. If we let $\iota:V\rightarrow W$ denote the inclusion map, then $\wedge^k\iota:\bwn^kV\rightarrow\bwn^kW$ is injective (cf. Rem. \ref{mc172}). Therefore, $\bwn^kV$ can naturally be viewed as a linear subspace of $\bwn^kW$ by means of $\wedge^k\iota$. 

In addition, assume that $W$ is a real inner product space and the inner product on $V$ is inherited from that of $W$, then by Thm. \ref{mc149}, $\wedge^k\iota$ sends an orthonormal basis of $\bwn^kV$ to a collection of orthonormal vectors in $\bwn^kW$. Therefore $\wedge^k\iota$ is an isometry, and hence $\bwn^kV$ can be viewed as an inner product subspace of $\bwn^kW$ via $\wedge^k\iota$.

Now, suppose that either $\partial M=\emptyset$ and $P$ is a smooth $\partial$-submanifold of $M$, or $P=\partial M$. From the above discussion, it is clear that for each $p\in P$, $\bwn^kT_pP$ can be viewed naturally as a linear subspace of $\bwn^kT_pM$. Moreover, if $(M,\gk)$ is Riemannian, then  $\bwn^kT_pP$ can be viewed naturally as an inner product subspace of $\bwn^kT_pM$.  \hfill\qedsymbol
\end{rem}



\subsubsection{The orientability of hypersurfaces}

In this subsection, we give one of the most important criteria for the orientability of hypersurfaces, namely, that the boundary of an oriented smooth $\partial$-manifold is orientable. Another important criterion (in terms of nowhere-tangent vector fields) will be given in Cor. \ref{mc213}.




\begin{thm}\label{mc170}
Let $(M,\mc O)$ be oriented and $n=\dim M\geq 1$. Then there exists a unique orientation $\partial\mc O\equiv\mc O_{\partial M}$ on $\partial M$ (called the \textbf{boundary orientation} \index{00@Boundary orientation} or \textbf{outward orientation}) satisfying the following properties:
\begin{itemize}
\item[(a)] If $n>1$ and $(U,\varphi^1,\dots,\varphi^n)$ is a positive chart of $(M,\mc O)$, then $(U\cap \partial M,\varphi^2,\dots,\varphi^n)$ is a \uwave{negative} chart of $(\partial M,\partial\mc O)$.
\item[(b)] If $n=1$ and $(U,\varphi)$ is a positive (resp. negative) chart of $(M,\mc O)$, then for each $p\in U\cap\partial M$ we have $\partial\mc O|_p=-1$ (resp. $\partial\mc O|_p=1$).
\end{itemize}
\end{thm}

The reason for choosing the boundary orientation in this way will be clear in the proof of Stokes' theorem.

\begin{proof}
The uniqueness is obvious. Let us prove the existence assuming $n>1$; the case $n=1$ is easier and is left to the readers. By Cor. \ref{mc168}, the set of all positive charts of $(M,\mc O)$ form an atlas $\fk U$ on $M$. Let $\partial\fk U$ be the set of all $(\partial U,\varphi^2,\dots,\varphi^n)$ where $(U,\varphi^1,\dots,\varphi^n)\in\fk U$. Then $\partial\fk U$ is clearly an atlas on $\partial M$. Let us show that $\partial\fk U$ is orientation-compatible; then Cor. \ref{mc168} will imply that $\partial M$ has an orientation $\partial\mc O$ under which every chart of $\partial\fk U$ is \textit{negatively} oriented. This will finish the proof.

Let $(U,\varphi),(V,\psi)\in\fk U$ such that $\partial U\cap\partial V\neq\emptyset$. Let $\wtd\varphi=(\varphi^2,\dots,\varphi^n)$ and $\wtd\psi=(\psi^2,\dots,\psi^n)$. By Prop. \ref{mc169}, it suffices to show that the determinant of $\partial_{\wtd\varphi}\wtd\psi$ is $>0$ on the boundary of $D=U\cap V$. Equivalently, if we let $F=\psi\circ\varphi^{-1}:\varphi(D)\rightarrow\psi(D)$, then we need to show that $(\Jac F)_{2,\dots,n}^{2,\dots,n}$ has strictly positive determinant at every $p\in\varphi(D)\cap\partial\Hbb^n$. Write $F=(F^1,F^2,\cdots F^n)$ and let $\wtd F=(F^2,\dots,F^n)$.  By Lem. \ref{lb993}, we see that $F$ maps points of $\partial\Hbb^n$ to points of $\partial\Hbb^n$, and that $\partial_1F^1\geq0$ on boundary points. Therefore, at $p$, $\Jac F$ is of the form
\begin{align*}
\Jac F=\begin{pmatrix}
\partial_1F^1 &0\\
\partial_1\wtd F&\Jac_{x^2,\dots,x^n}\wtd F
\end{pmatrix}
\end{align*}
By Prop. \ref{mc169}, $\det\Jac F|_p>0$. Therefore, the determinant of $(\Jac F)_{2,\dots,n}^{2,\dots,n}=\Jac_{x^2,\dots,x^n}\wtd F$ must $>0$ at $p$.
\end{proof}

\begin{eg}\label{mc171}
Let $\Omega$ be an open subset of $\Hbb^n$, equipped with the standard orientation $dx^1\wedge\cdots\wedge dx^n$. By Thm. \ref{mc170}, the boundary orientation of $\partial\Omega=\Omega\cap\partial\Hbb^n$ is that of $-dx^2\wedge\cdots \wedge dx^n$ (equivalently, that of $-\partial_{x^2}\wedge\cdots\wedge\partial_{x^n}$) if $n>1$, and is $-1$ if $n=1$.
\end{eg}


\begin{co}
Suppose that $(M,\mc O)$ is oriented and $\partial M=\emptyset$. Let $f\in C^\infty(M,\Rbb)$. Assume that $df$ is surjective at each $p\in Z(f)=f^{-1}(0)$. Then $Z(f)=f^{-1}(0)$ is a smooth orientable submanifold of $M$.  
\end{co}


\begin{proof}
Let $n=\dim M$. By shrinking $M$ to an open subset containing $Z(f)$, we may assume that $df$ is surjective everywhere. By the geometric implicit function Thm. \ref{lb999}, $P=f^{-1}[0,+\infty)$ is an $n$-dimensional smooth $\partial$-submanifold of $M$ with boundary $Z(f)$. Since $P$ has an orientation $\mc O|_P$, by Thm. \ref{mc170}, $Z(f)$ is orientable.
\end{proof}


\begin{sexe}
Suppose that $(M,\mc O)$ is oriented and $\partial M=0$. Let $F\in C^\infty(M,\Rbb^k)$ where $k\in\Zbb_+$. Assume that $dF$ is surjective at each $p\in Z(F)=F^{-1}(0)$. Prove that $Z(F)$ is a smooth orientable submanifold of $M$.  
\end{sexe}

\begin{proof}[Hint]
Shrink $M$ so that $dF$ is surjective everywhere. Write $F=(F^1,\dots,F^k)$. By using Exe. \ref{mc7} on transversal intersections, prove inductively that $S_{i-1}=Z(F^1,\dots,F^{i-1})\cap (F^i)^{-1}[0,+\infty)$ is a smooth oriented $\partial$-submanifold of $M$ with boundary $P_i=Z(F^1,\dots,F^i)$.
\end{proof}



\subsubsection{Determining the orientations of hypersurfaces}

Thm. \ref{mc170} is useful for proving that a manifold is orientable. However, the following theorem is more helpful for intuitively understanding the boundary orientations.


%Tangent vectors and their exterior product often make it easier for us to see the orientations than differential forms. In the following theorem, we describe the boundary orientation in terms of tangent vectors. Following the convention in Rem. \ref{mc173}, we view $\bwn^kT_p\partial M$ as a linear subspace of $\bwn^kT_pM$.


\begin{thm}\label{mc177}
Let $(M,\mc O)$ be oriented and $n=\dim M\geq 2$. Assume $p\in\partial M$. Let $\xi_1\in T_pM$ be \uwave{outward-pointing}. Then $\partial\mc O_p$ is represented by $\xi_2\wedge\cdots\wedge\xi_n\in\bwn^{n-1}T_p\partial M$ for any $\xi_2,\dots,\xi_n\in T_p\partial M$ such that $\xi_1\wedge\xi_2\wedge\dots\wedge\xi_n$ is nonzero and belongs to $\mc O_p$. In other words,
\begin{align*}
\xi_1\wedge\partial \mc O_p=\mc O_p
\end{align*}
\end{thm}

See Fig. \ref{mc178} for a picture explanation. When $\dim M=2,3$, the orientation of $M$ in Fig. \ref{mc178} is that of $\partial_{x^1}\wedge \partial_{x^2}$ resp. $\partial_{x^1}\wedge \partial_{x^2}\wedge\partial_{x^3}$.

\begin{proof}
Since the problem is local, by shrinking $M$ to a neighborhood of $p$, we assume WLOG that $M$ is an open subset of $\Hbb^n$, and that (by Cor. \ref{mc168}) $\mc O$ is the restriction of the standard orientation of $\Hbb^n$, i.e., the one of $dx^1\wedge\cdots\wedge dx^n$. Then $T_pM=\Rbb^n$ and $T_p\partial M=\{0\}\times\Rbb^{n-1}\simeq\Rbb^{n-1}$.


We shall prove that if $\Uppsi=\xi_2\wedge\cdots\wedge\xi_n$ represents $\partial\mc O_p$ then $\xi_1\wedge\Uppsi$ represents $\mc O_p$. It will follow that $\xi_1\wedge\Uppsi$ represents $-\mc O_p$ if $\Uppsi$ represents $-\partial\mc O_p$, and it is clear that $\xi_1\wedge\Uppsi=0$ if $\Uppsi=0$. This will finish the proof.

Let $e_1=\partial_{x^1},\dots,e_n=\partial_{x^n}$ be the standard basis vectors of $\Rbb^n$. According to Exp. \ref{mc171}, $\partial\mc O_p$ is represented by $-e_2\wedge\cdots\wedge e_n\in\bwn^{n-1}\Rbb^{n-1}$. Let $\Uppsi=\xi_2\wedge\cdots\wedge\xi_n$ also represent $\partial\mc O_p$. Then $\Uppsi=-\lambda e_2\wedge\cdots\wedge e_n\in\bwn^{n-1}\Rbb^{n-1}$ where $\lambda>0$. Since $\xi$ is outward pointing, we have $\xi_1=-\kappa e_1+*e_2+\cdots+*e_n$ for some $\kappa>0$. Then it is clear that $\xi_1\wedge\Uppsi=\kappa \lambda e_1\wedge\cdots\wedge e_n$, which is in $\mc O_p$.
\end{proof}
\begin{figure}
\begin{equation*}
\vcenter{\hbox{{
			\includegraphics[height=3cm]{fig13.png}}}}
\end{equation*}
	\caption{. Boundary orientations}\label{mc178}
\end{figure}


Thm. \ref{mc177} motivates the following definitions:

\begin{df}\label{mc197}
Let $(W,\mc O_W)$ be an $n$-dimensional oriented real vector space where $n\geq2$. Let $V$ be a \textbf{hyperplane}, \index{00@Hyperplane} i.e., an $(n-1)$-dimensional linear subspace of $W$. Let $\xi\in W\setminus V$. Then the \textbf{hyperplane orientation} \index{00@Hyperplane orientation} of $V$ determined by $\xi$ (and $(W,\mc O_W)$) is the unique orientation $\mc O_V$ such that for any $\Uppsi\in\bwn^{n-1}V$ in $\mc O_V$, $\xi\wedge\Uppsi$ is in the orientation $\mc O_W$. We abbreviate this condition to
\begin{align}
\xi\wedge\mc O_V=\mc O_W
\end{align}
\end{df}

We leave it to the readers to check that the notion of hyperplane orientations is well-defined.

\begin{df}
Let $(M,\mc O_M)$ be oriented and $n=\dim M\geq2$. Assume that either $S=\partial M$, or $\partial M=\emptyset$ and $S$ is a smooth orientable $\partial$-submanifold of $M$. Assume that $S$ is connected (so that $S$ has exactly two orientations) and $\dim S=n-1$. Let $p\in S$ and $\xi\in T_pM\setminus T_pS$. Then the \textbf{hypersurface orientation} \index{00@Hypersurface orientations} of $S$ determined by $\xi$ is the unique orientation $\mc O_S$ on $S$ such that $\mc O_S|_p$ is the hyperplane orientation of $T_pS$ (viewed as a subspace of $T_pM$) determined by $\xi$ (and $(M,\mc O_M)$), i.e.,
\begin{align*}
\xi\wedge \mc O_S|_p=\mc O_M|_p
\end{align*}
\end{df}



%% Record #27 2024/06/03 Two lectures  66



Let us consider the following problem. Suppose that $(M,\mc O_M)$ is oriented and $n=\dim M\geq2$. Suppose that we have a chart on $S:=\partial M$. How to determine whether a chart on $S$ is positive or negative? Since $M$ is locally and (orientation-)positively diffeomorphic to an $n$-dimensional smooth $\partial$-submanifold of $\Rbb^n$, $S$ is can be viewed locally as an $(n-1)$-dimensional smooth submanifold of $\Rbb^n$, and an outward pointing vector $\xi\in T_pS$ can be viewed as a vector in $\Rbb^n$. Equip $S$ with the hypersurface orientation determined by $\xi$ with respect to $\Rbb^n$. Let $(U,\varphi)$ be a chart on $S$ containing $p$. The question then is how to determine whether $(U,\varphi)$ is a positive chart. The following proposition answers this question.

\begin{pp}\label{mc179}
Let $n\geq2$. Let $\Omega$ be a connected smooth $(n-1)$-dimensional $\partial$-submanifold of $\Rbb^{n-1}$, equipped with the standard orientation $\mc O_\Omega$. Let $F:\Omega\rightarrow \Rbb^n$ be a smooth embedding, and let $S=F(\Omega)$. Let $p\in\Omega$ and $q=F(p)$. Let $\xi\in\Rbb^n\setminus T_qS$. Let $\mc O_S$ be the hypersurface orientation determined by $\xi$. Then the following are equivalent.
\begin{enumerate}
\item[(1)] $F:\Omega\rightarrow S$ is orientation preserving, i.e., $F_*\mc O_\Omega=\mc O_S$.
\item[(2)] We have
\begin{align}
\det (\xi,\Jac F|_p)>0
\end{align}
\end{enumerate}
\end{pp}

Note that $\Jac F|_p$ is an $n\times (n-1)$ matrix, and hence $(\xi,\Jac F|_p)$ is $n\times n$. 


\begin{proof}
Since $\Omega$ and $S$ are connected, either $F_*\mc O_\Omega=\mc O_S$ or $F_*\mc O_\Omega=-\mc O_S$. Since $\mc O_\Omega$ is given by $\partial_{x^1}\wedge\cdots\wedge\partial_{x^{n-1}}$, and since $dF\cdot \partial_{x^i}=\partial_iF$, we see that $F_*\mc O_\Omega$ is given by $\partial_1F\wedge\cdots\wedge \partial_{n-1}F$. By the definition of hyperplane/hypersurface orientation, $\partial_1F(p)\wedge\cdots\wedge \partial_{n-1}F(p)$ is in the orientation $\mc O_S|_q$ iff $\xi\wedge\partial_1F(p)\wedge\cdots\wedge \partial_{n-1}F(p)$ is in the standard orientation $e_1\wedge\cdots\wedge e_n$ of $\Rbb^n$ (where $e_1,\dots,e_n$ are the standard basis of $\Rbb^n$). Let $A=(\xi,\Jac F|_p)\in\Rbb^{n\times n}$, There clearly
\begin{align*}
(\xi,\partial_1F(p),\dots,\partial_{n-1}F(p))=(e_1,\dots,e_n)A
\end{align*}
Therefore, by Thm. \ref{mc140}, we have
\begin{align}\label{eq522}
\xi\wedge\partial_1F(p)\wedge\cdots\wedge \partial_{n-1}F(p)=\det A\cdot e_1\wedge\cdots\wedge e_n 
\end{align}
This finishes the proof.
\end{proof}

\begin{rem}
Note that in the setting of Prop. \ref{mc179}, for each $p\in \Omega$ we have $\det (\xi,\Jac F|_p)\neq0$. This is due to \eqref{eq522}, together with the fact that $\xi\wedge\partial_1F(p)\wedge\cdots\wedge \partial_{n-1}F(p)\neq 0$ for any $p$. The latter fact is due to $F_*\partial_{x^1}\wedge\cdots\wedge F_*\partial_{x^{n-1}}\neq0$ (since $F_*$ is injective and hence $\wedge^{n-1}F_*$ is injective) and the following easy exercise:
\end{rem}

\begin{exe}
Let $V$ be an $(n-1)$-dimensional subspace of an $n$-dimensional real vector space $W$ where $n\geq2$. Let $\xi\in W\setminus V$. Let $\Uppsi\in\bwn^{n-1}V$ be nonzero. Then $\xi\wedge\Uppsi\neq0$.
\end{exe}




\begin{eg}
Let $\Omega\subset\Rbb^{n-1}$ be open where $n>1$. Let $f\in C^\infty(\Omega,\Rbb)$. Let 
\begin{align*}
S:=\fk G(f)=\{(x_1,\dots,x_n)\in\Omega\times\Rbb:x_n=f(x_1,\dots,x_{n-1})\}
\end{align*}
which is the graph of $f$ and hence is a smooth $\partial$-submanifold of $\Rbb^n$. Equip $S$ with the \textbf{upward orientation}, denoted by $\mc O_S$. In other words, $\mc O_S$ is the hypersurface orientation with respect to $e_n$ and the standard orientation $e_1\wedge\cdots\wedge e_n$ of $\Rbb^n$ (where $e_1,\dots,e_n$ are the standard basis of $\Rbb^n$). Moreover, by Thm. \ref{mc177}, $\mc O_S$ is the orientation of $S$ as the boundary of
\begin{align*}
M=\{(x_1,\dots,x_n)\in\Rbb^n:x_n\leq f(x_1,\dots,x_{n-1})\}
\end{align*}
Now let $F=\id_\Omega\vee f:\Omega\rightarrow S$ be defined by sending each $(x_1,\dots,x_{n-1})$ to $(x_1,\dots,x_{n-1},f(x_1,\dots,x_{n-1}))$, which is a diffeomorphism. One easily computes that $\det(e_n,\Jac F)=(-1)^{n+1}$. Therefore, by Prop. \ref{mc179}, $F:\Omega\rightarrow S$ is orientation preserving iff  $n$ is odd.
\end{eg}



\subsection{The measures associated to differential forms}



Fix an $n$-dimensional smooth oriented $\partial$-manifold $(M,\mc O_M)$. In this section, we study the integral $\int_M\omega$ where $\omega$ is an $n$-form. When $n=0$, we view $\omega$ as a function on $M$, and $\int_M\omega=\sum_{p\in M}\omega(p)$. Thus, in the following, we shall always assume $n\geq1$. Moreover, unless otherwise stated, the $\sigma$-algebra on $M$ is chosen to be $\fk B_X$ (rather than its completion under any measure).


\subsubsection{The measure $\upmu_\omega$}

\begin{df}
Let $\omega$ be an $n$-form on $M$. We say that $\omega$ is \textbf{positive} (or \textbf{non-negative}) and write $\pmb{\omega\geq0}$ \index{00@Positive differential form} if $\omega/\eta\geq0$ for any positive continuous orientation form $\eta$ of $(M,\mc O_M)$. This definition is clearly independent of the choice of $\eta$. 
\end{df}

Note that the positivity of $\omega$ depends on the orientation $\mc O_M$. Changing $\mc O_M$ to $-\mc O_M$ will make a positive $n$-form negative (i.e. $-\omega\geq0$).

In this section, we shall associate to each Borel positive $n$-form $\omega$ on $M$ a Borel measure $\mol_\omega:\fk B_M\rightarrow[0,+\infty]$ in a similar way as we defined volume measures in Sec. \ref{mc182}.



\begin{df}\label{mc181}
Let $\Omega$ be an $n$-dimensional smooth $\partial$-submanifold of $\Rbb^n$ whose orientation $\mc O_\Omega$ is the standard one $dx^1\wedge\cdots\wedge dx^n$. Let $\omega\geq0$ be a Borel $n$-form on $\Omega$.  The \textbf{measure associated to $\omega$}  is the Borel measure $\upmu_\omega:\fk B_\Omega\rightarrow[0,+\infty]$ defined by 
\begin{align}
\tcboxmath{d\upmu_\omega=\frac{\omega}{dx^1\wedge\cdots\wedge dx^n}dm_\Omega}
\end{align}
where $m_\Omega$ is the Lebesgue measure of $\Omega$ (restricted to $\fk B_\Omega$). In other words, if $\omega=fdx^1\wedge\cdots\wedge dx^n$ where $f:\Omega\rightarrow\Rbb_{\geq0}$ is Borel, then $d\upmu_\omega=fdm_\Omega$.
\end{df}

Note that if $\omega$ is a continuous (i.e. $C^0$) Borel form, then clearly $\int_K\omega<+\infty$ for each compact $K\subset\Omega$, and hence $\upmu_\omega$ is Radon by Thm. \ref{lb818}.

\begin{thm}\label{mc183}
Let $\Omega$ and $\Delta$ be smooth $n$-dimensional $\partial$-submanifolds of $\Rbb^n$. Let $\Phi:\Omega\rightarrow\Delta$ be an orientation-preserving (resp. orientation-reversing) diffeomorphism. Let $\omega\geq0$ be a Borel $n$-form on $\Delta$. Then on $\fk B_\Omega$ we have
\begin{align}
\Phi^*d\upmu_\omega=\pm\dmol_{\Phi^*\omega}
\end{align}
where $\pm$ is $+$ (resp. $-$).
\end{thm}

\begin{proof}
By assumption, we have $|\Jbf\Phi|=\pm\Jbf\Phi$. We write $\omega=fdx^1\wedge\cdots\wedge dx^n$ where $f:\Delta\rightarrow\Rbb_{\geq0}$ is Borel. By Prop. \ref{mc180}, we have $\Phi^*(dx^1\wedge\cdots\wedge dx^n)=\Jbf\Phi\cdot dx^1\wedge\cdots\wedge dx^n$, and hence
\begin{align*}
\Phi^*\omega=(f\circ\Phi)\cdot \Jbf\Phi \cdot dx^1\wedge\cdots\wedge dx^n
\end{align*}
Therefore, by Def. \ref{mc181}, we have
\begin{align*}
d\mol_{\Phi^*\omega}=(f\circ\Phi)\cdot \Jbf\Phi \cdot dm_\Omega
\end{align*}
Also by Def. \ref{mc181}, we have $\dmol_\omega=fdm_\Delta$. Therefore, by the change of variables Thm. \ref{mc39} (which holds for smooth $n$-dimensional $\partial$-submanifolds of $\Rbb^n$, cf. Thm. \ref{mc105}), we have
\begin{align*}
\Phi^*\dmol_\omega=(\Phi^*f)\cdot \Phi^*dm_\Delta=(f\circ\Phi)\cdot (\pm\Jbf\Phi)\cdot dm_\Omega
\end{align*}
This finishes the proof.
\end{proof}


\begin{thm}\label{mc184}
For each $n$-dimensional smooth oriented $\partial$-manifold $(M,\mc O_M)$ and each Borel $n$-form $\omega\geq0$ on $M$, there is a Borel measure $\upmu_\omega$ on $M$,  \index{00@Measure associated to a differential form} called  \index{zz@$\upmu_\omega$, the measure associated to the differential form $\pmb\omega$} the \textbf{measure associated to $\omega$}, satisfying the following property:
\begin{itemize}
\item For any positive (resp. negative) chart $(U,\varphi)$ on $M$, the following relation holds on $\fk B_{\varphi(U)}$:
\begin{align}\label{eq525}
\varphi_*\big(\dmol_\omega|_U\big)=\pm\dmol_{\varphi_*\omega}
\end{align}
where $\mol_{\varphi_*\omega}$ is the Borel measure on $\varphi(U)$ associated to $\varphi_*\omega$ as defined as in Def. \ref{mc181}, and $\pm$ is $+$ (resp. $-$).
\end{itemize}
Moreover, $\upmu_\omega$ satisfies the following properties:
\begin{enumerate}[label=(\alph*)]
\item $\mol_\omega(\partial M)=0$. 
\item If $M$ is a smooth $n$-dimensional $\partial$-submanifold of $\Rbb^n$, equipped with the standard orientation $dx^1\wedge\cdots\wedge dx^n$ (resp. $-dx^1\wedge\cdots\wedge dx^n$), then $\pm\mol_\omega$ agrees with the volume measure defined in Def. \ref{mc181}, where $\pm$ is $+$ (resp. $-$).
\item If $\omega$ is continuous, then $\upmu_\omega$ is a Radon measure.
\end{enumerate}
\end{thm}



\begin{proof}
Similar to Thm. \ref{mc108}, the current theorem can be proved by Thm. \ref{mc183} and the gluing property Pb. \ref{mc106}-2. (When $\omega$ is continuous, one should use Prop. \ref{mc107} to show that $\upmu_\omega$ is Radon. Alternatively, one can use partitions of unity to show $\int f\dmol_\omega<+\infty$ for each $f\in C_c(M,\Rbb_{\geq0})$, and then conclude from Thm. \ref{lb818} that $\upmu_\omega$ is Radon.) We leave the details to the readers.
\end{proof}


\begin{pp}\label{mc186}
Let $\omega\geq0,\omega'\geq0$ be Borel $n$-forms on $M$, and let $f:M\rightarrow\Rbb_{\geq0}$ be Borel. Then
\begin{align}
d\upmu_{\omega+\omega'}=d\upmu_\omega+d\upmu_{\omega'}\qquad d\upmu_{f\omega}=fd\upmu_\omega
\end{align}
\end{pp}

\begin{proof}
In the case that $M$ is an open subset of $\Hbb^n$, by Def. \ref{mc181}, $d\upmu_{f\omega}=fd\upmu_\omega$ clearly holds. In general, for each positive (resp. negative) chart $(U,\varphi)$ on $M$, by the proved special case, we have $d\upmu_{\varphi_*f\cdot \varphi_*\omega}=\varphi_*fd\upmu_{\varphi_*\omega}$ on $\varphi(U)$, and hence
\begin{align*}
\varphi_*d\upmu_{f\omega}\xlongequal{\eqref{eq525}}\pm d\upmu_{\varphi_*f\cdot \varphi_*\omega}=\pm\varphi_*f\cdot d\upmu_{\varphi_*\omega}\xlongequal{\eqref{eq525}}\varphi_*f\cdot\varphi_*d\upmu_\omega=\varphi_*(fd\upmu_\omega)
\end{align*}
on $\varphi(U)$. This proves $d\upmu_{f\omega}=fd\upmu_\omega$ on $U$ for each $U\in\fk U$. It follows easily (cf. Pb. \ref{mc106}-1) that $d\upmu_{f\omega}=fd\upmu_\omega$ on $M$. A similar argument proves $d\upmu_{\omega+\omega'}=d\upmu_\omega+d\upmu_{\omega'}$ on $M$.
\end{proof}


\begin{pp}\label{mc188}
Let $\omega\geq0$ be a Borel $n$-form on $M$. The following are true.
\begin{enumerate}
\item[(a)] Let $U\subset M$ be open whose orientation is $\mc O_U=\mc O_M|_U$. Then
\begin{align*}
(\upmu_\omega)|_U=\upmu_{(\omega|_U)}
\end{align*}
\item[(b)] Let $(P,\mc O_P)$ be a smooth oriented $\partial$-manifold, and let $\Phi:P\rightarrow M$ be an orientation-preserving (resp. orientation-reversing) diffeomorphism. Then
\begin{align}\label{eq524}
\Phi^*\dmol_\omega=\pm\dmol_{\Phi^*\omega}
\end{align}
holds on $\fk B_P$, where $\pm$ is $+$ (resp. $-$).
\end{enumerate}
\end{pp}

\begin{proof}
Obvious from Thm. \ref{mc184}.
\end{proof}

\begin{exe}
Let $\fk M$ be the $\sigma$-algebra of Lebesgue measurable subsets of $M$, cf. Exe. \ref{mc185}. Let $\omega\geq0$ be a Borel $n$-form on $M$.
\begin{enumerate}
\item Prove that the completion of $\fk B_M$ under $\upmu_\omega$ contains $\fk M$. Prove that if $\omega$ is continuous and nowhere zero, then the completion equals $\fk M$.
\item Let $(P,\mc O_P)$ be a smooth oriented $\partial$-manifold, and let $\Phi:P\rightarrow M$ be an orientation-preserving (resp. orientation-reversing) diffeomorphism. Let $\fk P$ be the $\sigma$-algebra of Lebesgue measurable subsets of $P$. Recall that $\Phi:(P,\fk P)\rightarrow (M,\fk M)$ is measurable  (Exe. \ref{mc185}). Prove that $\Phi^*\dmol_\omega=\pm\dmol_{\Phi^*\omega}$ holds on $\fk P$, where $\pm$ is $+$ (resp. $-$).
\end{enumerate}
\end{exe}



Volume forms are closely related to volume measures.

\begin{thm}\label{mc191}
Let $(M,\gk,\mc O_M)$ be oriented and Riemannian. Let $\varpi_\gk$ be the volume form of $M$ (cf. Thm. \ref{mc165}). Then the measure associated to $\varpi_\gk$ is the volume measure, i.e., on $\fk B_M$ we have
\begin{align}\label{eq523}
d\upmu_{\varpi_\gk}=\dvol_\gk
\end{align}
Consequently, for each Borel $n$-form $\omega\geq0$ on $M$, we have (by Prop. \ref{mc186}) that
\begin{align}
d\upmu_\omega=\frac{\omega}{\varpi_\gk}\cdot\dvol_\gk
\end{align}
\end{thm}


\begin{proof}
Consider the special case that $M$ is an open subset of $\Hbb^n$ whose orientation is the standard one $dx^1\wedge\cdots\wedge dx^n$. Let $G=[\gk(\partial_x\otimes\partial_x)]$ be the function of Gram matrices under $\partial_{x^1},\dots,\partial_{x^n}$. Then by Cor. \ref{mc229}, we have $\varpi_\gk=\sqrt Gdx^1\wedge\cdots\wedge dx^n$, and hence $d\upmu_\omega=\sqrt Gdm^n$. By Def. \ref{mc103}, we also have $\dvol_\gk=\sqrt Gdx^1\wedge\cdots\wedge dx^n$. This proves \eqref{eq523}


Now, we consider the general case. By Pb. \ref{mc106}-1, it suffices to prove \eqref{eq523} locally. Let $(U,\varphi)$ be a positive (resp. negative) chart on $M$. Clearly $\varphi_*\varpi_\gk=\pm\varpi_{\varphi_*\gk}$ on $\varphi(U)$ where $\pm$ is $+$ (resp. $-$). (Note that the volume forms depend not only on the Riemannian metrics but also on the orientations.) Therefore, on $\fk B_{\varphi(U)}$ we have
\begin{align*}
\varphi_*d\upmu_{\varpi_\gk}\xlongequal{\eqref{eq525}}\pm\dmol_{\varphi_*\varpi_\gk}=\dmol_{\varpi_{\varphi_*\gk}}=\dvol_{\varphi_*\gk}
\end{align*}
where the last equation is due to the proved special case. By \eqref{eq462}, we have $\dvol_{\varphi_*\gk}=\varphi_*\dvol_\gk$. This proves \eqref{eq523}.
\end{proof}



\subsubsection{Integrals of Borel differential forms}

\begin{df}
For each Borel $n$-form $\omega\geq0$ on $M$, define the \textbf{integral of $\omega$} to be
\begin{align}
\int_M\omega:=\int_M\dmol_\omega
\end{align}
\end{df}

By Prop. \ref{mc186}, the map $\omega\mapsto\int_M\omega$ is linear. Moreover, if $f:M\rightarrow\Rbb_{\geq0}$ is Borel, then by Prop. \ref{mc186}, $\int_Mfd\mol_\omega$ and $\int_Md\mol_{f\omega}$ are equal, and they are both equal to $\int_M f\omega$.





\begin{thm}\label{mc189}
Let $\omega\geq0$ be a Borel $n$-form on $M$. The following are true.
\begin{enumerate}[label=(\alph*)]
\item We have $\int_M\omega=\int_{\Int M}\omega$.
\item Suppose that $U$ is an open subset of $M$, equipped with the orientation $\mc O_M|_U$. Then 
\begin{align}
\dps\int_U\omega=\int_M\chi_U\cdot\omega
\end{align}
\item Suppose that $(P,\mc O_P)$ is a smooth oriented $\partial$-manifold and $\Phi:P\rightarrow M$ is an orientation-preserving (resp. orientation-reversing) diffeomorphism, then
\begin{align}\label{eq527}
\int_M\omega=\int_P\pm\Phi^*\omega
\end{align}
where $\pm$ is $+$ (resp. $-$).
\item Suppose that $M$ is a smooth $n$-dimensional $\partial$-submanifold of $\Rbb^n$, equipped with the standard orientation $dx^1\wedge\cdots\wedge dx^n$. Let $\omega=fdx^1\wedge\cdots\wedge dx^n$ where $f:M\rightarrow\Rbb_{\geq0}$ is Borel. Then
\begin{align}
\int_M\omega=\int_Mfdm
\end{align}
\end{enumerate}
\end{thm}


\begin{proof}
This is obvious from Thm. \ref{mc184} and Prop. \ref{mc188}.
\end{proof}


We now discuss how to define $\int_M\omega$ for real Borel $n$-forms.


\begin{df}
Let $\omega$ be an $n$-form on $M$. Define an $n$-form $|\omega|$ on $M$ (called the \textbf{absolute value} of $\omega$) such that for each $p\in M$,
\begin{align*}
|\omega|(p)=\left\{
\begin{array}{ll}
\omega(p)&\text{ if $\omega(p)$ is in $\mc O_p$}\\
-\omega(p)&\text{ if $\omega(p)$ is in $-\mc O_p$}\\
0&\text{ if }\omega(p)=0
\end{array}
\right.
\end{align*}
It is clear that for any smooth positive orientation form $\nu$ on $M$, we have
\begin{align*}
|\omega|=|\omega/\nu|\cdot\nu
\end{align*}
Thus, if $\omega$ is $C^r$ (resp. Borel) then $|\omega|$ is $C^r$ (resp. Borel). Define $n$-forms
\begin{align*}
\omega^+=\frac{|\omega|+\omega}2\qquad\omega^-=\frac{|\omega|-\omega}2
\end{align*}
called the \textbf{positive part} and the \textbf{negative part} of $\omega$. Then clearly $\omega=\omega^+-\omega^-$.
\end{df}

\begin{df}
Let $\omega$ be a Borel $n$-form on $M$. We say that $\omega$ is \textbf{integrable} \index{00@Integrable differential forms} if $\int_M|\omega|<+\infty$, equivalently, if $\int_M\omega^+<+\infty$ and $\int_M\omega^-<+\infty$. If $\omega$ is integrable, we define its \textbf{integral} on $M$ to be
\begin{align}
\int_M\omega:=\int_M\omega^+-\int_M\omega^-
\end{align}
\end{df}

\begin{exe}
Prove that the map $\omega\mapsto\int_M\omega$ defined for integrable $n$-forms is linear. Prove that Thm. \ref{mc189} holds true for integrable $n$-forms on $M$.
\end{exe}
 
\begin{cv}\label{mc190}
Suppose that either $S=\partial M$, or $\partial M=\emptyset$ and $S$ is an oriented smooth $\partial$-submanifold of $M$. Assume $\dim S=k$, and $\omega$ is a Borel $k$-form on $M$. We set
\begin{align}
\int_S\omega:=\int_S(\omega|_S)
\end{align}
if $\omega|_S\geq0$ or if $\omega|_S$ is integrable on $S$. Recall that $\omega|_S=\iota^*\omega$ where $\iota:S\rightarrow M$ is the inclusion map.
\end{cv}



The following theorem shows how the integrals of functions are related to the integrals of differential forms.
\begin{thm}\label{mc208}
Let $(M,\gk,\mc O_M)$ be an $n$-dimensional oriented Riemannian $\partial$-manifold with volume form $\varpi_\gk$ and volume measure $\vol_\gk$. Let $f:M\rightarrow\Rbb$ be a Borel function. Then
\begin{align}
\int_M f\dvol_\gk=\int_M f\varpi_\gk\label{eq564}
\end{align}
if $f\geq0$ or if one of the two sides is integrable.
\end{thm}

\begin{proof}
This is clear from Thm. \ref{mc191}.
\end{proof}



\begin{rem}
Thm. \ref{mc189} (for integrable $n$-forms) shows how to calculate the integral $\int_M\omega$ for a positive or integrable $n$-form $\omega$ on $M$. First, by replacing $M$ with $\Int M$, we assume that $\partial M=\emptyset$. Next, we write $M$ as a countable disjoint union of Borel sets $M=\bigsqcup_k E_k$ where each $E_k$ is contained in $U$ for some chart $(U,\varphi^1,\dots,\varphi^n)$. Then $\int_M\omega=\sum_k\int_M \chi_{E_k}\omega$ by the monotone/dominated convergence theorem. Thus, it suffices to compute each $\int_M \chi_{E_k}\omega$. 

Let $(U,\varphi)$ be a chart containing $E_k$. Let $\Omega=\varphi(U)$, which is an open subset of $\Rbb^n$. Then $\Phi=\varphi^{-1}:\Omega\rightarrow U$ is a parametrization of $U$. We need to calculate $\Phi^*\omega$ (e.g. by using \eqref{eq515}) and determine whether $\Phi$ is orientation-preserving or orientation-reversing. Write $\Phi^*\omega=fdx^1\wedge\cdots\wedge dx^n$. Then $f$ must be Lebesgue integrable, and
\begin{align*}
\int_M\chi_{E_k}\omega=\pm\int_\Omega fdm
\end{align*}
where $\pm$ is $+$ (resp. $-$) if $\Phi$ preserves (resp. reverses) the orientations.  \hfill\qedsymbol
\end{rem}


\begin{exe}\label{mc212}
Let $\Omega\subset\Rbb^{n-1}$ be open. Let $h:\Omega\rightarrow\Rbb$ be smooth. Fix $1\leq k\leq n$. Let
\begin{align*}
M=\{(x_1,\dots,x_n):x_k=h(x_1,\dots,\wht{x_k},\dots,x_n)\}
\end{align*}
Let $f:\Rbb^n\rightarrow\Rbb$ be Borel. Equip $M$ with the orientation determined by $\partial_{x^k}$. Prove that
\begin{align*}
\begin{aligned}
&\int_M fdx^1\wedge\cdots\wedge\wht{dx^k}\wedge\cdots\wedge dx^n\\
=&(-1)^{k+1}\int_{\Omega} f(x^1,\dots,x^{k-1},h(x^1,\dots,\wht{x^k},\dots,x^n),x^{k+1},\dots,x^n)dm
\end{aligned}
\end{align*}
where the LHS is integrable iff the RHS is integrable.
\end{exe}


\begin{exe}
Let $M=\{(x,y,z)\in\Rbb^3:x,y,z>0,x+y+z=1\}$ whose orientation is determined by $(1,1,1)\in\Rbb^3$. Let $a,b,c\in\Rbb$. Use Exe. \ref{mc212} to show that
\begin{align*}
\int_M (a\cdot xdy\wedge dz+b\cdot ydz\wedge dx+c\cdot zdx\wedge dy)=\frac {a+b+c}6
\end{align*}
\end{exe}



\begin{eg}\label{mc214}
Let $I$ be a (nonempty) interval of $\Rbb$, equipped with the standard orientation. (So $I$ is a smooth $\partial$-submanifold of $\Rbb$.) Let $\gamma:I\rightarrow\Rbb^n$ be a smooth embedding. Let $C=\gamma(I)$, equipped with the orientation $\mc O_C$ such that the restriction $\wtd\gamma:I\rightarrow C$ of $\gamma$ is orientation-preserving. Let $X:C\rightarrow\Rbb^n$ be a continuous map, viewed as a vector field of $\Rbb^n$ along $C$. Then we have
\begin{align}\label{eq526}
\int_I \bk{X\circ\gamma(t),\gamma'(t)}dt=\int_C \Theta X
\end{align}
where $\Theta:\Rbb^n\rightarrow (\Rbb^n)^*,\partial_{x_i}\mapsto dx^i$ is the Riesz isomorphism of $\Rbb^n$. Eq. \eqref{eq526} is called the \textbf{line integral} of $X$ over $\gamma$. \index{00@Line integral of a vector field} In the literature, this line integral is often written as
\begin{align*}
\int_C X\cdot d\mbf r
\end{align*}
\end{eg}

Note that $X$ can be viewed as a Borel vector field on $\Rbb^n$ vanishing outside $C$. Then $\Theta X$ is a Borel $1$-form on $\Rbb^n$. 


\begin{proof}
Write $X=(X^1,\dots,X^n)$ and $\gamma=(\gamma_1,\dots,\gamma_n)$. Then
\begin{align*}
\int_I \bk{X\circ\gamma(t),\gamma'(t)}dt=\sum_{i=1}^n\int_I (X^i\circ\gamma(t))\gamma_i'(t)dt
\end{align*}
On the other hand, we have $\Theta X=X^1dx^1+\cdots+X^ndx^n$. Recall that by Conv. \ref{mc190}, we have $\int_C\Theta X=\int_C \iota^*(\Theta X)$ where $\iota:C\rightarrow\Rbb^n$ is the inclusion map. Then by \eqref{eq527}, we have
\begin{align*}
&\int_C\Theta X=\int_I \wtd\gamma^*\iota^*(\Theta X)=\int_I\gamma^*(\Theta X)=\int_I\gamma^*(X^1dx^1+\cdots+X^ndx^n)\\
=&\int_I\big((X^1\circ\gamma)d(x^1\circ \gamma)+\cdots+(X^n\circ\gamma)d(x^n\circ\gamma)\big)
\end{align*}
Let $t$ be the standard coordinate of $I$. Then the last term above equals
\begin{align*}
\int_I \big((X^1\circ\gamma(t))\gamma_1'(t)dt+\cdots+(X^n\circ\gamma(t))\gamma_n'(t)dt\big)
\end{align*}
and hence equals the LHS of \eqref{eq526}.
\end{proof}



Faraday's law says that if $\mbf B$ is the magnetic field in $\Rbb^3$ depending on the time $t$, and if $M$ is a smooth compact oriented $2$-dimensional $\partial$-submanifold of $\Rbb^3$, then $\mbf B$ and the induced electric field $\mbf E$ satisfy
\begin{align}\label{eq550}
\int_{\partial M}\mbf E\cdot d\mbf r=-\int_M\frac{\partial\mbf B}{\partial t}\cdot d\mbf S
\end{align}
where the LHS is the line integral of $\mbf E$ over $\partial M$. The RHS is the surface integral of $X=-\partial_t\mbf B$ on $M$, which can be defined by either side of the following identity:
\begin{align}\label{eq528}
\int_M \bk{X,\mbf n}\dvol_M=\int_M \star\Theta X
\end{align}
Here, $\mbf n:M\rightarrow\Rbb^n$ is the unit normal vector field along $M$ determining the orientation of $M$, and $\star\Theta X=X^1dx^2\wedge dx^3-X^2dx^1\wedge dx^3+X^3dx^1\wedge dx^2$ where $X=(X^1,X^2,X^3)$. In the remaining part of this chapter, one of the main goals is to understand the relation \eqref{eq528} and prove it in a general setting. (See Thm. \ref{mc206}.)




\subsection{Hodge star for vector spaces}



In this section, we fix a real $n$-dimensional oriented inner product space $(V,\bk{\cdot,\cdot}_V,\mc O_V)$ where $n\geq1$. Its dual space $(V^*,\bk{\cdot,\cdot}_{V^*},\mc O_{V^*})$ is equipped with the dual inner product and the dual orientation so that the Riesz isomorphism $\Theta_V:V\rightarrow V^*$ is an orientation-preserving isometry. (Recall that by \eqref{eq512}, $\Theta_V$ sends an orthonormal basis $(e_1,\dots,e_n)$ to the dual orthonormal basis $(\wch e^1,\dots,\wch e^n)$, and hence $\bwn^n\Theta_V$ sends the volume tensor $e_1\wedge\cdots\wedge e_n$ to the volume tensor $\wch e^1\wedge\cdots\wedge\wch e^n$). We
\begin{align*}
\text{abbreviate $\bwn^k\Theta_V$ to $\Theta_V$}
\end{align*}
when no confusion arises.


\uwave{Let $\mc T_V$ and $\mc T_{V^*}$ be the volume tensors of $V$ and $V^*$ respectively.} Recall that $\bk{\mc T_V,\mc T_V}=1$. Thus, for each $\eta\in\bwn^nV$ we have $\eta/\mc T_V=\bk{\eta,\mc T_V}$.

A permutation $\sigma\in\fk S_n$ is also written as
\begin{align}
\sigma=[\sigma(1),\dots,\sigma(n)]
\end{align}


\subsubsection{The definition of Hodge star}


\begin{thm}
Let $0\leq k\leq n$. Then the following bilinear map is a perfect pairing:
\begin{gather}\label{eq529}
\begin{gathered}
\bwn^kV\times\bwn^{n-k}V\rightarrow\Rbb\\
(\alpha,\beta)\mapsto \frac{\alpha\wedge\beta}{\mc T_V}\equiv\bk{\alpha\wedge\beta,\mc T_V}
\end{gathered}
\end{gather}
\end{thm}

\begin{proof}
Both $\bwn^kV$ and $\bwn^{n-k}V$ have dimension ${n\choose k}={n\choose n-k}$. Let $e_1,\dots,e_n$ be an orthnormal basis of $V$. Then $(e_{i_1}\wedge\cdots\wedge e_{i_k})_{i_1<\cdots<i_k}$ is a basis of $\bwn^kV$. For each $1\leq i_1<\cdots <i_k\leq n$ with \textbf{ordered complement} $1\leq j_1<\cdots<j_{n-k}\leq n$ (so $\{1,\dots,n\}=\{i_1,\dots,i_k\}\sqcup\{j_1,\dots,j_{n-k}\}$), then we have
\begin{align}\label{eq532}
(e_{i_1}\wedge\cdots\wedge e_{i_k})\wedge(e_{j_1}\wedge\cdots\wedge e_{j_{n-k}})=\sgn[i_1,\dots,i_k,j_1,\dots,j_{n-k}] \cdot\mc T_V
\end{align} 
Therefore, by Prop. \ref{mc137}, \eqref{eq529} is a perfect pairing.
\end{proof}


\begin{df}
Let $0\leq k\leq n$. The \textbf{Hodge star operator} \index{00@Hodge star}
\begin{align*}
\star_k\equiv\star:\bwn^kV\xrightarrow{\simeq}\bwn^{n-k}V
\end{align*}
is the linear isomorphism defined by the composition of the Riesz isomorphism $\bwn^k\Theta_V:\bwn^kV\rightarrow(\bwn^kV)^*$ and the inverse $\Gamma^{-1}$ of the canonical isomorphsm $\Gamma:\bwn^{n-k}V\rightarrow(\bwn^kV)^*$ induced by the perfect pairing \eqref{eq529} (cf. Def. \ref{mc148}). For each $\beta\in\bwn^kV$, $\star\beta$ is determined by the property that for each $\alpha\in\bwn^kV$,
\begin{subequations}\label{eq530}
\begin{align}\label{eq530a}
\alpha\wedge(\star\beta)=\bk{\alpha,\beta}\cdot\mc T_V
\end{align}
Equivalently,
\begin{align}\label{eq530b}
\bk{\alpha\wedge(\star\beta),\mc T_V}=\bk{\alpha,\beta}
\end{align}
\end{subequations}
\end{df}

\begin{proof}[Proof of \eqref{eq530}]
Since \eqref{eq529} is a perfect pairing, \eqref{eq530} clearly determines $\star\beta$. Let us prove that \eqref{eq530} is true. The Riesz isomorphism sends $\beta$ to $\Theta_V\beta\in (\bwn^kV)^*$ satisfying $\bk{\alpha,\beta}_V=\bk{\alpha,\Theta_V\beta}$ for all $\alpha\in\bwn^kV$. In other words, $\Theta_V\beta=\bk{\cdot,\beta}_V$.  By the definition of $\star$ (i.e., $\star=\Gamma^{-1}\Theta_V$), $\Gamma$ sends $\star\beta$ to $\Theta_V\beta=\bk{\cdot,\beta}_V$. By the definition of $\Gamma$, we know that $\Gamma$ sends $\star\beta$ to $\bk{\cdot\wedge\star\beta,\mc T_V}$. This proves \eqref{eq530b}.
\end{proof}

The following proposition gives an equivalent description of $\star$ in terms of orthonormal bases.

\begin{pp}\label{mc192}
$\star:\bwn^kV\rightarrow\bwn^{n-k}V$ is the unique linear map such that for any positive orthonormal basis $(e_1,\dots,e_n)$ of $(V,\mc O_V)$, we have
\begin{align}\label{eq531}
\star(e_1\wedge\cdots\wedge e_k)=e_{k+1}\wedge\cdots\wedge e_n
\end{align}
In the special case that $k=0$ resp. $k=n$, noting that $\bwn^0V=\Rbb$, \eqref{eq531} reads
\begin{align}\label{eq533}
\star 1=e_1\wedge\cdots\wedge e_n\qquad \star(e_1\wedge\cdots\wedge e_n)=1
\end{align}
\end{pp}

Eq. \eqref{eq533} says that $\star 1=\mc T_V$ and $\star\mc T_V=1$. 


\begin{proof}
The uniqueness is obvious since any orthonormal family can be extended to an orthonormal basis. Let us prove that $\star_k$ satisfies \eqref{eq531}. Choose any $1\leq i_1<\cdots<i_k\leq n$. Then $\mc T_V=e_1\wedge\cdots\wedge e_n$, and hence
\begin{align*}
&(e_{i_1}\wedge\cdots\wedge e_{i_k})\wedge\star (e_1\wedge\cdots\wedge e_k)\xlongequal{\eqref{eq530}}\bk{e_{i_1}\wedge\cdots\wedge e_{i_k},e_1\wedge\cdots\wedge e_k}\cdot\mc T_V\\
=&\delta_{1,\dots,k}^{i_1,\dots,i_k}\cdot \mc T_V=(e_{i_1}\wedge\cdots\wedge e_{i_k})\wedge(e_{k+1}\wedge\cdots\wedge e_n)
\end{align*}
where the $\delta_{1,\dots,k}^{i_1,\dots,i_k}$ means $1$ if $i_1=1,\dots,i_k=k$ and $0$ otherwise. 
\end{proof}






Let us give a basis-free reformulation of Prop. \ref{mc192}:
\begin{rem}\label{mc194}
Suppose that $U$ is a $k$-dimensional linear subspace of $V$, equipped with an orientation $\mc O_U$. Let $U^\perp=\{v\in V:\bk{u,v}=0\text{ for all }u\in U\}$. We view $\bwn^kU$ and $\bwn^{n-k}U^\perp$ as inner product subspaces of $V$, cf. Rem. \ref{mc173}. Let $\mc O_{U^\perp}$ be the orientation such that
\begin{align}
\mc O_U\wedge\mc O_{U^\perp}=\mc O_V
\end{align}
(understood in terms of their representatives). Let $\mc T_U\in\bwn^k U$ and $\mc T_{U^\perp}\in\bwn^{n-k}U^\perp$ be the volume tensors of $(U,\mc O_U)$ and $(U^\perp,\mc O_{U^\perp})$ respectively. Then \eqref{eq531} implies
\begin{align}
\star\mc T_U=\mc T_{U^\perp}
\end{align}
\end{rem}


\subsubsection{General properties}



\begin{co}\label{mc193}
In the setting of Prop. \ref{mc192}, for each $1\leq i_1<\cdots<i_k\leq n$, if we let $1\leq j_1<\cdots<j_{n-k}\leq n$ be its ordered complement in $\{1,\dots,n\}$, then
\begin{align}
\star(e_{i_1}\wedge\cdots\wedge e_{i_k})=\sgm e_{j_1}\wedge\cdots\wedge e_{j_{n-k}}
\end{align}
where $\sgm$ is the sign of the permutation $[i_1,\dots,i_k,j_1,\dots,j_{n-k}]$.
\end{co}

\begin{proof}
This is clear from Rem. \ref{mc194} and the fact that $e_{i_1}\wedge\cdots\wedge e_{i_k}\wedge e_{j_1}\wedge\cdots\wedge e_{j_{n-k}}$ equals $\pm\mc T_V$
\end{proof}

\begin{co}\label{mc200}
$\star:\bwn^kV\rightarrow\bwn^{n-k}V$ is an isomorphism of inner product spaces.
\end{co}
\begin{proof}
By Cor. \ref{mc193}, $\star$ sends an orthonormal basis of $\bwn^kV$ to an orthonormal basis of $\bwn^{n-k}V$.
\end{proof}



\begin{co}\label{mc196}
The inverse of $\star_k:\bwn^kV\rightarrow\bwn^{n-k}V$ is
\begin{align}
\star_k^{-1}=(-1)^{k(n-k)}\cdot\star_{n-k}
\end{align}
\end{co}

\begin{proof}
We clearly have
\begin{align*}
\star_{n-k}\star_k=(-1)^{k(n-k)}
\end{align*}
since, in the setting of Prop. \ref{mc192}, we have
\begin{align*}
\star (e_{k+1}\wedge\cdots\wedge e_n)=(-1)^{k(n-k)}e_1\wedge\cdots\wedge e_k
\end{align*}
by Cor. \ref{mc193}.
\end{proof}

The following corollary says that if we identify $V$ and its exterior powers with their dual spaces via the Riesz isomorphisms, then $\star$ is well-defined.


\begin{co}\label{mc195}
We have $\Theta\star=\star\Theta$. Namely, the following diagram commutes:
\begin{equation}\label{eq538}
\begin{tikzcd}
\bwn^kV \arrow[d,"\Theta_V"] \arrow[r,"\star"] & \bwn^{n-k}V \arrow[d,"\Theta_V"] \\
\bwn^kV^* \arrow[r,"\star"]           & \bwn^{n-k}V^*         
\end{tikzcd}
\end{equation}
\end{co}

\begin{proof}
By Prop. \ref{mc192}, for each positive orthonormal basis $(e_1,\dots,e_n)$ of $V$, both ${}^\rightarrow\!\downarrow$ and $\downarrow_{\rightarrow}$ send $e_1\wedge\cdots\wedge e_k$ to $\wch e^{k+1}\wedge\cdots\wedge \wch e^n$.
\end{proof}


To show that $\star$ sends a smooth differential form (or a smooth contravariant alternating tensor field) to a smooth one, it is not always convenient to work with orthonormal bases. In the case that the basis is not orthonormal, it is more convenient to describe $\star\Theta$ (which equals $\Theta\star$ by Cor. \ref{mc195}).

\begin{lm}\label{mc203}
Let $(e_1,\dots,e_n)$ be a (not necessarily orthonormal) ordered basis of $V$ in the orientation $\mc O_V$. Let $(\wch e^1,\dots,\wch e^n)$ be the dual basis (which is in the orientation $\mc O_{V^*}$). Then for each $1\leq i_1<\cdots<i_k\leq n$, if we let $1\leq j_1<\cdots<j_{n_k}\leq n$ be its ordered complement, then
\begin{align}\label{eq534}
\star\Theta_V(e_{i_1}\wedge\cdots\wedge e_{i_k})=\sgm\sqrt{\det[\bk{e_\blt,e_\blt}]}\cdot  \wch e^{j_1}\wedge\cdots\wedge \wch e^{j_{n-k}}
\end{align}
where $\sgm$ is the sign of the permutation $[i_1,\dots,i_k,j_1,\dots,j_{n-k}]$, and $[\bk{e_\blt,e_\blt}]$ is the Gram matrix.
\end{lm}

The following rules help us remember the factor before $\wch e^{j_1}\wedge\cdots\wedge \wch e^{j_{n-k}}$: First, its absolute value is independent of $k$. Second, when $k=0$, $\star\Theta_V1$ should be the volume form, which according to Eq. \eqref{eq534} is $\sqrt {\det G}\cdot\wch e^1\wedge\cdots\wedge \wch e^n$ where $G=[\bk{e_\blt,e_\blt}]$. So the factor in general is $\pm\sqrt {\det G}$.

\begin{proof}
Let $G=\det[\bk{e_\blt,e_\blt}]$. We prove the special case that $i_1=1,\dots,i_k=k$, and leave the general case to the readers. So let us prove
\begin{align*}
\star\Theta_V(e_1\wedge\cdots\wedge e_k)=\sqrt{\det G}\cdot  \wch e^{k+1}\wedge\cdots\wedge \wch e^n
\end{align*}
Choose any $1\leq l_1<\cdots<l_k\leq n$. Then
\begin{align*}
&(\wch e^{l_1}\wedge\cdots\wedge\wch e^{l_k})\wedge \star\Theta_V(e_1\wedge\cdots\wedge e_k)\\
\xlongequal{\eqref{eq530}}&\bk{\wch e^{l_1}\wedge\cdots\wedge\wch e^{l_k},\Theta_V(e_1\wedge\cdots\wedge e_k)}_{V^*}\cdot\mc T_{V^*}\\
\xlongequal{\eqref{eq508}}&\bk{\wch e^{l_1}\wedge\cdots\wedge\wch e^{l_k},e_1\wedge\cdots\wedge e_k}\cdot\mc T_{V^*}=\delta_{1,\dots,k}^{l_1,\dots,l_k}\cdot\mc T_{V^*}
\end{align*}
By Prop. \ref{mc162}, we have $\mc T_{V^*}=\sqrt{\det G}\cdot\wch e^1\wedge\cdots\wedge\wch e^n$. Thus
\begin{align*}
\sqrt{\det G}\cdot (\wch e^{l_1}\wedge\cdots\wedge\wch e^{l_k})\wedge(\wch e^{k+1}\wedge\cdots\wedge \wch e^n)=\delta_{1,\dots,k}^{l_1,\dots,l_k}\cdot\mc T_{V^*}
\end{align*}
This finishes the proof.
\end{proof}


\subsubsection{Hodge star and hyperplanes}



In this course, we will apply Hodge star mainly to the study of hypersurfaces. Therefore, the most important cases for us are $\star_1:V\rightarrow\bwn^{n-1}V$ and $\star_1:V^*\rightarrow\bwn^{n-1}V^*$. Then, by Cor. \ref{mc196},  $\star_{n-1}:\bwn^{n-1}V\rightarrow V$ is equal to
\begin{align}
\star_{n-1}=(-1)^{(n-1)}\cdot\star_1^{-1}
\end{align}
When $n$ equals $3$, the dimension for classical electromagnetism (which gave birth to vector analysis), we have $\star_2=\star_1^{-1}$. For a general $n$, as we will see, $\star_1^{-1}$ is more convenient to use than $\star_{n-1}$. Note also that if $(e_1,\dots,e_n)$ is a positive orthonormal basis of $(V,\mc O_V)$, then by Cor. \ref{mc193},
\begin{align}\label{eq535}
\tcboxmath{\star e_i=(-1)^{i+1} e_1\wedge\cdots\wedge\wht{e_i}\wedge\cdots\wedge e_n}
\end{align}


In the following, we let $(U,\mc O)$ be an oriented $(n-1)$-dimensional  inner product subspace of $V$. The inner product of $U$ is the restriction of that of $V$. Then $U$ has two unit \textbf{normal vectors} (i.e., vectors orthogonal to $V$ with length $1$). \uwave{Let $\mc T_U$ and $\mc T_{U^*}$ be the volume tensors of $(U,\mc O_U)$ and $(U^*,\mc O_{U^*})$ respectively.} Here, $\mc O_{U^*}$ is dual to $\mc O_U$.

\begin{df}
Let $\nu\in V$ be a nonzero normal vector of $U$. We say that $\nu$ is a \textbf{positive normal vector} \index{00@Positive normal vector} of $(U,\mc O_U)$ if $\mc O_U$ is the hyperplane orientation determined by $\nu$ (cf. Def. \ref{mc197}), i.e.,  $\nu\wedge\mc O_U=\mc O_V$.
\end{df}

The following theorem is fundamental to the study of hypersurfaces and hyperplanes. It tells us that the positive unit normal vector $\nu$ can be used to describe the orientation $\mc O_U$ (which fits our intuition better than the volume tensor), and that the relationship between $\nu$ and the volume tensor is simple. 

\begin{thm}\label{mc201}
Let $\nu\in V$ be the positive unit normal vector of $(U,\mc O_U)$. Then
\begin{align}\label{eq536}
\star\nu=\mc T_U
\end{align}
\end{thm}
``Unit" means that $\Vert\nu\Vert=1$. 

\begin{proof}
This is clear from Rem. \ref{mc194} or from Eq. \eqref{eq535}. Note that \eqref{eq536} is just a basis-free version of \eqref{eq535}.
\end{proof}



\begin{co}\label{mc202}
Let $\xi_1,\dots,\xi_{n-1}\in V$. Define the \textbf{cross product} \index{00@Cross product of vectors} of $\xi_1,\dots,\xi_{n-1}$ to be
\begin{align}\label{eq542}
\xi_1\vartimes\cdots\vartimes\xi_{n-1}:=\star^{-1}(\xi_1\wedge\cdots\wedge\xi_{n-1})
\end{align}
Assume that $\xi_1,\dots,\xi_{n-1}$ are linearly independent (so that $\xi_1\wedge\cdots\wedge\xi_{n-1}\neq0$). Let $U=\Span\{\xi_1,\dots,\xi_{n-1}\}$ with orientation $\mc O_U$ given by $\xi_1\wedge\cdots\wedge\xi_{n-1}$. Then
\begin{align}\label{eq539}
\nu:=\frac{\xi_1\vartimes\cdots\vartimes\xi_{n-1}}{\Vert\xi_1\vartimes\cdots\vartimes\xi_{n-1}\Vert}
\end{align}
is the positive unit normal vector of $(U,\mc O_U)$.
\end{co}

\begin{proof}
Since both $\xi_1\wedge\cdots\wedge\xi_{n-1}$ and $\mc T_U$ are in $\bwn^{n-1}U\subset\bwn^{n-1}V$, and since $\mc T_U$ has length $1$, we have
\begin{align}
\mc T_U=\frac{\xi_1\wedge\cdots\wedge\xi_{n-1}}{\Vert \xi_1\wedge\cdots\wedge\xi_{n-1}\Vert}\xlongequal{\text{Cor. \ref{mc200}}}\frac{\xi_1\wedge\cdots\wedge\xi_{n-1}}{\Vert\xi_1\vartimes\cdots\vartimes\xi_{n-1}\Vert}
\end{align}
Apply $\star^{-1}$ to the above expressions. Then the leftmost term becomes $\nu$ by Thm. \ref{mc201}, and the rightmost term becomes the RHS of \eqref{eq539}.
\end{proof}


The following example shows that when $V=\Rbb^3$, the cross product in \ref{mc202} agrees with the one we are familiar with in vector analysis.
\begin{eg}
Let $\xi_1,\dots,\xi_{n-1}\in\Rbb^{n-1}$ where
\begin{align*}
\xi_j=\begin{pmatrix}
a_j^1\\
\vdots\\
a_j^n
\end{pmatrix}
\end{align*}
Let $e_1,\dots,e_n$ be the standard (orthonormal positive) basis of $\Rbb^n$. Then
\begin{align}\label{eq540}
\xi_1\vartimes\cdots\vartimes\xi_{n-1}=\begin{vmatrix}
e_1&a_1^1&\cdots&a_{n-1}^1\\
\vdots&&\vdots&\\
e_n&a_1^n&\cdots&a_{n-1}^n
\end{vmatrix}
\end{align}
interpreted in the following way: Let $A=(a_j^i)^{i\leq n}_{j\leq n-1}\in\Rbb^{n\times(n-1)}$, and let $A(i)\in\Rbb^{(n-1)\times(n-1)}$ be the submatrix of $A$ defined by deleting the $i$-th row. Then the cofactor expansion of \eqref{eq540} along the first column gives
\begin{align}\label{eq541}
\xi_1\vartimes\cdots\vartimes\xi_{n-1}=\sum_{1\leq i\leq n} (-1)^{i+1}\det A(i)\cdot e_i
\end{align}
\end{eg}

\begin{proof}
We have $(\xi_1,\dots,\xi_{n-1})=(e_1,\dots,e_n)A$. Therefore, by Thm. \ref{mc140}, we have
\begin{align*}
\xi_1\wedge\cdots\wedge\xi_{n-1}=\sum_{1\leq i\leq n}\det A(i)\cdot e_1\wedge\cdots\wedge\wht{e_i}\wedge\cdots\wedge e_n
\end{align*}
By \eqref{eq535}, $\star^{-1}$ sends the RHS above to the RHS of \eqref{eq541}.
\end{proof}


%% Record #27 2024/06/03 Two lectures  66

For the convenience of studying the integrals on manifolds, let us examine the relationship between the positive unit normal vector $\nu$ of $(U,\mc O)$ and the volume tensor $\mc T_{U^*}$ of $(U^*,\mc O_{U^*})$. The following property will be used to compare two definitions of hypersurface integrals, cf. Thm. \ref{mc206}.

\begin{lm}\label{mc207}
Let $\nu\in V$ be the positive unit normal vector of $(U,\mc O_U)$. Let $\xi\in V$. Then we have the following relation of elements of $\bwn^{n-1}U^*\simeq (\bwn^{n-1}U)^*$.
\begin{align}\label{eq537}
\bk{\xi,\nu}\mc T_{U^*}=\star\Theta_V \xi\big|_{\bwn^{n-1}U}
\end{align}
\end{lm}
Note that the RHS of \eqref{eq537} is the restriction of $\star\Theta \xi\in\big(\bwn^{n-1}V\big)^*$ to ${\bwn^{n-1}U}$, i.e., it is $(\wedge^{n-1}\iota^\tr)(\star\Theta \xi)$ where $\iota:U\rightarrow V$ is the inclusion map and hence $\wedge^{n-1}\iota^\tr:\bwn^{n-1}V^*\rightarrow \bwn^{n-1}U^*$.

\begin{proof}
It suffices to prove that the two sides of \eqref{eq537} are equal when evaluated with $\mc T_U$. We compute
\begin{align*}
\bigbk{\star\Theta_V \xi\big|_{\bwn^{n-1}U},\mc T_U }=\bk{\star\Theta_V \xi,\mc T_U}\xlongequal{\eqref{eq508}}\bk{\star\Theta_V \xi,\Theta_V\mc T_U}\xlongequal[\eqref{eq538}]{\eqref{eq536}}\bk{\star\Theta_V \xi,\star\Theta_V \nu}
\end{align*}
Since $\star$ and $\Theta_V$ are both isometries, the last term above equals $\bk{\xi,\nu}$, and hence equals $\bk{\xi,\nu}\cdot\bk{\mc T_{U^*},\mc T_U}$.
\end{proof}


\subsection{Hodge star and hypersurface integrals of vector fields}

Let $M$ be a smooth $\partial$-manifold with dimension $n$. Recall Prop. \ref{mc176} for the Riesz isomorphism $\Theta_M:\bwn^kTM\rightarrow\bwn^kT^*M$. 

In this section, we will use Hodge star to prove that the two ways of calculating the integral of a vector field along a hypersurface $S\subset M$ (as mentioned in \eqref{eq528}) are equal. We will also prove some useful criteria for the orientability of hypersurfaces.

\begin{df}
Let $E\subset M$. An order-$k$ \textbf{contravariant alternating tensor field of $M$ along $E$} \index{00@Tensor field along a subset} is defined to be a map $A:E\rightarrow \bwn^kTM$ such that $A|_p\in\bwn^kT_pM$ for each $p\in E$. For such $A$, we say that $A$ is a \textbf{Borel/$\pmb{C^r}$-tensor field} (where $r\in\Nbb\cup\{\infty\}$) if for every $p\in E$ there exist $U\in\Nbh_M(p)$ and a $C^r$/Borel contravariant alternating tensor field $\wtd A:U\rightarrow\bwn^kTM$ such that $\wtd A|_{U\cap E}=A|_{U\cap E}$.

$k$-forms of $M$ along $E$, as well as their Borel/$C^r$ versions, are defined in a similar way. \hfill\qedsymbol
\end{df}

\begin{ass}\label{mc209}
In this section, we fix an oriented Riemannian $\partial$-manifold $(M,\gk,\mc O_M)$ with dimension $n\geq2$ and volume form $\varpi_M$. The
pairing $\gk(\cdot,\cdot)$ is often abbreviated to $\bk{\cdot,\cdot}$. Let $S$ be either $\partial M$ or a smooth $\partial$-submanifold of $M$. (In the latter case, we assume $\partial M=\emptyset$.) Assume $\dim S=n-1$. Equip $S$ with the Riemannian metric $\gk|_S$.
\end{ass}


\begin{df}
A \textbf{normal vector field} \index{00@Normal vector field} $\mbf n:E\rightarrow TM$ of $S$ is defined to be a vector field of $M$ along $S$ such that $\bk{\mbf n,T_pS}=0$ for each $p\in S$. A normal vector field $\mbf n$ is called a \textbf{unit normal vector field} if $\bk{\mbf n|_p,\mbf n|_p}=1$ for all $p\in S$. If $S$ is equipped with an orientation $\mc O_S$, we say that a normal vector field $\mbf n$ is \textbf{positive} if for each $p\in S$, $\mbf n|_p$ is a positive normal vector of $(T_pM,\mc O_S|_p)$ (i.e., $\mbf n|_p\wedge\mc O_S|_p=\mc O_M|_p$).
\end{df}






\subsubsection{The smoothness of Hodge star}





\begin{df}
Let  $E\subset M$. For each contravariant alternating tensor field $A:E\rightarrow\bwn^kTM$, we define $\star A:E\rightarrow \bwn^{n-k}TM$ sending each $p\in E$ to $\star (A|_p)$ where $\star:\bwn^kT_pM\rightarrow\bwn^{n-k}T_pM$ is the Hodge star for $T_pM$ under $\gk|_p$ and $\mc O_p$. Similarly, for each $k$-form $\omega$ of $M$ along $E$, $\star\omega$ is an $(n-k)$-form of $M$ along $E$ defined pointwise by the Hodge star $\star:\bwn^kT_p^*M\rightarrow\bwn^{n-k}T_p^*M$ for $T_p^*M$ under the dual inner product $\gk^*|_p$ and $\mc O_p$.
\end{df}

Recall that by Prop. \ref{mc176}, a contravariant alternating tensor field $A$ (resp. a differential form $\omega$) is $C^r$ iff $\Theta_VA$ is $C^r$ (resp. $\Theta_V\omega$ is $C^r$). The hodge star satisfies the same property: 

\begin{pp}\label{mc204}
Let $r\in\Nbb\cup\{\infty\}$. Let $E\subset M$. Let $A:E\rightarrow\bwn^kTM$ be a contravariant alternating tensor field of $M$ along $E$. Then $A$ is Borel/$C^r$ iff $\star A$ is Borel/$C^r$. Similarly, let $\omega$ be a $k$-form of $M$ along $E$. Then $\omega$ is Borel/$C^r$ iff $\star\omega$ is Borel/$C^r$.
\end{pp}


\begin{proof}
By Prop. \ref{mc203} and the smoothness of $\gk$, one easily sees that $\star\Theta_V$ sends Borel/$C^r$ alternating tensor fields (inclusing contravariant alternating tensor fields and differential forms) to Borel/$C^r$  alternating tensor fields. Since $\Theta_V$ sends Borel/$C^r$ fields to Borel/$C^r$ fields, we conclude that $\star$ sends Borel/$C^r$-fields to Borel/$C^r$-fields. The same can be said about $\star^{-1}$ since $\star_k^{-1}=(-1)^{k(n-k)}\star_{n-k}$ (Cor. \ref{mc196}).
\end{proof}



\subsubsection{Hypersurface integrals of vector fields}




\begin{pp}\label{mc205}
Assume that $S$ is equipped with an orientation $\mc O_S$. Then $S$ has a unique positive normal vector field $\mbf n:S\rightarrow TM$. Moreover, $\mbf n$ is smooth along $S$.
\end{pp}

\begin{proof}
For each $p\in S$, there is a unique positive normal vector $\mbf n|_p\in T_pM$ of $(T_pS,\mc O_S|_p)$. Therefore, the existence and the uniqueness of $\mbf n$ is obvious. Let us prove that $\mbf n$ is smooth. Let $\varpi_S:S\rightarrow \bwn^{n-1}T^*S$ be the volume form of $(S,\gk|_S,\mc O_S)$, which is smooth by Thm. \ref{mc165}. Let $\Theta_S:\bwn^{n-1}TS\rightarrow\bwn^{n-1}T^*S$ be the Riesz isomorphism of $S$. By  Prop. \ref{mc176}, $\Theta_S^{-1}\varpi_S:S\rightarrow\bwn^{n-1}TS$ is smooth. For each $p\in S$, since $\Theta_S|_p$ sends the (positive) volume tensor of $(T_pS,\mc O_p)$ to that of $(T_p^*S,\mc O_p)$, we see that $\Theta_S^{-1}\varpi_S$ is the volume tensor of $T_pS$. 

Let us view $\Theta_S^{-1}\varpi_S$ as a contravariant alternating tensor field of $M$ along $S$, which is clearly also smooth. Therefore, by Thm. \ref{mc201}, we have $\star\mbf n=\Theta_S^{-1}\varpi_S$. Thus, $\mbf n$ is smooth by Prop. \ref{mc204}.
\end{proof}

\begin{rem}
We now give another proof of the smoothness of $\mbf n$. We assume WLOG that $M$ is an $n$-dimensional smooth $\partial$-submanifold of $\Rbb^n$ equipped with the standard orientation. (We do not assume that its Riemannian metric $\gk$ is Euclidean.) We assume moreover that there is an $n-1$ dimensional smooth $\partial$-submanifold $\Omega$ of $\Rbb^{n-1}$ and a smooth map $F:\Omega\rightarrow\Rbb^n$ restricting to a diffeomorphism $\wtd F:\Omega\xrightarrow{\simeq}S$. Let $\pm$ be $+$ (resp $-$) if $\wtd F$ is orientation-preserving (resp. orientation-reversing). Since $dF$ is injective everywhere, and since $dF\cdot\partial_{x^i}=\partial_iF$, for each $p\in\Omega$, we know that $\pm dF(\partial_{x^1}\wedge\cdots\wedge\partial_{x^n})|_p=\pm\partial_1F\wedge\cdots\wedge\partial_{n-1}F|_p$ is a nonzero element of $\bwn^{n-1}T_{F(p)}S$ representing the orientation $\mc O_S|_{F(p)}$. Thus, by Cor. \ref{mc202},
\begin{align}\label{eq546}
\nbf|_{F(p)}=\pm\frac{\partial_1F\vartimes\cdots\vartimes\partial_{n-1}F}{\Vert \partial_1F\vartimes\cdots\vartimes\partial_{n-1}F\Vert }~\bigg|_p
\end{align}
This formula not only proves that $\nbf$ is smooth along $S$, but also shows us how to calculate $\nbf$ in concrete examples. 

Note that if $\gk$ is Euclidean, then the cross product can be computed by \eqref{eq540}. This formula, together with the Cauchy-Binet formula (cf. Rem. \ref{mc143}), shows
\begin{align}\label{eq549}
\Vert \partial_1F\vartimes\cdots\vartimes\partial_{n-1}F\Vert=\sqrt{\det((\Jac F)^\tr \Jac F)}
\end{align}
We will use \eqref{eq549} to give an explicit formula of hypersurface integral under the Euclidean metric, cf. Exp. \ref{mc211}. \hfill\qedsymbol
\end{rem}


\begin{thm}\label{mc206}
Let $\mc O_S$ be an orientation on $S$, and let $\nbf:S\rightarrow TM$ be its positive unit normal vector field which is smooth by Prop. \ref{mc205}. Let $X:S\rightarrow TM$ be a vector field of $M$ along $S$. Let $\varpi_S:S\rightarrow\bwn^{n-1}T^*S$ be the volume form of $(S,\gk|_S,\mc O_S)$. Then
\begin{align}\label{eq543}
\bk{X,\nbf}\cdot \varpi_S=(\star\Theta_M X)\big|_S
\end{align}
Consequently, if $X$ is Borel, then
\begin{align}\label{eq544}
\int_S  \bk{X,\nbf}\dvol_S=\int_S \star\Theta_MX
\end{align}
where the LHS is integrable iff the RHS is integrable.
\end{thm}

Recall from Asmp. \ref{mc209} that $\bk{X,\nbf}$ means $\gk(X,\nbf)$. Both sides of \eqref{eq544} are called the \textbf{hypersurface integral of $X$ on $S$} \index{00@Hypersurface integrals of vector fields} and denoted by \footnote{The symbol $d\Sbf$ stands for an ``infinitesimal oriented (hyper)surface" and is not related to the name of the manifold $S$. For any other hypersurface $P$, we also write $\int_PX\cdot d\Sbf$.}
\begin{align*}
\int_S X\cdot d\mbf S
\end{align*}


\begin{proof}
Eq. \eqref{eq543} follows immediately from Lem. \ref{mc207}.  Eq. \eqref{eq544} follows from \eqref{eq543} and Thm. \ref{mc208}.
\end{proof}

\begin{rem}
Suppose that $M$ is an $n$-dimensional smooth $\partial$-submanifold of $\Rbb^n$ equipped with the standard orientation. The Riemannian metric $\gk$ of $M$ is not necessarily Euclidean. Let $X:S\rightarrow TM$ be a vector field of $M$ along $S$, written as
\begin{align*}
X=\sum_{i=1}^nX^i\partial_{x^i}
\end{align*}
where $X^i:S\rightarrow\Rbb$. Then by Lem. \ref{mc203}, we have
\begin{align}\label{eq545}
\star\Theta_MX=\sqrt{\det[\gk(\partial_x\otimes\partial_x)]}\cdot\sum_{i=1}^n(-1)^{i+1}X^idx^1\wedge\cdots\wedge\wht{dx^i}\wedge\cdots\wedge dx^n
\end{align}
where $\gk(\partial_x\otimes\partial_x)$ is the Gram matrix function of $\bk{\cdot,\cdot}=\gk$ under $\partial_{x^1},\dots,\partial_{x^n}$. This provides the specific formula for calculating $\star\Theta_MX$. Of particular importance is the case that $\gk$ is the Euclidean metric, where \eqref{eq545} becomes
\begin{align}\label{eq547}
\star\Theta_MX=\sum_{i=1}^n(-1)^{i+1}X^idx^1\wedge\cdots\wedge\wht{dx^i}\wedge\cdots\wedge dx^n
\end{align}
\end{rem}

%% Proofread

\begin{eg}\label{mc211}
Let $\Omega$ be an $(n-1)$-dimensional smooth $\partial$-submanifold of $\Rbb^{n-1}$. Let $F=(F^1,\dots,F^n):\Omega\rightarrow\Rbb^n$ be a smooth embedding. Equip $S:=F(\Omega)$ with an orientation $\mc O_S$. The Riemannian metric of $S$ is the standard one (i.e. the restriction of $\fk E^n$). Let $\pm$ be $+$ (resp. $-$) if $F:\Omega\rightarrow S$ is orientation-preserving (resp. orientation-reversing). Let $X:S\rightarrow \Rbb^n$ be Borel. Then the hypersurface integral of $X$ on $S$ is
\begin{align}\label{eq548}
\int_S X\cdot d\Sbf=\pm\int_\Omega \det (X\circ F,\Jac F)dm 
\end{align}
where $X$ is viewed as a function of $n\times 1$ matrices, and $\Jac F$ is $n\times(n-1)$. The LHS of \eqref{eq548} is integrable iff the RHS is integrable.
\end{eg}



\begin{proof}
By Thm. \ref{mc206}, we have
\begin{align*}
\int_S X\cdot d\Sbf=\int_S\bk{X,\nbf}\dvol_S\xlongequal{\eqref{eq465}}\int_\Omega \bk{X\circ F,\nbf\circ F}\cdot \sqrt{\det((\Jac F)^\tr\Jac F)}~dm
\end{align*}
By \eqref{eq546} and \eqref{eq549}, the last term above equals
\begin{align*}
\pm\int_\Omega\bk{X\circ F,\partial_1F\vartimes\cdots\vartimes\partial_{n-1}F}dm
\end{align*}
Using the formula \eqref{eq540} for Euclidean cross products, one can easily show that the above expression equals the RHS of \eqref{eq548}.
\end{proof}

\begin{exe}
Prove \eqref{eq548} by calculating $\int_S\star\Theta_MX$, i.e., calculating the integral of the differential form on the RHS of \eqref{eq547}. This is a good exercise of computing the integral of differential forms and gives another proof of Eq. \eqref{eq544} under the Euclidean metric. 
\end{exe}






\subsubsection{Applications of Thm. \ref{mc206}}






\begin{co}\label{mc213}
The following are equivalent:
\begin{enumerate}
\item[(1)] $S$ is orientable.
\item[(2)] There exists a continuous vector field $X:S\rightarrow TM$ along $S$ which is nowhere tangent to $S$, i.e., $X|_p\notin T_pS$ for each $p\in S$.
\end{enumerate}
\end{co}

In this corollary, there is no need to assume that $M$ is Riemannian since any smooth $\partial$-manifold has a Riemannian metric (Thm. \ref{mc109}).

\begin{proof}
Assume (1). Let $\mc O_S$ be an orientation of $S$. Then the positive normal vector field $\nbf$ of $S$ is smooth (by Prop. \ref{mc205}) and hence satisfies the requirement of (2).

Assume (2). Let $\omega:S\rightarrow \bwn^{n-1}T^*S$ be an $(n-1)$-form defined by $\omega=(\star\Theta_MX)|_S$. Since $X$ is continuous,  by Prop. \ref{mc204}, $\omega$ is continuous. Let us show that $\omega$ is an orientation form of $S$, i.e., $\omega$ is nowhere zero. Then $\omega$ defines an orientation of $S$.

Choose any $p\in S$. Let us show that $\omega$ is nowhere zero on a neighborhood of $p$. For that purpose, we may shrink $M$ to a neighborhood of $p$ (and shrink $S$ accordingly) so that $S$ has a global chart. Then $S$ has an orientation $\mc O_S$. Let $\nbf$ be the positive unit normal vector field of $(S,\mc O_S)$. Let $\varpi_S$ be the volume form of $(S,\gk|_S,\mc O_S)$. Then by Thm. \ref{mc206} we have $\omega=\bk{X,\nbf}\varpi_S$. Since $X$ is nowhere tangent to $S$, we see that $\bk{X,\nbf}$ is nowhere zero. Thus $\omega$ is nowhere zero.
\end{proof}



Eq. \eqref{eq546} indicates how to calculate the positive normal vector field $\nbf$ when $S$ has a (global) parametrization. The following corollary shows how to calculate the volume form $\varpi_S$ by realizing it as the restriction of a smooth $(n-1)$-form of $M$. 

\begin{co}\label{mc210}
Let $\mc O_S$ be an orientation of $S$. Let $\nbf$ and $\varpi_S$ be the positive unit normal vector field and the volume form of $(S,\gk|_S,\mc O_S)$. Then
\begin{align}
\varpi_S=(\star\Theta_M\nbf)\big|_S
\end{align}
\end{co}

\begin{proof}
In \eqref{eq543}, let $X=\nbf$.
\end{proof}


\begin{eg}\label{mc231}
Equip $\Rbb^n$ with the standard orientation and metric tensor. Equip $\Sbb^{n-1}$ with the outward orientation $\mc O_{\Sbb^{n-1}}$. Let $\nbf:\Sbb^{n-1}\rightarrow\Rbb^n$ be the (smooth) positive unit normal vector field of $\Sbb^{n-1}$. We extend $\nbf$ to a (global) vector field of $\Rbb^n$ by setting $\nbf|_p=p$ for every $p\in\Rbb^n$. In other words,  $\nbf=\sum_i x^i\partial_{x^i}$. Let $\omega=\star\Theta_{\Rbb^n}\nbf$. Then, by \eqref{eq547}, we have
\begin{align}
\omega=\sum_{i=1}^n(-1)^{i+1}x^idx^1\wedge\cdots\wedge\wht{dx^i}\wedge\cdots\wedge dx^n
\end{align}
By Cor. \ref{mc210}, $\omega|_{\Sbb^{n-1}}$ is the volume form of $\Sbb^{n-1}$. By suitably scaling $\omega$, we obtain an important smooth $(n-1)$-form on $\Rbb^n\setminus\{0\}$ which is ``closed but not exact". See Exp. \ref{mc233} for a continued discussion of this example.
\end{eg}



\newpage



\section{Stokes' theorem}



\subsection{Introduction}


We have mentioned in Eq. \eqref{eq550} Faraday's law $\int_{\partial M}\mbf E\cdot d\mbf r=-\int_M\frac{\partial\mbf B}{\partial t}\cdot d\mbf S$. By Exp. \ref{mc214} and Thm. \ref{mc206}, Faraday's law can be written as
\begin{align*}
\int_{\partial M}\Theta \mbf E=-\int_M \star\Theta\partial_t\mbf B
\end{align*}
The goal of this chapter is to prove Stokes' theorem, which says that for each smooth $k$-dimensional $\partial$-manifold $M$ and each compactly supported smooth $(k-1)$-form $\omega$ on $M$ we have
\begin{align}\label{eq551}
\int_{\partial M}\omega=\int_Md\omega
\end{align}
where $d\omega$ is an $n$-form, called the \textbf{exterior derivative} of $\omega$. If we view $\omega$ as a higher dimensional electric field, then Stokes' theorem says that $\omega$ can be induced by a ``magnetic field" whose rate of change is $-d\omega$ and hence is uniquely determined by $\omega$.



If we assume that $\omega$ is a smooth $(k-1)$-form on an $n$-dimensional smooth manifold $\Omega$, then Stokes' theorem asserts that there is a smooth $k$-form $d\omega$ on $\Omega$ such that \eqref{eq551} holds for any compact $k$-dimensional smooth $\partial$-submanifold $M$ of $\Omega$. This property determines $d\omega$ uniquely:
\begin{exe}\label{mc216}
Let $\Omega$ be an $n$-dimensional smooth manifold, and let $\eta_1,\eta_2$ be continuous $k$-forms on $\Omega$. Prove that the following are equivalent:
\begin{enumerate}
\item[(1)] $\eta_1=\eta_2$.
\item[(2)] For any compact $k$-dimensional smooth $\partial$-submanifold $M$ of $\Omega$ we have $\int_M\eta_1=\int_M\eta_2$.
\end{enumerate} 
\end{exe}




By Exe. \ref{mc216}, we may define $d\omega$ to be the unique $k$-form such that Stokes' formula \eqref{eq551} holds for any $M$. This is indeed the geometric definition of $d\omega$. Of course, if we use this definition, then we must first prove the existence of $d\omega$ satisfying this definition. Let us set aside for the moment the problem of existence, and derive some immediate consequences from Stokes' theorem. 

Let $\Omega$ be a smooth $n$-dimensional manifold, and let $\omega$ be a smooth $k$-form. Of course, Stokes' theorem implies that $\omega\mapsto d\omega$ is linear. Besides this trivial property, we also have:
%In the following, we assume that $\Omega$ is an open subset of $\Rbb^n$. 

\begin{itemize}
\item[$\boxed{1}$] For any open $U\subset\Omega$, we have $(d\omega)|_U=d(\omega|_U)$.
\item[$\boxed{2}$] If  $\Phi:D\rightarrow\Omega$ is a diffeomorphism of smooth manifolds, then $d\Phi^*\omega=\Phi^*d\omega$.
\end{itemize}
In other words, $d$ should be ``invariant under diffeomorphisms" and compatible with the restriction to open subsets. These properties should obviously be satisfied.  In fact, as we shall show, the relation $d\Phi^*\omega=\Phi^*d\omega$ holds provided that $\Phi$ is smooth; there is no need to assume that $\Phi$ is a diffeomorphism.





\begin{itemize}
\item[$\boxed{3}$] $d^2\omega\equiv dd\omega=0$.
\end{itemize}
Assume $\omega$ is a $(k-1)$-form, and let $M$ be any $(k+1)$-dimension smooth $\partial$-submanifold of $\Omega$. Then $\partial M$ has empty boundary, and hence $\partial\partial M=\emptyset$. So, assuming Stokes' theorem, we have
\begin{align*}
\int_M d^2\omega=\int_{\partial M}d\omega=\int_{\partial^2M}\omega=0
\end{align*}
Hence $d^2\omega$ must be $0$.



In the following sections, we shall first define $d\omega$ on a chart using an explicit formula. Then, we will show that property $\boxed{2}$ holds whenever $D,\Omega$ are equipped with global coordinates. This will imply that the definition of the exterior derivative $d$ is independent of coordinates, and hence can be defined for differential forms on arbitrary smooth manifolds. It will also imply that $\boxed{2}$ holds when $D,\Omega$ are general manifolds not necessarily possessing global coordinates. 

Property $\boxed{2}$ will play a crucial role in our proof of Stokes' theorem, since it allows us to reduce the general case to the special case that $\omega$ is a compactly supported smooth $k$-form on $\Hbb^k$. Thus, it can be said that property $\boxed{2}$ is one of the deepest properties of exterior derivatives. As we shall see, in order to prove $\boxed{2}$ one must first prove $\boxed{3}$. Therefore, although $\boxed{2}$ and $\boxed{3}$ will follow immediately from Stokes' theorem, and although Stokes' theorem provides the geometric intuitions for $\boxed{2}$ and $\boxed{3}$, one must first prove $\boxed{2}$ and $\boxed{3}$ \textit{algebraically} in order to prove Stokes' theorem.















\subsection{Exterior derivatives}



In this section, unless otherwise stated, we let $M$ denote a smooth $\partial$-manifold.

For any open set $U\subset M$ and any $k$-form $\omega$ and $l$-form $\eta$ on $U$, the $(k+l)$-form $\omega\wedge\eta$ on $U$ is defined by the pointwise wedge product, i.e., for each $p\in U$,
\begin{align}
(\omega\wedge\eta)|_p=(\omega|_p)\wedge(\eta|_p) 
\end{align}
where the RHS is defined by Cor. \ref{mc150} and is an element of $\bwn^{k+l}T^*_pM$. Note that if $\Phi:S\rightarrow U$ is a smooth map where $S$ is a smooth $\partial$-manifold, then by Prop. \ref{mc223}, we have
\begin{align}\label{eq558}
F^*(\omega\wedge\eta)=(F^*\omega)\wedge(F^*\eta)
\end{align}

\begin{df}\label{mc220}
Let $(U,\varphi^1,\dots,\varphi^n)$ be a chart on $M$. Let $\omega$ be a $C^1$ $k$-form on $U$, written as
\begin{align*}
\omega=\sum_{1\leq i_1<\cdots<i_k\leq n}\omega_{i_1,\dots,i_k}d\varphi^{i_1}\wedge\cdots\wedge d\varphi^{i_k}
\end{align*}
where $\omega_{i_1,\dots,i_k}\in C^1(U,\Rbb)$. The \textbf{exterior derivative}  $d\omega$ is a differential form on $U$ defined by
\begin{align}
d\omega=\sum_{1\leq i_1<\cdots<i_k\leq n}d\omega_{i_1,\dots,i_k}\wedge d\varphi^{i_1}\wedge\cdots\wedge d\varphi^{i_k}
\end{align}
where $d\omega_{i_1,\dots,i_k}$ is the $1$-form defined as in Def. \ref{mc215}.
\end{df}

The map $\omega\mapsto d\omega$ is clearly linear. At this moment, our definition of $d$ replies on the choice of $\varphi^1,\dots,\varphi^n$. We will show that the choice of coordinates is irrelevant.

\begin{lm}
Let $(U,\varphi^1,\dots,\varphi^n)$ be a chart on $M$. Let $1\leq i_1,\dots,i_k\leq n$ not necessarily satisfying $i_1<\cdots<i_k$. Let $f\in C^1(U,\Rbb)$. Then
\begin{align}\label{eq553}
d(fd\varphi^{i_1}\wedge\cdots\wedge d\varphi^{i_k})=df\wedge d\varphi^{i_1}\wedge\cdots\wedge d\varphi^{i_k}
\end{align}
\end{lm}

\begin{proof}
If there are duplicate terms among $i_1,\dots,i_k$, then both sides of \eqref{eq553} are clearly equal to $0$. Suppose that there are no duplicate terms. Then, in the special case $i_1<\cdots<i_k$,  \eqref{eq553} holds by Def. \ref{mc220}. In the general case, rearranging the order of $i_1,\dots,i_k$ in $fd\varphi^{i_1}\wedge\cdots\wedge d\varphi^{i_k}$ from smallest to largest, using Def. \ref{mc220} to calculate the exterior derivative, and then restoring the original order, yields Formula \eqref{eq553}.
\end{proof}

\begin{pp}\label{mc221}
Let $(U,\varphi^1,\dots,\varphi^n)$ be a chart on $M$. Let $\omega,\eta$ be $C^1$ $k$-forms and $l$-forms on $U$. Then
\begin{align}
d(\omega\wedge\eta)=d\omega\wedge\eta+(-1)^{\deg\omega}\cdot\omega\wedge d\eta
\end{align}
\end{pp}




\begin{proof}
By linearity, it suffices to assume $\omega=f\alpha$ and $\eta=g\beta$ where $f,g\in C^1(U,\Rbb)$ and 
\begin{align*}
\alpha=d\varphi^{i_1}\wedge\cdots\wedge d\varphi^{i_k}\qquad\beta=d\varphi^{j_1}\wedge\cdots\wedge d\varphi^{j_l}
\end{align*}
Then
\begin{align*}
&d(\omega\wedge\eta)=d(fg\cdot\alpha\wedge\beta)\xlongequal{\eqref{eq553}}d(fg)\wedge\alpha\wedge\beta\xlongequal{\eqref{eq554}}(gdf+fdg)\wedge\alpha\wedge\beta\\
=&gdf\wedge\alpha\wedge\beta+fdg\wedge\alpha\wedge\beta\xlongequal{\eqref{eq555}}(df\wedge \alpha)\wedge(g\beta)+(-1)^kf\alpha\wedge (dg\wedge\beta)\\
=&d\omega\wedge\eta+(-1)^k\cdot\omega\wedge d\eta
\end{align*}
\end{proof}



\begin{pp}\label{mc222}
Let $(U,\varphi^1,\dots,\varphi^n)$ be a chart on $M$. Let $\omega$ be a $C^2$ $k$-form on $U$. Then $d^2\omega\equiv dd\omega$ is zero.
\end{pp}


\begin{proof}
Assume WLOG that $\omega=f\alpha$ where $f\in C^2(U,\Rbb)$ and $\alpha=d\varphi^{i_1}\wedge\cdots\wedge d\varphi^{i_k}$. Then $d\alpha=0$ by Def. \ref{mc220}. Therefore, by Prop. \ref{mc221}, we have $d\omega=df\wedge\alpha$, and hence $d^2\omega=d^2f\wedge\alpha$. It suffices to show that $d^2f=0$. Since $f$ is $C^2$, by Thm. \ref{lb406} or \ref{lb407}, we have $\partial_{\varphi^i}\partial_{\varphi^j}f=\partial_{\varphi^j}\partial_{\varphi^i}f$. Thus
\begin{align*}
&d^2f=d\Big(\sum_i \partial_{\varphi^i}fd\varphi^i \Big)=\sum_j\sum_i\partial_{\varphi^j}\partial_{\varphi^i}f d\varphi^j\wedge d\varphi^i\\
=&\sum_{j<i}\partial_{\varphi^j}\partial_{\varphi^i}f d\varphi^j\wedge d\varphi^i+\sum_{j>i}\partial_{\varphi^j}\partial_{\varphi^i}f d\varphi^j\wedge d\varphi^i\\
=&\sum_{j<i}(\partial_{\varphi^j}\partial_{\varphi^i}f-\partial_{\varphi^i}\partial_{\varphi^j}f)d\varphi^j\wedge d\varphi^i=0
\end{align*}
\end{proof}









\begin{pp}\label{mc224}
Let $N$ be a smooth $\partial$-manifold, and let $\Phi:M\rightarrow N$ be a smooth map. Let $(U,\varphi)$ and $(V,\psi)$ be charts on $M$ and $N$ respectively satisfying $\Phi(U)\subset V$. Let $\omega$ be a $C^1$ differential form on $V$. Then
\begin{align}\label{eq556}
\Phi^*(d\omega)=d(\Phi^*\omega)
\end{align}
where $d\omega$ is defined by the coordinates $\varphi$, and $d(\Phi^*\omega)$ is defined by $\psi$.
\end{pp}



\begin{proof}
Step 1. Let $\scr A$ be the set of all $C^1$ differential forms $\omega$ on $V$ satisfying \eqref{eq556}. In this step, we show that if $\alpha,\beta\in\scr A$ then $\alpha\wedge\beta\in\scr A$. Choose $\alpha,\beta\in\scr A$. Using Prop. \ref{mc221} and Eq. \eqref{eq558}, we compute
\begin{align*}
&\Phi^*d(\alpha\wedge\beta)=\Phi^*(d\alpha\wedge\beta+(-1)^{\deg\omega}\alpha\wedge d\beta)\\
=&(\Phi^*d\alpha)\wedge(\Phi^*\beta)+(-1)^{\deg\omega}(\Phi^*\alpha)\wedge (\Phi^*d\beta)\\
=&d(\Phi^*\alpha)\wedge (\Phi^*\beta)+(-1)^{\deg\omega}(\Phi^*\alpha)\wedge(d\Phi^*\beta)
\end{align*}
where the fact that $\alpha,\beta\in\scr A$ is used in the last equality. Also by Prop. \ref{mc221},
\begin{align*}
d\Phi^*(\alpha\wedge\beta)=d(\Phi^*\alpha\wedge \Phi^*\beta)=d(\Phi^*\alpha)\wedge (\Phi^*\beta)+(-1)^{\deg\omega}(\Phi^*\alpha)\wedge(d\Phi^*\beta)
\end{align*}
This proves $\alpha\wedge\beta\in\scr A$.\\[-1ex]


Step 2. Let us prove that any smooth differential form $\omega$ on $V$ belongs to $\scr A$ by induction on $\deg\omega$. 

Assume $\deg\omega=0$. Then $\omega$ is a $C^1$ function. Then by Prop. \ref{lb985}, we have $\Phi^*d\omega=d(\omega\circ\Phi)=d(\Phi^*\omega)$. 

Assume $\deg\omega=1$.  By linearity, it suffices to assume $\omega=fd\varphi^i$ for some $f\in C^1(V,\Rbb)$. We have proved that $f\in\scr A$. Thus, by Step 1, it suffices to prove that $d\varphi^i\in\scr A$. By Prop. \ref{mc222}, we have $\Phi^*dd\varphi^i=0$ and (by the case $\deg=0$)
\begin{align*}
d\Phi^*d\varphi^i=d^2\Phi^*\varphi^i=0
\end{align*}
This proves $d\varphi^i\in\scr A$.

Finally, assume that every smooth differential forms on $V$ of degree $\leq k$ belongs to $\scr A$ (where $k\in\Zbb_+$). Let $\deg\omega=k+1$. By linearity, we may assume that $\omega$ is of the form $\omega=\alpha\wedge\beta$ where $\alpha,\beta$ are $C^1$ differential forms on $V$ and $1\leq\deg\alpha,\deg\beta\leq k$. (For example, we may assume $\omega=fd\varphi^{i_1}\wedge\cdots\wedge d\varphi^{i_{k+1}}$ where $f\in C^1(V,\Rbb)$. Then we can set $\alpha=fd\varphi^{i_1}\wedge\cdots\wedge d\varphi^{i_k}$ and $\beta=d\varphi^{i_{k+1}}$.) Then by the lower degree cases, we have $\alpha,\beta\in\scr A$. Thus $\omega\in\scr A$ by Step 1. This finishes the proof.
\end{proof}



\begin{co}\label{mc225}
Let $(U,\varphi)$ and $(U,\psi)$ be charts on $M$, and let $\omega$ be a $C^1$ differential form on $U$. Then the exterior derivative $d\omega$ defined by $\varphi$ is equal to the one defined by $\psi$.
\end{co}

\begin{proof}
In Prop. \ref{mc224}, set $N=M$, $V=U$, and $\Phi=\id_M$.
\end{proof}


The following theorem summarizes the main properties about exterior derivatives.

\begin{thm}\label{mc226}
Let $r\in\Zbb_+$. For each smooth $\partial$-manifold and each $C^r$ $k$-form $\omega$ on $M$, there is a unique $(k+1)$-form $d\omega$ on $M$ (called the \textbf{exterior derivative} of $\omega$) \index{00@Exterior derivative} satisfying the following property:
\begin{itemize}
\item For any chart $(U,\varphi)$ on $M$, the restriction $d\omega|_U$ is equal to the exterior derivative $d(\omega|_U)$ defined as in Def. \ref{mc220}. 
\end{itemize}
Moreover, $d\omega$ is $C^{r-1}$. The map $\omega\mapsto d\omega$ is linear. If $\omega,\eta$ are $C^r$ differential forms on $M$, then
\begin{align}
d(\omega\wedge\eta)=d\omega\wedge\eta+(-1)^{\deg\omega}\cdot \omega\wedge d\eta
\end{align}
If $r\geq2$, then
\begin{align}
d^2\omega=0
\end{align}
If $\Phi:S\rightarrow M$ is a smooth map where $S$ is a smooth $\partial$-manifold, then
\begin{align}\label{eq559}
\Phi^*d\omega=d\Phi^*\omega
\end{align}
\end{thm}

\begin{proof}
The uniqueness is obvious. The existence follows from Cor. \ref{mc225}. The other properties follow from the results proved in this section.
\end{proof}

\begin{sexe}\label{mc227}
Let $r\in\Zbb_+$. Prove that for each $C^2$ $\partial$-manifold and each $C^r$ $k$-form $\omega$ on $M$, there is a unique $(k+1)$-form $d\omega$ on $M$ whose local expression (with respect to a chart) is determined  by Def. \ref{mc220}. Prove that  $d\omega$ is $C^{r-1}$.

Let $S$ be a $C^2$ $\partial$-manifold. Let $\Phi:S\rightarrow M$ be a $C^2$-maps. Prove that $\Phi^*\omega$ is a $C^1$ $k$-form, and that $\Phi^*d\omega=d\Phi^*\omega$.  \hfill\qedsymbol
\end{sexe}











\subsection{Stokes' theorem}

\subsubsection{Proof of Stokes' theorem}


\begin{thm}[\textbf{Stokes' theorem}] \index{00@Stokes' theorem}\label{mc230}
Let $n\in\Zbb_+$. Let $M$ be a smooth oriented $\partial$-manifold with $\dim M=n$. Let $\omega$ be a $C^1$-differential $(n-1)$-form on $M$ with compact support. Equip $\partial M$ with the boundary orientation. Then
\begin{align}\label{eq560}
\int_{\partial M}\omega=\int_Md\omega
\end{align}
\end{thm}

Note that by Conv. \ref{mc190}, $\int_{\partial M}\omega$ actually means $\int_{\partial M}\omega|_{\partial M}$ where $\omega|_{\partial M}$ is the pullback of $\omega$ by the inclusion map $\partial M\hookrightarrow M$.

\begin{proof}
Step 1. Let $K$ be the support of $\omega$, i.e., the closure of $\{p\in M:\omega|_p\neq0\}$. Since $K$ is compact, there exist connected charts $(U_1,\varphi_1),\dots,(U_k,\varphi_k)$ of $M$ covering $K$. By choosing a smooth partition of unity of $K$ subordinate to $U_1,\dots,U_k$ (cf. Thm. \ref{mc27}), we can write $\omega=\omega_1+\cdots \omega_k$ where each $\omega_i$ is a $C^1$ $(n-1)$-form compactly supported in $U_i$. for each $1\leq i\leq k$.  Therefore, it suffices to prove that $\int_{\partial M}\omega_i=\int_Md\omega_i$. 

Let $V_i=\varphi_i(U_i)$. Let $\pm$ be $+$ (resp. $-$) if $\varphi_i$ is orientation-preserving (resp. orientation-reversing). Since $\partial M\cap U_i=\partial U_i$, we have
\begin{align*}
\int_{\partial M}\omega_i=\int_{\partial U_i}\omega_i\xlongequal{\eqref{eq527}}\pm\int_{\partial V_i}\varphi_*\omega_i
\end{align*} 
We also have
\begin{align*}
\int_M d\omega=\int_{U_i}d\omega\xlongequal{\eqref{eq527}}\pm\int_{V_i}\varphi_*d\omega_i\xlongequal{\eqref{eq559}}\pm\int_{V_i}d\varphi_*\omega_i
\end{align*}
Thus, it suffices to prove $\int_{\partial V_i}\varphi_*\omega_i=\int_{V_i}d\varphi_*\omega_i$.  \\[-1ex]

Step 2. Replacing $M$ with $V_i$ and $\omega$ with $\varphi_*\omega_i$, it suffices to prove \eqref{eq560} under the assumption that $M$ is an open subset of $\Hbb^n$, and that $\omega$ is a compactly supported $C^1$ $(n-1)$-form on $M$. Thus, it suffices to prove
\begin{align*}\label{eq561}
\int_{\partial\Hbb^n}\omega=\int_{\Hbb^n}d\omega\tag{$\star$}
\end{align*}
Let $(x^1,\dots,x^n)$ be the standard coordinates of $\Hbb^n$. Then $\omega$ is a linear combination of the following two cases.

Case 1: $\omega=fdx^2\wedge\cdots\wedge dx^{n-1}$ where $f\in C_c^1(\Hbb^n,\Rbb)$. Then
\begin{align*}
\int_{\partial\Hbb^n}\omega=-\int_{\Rbb^{n-1}}f(0,\mbf y)dm(\mbf y)
\end{align*}
where $\mbf y$ denotes a variable in $\Rbb^{n-1}$. On the RHS, we have the negative sign because the diffeomorphism $p\in\Rbb^{n-1}\mapsto (0,p)\in\partial\Hbb^n$ is orientation-reversing since $\partial\Hbb^n$ is equipped with the boundary orientation (cf. Thm. \ref{mc170}). Also,
\begin{align*}
&\int_{\Hbb^n}d\omega=\int_{\Hbb^n}\partial_1f dx^1\wedge\cdots\wedge dx^n=\int_{\Hbb^n}\partial_1f(x,\mbf y)dm(x,\mbf y)\\
=&\int_{\Rbb^{n-1}}\int_0^{+\infty}\partial_1f(x,\mbf y)dm(x)dm(\mbf y)=-\int_{\Rbb^{n-1}}f(0,\mbf y)dm(\mbf y)
\end{align*}
where the last equality is due to the fundamental theorem of calculus. This proves \eqref{eq561}.

Case 2: $\omega=fdx^1\wedge\cdots\wedge\wht{dx^k}\wedge\cdots\wedge dx^n$ where $2\leq k\leq n$. (In particular, $n\geq2$.) Then $\omega|_{\partial\Hbb^n}=0$. (Proof: Let $\iota:\partial\Hbb^n\rightarrow\Hbb^n$ be the inclusion map. Then $\iota^*dx^1=0$. Thus $\iota^*\omega=\iota^*f\cdot\iota^*dx^1\wedge\cdots=0$.) So $\int_{\partial\Hbb^n}\omega=0$. On the other hand
\begin{align*}
\int_{\Hbb^n}d\omega=(-1)^{k+1}\int_{\Hbb^n}\partial_kf dx^1\wedge\cdots\wedge dx^n=(-1)^{k+1}\int_{\Hbb^n}\partial_kfdm
\end{align*}
We can use Fubini's theorem to write the last term above as an iterated integral where the inside integral is $\int_\Rbb \partial_kf(x_1,\dots,x_n)dx_k$, which equals $0$ by the fundamental theorem of calculus and the fact that $x_k\in\Rbb\mapsto f(x_1,\dots,x_n)$ is a compactly supported $C^1$-function. This proves \eqref{eq561}, since both sides of \eqref{eq561} are zero.
\end{proof}



\begin{srem}
Stokes' theorem holds more generally when $M$ is a $C^2$ oriented $\partial$-manifold, since exterior derivatives can be defined for $C^1$ differential forms on $C^2$-manifolds (cf. Exe. \ref{mc227}).
\end{srem}


\subsubsection{Divergence theorem}


\begin{df}\label{mc228}
Let $(M,\gk,\mc O)$ be a Riemanniann oriented $\partial$-manifold with volume form $\varpi_M$, Riesz isomorphism $\Theta_M:\bwn^kTM\rightarrow\bwn^kT^*M$, and Hodge star $\star$.  Let $X:M\rightarrow TM$ be a $C^1$ vector field. Then
\begin{align}\label{eq563}
\dive X:=\bk{d\star \Theta_MX,\varpi_M}\equiv\frac{d\star \Theta_MX}{\varpi_M}
\end{align} 
(which is a smooth function $M\rightarrow\Rbb$) is called the \textbf{divergence} \index{00@Divergence} of $X$.
\end{df}

\begin{rem}
In Def. \ref{mc228}, let $(U,\varphi^1,\dots,\varphi^n)$ be a chart on $M$, and write
\begin{align*}
X|_U=\sum_{i=1}^nX_i\frac{\partial}{\partial\varphi^i}
\end{align*}
Let $G=[\gk(\partial_{\varphi}\otimes \partial_{\varphi})]$. Then
\begin{align}\label{eq562}
\dive X|_U=\frac 1{\sqrt {\det G}}\sum_{i=1}^n\partial_i({\sqrt{\det G}\cdot X^i})
\end{align}
\end{rem}


\begin{proof}
Let $\pm$ be $+$ (resp. $-$) if $\varphi$ is orientation-preserving (resp. orientation-reversing). By Lem. \ref{mc203}, we have
\begin{align*}
\star\Theta_M X|_U=\pm\sum_{i=1}^n(-1)^i \sqrt{\det G}\cdot X^id\varphi^1\wedge\cdots\wht{d\varphi^i}\wedge\cdots\wedge d\varphi^n
\end{align*}
Thus $d\star\Theta_M X|_U=\pm\sum_i\partial_i(\sqrt{\det G}\cdot X^i)d\varphi^1\wedge\cdots\wedge d\varphi^n$. Dividing it by $\varpi_M$ (which equals $\pm\sqrt{\det G}d\varphi^1\wedge\cdots\wedge d\varphi^n$ by Cor. \ref{mc229}), we get \eqref{eq562}.
\end{proof}


\begin{co}[\textbf{Divergence theorem}]\index{00@Divergence theorem}
Let $(M,\gk)$ be a Riemanniann oriented $\partial$-manifold. Let $X:M\rightarrow TM$ be a smooth vector field with compact support. Then
\begin{align}
\int_{\partial M}X\cdot d{\Sbf}=\int_M\dive X\cdot\dvol_M
\end{align}
\end{co}

\begin{proof}
Recall from Thm. \ref{mc206} that the surface integral $\int_{\partial M}X\cdot d{\Sbf}$ is $\int_{\partial M}\star\Theta X$. By Stokes' theorem,
\begin{align*}
\int_{\partial M}\star\Theta X=\int_M d\star\Theta X\xlongequal{\eqref{eq563}}\int_M\dive X\cdot \varpi_M
\end{align*}
where the last term equals $\int_M\dive X\cdot\dvol_M$ by Thm. \ref{mc208}.
\end{proof}





\subsection{Closed forms and exact forms}


Fix a smooth $\partial$-manifold $M$. A smooth differential form $\omega$ on $M$ is called a \textbf{closed form} if $d\omega=0$; it is called an \textbf{exact form} if $\omega=d\eta$ for some smooth differential form $\eta$ on $M$. Since $d^2=0$, an exact form must be closed. The converse is not necessarily true. 

The question of when every closed form on a manifold $M$ is exact is closely related to the topology of $M$. For example, we can prove that all closed forms on $\mathbb{R}^n$ are exact, whereas this is not the case for $\mathbb{R}^n \setminus \{0\}$. From this, we can conclude that $\Rbb^n$ is not diffeomorphic to $\Rbb^n\setminus\{0\}$. A detailed discussion on this topic involves de Rham cohomology, which is beyond the scope of this course. Interested readers can refer to the classical book \cite{BT}. 

\begin{eg}
Assume that $M$ is a smooth oriented compact manifold (without boundary). Let $n=\dim M$. Then every smooth $n$-form on $M$ is clearly closed (since $\bwn^{n+1}T^*M=0$). However, if we choose a Riemannian metric on $M$, and let $\omega$ be the volume form on $M$, then $\omega$ is not closed.
\end{eg}

\begin{proof}
Let $\omega$ be the volume form. By Thm. \ref{mc208}, we have $\int_M\omega=\Vol(M)>0$. If $\omega$ is exact, then $\omega=d\eta$ for some smooth $n-1$ form $\eta$ on $M$, and hence $\int_M\omega=\int_{\partial M}\eta=0$ by Stokes' theorem. This is impossible.
\end{proof}



In the case that $M$ is not compact, the following is one of the most famous examples of closed non-exact forms.


\begin{eg}\label{mc233}
Let $n\geq2$ and $M=\Rbb^n\setminus\{0\}$. Let $\varpi_{\Sbb^{n-1}}$ be the volume form of $\Sbb^{n-1}$. Let $\fk r:M\rightarrow \Sbb^{n-1}$ be defined by $\fk r(p)=p/\Vert p\Vert$. Let $\omega=\fk r^*\varpi_{\Sbb^{n-1}}$. Then $\omega$ is a smooth $(n-1)$-form on $M$ which is closed but not exact. Moreover,
\begin{align}\label{eq566}
\omega=\sum_{i=1}^n\frac{(-1)^{i+1}x^idx^1\wedge\cdots\wedge\wht{dx^i}\wedge\cdots\wedge dx^n}{\big((x^1)^2+\cdots+(x^n)^2\big)^{\frac n2}}
\end{align}
\end{eg}


\begin{proof}
Since $d$ commutes with $\fk r^*$ (cf. \eqref{eq559}), we have $d\omega=d(\fk r^*\varpi_{\Sbb^{n-1}})=\fk r^*d\varpi_{\Sbb^{n-1}}=0$. So $\omega$ is closed. If $\omega=d\eta$ where $\eta$ is a smooth $(n-2)$-form on $M$, then
\begin{align*}
\int_{\Sbb^{n-1}}\omega=\int_{\partial\Sbb^{n-1}}\eta=0
\end{align*}
by Stokes' theorem. This is impossible, since
\begin{align*}
\int_{\Sbb^{n-1}}\omega=\int_{\Sbb^{n-1}}\varpi_{\Sbb^{n-1}}=\Vol(\Sbb^{n-1})>0
\end{align*}
So $\omega$ is not exact.


For each $p\in M$, consider $d\fk r|_p:\Rbb^n\simeq T_pM\rightarrow T_{\fk r(p)}\Sbb^{n-1}$ where $T_{\fk r(p)}\Sbb^{n-1}$ is viewed as a subspace of $\Rbb^n$. It is easy to see that $d\fk r|_p$ is $\Vert p\Vert^{-1}$ times the orthogonal projection onto $T_{\fk r(p)}\Sbb^{n-1}$. Therefore, by the following Lem. \ref{mc232}, 
\begin{align*}
\omega|_p=\fk r^*(\varpi_{\Sbb^{n-1}}|_{\fk r(p)})=\Vert p\Vert^{1-n}\star\Theta_M \nu_{\fk r(p)}
\end{align*}
where $\nu_{\fk r(p)}$ is the unit vector orthogonal to $T_{\fk r(p)}\Sbb^{n-1}$ and pointing outward. Thus, writing $p=(p_1,\dots,p_n)$, we have
\begin{align*}
\nu_{\fk r(p)}=\Vert p\Vert^{-1}(p_1\partial_{x^1}+\cdots+p_n\partial_{x^n})
\end{align*}
and hence
\begin{align*}
&\omega|_p=\Vert p\Vert^{-n}\star\Theta_M(p_1\partial_{x^1}+\cdots+p_n\partial_{x^n})=\sum_i \Vert p\Vert^{-n}p_i\star dx^i\\
\xlongequal{\eqref{eq535}}&\sum_i(-1)^i\Vert p\Vert^{-n}p_idx^1\wedge\cdots\wedge\wht{dx^i}\wedge\cdots\wedge dx^n
\end{align*}
This proves \eqref{eq566}.
\end{proof}



\begin{lm}\label{mc232}
Assume $n\geq2$. Let $(V,\mc O_V)$ be an $n$-dimensional oriented real inner product space with Hodge star $\star$ and Riesz isomorphism $\Theta:V\rightarrow V^*$. Let $U$ be an $(n-1)$-dimensional subspace of $V$ with orientation $\mc O_U$ and positive unit normal vector $\nu$. Let $\varpi_U\in\bwn^{n-1}U^*$ be the volume tensor of $(U^*,\mc O_{U^*})$ (i.e., the volume form of $(U,\mc O_U)$). Let $\pi:V\rightarrow U$ be the orthogonal projection onto $U$. Then
\begin{align}
(\pi^\tr)^{\wedge(n-1)}\varpi_U=\star\Theta\nu
\end{align}
\end{lm}



It follows that for each $\lambda\in\Rbb$ we have
\begin{align}
(\lambda\pi^\tr)^{\wedge(n-1)}\varpi_U=\lambda^{n-1}\star\Theta\nu
\end{align}


\begin{proof}
Let $e_2,\dots,e_n$ be a positive orthonormal basis of $U$ and $\nu=e_1$. Then $e_1,\dots,e_n$ are a positive orthonormal basis of $V$ whose dual basis is denoted by $\wch e^1,\dots,\wch e^n$. With abuse of notations, we also let $\wch e^2,\dots,\wch e^n$ denote the dual basis of $e_2,\dots,e_n$. Then $\pi^\tr \wch e^i=\wch e^i$ if $2\leq i\leq n$, and $\pi^\tr \wch e^1=0$. Since $\varpi_U=\wch e^2\wedge\cdots\wedge\wch e^n$, we have $(\pi^\tr)^{\wedge(n-1)}\varpi_U=\wch e^2\wedge\cdots\wedge\wch e^n$, where the RHS also equals $\star\Theta e_1=\star\wch e^1$.
\end{proof}




\subsection{Manifolds with corners}

In practice, Stokes' theorem is usually applied to more general geometric objects than smooth manifolds with boundary. The simplest example is the cube $[0,1]^n$ (where $n\geq 2$), which is not a $C^1$ $\partial$-submanifold of $\Rbb^n$, but a smooth manifold with corners. In this section, we outline the basic theory of manifolds with corners. Many properties of manifolds with corners are direct generalizations of those of manifolds with boundaries, and the proofs are similar. Therefore, we leave the details of the proofs to the readers. See also \cite[Ch. 16]{Lee} for a discussion of manifolds with corners.

A standard example of a smooth manifolds with corners is $\Rbb_{\geq0}^k$. Its manifold interior is defined to be the topological interior (with respect to $\Rbb^k$), namely,
\begin{align}
\Int\Rbb_{\geq0}^k=\Rbb_{>0}^k
\end{align}
However, if we define $\partial\Rbb_{\geq0}^k$ to be its topological boundary (with respect to $\Rbb^k$) which is the zero set $Z(x^1\cdots x^n)$, then  $\partial\Rbb_{\geq0}^k$ is not a smooth $\partial$-submanifold of $\Rbb^k$. Instead, we define
\begin{align*}
\partial\Rbb_{\geq0}^k=\{p\in Z(x^1\cdots x^n)\cap\Rbb^k_{\geq0}:d(x^1\cdots x^n)|_p\neq 0\}
\end{align*}
Then one checks easily that $\partial\Rbb_{\geq0}^k=\bigsqcup_{1\leq i\leq k}\mbf H^{k-1}_i$ where
\begin{align}\label{eq552}
\mbf H^{k-1}_i=\{(a_1,\dots,a_n)\in\Rbb^k:a_i=0\text{, and }a_j>0\text{ for all }j\neq i\}
\end{align}


\begin{df}
A second countable Hausdorff space $M$ is called a \textbf{smooth manifolds with corners} \index{00@Manifolds with corners} if $M$ is equipped with a collection $(U_\alpha,\varphi_\alpha)_{\alpha\in\scr A}$ (called an \textbf{atlas}) satisfying the following properties:
\begin{itemize}
\item Each $U_\alpha$ is open, and $M=\bigcup_{\alpha\in\scr A}U_\alpha$.
\item Each $\varphi_\alpha:U_\alpha\rightarrow\varphi_\alpha(U_\alpha)$ is a homeomorphism where $\varphi_\alpha(U_\alpha)$ is an open subset of  $\Rbb_{\geq0}^{k_\alpha}$ for some $k_\alpha\in\Nbb$.
\item For each $\alpha,\beta\in\scr A$, $\varphi_\alpha$ and $\varphi_\beta$ are $C^\infty$-compatible.
\end{itemize}
A point $p\in M$ is called an \textbf{interior point} resp. \textbf{boundary point} if there exists a chart $(U_\alpha,\varphi_\alpha)$ containing $p$ such that $\varphi_\alpha(p)\in \Rbb_{>0}^k$ resp. $\varphi_\alpha(p)\in\partial\Rbb_{\geq0}^k$. The set of interior points resp. boundary points is denoted by $\Int M$ resp. $\partial M$. If $p\in M$ is neither an interior point nor a boundary point, it is called a \textbf{corner point}.
\end{df}

We leave it to the readers to check that the notion of interior point (resp. boundary point, corner point) is independent of the choice of charts. (Cf. \cite[Prop. 16.20]{Lee}.) 


\begin{eg}
If $M$ is a smooth $k$-dimensional manifold with corners, then $\partial M$ is canonically a smooth $(k-1)$-dimensional manifold (without boundary).
\end{eg}

\begin{rem}
Our definition of boundary points is different from that in \cite{Lee} in that Lee includes corner points as part of the boundary. This leads to the boundary $\partial M$ not even a boundary with corner. (For example, if $M=[0,1]^n$, then Lee's definition of $\partial M$ is equal to the topological boundary of $M$ with respect to $\Rbb^n$.) The reason Lee defines $\partial M$ this way is because his treatment of integration on manifolds is limited to compactly supported continuous functions. Therefore, if $f$ is a compactly supported continuous function on a manifold with corners $M$,
then $f|_{\partial M}$ has compact support if $\partial M$ is defined as in \cite{Lee}, but does not necessarily have compact support if we use our definition of $\partial M$. We can freely handle Borel functions with non-compact supports, thanks to our systematic introduction of measure theory.
\end{rem}





If $N$ is a smooth manifold, a \textbf{smooth submanifold of $N$ with corner} is defined in a similar way to smooth $\partial$-submanifolds (cf. Def. \ref{mc13}), i.e., its inclusion map into $N$ is locally equivalent to $V\cap\Rbb_{\geq0}^k\hookrightarrow V$ for some open subset $V\subset\Rbb^k$.


Note that a smooth manifold with corners does not necessarily have a ``corner point". For example, any open subset of $\Rbb_{\geq0}^k$, whether containing $0_k$ or not, is a manifolds with corners. From this observation, we see that any open subset of $\Rbb^k$ is a smooth manifolds with corners.


The following theorem can be proved in a similar way to Thm. \ref{lb999}:
\begin{thm}
Let $M,N$ be smooth manifolds (without boundary). Let $F:M\rightarrow N\times\Rbb^k$ be smooth. Let $q\in N$ and $P=F^{-1}(\{q\}\times\Rbb_{\geq0}^k)$. Assume that  $dF|_p:T_pM\rightarrow T_{F(p)}(N\times\Rbb^k)$ is surjective for every $p\in P$. Then $P$ is a smooth submanifold of $M$ with corners, and 
\begin{align}
\partial P=\bigsqcup_{i=1}^kF^{-1}\big(\{q\}\times\mbf H_i^{k-1}\big)
\end{align}
Moreover,  we have
\begin{align}
\dim_pP=\dim_pM-\dim_qN
\end{align}
\end{thm}





Since $\Rbb_{\geq0}^k\times\Rbb_{\geq0}^n\simeq\Rbb_{\geq0}^{k+n}$ is a smooth manifold with corners, we see that a (finite) product of smooth manifolds with corners is a smooth manifold with corners. In particular:
\begin{eg}
If $M,N$ are smooth $\partial$-manifolds, then $M\times N$ is canoincally a smooth manifold with corners. Moreover, we have
\begin{align}
\partial (M\times N)=((\partial M)\times\Int N)\sqcup (\Int M\times\partial N)
\end{align}
\end{eg}

From this, we easily see that the cube $[0,1]^k$ is a smooth $k$-dimensional manifolds with corners. Similarly, $\Hbb^k=\Rbb_{\geq0}\times\Rbb^{k-1}$ is a smooth manifold with corners. Therefore,
\begin{eg}
A smooth $\partial$-manifold is canonically a smooth manifold with corner.
\end{eg}


The orientations of smooth manifolds with corners are defined in a similar to smooth $\partial$-manifolds. The boundary orientation is also defined to be the outward-pointing orientation. Moreover, if $M$ is an oriented manifolds with corners, we let $-M$ denote the same manifold but with negative orientations. More generally, if $M$ is oriented and has connected components $M_1,\dots,M_l$, for each $1\leq j\leq l$ we let $\sgm_j\in\{\pm1\}$. Then
\begin{align*}
\sgm_1M_1+\cdots+\sgm_lM_l
\end{align*}
denotes the same manifold as $M$ whose restriction to $M_j$ has the same (resp. opposite) orientation as the corresponding component as that of $M$ if $\sgm_j=1$ (resp. $\sgm_j=-1$).

We leave it to the readers to define the integrals of functions and differential forms on smooth manifolds with corners.





\begin{exe}
Let $M$ be a $k$-dimensional smooth oriented manifold with corners. Let $\omega$ be a continuous $(k-1)$-form on $M$ with compact support. Prove that $\int_{\partial M}\omega$ is integrable. (Note that the support of $\omega|_{\partial M}$ is not necessarily compact.)
\end{exe}



\begin{exe}\label{mc217}
Equip $\Rbb_{\geq0}^k$ with the standard orientation, i.e., the one of $dx^1\wedge\cdots\wedge dx^k$. Equip $\partial\Rbb_{\geq0}^k$ with the boundary orientation which restricts to an orientation on $\mbf H^{k-1}_i=\eqref{eq552}$. Prove that the diffeomorphism
\begin{align*}
\Phi_i:\Rbb_{>0}^{k-1}\rightarrow \mbf H^{k-1}_i\qquad (a_1,\dots,a_k)\mapsto (a_1,\dots,a_{i-1},0,a_{i+1},\dots,a_k)
\end{align*}
is orientation-preserving (resp. orientation-reversing) if $(-1)^i$ is $+1$ (resp. $-1$).
\end{exe}

Using Exe. \ref{mc217}, it is easy to prove:
\begin{pp}
Let $M$ and $N$ be equidimensional smooth oriented manifolds with corners. Unless otherwise stated, we always equip $M\times N$ with the orientation as in Exp. \ref{mc219}.  Then
\begin{align}\label{eq565}
\partial(M\times N)=(\partial M)\times \Int N+(-1)^{\dim M} \Int M\times(\partial N)
\end{align}
\end{pp}
Notice the formal similarity between \eqref{eq565} and the formula $d(\omega\wedge\eta)=d\omega\wedge\eta+(-1)^{\deg\omega}\omega\wedge d\eta$.


\begin{comment}
\begin{exe}
Let $M$ and $N$ be equidimensional smooth oriented manifolds with corners. Let $\dim M=k$ and $\dim N=l$. Let $\omega\geq0$ be a Borel $k$-form on $M$. Let $\eta\geq0$ be a Borel $N$-form on $N$. We understand $\omega\wedge\eta$ as $(\pi_M^*\omega)\wedge(\pi_N^*\eta)$ where $\pi_M:M\times N\rightarrow M$ and $\pi_N:M\times N\rightarrow N$ are projections.  Prove that $\omega\wedge\eta\geq0$ (with respect to the orientation of $M\times N$), and that
\begin{align}
\int_{M\times N}\omega\wedge\eta=\int_M\omega\cdot\int_N\eta
\end{align}
\end{exe}
\end{comment}





\begin{thm}[\textbf{Stokes' theorem}] \index{00@Stokes' theorem for manifolds with corner}
Let $n\in\Zbb_+$. Let $M$ be a smooth oriented manifold with corners satisfying $\dim M=n$. Let $\omega$ be a $C^1$-differential $(n-1)$-form on $M$ with compact support. Equip $\partial M$ with the boundary orientation. Then
\begin{align}
\int_{\partial M}\omega=\int_Md\omega
\end{align}
\end{thm}


\begin{proof}
The proof is similar to that of Thm. \ref{mc230}, namely, by reducing it to the special case that $M=\Rbb_{\geq0}^n$. We leave the details to the readers.
\end{proof}






















\printindex	






	\begin{thebibliography}{999999}
		\footnotesize	

\bibitem[AK]{AK}
Albiac, F., \& Kalton, N. J. (2006). Topics in Banach space theory (Vol. 233, pp. xii+-373). New York: Springer.

\bibitem[Apo]{Apo}
Apostol, Tom M. (1974). Mathematical analysis. 2nd ed.


\bibitem[Axl]{Axl}
Axler, S. (2015). Linear algebra done right. 3rd ed.

\bibitem[BK84]{BK84}
Birkhoff, G., \& Kreyszig, E. (1984). The establishment of functional analysis. Historia Mathematica, 11(3), 258-321.

%\bibitem[BS]{BS}
%B\"uhler, T., \& Salamon, D. A. (2018). Functional analysis (Vol. 191). American Mathematical Soc..


\bibitem[BNS84]{BNS84}
Butzer, P. L., Nessel, R. J., \& Stark, E. L. (1984). Eduard Helly (1884-1943), in memoriam. Results in Mathematics, 7(2), 145-153.

\bibitem[BT]{BT}
Bott, R., \& Tu, L. W. (1982). Differential forms in algebraic topology (Vol. 82, pp. xiv+-331). New York: Springer.


\bibitem[Ber65]{Ber65}
Bernkopf, M. (1965). The development of function spaces with particular reference to their origins in integral equation theory. Archive for History of Exact Sciences.

\bibitem[CL]{CL}
Coddington, E. A., Levinson, N. (1955). Theory of ordinary differential equations.

\bibitem[Che92]{Che92}
Chernoff, P. R. (1992). A simple proof of Tychonoff's theorem via nets. The American mathematical monthly, 99(10), 932-934.


\bibitem[Die-H]{Die-H}
Dieudonn\'e, J. (1983). History of Functional Analysis. North Holland, 1st edition.

\bibitem[Eva]{Eva}
Evans, L. C. (2022). Partial differential equations (Vol. 19). American Mathematical Society.

\bibitem[Fol-P]{Fol-P}
Folland, G. B. Introduction to partial differential equations. 2nd ed. Princeton, NJ: Princeton University Press (1995)

\bibitem[Fol-R]{Fol-R}
Folland, G. B. (1999). Real analysis: modern techniques and their applications. 2nd ed.

\bibitem[G\"od47]{God47}
G\"odel, K. (1947). What is Cantor's continuum problem?. The American Mathematical Monthly, 54(9), 515-525.

%\bibitem[Gray84]{Gray84}
%Gray, J. D. (1984). The shaping of the Riesz representation theorem: A chapter in the history of analysis. Archive for History of Exact Sciences, 31, 127-187.

\bibitem[Gud74]{Gud74}
Gudder, S. (1974). Inner product spaces. The American Mathematical Monthly, 81(1), 29-36.

\bibitem[HR-1]{HR-1}
Hewitt, E., \& Ross. K. A., Abstract harmonic analysis. Volume I: Structure of topological groups, integration theory, group representations. 2nd ed. Berlin: Springer-Verlag (1994)

\bibitem[HS]{HS}
Hewitt, E., \& Stromberg, K. (1969). Real and abstract analysis: A modern treatment of the theory of functions of a real variable. 2nd printing corrected.

\bibitem[Hal63]{Hal63}
Halmos, P. R. (1963). What does the spectral theorem say?. The American Mathematical Monthly, 70(3), 241-247.

\bibitem[Hau14]{Hau14}
Hausdorff, F. (1914) Grundz\"uge der Mengenlehre


\bibitem[Haw]{Haw}
Hawkins, T. (1979) Lebesgue's theory of integration: Its origins and development. Corrected reprint of the 2nd edition. 


\bibitem[Hel12]{Hel12}
Helly, E. (1912) \"Uber lineare Funktionaloperationen. Wien. Ber. 121, 265-297

\bibitem[Hel21]{Hel21}
Helly, E. (1921). \"Uber Systeme linearer Gleichungen mit unendlich vielen Unbekannten. Monatshefte f\"ur Mathematik und Physik, 31, 60-91.


\bibitem[Hil12]{Hil12}
Hilbert, D. (1912) Grundz\"uge einer allgemeinen Theorie der linearen Integralgleichungen.

\bibitem[Jah]{Jah}
Jahnke, H. N. (2003). A history of analysis (No. 24). American Mathematical Soc..


\bibitem[Kel]{Kel}
Kelley, J. L., General topology. 

\bibitem[Kli]{Kli}
Kline, M. (1990). Mathematical Thought from Ancient to Modern Times.

\bibitem[Lax]{Lax}
Lax, P. D., (2002) Functional analysis. 


\bibitem[Lee]{Lee}
Lee, J. M., (2013). Introduction to Smooth manifolds, 2nd ed. Springer.

\bibitem[MS22]{MS22}
Moore, E. H., \& Smith, H. L. (1922). A general theory of limits. American journal of Mathematics, 44(2), 102-121.

\bibitem[Mun]{Mun}
Munkres, J. (2000). Topology. Second Edition.

\bibitem[NB97]{NB97}
Narici, L., \& Beckenstein, E. (1997). The Hahn-Banach theorem: the life and times. Topology and its Applications, 77(2), 193-211.


\bibitem[vNeu30]{vNeu30}
von Neumann, J. (1930). Allgemeine eigenwerttheorie hermitescher funktionaloperatoren. Mathematische Annalen, 102(1), 49-131.

\bibitem[Nie]{Nie}
Nietzsche, F. W. (1887). The Gay Science: with a Prelude in Rhymes and an Appendix of Songs. Translated, with Commentary, by Walter Kaufmann (1974).

\bibitem[Ped]{Ped}
Pedersen, G. K. Analysis now. Springer-Verlag (1989)


\bibitem[Pes]{Pes}
Pesin, I. N. (1970).  Classical and modern integration theories. 

\bibitem[RF]{RF}
H. Royden, \& P. M. Fitzpatrick, Real analysis. 4th ed. Pearson Education (2010)


\bibitem[RN]{RN}
F. Riesz and B. Sz.-Nagy, Functional analysis. Transl. from the 2nd French ed. by Leo F. Boron. (1956)

\bibitem[RS]{RS}
Reed, M., \& Simon, B. (1972). Methods of Modern Mathematical Physics I: Functional analysis, Academic Press, New York.


\bibitem[Rie09]{Rie09}
Riesz, F. (1909). Sur les op\'erations functionnelles lin\'eaires. Gauthier-Vllars.

\bibitem[Rie10]{Rie10}
Riesz, F. (1910). Untersuchungen \"uber systeme integrierbarer funktionen. Mathematische Annalen, 69(4), 449-497.


\bibitem[Rie11]{Rie11}
Riesz, F. (1911). Sur certains syst\'emes singuliers d'\'equations int\'egrales. In Annales scientifiques de l'\'Ecole Normale Sup\'erieure (Vol. 28, pp. 33-62).

\bibitem[Rie13]{Rie13}
Riesz, F. (1913). Les syst\`emes d'\'equations lin\'eaires \`a une infinite d'inconnues.


\bibitem[Rie14]{Rie14}
Riesz, F. (1914). D{\'e}monstration nouvelle d'un th{\'e}or{\`e}me concernant les op{\'e}rations fonctionelles lin{\'e}aires. Ann. Sci. {\'E}c. Norm. Sup{\'e}r. (3).

\bibitem[Rie18]{Rie18}
Riesz, F. (1918). \"Uber lineare funktionalgleichungen. Acta math, 41(1), 71-98.


\bibitem[Roy]{Roy}
H. Royden, Real analysis. 3rd ed. (1988)


\bibitem[Rud-P]{Rud-P}
Rudin, W. (1976). Principles of Mathematical Analysis. 3rd ed.

\bibitem[Rud-R]{Rud-R}
Rudin, W. (1987). Real and complex analysis. 3rd ed. 


\bibitem[Rud-F]{Rud-F}
Rudin, W. (1991). Functional analysis. 2nd ed.


\bibitem[SS-R]{SS-R}
E. M. Stein and R. Shakarchi, Real analysis. Measure theory, integration, and Hilbert spaces. Princeton University Press (2005)

\bibitem[Sch54]{Sch54}
Schwartz, J. (1954). The formula for change in variables in a multiple integral. The American Mathematical Monthly, 61(2), 81-85.


\bibitem[Seg51]{Seg51}
Segal, I. E. (151). Decompositions of operator algebras, II. Providence, RI: American Mathematical Society (AMS)

\bibitem[Sim-R]{Sim-R}
Simon, B. (2015). Real analysis. A comprehensive course in analysis, part 1. Providence, RI: American Mathematical Society (AMS)

\bibitem[Sim-O]{Sim-O}
Simon, B. (2015). Operator theory. A comprehensive course in analysis, part 4. Providence, RI: American Mathematical Society (AMS) 

\bibitem[Sto37]{Sto37}
Stone, M. H. (1937). Applications of the theory of Boolean rings to general topology. Transactions of the American Mathematical Society, 41(3), 375-481.

\bibitem[Sto48]{Sto48}
Stone, M. H. (1948). The generalized Weierstrass approximation theorem. Mathematics Magazine, 21(5), 167-184, 237-254.


\bibitem[Tao]{Tao}
T. Tao, An introduction to measure theory.  American Mathematical Society (AMS) (2011)

\bibitem[Tay]{Tay}
M. E. Taylor, Partial differential equations. I: Basic theory. 2nd ed. New York, NY: Springer (2011)

\bibitem[Tes]{Tes}
G. Teschl, Ordinary differential equations and dynamical systems. Providence, RI: American Mathematical Society (AMS) (2012)

\bibitem[Wil]{Wil}
Willard, S. (1970). General topology. 

\bibitem[Yu]{Yu}
Pin Yu (2020). Lecture notes of mathematical analysis (in Chinese). Version of 2020.12.27


\bibitem[Zor-2]{Zor-2}
Zorich, V. A.(2016). Mathematical analysis II, 2nd ed.

		
\end{thebibliography}

%\noindent {\small \sc Yau Mathematical Sciences Center, Tsinghua University, Beijing, China.}

%\noindent {\textit{E-mail}}: binguimath@gmail.com\qquad bingui@tsinghua.edu.cn
\end{document}








