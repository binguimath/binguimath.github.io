% !TeX spellcheck = en_US
% !TEX program = pdflatex
\documentclass[12pt,b5paper,notitlepage]{article}
\usepackage[b5paper, margin={0.5in,0.65in}]{geometry}
%\usepackage{fullpage}
\usepackage{amsmath,amscd,amssymb,amsthm,mathrsfs,amsfonts,layout,indentfirst,graphicx,caption,mathabx, stmaryrd,appendix,calc,imakeidx,upgreek} % mathabx for \wtidecheck
%\usepackage{ulem} %wave underline
\usepackage[dvipsnames]{xcolor}
\usepackage{palatino}  %template
\usepackage{slashed} % Dirac operator
\usepackage{mathrsfs} % Enable using \mathscr
%\usepackage{eufrak}  another template/font
\usepackage{extarrows} % long equal sign, \xlongequal{blablabla}
\usepackage{enumitem} % enumerate label change e.g. [label=(\alph*)]  shows (a) (b) 


%\pmb  mandatory math bold 

\usepackage{fancyhdr} % date in footer

\usepackage{soul}  %\ul underline break line automatically

\usepackage{relsize} % use \mathlarger \larger \text{\larger[2]$...$} to enlarge the size of math symbols

\usepackage{verbatim}  % comment environment

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tcolorbox}
\tcbuselibrary{theorems}
% box around equations   \tcboxmath
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% circled colon and thick colon \hcolondel and \colondel

\usepackage{pdfrender}

\newcommand*{\hollowcolon}{%
	\textpdfrender{
		TextRenderingMode=Stroke,
		LineWidth=.1bp,
	}{:}%
}

\newcommand{\hcolondel}[1]{%
	\mathopen{\hollowcolon}#1\mathclose{\hollowcolon}%
}
\newcommand{\colondel}[1]{%
	\mathopen{:}#1\mathclose{:}%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\usepackage{tikz}
\usetikzlibrary{fadings}
\usetikzlibrary{patterns}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes}

\usepackage{tikz-cd}
\usepackage[nottoc]{tocbibind}   % Add  reference to ToC


\makeindex


% The following set up the line spaces between items in \thebibliography
\usepackage{lipsum}  
\let\OLDthebibliography\thebibliography
\renewcommand\thebibliography[1]{
	\OLDthebibliography{#1}
	\setlength{\parskip}{0pt}
	\setlength{\itemsep}{2pt} 
}


\allowdisplaybreaks  %allow aligns to break between pages
\usepackage{latexsym}
\usepackage{chngcntr}
\usepackage[colorlinks,linkcolor=blue,anchorcolor=blue, linktocpage,
%pagebackref
]{hyperref}
\hypersetup{ urlcolor=cyan,
	citecolor=[rgb]{0,0.5,0}}


\setcounter{tocdepth}{2}	 %hide subsections in the content


\counterwithin{figure}{section}

\pagestyle{plain}

\captionsetup[figure]
{
	labelsep=none	
}













\theoremstyle{definition}
\newtheorem{df}{Definition}[section]
\newtheorem{eg}[df]{Example}
\newtheorem{exe}[df]{Exercise}
\newtheorem{rem}[df]{Remark}
\newtheorem{obs}[df]{Observation}
\newtheorem{ass}[df]{Assumption}
\newtheorem{cv}[df]{Convention}
\newtheorem{prin}[df]{Principle}
\newtheorem{nota}[df]{Notation}
\newtheorem*{axiom}{Axiom}
\newtheorem{coa}[df]{Theorem}
\newtheorem{prob}{Problem}[section]
\newtheorem{sprob}[prob]{$\star$ Problem}
\newtheorem{ssprob}[prob]{$\star\star$ Problem}

\theoremstyle{plain}
\newtheorem{thm}[df]{Theorem}
\newtheorem{ccl}[df]{Conclusion}
\newtheorem{thd}[df]{Theorem-Definition}
\newtheorem{pp}[df]{Proposition}
\newtheorem{co}[df]{Corollary}
\newtheorem{lm}[df]{Lemma}


\newtheorem{cond}{Condition}
\newtheorem{Mthm}{Main Theorem}
\renewcommand{\thecond}{\Alph{cond}} % "letter-numbered" theorems
\renewcommand{\theMthm}{\Alph{Mthm}} % "letter-numbered" theorems


%\substack   multiple lines under sum
%\underset{b}{a}   b is under a


% Remind: \overline{L_0}



\usepackage{calligra}
\DeclareMathOperator{\shom}{\mathscr{H}\text{\kern -3pt {\calligra\large om}}\,}
\DeclareMathOperator{\sext}{\mathscr{E}\text{\kern -3pt {\calligra\large xt}}\,}
\DeclareMathOperator{\Rel}{\mathscr{R}\text{\kern -3pt {\calligra\large el}~}\,}
\DeclareMathOperator{\sann}{\mathscr{A}\text{\kern -3pt {\calligra\large nn}}\,}
\DeclareMathOperator{\send}{\mathscr{E}\text{\kern -3pt {\calligra\large nd}}\,}
\DeclareMathOperator{\stor}{\mathscr{T}\text{\kern -3pt {\calligra\large or}}\,}

\usepackage{aurical}
\DeclareMathOperator{\VVir}{\text{\Fontlukas V}\text{\kern -0pt {\Fontlukas\large ir}}\,}






\newcommand{\fk}{\mathfrak}
\newcommand{\mc}{\mathcal}
\newcommand{\wtd}{\widetilde}
\newcommand{\wht}{\widehat}
\newcommand{\wch}{\widecheck}
\newcommand{\ovl}{\overline}
\newcommand{\udl}{\underline}
\newcommand{\tr}{\mathrm{t}} %transpose
\newcommand{\Tr}{\mathrm{Tr}}
\newcommand{\End}{\mathrm{End}} %endomorphism
\newcommand{\idt}{\mathbf{1}}
\newcommand{\id}{\mathrm{id}}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\Conf}{\mathrm{Conf}}
\newcommand{\Res}{\mathrm{Res}}
\newcommand{\res}{\mathrm{res}}
\newcommand{\KZ}{\mathrm{KZ}}
\newcommand{\ev}{\mathrm{ev}}
\newcommand{\coev}{\mathrm{coev}}
\newcommand{\opp}{\mathrm{opp}}
\newcommand{\Rep}{\mathrm{Rep}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\Dom}{\scr D}
\newcommand{\loc}{\mathrm{loc}}
\newcommand{\con}{\mathrm{c}}
\newcommand{\uni}{\mathrm{u}}
\newcommand{\ssp}{\mathrm{ss}}
\newcommand{\di}{\slashed d}
\newcommand{\Diffp}{\mathrm{Diff}^+}
\newcommand{\Diff}{\mathrm{Diff}}
\newcommand{\PSU}{\mathrm{PSU}(1,1)}
\newcommand{\Vir}{\mathrm{Vir}}
\newcommand{\Witt}{\mathscr W}
\newcommand{\Span}{\mathrm{Span}}
\newcommand{\pri}{\mathrm{p}}
\newcommand{\ER}{E^1(V)_{\mathbb R}}
\newcommand{\prth}[1]{( {#1})}
\newcommand{\bk}[1]{\langle {#1}\rangle}
\newcommand{\bigbk}[1]{\big\langle {#1}\big\rangle}
\newcommand{\Bigbk}[1]{\Big\langle {#1}\Big\rangle}
\newcommand{\biggbk}[1]{\bigg\langle {#1}\bigg\rangle}
\newcommand{\Biggbk}[1]{\Bigg\langle {#1}\Bigg\rangle}
\newcommand{\GA}{\mathscr G_{\mathcal A}}
\newcommand{\vs}{\varsigma}
\newcommand{\Vect}{\mathrm{Vec}}
\newcommand{\Vectc}{\mathrm{Vec}^{\mathbb C}}
\newcommand{\scr}{\mathscr}
\newcommand{\sjs}{\subset\joinrel\subset}
\newcommand{\Jtd}{\widetilde{\mathcal J}}
\newcommand{\gk}{\mathfrak g}
\newcommand{\hk}{\mathfrak h}
\newcommand{\xk}{\mathfrak x}
\newcommand{\yk}{\mathfrak y}
\newcommand{\zk}{\mathfrak z}
\newcommand{\pk}{\mathfrak p}
\newcommand{\hr}{\mathfrak h_{\mathbb R}}
\newcommand{\Ad}{\mathrm{Ad}}
\newcommand{\DHR}{\mathrm{DHR}_{I_0}}
\newcommand{\Repi}{\mathrm{Rep}_{\wtd I_0}}
\newcommand{\im}{\mathbf{i}}
\newcommand{\Co}{\complement}
%\newcommand{\Cu}{\mathcal C^{\mathrm u}}
\newcommand{\RepV}{\mathrm{Rep}^\uni(V)}
\newcommand{\RepA}{\mathrm{Rep}(\mathcal A)}
\newcommand{\RepN}{\mathrm{Rep}(\mathcal N)}
\newcommand{\RepfA}{\mathrm{Rep}^{\mathrm f}(\mathcal A)}
\newcommand{\RepAU}{\mathrm{Rep}^\uni(A_U)}
\newcommand{\RepU}{\mathrm{Rep}^\uni(U)}
\newcommand{\RepL}{\mathrm{Rep}^{\mathrm{L}}}
\newcommand{\HomL}{\mathrm{Hom}^{\mathrm{L}}}
\newcommand{\EndL}{\mathrm{End}^{\mathrm{L}}}
\newcommand{\Bim}{\mathrm{Bim}}
\newcommand{\BimA}{\mathrm{Bim}^\uni(A)}
%\newcommand{\shom}{\scr Hom}
\newcommand{\divi}{\mathrm{div}}
\newcommand{\sgm}{\varsigma}
\newcommand{\SX}{{S_{\fk X}}}
\newcommand{\DX}{D_{\fk X}}
\newcommand{\mbb}{\mathbb}
\newcommand{\mbf}{\mathbf}
\newcommand{\bsb}{\boldsymbol}
\newcommand{\blt}{\bullet}
\newcommand{\Vbb}{\mathbb V}
\newcommand{\Ubb}{\mathbb U}
\newcommand{\Xbb}{\mathbb X}
\newcommand{\Kbb}{\mathbb K}
\newcommand{\Abb}{\mathbb A}
\newcommand{\Wbb}{\mathbb W}
\newcommand{\Mbb}{\mathbb M}
\newcommand{\Gbb}{\mathbb G}
\newcommand{\Cbb}{\mathbb C}
\newcommand{\Nbb}{\mathbb N}
\newcommand{\Zbb}{\mathbb Z}
\newcommand{\Qbb}{\mathbb Q}
\newcommand{\Pbb}{\mathbb P}
\newcommand{\Rbb}{\mathbb R}
\newcommand{\Ebb}{\mathbb E}
\newcommand{\Dbb}{\mathbb D}
\newcommand{\Hbb}{\mathbb H}
\newcommand{\cbf}{\mathbf c}
\newcommand{\Rbf}{\mathbf R}
\newcommand{\wt}{\mathrm{wt}}
\newcommand{\Lie}{\mathrm{Lie}}
\newcommand{\btl}{\blacktriangleleft}
\newcommand{\btr}{\blacktriangleright}
\newcommand{\svir}{\mathcal V\!\mathit{ir}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cok}{\mathrm{Coker}}
\newcommand{\Sbf}{\mathbf{S}}
\newcommand{\low}{\mathrm{low}}
\newcommand{\Sp}{\mathrm{Sp}}
\newcommand{\Rng}{\mathrm{Rng}}
\newcommand{\vN}{\mathrm{vN}}
\newcommand{\Ebf}{\mathbf E}
\newcommand{\Nbf}{\mathbf N}
\newcommand{\Stb}{\mathrm {Stb}}
\newcommand{\SXb}{{S_{\fk X_b}}}
\newcommand{\pr}{\mathrm {pr}}
\newcommand{\SXtd}{S_{\wtd{\fk X}}}
\newcommand{\univ}{\mathrm {univ}}
\newcommand{\vbf}{\mathbf v}
\newcommand{\ubf}{\mathbf u}
\newcommand{\wbf}{\mathbf w}
\newcommand{\CB}{\mathrm{CB}}
\newcommand{\Perm}{\mathrm{Perm}}
\newcommand{\Orb}{\mathrm{Orb}}
\newcommand{\Lss}{{L_{0,\mathrm{s}}}}
\newcommand{\Lni}{{L_{0,\mathrm{n}}}}
\newcommand{\UPSU}{\widetilde{\mathrm{PSU}}(1,1)}
\newcommand{\Sbb}{{\mathbb S}}
\newcommand{\Gc}{\mathscr G_c}
\newcommand{\Obj}{\mathrm{Obj}}
\newcommand{\bpr}{{}^\backprime}
\newcommand{\fin}{\mathrm{fin}}
\newcommand{\Ann}{\mathrm{Ann}}
\newcommand{\Real}{\mathrm{Re}}
\newcommand{\Imag}{\mathrm{Im}}
\newcommand{\cl}{\mathrm{cl}}
\newcommand{\Ind}{\mathrm{Ind}}
\newcommand{\Supp}{\mathrm{Supp}}
\newcommand{\Specan}{\mathrm{Specan}}
\newcommand{\red}{\mathrm{red}}
\newcommand{\uph}{\upharpoonright}
\newcommand{\Mor}{\mathrm{Mor}}
\newcommand{\pre}{\mathrm{pre}}
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\Jac}{\mathrm{Jac}}
\newcommand{\emb}{\mathrm{emb}}
\newcommand{\Sg}{\mathrm{Sg}}
\newcommand{\Nzd}{\mathrm{Nzd}}
\newcommand{\Owht}{\widehat{\scr O}}
\newcommand{\Ext}{\mathrm{Ext}}
\newcommand{\Tor}{\mathrm{Tor}}
\newcommand{\Com}{\mathrm{Com}}
\newcommand{\Mod}{\mathrm{Mod}}
\newcommand{\nk}{\mathfrak n}
\newcommand{\mk}{\mathfrak m}
\newcommand{\Ass}{\mathrm{Ass}}
\newcommand{\depth}{\mathrm{depth}}
\newcommand{\Coh}{\mathrm{Coh}}
\newcommand{\Gode}{\mathrm{Gode}}
\newcommand{\Fbb}{\mathbb F}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\Modf}{\mathrm{Mod}^{\mathrm f}}
\newcommand{\codim}{\mathrm{codim}}
\newcommand{\card}{\mathrm{card}}
\newcommand{\dps}{\displaystyle}






\usepackage{tipa} % wierd symboles e.g. \textturnh
\newcommand{\tipar}{\text{\textrtailr}}
\newcommand{\tipaz}{\text{\textctyogh}}
\newcommand{\tipaomega}{\text{\textcloseomega}}
\newcommand{\tipae}{\text{\textrhookschwa}}
\newcommand{\tipaee}{\text{\textreve}}
\newcommand{\tipak}{\text{\texthtk}}
\newcommand{\eps}{\varepsilon}




\usepackage{tipx}
\newcommand{\tipxgamma}{\text{\textfrtailgamma}}
\newcommand{\tipxcc}{\text{\textctstretchc}}
\newcommand{\tipxphi}{\text{\textqplig}}















\numberwithin{equation}{section}




\title{Qiuzhen Lectures on Analysis}
\author{{\sc Bin Gui}
	%\\
	%{\small Department of Mathematics, Rutgers university}\\
	%{\small bin.gui@rutgers.edu}
}
%\date{}
\begin{document}\sloppy % avoid stretch into margins
	\pagenumbering{arabic}
	%\pagenumbering{gobble}
	\setcounter{page}{1}
%	\setcounter{section}{-1}
	%\setcounter{equation}{6}
	



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



	
	\maketitle
%\thispagestyle{empty}	 %remove page number of this page


%Contents hyperlinks: \hyperlink{page.2}{Page 2}, \hyperlink{page.3}{Page 3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-0.5cm}
\makeatletter
\newcommand*{\toccontents}{\@starttoc{toc}}
\makeatother
\toccontents



	
% title and table of contents same page, no content title

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\section{Basic set theory and numbers}


In this chapter, we discuss informally some of the basic notions in set theory and basic properties about numbers. A more thorough treatment can be found in \cite[Ch. 1]{Mun} (for set theory) and \cite[Ch. 1]{Rud-P} (for numbers). 

Let me first list the notations and conventions that will be used throughout the notes. We use frequently the abbreviations:
\begin{gather*}
\text{iff=if and only if}\\
\text{LHS=left hand side}\qquad
\text{RHS=reft hand side}\\
\text{$\exists$=there exists}\qquad \text{$\forall$=for all}\\
\text{i.e.=id est=that is=namely}\qquad\text{e.g.=for example}\\
\text{cf.=compare/check/see/you are referred to}\\
\text{resp.=respectively}\qquad 
\text{WLOG=without loss of generality}
\end{gather*}
If $\Fbb$ is any field (e.g. $\Qbb,\Rbb,\Cbb$), we let $\Fbb^\times=\Fbb\setminus\{0\}$. \index{F@$\Fbb^\times=\Fbb\setminus\{0\}$}

Topics marked with $\star\star$ are technical and/or their methods are rarely used in later studies. You can skim or skip them on first reading. Topics marked with $\star$ are interesting, but not necessarily technical. They are not essential for understanding the later part of the notes.

%Topics in the ``Problems" section (or the whole ``Problems" sections) marked with $\heartsuit$ are important problems that will be used later in this course.



\subsection{Basic operations and axioms}
Intuitively, a set denotes a collection of elements. For instance:\index{N@$\Nbb=\{0,1,2,\dots\}$} \index{Z@$\Zbb_+=\{1,2,\dots\}$}
\begin{gather*}
\Zbb=\{\text{all integers}\}\qquad \Nbb=\Zbb_{\geq0}=\{n\in\Zbb:n\geq0\}\qquad \Zbb_+=\{n\in\Zbb:n>0\}
\end{gather*}
have infinitely many elements. (In this course, we will not be concerned with the rigorous construction of natural numbers and integers from Peano axioms.) We also let
\begin{align*}
\Qbb=\{\text{all rational numbers}\}\qquad\Rbb=\{\text{all real numbers}\}
\end{align*}
assuming that rational and real numbers exist and satisfy the properties we are familiar with in high school mathematics.


Set theory is the foundation of modern mathematics. It consists of several Axioms telling us what we can do about the sets. For example, the following way of describing sets
\begin{align}
\{x: x\text{ satisfies property...}\}  \label{eq1}
\end{align}
is illegal, since it gives \textbf{Russell's paradox}: Consider
\begin{align}
S=\{A: A\text{ is a set and }A\notin A\}\label{eq12}
\end{align}
If $S$ were a set, then $S\in S\Rightarrow S\notin S$ and $S\notin S\Rightarrow S\in S$. This is something every mathematician doesn't want to happen.

Instead, the following way of defining sets is legitimate:
\begin{align}
\{x\in X:x\text{ satisfies property}\dots\}  \label{eq2}
\end{align}
where \emph{$X$ is a given set}.  For instance, we can define the \textbf{difference} of two sets:\index{AB@$A\backslash B$}
\begin{align*}
A\setminus B=A-B=\{x\in A:x\notin B\}
\end{align*}




So let us figure out the legal way of defining unions and intersections of sets. The crucial point is that we assume the following axiom:
\begin{axiom}
If $\scr A$ is a set of sets, then there exists a set $X$ such that $A\subset X$ for all $A\in\scr A$.
\end{axiom}

Thus, if $\scr A$ is a set of sets, let $X$ satisfy $A\subset X$ for all $A\in\scr A$, then we can define the \textbf{union} and the \textbf{intersection} 
\begin{subequations}\label{eq3}
\begin{gather}
\bigcup_{A\in\scr A}A=\{x\in X:\text{there exists $A\in\scr A$ such that $x\in A$}\}\\
\bigcap_{A\in\scr A}A=\{x\in X:\text{for all $A\in\scr A$ we have $x\in A$}\}
\end{gather}
\end{subequations}
It is clear that this definition does not rely on the particular choice of $X$.

\begin{rem}
In many textbooks, it is not uncommon that sets are defined as in \eqref{eq1}. You should interpret such definition as \eqref{eq2}, where the set $X$ is omitted because it is clear from the context. For instance, if the context is clear, the set $\{x\in\Rbb:x\geq 0\}$ could be simply written as $\{x:x\geq0\}$ or even $\{x\geq0\}$. By the same token, the phrase ``$\in X$" in \eqref{eq3} could be omitted. So we can also write
\begin{gather*}
A\cup B=\{x: x\in A\text{ or }x\in B\} \qquad  A\cap B=\{x: x\in A\text{ and }x\in B\}
\end{gather*}
which are special cases of \eqref{eq3}.
\end{rem}


\begin{rem}
In the same spirit, when discussing subsets of a given ``large" set $X$, and if $X$ is clear from the context, we shall write $X\setminus A$ (where $A\subset X$) as $A^c$ \index{Ax@$A^c$, the complement of $A$} and call it the \textbf{complement} of $A$.
\end{rem}


\begin{eg}
We have
\begin{gather*}
\bigcup_{x\in(1,+\infty)}[0,x)=[0,+\infty)\qquad\bigcap_{n\in\Zbb_+}(0,1+1/n)=(0,1]\qquad \bigcup_{n\in\Nbb}(0,1-1/n]=(0,1)
\end{gather*}
The readers may notice that these examples are not exactly in the form \eqref{eq3}. They are actually unions and intersections of indexed families of sets. (See Def. \ref{lb1}.) We need some preparation before discussing this notion.
\end{eg}




\begin{axiom}
If $A_1,\dots,A_n$ are sets, their \textbf{Cartesian product} exists:
\begin{align*}
A_1\times\cdots\times A_n=\{(a_1,\dots,a_n): a_i\in A_i\text{ for all }1\leq i\leq n\}
\end{align*}
where two elements $(a_1,\dots,a_n)$ and $(b_1,\dots,b_n)$ of the Cartesian product are viewed as equal iff $a_1=b_1,\dots,a_n=b_n$. We also write
\begin{align*}
(a_1,\dots,a_n)=a_1\times\cdots\times a_n
\end{align*}
especially when $a,b$ are real numbers and $(a,b)$ can mean an open interval. We understand $A_1\times\cdots\times A_n$ as $\emptyset$ if some $A_i$ is $\emptyset$.

If $A_1=\cdots=A_n=A$, we write the Cartesian product as $A^n$. \hfill\qedsymbol
\end{axiom}

\begin{eg}
Assume that the set of real numbers $\Rbb$ exists. Then the set of complex numbers $\Cbb$ \index{C@$\Cbb$, the set of complex numbers} is defined to be $\Rbb^2=\Rbb\times\Rbb$ as a set. We write $(a,b)\in\Cbb$ as $a+b\im$ where $a,b\in\Rbb$. Define
\begin{gather*}
(a+b\im)+(c+d\im)=(a+c)+(b+d)\im\\
(a+b\im)\cdot (c+d\im)=(ac-bd)+(ad+bc)\im
\end{gather*}
Define the zero element $0$ of $\Cbb$ to be $0+0\im$. More generally, we consider $\Rbb$ as a subset of $\Cbb$ by viewing $a\in\Rbb$ as $a+0\im\in\Cbb$. This defines the usual arithmetic of complex numbers. 

If $z=a+b\im$, we define its \textbf{absolute value} $|z|=\sqrt{a^2+b^2}$. Then $z=0$ iff $|z|=0$. We define the \textbf{(complex) conjugate} of $z$ to be $\ovl z=a-b\im$. Then $|z|^2=z\ovl z$.

If $z\neq 0$, then there clearly exists a unique $z^{-1}\in\Cbb$ such that $zz^{-1}=z^{-1}z=1$:  $z^{-1}=|z|^{-2}\cdot \ovl z$. Thus, using the language of modern algebra, $\Cbb$ is a \index{00@Field} \textbf{field}.\footnote{The readers can easily find the definition of fields online or through textbooks (e.g. \cite[Def. 1.12]{Rud-P}). We will not present the full definition of fields in the notes. Just keep in mind some typical (counter)examples: $\Qbb,\Rbb,\Cbb$ are fields. $\Zbb$ is not a field, because not every non-zero element of $\Zbb$ has an inverse. The set of quaternions $\{a+b\im+c\mathbf{j}+d\mathbf{k}: a,b,c,d\in\Rbb\}$ is not a field because it is not commutative ($\im\mathbf{j}=-\mathbf{j}\im=\mathbf{k}$). The set of rational functions $P(x)/Q(x)$, where $P,Q$ are polynomials with coefficients in $\Rbb$ and $Q\neq 0$, is a field.}  \hfill\qedsymbol
\end{eg}


The axiom of Cartesian product allows us to define relations and functions:

\begin{df}
If $A,B$ are sets, a subset $R$ of $A\times B$ is called a \textbf{relation}. For $(a,b)\in A\times B$, we write $aRb$ iff $(x,y)\in R$. We understand ``$aRb$" as ``$a$ is related to $b$ through the relation $R$".
\end{df}


\begin{df}\label{lb39}
A relation $f$ of $A,B$  is called a \textbf{function} or a \textbf{map} (or a \textbf{mapping}), if for every $a\in A$ there is a unique $b\in B$ such that $afb$. In this case, we write $b=f(a)$. 

When we write $f:A\rightarrow B$, we always mean that $A,B$ are sets and $f$ is a function from $A$ to $B$. $A$ and $B$ are called respectively the \textbf{domain} and the \textbf{codomain} of $f$. (Sometimes people also use the words ``source" and ``target" to denote $A$ and $B$.) 

If $E\subset A$ and $F\subset B$, we define the \textbf{image under $f$} of $E$  and the \textbf{preimage under $f$} of $F$ to be
\begin{gather*}
f(E)=\{b\in B:\exists a\in E\text{ such that }b=f(a)\}\\
f^{-1}(F)=\{a\in A: f(a)\in F\}.
\end{gather*}
$f(A)$ is simply called the \textbf{image} of $f$, or the \textbf{range} of $f$. If $b\in B$, $f^{-1}(\{b\})$ is often abbreviated to $f^{-1}(b)$. The function \index{f@$f\lvert_E$, the restriction of $f$ to $E$}
\begin{align*}
f|_E:E\rightarrow B\qquad x\mapsto f(x)
\end{align*}
is called the \textbf{restriction}  of $f$ to $E$. \hfill\qedsymbol
\end{df}


The intuition behind the definition of functions is clear: we understand functions as the same as their graphs. So a subset $f$ of the ``coordinate plane" $A\times B$ is the graph of a function iff it ``intersects every vertical line precisely once".


\begin{rem}\label{lb40}
According to our definition, $\emptyset$ (as a subset of $\emptyset\times B$) is the only function from $\emptyset$ to $B$. (A false assumption implies any statement.) If $A\neq\emptyset$, there are no functions $A\rightarrow\emptyset$.
\end{rem}


\begin{df}\label{lb13}
A function $x:\Zbb_+\rightarrow A$ is called a \textbf{sequence in $A$}. We write $x(n)$ as $x_n$, and write this sequence as $(x_n)_{n\in\Zbb_+}$ (or simply $(x_n)_n$ or $(x_n)$).
\end{df}

Many people write such a sequence as $\{x_n\}_{n\in\Zbb_+}$. We do not use this notation, since it can be confused with $\{x_n: n\in\Zbb_+\}$ (the range of the function $x$).



\begin{axiom}
If $X$ is a set, then the \textbf{power set} \index{00@Power set $2^X$} $2^X$ exists, where
\begin{align*}
2^X=\{\text{Subsets of }X\}
\end{align*}
\end{axiom}

\begin{eg}
The set $2^{\{1,2,3\}}$ has $8$ elements: $\emptyset$, $\{1\}$, $\{2\}$, $\{3\}$, $\{1,2\}$, $\{1,3\}$, $\{2,3\}$, $\{1,2,3\}$. Surprisingly, $8=2^3$. As we shall see in Exp. \ref{lb11} and Cor. \ref{lb12}, this relationship holds more generally, which explains the terminology $2^X$.  
\end{eg}

Now we are ready to define indexed families of sets.
\begin{df}\label{lb1}
An \textbf{indexed family of sets} \index{00@Indexed family of sets}  $(S_i)_{i\in I}$ is defined to be a function $S:I\rightarrow 2^X$ for some sets $I,X$. We write $S(i)$ as $S_i$. (So $S_i$ is a subset of $X$.) $I$ is called the \textbf{index set}. Define
\begin{align*}
\bigcup_{i\in I}S_i= \bigcup_{T\in S(I)}T\qquad \bigcap_{i\in I}S_i= \bigcap_{T\in S(I)}T
\end{align*}
Note that $S(I)$ is the image of the function $S$.
\end{df}


\begin{eg}
In the union $\bigcup_{x\in(1,+\infty)}[0,x)$, the index set is $I=(1,+\infty)$, and $X$ can be the set of real numbers $\Rbb$. Then $S:I\rightarrow 2^X$ is defined to be $S_i=S(i)=[0,i)$.
\end{eg}




\begin{exe}\label{lb5}
Let $f:A\rightarrow B$ be a function. We say that $f$ is \textbf{injective} if for all $a_1,a_2\in A$ satisfying $a_1\neq a_2$ we have $f(a_1)\neq f(a_2)$. We say that $f$ is \textbf{surjective} if for each $b\in B$ we have $f^{-1}(b)\neq\emptyset$. $f$ is called \textbf{bijective} if it is both surjective and bijective. Define the \textbf{identity maps} $\id_A:A\rightarrow A,a\mapsto a$ \index{id@$\id_A$} and $\id_B$ in a similar way. Prove that
\begin{subequations}
\begin{gather}
\text{$f$ is injective $\Longleftrightarrow$ there is $g:B\rightarrow A$ such that $g\circ f=\id_A$}\label{eq4}\\
\text{$f$ is surjective $\Longleftrightarrow$ there is $g:B\rightarrow A$ such that $f\circ g=\id_B$}\label{eq5}\\
\text{$f$ is bijective $\Longleftrightarrow$ there is $g:B\rightarrow A$ such that $g\circ f=\id_A$ and $f\circ g=\id_B$}\label{eq6}
\end{gather}
\end{subequations}
Show that the $g$ in \eqref{eq4} (resp. \eqref{eq5}, \eqref{eq6}) is surjective (resp. injective, bijective).
\end{exe}


The equivalence \eqref{eq5} is subtler, since its proof requires Axiom of Choice.


\begin{axiom}
Let $(S_i)_{i\in I}$ be an indexed family of sets. The \textbf{Axiom of Choice} asserts that if $S_i\neq\emptyset$ for all $i\in I$, then there exists a function (the \textbf{choice function})
\begin{align*}
f:I\rightarrow \bigcup_{i\in I}S_i
\end{align*}
such that $f(i)\in S_i$ for each $i\in I$.
\end{axiom}


Intuitively, the axiom of choice says that for each $i\in I$ we can choose an element $f(i)$ of $S_i$. And such choice gives a function $f$.


\begin{eg}
Let $f:A\rightarrow B$ be surjective. Then each member of the family $(f^{-1}(b))_{b\in B}$ is nonempty. Thus, by axiom of choice, there is a choice function $g$ defined on the index set $B$ such that $g(b)\in f^{-1}(b)$ for each $b$. Clearly $f\circ g=\id_B$.
\end{eg}



\begin{rem}
Suppose that each member $S_i$ of the family $(S_i)_{i\in I}$ has exactly one element. Then the existence of a choice function does not require Axiom of Choice: Let $X=\bigcup_{i\in I}S_i$ and define relation
\begin{align*}
f=\{(i,x)\in I\times X: x\in S_i\}
\end{align*}
Then one checks easily that this relation between $I$ and $X$ is a function, and that it is the (necessarily unique) choice function of $(S_i)_{i\in I}$.
\end{rem}

According to the above remark, one does not need Axiom of Choice to prove \eqref{eq4} and \eqref{eq6}. Can you see why?


\subsection{Partial and total orders, equivalence relations}

\begin{df}
Let $A$ be a set. A \textbf{partial order} (or simply an \textbf{order}) $\leq$ on $A$ is a relation on $A\times A$ satisfying for all $a,b,c\in A$ that:
\begin{itemize}
\item (Reflexivity) $a\leq a$.
\item (Antisymmetry) If $a\leq b$ and $b\leq a$ then $a=b$.
\item (Transitivity) If $a\leq b$ and $b\leq c$ then $a\leq c$.
\end{itemize}
We write $b\geq a$ iff $a\leq b$. Write $a>b$ iff $a\geq b$ and $a\neq b$. Write $a<b$ iff $b>a$. So $\geq$ is also an order on $A$. The pair $(A,\leq)$ is called a \textbf{partially ordered set}. A partial order $\leq$ on $A$ is called a \textbf{total order}, if for every $a,b\in A$ we have either $a\leq b$ or $b\leq a$.
\end{df}


\begin{eg}
The following are examples of orders.
\begin{itemize}
\item Assume that $\Rbb$ exists. Then $\Rbb$ has the canonical total order, which restricts to the total order of $\Zbb$. This is the total order that everyone is familiar with.
\item Let $X$ be a set. Then $(2^X,\subset)$ is a partially ordered set.
\item $\Rbb^2$ is a partially ordered set, if we define $(a,b)\leq (c,d)$ to be $a\leq c$ and $b\leq d$. 
\end{itemize}
\end{eg}


\begin{df}
A relation $\sim$ on a set $A$ is called an \textbf{equivalence relation}, if for all $a,b,c\in A$ we have
\begin{itemize}
\item (Reflexivity) $a\sim a$.
\item (Symmetry) $a\sim b$ iff $b\sim a$.
\item (Transitivity) If $a\sim b$ and $b\sim c$ then $a\sim c$.
\end{itemize}
\end{df}

Later, we will use the notions of partial orders and equivalence relation not just for a set, but for a collection of objects ``larger" than a set. See Sec. \ref{lb4}.

\begin{df}
Let $A$ be a set, together with an equivalence relation $\sim$. Define a new set
\begin{align*}
{A/\sim}=\{[a]: a\in A\}
\end{align*}
where the notion $[a]$ can be understood in the following two equivalent ways (we leave it to the readers to check the equivalence):
\begin{itemize}
\item[(1)] $[a]$ is a new symbol. We understand $[a]$ and $[b]$ as equal iff $a\sim b$.
\item[(2)] $[a]=\{x\in A: x\sim a \}$
\end{itemize}
We call $[a]$ the \textbf{equivalence class} (or the \textbf{residue class}) of $a$, and call $A/\sim$ the \textbf{quotient set} \index{00@Quotient sets} of $A$ under $\sim$. The surjective map $\pi:a\in A\mapsto [a]\in {A/\sim}$ is called the \textbf{quotient map}.
\end{df}


\begin{exe}
Prove that every surjective map  is equivalent to a quotient map. More precisely, prove that for every surjection $f:A\rightarrow B$, there is an equivalence relation $\sim$ on $A$ and a bijective map $\Phi:{A/\sim}\rightarrow B$ such that the following diagram commutes:
\begin{equation}\label{eq7}
\begin{tikzcd}[column sep=small]
                          & A \arrow[rd, "f"] \arrow[ld, "\pi"'] &   \\
{A/\sim} \arrow[rr, "\Phi"] &                                      & B
\end{tikzcd}
\end{equation}
\end{exe}


This is the first time we see commutative diagrams. Commutative diagrams are very useful for indicating that certain maps between sets are ``equivalent" or are satisfying some more general relations. For example, \eqref{eq7} shows that the maps $f$ and $\pi$ are equivalent, and that this equivalence is implemented by the bijection $\Phi$. The formal definition of commutative diagrams is the following:


\begin{df}
A diagram (i.e. some sets denoted by symbols, and some maps denoted by arrows) is called a \textbf{commutative diagram}, \index{00@Commutative diagram} if all directed paths in the diagram with the same start and endpoints lead to the same result.
\end{df}


Here is an example of commutative diagram in linear algebra. This example assumes some familiarity with the basic properties of vector spaces \index{00@Vector spaces} and linear maps.\footnote{Again, we refer the readers to Internet or any Linear Algebra textbook (e.g. \cite{Axl}) for the definition of vector spaces and linear maps.}


\begin{eg}\label{lb67}
Let $V,W$ be vector spaces over a field $\Fbb$ with finite dimensions $m,n$ respectively. Let $e_1,\dots,e_m$ be a basis of $V$, and let $\eps_1,\dots,\eps_n$ be a basis of $W$. We know that there are unique linear isomorphisms $\Phi:\Fbb^m\xrightarrow{\simeq} V$ and $\Psi:\Fbb^n\xrightarrow{\simeq} W$ such that
\begin{align*}
\Phi(a_1,\dots,a_m)=a_1e_1+\cdots+a_me_m\qquad \Psi(b_1,\dots,b_n)=b_1\eps_1+\cdots+b_n\eps_n
\end{align*}
Let $T:V\rightarrow W$ be a \index{00@Linear maps} \textbf{linear map}, i.e., a map satisfying $T(a\xi+b\eta)=aT\xi+bT\eta$ for all $a,b\in\Fbb,\xi,\eta\in V$. Then there is a unique $n\times m$ matrix $A\in\Fbb^{n\times m}$ \index{Fnm@$\Fbb^{n\times m}$, the set of $n\times m$ matrices} such that the following diagram commutes:
\begin{equation}
\begin{tikzcd}
\Fbb^m \arrow[r,"\Phi","\simeq"'] \arrow[d,"A"'] & V \arrow[d,"T"] \\
\Fbb^n \arrow[r,"\Psi","\simeq"']           & W          
\end{tikzcd}
\end{equation} 
namely, $T\Phi=\Psi A$. This commutative diagram tells us that $T$ is equivalent to its \textbf{matrix representation} \index{00@Matrix representation} $A$ under the bases $e_\blt,\eps_\star$, and that this equivalence is implemented by the linear isomorphisms $\Phi$ (on the sources) and $\Psi$ (on the targets). 
\end{eg}

Commutative diagrams are ubiquitous in mathematics. You should learn how to read commutative diagrams and understand their intuitive meanings. We will see more examples in the future of this course.



\subsection{$\Qbb$, $\Rbb$, and $\overline{\mathbb R}=[-\infty,+\infty]$}



Using equivalence classes, one can construct rational numbers from integers, and real numbers from rationals. We leave the latter construction to the future, and discuss the construction of rationals here.

\begin{eg}[Construction of $\Qbb$ from $\Zbb$]\label{lb17}
Define a relation on $\Zbb\times\Zbb^\times$ (where $\Zbb^\times=\Zbb\setminus\{0\}$) as follows. If $(a,b),(a',b')\in\Zbb\times\Zbb^\times$, we say $(a,b)\sim(a',b')$ iff $ab'=a'b$. It is a routine check that $\sim$ is an equivalence relation. Let \index{Q@$\Qbb$, the field of rational numbers}  $\Qbb=(\Zbb\times\Zbb^\times)/\sim$, and write the equivalence class of $(a,b)$ as $a/b$ or $\frac ab$. Define additions and multiplications in $\Qbb$ to be
\begin{align*}
\frac ab+\frac cd=\frac{ad+bc}{bd}\qquad \frac ab\cdot\frac cd=\frac{ac}{bd}
\end{align*}
We leave it to the readers to check that this definition is \index{00@Well defined} \textbf{well-defined}: If $(a,b)\sim(a',b')$ and $(c,d)\sim(c',d')$ then $(ad+bc,bd)\sim(a'd'+b'c',b'd')$ and $(ac,bd)\sim(a'c',b'd')$.

We regard $\Zbb$ as a subset of $\Qbb$ by identifying $n\in\Zbb$ with $\frac n1$. (This is possible since the map $n\in\Zbb\mapsto \frac n1\in\Qbb$ is injective.) Each $a/b\in\Qbb$ has additive inverse $\frac{-a}b$. If $a/b\in\Qbb$ is not zero (i.e. $(a,b)\nsim (0,1)$), then $a/b$ has multiplicative inverse $b/a$. This makes $\Qbb$ a field: the field of \textbf{rational numbers}.

If $a/b\in\Qbb$, we say $a/b\geq 0$ if $ab\geq0$. Check that this is well-defined (i.e., if $(a,b)\sim(a',b')$, then $ab\geq0$ iff $a'b'\geq0$). More generally, if $a/b,c/d\in\Qbb$, we say $\frac ab\geq \frac cd$ if $\frac ab-\frac cd\geq0$. Check that $\geq$ is a total order on $\Qbb$.  Check that $\Qbb$ is an Archimedean ordered field, defined below.\hfill\qedsymbol
\end{eg}


\begin{df}
A field $\Fbb$, together with a total order $\leq$, is called an \index{00@Ordered field} \textbf{ordered field}, if for every $a,b,c\in\Fbb$ we have
\begin{itemize}
\item (Addition preserves $\leq$) If $a\leq b$ then $a+c\leq b+c$.
\item (Multiplication by $\Fbb_{\geq0}$ preserves $\leq$) If $a,b\geq 0$ then $ab\geq0$.
\end{itemize}
These two properties relate $\leq$ to $+$ and $\cdot$ respectively.
\end{df}

\begin{rem}
Many familiar properties about inequalities in $\Qbb$ hold for an ordered field. For instance: 
\begin{gather*}
a\geq b~\wedge~ c\geq d \qquad\Longrightarrow\qquad a+c\geq b+d\\
a\geq0\qquad\Longleftrightarrow\qquad -a\leq0\\
a\geq0~\wedge~b\geq c\qquad\Longleftrightarrow\qquad ab\geq ac\\
a\leq0~\wedge~b\geq c\qquad\Longleftrightarrow\qquad ab\leq a\\
a^2\geq0\\
0<a\leq b\qquad\Longrightarrow\qquad 0< b^{-1}\leq a^{-1}
\end{gather*}
Check them yourself, or see \cite[Prop. 1.18]{Rud-P}.
\end{rem}


\begin{df}
We say that an ordered field $\Fbb$ satisfies \index{00@Archimedean property} \textbf{Archimedean property} if for each $a,b\in\Fbb$ we have
\begin{align*}
a> 0\qquad\Longrightarrow \qquad\exists n\in\Nbb\text{ such that }na>b
\end{align*}
where $na$ means $\underbrace{a+\cdots+a}_{n}$.
\end{df}

\begin{eg}
$\Qbb$ satisfies Archimedean property. Indeed, let $a,b\in\Qbb$ and $a>0$. Then $a=p/q$ and $b=r/s$ where $p,q,s\in\Zbb_+$ and $r\in\Zbb$. So $na>b$ where $n=q|r|+q$.
\end{eg}



Prop. \ref{lb2} gives an important application of Archimedian property. We will use this in the construction of $\Rbb$ from $\Qbb$, and in the proof that $\Qbb$ is dense in $\Rbb$. 

\begin{df}
Let $\Fbb$ be a field. A subset $\Ebb\subset\Fbb$ is called a  \textbf{subfield} \index{00@Subfield} of $\Fbb$, if $\Ebb$ contains the $1$ of $\Fbb$, and if $\Ebb$ is closed under the operations of addition, multiplication, taking negative, and taking inverse in $\Fbb$ (i.e. if $a,b\in\Ebb$ then $a+b,ab,-a\in\Ebb$, and $a^{-1}\in\Ebb$ whenever $a\neq 0$). We also call $\Fbb$ a \index{00@Field extension} \textbf{field extension} of $\Ebb$, since $\Ebb$ is clearly a field.
\end{df}

Note that if $\Ebb$ is a subfield of $\Fbb$, the $0$ of $\Fbb$ is in $\Ebb$ since $0=1+(-1)\in\Ebb$.

\begin{df}
Let $\Ebb$ be an ordered field. A field extension $\Fbb$ of $\Ebb$ is called an \index{00@Ordered field extension=ordered subfield} \textbf{ordered field extension}, if $\Fbb$ is equipped with a total order $\leq$ such that $\Fbb$ is an ordered field, and if the order $\leq$ of $\Fbb$ restricts to that of $\Ebb$. We also call $\Ebb$ an \textbf{ordered subfield} of $\Fbb$.
\end{df}

Our typical example of ordered field extension will be $\Qbb\subset\Rbb$.

\begin{pp}\label{lb2}
Let $\Fbb$ be an ordered field extension  of $\Qbb$. Assume that $\Fbb$ is Archimedean. Then for every $x,y\in\Fbb$ satisfying $x<y$, there exists $p\in\Qbb$ such that $x<p<y$.
\end{pp}

\begin{proof}
Assume $x,y\in\Fbb$ and $x<y$. Then $y-x>0$ (since $y-x\neq 0$ and $-x+x\leq -x+y$). By Archimedean property, there exists $n\in\Zbb_+$ such that $n(y-x)>1$. So $\displaystyle y-x>\frac 1n$ and hence $\displaystyle x+\frac 1n<y$.

Let us prove that the subset
\begin{equation*}
A=\big\{k\in\Zbb: \frac {~k~}{n}\leq x\big\}
\end{equation*}
is nonempty and bounded from above in $\Zbb$. By Archimedean property, there is $m\in\Zbb_+$ such that $m>nx$, i.e. $\displaystyle \frac mn>x$. So for each $k\in\Zbb_+$ satisfying $k\geq m$, we have $\displaystyle \frac kn=\frac mn+\frac{k-m}n>x$. Therefore, for each $k\in A$ we have $k<m$. So $A$ is bounded above. By Archimedean property again, there is $l\in\Zbb_+$ such that $\displaystyle \frac ln>-x$. So $\displaystyle -\frac ln<x$, and hence $A$ is nonempty.

We now use the fact that \emph{every nonempty subset of $\Zbb$ bounded above has a maximal element}. Let $k=\max A$. Since $k+1\notin A$, we have $\displaystyle x<\frac{k+1}n$. Since $\displaystyle \frac kn\leq x$, we have
\begin{align*}
\frac{k+1}n=\frac kn+\frac 1n\leq x+\frac 1n<y
\end{align*}
This proves $x<p<y$ with $\displaystyle p=\frac{k+1}n$.
\end{proof}

To introduce $\Rbb$ formally, we need more definitions:

\begin{df}
Let $(X,\leq)$ be a partially ordered set and $E\subset X$. An \textbf{upper bound of $E$ in $X$} \index{00@Upper bound} is an element $x\in X$ satisfying $e\leq x$ for all $e\in E$. An upper bound $x\in X$ of $E$ is called a \textbf{least upper bound} or a \textbf{supremum} \index{00@Supremum}  if $x\leq y$ for every upper bound $y\in Y$ of $E$. In this case, we write the supremum as \index{sup@$\sup E$} $\sup E$. It is not hard to check that supremums are unique if they exist.

We leave it to the readers to define \textbf{lower bounds} and the \textbf{greatest lower bound} (if exists) of $E$, also called the \textbf{infinimum} \index{00@Infinimum} and is denoted by \index{inf@$\inf E$} $\inf E$. \hfill\qedsymbol
\end{df}


\begin{df}
Let $(X,\leq)$ be a partially ordered set. We say that $X$ satisfies the \textbf{least-upper-bound property}, if every every nonempty subset $E\subset X$ which is bounded above (i.e. $E$ has an upper bound) has a supremum in $X$. The \textbf{greatest-lower-bound property} is defined in the opposite way.
\end{df}

\begin{eg}
$\Zbb$ satisfies the least-upper-bound and the greatest-lower-bound property: Let $A\subset \Zbb$. If $A$ is bounded above (resp. below), then the maximum $\max A$ (resp. minimum $\min A$) exists and is the supremum (resp. infinimum) of $A$.
\end{eg}

\begin{eg}
Let $X$ be a set. Then $(2^X,\subset)$ satisfies the least-upper-bound and the greatest-lower-bound property: Let $\scr A\subset 2^X$, i.e., $\scr A$ is a set of subsets of $X$. Then $\scr A$ is bounded from above by $X$, and is bounded from below by $\emptyset$. Moreover,
\begin{align*}
\sup\scr A=\bigcup_{A\in\scr A}A\qquad \inf\scr A=\bigcap_{A\in\scr A}A
\end{align*}
\end{eg}



\begin{thm}\label{lb3}
There is an ordered field extension of $\Qbb$ which is Archimedian and satisfies the least-upper-bound property. This field is denoted by  $\Rbb$. Its elements are called \index{00@Real number} \textbf{real numbers}.
\end{thm}

By taking negative, we see that $\Rbb$ also satisfies the greatest-lower-bound property.


\begin{rem}
The ordered field extensions satisfying the conditions in Thm. \ref{lb3} are unique ``up to isomorphisms". (The words ``\textbf{isomorphism}"\index{00@Isomorphism}  and ``equivalence" are often interchangeable, though ``isomorphism" is more often used in the algebraic setting, whereas ``equivalence" can be used in almost every context. For example, in point-set topology, ``equivalence" means ``homeomorphism".) We leave it to the readers to give the precise statement. We will not use this uniqueness in this course. 

Note that to compare two extensions $\Fbb,\Rbb$ of $\Qbb$, it is very confusing to regard $\Qbb$ as a subset of both $\Fbb$ and $\Rbb$. You'd better consider two different injective maps $\tau:\Qbb\rightarrow \Fbb$ and $\iota:\Qbb\rightarrow\Rbb$ preserving the algebraic operations and the order of $\Qbb$, and use a commutative diagram to indicate that $\tau$ and $\iota$ are equivalent. (Thus, what's happening here is that we have an equivalence of maps, not just an equivalence of the fields $\Fbb$ and $\Rbb$.) \hfill\qedsymbol
\end{rem}


\begin{df}
Let $-\infty,+\infty$ be two different symbols, and extend the total order $\leq$ of $\Rbb$ to the \textbf{extended real line}\index{R@$\ovl\Rbb=[-\infty,+\infty]=\Rbb\cup\{-\infty,+\infty\}$}
\begin{align*}
\ovl\Rbb=\Rbb\cup\{-\infty,+\infty\}
\end{align*}
by letting $-\infty<x<+\infty$ for all $x\in\Rbb$. Define for each $x\in\Rbb$ that
\begin{gather*}
x\pm\infty=\pm\infty+x=\pm\infty\qquad +\infty-(-\infty)=+\infty\\
x\cdot(\pm\infty)=\pm\infty\cdot x=\left\{
\begin{array}{cc}
\pm\infty&\text{if }x>0\\
\mp\infty&\text{if }x<0
\end{array}
\right.\\
\frac x{\pm\infty}=0\\
\frac{\pm\infty}{x}=x^{-1}\cdot(\pm\infty)\qquad \text{if }x\neq0
\end{gather*}
If $a,b\in\ovl\Rbb$ and $a\leq b$, we define \textbf{intervals} \index{00@Interval} with endpoints \index{00@Endpoints of an interval} $a,b$:
\begin{gather}\label{eq8}
\begin{gathered}
[a,b]=\{x\in\ovl\Rbb:a\leq x\leq b\}\qquad (a,b)=\{x\in\ovl\Rbb:a< x< b\}\\
(a,b]=\{x\in\ovl\Rbb:a< x\leq b\}\qquad [a,b)=\{x\in\ovl\Rbb:a\leq x< b\}
\end{gathered}
\end{gather}
So $\Rbb=(-\infty,+\infty)$ and $\ovl\Rbb=[-\infty,+\infty]$.
\end{df}

In this course, unless otherwise stated, an interval always means one of the four sets in \eqref{eq8}. The first two intervals are called respectively a \textbf{closed interval} and an \textbf{open interval}.


\begin{rem}
Clearly, every subset $E$ of $\ovl\Rbb$ is bounded and has a supremum and an infinimum. We have that $\sup E=+\infty$ iff $E$ is not bounded above in $\Rbb$, and that $\inf E=-\infty$ iff $E$ is not bounded below in $\Rbb$. 
\end{rem}


\subsection{Cardinalities, countable sets, and product spaces $Y^X$}\label{lb4}


\begin{df}
Let $A$ and $B$ be sets. We say that $A$ and $B$ have the same \textbf{cardinality} \index{00@Cardinality $\card(A)$} and write $\card(A)=\card(B)$ (or simply $A\approx B$), if there is a bijection $f:A\rightarrow B$. We write $\card(A)\leq\card(B)$ (or simply $A\precsim B$) if $A$ and a subset of $B$ have the same cardinality. 
\end{df}



\begin{exe}\label{lb9}
Show that $\card(A)\leq\card(B)$ iff there is an injection $f:A\rightarrow B$, iff there is a surjection $g:B\rightarrow A$. (You need either Axiom of Choice or its consequence \eqref{eq5} to prove the last equivalence.)
\end{exe}

It is clear that $\approx$ is an equivalence relation on the collection of sets. It is also true that $\precsim$ is a partial order: Reflexivity and transitivity are easy to show. The proof of antisymmetry is more involved:



\begin{thm}[Schr\"oder-Bernstein]\label{lb8}\index{00@Schr\"oder-Bernstein theorem}
Let $A,B$ be two sets. If $A\precsim B$ and $B\precsim A$, then $A\approx B$.
\end{thm}

\begin{proof}[$\star\star$ Proof]
Assume WLOG that $A\subset B$. Let $f:B\rightarrow A$ be an injection. Let $A_n=f^n(A)$ defined inductively by $f^0(A)=A$, $f^n(A)=f(f^{n-1}(A))$. Let $B_n=f^n(B)$. Then
\begin{align*}
B_0\supset A_0\supset \cdots\supset B_n\supset A_n\supset B_{n+1}\supset\cdots
\end{align*}
In particular, $C=\bigcap_{n\in\Nbb}A_n$ equals $\bigcap_{n\in\Nbb}B_n$. Note that $f$ gives a bijection $B_n\setminus A_n\rightarrow B_{n+1}\setminus A_{n+1}$ (since $f$ gives bijections $B_n\rightarrow B_{n+1}$ and $A_n\rightarrow A_{n+1}$). Therefore, we have a bijection $g:B\rightarrow A$ defined by
\begin{gather*}
g(x)=\left\{
{\begin{array}{ll}
f(x)&\text{if $x\in B_n\setminus A_n$ for some $n\in\Nbb$}\\[0.5ex]
x&\text{otherwise}
\end{array}}
\right.
\end{gather*}
where ``otherwise" means either $x\in C$ or $x\in A_n\setminus B_{n+1}$ for some $n$.
\end{proof}

Intuition about the above proof: View $B$ as an onion. The layers of $B$ are $B_n\setminus A_n$ (the odd layers) and $A_n\setminus B_{n+1}$ (the even layers). The bijection $g$ maps each odder layer to the subsequent odd one, and fixes the even layers and the core $C$.


\begin{eg}\label{lb6}
If $-\infty<a<b<+\infty$, then $(0,1)\approx (a,b)$.
\end{eg}
\begin{proof}
$f:(0,1)\rightarrow (a,b)$ sending $x$ to $(b-a)x+a$ is a bijection.
\end{proof}

\begin{eg}\label{lb7}
If $-\infty<a<b<+\infty$, then $\Rbb\approx (a,b)$
\end{eg}

\begin{proof}
By the previous example, it suffices to prove $\Rbb\approx(-1,1)$. The function
\begin{gather}\label{eq20}
f:\Rbb\rightarrow(-1,1)\qquad f(x)=\left\{
\begin{array}{ll}
\frac x{1+x}&\text{ if $x\geq0$}\\[0.5ex]
-f(-x)&\text{ if $x<0$}
\end{array}
\right.
\end{gather}
is bijective.
\end{proof}


Alternatively, one may use the tangent function to give a bijection between $(-\pi/2,\pi/2)$ and $\Rbb$. I have avoided this method, since \eqref{eq20} is more elementary than trigonometric functions. The mathematically rigorous definition of trigonometric functions and the verification of their well-known properties are far from easy tasks. 



\begin{pp}
Let $I$ be an interval with endpoints $a<b$ in $\ovl\Rbb$. Then $I\approx\Rbb$.
\end{pp}

\begin{proof}
Let $A=(0,1)\cup\{-\infty,+\infty\}$. By Exp.  \ref{lb7}, we have
\begin{align*}
(a,b)\subset I\precsim \ovl\Rbb\approx A\approx[0,1]\subset (-2,2)\approx (a,b)
\end{align*}
So $I\approx\ovl\Rbb$ by Schr\"oder-Bernstein Thm. \ref{lb8}. In particular, $\Rbb=(-\infty,+\infty)\approx\ovl\Rbb$.
\end{proof}


\begin{df}
A set $A$ is called \textbf{finite} if $A\precsim\{1,\dots,n\}$ for some $n\in\Zbb_+$. $A$ is called  \textbf{countable} if $A\precsim\Nbb$. \index{00@Countable}
\end{df}

Clearly, a set $A$ is finite iff either $A\approx\emptyset$ or $A\approx\{1,\dots,n\}$ for some $n\in\Zbb_+$.

\begin{rem}
Let $A\subset\Nbb$. If $A$ is bounded above, then $A\subset\{0,\dots,n\}$ and hence $A$ is finite. If $A$ is not bounded above, then we can construct a strictly increasing sequence $(x_n)_{n\in\Nbb}$ in $A$. (Pick any $x_0\in A$. Suppose we have $x_n\in A$. Since $x_n$ is not an upper bounded of $A$, there is $x_{n+1}\in A$ larger than $x_n$. So $(x_n)_{n\in\Nbb}$ can be constructed inductively.) This gives an injection $\Nbb\rightarrow A$. Therefore $A\succsim \Nbb$, and hence $A\approx \Nbb$ by Schr\"oder-Bernstein.

It follows that if $B\precsim\Nbb$, then either $B$ is a finite set, or $B\approx\Nbb$. Therefore, ``a set $B$ is \textbf{countably infinite}" \index{00@Countably infinite} means the same as ``$B\approx\Nbb$".  \hfill\qedsymbol 
\end{rem}


\begin{thm}\label{lb15}
A countable union of countable sets is countable. In particular, $\Nbb\times\Nbb\approx\Nbb$.
\end{thm}

\begin{proof}
Recall Exe. \ref{lb9}. Let $A_1,A_2,\dots$ be countable sets. Since each $A_i$ is countable, there is a surjection $f_i:\Nbb\rightarrow A_i$. Thus, the map $f:\Nbb\times\Nbb\rightarrow \bigcup_i A_i$ defined by $f(i,j)=f_i(j)$ is surjective. Therefore, it suffices to show that there is a surjection $\Nbb\rightarrow\Nbb\times\Nbb$. This is true, since we have a bijection $g:\Nbb\rightarrow\Nbb\times\Nbb$ where $g(0),g(1),g(2),\dots$ are $(0,0)$, $(1,0)$, $(0,1)$, $(2,0)$, $(1,1)$, $(0,2)$, $(3,0)$, $(2,1)$, $(1,2)$, $(0,3)$, etc., as shown by the figure
\begin{align*}
\vcenter{\hbox{{
			\includegraphics[width=3.5cm]{fig1.png}}}}
\end{align*}
\end{proof}

As an application, we prove the extremely important fact that $\Qbb$ is countable.
\begin{co}
We have $\Nbb\approx\Zbb_+\approx\Zbb\approx \Qbb$.
\end{co}



\begin{proof}
Clearly $\Zbb_{<0}\approx\Nbb\approx \Zbb_+$. By Thm. \ref{lb15}, $\Zbb=\Zbb_{<0}\cup\Nbb$ is countably infinite, and hence $\Zbb\approx\Nbb$. It remains to prove $\Zbb\approx\Qbb$. By Schr\"oder-Bernstein, it suffices to prove $\Qbb\precsim\Zbb$.  By Thm. \ref{lb15} again, $\Zbb\times\Zbb\approx\Zbb$. By Exp. \ref{lb17}, there is a surjection from a subset of $\Zbb\times\Zbb$ to $\Qbb$. So $\Qbb\precsim\Zbb\times\Zbb\approx\Zbb$.
\end{proof}



Later, when we have learned Zorn's Lemma (an equivalent form of Axiom of Choice), we will be able to prove the following generalization of $\Nbb\times\Nbb\approx\Nbb$. So we defer the proof of the following theorem to a later section.

\begin{thm}\label{lb16}
Let $X$ be a infinite set. Then $X\times\Nbb\approx X$.
\end{thm}





Our next goal is to prove an exponential law $a^{b+c}=a^b\cdot a^c$ for cardinalities. For that purpose, we first need to define the set-theoretic operations that correspond to the summation $b+c$ and the exponential $a^b$.


\begin{df}
We write $X=\bigsqcup_{\alpha\in\scr A}A_\alpha$ \index{A@$\bigsqcup_{\alpha\in\scr A}A_\alpha$, the disjoint union} and call $X$ the \textbf{disjoint union} \index{00@Disjoint union} of $(A_\alpha)_{\alpha\in\scr A}$,  if $X=\bigcup_{\alpha\in\scr A}A_\alpha$ and $(A_\alpha)_{\alpha\in\scr A}$ is a family of pairwise disjoint sets (i.e. $A_\alpha\cap A_\beta=\emptyset$ if $\alpha\neq\beta$). If moreover $\scr A=\{1,\dots,n\}$, we write $X=A_1\sqcup\cdots\sqcup A_n$.
\end{df}

\begin{df}
Let $X,Y$ be sets. Then \index{YX@$Y^X$, the set of functions $X\rightarrow Y$}
\begin{align}
Y^X=\{\text{functions }f:X\rightarrow Y\}
\end{align}
A more precise definition of $Y^X$ (in the spirit of \eqref{eq2}) is $\{f\in X\times Y \mid f:X\rightarrow Y\text{ is a function}\}$. Note that by Rem. \ref{lb40},
\begin{align}
Y^\emptyset=\{\emptyset\}  \label{eq10}
\end{align}
\end{df}

This new notation is compatible with the old one $Y^n=Y\times\cdots\times Y$:
\begin{eg}
Let $n\in\Zbb_+$. We have $Y^{\{1,\dots,n\}}\approx Y^n$ due to the bijection
\begin{align*}
Y^{\{1,\dots,n\}}\rightarrow Y^n\qquad f\mapsto (f(1),\dots,f(n))
\end{align*}
\end{eg}

\begin{rem}\label{lb18}
The above example suggests that in the general case that $X$ is not necessarily finite, we can view each function $f:X\rightarrow Y$ as $(f(x))_{x\in X}$, an \textbf{indexed family of elements} of $Y$ with index set $X$. Thus, intuitively and hence not quite rigorously, 
\begin{align}
Y^X=\underbrace{Y\times Y\times\cdots}_{\card(X)\text{ pieces}} \label{eq11}
\end{align}
This generalizes the intuition in Def. \ref{lb13} that a function $f:\Zbb_+\rightarrow Y$ is equivalently a sequence $(f(1),f(2),f(3),\dots)$.

The viewpoint that $Y^X$ is a \textbf{product space} with index set $X$ is very important and will be adopted frequently in this course. More generally, we can define:\hfill\qedsymbol
\end{rem}

\begin{df}
Let $(X_i)_{i\in I}$ be a family of sets with index set $I$. Their \textbf{product space} \index{00@Product space} \index{X@$\prod_{i\in I}X_i$} is defined by
\begin{align*}
\prod_{i\in I}X_i =\{f\in \fk X^I:f(i)\in X_i\text{ for all }i\in I \}
\end{align*}
where $\fk X=\bigcup_{i\in I}X_i$. If each $X_i$ is nonempty, then $\prod_{i\in I}X_i$ is nonempty by Axiom of Choice. An element of $\prod_{i\in I}X_i$ is also written as $(f_i)_{i\in I}$ when the $i$-th component if it is $f_i\in X_i$.
\end{df}

In particular, if all $X_i$ are equal to $X$, then $X^I=\prod_{i\in I}X$.



\begin{eg}\label{lb11}
Let $X$ be a set. For each $A\subset X$, define the \textbf{characteristic function} \index{00@Characteristic function} \index{zz@$\chi_A$, the characteristic function of $A$} $\chi_A:X\rightarrow\{0,1\}$ to be
\begin{align*}
\chi_A(x)=\left\{
\begin{array}{ll}
1&\text{if }x\in A\\
0&\text{if }x\notin A
\end{array}
\right.
\end{align*}
Then we have
\begin{align*}
2^X\approx \{0,1\}^X
\end{align*}
since the following map is bijective:
\begin{gather*}
2^X\rightarrow\{0,1\}^X\qquad A\mapsto\chi_A
\end{gather*}
Its inverse is $f\in\{0,1\}^X\mapsto f^{-1}(1)\in 2^X$.
\end{eg}

\begin{pp}[Exponential Law]\label{lb10}
Suppose that $X=A_1\sqcup\cdots\sqcup A_n$. Then
\begin{align*}
Y^X\approx Y^{A_1}\times \cdots\times Y^{A_n}
\end{align*}
\end{pp}

\begin{proof}
We have a bijection
\begin{gather}\label{eq9}
\begin{gathered}
\Phi:Y^X\rightarrow Y^{A_1}\times \cdots\times Y^{A_n}\\
f\mapsto (f|_{A_1},\dots,f|_{A_n})
\end{gathered}
\end{gather}
where we recall that $f|_{A_i}$ is the restriction of $f$ to $A_i$. 
\end{proof}

\begin{exe}
Assume that $A_1,\dots,A_n$ are subsets of $X$. Define $\Phi$ by \eqref{eq9}. Prove that $\Phi$ is injective iff $X=A_1\cup\cdots\cup A_n$. Prove that $\Phi$ is surjective iff $A_1,\dots, A_n$ are pairwise disjoint. 
\end{exe}

\begin{co}\label{lb12}
Let $X,Y$ be finite sets with cardinalities $m,n\in\Nbb$ respectively. Assume that $Y\neq\emptyset$. Then $Y^X$ is a finite set with cardinality $n^m$.
\end{co}

\begin{proof}
The special case that $m=0$ (i.e. $X=\emptyset$, cf. \eqref{eq10}) and $m=1$ is clear. When $m>1$, assume WLOG that $X=\{1,\dots,m\}$. Then $X=\{1\}\sqcup\cdots\sqcup\{m\}$. Apply Prop. \ref{lb10} to this disjoint union. We see that $Y^X\simeq Y\times \cdots\times Y\simeq\{1,\dots,n\}^m$ has $n^m$ elements.
\end{proof}



We end this section with some (in)equalities about the cardinalities of product spaces. To begin with, we write $X\precnsim Y$ (or $\card(X)<\card(Y)$) if $X\precsim Y$ and $X\napprox Y$.

\begin{pp}\label{lb14}
Let $X,Y$ be sets with $\card(Y)\geq 2$ (i.e. $Y$ has at least two elements). Then $X\precnsim Y^X$. In particular, $X\precnsim 2^X$.
\end{pp}

\begin{proof}
The case $X=\emptyset$ is obvious since $0<1$. So we assume $Y\neq\emptyset$. Clearly $2^X\simeq\{0,1\}^X$ is $\precsim Y^X$. So it suffices to prove $X\precnsim 2^X$. Since the map $X\rightarrow 2^X$ sending $x$ to $\{x\}$ is injective, $X\precsim 2^X$. Let us prove $X\napprox 2^X$.

Assume that $X\approx 2^X$. So there is a bijection $\Phi:X\rightarrow 2^X$ sending each $x\in X$ to a subset $\Phi(x)$ of $X$. Motivated by Russell's Paradox \eqref{eq12}, we define
\begin{align*}
S=\{x\in X:x\notin \Phi(x)\}
\end{align*}
Since $\Phi$ is surjective, there exists $y\in X$ such that $S=\Phi(y)$. If $y\in\Phi(y)$, then $y\in S$, and hence $y\notin \Phi(y)$ by the definition of $S$. If $y\notin\Phi(y)$, then $y\notin S$, and hence $y\in\Phi(y)$ by the definition of $S$. This gives a contradiction.
\end{proof}


\begin{rem}
Write $\{1,\dots,n\}^X$ as $n^X$ for short. \index{nX@$n^X=\{1,\dots,n\}^X$} Assuming that real numbers have decimal, binary, or (more generally) base-$n$ presentations where $n\in\Zbb_{\geq 2}$, then  $\Rbb\approx n^{\Nbb}$. So by Prop. \ref{lb14}, $\Nbb\precnsim\Rbb$, i.e. \emph{$\Rbb$ is uncountable}. The base-$n$ presentations of real numbers suggest that $\card(n^\Nbb)$ is independent of $n$. This fact can be proved by elementary methods without  resorting to the analysis of real numbers:
\end{rem}

\begin{thm}
Let $X$ be an infinite set. Then
\begin{align*}
2^X\approx 3^X\approx 4^X\approx\cdots\approx \Nbb^X
\end{align*}
\end{thm}

\begin{proof}
First, we assume that $X=\Nbb$. Clearly, for each $n\in\Zbb_{\geq 2}$ we have $2^X\precsim n^X\precsim \Nbb^X$. Since elements of $\Nbb^X$ are subsets of $X\times\Nbb$ (i.e. elements of $2^{X\times\Nbb}$), we have
\begin{align*}
\Nbb^X\subset 2^{X\times\Nbb}\simeq 2^X
\end{align*}
since $X\times\Nbb\approx X$ by Thm. \ref{lb15}. So $2^X\approx n^X\approx \Nbb^X$ by Schr\"oder-Bernstein.

As pointed out earlier (cf. Thm. \ref{lb16}), it can be proved by Zorn's Lemma that $X\times\Nbb\approx X$ for every infinite set $X$. So the same conclusion holds for such $X$.
\end{proof}

\newpage

\section{Metric spaces, convergence of sequences, and continuous functions}


We first give an informal introduction to metric spaces, hoping to motivate the readers from a (relatively) historical perspective. It is okay if you do not understand all of the concepts mentioned in the introduction on the first read. Simply return to this section when you feel unmotivated while formally studying these concepts in later sections. (The same suggestion applies to all the introductory sections and historical comments in our notes.)









\subsection{Introduction}\label{lb55}

In this chapter, we begin the study of point-set topology by learning one of its most important notions: metric spaces. Similar to \cite{Rud-P}, we prefer to introduce metric spaces and basic point-set topology at the early stage of our study. An obvious reason for doing so is that metric spaces provide a uniform language for the study of basic analysis problems in $\Rbb,\Rbb^n,\Cbb^n$, and more generally in function spaces such as the space of continuous functions $C([a,b])$ on the interval $[a,b]\subset\Rbb$. With the help of such a language, for example, many useful criteria for the convergence of series in $\Rbb$ and $\Cbb$ (e.g. root test, ratio test) are generalized straightforwardly to criteria for the \emph{uniform} convergence of series of functions in $C([a,b])$.

Point-set topology was born in 1906 when Fr\'echet defined metric spaces, motivated mainly by the study of function spaces in analysis (i.e. \emph{functional analysis}). Indeed, point-set topology and functional analysis are the two faces of the same coin, because they share a common theme: one regards the set of functions as a space $X$, and views each function as a point of that space. This viewpoint allows one to \ul{study the analytic properties of function spaces by using the intuitions from $\Rbb$ and $\Rbb^n$}. (Sequential) compactness, completeness, and separability are prominent examples of such properties. Their importance was already recognized by Fr\'echet by the time he defined metric spaces. 


Consider sequential compactness for example. The application of compactness to function spaces originated from the problems in calculus of variations. For instance, let $L(x,y,z)$ be a polynomial or (more generally) a continuous function in $3$ variables. We want to find a ``good" (e.g. differentiable) function $f:[0,1]\rightarrow \Rbb$ minimizing or maximizing the expression
\begin{align}
S(f)=\int_0^1 L(t,f(t),f'(t))dt
\end{align}
This is the general setting of Lagrangian mechanics. In the theory of integral equations, one considers the extreme values and points of the \textbf{functional} (i.e. function of functions)
\begin{align}
S(f)=\int_0^1\int_0^1 f(x)K(x,y)\ovl{f(y)}dxdy
\end{align}
where $K:[0,1]^2\rightarrow\Rbb$ is continuous and $f:[0,1]\rightarrow\Cbb$ is subject to the condition $\int_0^1 |f(x)|^2dx=1$. Any $f$ maximizing (resp. minimizing) $S(f)$ is an eigenvector of the linear operator $g\mapsto \int_0^1 K(x,y)g(y)dy$ with maximal (resp. minimal) eigenvalue.


As we shall learn, (sequential) compactness is closely related to the problem of finding (or proving the existence of) maximal/minimal values and points of a continuous function. So, in 19th century, when people were already familiar with sequential compactness in $\Rbb^n$ (e.g. Bolzano-Weierstrass theorem, Heine-Borel theorem), they applied compactness to function spaces and functionals. The idea is simple: Suppose we are given $X$, a set of functions (say continuous and differentiable) from $[a,b]$ to $\Rbb$. We want to find $f\in X$ maximizing $S(f)$. Here is an explicit process (see also the proof of Lem. \ref{lb56}):
\begin{itemize}
\item[(A)] Find a sequence $(f_n)_{n\in\Zbb_+}$ in $X$ such that $S(f_n)$ increases to $M=\sup S(X)$. 
\item[(B)] Define convergence in $X$ in a suitable way, and verify that $S:X\rightarrow\Rbb$ is continuous (i.e. if $f_n$ converges to $f$ in the way we define, then $S(f_n)\rightarrow S(f)$). 
\item[(C)] Suppose we can find a subsequence $(f_{n_k})_{k\in\Zbb_+}$ converging to some $f\in X$, then $S$ attains its maximum at $f$. In particular, $S(f)=M$ and hence $M<+\infty$. 
\end{itemize}


To carry out step (B), we need to \ul{define suitable geometric structures for a function space $X$ so that the convergence of sequences in $X$ and the continuity of functions $S:X\rightarrow\Rbb$ can be defined and studied in a similar pattern as that for $\Rbb^n$}. \textbf{Metric} (of a metric space) and \textbf{topology} (of a topological space) are such geometric structures. As we shall learn, the topology of a metric space is uniquely determined by the convergence of sequences in this space. Step (C) can be carried out if every sequence in $X$ has a convergent subsequent, i.e., if $X$ is sequentially compact. Thus, we need a good criterion for sequential compactness of subsets of a function space.  Arzel\`a-Ascoli theorem, the  $C([a,b])$-version of Heine-Borel theorem, is such a criterion. This famous theorem was proved in late 19th century (and hence before the birth of point-set topology), and it gave an important motivation for Fr\'echet to consider  metric spaces in general. We will learn this theorem at the end of the first semester.


To summarize: Metric spaces are defined not just for fun. We introduce such geometric objects because we want to study the convergence of sequences and the continuity of functions. And moreover, the examples we are interested in are not just subsets of $\Rbb^n$, but also subsets of function spaces. With this in mind, we now begin our journey into point-set topology.


\subsection{Basic definitions and examples}



\begin{df}
Let $X$ be a set. A function $d:X\times X\rightarrow\Rbb_{\geq0}$ is called a \textbf{metric} if for all $x,y,z\in X$ we have
\begin{enumerate}[label=(\arabic*)]
\item $d(x,y)=d(y,x)$.
\item $d(x,y)=0$ iff $x=y$.
\item (Triangle inequality) \index{00@Triangle inequality} $d(x,z)\leq d(x,y)+d(y,z)$.
\end{enumerate}
The pair $(X,d)$, or simply $X$, is called \index{00@Metric space} a \textbf{metric space}. If $x\in X$ and $r\in(0,+\infty]$, the set \index{Br@$B_X(x,r)=B(x,r)$ and $\ovl B_X(x,r)=\ovl B(x,r)$}
\begin{align*}
B_X(x,r)=\{y\in X:d(x,y)<r\}
\end{align*}
often abbreviated to $B(x,r)$, is called the \textbf{open ball} with center $x$ and radius $r$. If $r\in[0,+\infty)$,
\begin{align*}
\ovl B_X(x,r)=\{y\in X:d(x,y)\leq r\}
\end{align*}
also abbreviated to $\ovl B(x,r)$, is called the \textbf{closed ball} with center $x$ and radius $r$.
\end{df}


We make some comments on this definition.


\begin{rem}
That ``$d(x,y)=0$ iff $x=y$" is very useful. Think about $X$ as a set of functions $[0,1]\rightarrow\Rbb$ and $d$ is a metric on $X$. To show that $f,g\in X$ are equal, instead of checking that infinitely many values are equal (i.e. $f(t)=g(t)$ for all $t\in\Rbb$), it suffices to check that one value (i.e. $d(f,g)$) is zero.
\end{rem}

\begin{rem}
Triangle inequality clearly implies ``polygon inequality":
\begin{align}
d(x_0,x_n)\leq\sum_{j=1}^n d(x_{j-1},x_j)
\end{align}
\end{rem}

\begin{rem}\label{lb20}
Choose distinct points $x,y\in X$. Then $x,y$ are separated by two open balls centered at them: there exists $r,\rho>0$ such that $B(x,r)\cap B(y,\rho)=\emptyset$. This is called the \textbf{Hausdorff property}. 

To see this fact, note that $d(x,y)>0$. Choose $r,\rho$ such that $r+\rho\leq d(x,y)$. If $z\in B(x,r)\cap B(y,\rho)$, then $d(x,z)+d(y,z)<r+\rho\leq d(x,y)$, contradicting triangle inequality.

We will see (cf. Prop. \ref{lb21}) that Hausdorff property guarantees that any sequence in a metric space cannot converge to two different points. Intuition: one cannot find a point which is very close to $x$ and $y$ at the same time.  \hfill\qedsymbol
\end{rem}



We give some examples, and leave it to the readers to check that they satisfy the definition of metric spaces. We assume that square roots of positive real numbers can be defined. (We will rigorously define square roots after we define $e^x$ using the series $\sum_{n\in\Nbb}x^n/n!$.)


\begin{eg}
$\Rbb$ is a metric space if we define $d(x,y)=|x-y|$
\end{eg}


\begin{eg}
On $\Rbb^n$, we can define \textbf{Euclidean metric} \index{00@Euclidean metric}
\begin{align*}
d(x,y)=\sqrt{(x_1-y_1)^2+\cdots+(x_n-y_n)^2}
\end{align*}
if $x_\blt,y_\blt$ are the components of $x,y$. The following are also metrics:
\begin{gather*}
d_1(x,y)=|x_1-y_1|+\cdot+|x_n-y_n|\\
d_\infty(x,y)=\max\{|x_1-y_1|,\dots,|x_n-y_n|\}
\end{gather*}
\end{eg}

\begin{eg}
The \textbf{Euclidean metric} on $\Cbb^n$ is
\begin{align*}
d(z,w)=\sqrt{|z_1-w_1|^2+\cdots+|x_n-y_n|^2}
\end{align*}
which agrees with the Euclidean metric on $\Rbb^{2n}$. The following are also metrics:
\begin{gather*}
d_1(z,w)=|z_1-w_1|+\cdot+|z_n-w_n|\\
d_\infty(z,w)=\max\{|z_1-w_1|,\dots,|z_n-w_n|\}
\end{gather*}
\end{eg}

\begin{cv}\label{lb33}
Unless otherwise stated, the metrics on $\Rbb^n$ and $\Cbb^n$ (and their subsets) are assumed to be the Euclidean metrics.
\end{cv}


\begin{rem}
One may wonder what the subscripts $1,\infty$ mean. This notation is actually due to the general fact that
\begin{equation*}
d_p(z,w)=\sqrt[p]{|z_1-w_1|^p+\cdots+|z_n-w_n|^p}
\end{equation*}
is a metric where $1\leq p< +\infty$, and $d_\infty=\lim_{q\rightarrow +\infty}d_q$. It is not easy to prove that $d_p$ satisfies triangle inequality: one needs Minkowski inequality. For now, we will not use such general $d_p$. And we will discuss Minkowski inequality in later sections.
\end{rem}


\begin{eg}\label{lb19}
Let $X=X_1\times\cdots\times X_N$ where each $X_i$ is a metric space with metric $d_i$. Write $x=(x_1,\dots,x_N)\in X$ and $y=(y_1,\dots,y_N)\in Y$. Then the following are metrics on $X$:
\begin{gather*}
d(x,y)=d_1(x_1,y_1)+\cdots+d_N(x_N,y_N)\\
\delta(x,y)=\max\{d_1(x_1,y_1),\dots,d_N(x_N,y_N)\}\\
\rho(x,y)=\sqrt{d_1(x_1,y_1)^2+\cdots+d_N(x_N,y_N)^2}
\end{gather*}
With respect to the metric $\delta$, the open balls of $X$ are ``polydisks"
\begin{align*}
B_X(x,r)=B_{X_1}(x_1,r)\times\cdots\times B_{X_N}(x_N,r)
\end{align*}
\end{eg}


There is no standard choice of metric on the product of metric spaces. $d,\delta,\rho$ are all good, and they are equivalent in the following sense:

\begin{df}
We say that two metrics $d_1,d_2$ on a set $X$ are \index{00@Equivalent metrics} \textbf{equivalent} and write $d_1\approx d_2$, if there exist $\alpha,\beta>0$ such that  for any $x,y\in X$ we have
\begin{gather*}
d_1(x,y)\leq\alpha d_2(x,y)\qquad d_2(x,y)\leq\beta d_1(x,y)
\end{gather*}  
This is an equivalence relation. More generally, we may write $d_1\precsim d_2$ if $d_1\leq \alpha d_2$ for some $\alpha>0$. Then $d_1\approx d_2$ iff $d_1\precsim d_2$ and $d_2\precsim d_1$.
\end{df}



\begin{eg}
In Exp. \ref{lb19}, we have $\delta\leq \rho\leq d\leq 2\delta$. So $\delta\approx\rho\approx d$.
\end{eg}

\begin{cv}\label{lb32}
Given finitely many metric spaces $X_1,\dots,X_N$, the metric on their product space $X=X_1\times\cdots\times X_N$ is chosen to be any one that is equivalent to the ones defined in Exp. \ref{lb19}. In the case that each $X_i$ is a subset of $\Rbb$ or $\Cbb$, this convention is compatible with Convention \ref{lb33}, and we choose the metric on $X$ to be the Euclidean metric (unless otherwise stated).
\end{cv}


\begin{df}\label{lb43}
Let $(X,d)$ be a metric space. Then a \textbf{metric subspace} \index{00@Metric subspace} is denotes an object $(Y,d|_Y)$ where $Y\subset X$ and $d|_Y$ is the restriction of $d$ to $Y$, namely, for all $y_1,y_2\in Y$ we set
\begin{align*}
d|_Y(y_1,y_2)=d(y_1,y_2)
\end{align*}
\end{df}

\begin{cv}\label{lb76}
Suppose $Y$ is a subset of a given metric space $(X,d)$. Unless otherwise stated, the metric of $Y$ is chosen to be $d|_Y$ whenever $Y$ is viewed as a metric space. For example, the metric of any subset of $\Rbb^n$ is assumed to be the Euclidean metric, unless otherwise stated.
\end{cv}



\subsection{Convergence of sequences} \label{lb73}

\begin{df}
Let $(x_n)_{n\in\Zbb_+}$ be a sequence in a metric space $X$. Let $x\in X$. We say that $x$ is the \textbf{limit} of $x_n$ and write $\displaystyle\lim_{n\rightarrow\infty}x_n=x$ (or $x_n\rightarrow x$), if:
\begin{itemize}
\item For every real number $\varepsilon>0$ there exists $N\in\Zbb_+$ such that for every $n\geq N$ we have $d(x_n,x)<\varepsilon$. 
\end{itemize}
Equivalently, this means that every (nonempty) open ball centered at $x$ contains \textbf{all but finitely many} \index{00@All but finitely many $x_n$} $x_n$.\footnote{``All but finitely many $x_n$ satisfies..." means ``for all but finitely many $n$, $x_n$ satisfies...". It does NOT mean that ``all but finitely many elements of the set $\{x_n:n\in\Zbb_+\}$ satisfies...".} 
\end{df}

\begin{exe}
Show that in the above definition of limits,  it suffices to consider rational numbers $\varepsilon>0$. (Note: You need to use Prop. \ref{lb2}.) 
\end{exe}
This exercise implies that the definition of limits does not require the existence of real numbers, i.e., does not assume Thm. \ref{lb3}. Indeed, we will use limits of sequences (and ``double sequences") to prove Thm. \ref{lb3}.


In many textbooks and research papers, you will see phrases such as \index{00@Sufficiently large}
\begin{gather}
\text{$x_n$ satisfies property $P$ for } \textbf{sufficiently large} \text{ $n$}
\end{gather}
This means that ``there exists $N\in\Zbb_+$ such that $P$ holds for all $n\geq N$". (We also say that $x_n$ \textbf{eventually} satisfies $P$.) Then $\lim_{n\rightarrow\infty} x_n=x$ means that ``for every $\varepsilon>0$, we have $d(x_n,x)<\varepsilon$ for sufficiently large $n$". 

\begin{pp}\label{lb21}
Any sequence $(x_n)_{n\in\Zbb_+}$ in a metric space $X$ has at most one limit.
\end{pp}

\begin{proof}
Suppose $(x_n)_{n\in\Zbb_+}$ converges to $x,y\in X$ where $x\neq y$. By Hausdorff property (Rem. \ref{lb20}), there exist $r,\rho>0$ such that $B(x,r)\cap B(y,\rho)=\emptyset$. By the definition of $x_n\rightarrow x$, there exists $N_1\in\Zbb_+$ such that $x_n\in B(x,r)$ for all $n\geq N_1$. Similarly, $x_n\rightarrow y$ means that there is $N_2\in\Zbb_+$ such that $x_n\in B(y,\rho)$ for all $n\geq N_2$. Choose any $n\geq N_1,N_2$ (e.g. $n=\max\{N_1,N_2\}$). Then $x_n\in B(x,r)\cap B(y,\rho)=\emptyset$, impossible.
\end{proof}


\subsubsection{Methods for proving convergence and computing limits}

\begin{eg}
$\dps \lim_{n\rightarrow\infty}\frac 1n=0$.
\end{eg}


\begin{proof}
Choose any $\varepsilon\in\Qbb_{>0}$. By Archimedean property, there exists $N\in\Zbb_+$ such that $N\varepsilon>1$, i.e. $1/N<\varepsilon$. Thus, for all $n\geq N$ we have $1/n<\varepsilon$.
\end{proof}

\begin{pp}
Let $\Fbb\in\{\Qbb,\Rbb\}$ and $(x_n),(y_n)$ be sequences in $\Fbb$ converging to $x,y\in\Rbb$. If $x_n\leq y_n$ for all $n$, then $x\leq y$.
\end{pp}

\begin{proof}
If $y<x$, let $\varepsilon=x-y$. Then infinitely members of $(x_n)$ are in $(x-\varepsilon/2,x+\varepsilon/2)$, and infinitely members of $(y_n)$ are in $(y-\varepsilon/2,y+\varepsilon/2)$. Since $y+\eps/2<x-\eps/2$, there must exist infinitely many $n$ satisfying $y_n<x_n$.
\end{proof}

\begin{pp}\label{lb57}
Let $(x_n)_{n\in\Zbb}$ be a sequence in $[a,b]\subset\Rbb$. If $(x_n)$ is increasing (resp. decreasing), then $\dps\lim_{n\rightarrow \infty}x_n$ equals $\dps\sup\{x_n:n\in\Zbb_+\}$ (resp. $\dps\inf\{x_n:n\in\Zbb_+\}$).
\end{pp}

\begin{proof}
Assume $(x_n)$ increases. (The case of decreasing is similar and hence its proof is omitted.) Let $A=\sup\{x_n:n\in\Zbb_+\}<+\infty$. Then for each $\eps>0$ there is $N$ such that $x_N>A-\eps$ (since $A-\eps$ is not an upper bound). Since $(x_n)$ is increasing, for all $n\in\Nbb$ we have $A-\eps<x_n\leq A$ and so $|x_n-A|<\eps$.
\end{proof}



\begin{eg}\label{lb27}
Let $(x_n)_{n\in\Zbb_+}$ be a sequence in a metric space $X$, and let $x\in X$. It is easy to see that
\begin{align*}
\lim_{n\rightarrow\infty} x_n=x\qquad\Longleftrightarrow \qquad \lim_{n\rightarrow\infty} d(x_n,x)=0
\end{align*}
\end{eg}

\begin{eg}\label{lb28}
Suppose that $(a_n)$ and $(b_n)$ are sequences in $\Rbb_{\geq 0}$, that $a_n\leq b_n$ for all $n$, and that $b_n\rightarrow 0$. Then  $a_n\rightarrow 0$. 
\end{eg}
\begin{proof}
For each $\varepsilon>0$, $[0,\varepsilon)$ contains all but finitely many $b_n$, and hence all but finitely many $a_n$.
\end{proof}


More generally, we have:

\begin{pp}[\textbf{Squeeze theorem}]\label{lb29}\index{00@Squeeze theorem}
Suppose that $(x_n)$ is a sequence in a metric space $X$. Let $x\in X$. Suppose that there is a sequence $(a_n)$ in $\Rbb_{\geq 0}$ such that $\dps\lim_{n\rightarrow\infty}a_n=0$ and that $d(x_n,x)\leq a_n$ for all $n$. Then $\dps\lim_{n\rightarrow\infty} x_n=x$.
\end{pp}

\begin{proof}
This follows immediately from Exp. \ref{lb27} and \ref{lb28}.
\end{proof}

The above proposition explains why many people say that ``analysis is the art of inequalities": It transforms the problem of convergence to the problem of finding a sequence $(a_n)\in\Rbb_{\geq 0}$ converging to $0$ such that the inequality $d(x_n,x)\leq a_n$ holds. And very often, a good (hard) analyst is one who knows how to find such good sequences!






\begin{pp}\label{lb38}
Let $X=X_1\times\cdots\times X_N$ be a product of metric spaces $(X_i,d_i)$. Let $d$ be any of the three metrics of $X$ in Exp. \ref{lb19}. Let $\mbf x_n=(x_{1,n},\dots,x_{N,n})$ be a sequence in $X$. Let $\mbf y=(y_1,\dots,y_N)$. Then 
\begin{align*}
\lim_{n\rightarrow\infty} \mbf x_n=\mbf y\qquad\Longleftrightarrow \qquad \lim_{n\rightarrow\infty} x_{i,n}=y_i~~(\forall 1\leq i\leq N)
\end{align*}
\end{pp}

\begin{proof}
We let $d$ be the metric $\delta$ in Exp. \ref{lb19}, i.e. defined by $\max_j d_j(x_j,y_j)$. Now choose a sequence $(\mbf x_n)$ and an element $\mbf y$ in $X$. Then
\begin{align}
\mbf x_n\rightarrow \mbf y~~\Longleftrightarrow~~ d_X(\mbf x_n,\mbf y)\rightarrow 0 ~~\Longleftrightarrow~~ \max_{1\leq j\leq N} d_j(x_j,y_j)\rightarrow 0  \label{eq13}
\end{align}


Suppose that the RHS of \eqref{eq13} is true. Fix any $1\leq i\leq N$. Then for every $\varepsilon>0$, there is $K\in\Zbb_+$ such that for all $n\geq K$ we have $\max_j d_j(x_{j,n},y_j)<\varepsilon$, and hence $d_i(x_{i,n},y_i)<\varepsilon$. This proves $x_{i,n}\rightarrow y_i$ (for all $i$).

Conversely, assume that for every $i$ we have $x_{i,n}\rightarrow y_i$. Then for every $\eps>0$ there is $K_i\in\Zbb_+$ such that $d_i(x_{i,n},y_i)<\varepsilon$ for every $n\geq K_i$. Let $K=\max\{K_1,\dots,K_N\}$. Then for all $n\geq K$ we have $\max_j d_j(x_{j,n},y_j)<\eps$. This proves the RHS of \eqref{eq13}.

If $d$ is one of the other two metrics in Exp. \ref{lb19}, one can either use a similar argument, or use the following important (but easy) fact.
\end{proof}





\begin{pp}
Let $d,\delta$ be two equivalent metrics on a set $X$. Let $(x_n)_{n\in\Zbb_+}$ and $x$ be in $X$. Then $(x_n)_n$ converges to $x$ under the metric $d$ iff  $(x_n)_n$ converges to $x$ under $\delta$. Namely, $d(x_n,x)\rightarrow 0$ iff $\delta(x_n,x)\rightarrow 0$.
\end{pp}

\begin{proof}
Prove it yourself. (Or see Prop. \ref{lb48}.)
\end{proof}








\subsubsection{Criteria for divergence}

\begin{df}
A subset $E$ of a metric space $X$ is called \index{00@Bounded subset} \textbf{bounded} if there exists $p\in X$ and $R\in\Rbb_{>0}$ such that $E\subset B_X(p,R)$.
\end{df}

\begin{rem}
Note that if $E$ is bounded, then  for \emph{any} $q\in X$ there exists $\wtd R\in\Rbb_{>0}$ such that $E\subset B_X(q,\wtd R)$. (Indeed, choose $\wtd R=R+d(p,q)$, then by triangle inequality, $B(p,R)\subset B(q,\wtd R)$.)
\end{rem}

From this Remark, we immediately see:
\begin{eg}
In a metric space $X$, if $x\in X$ and $0<r<+\infty$, then $B(x,r)$ is bounded. Hence $\ovl B(x,r)$ is bounded (since it is inside $B(x,2r)$).
\end{eg}

Also, it is easy to see:
\begin{eg}\label{lb22}
A finite union of bounded subsets is bounded.
\end{eg}

\begin{pp}\label{lb24}
Let $(x_n)_{n\in\Zbb_+}$ be a convergent sequence in a metric space $X$. Then $(x_n)_{n\in\Zbb_+}$ is bounded.
\end{pp}

By saying that a sequence \index{00@Bounded sequence} $(x_n)_{n\in\Zbb_+}$ in $X$ is \textbf{bounded}, we mean that its range in $X$ (namely $\{x_n:n\in\Zbb_+\}$) is bounded.

\begin{proof}
Suppose that $x_n\rightarrow x$. Then for each $\varepsilon>0$, say $\varepsilon=1$, all but finitely many elements of $x_n$ (say $x_1,\dots,x_N$) are in $B(x,1)$. So this whole sequence is in $A=\{x_1\}\cup\cdots\{x_N\}\cup B(x,1)$. Since each $\{x_i\}$ is bounded, and since $B(x,1)$ is bounded, $A$ is bounded by Exp. \ref{lb22}.
\end{proof}


\begin{rem}\label{lb26}
Prop. \ref{lb24} gives our first criterion on divergence: If a sequence is unbounded (e.g. $x_n=n^2$), then it does not converge. But there are many bounded and divergent sequences. (See Exp. \ref{lb25}.) In this case, we need the second criterion: If a sequence has two subsequences converging to two different points, then this sequence diverge. (See Prop. \ref{lb23})
\end{rem}




\begin{df}
Let $(x_n)_{n\in\Zbb_+}$ be a sequence in a set $X$. If $(n_k)_{k\in\Zbb_+}$ is a strictly increasing sequence in $\Zbb_+$, we say that $(x_{n_k})_{k\in\Zbb_+}$ is a subsequence of $(x_n)_{n\in\Zbb_+}$. 
\end{df}

\begin{df}
If $A$ and $B$ are partially ordered set, we say a function $f:A\rightarrow B$ is \textbf{increasing} \index{00@Increasing and decreasing} \index{00@Strictly increasing and strictly decreasing} (resp. \textbf{strictly increasing}), if for each $x,y\in A$ we have
\begin{gather*}
x\leq y\qquad\Longrightarrow\qquad f(x)\leq f(y)\\
\text{resp.}\\
x<y\qquad\Longrightarrow \qquad f(x)<f(y)
\end{gather*}
We leave the definitions of \textbf{decreasing} and \textbf{strictly decreasing} to the readers. We say that $f$ is \index{00@Monotonic} \index{00@Strictly monotonic} \textbf{monotonic} (resp. \textbf{strictly monotonic}), if $f$ is either increasing or decreasing (resp. either strictly increasing or strictly decreasing).
\end{df}

Thus, a subsequence of $(x_n)_{n\in\Zbb_+}$ is equivalently the restriction of the function $x:\Zbb_+\rightarrow X$ to an infinite subset of $\Zbb_+$.

\begin{pp}\label{lb23}
Let $(x_n)_{n\in\Zbb_+}$ be a sequence in a metric space $X$ converging to $x\in X$. Then every subsequence $(x_{n_k})_{k\in\Zbb_+}$ converges to $x$.
\end{pp}

\begin{proof}
For every $\varepsilon>0$, $B(x,\varepsilon)$ contains all but finitely many $\{x_n:n\in\Zbb_+\}$, and hence all but finitely many $\{x_{n_k}:k\in\Zbb_+\}$.
\end{proof}

\begin{eg}\label{lb25}
The sequence $x_n=(-1)^n$ in $\Rbb$ is divergent, because the subsequence $(x_{2k})_{k\in\Zbb_+}$ converges to $1$, whereas $(x_{2k-1})_{k\in\Zbb_+}$ converges to $-1$. 
\end{eg}




One may wonder if the two criteria in Rem. \ref{lb26} are complete in order to determine whether a sequence diverges. This is true for sequences in $\Rbb^n$. We will discuss this topic later. (See Cor. \ref{lb75}.)



\subsection{Continuous maps of metric spaces}

Continuous maps are a powerful tool for showing that a sequence converges.


\begin{df}\label{lb31}
Let $f:X\rightarrow Y$ be a map of metric spaces. Let $x\in X$. We say that $f$ is \textbf{continuous at $x$} if one of the following equivalent conditions hold:
\begin{itemize}[align=left]
\item [(1)] For every sequence $(x_n)_{n\in\Zbb_+}$ in $X$, we have
\begin{align*}
\lim_{n\rightarrow\infty} x_n=x\qquad\Longrightarrow\qquad \lim_{n\rightarrow\infty} f(x_n)=f(x)
\end{align*}
\item[(2)] For every $\varepsilon>0$, there exists $\delta>0$ such that for every $p\in X$ satisfying $d(p,x)<\delta$, we have $d(f(p),f(x))<\varepsilon$.
\item[(2')] For every $\varepsilon>0$, there exists $\delta>0$ such that $B_X(x,\delta)\subset f^{-1}(B_Y(f(x),\varepsilon)))$.
\end{itemize}
We say that $f$ is a \textbf{continuous map/function}, if $f$ is continuous at every point of $X$.
\end{df}

\begin{proof}[Proof of the equivalence]
(2)$\Leftrightarrow$(2'): Obvious.

(2)$\Rightarrow$(1): Assume (2). Assume $x_n\rightarrow x$. For every $\varepsilon>0$, let $\delta>0$ be as in (2). Then since $x_n\rightarrow x$, there is $N\in\Zbb_+$ such that for all $n\geq N$ we have $d(x_n,x)<\delta$. By (2), we have $d(f(x_n),f(x))<\varepsilon$ for all $n\geq N$. This proves $f(x_n)\rightarrow f(x)$.

$\neg$(2)$\Rightarrow$ $\neg$(1): Assume that (2) is not true. Then there exists $\varepsilon>0$ such that for every $\delta>0$, there exists $p\in X$ such that $d(p,x)<\delta$ and $d(f(p),f(x))\geq\varepsilon$. Thus, for every $n\in\Zbb_+$, by taking $\delta=1/n$, we see that there exists $x_n\in X$ such that $d(x_n,x)<1/n$ and $d(f(x_n),f(x))\geq\varepsilon$. By Squeeze theorem (Prop. \ref{lb29}), $x_n\rightarrow x$. But $f(x_n)\nrightarrow f(x)$. So (1) is not true.
\end{proof}

\begin{rem}
One can compare Def. \ref{lb31}-(1) to the definition of linear maps. A map is continuous iff it \emph{preserves the convergence of sequences}, i.e., iff it maps convergent sequences to convergent ones. A map (between vector spaces) is linear iff it perserves the addition and the scalar multiplication of vectors. In general, a good map between two sets with ``structures" is a map which preserves the structures. (Thus, linear combinations encode the linear structures of vector spaces. Similarly, the convergence of sequences remembers the ``topological" structures of metric spaces.) As another example, we will define an isometry of metric spaces to be one that preserves the metrics (the structures of metric spaces), see Exe. \ref{lb46}.
\end{rem}

\begin{rem}
In this section, we mainly use Def. \ref{lb31}-(1) to study continuity. But in later sections we will also use Def. \ref{lb31}-(2'). An advantage of (2') is that it is more geometric. Indeed, if $X$ is a metric space and $E\subset X$, we say that $x\in E$ is an \textbf{interior point of $E$ in $X$} \index{00@Interior point} if there exists $\delta>0$ such that $B_X(x,\delta)\subset E$. For example, a point  $z\in\Cbb$ is an interior point of the closed unit disk $\ovl B_\Cbb(0,1)=\{w\in\Cbb:|w|\leq 1\}$ iff $|z|<1$. 

Thus, Def. \ref{lb31}-(2') says that for any map of metric spaces $f:X\rightarrow Y$ and $x\in X$, the following are equivalent:
\begin{itemize}
\item[(a)] $f$ is continuous at $x$.
\item[(b)] For each $\eps>0$, every $x\in X$ is an interior point of $f^{-1}\big(B_Y(f(x),\varepsilon)\big)$.
\end{itemize}
We say that a subset $U\subset X$ is \textbf{open} \index{00@Open set} if each point of $U$ is an interior point. For example, by triangle inequality, every open ball in a metric space is an open set. Thus, we have:
\begin{itemize}
\item A map of metric spaces $f:X\rightarrow Y$ is continuous iff the preimage under $f$ of every open ball of $Y$ is an open subset of $X$.
\end{itemize}

In the study of point-set topology, we will see that many properties can be studied in two approaches: using sequences (or using nets, the natural generalizations of sequences) and their convergence, and using open sets. The first example of such property is continuity, as we have seen in Def. \ref{lb31}. Another prominent example is sequential compactness vs. compactness. These two approaches represent two (very) different intuitions. (So it is surprising that these two things, which seem so different, are actually equivalent!) Sometimes both approaches work for a problem, but sometimes only one of them works, or one of them is much simpler. If you are a beginner in analysis and point-set topology, I suggest that whenever you see one approach applied to a problem, try to think about whether the other approach also works and which one is better.   \hfill\qedsymbol
\end{rem}


\subsubsection{Methods for proving continuity}


\begin{lm}\label{lb30}
Let $f:X\rightarrow Y$ be a map of metric spaces.  Let $(B_i)_{i\in I}$ be a collection of open balls in $X$ such that $X=\bigcup_{i\in I}B_i$. Suppose that for each $i$, the restriction $f|_{B_i}:B_i\rightarrow Y$ is continuous. Then $f$ is continuous. 
\end{lm}

This lemma shows that if we can prove that $f$ is ``locally" continuous, then $f$ is globally continuous. 

\begin{proof}
Choose $(x_n)$ in $X$ converging to $x\in X$. We shall show $f(x_n)\rightarrow f(x)$. Choose $i$ such that $x\in B_i$. Then one can find $\delta>0$ such that $B(x,\delta)\subset B_i$. (In the language of point-set topology: $x$ is an interior point of $B_i$.) To see this, write $B_i=B(y,r)$. Since $x\in B(y,r)$, we have $r-d(x,y)>0$. Choose $0<\delta<r-d(x,y)$. Then triangle inequality implies $B(x,\delta)\subset B(y,r)$. 

Since $x_n\rightarrow x$, there is $N\in\Zbb_+$ such that $x_n\in B(x,\delta)$ for all $n\geq N$. Thus, $(x_{k+N})_{k\in\Zbb_+}$ converges in $B_i$ to $x$. Since $f|_{B_i}$ is continuous, $\lim_{k\rightarrow\infty} f(x_{k+N})=f(x)$. So $f(x_n)\rightarrow f(x)$.
\end{proof}







\begin{df}
A map of metric spaces $f:X\rightarrow Y$ is called \index{00@Lipschitz continuous} \textbf{Lipschitz continuous} if there exists $L\in\Rbb_{>0}$ (called \textbf{Lipschitz constant}) \index{00@Lipschitz constant} such that for all $x_1,x_2\in X$,
\begin{align}
d_Y\big(f(x_1),f(x_2) \big)\leq L\cdot d_X(x_1,x_2) \label{eq14}
\end{align}
\end{df}

\begin{lm}\label{lb34}
Lipschitz continuous maps are continuous. 
\end{lm}

\begin{proof}
Suppose that $f:X\rightarrow Y$ is Lipschitz continuous with Lipschitz constant $L$. Suppose $x_n\rightarrow x$ in $X$. Then $L\cdot d(x_n,x)\rightarrow 0$. By \eqref{eq14} and Squeeze theorem (Prop. \ref{lb29}), $f(x_n)\rightarrow f(x)$. (You can also use Def. \ref{lb31}-(2) to prove this lemma.)
\end{proof}

\begin{eg}\label{lb35}
Let $\Fbb\in\{\Qbb,\Rbb,\Cbb\}$. The map $z\in\Fbb\setminus \{0\}\mapsto z^{-1}\in\Fbb$ is continuous.
\end{eg}



\begin{proof}
Let this map be $f$. Since $\Fbb$ is covered by open balls $B(z,\delta)$ where $z\in\Fbb\setminus\{0\}$ and $0<\delta<|z|$, by Lem. \ref{lb30}, it suffices to prove that $f$ is continuous when restricted to every such $B(z,\delta)$. Let $\eps=|z|-\delta>0$. Choose $x,y\in B(z,\delta)$. Then $|x|=|x-z+z|\geq |z|-|z-x|>\eps$ by triangle inequality. Similarly, $|y|>\eps$. So
\begin{align*}
|f(x)-f(y)|=|x^{-1}-y^{-1}|=|x-y|/|xy|\leq \eps^{-2}|x-y|
\end{align*}
So $f|_{B(z,\delta)}$ has Lipschitz constant $\eps^{-2}$, and hence is continuous.
\end{proof}

(Question: in the above proof, is the map $f:\Fbb\setminus\{0\}\rightarrow\Fbb$ Lipschitz continuous?)

We have given a fancy way of proving that  if $(z_n)$ is a sequence in $\Fbb\setminus\{0\}$ converging to $z\in\Fbb\setminus\{0\}$, then $z_n^{-1}\rightarrow z^{-1}$. You should think about how to prove this fact directly using $\eps-N$ language, and compare your proof with the above proof to find the similarities!




\begin{pp}\label{lb41}
Let $\Fbb\in\{\Qbb,\Rbb,\Cbb\}$. Then the following maps are continuous:
\begin{gather*}
+:\Fbb\times\Fbb\rightarrow\Fbb\qquad (x,y)\mapsto x+y\\
-:\Fbb\times\Fbb\rightarrow\Fbb\qquad  (x,y)\mapsto x-y\\
\times: \Fbb\times\Fbb\rightarrow\Fbb\qquad  (x,y)\mapsto xy\\
\div:\Fbb\times\Fbb^\times\rightarrow\Fbb\qquad  (x,y)\mapsto x/y
\end{gather*}
\end{pp}


Recall our Convention \ref{lb32} on the metrics of finite product spaces. 


\begin{proof}
We only prove that the last two are continuous: the first two can be treated in a similar (and easier) way.

Denote the multiplication map by $\mu$. We choose the metric on $\Fbb^2$ to be $d(\mbf x,\mbf x')=\max\{|x_1-x_1'|,|x_2-x_2'|\}$. Since $\Fbb\times\Fbb$ is covered by open balls of the form $B(0,r)=\{(x,y)\in\Fbb^2:|x|<r,|y|<r\}$ where $0<r<+\infty$, by Lem. \ref{lb30} and \ref{lb34}, it suffices to show that $\mu|_{B(0,r)}$ is Lipschitz continuous. This is true, since for each $(x,y),(x',y')\in B(0,r)$, we have
\begin{align}\label{eq22}
\begin{aligned}
&|\mu(x,y)-\mu(x',y')|=|xy-x'y'|\leq |(x-x')y|+|x'(y-y')|\\
<&2r\cdot \max\{|x-x'|,|y-y'|\}=2r \cdot d((x,y),(x',y'))  
\end{aligned}
\end{align}

By Exp. \ref{lb35} and Prop. \ref{lb37}, the map $(x,y)\in\Fbb\times\Fbb^\times\mapsto (x,y^{-1})\in\Fbb\times\Fbb$ is continuous. So its composition with the continuous map $\mu$ is continuous, thanks to Prop. \ref{lb36}. So $\div$ is continuous. 
\end{proof}

\begin{pp}\label{lb36}
Suppose that $f:X\rightarrow Y$ and $g:Y\rightarrow Z$ are continuous maps of metric spaces. Then $g\circ f:X\rightarrow Z$ is continuous.
\end{pp}

\begin{pp}\label{lb37}
Suppose that $f_i:X_i\rightarrow Y_i$ is a map of metric spaces, where $1\leq i\leq N$. Then the product map \index{00@Product map}
\begin{gather*}
f_1\times\cdots\times f_N:X_1\times\cdots\times X_N\rightarrow Y_1\times\cdots\times Y_N\\
(x_1,\dots,x_N)\mapsto (f_1(x_1),\dots,f_N(x_N))
\end{gather*}
is continuous if and only if $f_1,\dots,f_N$ are continuous.
\end{pp}

\begin{proof}[Proof of Prop. \ref{lb36} and \ref{lb37}]
Immediate from Def. \ref{lb31}-(1) and Prop. \ref{lb38}.
\end{proof}


\begin{co}[\textbf{Squeeze theorem}]\index{00@Squeeze theorem}\label{lb61}
Let $\Fbb\in\{\Qbb,\Rbb\}$ and $(x_n),(y_n),(z_n)$ be sequences in $\Rbb$. Assume that $x_n\leq y_n\leq z_n$ for all $n$. Assume that $x_n$ and $z_n$ both converge to $A\in\Rbb$. Then $\lim_{n\rightarrow\infty}y_n=A$. 
\end{co}

\begin{proof}
Let $a_n=y_n-x_n$ and $b_n=z_n-x_n$. Then $0\leq a_n\leq b_n$, and $\lim_n b_n=\lim_n z_n-\lim_n x_n= 0$ because the subtraction map is continuous (Prop. \ref{lb41}). By Exp. \ref{lb28}, $a_n\rightarrow 0$. Since $x_n\rightarrow A$, $y_n=x_n+a_n$ converges to $A$, since the addition map is continuous by Prop. \ref{lb41}.
\end{proof}

Again, this is a fancy way of proving Squeeze theorem. The readers should know how to prove it directly from the definition of limits of sequences.

We give some more examples of continuous maps.

\begin{eg}
By Prop. \ref{lb41}, $f(x,y,z)=x^2y+5y^4z^7-3xyz^2$ is a continuous function on $\Cbb^3$. Clearly $z\in\Cbb\mapsto \ovl z\in\Cbb$ is continuous. So $g(x,y,z)=f(\ovl x,\ovl y,z)+2\ovl{f(z,x^2,xy^{-9})}-5xy^{-2}\ovl{z^{-3}}$ is a continuous function on $\Cbb\times\Cbb^\times\times\Cbb^\times$.
\end{eg}


\begin{eg}\label{lb44}
Let $f,g:X\rightarrow \Fbb$ be continuous functions where $\Fbb\in\{\Qbb,\Rbb,\Cbb\}$. Then by Prop. \ref{lb41} and \ref{lb36}, $f\pm g$ and $fg$ are continuous, and $f/g$ is continuous when $0\notin g(X)$. Here
\begin{align}
(f\pm g)(x)=f(x)\pm g(x)\qquad (fg)(x)=f(x)g(x)\qquad (f/g)(x)=f(x)/g(x)
\end{align} 
\end{eg}


\begin{eg}\label{lb54}
Let $f:X\rightarrow Y$ be a map of metric spaces. Let $E,F$ be subsets of $X,Y$ respectively. (Recall that the metrics subspaces are chosen as in Def. \ref{lb43}.) 
\begin{itemize}
\item The inclusion map $\iota_E:E\rightarrow X,x\mapsto x$ is clearly continuous. Thus, if $f$ is continuous, then $f|_E:E\rightarrow Y$ is continuous, since $f|_E=f\circ\iota_E$.
\item If $f(X)\subset F$, then we can restrict the codomain of $f$ from $Y$ to $F$: let $\wtd f:X\rightarrow F$ be $\wtd f(x)=f(x)$. Then it is clear that $f$ is continuous iff $\wtd f$ is continuous.
\end{itemize}
\end{eg}




\begin{pp}
Let $X_1,\dots,X_N$ be metric spaces. The following  projection is clearly continuous:
\begin{gather*}
\pi_{X_i}:X_1\times\cdots\times X_N\rightarrow X_i\qquad(x_1,\dots,x_N)\mapsto x_i
\end{gather*}
\end{pp}

\begin{pp}
Let $f_i:X\rightarrow Y_i$ be maps where $X,Y_1,\dots,Y_N$ are continuous. Then 
\begin{gather*}
f_1\vee \cdots\vee f_N:X\rightarrow Y_1\times\cdots\times Y_N\qquad x\mapsto (f_1(x),\dots,f_N(x))
\end{gather*}
is continuous iff $f_1,\dots,f_N$ are continuous.
\end{pp}


\begin{eg}
Let $X$ be a metric space. Then $d:X\times X\rightarrow\Rbb,(x,y)\mapsto d(x,y)$ is Lipschiz continuous with Lipschitz constant $1$ (by triangle inequality). So $d$ is continuous.
\end{eg}

\begin{pp}\label{lb42}
Let $X$ be a metric space and $E\subset X$. Define \textbf{distance function} \index{00@Distance function $d(\cdot,E)$} \index{dE@$d(x,E)$} 
\begin{gather*}
d(\cdot,E):X\rightarrow\Rbb_{\geq0}\qquad
d(x,E)=\inf_{e\in E}d(x,e)
\end{gather*}
Then $d(\cdot,E)$ is has Lipschitz constant $1$. So $d(\cdot,E)$ is continuous.
\end{pp}


\begin{proof}
Choose any $x,y\in X$. By triangle inequality, for each $e\in E$ we have $d(x,e)\leq d(x,y)+d(y,e)$. Since $d(x,E)\leq d(x,e)$, we get  $d(x,E)\leq d(x,y)+d(y,e)$. Applying $\inf_{e\in E}$ to the RHS gives $d(x,E)\leq d(x,y)+d(y,E)$. Hence $d(x,E)-d(y,E)\leq d(x,y)$. Exchanging $x$ and $y$ gives
\begin{align}
\big|d(x,E)-d(y,E)\big|\leq d(x,y)
\end{align}
This proves that $d(\cdot,E)$ has Lipschitz constant $1$.
\end{proof}

\begin{df}
More generally, if $E,F$ are subsets of a metric space $E$, we can define \index{DEF@$d(E,F)$}
\begin{align}
d(E,F)=\inf_{e\in E,f\in F}d(e,f)
\end{align}
to be the \textbf{distance between $E$ and $F$}.
\end{df}

\begin{exe}
Let $E,F\subset X$. Prove that
\begin{align}
d(E,F)=\inf_{f\in F}d(E,f)
\end{align}
\end{exe}

\begin{eg}\label{lb45}
If $X$ is a metric space and $p\in X$, then by Prop. \ref{lb42} (or simply by triangle inequality), the function $d_p:x\in X\mapsto d(x,p)\in\Rbb$ has Lipschitz constant $1$ and hence is continuous. In particular, if $\Fbb\in\{\Rbb,\Cbb\}$,  the function $z\in\Fbb\mapsto |z|$ is continuous (since $|z|=d_\Fbb(z,0)$). Thus, if $f:X\rightarrow\Fbb$ is continuous, then $|f|:X\rightarrow\Rbb_{\geq0}$ is continuous where
\begin{align}
|f|(x)=|f(x)|
\end{align}
\end{eg}


\begin{eg}
Let $N\in\Zbb_+$. Then the following function is continuous:
\begin{align*}
\max:\Rbb^N\rightarrow \Rbb\qquad (x_1,\dots,x_N)\mapsto\max\{x_1,\dots,x_N\}\in\Rbb
\end{align*}
Similarly, the minimum function is continuous.
\end{eg}

\begin{proof}
To avoid confusion, we write $\max$ as $\max_N$. The case $N=1$ is obvious. When $N=2$, we have
\begin{align}
\max(x_1,x_2)=\frac{x_1+x_2+|x_1-x_2|}2
\end{align}
So $\max_2$ is continuous by Exp. \ref{lb44} and \ref{lb45}.

We use induction. Suppose we have proved that $\max_N$ is continuous. Then $\max_N\times\id_\Rbb:\Rbb^N\times \Rbb\rightarrow\Rbb\times\Rbb$ is continuous. So $\max_{N+1}=\max_2\circ(\max_N\times\id_\Rbb)$ is continuous.
\end{proof}


\subsection{Homeomorphisms and isometric isomorphisms; convergence in $\ovl{\Rbb}$}

\subsubsection{General theory}



\begin{df}
A bijection of metric spaces $f:X\rightarrow Y$ is called a \textbf{homeomorphism} if one of the following equivalent (cf. Def. \ref{lb31}) statements holds:
\begin{itemize}
\item[(1)] $f:X\rightarrow Y$ and its inverse map $f^{-1}:Y\rightarrow X$ are continuous.
\item[(2)] For each sequence $(x_n)$ in $X$ and each $x\in X$, we have $\dps \lim_{n\rightarrow\infty}x_n=x$ iff $\dps\lim_{n\rightarrow\infty}f(x_n)=f(x)$.
\end{itemize}
If such $f$ exists, we say that $X,Y$ are \textbf{homeomorphic}.
\end{df}

A special case of the above definition is:
\begin{df}
Let $X$ be a set with metrics $d,\delta$. We say that $d$ and $\delta$ induce the \textbf{same topology} on $X$ (or that $d,\delta$ are \index{00@Topologically equivalent metrics} \textbf{topologically equivalent}) if one of the following clearly equivalent statements holds:
\begin{itemize}
\item[(1)] The map $(X,d)\rightarrow (X,\delta),x\mapsto x$ is a homeomorphism.\footnote{We prefer not to call this map the identity map, because the metrics on the source and on the target are different.}
\item[(2)] For each sequence $(x_n)$ in $X$ and each $x\in X$, $(x_n)$ converges to $x$ under the metric $d$ iff $(x_n)$ converges to $x$ under $\delta$.
\end{itemize}
\end{df}


\begin{pp}\label{lb48}
Suppose that $d,\delta$ are equivalent metrics on a set $X$. Then $d,\delta$ are topologically equivalent.
\end{pp}

\begin{proof}
Suppose $\delta\leq\alpha d$ and $d\leq\beta\delta$ for some $\alpha,\beta>0$. Then the map $f:(X,d)\rightarrow (X,\delta),x\mapsto x$ and its inverse $f^{-1}$ have Lipschitz constants $\alpha$ and $\beta$ respectively. So $f,f^{-1}$ are continuous.
\end{proof}






\begin{exe}\label{lb46}
Let $f:X\rightarrow Y$ be a map of metric spaces. We say that $f:X\rightarrow Y$ is an \textbf{isometry} (or is \textbf{isometric}) \index{00@Isometry and isometric isomorphism} if for all $x_1,x_2\in X$ we have
\begin{align}
d_Y(f(x_1),f(x_2))=d_X(x_1,x_2) \label{eq15}
\end{align}
Show that an isometry is injective and continuous.

We say that $f$ is an \textbf{isometric isomorphism} if $f$ is a surjective isometry. If an isometric isomorphism between two metric spaces $X,Y$ exists, we say that $X$ and $Y$ are \textbf{isometric metric spaces}.\index{00@Isometric metric spaces} Show that an isometric isomorphisms is a homeomorphism.   \hfill\qedsymbol
\end{exe}

\begin{rem}
Isometric isomorphisms are important examples of homeomorphisms. That $f:X\rightarrow Y$ is an isometric isomorphism means that $X$ and $Y$ are equivalent as metric spaces, and that this equivalence can be implemented by the bijection $f$. 

We now look at isometric isomorphisms in a different direction. Suppose that $f:X\rightarrow Y$ is a bijection of sets. Suppose that $Y$ is a metric space. Then there is unique metric $d_X$ on $X$ such that $f$ is an isometric isomorphism: one defines $d_X$ using \eqref{eq15}. We write such $d_X$ as $f^*d_Y$, \index{fdY@$f^*d_Y$: pullback metric}  i.e.,
\begin{align*}
f^*d_Y(x_1,x_2)=d_Y(f(x_1),f(x_2))
\end{align*}
and call $f^*d_Y$ the \textbf{bullback metric} \index{00@Pullback metrics} of $d_Y$ by $f$. \hfill\qedsymbol
\end{rem}

Pullback metrics are a very useful way of constructing metrics on a set. We consider some examples below. 


\begin{exe}\label{lb49}
Two metrics inducing the same topology are not necessarily equivalent metrics. For example, let $f:[0,1]\rightarrow [0,1]$ be $f(x)=x^2$. Let $X=[0,1]$, and let $d_X$ be the  Euclidean metric: $d_X(x,y)=|x-y|$. So
\begin{align*}
f^*d_X(x,y)=|x^2-y^2|
\end{align*}
is a metric on $X$. It is not hard to check that $f:(X,d_X)\rightarrow (X,d_X)$ is a homeomorphism.  So $d_X$ and $f^*d_X$ give the same topology on $[0,1]$ (cf. Exe. \ref{lb50}). Show that $f^*d_X$ and $d_X$ are not equivalent metrics.
\end{exe}

\begin{exe}\label{lb50}
Let $f:X\rightarrow Y$ be a bijection of sets with metrics $d_X,d_Y$. Show that $d_X$ and $f^*d_Y$ give the same topology on $X$ iff $f:(X,d_X)\rightarrow(Y,d_Y)$ is a homeomorphism. 

In particular, if $f:X\rightarrow X$ is a bijection, and $d_X$ is a metric on $X$. Then $d_X$ and $f^*d_X$ give the same topology on $X$ iff $f:(X,d_X)\rightarrow (X,d_X)$ is a homeomorphism. 
\end{exe}


\subsubsection{Convergence in $\ovl\Rbb$}


Our second application of pullback metrics is the convergence in $\ovl\Rbb$.




\begin{df}\label{lb47}
We say that a sequence $(x_n)$ in $\ovl\Rbb$ \textbf{converges to} \index{00@Convergence in $\ovl{\Rbb}$} $+\infty$ (resp. $-\infty$), if for every $A\in\Rbb_{>0}$ there is $N\in\Zbb_+$ such that for all $n\geq N$ we have $x_n>A$ (resp. $x_n<-A$). 

Suppose $x\in\Rbb$. We say that a sequence $(x_n)$ in $\ovl\Rbb$ \textbf{converges to} $x$, if there is $N\in\Zbb_+$ such that $x_n\in\Rbb$ for all $n\geq N$ (i.e. $x_n\in\Rbb$ for sufficiently large $n$), and that the subsequence $(x_{k+N})_{k\in\Zbb_+}$ converges in $\Rbb$ to $x$.  \hfill\qedsymbol
\end{df}



This notion of convergence is weird: it is not defined by a metric. So one wonders if there is a metric $d$ on $\ovl\Rbb$ such that convergence of sequences under $d$ agrees with that in Def. \ref{lb47}. We shall now find such a metric.

\begin{lm}\label{lb59}
Let $-\infty\leq a<b\leq +\infty$ and $-\infty\leq c<d\leq +\infty$. Then there is a strictly increasing bijective map $[a,b]\rightarrow[c,d]$.
\end{lm}
Note that this map clearly sends $a$ to $c$ and $b$ to $d$. So it restricts to strictly increasing bijections $(a,b)\rightarrow(c,d)$, $(a,b]\rightarrow(c,d]$, $[a,b)\rightarrow[c,d)$.

\begin{proof}
We have a strictly increasing bijection $f:\Rbb\rightarrow(-1,1)$ defined by \eqref{eq20}.  $f$ can be extended to a strictly increasing bijective map $\ovl\Rbb\rightarrow[-1,1]$ if we set $f(\pm\infty)=\pm1$. Thus, $f$ restricts to a strictly increasing bijection $[a,b]\rightarrow [c',d']$ where $c'=f(a),d'=f(b)$. Choose a linear function $g(x)=\alpha x+\beta$ (where $\alpha>0$) giving an increasing bijection $[c',d']\rightarrow[c,d]$. Then $g\circ f$ is the desired map.
\end{proof}


\begin{thm}\label{lb51}
Let $\varphi:\ovl\Rbb\rightarrow[a,b]$ be a strictly increasing bijective map where $[a,b]\subset\Rbb$ is equipped with the Euclidean metric $d_{[a,b]}$. Then a sequence $(x_n)$ in $\ovl\Rbb$ converges to $x\in\ovl\Rbb$ in the sense of Def. \ref{lb47} iff $\varphi(x_n)$ converges to $\varphi(x)$ under the metric $d_{[a,b]}$. In other words, the convergence in $\ovl\Rbb$ is given by the metric $\varphi^*d_{[a,b]}$.
\end{thm}

\begin{proof}
Let $y=\varphi(x)$ and $y_n=\varphi(x_n)$. We need to prove that $x_n\rightarrow x$ (in the sense of Def. \ref{lb47}) iff $y_n\rightarrow y$ (under the Euclidean metric). Write $\psi=\varphi^{-1}$, which is a strictly increasing map $[a,b]\rightarrow\ovl\Rbb$. Note that $\varphi(+\infty)=b$ and $\varphi(-\infty)=a$. 

Case 1: $x\in\Rbb$. By discarding the first several terms, we may assume that $(x_n)$ is always in $\Rbb$. If $x_n\rightarrow x$, then for every $\eps>0$, all but finitely many $x_n$ are inside the open interval $(\psi(y-\varepsilon),\psi(y+\varepsilon))$. So all but finitely many $y_n$ are inside $(y-\varepsilon,y+\varepsilon)$. So $y_n\rightarrow y$. That $y_n\rightarrow y$ implies $x_n\rightarrow x$ is proved in a similar way.

Case 2: $x=\pm\infty$. We consider $x=+\infty$ only; the other case is similar. Note that if $0<\eps<b-a$, then $B_{[a,b]}(b,\varepsilon)=(b-\varepsilon,b]$.  If $x_n\rightarrow+\infty$, then for each  $0<\eps<b-a$, all but finitely many $x_n$ are $>\psi(b-\eps)$. So all but finitely many $y_n$ are inside $(b-\eps,b]$. This proves $y_n\rightarrow b$. Conversely, if $y_n\rightarrow b$, then for each $A>0$, all but finitely many $y_n$ are inside $(\varphi(A),b]$ and hence $>\varphi(A)$. So all but finitely many $x_n$ are $>A$.
\end{proof}


\begin{cv}\label{lb77}
Unless otherwise stated, a metric on $\ovl\Rbb$ is one that makes Def. \ref{lb47} true, for instance $\varphi^*d_{[a,b]}$ in Thm. \ref{lb51}. Unless otherwise stated, we do NOT view $\Rbb$ (or any subset of $\Rbb$) as a metric subspace of $\ovl\Rbb$. Namely, we do not follow Convention \ref{lb76} for $\Rbb\subset\ovl\Rbb$, or more generally for $\Rbb^N\subset\ovl\Rbb^N$. Instead, we choose Euclidean metrics on $\Rbb^N$, following Convention \ref{lb33}. 
\end{cv}



The main reason for not following Convention \ref{lb76} here is that metrics on $\ovl\Rbb$ are all bounded (by Prop. \ref{lb71}). Thus, every subset of $\Rbb$ is bounded if we view $\Rbb$ as a metric subspace of $\ovl\Rbb$. However, we want a subset of $\Rbb$ to be bounded precisely when it is contained in $[a,b]$ for some $-\infty<a<b<+\infty$.



\begin{rem}\label{lb58}
By Thm. \ref{lb51}, the properties of $[a,b]$ about convergence of sequences and inequalities can be transported to $\ovl\Rbb$, for example:
\begin{enumerate}
\item If $(x_n),(y_n)$ are sequences in $\ovl\Rbb$ converging to $A,B\in\ovl\Rbb$, and if $x_n\leq y_n$ for all $n$, then $A\leq B$.
\item \textbf{Squeeze theorem}: \index{00@Squeeze theorem} Suppose that $(x_n),(y_n),(z_n)$ are sequences in $\ovl\Rbb$, $x_n\leq y_n\leq z_n$ for all $n$, and $x_n$ and $z_n$ both converge to $A\in\ovl\Rbb$. Then $y_n\rightarrow A$.
\item Prop. \ref{lb57} also holds for $[a,b]$ in $\ovl\Rbb$: if $(x_n)$ is an increasing resp. decreasing sequence in $[a,b]$, then $\lim_n x_n$ equals $\sup_n x_n$ resp. $\inf_n x_n$.
\end{enumerate}
We will see more examples when studying $\limsup$ and $\liminf$ in the future.
\end{rem}


We have shown that there is a metric on $\ovl\Rbb$ which defines the convergence in Def. \ref{lb47}. However, there is no standard choice of such a metric on $\ovl\Rbb$. Even worse, two possible choices of metrics might not be equivalent: Let $\varphi,\psi:\ovl\Rbb\rightarrow[0,1]$ be a strictly increasing bijections where $\psi\circ\varphi^{-1}:[0,1]\rightarrow[0,1]$ is $x\mapsto x^2$. Then by Exe. \ref{lb49}, $\varphi^*d_{[0,1]}$ and $\psi^*d_{[0,1]}$ are non-equivalent metrics giving the same topology on $\ovl\Rbb$. This is the first example that metrics are not convenient for the description of convergence. When studying the convergence in $\ovl\Rbb$, thinking about metrics is distracting. In the future, we will see a better notion for the study of convergence: the notion of topological spaces.

We end this section with a generalization of Thm. \ref{lb51}.

\begin{thm}\label{lb65}
Let $\varphi$ be a strictly increasing bijection in one of the following forms
\begin{gather*}
[a,b]\rightarrow [c,d]\qquad (a,b)\rightarrow(c,d)\\
(a,b]\rightarrow (c,d]\qquad [a,b)\rightarrow [c,d)
\end{gather*}
where $-\infty\leq a\leq b\leq +\infty$ and $-\infty\leq c\leq d\leq +\infty$. Then $\varphi$ is a homeomorphism, i.e., if $(x_n)$ and $x$ are in the domain, then $x_n\rightarrow x$ iff $\varphi(x_n)\rightarrow \varphi(x)$ (in the sense of Def. \ref{lb47}).
\end{thm}

\begin{proof}
The case $a=b$ is obvious. So we consider $a<b$, and hence $c<d$. We consider the left-open-right-closed case for example. The other cases are treated in a similar way. If the theorem can be proved for $(-\infty,+\infty]\rightarrow(c,d]$, then it can also be proved $(-\infty,+\infty]\rightarrow(a,b]$. By composing the inverse of the second map with the first map, we see that the theorem holds for $[a,b]\rightarrow[c,d]$. 

Let us consider $\varphi:(-\infty,+\infty]\rightarrow(c,d]$. $\varphi$ can be extended to a strictly increasing bijection $\varphi:\ovl\Rbb\rightarrow[c,d]$ by letting $\varphi(-\infty)=c$. It suffices to prove that this $\varphi$ is a homeomorphism. When $-\infty<c<d<+\infty$, then the theorem holds by Thm. \ref{lb51}. If one of $c,d$ is $\pm\infty$, the same argument as in the proof of Thm. \ref{lb51} proves that $\varphi$ is a homeomorphism. We leave it to the readers to fill in the details.
\end{proof}



\subsection{Problems and supplementary material}

\begin{df}
Let $A$ be a subset of $\Rbb$  satisfying $x+y\in A$ for all $x,y\in A$. (Or more generally, let $A$ be an abelian semigroup.) We say that a function $f:A\rightarrow \Rbb$ is \textbf{subadditive} \index{00@Subadditivity} if for every $x,y\in A$ we have $f(x+y)\leq f(x)+f(y)$.
\end{df}

\begin{prob}\label{lb52}
Consider the following increasing functions:
\begin{gather*}
f_1:\Rbb_{\geq 0}\rightarrow[0,1)\qquad f_1(x)=\frac{x}{1+x}\\
f_2:\Rbb_{\geq 0}\rightarrow[0,1]\qquad f_2(x)=\min\{x,1\}
\end{gather*}
Prove that they are subadditive functions. 
\end{prob}

\begin{prob}\label{lb53}
Let $f:\Rbb_{\geq0}\rightarrow \Rbb_{\geq0}$ be an increasing subadditive function satisfying the following conditions:
\begin{itemize}
\item[(1)] $f^{-1}(0)=\{0\}$.
\item[(2)] For any $(x_n)_{n\in\Zbb_+}$ in $\Rbb_{\geq0}$ we have $x_n\rightarrow 0$ iff $f(x_n)\rightarrow 0$.
\end{itemize}
Let $(X,d)$ be a metric space. Define
\begin{align*}
\delta:X\times X\rightarrow [0,A)\qquad \delta(x,y)=f\circ d(x,y)
\end{align*}  
Prove that $\delta$ is a metric, and that $\delta$ and $d$ are topologically equivalent.
\end{prob}


\begin{pp}
Let $(X,d)$ be a metric space. Then there is a \textbf{bounded metric} \index{00@Bounded metric} $\delta$ on $X$, where ``bounded" means $\sup d(X\times X)<+\infty$, such that $d$ and $\delta$ induce the same topology.
\end{pp}
\begin{proof}
Let $f$ be either $f_1$ or $f_2$ defined in Pb. \ref{lb52}. Then $f$ satisfies the assumptions in Pb. \ref{lb53}. So $\delta=f\circ d$ is a desired metric due to Pb. \ref{lb53}. We write down the formulas explicitly:
\begin{align*}
\delta_1(x,y)=\frac{d(x,y)}{1+d(x,y)}\qquad \delta_2(x,y)=\min\{d(x,y),1\}
\end{align*}
\end{proof}

\begin{prob}\label{lb78}
Let $(X_i,d_i)_{i\in\Zbb_+}$ be an sequence of metric spaces. Assume that $d_i\leq 1$ for each $i$. Let $\dps S=\prod_{i\in\Zbb_+} X_i$. For each elements $f=(f(i))_{i\in\Zbb_+}$ and $g=(g(i))_{i\in\Zbb_+}$ of $S$, define
\begin{align}
d(f,g)=\sup_{i\in\Zbb_+} \frac {d_i(f(i),g(i))}{i}  \label{eq16}
\end{align} 
Prove that $d$ is a metric on $S$. Let $f_n=(f_n(i))_{i\in\Zbb_+}$ be a sequence in $S$. Let $g\in S$. Prove that the following are equivalent:
\begin{enumerate}[label=(\alph*)]
\item $\dps \lim_{n\rightarrow\infty} f_n=g$ under the metric $d$.
\item $f_n$ \textbf{converges pointwisely} to $g$, namely, $\dps\lim_{n\rightarrow\infty} f_n(i)=g(i)$ for every $i\in\Zbb_+$.
\end{enumerate}
\end{prob}

\begin{rem}
The above problem gives our first non-trivial example of function spaces  as metric spaces, where the domain of functions is a countable set. After learning series, the readers can check that 
\begin{align*}
\delta(f,g)=\sum_{i\in\Zbb_+}2^{-i} d_i(f(i),g(i))
\end{align*}
also defines a metric, and that (a) (with $d$ replaced by $\delta$) and (b) equivalent. So $\delta$ and $d$ (defined by \eqref{eq16}) induce the same topology on $X$, called the \textbf{pointwise convergence topology} or simply \textbf{product topology}. Unfortunately, if the index set $\Zbb_+$ is replaced by an uncountable set, there is in general no metric inducing the product topology. We will prove this in a later problem.
\end{rem}













\begin{sprob}
Let $X=\bigsqcup_{i\in I}A_i$ be a disjoint union of metric spaces $(A_i,d_i)$. Assume that $d_i\leq 1$ for all $i$. For each $x,y\in X$, define
\begin{gather*}
d(x,y)=\left\{
\begin{array}{ll}
d_i(x,y)&\text{ if $x,y\in A_i$ for some $i\in A$}\\[0.5ex]
\frac 12&\text{ otherwise}
\end{array}
\right.
\end{gather*}
\begin{enumerate}
\item Prove that $d$ defines a metric on $X$. 
\item Choose $(x_n)_{n\in\Zbb_+}$ in $X$ and $x\in X$. What does $\dps\lim_{n\rightarrow\infty}x_n=x$ mean in terms of the convergence in each $A_i$?
\end{enumerate}
\end{sprob}

Think about the question: Let $X$ be a set. For each $x,y\in X$ define $d(x,y)=0$ if $x=y$, and $d(x,y)=1$ if $x\neq y$. What does convergence in $(X,d)$ mean?




\newpage



\section{Sequential compactness and completeness}



\subsection{Sequential compactness}


\subsubsection{Basic properties of sequentially compact spaces}

\begin{df}
Let $X$ be a metric space. We say that $X$ is \textbf{sequentially compact} \index{00@Sequentially compact} if every sequence in $X$ has a subsequence converging to some point of $X$.
\end{df}





The notion of sequential compactness is extremely useful for finding solutions in an analysis problem. In general, suppose we want to find a point $x\in X$ which makes a property $P(x)$ to be true. Suppose that we can find an ``approximate solution", i.e. an $y\in X$ such that $P(y)$ is close to being true. Thus, we can find a sequence $(x_n)$ in $X$ such that $P(x_n)$ is closer and closer to being true when $n\rightarrow\infty$. Now, if $X$ is sequentially compact, then $(x_n)$ has a subsequence $(x_{n_k})$ converging to $x\in X$. Then $P(x)$ is true, and hence $x$ is a solution for the problem. (See also Sec. \ref{lb55}.) Let us see an explicit example:

\begin{lm}[Extreme value theorem]\label{lb56}
Let $X$ be a sequentially compact metric space. Let $f:X\rightarrow\Rbb$ be a continuous function. Then $f$ attains its maximum and minimum at points of $X$. In particular, $f(X)$ is a bounded subset of $\Rbb$.
\end{lm}

This extremely important result is the main reason for introducing sequentially compact spaces. We call this a lemma, since we will substantially generalize this result later. (See Exe. \ref{lb63}.)

Note that the \textbf{boundedness} of subsets of $\Rbb$ (or more generally, of $\Rbb^N$) is always understood under the Euclidean metric of $\Rbb$, not under any metric of $\ovl\Rbb$ or $\ovl\Rbb^N$. (Recall Convention \ref{lb77}.)

\begin{proof}
We show that $f$ attains its maximum on $X$. The proof for minimum is similar. Let $A=\sup f(X)$. Then $A\in (-\infty,+\infty]$. If $A<+\infty$, then for each $n\in\Zbb_+$ there is $x_n\in X$ such that $A-1/n<f(x_n)\leq A$ (since $A-1/n$ is not an upper bound of $f(X)$). If $A=+\infty$, then for each $n$ there is $x_n\in X$ such that $f(x_n)>n$. In either case, we have a sequence $(x_n)$ in $X$ such that $f(x_n)\rightarrow A$ in $\ovl \Rbb$.

Since $X$ is sequentially compact, $(x_n)$ has a subsequence $(x_{n_k})_{k\in\Zbb_+}$ converging to some $x\in X$. Now, consider $f$ as a map $f:X\rightarrow\ovl\Rbb$, which is continuous (cf. Exp. \ref{lb54}). Since $f(x_n)\rightarrow A$, its subsequence $f(x_{n_k})$ also converges to $A$. But since $x_{n_k}\rightarrow x$ and $f$ is continuous at $x$, we have $A=f(x)$. So $f$ attains its maximum at $x$. Since $f(X)\subset\Rbb$, we have $A\in\Rbb$.
\end{proof}

The following are some elementary examples of sequential compactness:


\begin{exe}
Show that finite unions of sequentially compact spaces is sequentially compact. (In particular, a finite set is sequentially compact.) 

More precisely, let $X$ be a metric space. Assume $X=A_1\cup\cdots\cup A_N$ where each metric subspace $A_i$ is sequentially compact. Show that $X$ is sequentially compact.  
\end{exe}

\begin{pp}\label{lb72}
Let $X_1,\dots,X_N$ be sequentially compact metric spaces. Then $X=X_1\times\cdots\times X_N$ is sequentially compact.
\end{pp}

\begin{proof}
Since $X=(X_1\times\cdots\times X_{N-1})\times X_n$, by induction, it suffices to assume $N=2$. So we write $X=A\times B$ where $A,B$ are sequentially compact. Let $(a_n,b_n)$ be a sequence in $X$. Since $A$ is sequentially compact, $(a_n)$ has a convergent subsequence $(a_{n_k})$. Since $B$ is sequentially compact, $(b_{n_k})$ has a convergent subsequence $(b_{n_{k_l}})$. So $(a_{n_{k_l}},b_{n_{k_l}})$ is a convergent subsequence of $(a_n,b_n)$.
\end{proof}


\begin{pp}\label{lb62}
Let $f:X\rightarrow Y$ be a continuous surjective map of metric spaces. Assume that $X$ is sequentially compact. Then $f(X)$, as a metric subspace of $Y$, is sequentially compact.
\end{pp}

\begin{proof}
Choose any sequence $(y_n)$ in $f(X)$. We can write $y_n=f(x_n)$ where $x_n\in X$. Since $X$ is sequentially compact, $(x_n)$ has a subsequence $(x_{n_k})$ converging to some $x\in X$. Since $f$ is continuous, $y_{n_k}=f(x_{n_k})$ converges to $f(x)$.
\end{proof}


\begin{exe}\label{lb63}
Prove that if $Y$ is a sequentially compact subset of $\Rbb$, then $\sup Y\in Y$ and $\inf Y\in Y$. Therefore, Prop. \ref{lb62} generalizes Lem. \ref{lb56}.
\end{exe}

\begin{pp}\label{lb71}
Let $X$ be a sequentially compact metric space. Then $X$ is bounded under its metric $d$, equivalently, $\sup d(X\times X)<+\infty$.
\end{pp}

\begin{proof}
Fix $p\in X$. The function $d_p:x\in X\mapsto d(x,p)\in\Rbb_{\geq 0}$ is continuous by Exp. \ref{lb45}. So, by Lem. \ref{lb56}, $d_p$ is bounded by some $0<R<+\infty$. So $X=\ovl B_X(p,R)$.
\end{proof} 






\subsubsection{Limits inferior and superior, and Bolzano-Weierstrass}\label{lb69}

The goal of this subsection is to prove that closed intervals are sequentially compact. 


\begin{df}
Let $(x_n)$ be a sequence in a metric space $X$. We say that $x\in X$ is a \textbf{cluster point} \index{00@Cluster point of a sequence} of $(x_n)$, if $(x_n)$ has a subsequence $(x_{n_k})$ converging to $x$.
\end{df}







\begin{df}\label{lb60}
Let $(x_n)$ be a sequence in $\ovl\Rbb$. Define
\begin{gather}
\alpha_n=\inf\{x_k:k\geq n \}\qquad \beta_n=\sup\{x_k:k\geq  n \}
\end{gather}
It is clear that $\alpha_n\leq x_n\leq \beta_n$, that $(\alpha_n)$ is increasing and $(\beta_n)$ is decreasing. Define \index{liminfsup@$\liminf,\limsup$}
\begin{subequations}
\begin{gather}
\liminf_{n\rightarrow\infty}x_n=\sup\{\alpha_n:n\in\Zbb_+\}=\lim_{n\rightarrow\infty} \alpha_n \label{eq18}\\
\limsup_{n\rightarrow\infty}x_n=\inf\{\beta_n:n\in\Zbb_+\}=\lim_{n\rightarrow\infty} \beta_n\label{eq19}
\end{gather}
\end{subequations}
(cf. Rem. \ref{lb58}), called respectively the \textbf{limit inferior} and the \textbf{limit superior} \index{00@Limit inferior and superior} of $(x_n)$.
\end{df}

\begin{thm}\label{lb68}
Let $(x_n)$ be a sequence in $\ovl\Rbb$, and let $S$ be the set of cluster points of $(x_n)$. Then $\dps\liminf_{n\rightarrow\infty}x_n$ and $\dps\limsup_{n\rightarrow\infty}x_n$ belong to $S$. They are respectively the minimum and the maximum of $S$.
\end{thm}

In particular, every sequence in $\ovl\Rbb$ has at least one cluster point.

\begin{proof}
We use the notations in Def. \ref{lb60}. Let $A=\eqref{eq18}$ and $B=\eqref{eq19}$. If $x\in S$, pick a subsequence $(x_{n_k})$ converging to $x$. Since $\alpha_{n_k}\leq x_{n_k}\leq \beta_{n_k}$, we have $A\leq x\leq B$ by Rem. \ref{lb58}. It remains to show that $A,B\in S$. We prove $B\in S$ by constructing a subsequence $(x_{n_k})$ converging to $B$; the proof of $A\in S$ is similar. 

Consider first of all the special case that $(x_n)$ is bounded, i.e., is inside $[a,b]\subset\Rbb$. Choose an arbitrary $n_1\in\Zbb_+$. Suppose $n_1<\dots<n_k$ has be constructed. By the definition of $\beta_{1+n_k}$, there is $n_{k+1}\geq 1+n_k$ such that $x_{n_{k+1}}$ is close to $\beta_{1+n_k}$, say
\begin{align}
\beta_{1+n_k}-\frac 1k<x_{n_{k+1}}\leq \beta_{1+n_k}  \label{eq17}
\end{align}
Since the left most and the right most of \eqref{eq17} both converge to $B$ as $k\rightarrow\infty$, by Squeeze theorem (Cor. \ref{lb61}) we conclude $\lim_k x_{n_k}=B$. 

In general, by Lem. \ref{lb59} and Thm. \ref{lb65}, there is an increasing (i.e. order-preserving) homeomorphism (i.e. topopogy-preserving map) $\varphi:\ovl\Rbb\rightarrow[0,1]$. Then $\varphi(\beta_n)=\sup\{\varphi(x_k):k\geq n\}$ (cf. Exe. \ref{lb66}) and $\varphi(B)=\lim_n\varphi(\beta_n)$. So $\varphi(B)=\limsup_n \varphi(x_n)$. By the above special case, $(\varphi(x_n))$ has a subsequence $(\varphi(x_{n_k}))$ converging to $\varphi(B)$. So $(x_{n_k})$ converges to $B$. 
\end{proof}

\begin{rem}
One can also prove the above general case directly using a similar idea as in the special case. And you are encouraged to do so! (Pay attention to the case $B=\pm\infty$.) 

The proof given above belongs to a classical proof pattern: To prove that a space $X$ satisfies some property, one first prove it in a convenient case. Then, in the general case, one finds an ``isomorphism" (i.e. ``equivalence" in a suitable sense) $\varphi:X\rightarrow Y$ where $Y$ is in the convenient case. Then the result on $Y$ can be translated via $\varphi^{-1}$ to $X$, finishing the proof. 

For example, to solve a linear algebra problem about linear maps between finite-dimensional vector spaces $V,W$, one first proves it in the special case that $V=\Fbb^m$ and $W=\Fbb^n$. Then, the general case can be translated to the special case via an equivalence as in Exp. \ref{lb67}.  \hfill\qedsymbol
\end{rem}


\begin{exe}\label{lb66}
Let $X,Y$ be partially ordered sets. Let $\varphi:X\rightarrow Y$ be an increasing bijection whose inverse is also increasing. (Namely, $\varphi$ induces an equivalence of partially ordered sets). Suppose $E\subset X$ has supremum $\sup E$. Explain why $\varphi(E)$ has supremum $\varphi(\sup E)$.
\end{exe}


It is now fairly easy to prove the famous

\begin{thm}[Bolzano-Weierstrass]\index{00@Bolzano-Weierstrass theorem}
Let $[a_1,b_1],\dots,[a_N,b_N]$ be closed intervals in $\ovl\Rbb$. Then $[a_1,b_1]\times\cdots\times [a_N,b_N]$ is sequentially compact. 
\end{thm}

\begin{proof}
By Prop. \ref{lb72}, it suffices to assume $N=1$. Write $a_1=a,b_1=b$. Let $(x_n)$ be a sequence in $[a,b]$. By Thm. \ref{lb68}, $(x_n)$ has a subsequence $(x_{n_k})$ converging to some $x\in\ovl\Rbb$. (E.g. $x=\limsup_n x_n$.) Since $a\leq x_{n_k}\leq b$, we have $a\leq x\leq b$ by Rem. \ref{lb58}.
\end{proof}

Bolzano-Weierstrass theorem illustrates why we sometimes prefer to work with $\ovl\Rbb$ instead of $\Rbb$: $\ovl\Rbb$ is sequentially compact, while $\Rbb$ is not. That every sequence has limits superior and inferior in $\ovl\Rbb$ but not necessarily in $\Rbb$ is closely related to this fact. In the language of point-set topology, $\ovl\Rbb$ is a \textbf{compactification} of $\Rbb$.








\subsubsection{A criterion for convergence in sequentially compact spaces}

At the end of Sec. \ref{lb73}, we have raised the following question: Suppose that $(x_n)$ is a bounded sequence in a metric space $X$ such that any two convergent subsequences converge to the same point. Does $(x_n)$ converge?

When $X$ is sequentially compact, $(x_n)$ is automatically bounded due to Prop. \ref{lb71}. The answer to the above question is yes:

\begin{thm}\label{lb74}
Let $X$ be a sequentially compact metric space. Let $(x_n)$ be a sequence in $X$. Then the following are equivalent.
\begin{itemize}
\item[(1)] The sequence $(x_n)$ converges in $X$.
\item[(2)] Any two convergent subsequences of $(x_n)$ converge to the same point. In other words, $(x_n)$ has only one cluster point. 
\end{itemize}
\end{thm}


\begin{proof}
(1)$\Rightarrow$(2): By Prop. \ref{lb23}.

(2)$\Rightarrow$(1): Assume that $(x_n)$ has at most one cluster point. Since $X$ is sequentially compact, $(x_n)$ has at least one cluster point $x\in X$. We want to prove $\lim_{n\rightarrow\infty} x_n=x$. Suppose not. Then there exists $\eps>0$ such that for every $N\in\Zbb_+$ there is $n\geq N$ such that $d(x_n,x)\geq \eps$. Thus, one can inductively construct a subsequence $(x_{n_k})$ of $(x_n)$ such that $d(x_{n_k},x)\geq\eps$ for all $k$. Since $X$ is sequentially compact, $(x_{n_k})$ has a subsequence $x'_n$ converging to $x'\in X$. So $d(x'_n,x)\geq\eps$ for all $n$. Since the function $y\in X\mapsto d(y,x)$ is continuous (Exp. \ref{lb45}), we have $\lim_{n\rightarrow\infty}d(x_n',x)=d(x',x)$. This proves that $d(x',x)\geq\eps>0$. However, $x',x$ are both cluster points of $(x_n)$, and so $x=x'$. This gives a contradiction. 
\end{proof}

\begin{rem}
Thm. \ref{lb74} can be used in the following way. Suppose that we want to prove that a given sequence $(x_n)$ in a sequentially compact space $X$ converges to $x$. Then it suffices to prove that if $(x_n')$ is a subsequence of $(x_n)$ converging to some $y\in X$, then $y=x$. This is sometimes easier to prove than directly proving the convergence of $(x_n)$. We will use this strategy in the proof of L'H\^ospital's rule, for example.
\end{rem}





\begin{co}\label{lb75}
Let $(x_n)$ be a sequence in $\Rbb^N$. The following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item The sequence $(x_n)$ converges in $\Rbb^N$.
\item The sequence $(x_n)$ is bounded. Moreover, any two convergent subsequences of $(x_n)$ converge to the same point of $\Rbb^N$.
\end{enumerate}
\end{co}

\begin{proof}
(1)$\Rightarrow$(2): By Prop. \ref{lb24} and \ref{lb23}. 

(2)$\Rightarrow$(1): Assume (2). Since $(x_n)$ is bounded, it can be contained in $X=I_1\times\cdots\times I_N$ where each $I_i$ is a closed interval in $\Rbb$. By Bolzano-Weierstrass, $X$ is sequentially compact. Thus, by Thm. \ref{lb74}, $(x_n)$ has a subsequence converging in $X$ and hence in $\Rbb^N$.
\end{proof}

\begin{co}
The following are true.
\begin{itemize}
\item[1.] Let $(x_n)$ be a sequence in $\ovl\Rbb$. Then $(x_n)$ converges in $\ovl\Rbb$ iff $\dps\limsup_{n\rightarrow\infty} x_n$ equals $\dps\liminf_{n\rightarrow\infty} x_n$. 
\item[2.] Let $(x_n)$ be a sequence in $\Rbb$. Then $(x_n)$ converges in $\Rbb$ iff $\dps\limsup_{n\rightarrow\infty} x_n$ equals $\dps\liminf_{n\rightarrow\infty} x_n$ and $(x_n)$ is bounded.
\end{itemize}
\end{co}

\begin{proof}
1. Let $A=\liminf x_n$ and $B=\limsup x_n$. Let $S$ be the set of cluster points of $(x_n)$.  By Thm. \ref{lb68}, $A=\min S,B=\max S $. So $A=B$ iff $S$ has only one element. This is equivalent to the convergence of $(x_n)$ in $\ovl\Rbb$ due to Thm. \ref{lb74} (since $\ovl\Rbb$ is sequentially compact by Bolzano-Weierstrass.)

2. If $(x_n)$ converges, then $A=B$ by part 1. And $(x_n)$ is bounded due to Prop. \ref{lb24}. Conversely, if $A=B$ and if $(x_n)$ is bounded, say $\alpha\leq x_n\leq \beta$ for all $n$ where $-\infty<\alpha<\beta<+\infty$. Then $\alpha\leq A\leq B\leq\beta$. So $A,B\in\Rbb$. By part 1, $(x_n)$ converges to $A\in\Rbb$.
\end{proof}



\subsection{Outlook: sequentially compact function spaces}


In Sec. \ref{lb55}, we mentioned that metric spaces and (more generally) point-set topology were introduced by mathematicians in order to study (typically infinite dimensional) function spaces using the intuition from $\Rbb^N$.  Now we have learned a couple of important results about sequentially compact spaces. But we have not met any example arising from function spaces. So let me show one example to the curious readers: The product space $[0,1]^{\Zbb_+}$, equipped with the metric defined in Pb. \ref{lb78}, is sequentially compact. We will prove this result at the end of this chapter. (Indeed, we will prove a slightly more general version. See  Thm. \ref{lb89}.) This is a famous result, not only because it has many important applications (some of which will be hinted at in this section), but also because its proof uses the clever  ``diagonal method".  

Moreover, we will later prove an even more surprising fact: every sequentially compact metric space is homeomorphic to a closed subset of $[0,1]^{\Zbb_+}$. Thus, all sequentially compact metric spaces can be constructed explicitly, in some sense.

The readers may still complain that functions on $\Zbb_+$ are very different from those we often see and use in analysis and (especially) in differential equations: We are ultimately interested in functions on $\Rbb$ or on $[a,b]$, but not on countable sets. This is correct. But $[0,1]^{\Zbb_+}$ (and its closed subsets) are in fact very helpful for the study of spaces of functions on $\Rbb$ and on $[a,b]$. In this course, we shall learn two major examples that the sequential compactness of $[0,1]^{\Zbb_+}$ helps with:
\begin{enumerate}
\item $A=\Qbb\cap[a,b]$ is a countable dense subset of $[a,b]$. Thus, if we let $C([a,b])$ denote the set of continuous $\Rbb$-functions on $[a,b]$, then the restriction map $f\in C([a,b])\mapsto f|_A\in\Rbb^A$ is injective. In many applications, we are interested in a subset $\mc X\subset C([a,b])$ of uniformly bounded functions, say all $f\in\mc X$ take values in $[-1,1]$. Then we have an injective map
\begin{align*}
\Phi:\mc X\rightarrow [-1,1]^A\qquad f\mapsto f|_A
\end{align*}
If $\mc X$ satisfies a condition called ``\textbf{equicontinuous}", then  a sequence $f_n$ in $\mc X$ converges \emph{uniformly} to $f\in\mc X$ iff $f_n|_A$ converges \emph{pointwisely} to $f|_A$. Thus, the sequential compactness of $[-1,1]^A$ under pointwise convergence topology implies the sequential compactness of $\mc X$ under uniform convergence topology. This remarkable sequential compactness result on $\mc X$ is called \textbf{Arzel\`a-Ascoli theorem}, and will be used to prove the fundamental Peano existence theorem in ordinary differential equations. We also see that the fact that $[a,b]$ has a countable dense subset $A$ plays a crucial role. This property of metric spaces is called ``\textbf{separable}" and will be studied later.

\item \textbf{Fourier series} are powerful for the study of partial differential equations. A continuous function $f:[-\pi,\pi]\rightarrow\Cbb$ satisfying $f(-\pi)=f(\pi)$ has Fourier series expansion $f(x)=\sum_{n\in\Zbb}a_n e^{\im nx}$ where $a_n\in\Cbb$. However, for the sake of studying differential equations, one needs to consider series $\sum_{n\in\Zbb}a_n e^{\im nx}$ converging to a function much worse than a continuous function. For example, in the study of integral equations (which are closely related to certain partial differential equations), Hilbert and Schmidt discovered that one has to consider all $f(x)=\sum_{n\in\Zbb}a_n e^{\im nx}$ satisfying $\sum_n |a_n|^2\leq 1$. Therefore, one lets $\ovl B=\{z\in\Cbb:|z|\leq 1\}$ and considers $\wht f:n\in\Zbb\mapsto a_n\in\Cbb$ as an element of $\ovl B^\Zbb$. The sequential compactness of $\ovl B^\Zbb$ helps one find the $\wht f$ such that the corresponding $f(x)=\sum_n \wht f(n)\cdot e^{\im nx}$ is a desired solution of the integral equation. 
\end{enumerate}




\subsection{Complete metric spaces and Banach spaces}

In this section, we let $\Fbb\in\{\Rbb,\Cbb\}$, and assume that all vector spaces are over $\Fbb$.


\subsubsection{Cauchy sequences and complete metric spaces}

\begin{df}
A sequence $(x_n)$ in a metric space $X$ is called a \textbf{Cauchy sequence}, \index{00@Cauchy sequence}if:
\begin{itemize}
\item For every $\eps>0$  there exists $N\in\Zbb_+$ such that for all $m,n\geq N$ we have $d(x_m,x_n)<\eps$.
\end{itemize}
\end{df}

Here, ``$\eps>0$" can mean either ``$\eps\in\Rbb_{>0}$" or ``$\eps\in\Qbb_{>0}$". The choice of this meaning does not affect the definition. The above definition can be abbreviated to ``for every $\eps>0$, we have $d(x_m,x_n)<\eps$ for sufficiently large $m,n$". 

\begin{rem}
It is an easy consequence of triangle inequality that $(x_n)$ is a Cauchy sequence iff
\begin{itemize}
\item For every $\eps>0$ there exists $N\in\Zbb_+$ such that for all $n\geq N$ we have $d(x_n,x_N)<\eps$.
\end{itemize}
Also, it is clear that every Cauchy sequence is bounded.
\end{rem}


\begin{pp}\label{lb83}
Every convergent sequence in a metric space $X$ is a Cauchy sequence.
\end{pp}

\begin{proof}
Assume $(x_n)$ converges to $x$ in $X$. Then for every $\eps>0$ there is $N\in\Zbb_+$ such that $d(x,x_n)<\eps/2$ for all $n\geq N$. Since this is true for every $m\geq N$, we have $d(x_m,x_n)\leq d(x,x_n)+d(x,x_m)<\eps/2+\eps/2=\eps$.
\end{proof}


\begin{df}
A metric space $X$ is called \textbf{complete} \index{00@Complete metric space} if every Cauchy sequence in $X$ converges.
\end{df}




We have many examples of complete metric spaces:

\begin{thm}\label{lb79}
If $(x_n)$ is a Cauchy sequence in a metric space $X$ with at least one cluster point, then $(x_n)$ converges in $X$. Consequently, every sequentially compact metric space is complete.
\end{thm}

\begin{proof}
Let $(x_n)$ be a Cauchy sequence in $X$ with subsequence $(x_{n_k})$ converging to $x\in X$. Let us show that $x_n\rightarrow x$. 

Since $(x_n)$ is Cauchy, for every $\eps>0$ there is $N\in\Zbb_+$ such that $d(x_n,x_m)<\eps/2$ for all $m,n\geq \Zbb_+$. Since $x_{n_k}\rightarrow x$, there is $k\geq N$ such that $d(x_{n_k},x)<\eps/2$. Since $n_k$ is strictly increasing over $k$, we have $n_k\geq k$. So $n_k\geq N$. So we can let $m=n_k$. This gives $d(x_n,x_{n_k})<\eps/2$. Therefore $d(x_n,x)\leq d(x_n,x_{n_k})+d(x_{n_k},x)<\eps$ for all $n\geq N$.
\end{proof}

\begin{eg}\label{lb84}
Let  $X=[a_1,b_1]\times\cdots\times [a_N,b_N]$  where each $[a_i,b_i]$ is a closed interval in $\Rbb$, then $X$ is  sequentially compact by Bolzano-Weierstrass. Thus, by Thm. \ref{lb79}. $X$ is complete.
\end{eg}


\begin{co}\label{lb80}
$\Rbb^N$ and $\Cbb^N$ are complete (under the Euclidean metrics).
\end{co}

\begin{proof}
Since $\Cbb^N$ is isometrically isomorphic to $\Rbb^{2N}$, it suffices to prove that $\Rbb^N$ is complete. Choose a Cauchy sequence $(x_n)$ in $\Rbb^N$. Since $(x_n)$ is bounded, $(x_n)$ is contained inside $X=I_1\times\cdots\times I_N$ where each $I_i=[a,b]$ is in $\Rbb$. By Exp. \ref{lb84}, $X$ is complete. So $(x_n)$ converges to some $x\in X$.
\end{proof}





\begin{df}
We say that subset $A$ of a metric space $X$ is \textbf{closed} \index{00@Closed subsets} if the following condition is true: For every sequence $(x_n)$ in $A$ converging to a point $x\in X$, we have $x\in A$.
\end{df}


Thus, the word ``closed" here means ``closed under taking limits".


\begin{pp}\label{lb86}
Let $A$ be a metric subspace of a complete metric space $Y$. Recall  that the metric of $A$ inherits from that of $Y$ (cf. Def. \ref{lb43}). Then $A$ is a closed subset of $Y$ iff $A$ is complete.
\end{pp}


\begin{proof}
First, assume that $A$ is closed. Let $(x_n)$ be a Cauchy sequence in $A$. Then it is a Cauchy sequence in $Y$. So $x_n\rightarrow x\in X$ because $Y$ is complete. So $x\in A$ by the definition of closedness.

Next, we assume that $A$ is complete. Choose a sequence $(x_n)$ in $A$ converging to a point $x\in X$. By Prop. \ref{lb83}, $(x_n)$ is a Cauchy sequence in $X$, and hence a Cauchy sequence in $A$. Since $A$ is complete, there is $a\in A$ such that $x_n\rightarrow a$. So we must have $x=a$ because any sequence has at most one limit in a metric space. This proves $x\in A$. So $A$ is closed.
\end{proof}


\begin{eg}
Let $-\infty<a<b<+\infty$. Then $(a,b)$ is not complete (under the Euclidean metric), because $(a,b)$ is not closed in the complete metric space $\Rbb$. (For sufficiently large $n$, $b-1/n$ is in $(a,b)$, but $\lim_{n\rightarrow\infty} (b-1/n)=b$ is not in $b$.) 
\end{eg}

\begin{eg}
By Prop. \ref{lb2}, for each $x\in\Rbb\setminus\Qbb$, we can choose an increasing sequence in $\Qbb$ converging to $x$. So $\Qbb$ is not closed in $\Rbb$. So $\Qbb$ is not complete under the Euclidean topology.
\end{eg}


\begin{exe}
Let $d,\delta$ be two equivalent metrics on a set $X$. Show that a sequence $(x_n)$ in $X$ is Cauchy under $d$ iff $(x_n)$ is Cauchy under $\delta$. 

Note that if, instead of assuming $d,\delta$ are equivalent, we only assume that $d,\delta$ are topologically equivalent. Then the above conclusion is not necessarily true:
\end{exe}


\begin{exe}
Find a non-complete metric $\delta$ on $\Rbb$ topologically equivalent to the Euclidean metric.
\end{exe}




\subsubsection{Normed vector spaces and Banach spaces}



A major application of complete metric spaces is to show that many series converge without knowing to what exact values these series converge. A typical example is the convergence of $\sum_{n\in\Zbb_+}\sin(\sqrt 2n)/n^2$ in $\Rbb$. We are also interested in the convergence of series in functions spaces, for instance: the uniform convergence of $f(x)=\sum_{n\in\Zbb_+}\sin(\sqrt 2nx^3)/n^2$ on $\Rbb$; a suitable convergence of the Fourier series $\sum_{n\in\Zbb}a_ne^{\im n x}$. But we cannot take sum in a general metric space since it has no vector space structures. Therefore, we need a notion which combines complete metric spaces with vector spaces. Banach spaces are such a notion. 



\begin{df}
Let $V$ be a vector space over $\Fbb$ with zero vector $0_V$. A function $\lVert\cdot\lVert:V\rightarrow\Rbb_{\geq 0}$ is called a \textbf{norm} \index{00@Norm} if for every $u,v\in V$ and $\lambda\in\Fbb$, the following hold:
\begin{itemize}
\item (Subadditivity) $\lVert u+v\lVert\leq \lVert u\lVert+\lVert v\lVert$. \index{00@Subadditivity}
\item (Absolute homogeneity) $\lVert\lambda v\lVert=|\lambda|\cdot \lVert v\lVert$. In particular, (by taking $\lambda=0$) we have $\lVert 0_V\lVert=0$.
\item If $\lVert v\lVert=0$ then $v=0_V$.
\end{itemize}
We call $(V,\lVert\cdot\lVert)$ (often abbreviated to $V$) a \textbf{normed vector space}. \index{00@Normed vector space}
\end{df}

\begin{rem}
Let $V$ be a vector space. If $V$ is a normed vector space, then
\begin{align}
d(u,v)=\lVert u-v\lVert  \label{eq21}
\end{align} 
clearly defines a metric. (Note that triangle inequality follows from subadditivity.) Unless otherwise stated, we always assume that the metric of a normed vector space is defined by \eqref{eq21}.
\end{rem}




\begin{df}
Let $V$ be a normed vector space. We say that $V$ is a \textbf{Banach space} \index{00@Banach space} if $V$ is a complete metric space where the metric is the canonical one \eqref{eq21}.
\end{df}




\begin{eg}
We always assume that the norm on $\Fbb^N$ is the \textbf{Euclidean norm} \index{00@Euclidean norm}
\begin{align}
\lVert (a_1,\dots,a_N)\lVert=\sqrt{|a_1|^2+\cdots+|a_N|^2}
\end{align}
The canonical metric it gives is the Euclidean metric. Thus, by Cor. \ref{lb80}, $\Fbb^N$ is a Banach space.
\end{eg}



If $(\lambda_n)$ is a sequence in $\Fbb$ converging to $\lambda$, and if $(x_n)$ is a sequence in $\Fbb^N$ converging to $x$, then one can show that $\lambda_nx_n$ converges to $\lambda x$ by checking that each component of $\lambda_nx_n$ converges to the corresponding component of $\lambda x$. This is due to Prop. \ref{lb38}. However, if $(x_n)$ is in general a sequence in a normed vector space, this method fails. So we need a different argument:

\begin{pp}\label{lb82}
Let $V$ be a normed vector space. The following maps are continuous
\begin{gather*}
+: V\times V\rightarrow V\qquad (u,v)\mapsto u+v\\
-: V\times V\rightarrow V\qquad (u,v)\mapsto u-v\\
\times_\Fbb: \Fbb\times V\rightarrow V\qquad (\lambda,v)\mapsto \lambda v\\
\lVert\cdot\lVert:V\rightarrow\Rbb_{\geq 0}\qquad v\mapsto \lVert v\lVert
\end{gather*}
\end{pp}

We didn't mention the continuity of the division map $(\lambda,v)\in\Fbb^\times\times V\mapsto\lambda^{-1}v$ since it follows from that of $\times_\Fbb$ and of the inversion map $\lambda\mapsto\lambda^{-1}$ by Exp. \ref{lb35}.

\begin{proof}
One can check that the addition map, the subtraction map, and the last map $\lVert\cdot\lVert$ are Lipschitz continuous. 

Define metric $d((\lambda,v),(\lambda',v'))=\max\{|\lambda-\lambda'|,\lVert v-v'\lVert \}$ on $\Fbb\times V$. Then $\Fbb\times V$ is covered by open balls of the form $B(0,r)=\{(\lambda,v)\in\Fbb\times V:|\lambda|<r,\lVert v\lVert<r\}$. Similar to the argument in \eqref{eq22}, one uses subadditivity (i.e. triangle inequality) and absolute homogeneity to show that $\times_\Fbb$ has Lipschitz constant $2r$ on $B(0,r)$. So $\times_\Fbb$ is continuous by Lem. \ref{lb30} and Lem. \ref{lb34}.
\end{proof}




\subsection{The Banach spaces $l^\infty(X,V)$ and $C(X,V)$}


In this section, we let $\Fbb\in\{\Rbb,\Cbb\}$ and assume that the vector spaces $V$ are over $\Fbb$. As the title suggests, in this section we shall introduce two important examples of Banach spaces: the space of uniformly bounded functions $l^\infty(X,V)$ and its  subspace of continuous functions $C(X,V)$ (when $X$ is a sequentially compact metric space).  In order for these two spaces to be Banach spaces, we must assume that $V$ is also Banach. 

In application, the main examples are $V=\Rbb,\Cbb,\Rbb^N,\Cbb^N$. Indeed, $C([a,b],\Rbb^N)$ is one the main examples of function spaces considered by Fr\'echet when he defined metric spaces. Therefore, the readers can assume that $V$ is one of such spaces if they want to make life easier. Just keep in mind that we sometimes also consider the case where $V$ itself is a function space.

\begin{df}
Let $X$ be a vector space and let $V$ be a vector space. The set $V^X$ \index{VX@$V^X$ as a vector space} is a vector space if we define for each $f,g\in V^X$ and $\lambda\in\Fbb$:
\begin{gather*}
f+g:X\rightarrow V\qquad (f+g)(x)=f(x)+g(x)\\
\lambda f:X\rightarrow V\qquad (\lambda f)(x)=\lambda f(x)
\end{gather*}
We also define the \textbf{absolute value function}\index{00@Absolute function $\lvert f\lvert$} \index{f@$\lvert f\lvert$}
\begin{align}
|f|:X\rightarrow\Rbb_{\geq 0}\qquad x\in X\mapsto \lVert f(x)\lVert
\end{align}
\end{df}



\begin{df}
Let $X$ be a set and let $V$ be a normed vector space. For each $f\in V^X$, define the \index{l@$\lVert\cdot\lVert_{l^\infty}=\lVert\cdot\lVert_\infty$} \pmb{$l^\infty$}\textbf{-norm}
\begin{align}
\lVert f\lVert_{l^\infty}\equiv \lVert f\lVert_\infty=\sup_{x\in X}\lVert f(x)\lVert
\end{align}
where $\lVert f(x)\lVert$ is defined by the norm of $V$. Define the \pmb{$l^\infty$}\textbf{-space} \index{l@$l^\infty(X,V)$} 
\begin{align}
l^\infty(X,V)=\{f\in V^X:\lVert f\lVert_\infty<+\infty\}
\end{align}
which is a vector subspace of $V^X$. Then $l^\infty(X,V)$ is a normed vector space under the $l^\infty$-norm.
\end{df}





\begin{exe}
Prove that for every $f,g\in V^X$ and $\lambda\in\Fbb$ we have
\begin{gather}\label{eq23}
\begin{gathered}
\lVert f+g\lVert_\infty\leq \lVert f\lVert_\infty+\lVert g\lVert_\infty\\
\lVert \lambda f\lVert_\infty=|\lambda|\cdot \lVert f\lVert_\infty
\end{gathered}
\end{gather}
(Note that clearly we have that $\lVert f\lVert_\infty=0$ implies $f=0$.) Here, we understand $0\cdot (+\infty)=0$. Use these relations to verify that $l^\infty(X,V)$ is a linear subspace of $V^X$ (i.e. it is closed under addition and scalar multiplication) and that $\lVert\cdot\lVert_\infty$ is a norm on $l^\infty(X,V)$.  \hfill\qedsymbol
\end{exe}

\begin{df}
Let $V$ be a normed vector space. We say that a sequence $(f_n)$ in $V^X$ \textbf{converges uniformly} \index{00@Uniform convergence} to $f\in V^X$ if $\lim_{n\rightarrow\infty}\lVert f-f_n\lVert_\infty=0$. In this case, we write ${f_n}\rightrightarrows f$. \index{fnf@$f_n\rightrightarrows f$}

We say that $(f_n)$ \textbf{converges pointwisely} \index{00@Pointwise convergence} to $f\in V^X$ if for every $x\in X$ we have $\lim_{n\rightarrow\infty} f_n(x)=f(x)$, i.e. $\lim_{n\rightarrow\infty} \lVert f_n(x)-f(x)\lVert=0$. \hfill\qedsymbol
\end{df}


In more detail, the uniform convergence of $f_n$ to $f$ means that ``for every $\eps>0$ there is $N\in\Zbb_+$ such that for all $n\geq N$ and  \emph{for all $x\in X$}, we have $\lVert f_n(x)-f(x)\lVert<\eps$". If we place the words ``for all $x\in X$" at the very beginning of the sentence, we get pointwise convergence.


Uniform convergence implies pointwise convergence, because if $\lVert f-f_n\lVert_\infty\rightarrow 0$, then clearly $\lVert f_n(x)-f(x)\lVert\rightarrow 0$ for each $x\in X$. 



\begin{eg}
Let $f_n:(0,1)\rightarrow\Rbb$ be $f_n(x)=x^n$. Then $f_n$ converges pointwisely to $0$. But $\sup_{x\in(0,1)}|x^n-0|=1$ does not converge to $0$. So $f_n$ does not converge uniformly to $0$.
\end{eg}



\begin{rem}
The uniform convergence of sequences in $l^\infty(X,V)$ is induced by the $l^\infty$-norm, and hence is induced by the metric $d(f,g)=\lVert f-g\lVert_\infty$. However, this formula cannot be extended to a metric on $V^X$, since for arbitrary $f,g\in V^X$, $\lVert f-g\lVert_\infty$ is possibly $+\infty$. 



In fact, it is true that the uniform convergence of sequences in $V^X$ is induced by a metric, see Pb. \ref{lb81}. When $X$ is countable, we have seen in Pb. \ref{lb78} that the pointwise convergence in $V^X$ is also given by a metric. \hfill\qedsymbol
\end{rem}












\begin{thm}\label{lb85}
Let $X$ be a set, and let $V$ be an $\Fbb$-Banach space. Then $l^\infty(X,V)$ is an $\Fbb$-Banach space.
\end{thm}


\begin{proof}
Let $(f_n)$ be a Cauchy sequence in $l^\infty(X,V)$. Then for every $\eps>0$ there is $N\in\Zbb_+$ such that for all $m,n\geq N$ we have that $\sup_{x\in X}\lVert f_n(x)-f_m(x)\lVert <\eps$, and hence $\lVert f_n(x)-f_m(x)\lVert <\eps$ for each $x\in X$. This shows that for each $x\in X$, $(f_n(x))$ is a Cauchy sequence in $V$, which converges to some element $f(x)\in V$ because $V$ is complete.

We come back to the statement that for each $\eps>0$, there exists $N\in\Zbb_+$ such that for all $n\geq N$ and all $x$,
\begin{align*}
\lVert f_n(x)-f_m(x)\lVert <\eps  
\end{align*}
for every $m\geq N$. Let $m\rightarrow\infty$. Then by the continuity of subtraction and taking norm (cf. Prop. \ref{lb82}.), we obtain $\lVert f_n(x)-f(x)\lVert\leq \eps$ for all $n\geq N$ and $x\in X$. In other words, $\lVert f_n-f\lVert_\infty\leq\eps$ for all $n\geq N$. In particular, $\lVert f\lVert_\infty\leq\lVert f_N\lVert_\infty +\lVert f_N-f\lVert_\infty<+\infty$ by \eqref{eq23}. This proves $f\in l^\infty(X,V)$ and $f_n\rightrightarrows f$.
\end{proof}


Mathematicians used to believe that ``if a sequence of continuous functions $f_n:[0,1]\rightarrow\Rbb$ converges pointwisely to a function $f:[0,1]\rightarrow\Rbb$, then $f$ is continuous". Cauchy, one of the main figures in 19th century working on putting analysis on a rigorous ground, has given a problematic proof of this wrong statement. Counterexamples were later found in the study of Fourier series: Let $f:\Rbb\rightarrow\Rbb$ be a function with period $2\pi$ such that $f(x)=x$ when $-\pi<x<\pi$, and $f(x)=0$ when $x=\pm \pi$. Then the Fourier series  of this noncontinuous function $f$ converges pointwisely to $f$, yet the partial sums of this series are clearly continuous functions. Later, it was realized that uniform convergence is needed to show the continuity of the limit function. This was the first time the importance of uniform convergence was realized.

\begin{df}
Let $X,Y$ be  metric spaces (or more generally, topological spaces to be defined later). Then $C(X,Y)$ \index{CXY@$C(X,Y)$, the set of continuous functions $X\rightarrow Y$. See Conv. \ref{lb85} also} denotes the set of continuous functions from $X$ to $Y$. 
\end{df}

\begin{thm}\label{lb87}
Let $X$ be a sequentially compact metric space. Let $V$ be a Banach space. Then $C(X,V)$ is a closed linear subspace of $l^\infty(X,V)$.
\end{thm}



\begin{proof}
For any $f\in C(X,V)$, the absolute value function $|f|:x\in X\mapsto\lVert f(x)\lVert$ is continuous. Thus by the sequential compactness of $X$ and Lem. \ref{lb56}, $|f|$ is bounded on $X$. This proves that $\lVert f\lVert_\infty<+\infty$. Thus $C(X,V)$ is a subset of $l^\infty(X,V)$. Using Prop. \ref{lb82}, one checks easily that $C(X,V)$ is a linear subspace of $l^\infty(X,V)$.

It remains to prove that $C(X,V)$ is closed in $l^\infty(X,V)$. Choose a sequence $(f_n)$ in $C(X,V)$ converging in $l^\infty(X,V)$ to $f$. Namely, $f_n\rightrightarrows f$. We want to prove that $f$ is continuous. We check that $f$ satisfies Def. \ref{lb31}-(2'). (One can also use Def. \ref{lb31}-(1). The proofs using these two definitions are not substantially different.)

Fix $p\in X$. Choose any $\eps>0$. Since $f_n\rightrightarrows f$, there exists $N\in\Zbb_+$ such that for all $n\geq N$ and we have $\lVert f-f_n\lVert_\infty<\eps$. Since $f_N$ is continuous, there exists $r>0$ such that for each $x\in B_X(p,r)$ we have $\lVert f_N(x)-f_N(p)\Vert<\eps$. Thus, for each $x\in B_X(p,r)$ we have
\begin{align*}
\lVert f(x)-f(p)\lVert\leq \lVert f(x)-f_N(x)\lVert +\lVert f_N(x)-f_N(p)\lVert+\lVert f_N(p)-f(p)\lVert<3\eps
\end{align*}
This finishes the proof.
\end{proof}

We emphasize that in the above proof, the sequential compactness of $X$ is used only to show that $C(X,V)$ is a subset of $l^\infty(X,V)$.



\begin{cv}\label{lb88}
Unless otherwise stated, if $X$ is sequentially compact metric space (or more generally, a compact Hausdorff space to be defined latter), and if $V$ is a normed vector space, the norm on $C(X,V)$ is chosen to be the $l^\infty$-norm.
\end{cv}


\begin{co}
Let $X$ be a sequentially compact metric space. Let $V$ be a Banach space. Then  $C(X,V)$ is a Banach space (under the $l^\infty$-norm).
\end{co}

\begin{proof}
This follows immediately from Prop. \ref{lb86}, Thm. \ref{lb87}, and the fact that $l^\infty(X,V)$ is complete (Thm. \ref{lb85}).
\end{proof}






\subsection{Problems and supplementary material}



\begin{prob}\label{lb64}
Let $(x_n)$ be a sequence in a metric space $X$. Let $x\in X$. Prove that the following are equivalent.
\begin{itemize}
\item[(1)] $x$ is a cluster point of $(x_n)$, i.e., the limit of a convergent subsequence of $(x_n)$.
\item[(2)] For each $\eps>0$ and each $N\in\Zbb_+$, there exists $n\geq N$ such that $d(x_n,x)<\eps$.
\end{itemize}
\end{prob}


\begin{rem}
Condition (2) is often abbreviated to ``for each $\eps>0$, the sequence $(x_n)$ is frequently in $B(x,\eps)$". In general, we say ``$(x_n)$ \textbf{frequently} satisfies P" if for each $N\in\Zbb_+$ there is $n\geq N$ such that $x_n$ satisfies P. We say that ``$(x_n)$ \textbf{eventually} satisfies P" if there exists $N\in\Zbb_+$ such that for every $n\geq N$, $x_n$ satisfies P. \index{00@Eventially} \index{00@Frequently}  

Thus ``$(x_n)$ eventually satisfies P" means the same as ``all but finitely many $x_n$ satisfies P". Its negation is ``$(x_n)$ frequently satisfies $\neg$P".   \hfill\qedsymbol
\end{rem}

\begin{rem}
Condition (2) of Pb. \ref{lb64} is sometimes easier to use than (1). For example: compared to the original definition of cluster points, it is much easier to find an explicit negation of (2).
\end{rem}



\begin{prob}\label{lb70}
Use Pb. \ref{lb64}-(2) to prove that if $(x_n)$ is a sequence in $\ovl\Rbb$, then $\dps\limsup_{n\rightarrow\infty} x_n$ is a cluster point of $(x_n)$.
\end{prob}

\begin{rem}
You will notice that your proof of Pb. \ref{lb70} is slightly simpler than the proof we gave for Thm. \ref{lb68}. This is because our construction of subsequence as in \eqref{eq17} has been incorporated into your proof of (2)$\Rightarrow$(1) in Pb. \ref{lb64}.
\end{rem}

\begin{thm}[\textbf{Tychonoff theorem, countable version}]\index{00@Tychonoff theorem, countable version}  \label{lb89}
Let $(X_n)_{n\in\Zbb_+}$ be a sequence of metric spaces where each $X_n$ is sequentially compact. Then the product space $\dps S=\prod_{n\in\Zbb_+} X_n$ is sequentially compact under the metric defined  as in Pb. \ref{lb78}.
\end{thm}

The method of choosing subsequence in the following proof is the reknowned \textbf{diagonal method}. \index{00@Diagonal method}

\begin{proof}
Let $(x_m)_{m\in\Zbb_+}$ be a sequence in $S$. Since $(x_m(1))_{m\in\Zbb_+}$ is a sequence in the sequentially compact space $X_1$, $(x_m)_{m\in\Zbb_+}$ has a subsequence $x_{1,1},x_{1,2},x_{1,3}\dots$ whose value at $n=1$ converges in $X_1$. Since $X_2$ is sequentially compact, we can choose a subsequence $x_{2,1},x_{2,2},x_{2,3},\dots$ of the previous subsequence such that its values at $n=2$ converge in $X_2$. Then pick a subsequence from the previous one whose values at $3$ converge in $X_3$. 

By repeating this process, we get an $\infty\times\infty$ matrix $(x_{i,j})_{i,j\in\Zbb_+}$:
\begin{equation}
\begin{tikzcd}[sep=0cm]
{x_{1,1}} & {x_{1,2}} & {x_{1,3}} & \cdots \\
{x_{2,1}} & {x_{2,2}} & {x_{2,3}} & \cdots \\
{x_{3,1}} & {x_{3,2}} & {x_{3,3}} & \cdots \\
\vdots    & \vdots    & \vdots    & \ddots
\end{tikzcd}
\end{equation}
such that the following hold:
\begin{itemize}
\item The $1$-st line is a subsequence of the original sequence $(x_m)_{m\in\Zbb_+}$.
\item The $(i+1)$-th line is a subsequence of the $i$-th line.
\item For each $n$, $\lim_{j\rightarrow\infty} x_{n,j}(n)$ converges in $X_n$.
\end{itemize}
Then the diagonal line $(x_{i,i})_{i\in\Zbb_+}$ is a subsequence of the original sequence $(x_m)_{m\in\Zbb_+}$. Moreover, for each $n$, $(x_{i,i})_{i\geq n}$ is a subsequence of the $n$-th line, whose value at $n$ therefore converges in $X_n$. Thus $\lim_{i\rightarrow\infty} x_{i,i}(n)$ converges in $X_n$. Thus, by Pb. \ref{lb78}, $(x_{i,i})_{i\in\Zbb_+}$ converges under any metric inducing the product topology.
\end{proof}




\begin{prob}\label{lb81}
Let $V$ be a normed vector space. For every $f,g\in V^X$ define
\begin{align}
d(f,g)=\min\{1,\lVert f-g\lVert_\infty \}
\end{align}
Show that $d$ defines a metric on $V^X$. Show that for every sequence $(f_n)$ in $V^X$ and every $V^X$, we have $f_n\rightarrow g$ under the metric $d$ iff $f_n\rightrightarrows g$.
\end{prob}














\newpage

\printindex	






	\begin{thebibliography}{999999}
		\footnotesize	

\bibitem[Axl]{Axl}
Axler, S. (2015). Linear algebra done right. 3rd ed.

\bibitem[Mun]{Mun}
Munkres, J. (2000). Topology. Second Edition.



\bibitem[Rud-P]{Rud-P}
Rudin, W. (1976). Principles of Mathematical Analysis. 3rd ed.


		
\end{thebibliography}

\noindent {\small \sc Yau Mathematical Sciences Center, Tsinghua University, Beijing, China.}

\noindent {\textit{E-mail}}: binguimath@gmail.com\qquad bingui@tsinghua.edu.cn
\end{document}









