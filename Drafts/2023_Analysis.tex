% !TeX spellcheck = en_US
% !TEX program = pdflatex
\documentclass[12pt,b5paper,notitlepage]{article}
\usepackage[b5paper, margin={0.5in,0.65in}]{geometry}
%\usepackage{fullpage}
\usepackage{amsmath,amscd,amssymb,amsthm,mathrsfs,amsfonts,layout,indentfirst,graphicx,caption,mathabx, stmaryrd,appendix,calc,imakeidx,upgreek} % mathabx for \wtidecheck
%\usepackage{ulem} %wave underline
\usepackage[dvipsnames]{xcolor}
\usepackage{palatino}  %template
\usepackage{slashed} % Dirac operator
\usepackage{mathrsfs} % Enable using \mathscr
%\usepackage{eufrak}  another template/font
\usepackage{extarrows} % long equal sign, \xlongequal{blablabla}
\usepackage{enumitem} % enumerate label change e.g. [label=(\alph*)]  shows (a) (b) 


\usepackage{csquotes} % \begin{displayquote}   \begin{displaycquote}

%\pmb  mandatory math bold 

\usepackage{fancyhdr} % date in footer

\usepackage{soul}  %\ul underline break line automatically

\usepackage{relsize} % use \mathlarger \larger \text{\larger[2]$...$} to enlarge the size of math symbols

\usepackage{verbatim}  % comment environment

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tcolorbox}
\tcbuselibrary{theorems}
% box around equations   \tcboxmath
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% circled colon and thick colon \hcolondel and \colondel

\usepackage{pdfrender}

\newcommand*{\hollowcolon}{%
	\textpdfrender{
		TextRenderingMode=Stroke,
		LineWidth=.1bp,
	}{:}%
}

\newcommand{\hcolondel}[1]{%
	\mathopen{\hollowcolon}#1\mathclose{\hollowcolon}%
}
\newcommand{\colondel}[1]{%
	\mathopen{:}#1\mathclose{:}%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\usepackage{tikz}
\usetikzlibrary{fadings}
\usetikzlibrary{patterns}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes}

\usepackage{tikz-cd}
\usepackage[nottoc]{tocbibind}   % Add  reference to ToC


\makeindex


% The following set up the line spaces between items in \thebibliography
\usepackage{lipsum}  
\let\OLDthebibliography\thebibliography
\renewcommand\thebibliography[1]{
	\OLDthebibliography{#1}
	\setlength{\parskip}{0pt}
	\setlength{\itemsep}{2pt} 
}


\allowdisplaybreaks  %allow aligns to break between pages
\usepackage{latexsym}
\usepackage{chngcntr}
\usepackage[colorlinks,linkcolor=blue,anchorcolor=blue, linktocpage,
%pagebackref
]{hyperref}
\hypersetup{ urlcolor=cyan,
	citecolor=[rgb]{0,0.5,0}}


\setcounter{tocdepth}{2}	 %hide subsections in the content


\counterwithin{figure}{section}

\pagestyle{plain}

\captionsetup[figure]
{
	labelsep=none	
}













\theoremstyle{definition}
\newtheorem{df}{Definition}[section]
\newtheorem{eg}[df]{Example}
\newtheorem{exe}[df]{Exercise}
\newtheorem{rem}[df]{Remark}
\newtheorem{obs}[df]{Observation}
\newtheorem{ass}[df]{Assumption}
\newtheorem{cv}[df]{Convention}
\newtheorem{prin}[df]{Principle}
\newtheorem{nota}[df]{Notation}
\newtheorem*{axiom}{Axiom}
\newtheorem{coa}[df]{Theorem}
\newtheorem{srem}[df]{$\star$ Remark}
\newtheorem{seg}[df]{$\star$ Example}
\newtheorem{sexe}[df]{$\star$ Exercise}


\newtheorem{prob}{\color{red}Problem}[section]
%\renewcommand*{\theprob}{{\color{red}\arabic{section}.\arabic{prob}}}
\newtheorem{sprob}[prob]{\color{red}$\star$ Problem}
%\renewcommand*{\thesprob}{{\color{red}\arabic{section}.\arabic{sprob}}}
% \newtheorem{ssprob}[prob]{$\star\star$ Problem}



\theoremstyle{plain}
\newtheorem{thm}[df]{Theorem}
\newtheorem{ccl}[df]{Conclusion}
\newtheorem{thd}[df]{Theorem-Definition}
\newtheorem{pp}[df]{Proposition}
\newtheorem{co}[df]{Corollary}
\newtheorem{lm}[df]{Lemma}


\newtheorem{cond}{Condition}
\newtheorem{Mthm}{Main Theorem}
\renewcommand{\thecond}{\Alph{cond}} % "letter-numbered" theorems
\renewcommand{\theMthm}{\Alph{Mthm}} % "letter-numbered" theorems


%\substack   multiple lines under sum
%\underset{b}{a}   b is under a


% Remind: \overline{L_0}



\usepackage{calligra}
\DeclareMathOperator{\shom}{\mathscr{H}\text{\kern -3pt {\calligra\large om}}\,}
\DeclareMathOperator{\sext}{\mathscr{E}\text{\kern -3pt {\calligra\large xt}}\,}
\DeclareMathOperator{\Rel}{\mathscr{R}\text{\kern -3pt {\calligra\large el}~}\,}
\DeclareMathOperator{\sann}{\mathscr{A}\text{\kern -3pt {\calligra\large nn}}\,}
\DeclareMathOperator{\send}{\mathscr{E}\text{\kern -3pt {\calligra\large nd}}\,}
\DeclareMathOperator{\stor}{\mathscr{T}\text{\kern -3pt {\calligra\large or}}\,}

\usepackage{aurical}
\DeclareMathOperator{\VVir}{\text{\Fontlukas V}\text{\kern -0pt {\Fontlukas\large ir}}\,}






\newcommand{\fk}{\mathfrak}
\newcommand{\mc}{\mathcal}
\newcommand{\wtd}{\widetilde}
\newcommand{\wht}{\widehat}
\newcommand{\wch}{\widecheck}
\newcommand{\ovl}{\overline}
\newcommand{\udl}{\underline}
\newcommand{\tr}{\mathrm{t}} %transpose
\newcommand{\Tr}{\mathrm{Tr}}
\newcommand{\End}{\mathrm{End}} %endomorphism
\newcommand{\idt}{\mathbf{1}}
\newcommand{\id}{\mathrm{id}}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\Conf}{\mathrm{Conf}}
\newcommand{\Res}{\mathrm{Res}}
\newcommand{\res}{\mathrm{res}}
\newcommand{\KZ}{\mathrm{KZ}}
\newcommand{\ev}{\mathrm{ev}}
\newcommand{\coev}{\mathrm{coev}}
\newcommand{\opp}{\mathrm{opp}}
\newcommand{\Rep}{\mathrm{Rep}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\Dom}{\scr D}
\newcommand{\loc}{\mathrm{loc}}
\newcommand{\con}{\mathrm{c}}
\newcommand{\uni}{\mathrm{u}}
\newcommand{\ssp}{\mathrm{ss}}
\newcommand{\di}{\slashed d}
\newcommand{\Diffp}{\mathrm{Diff}^+}
\newcommand{\Diff}{\mathrm{Diff}}
\newcommand{\PSU}{\mathrm{PSU}(1,1)}
\newcommand{\Vir}{\mathrm{Vir}}
\newcommand{\Witt}{\mathscr W}
\newcommand{\Span}{\mathrm{Span}}
\newcommand{\pri}{\mathrm{p}}
\newcommand{\ER}{E^1(V)_{\mathbb R}}
\newcommand{\prth}[1]{( {#1})}
\newcommand{\bk}[1]{\langle {#1}\rangle}
\newcommand{\bigbk}[1]{\big\langle {#1}\big\rangle}
\newcommand{\Bigbk}[1]{\Big\langle {#1}\Big\rangle}
\newcommand{\biggbk}[1]{\bigg\langle {#1}\bigg\rangle}
\newcommand{\Biggbk}[1]{\Bigg\langle {#1}\Bigg\rangle}
\newcommand{\GA}{\mathscr G_{\mathcal A}}
\newcommand{\vs}{\varsigma}
\newcommand{\Vect}{\mathrm{Vec}}
\newcommand{\Vectc}{\mathrm{Vec}^{\mathbb C}}
\newcommand{\scr}{\mathscr}
\newcommand{\sjs}{\subset\joinrel\subset}
\newcommand{\Jtd}{\widetilde{\mathcal J}}
\newcommand{\gk}{\mathfrak g}
\newcommand{\hk}{\mathfrak h}
\newcommand{\xk}{\mathfrak x}
\newcommand{\yk}{\mathfrak y}
\newcommand{\zk}{\mathfrak z}
\newcommand{\pk}{\mathfrak p}
\newcommand{\hr}{\mathfrak h_{\mathbb R}}
\newcommand{\Ad}{\mathrm{Ad}}
\newcommand{\DHR}{\mathrm{DHR}_{I_0}}
\newcommand{\Repi}{\mathrm{Rep}_{\wtd I_0}}
\newcommand{\im}{\mathbf{i}}
\newcommand{\Co}{\complement}
%\newcommand{\Cu}{\mathcal C^{\mathrm u}}
\newcommand{\RepV}{\mathrm{Rep}^\uni(V)}
\newcommand{\RepA}{\mathrm{Rep}(\mathcal A)}
\newcommand{\RepN}{\mathrm{Rep}(\mathcal N)}
\newcommand{\RepfA}{\mathrm{Rep}^{\mathrm f}(\mathcal A)}
\newcommand{\RepAU}{\mathrm{Rep}^\uni(A_U)}
\newcommand{\RepU}{\mathrm{Rep}^\uni(U)}
\newcommand{\RepL}{\mathrm{Rep}^{\mathrm{L}}}
\newcommand{\HomL}{\mathrm{Hom}^{\mathrm{L}}}
\newcommand{\EndL}{\mathrm{End}^{\mathrm{L}}}
\newcommand{\Bim}{\mathrm{Bim}}
\newcommand{\BimA}{\mathrm{Bim}^\uni(A)}
%\newcommand{\shom}{\scr Hom}
\newcommand{\divi}{\mathrm{div}}
\newcommand{\sgm}{\varsigma}
\newcommand{\SX}{{S_{\fk X}}}
\newcommand{\DX}{D_{\fk X}}
\newcommand{\mbb}{\mathbb}
\newcommand{\mbf}{\mathbf}
\newcommand{\bsb}{\boldsymbol}
\newcommand{\blt}{\bullet}
\newcommand{\Vbb}{\mathbb V}
\newcommand{\Ubb}{\mathbb U}
\newcommand{\Xbb}{\mathbb X}
\newcommand{\Kbb}{\mathbb K}
\newcommand{\Abb}{\mathbb A}
\newcommand{\Wbb}{\mathbb W}
\newcommand{\Mbb}{\mathbb M}
\newcommand{\Gbb}{\mathbb G}
\newcommand{\Cbb}{\mathbb C}
\newcommand{\Nbb}{\mathbb N}
\newcommand{\Zbb}{\mathbb Z}
\newcommand{\Qbb}{\mathbb Q}
\newcommand{\Pbb}{\mathbb P}
\newcommand{\Rbb}{\mathbb R}
\newcommand{\Ebb}{\mathbb E}
\newcommand{\Dbb}{\mathbb D}
\newcommand{\Hbb}{\mathbb H}
\newcommand{\cbf}{\mathbf c}
\newcommand{\Rbf}{\mathbf R}
\newcommand{\wt}{\mathrm{wt}}
\newcommand{\Lie}{\mathrm{Lie}}
\newcommand{\btl}{\blacktriangleleft}
\newcommand{\btr}{\blacktriangleright}
\newcommand{\svir}{\mathcal V\!\mathit{ir}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cok}{\mathrm{Coker}}
\newcommand{\Sbf}{\mathbf{S}}
\newcommand{\low}{\mathrm{low}}
\newcommand{\Sp}{\mathrm{Sp}}
\newcommand{\Rng}{\mathrm{Rng}}
\newcommand{\vN}{\mathrm{vN}}
\newcommand{\Ebf}{\mathbf E}
\newcommand{\Nbf}{\mathbf N}
\newcommand{\Stb}{\mathrm {Stb}}
\newcommand{\SXb}{{S_{\fk X_b}}}
\newcommand{\pr}{\mathrm {pr}}
\newcommand{\SXtd}{S_{\wtd{\fk X}}}
\newcommand{\univ}{\mathrm {univ}}
\newcommand{\vbf}{\mathbf v}
\newcommand{\ubf}{\mathbf u}
\newcommand{\wbf}{\mathbf w}
\newcommand{\CB}{\mathrm{CB}}
\newcommand{\Perm}{\mathrm{Perm}}
\newcommand{\Orb}{\mathrm{Orb}}
\newcommand{\Lss}{{L_{0,\mathrm{s}}}}
\newcommand{\Lni}{{L_{0,\mathrm{n}}}}
\newcommand{\UPSU}{\widetilde{\mathrm{PSU}}(1,1)}
\newcommand{\Sbb}{{\mathbb S}}
\newcommand{\Gc}{\mathscr G_c}
\newcommand{\Obj}{\mathrm{Obj}}
\newcommand{\bpr}{{}^\backprime}
\newcommand{\fin}{\mathrm{fin}}
\newcommand{\Ann}{\mathrm{Ann}}
\newcommand{\Real}{\mathrm{Re}}
\newcommand{\Imag}{\mathrm{Im}}
%\newcommand{\cl}{\mathrm{cl}}
\newcommand{\Ind}{\mathrm{Ind}}
\newcommand{\Supp}{\mathrm{Supp}}
\newcommand{\Specan}{\mathrm{Specan}}
\newcommand{\red}{\mathrm{red}}
\newcommand{\uph}{\upharpoonright}
\newcommand{\Mor}{\mathrm{Mor}}
\newcommand{\pre}{\mathrm{pre}}
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\Jac}{\mathrm{Jac}}
\newcommand{\emb}{\mathrm{emb}}
\newcommand{\Sg}{\mathrm{Sg}}
\newcommand{\Nzd}{\mathrm{Nzd}}
\newcommand{\Owht}{\widehat{\scr O}}
\newcommand{\Ext}{\mathrm{Ext}}
\newcommand{\Tor}{\mathrm{Tor}}
\newcommand{\Com}{\mathrm{Com}}
\newcommand{\Mod}{\mathrm{Mod}}
\newcommand{\nk}{\mathfrak n}
\newcommand{\mk}{\mathfrak m}
\newcommand{\Ass}{\mathrm{Ass}}
\newcommand{\depth}{\mathrm{depth}}
\newcommand{\Coh}{\mathrm{Coh}}
\newcommand{\Gode}{\mathrm{Gode}}
\newcommand{\Fbb}{\mathbb F}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\Modf}{\mathrm{Mod}^{\mathrm f}}
\newcommand{\codim}{\mathrm{codim}}
\newcommand{\card}{\mathrm{card}}
\newcommand{\dps}{\displaystyle}
\newcommand{\Int}{\mathrm{Int}}
\newcommand{\Nbh}{\mathrm{Nbh}}
\newcommand{\Pnbh}{\mathrm{PNbh}}
\newcommand{\Cl}{\mathrm{Cl}}





\usepackage{tipa} % wierd symboles e.g. \textturnh
\newcommand{\tipar}{\text{\textrtailr}}
\newcommand{\tipaz}{\text{\textctyogh}}
\newcommand{\tipaomega}{\text{\textcloseomega}}
\newcommand{\tipae}{\text{\textrhookschwa}}
\newcommand{\tipaee}{\text{\textreve}}
\newcommand{\tipak}{\text{\texthtk}}
\newcommand{\eps}{\varepsilon}




\usepackage{tipx}
\newcommand{\tipxgamma}{\text{\textfrtailgamma}}
\newcommand{\tipxcc}{\text{\textctstretchc}}
\newcommand{\tipxphi}{\text{\textqplig}}















\numberwithin{equation}{section}




\title{Qiuzhen Lectures on Analysis}
\author{{\sc Bin Gui}
	%\\
	%{\small Department of Mathematics, Rutgers university}\\
	%{\small bin.gui@rutgers.edu}
}
%\date{}
\begin{document}\sloppy % avoid stretch into margins
	\pagenumbering{arabic}
	%\pagenumbering{gobble}
	\setcounter{page}{1}
%	\setcounter{section}{-1}
	%\setcounter{equation}{6}
	



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



	
	\maketitle
%\thispagestyle{empty}	 %remove page number of this page


%Contents hyperlinks: \hyperlink{page.2}{Page 2}, \hyperlink{page.3}{Page 3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-0.5cm}
\makeatletter
\newcommand*{\toccontents}{\@starttoc{toc}}
\makeatother
\toccontents



	
% title and table of contents same page, no content title

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\section{Basic set theory and numbers}


In this chapter, we discuss informally some of the basic notions in set theory and basic properties about numbers. A more thorough treatment can be found in \cite[Ch. 1]{Mun} (for set theory) and \cite[Ch. 1]{Rud-P} (for numbers). 

Let me first list the notations and conventions that will be used throughout the notes. We use frequently the abbreviations:
\begin{gather*}
\text{iff=if and only if}\\
\text{LHS=left hand side}\qquad
\text{RHS=reft hand side}\\
\text{$\exists$=there exists}\qquad \text{$\forall$=for all}\\
\text{i.e.=id est=that is=namely}\qquad\text{e.g.=for example}\\
\text{cf.=compare/check/see/you are referred to}\\
\text{resp.=respectively}\qquad 
\text{WLOG=without loss of generality}\\
\end{gather*}
If $P,Q$ are properties, then
\begin{align*}
P\land Q=P\text{ and }Q\qquad P\lor Q=P\text{ or }Q\qquad \neg P=\text{ Not }P
\end{align*}

If $\Fbb$ is any field (e.g. $\Qbb,\Rbb,\Cbb$), we let $\Fbb^\times=\Fbb\setminus\{0\}$. \index{F@$\Fbb^\times=\Fbb\setminus\{0\}$} If $\alpha$ is a complex number and $n\in\Nbb$, we define the \textbf{binomial coefficient}\index{zz@$\alpha\choose n$}
\begin{align}
{\alpha\choose n}=\left\{
\begin{array}{ll}
\dps\frac{\alpha\cdot(\alpha-1)\cdots (\alpha-n+1)}{n!} &\text{ if }n\geq 1\\[1ex]
1&\text{ if }n=0
\end{array}
\right.
\end{align}
where $n!=n(n-1)(n-2)\cdots 2\cdot 1$ and $0!=1$.



Topics marked with $\star\star$ are technical and/or their methods are rarely used in later studies. You can skim or skip them on first reading. Topics marked with $\star$ are interesting, but not necessarily technical or difficult. They are not essential for understanding the later part of the notes.

%Topics in the ``Problems" section (or the whole ``Problems" sections) marked with $\heartsuit$ are important problems that will be used later in this course.



\subsection{Basic operations and axioms}
Intuitively, a set denotes a collection of elements. For instance:\index{N@$\Nbb=\{0,1,2,\dots\}$} \index{Z@$\Zbb_+=\{1,2,\dots\}$}
\begin{gather*}
\Zbb=\{\text{all integers}\}\qquad \Nbb=\Zbb_{\geq0}=\{n\in\Zbb:n\geq0\}\qquad \Zbb_+=\{n\in\Zbb:n>0\}
\end{gather*}
have infinitely many elements. (In this course, we will not be concerned with the rigorous construction of natural numbers and integers from Peano axioms.) We also let
\begin{align*}
\Qbb=\{\text{all rational numbers}\}\qquad\Rbb=\{\text{all real numbers}\}
\end{align*}
if we that rational and real numbers exist and satisfy the properties we are familiar with in high school mathematics. (We will construct $\Qbb$ and $\Rbb$ rigorously, by the way.)


Set theory is the foundation of modern mathematics. It consists of several Axioms telling us what we can do about the sets. For example, the following way of describing sets
\begin{align}
\{x: x\text{ satisfies property...}\}  \label{eq1}
\end{align}
is illegal, since it gives \textbf{Russell's paradox}: Consider
\begin{align}
S=\{A: A\text{ is a set and }A\notin A\}\label{eq12}
\end{align}
If $S$ were a set, then $S\in S\Rightarrow S\notin S$ and $S\notin S\Rightarrow S\in S$. This is something every mathematician doesn't want to happen.

Instead, the following way of defining sets is legitimate:
\begin{align}
\{x\in X:x\text{ satisfies property}\dots\}  \label{eq2}
\end{align}
where \emph{$X$ is a given set}.  For instance, we can define the \textbf{difference} of two sets:\index{AB@$A\backslash B$}
\begin{align*}
A\setminus B=A-B=\{x\in A:x\notin B\}
\end{align*}




So let us figure out the legal way of defining unions and intersections of sets. The crucial point is that we assume the following axiom:
\begin{axiom}
If $\scr A$ is a set of sets, then there exists a set $X$ such that $A\subset X$ for all $A\in\scr A$.
\end{axiom}

Thus, if $\scr A$ is a set of sets, let $X$ satisfy $A\subset X$ for all $A\in\scr A$, then we can define the \textbf{union} and the \textbf{intersection} 
\begin{subequations}\label{eq3}
\begin{gather}
\bigcup_{A\in\scr A}A=\{x\in X:\text{there exists $A\in\scr A$ such that $x\in A$}\}\\
\bigcap_{A\in\scr A}A=\{x\in X:\text{for all $A\in\scr A$ we have $x\in A$}\}
\end{gather}
\end{subequations}
It is clear that this definition does not rely on the particular choice of $X$.

\begin{rem}
In many textbooks, it is not uncommon that sets are defined as in \eqref{eq1}. You should interpret such definition as \eqref{eq2}, where the set $X$ is omitted because it is clear from the context. For instance, if the context is clear, the set $\{x\in\Rbb:x\geq 0\}$ could be simply written as $\{x:x\geq0\}$ or even $\{x\geq0\}$. By the same token, the phrase ``$\in X$" in \eqref{eq3} could be omitted. So we can also write
\begin{gather*}
A\cup B=\{x: x\in A\text{ or }x\in B\} \qquad  A\cap B=\{x: x\in A\text{ and }x\in B\}
\end{gather*}
which are special cases of \eqref{eq3}.
\end{rem}


\begin{rem}
In the same spirit, when discussing subsets of a given ``large" set $X$, and if $X$ is clear from the context, we shall write $X\setminus A$ (where $A\subset X$) as $A^c$ \index{Ax@$A^c$, the complement of $A$} and call it the \textbf{complement} of $A$.
\end{rem}


\begin{eg}
We have
\begin{gather*}
\bigcup_{x\in(1,+\infty)}[0,x)=[0,+\infty)\qquad\bigcap_{n\in\Zbb_+}(0,1+1/n)=(0,1]\qquad \bigcup_{n\in\Nbb}(0,1-1/n]=(0,1)
\end{gather*}
The readers may notice that these examples are not exactly in the form \eqref{eq3}. They are actually unions and intersections of indexed families of sets. (See Def. \ref{lb1}.) We need some preparation before discussing this notion.
\end{eg}




\begin{axiom}
If $A_1,\dots,A_n$ are sets, their \textbf{Cartesian product} exists:
\begin{align*}
A_1\times\cdots\times A_n=\{(a_1,\dots,a_n): a_i\in A_i\text{ for all }1\leq i\leq n\}
\end{align*}
where two elements $(a_1,\dots,a_n)$ and $(b_1,\dots,b_n)$ of the Cartesian product are regarded equal iff $a_1=b_1,\dots,a_n=b_n$. We also write
\begin{align*}
(a_1,\dots,a_n)=a_1\times\cdots\times a_n
\end{align*}
especially when $a,b$ are real numbers and $(a,b)$ can mean an open interval. We understand $A_1\times\cdots\times A_n$ as $\emptyset$ if some $A_i$ is $\emptyset$.

If $A_1=\cdots=A_n=A$, we write the Cartesian product as $A^n$. \hfill\qedsymbol
\end{axiom}

\begin{eg}
Assume that the set of real numbers $\Rbb$ exists. Then the set of complex numbers $\Cbb$ \index{C@$\Cbb$, the set of complex numbers} is defined to be $\Rbb^2=\Rbb\times\Rbb$ as a set. We write $(a,b)\in\Cbb$ as $a+b\im$ where $a,b\in\Rbb$. Define
\begin{gather*}
(a+b\im)+(c+d\im)=(a+c)+(b+d)\im\\
(a+b\im)\cdot (c+d\im)=(ac-bd)+(ad+bc)\im
\end{gather*}
Define the zero element $0$ of $\Cbb$ to be $0+0\im$. More generally, we consider $\Rbb$ as a subset of $\Cbb$ by viewing $a\in\Rbb$ as $a+0\im\in\Cbb$. This defines the usual arithmetic of complex numbers. 

If $z=a+b\im$, we define its \textbf{absolute value} $|z|=\sqrt{a^2+b^2}$. Then $z=0$ iff $|z|=0$. We define the \textbf{(complex) conjugate} of $z$ to be $\ovl z=a-b\im$. Then $|z|^2=z\ovl z$.

If $z\neq 0$, then there clearly exists a unique $z^{-1}\in\Cbb$ such that $zz^{-1}=z^{-1}z=1$:  $z^{-1}=|z|^{-2}\cdot \ovl z$. Thus, using the language of modern algebra, $\Cbb$ is a  \textbf{field}.\footnote{See Rem. \ref{lb166} or  \cite[Def. 1.12]{Rud-P} for the definition of fields. Rather than memorizing the full definition of fields, it is more important to keep in mind some typical (counter)examples: $\Qbb,\Rbb,\Cbb$ are fields. $\Zbb$ is not a field, because not every non-zero element of $\Zbb$ has an inverse. The set of quaternions $\{a+b\im+c\mathbf{j}+d\mathbf{k}: a,b,c,d\in\Rbb\}$ is not a field because it is not commutative ($\im\mathbf{j}=-\mathbf{j}\im=\mathbf{k}$). The set of rational functions $P(x)/Q(x)$, where $P,Q$ are polynomials with coefficients in $\Rbb$ and $Q\neq 0$, is a field.}  \hfill\qedsymbol
\end{eg}


The axiom of Cartesian product allows us to define relations and functions:

\begin{df}
If $A,B$ are sets, a subset $R$ of $A\times B$ is called a \textbf{relation}. For $(a,b)\in A\times B$, we write $aRb$ iff $(x,y)\in R$. We understand ``$aRb$" as ``$a$ is related to $b$ through the relation $R$".
\end{df}


\begin{df}\label{lb39}
A relation $f$ of $A,B$  is called a \textbf{function} or a \textbf{map} (or a \textbf{mapping}), if for every $a\in A$ there is a unique $b\in B$ such that $afb$. In this case, we write $b=f(a)$. 

When we write $f:A\rightarrow B$, we always mean that $A,B$ are sets and $f$ is a function from $A$ to $B$. $A$ and $B$ are called respectively the \textbf{domain} and the \textbf{codomain} of $f$. (Sometimes people also use the words ``source" and ``target" to denote $A$ and $B$.) 

If $E\subset A$ and $F\subset B$, we define the \textbf{image under $f$} of $E$  and the \textbf{preimage under $f$} of $F$ to be
\begin{gather*}
f(E)=\{b\in B:\exists a\in E\text{ such that }b=f(a)\}\\
f^{-1}(F)=\{a\in A: f(a)\in F\}.
\end{gather*}
$f(A)$ is simply called the \textbf{image} of $f$, or the \textbf{range} of $f$. If $b\in B$, $f^{-1}(\{b\})$ is often abbreviated to $f^{-1}(b)$. The function \index{f@$f\lvert_E$, the restriction of $f$ to $E$}
\begin{align*}
f|_E:E\rightarrow B\qquad x\mapsto f(x)
\end{align*}
is called the \textbf{restriction}  of $f$ to $E$. \hfill\qedsymbol
\end{df}


The intuition behind the definition of functions is clear: we understand functions as the same as their graphs. So a subset $f$ of the ``coordinate plane" $A\times B$ is the graph of a function iff it ``intersects every vertical line precisely once".


\begin{rem}\label{lb40}
According to our definition, $\emptyset$ (as a subset of $\emptyset\times B$) is the only function from $\emptyset$ to $B$. (A false assumption implies any statement.) If $A\neq\emptyset$, there are no functions $A\rightarrow\emptyset$.
\end{rem}


\begin{df}\label{lb13}
A function $x:\Zbb_+\rightarrow A$ is called a \textbf{sequence in $A$}. We write $x(n)$ as $x_n$, and write this sequence as $(x_n)_{n\in\Zbb_+}$ (or simply $(x_n)_n$ or $(x_n)$).
\end{df}

Many people write such a sequence as $\{x_n\}_{n\in\Zbb_+}$. We do not use this notation, since it can be confused with $\{x_n: n\in\Zbb_+\}$ (the range of the function $x$).



\begin{axiom}
If $X$ is a set, then the \textbf{power set} \index{00@Power set $2^X$} $2^X$ exists, where
\begin{align*}
2^X=\{\text{Subsets of }X\}
\end{align*}
\end{axiom}

\begin{eg}
The set $2^{\{1,2,3\}}$ has $8$ elements: $\emptyset$, $\{1\}$, $\{2\}$, $\{3\}$, $\{1,2\}$, $\{1,3\}$, $\{2,3\}$, $\{1,2,3\}$. Surprisingly, $8=2^3$. As we shall see in Exp. \ref{lb11} and Cor. \ref{lb12}, this relationship holds more generally, which explains the terminology $2^X$.  
\end{eg}

Now we are ready to define indexed families of sets.
\begin{df}\label{lb1}
An \textbf{indexed family of sets} \index{00@Indexed family of sets}  $(S_i)_{i\in I}$ is defined to be a function $S:I\rightarrow 2^X$ for some sets $I,X$. We write $S(i)$ as $S_i$. (So $S_i$ is a subset of $X$.) $I$ is called the \textbf{index set}. Define
\begin{align*}
\bigcup_{i\in I}S_i= \bigcup_{T\in S(I)}T\qquad \bigcap_{i\in I}S_i= \bigcap_{T\in S(I)}T
\end{align*}
Note that $S(I)$ is the image of the function $S$.
\end{df}


\begin{eg}
In the union $\bigcup_{x\in(1,+\infty)}[0,x)$, the index set is $I=(1,+\infty)$, and $X$ can be the set of real numbers $\Rbb$. Then $S:I\rightarrow 2^X$ is defined to be $S_i=S(i)=[0,i)$.
\end{eg}




\begin{exe}\label{lb5}
Let $f:A\rightarrow B$ be a function. We say that $f$ is \textbf{injective} if for all $a_1,a_2\in A$ satisfying $a_1\neq a_2$ we have $f(a_1)\neq f(a_2)$. We say that $f$ is \textbf{surjective} if for each $b\in B$ we have $f^{-1}(b)\neq\emptyset$. $f$ is called \textbf{bijective} if it is both surjective and bijective. Define the \textbf{identity maps} $\id_A:A\rightarrow A,a\mapsto a$ \index{id@$\id_A$} and $\id_B$ in a similar way. Prove that
\begin{subequations}
\begin{gather}
\text{$f$ is injective $\Longleftrightarrow$ there is $g:B\rightarrow A$ such that $g\circ f=\id_A$}\label{eq4}\\
\text{$f$ is surjective $\Longleftrightarrow$ there is $g:B\rightarrow A$ such that $f\circ g=\id_B$}\label{eq5}\\
\text{$f$ is bijective $\Longleftrightarrow$ there is $g:B\rightarrow A$ such that $g\circ f=\id_A$ and $f\circ g=\id_B$}\label{eq6}
\end{gather}
\end{subequations}
Show that the $g$ in \eqref{eq4} (resp. \eqref{eq5}, \eqref{eq6}) is surjective (resp. injective, bijective).
\end{exe}


The equivalence \eqref{eq5} is subtler, since its proof requires Axiom of Choice.


\begin{axiom}
Let $(S_i)_{i\in I}$ be an indexed family of sets. The \textbf{Axiom of Choice} asserts that if $S_i\neq\emptyset$ for all $i\in I$, then there exists a function (the \textbf{choice function})
\begin{align*}
f:I\rightarrow \bigcup_{i\in I}S_i
\end{align*}
such that $f(i)\in S_i$ for each $i\in I$.
\end{axiom}


Intuitively, the axiom of choice says that for each $i\in I$ we can choose an element $f(i)$ of $S_i$. And such choice gives a function $f$.


\begin{eg}
Let $f:A\rightarrow B$ be surjective. Then each member of the family $(f^{-1}(b))_{b\in B}$ is nonempty. Thus, by axiom of choice, there is a choice function $g$ defined on the index set $B$ such that $g(b)\in f^{-1}(b)$ for each $b$. Clearly $f\circ g=\id_B$.
\end{eg}



\begin{rem}
Suppose that each member $S_i$ of the family $(S_i)_{i\in I}$ has exactly one element. Then the existence of a choice function does not require Axiom of Choice: Let $X=\bigcup_{i\in I}S_i$ and define relation
\begin{align*}
f=\{(i,x)\in I\times X: x\in S_i\}
\end{align*}
Then one checks easily that this relation between $I$ and $X$ is a function, and that it is the (necessarily unique) choice function of $(S_i)_{i\in I}$.
\end{rem}

According to the above remark, one does not need Axiom of Choice to prove \eqref{eq4} and \eqref{eq6}. Can you see why?


\subsection{Partial and total orders, equivalence relations}

\begin{df}
Let $A$ be a set. A \textbf{partial order} (or simply an \textbf{order}) $\leq$ on $A$ is a relation on $A\times A$ satisfying for all $a,b,c\in A$ that:
\begin{itemize}
\item (Reflexivity) $a\leq a$.
\item (Antisymmetry) If $a\leq b$ and $b\leq a$ then $a=b$.
\item (Transitivity) If $a\leq b$ and $b\leq c$ then $a\leq c$.
\end{itemize}
We write $b\geq a$ iff $a\leq b$. Write $a>b$ iff $a\geq b$ and $a\neq b$. Write $a<b$ iff $b>a$. So $\geq$ is also an order on $A$. The pair $(A,\leq)$ is called a \textbf{partially ordered set}, or simply a \textbf{poset}. \index{00@Poset=partially ordered set} A partial order $\leq$ on $A$ is called a \textbf{total order}, if for every $a,b\in A$ we have either $a\leq b$ or $b\leq a$.
\end{df}


\begin{eg}
The following are examples of orders.
\begin{itemize}
\item Assume that $\Rbb$ exists. Then $\Rbb$ has the canonical total order, which restricts to the total order of $\Zbb$. This is the total order that everyone is familiar with.
\item Let $X$ be a set. Then $(2^X,\subset)$ is a poset.
\item $\Rbb^2$ is a poset, if we define $(a,b)\leq (c,d)$ to be $a\leq c$ and $b\leq d$. 
\end{itemize}
\end{eg}


\begin{df}\label{lb156}
A relation $\sim$ on a set $A$ is called an \textbf{equivalence relation}, \index{00@Equivalence relation} if for all $a,b,c\in A$ we have
\begin{itemize}
\item (Reflexivity) $a\sim a$.
\item (Symmetry) $a\sim b$ iff $b\sim a$.
\item (Transitivity) If $a\sim b$ and $b\sim c$ then $a\sim c$.
\end{itemize}
\end{df}

Later, we will use the notions of partial orders and equivalence relation not just for a set, but for a collection of objects ``larger" than a set. See Sec. \ref{lb4}.

\begin{df}\label{lb157}
Let $A$ be a set, together with an equivalence relation $\sim$. Define a new set
\begin{align*}
{A/\sim}=\{[a]: a\in A\}
\end{align*}
where the notion $[a]$ can be understood in the following two equivalent ways (we leave it to the readers to check the equivalence):
\begin{itemize}
\item[(1)] $[a]$ is a new symbol. We understand $[a]$ and $[b]$ as equal iff $a\sim b$.
\item[(2)] $[a]=\{x\in A: x\sim a \}$
\end{itemize}
We call $[a]$ the \textbf{equivalence class} (or the \textbf{residue class}) of $a$, and call $A/\sim$ the \textbf{quotient set} \index{00@Quotient sets} of $A$ under $\sim$. The surjective map $\pi:a\in A\mapsto [a]\in {A/\sim}$ is called the \textbf{quotient map}.
\end{df}


\begin{exe}
Prove that every surjective map  is equivalent to a quotient map. More precisely, prove that for every surjection $f:A\rightarrow B$, there is an equivalence relation $\sim$ on $A$ and a bijective map $\Phi:{A/\sim}\rightarrow B$ such that the following diagram commutes (i.e. $f=\Phi\circ\pi$):
\begin{equation}\label{eq7}
\begin{tikzcd}[column sep=small]
                          & A \arrow[rd, "f"] \arrow[ld, "\pi"'] &   \\
{A/\sim} \arrow[rr, "\Phi"] &                                      & B
\end{tikzcd}
\end{equation}
\end{exe}


This is the first time we see commutative diagrams. Commutative diagrams are very useful for indicating that certain maps between sets are ``equivalent" or are satisfying some more general relations. For example, \eqref{eq7} shows that the maps $f$ and $\pi$ are equivalent, and that this equivalence is implemented by the bijection $\Phi$. The formal definition of commutative diagrams is the following:


\begin{df}
A diagram (i.e. some sets denoted by symbols, and some maps denoted by arrows) is called a \textbf{commutative diagram}, \index{00@Commutative diagram} if all directed paths in the diagram with the same start and endpoints lead to the same result.
\end{df}


Here is an example of commutative diagram in linear algebra. This example assumes some familiarity with the basic properties of vector spaces \index{00@Vector spaces} and linear maps.\footnote{Again, we refer the readers to Internet or any Linear Algebra textbook (e.g. \cite{Axl}) for the definition of vector spaces and linear maps.}


\begin{eg}\label{lb67}
Let $V,W$ be vector spaces over a field $\Fbb$ with finite dimensions $m,n$ respectively. Let $e_1,\dots,e_m$ be a basis of $V$, and let $\eps_1,\dots,\eps_n$ be a basis of $W$. We know that there are unique linear isomorphisms $\Phi:\Fbb^m\xrightarrow{\simeq} V$ and $\Psi:\Fbb^n\xrightarrow{\simeq} W$ such that
\begin{align*}
\Phi(a_1,\dots,a_m)=a_1e_1+\cdots+a_me_m\qquad \Psi(b_1,\dots,b_n)=b_1\eps_1+\cdots+b_n\eps_n
\end{align*}
Let $T:V\rightarrow W$ be a \index{00@Linear maps} \textbf{linear map}, i.e., a map satisfying $T(a\xi+b\eta)=aT\xi+bT\eta$ for all $a,b\in\Fbb,\xi,\eta\in V$. Then there is a unique $n\times m$ matrix $A\in\Fbb^{n\times m}$ \index{Fnm@$\Fbb^{n\times m}$, the set of $n\times m$ matrices} (viewed as a linear map $\Fbb^m\rightarrow\Fbb^n$ defined by matrix multiplication) such that the following diagram commutes:
\begin{equation}
\begin{tikzcd}
\Fbb^m \arrow[r,"\Phi","\simeq"'] \arrow[d,"A"'] & V \arrow[d,"T"] \\
\Fbb^n \arrow[r,"\Psi","\simeq"']           & W          
\end{tikzcd}
\end{equation} 
namely, $T\Phi=\Psi A$. This commutative diagram tells us that $T$ is equivalent to its \textbf{matrix representation} \index{00@Matrix representation} $A$ under the bases $e_\blt,\eps_\star$, and that this equivalence is implemented by the linear isomorphisms $\Phi$ (on the sources) and $\Psi$ (on the targets). 
\end{eg}

Commutative diagrams are ubiquitous in mathematics. You should learn how to read commutative diagrams and understand their intuitive meanings. We will see more examples in the future of this course.



\subsection{$\Qbb$, $\Rbb$, and $\overline{\mathbb R}=[-\infty,+\infty]$}



Using equivalence classes, one can construct rational numbers from integers, and real numbers from rationals. We leave the latter construction to the future, and discuss the construction of rationals here.

\begin{eg}[Construction of $\Qbb$ from $\Zbb$]\label{lb17}
Define a relation on $\Zbb\times\Zbb^\times$ (where $\Zbb^\times=\Zbb\setminus\{0\}$) as follows. If $(a,b),(a',b')\in\Zbb\times\Zbb^\times$, we say $(a,b)\sim(a',b')$ iff $ab'=a'b$. It is a routine check that $\sim$ is an equivalence relation. Let \index{Q@$\Qbb$, the field of rational numbers}  $\Qbb=(\Zbb\times\Zbb^\times)/\sim$, and write the equivalence class of $(a,b)$ as $a/b$ or $\frac ab$. Define additions and multiplications in $\Qbb$ to be
\begin{align*}
\frac ab+\frac cd=\frac{ad+bc}{bd}\qquad \frac ab\cdot\frac cd=\frac{ac}{bd}
\end{align*}
We leave it to the readers to check that this definition is \index{00@Well defined} \textbf{well-defined}: If $(a,b)\sim(a',b')$ and $(c,d)\sim(c',d')$ then $(ad+bc,bd)\sim(a'd'+b'c',b'd')$ and $(ac,bd)\sim(a'c',b'd')$.

We regard $\Zbb$ as a subset of $\Qbb$ by identifying $n\in\Zbb$ with $\frac n1$. (This is possible since the map $n\in\Zbb\mapsto \frac n1\in\Qbb$ is injective.) Each $a/b\in\Qbb$ has additive inverse $\frac{-a}b$. If $a/b\in\Qbb$ is not zero (i.e. $(a,b)\nsim (0,1)$), then $a/b$ has multiplicative inverse $b/a$. This makes $\Qbb$ a field: the field of \textbf{rational numbers}.

If $a/b\in\Qbb$, we say $a/b\geq 0$ if $ab\geq0$. Check that this is well-defined (i.e., if $(a,b)\sim(a',b')$, then $ab\geq0$ iff $a'b'\geq0$). More generally, if $a/b,c/d\in\Qbb$, we say $\frac ab\geq \frac cd$ if $\frac ab-\frac cd\geq0$. Check that $\geq$ is a total order on $\Qbb$.  Check that $\Qbb$ is an Archimedean ordered field, defined below.\hfill\qedsymbol
\end{eg}


\begin{df}\label{lb161}
A field $\Fbb$, together with a total order $\leq$, is called an \index{00@Ordered field} \textbf{ordered field}, if for every $a,b,c\in\Fbb$ we have
\begin{itemize}
\item (Addition preserves $\leq$) If $a\leq b$ then $a+c\leq b+c$.
\item (Multiplication by $\Fbb_{\geq0}$ preserves $\geq0$) If $a,b\geq 0$ then $ab\geq0$.
\end{itemize}
These two properties relate $\leq$ to $+$ and $\cdot$ respectively.
\end{df}

\begin{rem}
Many familiar properties about inequalities in $\Qbb$ hold for an ordered field. For instance: 
\begin{gather*}
a\geq b~\wedge~ c\geq d \qquad\Longrightarrow\qquad a+c\geq b+d\\
a\geq0\qquad\Longleftrightarrow\qquad -a\leq0\\
a\geq0~\wedge~b\geq c\qquad\Longleftrightarrow\qquad ab\geq ac\\
a\leq0~\wedge~b\geq c\qquad\Longleftrightarrow\qquad ab\leq a\\
a^2\geq0\\
0<a\leq b\qquad\Longrightarrow\qquad 0< b^{-1}\leq a^{-1}
\end{gather*}
Check them yourself, or see \cite[Prop. 1.18]{Rud-P}.
\end{rem}


\begin{df}
We say that an ordered field $\Fbb$ satisfies \index{00@Archimedean property} \textbf{Archimedean property} if for each $a,b\in\Fbb$ we have
\begin{align*}
a> 0\qquad\Longrightarrow \qquad\exists n\in\Nbb\text{ such that }na>b
\end{align*}
where $na$ means $\underbrace{a+\cdots+a}_{n}$.
\end{df}

\begin{eg}
$\Qbb$ satisfies Archimedean property. Indeed, let $a,b\in\Qbb$ and $a>0$. Then $a=p/q$ and $b=r/s$ where $p,q,s\in\Zbb_+$ and $r\in\Zbb$. So $na>b$ where $n=q|r|+q$.
\end{eg}



Prop. \ref{lb2} gives an important application of Archimedian property. We will use this in the construction of $\Rbb$ from $\Qbb$, and in the proof that $\Qbb$ is dense in $\Rbb$. 

\begin{df}
Let $\Fbb$ be a field. A subset $\Ebb\subset\Fbb$ is called a  \textbf{subfield} \index{00@Subfield} of $\Fbb$, if $\Ebb$ contains the $1$ of $\Fbb$, and if $\Ebb$ is closed under the operations of addition, multiplication, taking negative, and taking inverse in $\Fbb$ (i.e. if $a,b\in\Ebb$ then $a+b,ab,-a\in\Ebb$, and $a^{-1}\in\Ebb$ whenever $a\neq 0$). We also call $\Fbb$ a \index{00@Field extension} \textbf{field extension} of $\Ebb$, since $\Ebb$ is clearly a field.
\end{df}

Note that if $\Ebb$ is a subfield of $\Fbb$, the $0$ of $\Fbb$ is in $\Ebb$ since $0=1+(-1)\in\Ebb$.

\begin{df}
Let $\Ebb$ be an ordered field. A field extension $\Fbb$ of $\Ebb$ is called an \index{00@Ordered field extension=ordered subfield} \textbf{ordered field extension}, if $\Fbb$ is equipped with a total order $\leq$ such that $\Fbb$ is an ordered field, and if the order $\leq$ of $\Fbb$ restricts to that of $\Ebb$. We also call $\Ebb$ an \textbf{ordered subfield} of $\Fbb$.
\end{df}

Our typical example of ordered field extension will be $\Qbb\subset\Rbb$.

\begin{pp}\label{lb2}
Let $\Fbb$ be an ordered field extension  of $\Qbb$. Assume that $\Fbb$ is Archimedean. Then for every $x,y\in\Fbb$ satisfying $x<y$, there exists $p\in\Qbb$ such that $x<p<y$.
\end{pp}

\begin{proof}
Assume $x,y\in\Fbb$ and $x<y$. Then $y-x>0$ (since $y-x\neq 0$ and $-x+x\leq -x+y$). By Archimedean property, there exists $n\in\Zbb_+$ such that $n(y-x)>1$. So $\displaystyle y-x>\frac 1n$ and hence $\displaystyle x+\frac 1n<y$.

Let us prove that the subset
\begin{equation*}
A=\big\{k\in\Zbb: \frac {~k~}{n}\leq x\big\}
\end{equation*}
is nonempty and bounded from above in $\Zbb$. By Archimedean property, there is $m\in\Zbb_+$ such that $m>nx$, i.e. $\displaystyle \frac mn>x$. So for each $k\in\Zbb_+$ satisfying $k\geq m$, we have $\displaystyle \frac kn=\frac mn+\frac{k-m}n>x$. Therefore, for each $k\in A$ we have $k<m$. So $A$ is bounded above. By Archimedean property again, there is $l\in\Zbb_+$ such that $\displaystyle \frac ln>-x$. So $\displaystyle -\frac ln<x$, and hence $A$ is nonempty.

We now use the fact that \emph{every nonempty subset of $\Zbb$ bounded above has a maximal element}. Let $k=\max A$. Since $k+1\notin A$, we have $\displaystyle x<\frac{k+1}n$. Since $\displaystyle \frac kn\leq x$, we have
\begin{align*}
\frac{k+1}n=\frac kn+\frac 1n\leq x+\frac 1n<y
\end{align*}
This proves $x<p<y$ with $\displaystyle p=\frac{k+1}n$.
\end{proof}

To introduce $\Rbb$ formally, we need more definitions:

\begin{df}
Let $(X,\leq)$ be a poset and $E\subset X$. An \textbf{upper bound of $E$ in $X$} \index{00@Upper bound} is an element $x\in X$ satisfying $e\leq x$ for all $e\in E$. An upper bound $x\in X$ of $E$ is called a \textbf{least upper bound} or a \textbf{supremum} \index{00@Supremum}  if $x\leq y$ for every upper bound $y\in Y$ of $E$. In this case, we write the supremum as \index{sup@$\sup E$} $\sup E$. It is not hard to check that supremums are unique if they exist.

We leave it to the readers to define \textbf{lower bounds} and the \textbf{greatest lower bound} (if exists) of $E$, also called the \textbf{infinimum} \index{00@Infinimum} and is denoted by \index{inf@$\inf E$} $\inf E$. \hfill\qedsymbol
\end{df}


\begin{df}
Let $(X,\leq)$ be a poset. We say that $X$ satisfies the \textbf{least-upper-bound property}, if every every nonempty subset $E\subset X$ which is bounded above (i.e. $E$ has an upper bound) has a supremum in $X$. The \textbf{greatest-lower-bound property} is defined in the opposite way.
\end{df}

\begin{eg}
$\Zbb$ satisfies the least-upper-bound and the greatest-lower-bound property: Let $A\subset \Zbb$. If $A$ is bounded above (resp. below), then the maximum $\max A$ (resp. minimum $\min A$) exists and is the supremum (resp. infinimum) of $A$.
\end{eg}

\begin{eg}
Let $X$ be a set. Then $(2^X,\subset)$ satisfies the least-upper-bound and the greatest-lower-bound property: Let $\scr A\subset 2^X$, i.e., $\scr A$ is a set of subsets of $X$. Then $\scr A$ is bounded from above by $X$, and is bounded from below by $\emptyset$. Moreover,
\begin{align*}
\sup\scr A=\bigcup_{A\in\scr A}A\qquad \inf\scr A=\bigcap_{A\in\scr A}A
\end{align*}
\end{eg}





\begin{thm}\label{lb3}
There is an ordered field extension of $\Qbb$ which is Archimedian and satisfies the least-upper-bound property. This field is denoted by  $\Rbb$. Its elements are called \index{00@Real number} \textbf{real numbers}.
\end{thm}

Thm. \ref{lb3} will be proved in Ch. \ref{lb167}. Note that by taking negative, we see that $\Rbb$ also satisfies the greatest-lower-bound property.


\begin{rem}
The ordered field extensions satisfying the conditions in Thm. \ref{lb3} are unique ``up to isomorphisms". (The words ``\textbf{isomorphism}"\index{00@Isomorphism}  and ``equivalence" are often interchangeable, though ``isomorphism" is more often used in the algebraic setting, whereas ``equivalence" can be used in almost every context. For example, in point-set topology, ``equivalence" means ``homeomorphism".) We leave it to the readers to give the precise statement. We will not use this uniqueness in this course. 

Note that to compare two extensions $\Fbb,\Rbb$ of $\Qbb$, it is very confusing to regard $\Qbb$ as a subset of both $\Fbb$ and $\Rbb$. You'd better consider two different injective maps $\tau:\Qbb\rightarrow \Fbb$ and $\iota:\Qbb\rightarrow\Rbb$ preserving the algebraic operations and the order of $\Qbb$, and use a commutative diagram to indicate that $\tau$ and $\iota$ are equivalent. (Thus, what's happening here is that we have an equivalence of maps, not just an equivalence of the fields $\Fbb$ and $\Rbb$.) \hfill\qedsymbol
\end{rem}


\begin{df}\label{lb114}
Let $-\infty,+\infty$ be two different symbols, and extend the total order $\leq$ of $\Rbb$ to the \textbf{extended real line}\index{R@$\ovl\Rbb=[-\infty,+\infty]=\Rbb\cup\{-\infty,+\infty\}$}
\begin{align*}
\ovl\Rbb=\Rbb\cup\{-\infty,+\infty\}
\end{align*}
by letting $-\infty<x<+\infty$ for all $x\in\Rbb$. Define for each $x\in\Rbb$ that
\begin{gather*}
x\pm\infty=\pm\infty+x=\pm\infty\qquad +\infty-(-\infty)=+\infty\\
x\cdot(\pm\infty)=\pm\infty\cdot x=\left\{
\begin{array}{cc}
\pm\infty&\text{if }x>0\\
\mp\infty&\text{if }x<0
\end{array}
\right.\\
\frac x{\pm\infty}=0\\
\frac{\pm\infty}{x}=x^{-1}\cdot(\pm\infty)\qquad \text{if }x\neq0
\end{gather*}
If $a,b\in\ovl\Rbb$ and $a\leq b$, we define \textbf{intervals} \index{00@Interval} with endpoints \index{00@Endpoints of an interval} $a,b$:
\begin{gather}\label{eq8}
\begin{gathered}
[a,b]=\{x\in\ovl\Rbb:a\leq x\leq b\}\qquad (a,b)=\{x\in\ovl\Rbb:a< x< b\}\\
(a,b]=\{x\in\ovl\Rbb:a< x\leq b\}\qquad [a,b)=\{x\in\ovl\Rbb:a\leq x< b\}
\end{gathered}
\end{gather}
So $\Rbb=(-\infty,+\infty)$ and $\ovl\Rbb=[-\infty,+\infty]$. If $a,b$ are in $\Rbb$, we say that the corresponding interval is \textbf{bounded}. \index{00@Bounded interval}
\end{df}

In this course, unless otherwise stated, an interval always means one of the four sets in \eqref{eq8}. The first two intervals are called respectively a \textbf{closed interval} and an \textbf{open interval}.


\begin{rem}
Clearly, every subset $E$ of $\ovl\Rbb$ is bounded and has a supremum and an infinimum. We have that $\sup E=+\infty$ iff $E$ is not bounded above in $\Rbb$, and that $\inf E=-\infty$ iff $E$ is not bounded below in $\Rbb$. 
\end{rem}


\subsection{Cardinalities, countable sets, and product spaces $Y^X$}\label{lb4}


\begin{df}
Let $A$ and $B$ be sets. We say that $A$ and $B$ have the same \textbf{cardinality} \index{00@Cardinality $\card(A)$} and write $\card(A)=\card(B)$ (or simply $A\approx B$), if there is a bijection $f:A\rightarrow B$. We write $\card(A)\leq\card(B)$ (or simply $A\precsim B$) if $A$ and a subset of $B$ have the same cardinality. 
\end{df}



\begin{exe}\label{lb9}
Show that $\card(A)\leq\card(B)$ iff there is an injection $f:A\rightarrow B$, iff there is a surjection $g:B\rightarrow A$. (You need either Axiom of Choice or its consequence \eqref{eq5} to prove the last equivalence.)
\end{exe}

It is clear that $\approx$ is an equivalence relation on the collection of sets. It is also true that $\precsim$ is a partial order: Reflexivity and transitivity are easy to show. The proof of antisymmetry is more involved:



\begin{thm}[Schr\"oder-Bernstein]\label{lb8}\index{00@Schr\"oder-Bernstein theorem}
Let $A,B$ be two sets. If $A\precsim B$ and $B\precsim A$, then $A\approx B$.
\end{thm}

\begin{proof}[$\star\star$ Proof]
Assume WLOG that $A\subset B$. Let $f:B\rightarrow A$ be an injection. Let $A_n=f^n(A)$ defined inductively by $f^0(A)=A$, $f^n(A)=f(f^{n-1}(A))$. Let $B_n=f^n(B)$. Then
\begin{align*}
B_0\supset A_0\supset \cdots\supset B_n\supset A_n\supset B_{n+1}\supset\cdots
\end{align*}
In particular, $C=\bigcap_{n\in\Nbb}A_n$ equals $\bigcap_{n\in\Nbb}B_n$. Note that $f$ gives a bijection $B_n\setminus A_n\rightarrow B_{n+1}\setminus A_{n+1}$ (since $f$ gives bijections $B_n\rightarrow B_{n+1}$ and $A_n\rightarrow A_{n+1}$). Therefore, we have a bijection $g:B\rightarrow A$ defined by
\begin{gather*}
g(x)=\left\{
{\begin{array}{ll}
f(x)&\text{if $x\in B_n\setminus A_n$ for some $n\in\Nbb$}\\[0.5ex]
x&\text{otherwise}
\end{array}}
\right.
\end{gather*}
where ``otherwise" means either $x\in C$ or $x\in A_n\setminus B_{n+1}$ for some $n$.
\end{proof}

Intuition about the above proof: View $B$ as an onion. The layers of $B$ are $B_n\setminus A_n$ (the odd layers) and $A_n\setminus B_{n+1}$ (the even layers). The bijection $g$ maps each odder layer to the subsequent odd one, and fixes the even layers and the core $C$.


\begin{eg}\label{lb6}
If $-\infty<a<b<+\infty$, then $(0,1)\approx (a,b)$.
\end{eg}
\begin{proof}
$f:(0,1)\rightarrow (a,b)$ sending $x$ to $(b-a)x+a$ is a bijection.
\end{proof}

\begin{eg}\label{lb7}
If $-\infty<a<b<+\infty$, then $\Rbb\approx (a,b)$
\end{eg}

\begin{proof}
By the previous example, it suffices to prove $\Rbb\approx(-1,1)$. The function
\begin{gather}\label{eq20}
f:\Rbb\rightarrow(-1,1)\qquad f(x)=\left\{
\begin{array}{ll}
\frac x{1+x}&\text{ if $x\geq0$}\\[0.5ex]
-f(-x)&\text{ if $x<0$}
\end{array}
\right.
\end{gather}
is bijective.
\end{proof}


Alternatively, one may use the tangent function to give a bijection between $(-\pi/2,\pi/2)$ and $\Rbb$. I have avoided this method, since \eqref{eq20} is more elementary than trigonometric functions. The mathematically rigorous definition of trigonometric functions and the verification of their well-known properties are far from easy tasks. 



\begin{pp}
Let $I$ be an interval with endpoints $a<b$ in $\ovl\Rbb$. Then $I\approx\Rbb$.
\end{pp}

\begin{proof}
Let $A=(0,1)\cup\{-\infty,+\infty\}$. By Exp.  \ref{lb7}, we have
\begin{align*}
(a,b)\subset I\precsim \ovl\Rbb\approx A\approx[0,1]\subset (-2,2)\approx (a,b)
\end{align*}
So $I\approx\ovl\Rbb$ by Schr\"oder-Bernstein Thm. \ref{lb8}. In particular, $\Rbb=(-\infty,+\infty)\approx\ovl\Rbb$.
\end{proof}


\begin{df}
A set $A$ is called \textbf{finite} if $A\precsim\{1,\dots,n\}$ for some $n\in\Zbb_+$. $A$ is called  \textbf{countable} if $A\precsim\Nbb$. \index{00@Countable}
\end{df}

Clearly, a set $A$ is finite iff either $A\approx\emptyset$ or $A\approx\{1,\dots,n\}$ for some $n\in\Zbb_+$.

\begin{rem}
Let $A\subset\Nbb$. If $A$ is bounded above, then $A\subset\{0,\dots,n\}$ and hence $A$ is finite. If $A$ is not bounded above, then we can construct a strictly increasing sequence $(x_n)_{n\in\Nbb}$ in $A$. (Pick any $x_0\in A$. Suppose we have $x_n\in A$. Since $x_n$ is not an upper bounded of $A$, there is $x_{n+1}\in A$ larger than $x_n$. So $(x_n)_{n\in\Nbb}$ can be constructed inductively.) This gives an injection $\Nbb\rightarrow A$. Therefore $A\succsim \Nbb$, and hence $A\approx \Nbb$ by Schr\"oder-Bernstein.

It follows that if $B\precsim\Nbb$, then either $B$ is a finite set, or $B\approx\Nbb$. Therefore, ``a set $B$ is \textbf{countably infinite}" \index{00@Countably infinite} means the same as ``$B\approx\Nbb$".  \hfill\qedsymbol 
\end{rem}


\begin{thm}\label{lb15}
A countable union of countable sets is countable. In particular, $\Nbb\times\Nbb\approx\Nbb$.
\end{thm}

\begin{proof}
Recall Exe. \ref{lb9}. Let $A_1,A_2,\dots$ be countable sets. Since each $A_i$ is countable, there is a surjection $f_i:\Nbb\rightarrow A_i$. Thus, the map $f:\Nbb\times\Nbb\rightarrow \bigcup_i A_i$ defined by $f(i,j)=f_i(j)$ is surjective. Therefore, it suffices to show that there is a surjection $\Nbb\rightarrow\Nbb\times\Nbb$. This is true, since we have a bijection $g:\Nbb\rightarrow\Nbb\times\Nbb$ where $g(0),g(1),g(2),\dots$ are $(0,0)$, $(1,0)$, $(0,1)$, $(2,0)$, $(1,1)$, $(0,2)$, $(3,0)$, $(2,1)$, $(1,2)$, $(0,3)$, etc., as shown by the figure
\begin{align*}
\vcenter{\hbox{{
			\includegraphics[width=3.5cm]{fig1.png}}}}
\end{align*}
\end{proof}

As an application, we prove the extremely important fact that $\Qbb$ is countable.
\begin{co}
We have $\Nbb\approx\Zbb_+\approx\Zbb\approx \Qbb$.
\end{co}



\begin{proof}
Clearly $\Zbb_{<0}\approx\Nbb\approx \Zbb_+$. By Thm. \ref{lb15}, $\Zbb=\Zbb_{<0}\cup\Nbb$ is countably infinite, and hence $\Zbb\approx\Nbb$. It remains to prove $\Zbb\approx\Qbb$. By Schr\"oder-Bernstein, it suffices to prove $\Qbb\precsim\Zbb$.  By Thm. \ref{lb15} again, $\Zbb\times\Zbb\approx\Zbb$. By Exp. \ref{lb17}, there is a surjection from a subset of $\Zbb\times\Zbb$ to $\Qbb$. So $\Qbb\precsim\Zbb\times\Zbb\approx\Zbb$.
\end{proof}



Later, when we have learned Zorn's Lemma (an equivalent form of Axiom of Choice), we will be able to prove the following generalization of $\Nbb\times\Nbb\approx\Nbb$. So we defer the proof of the following theorem to a later section.

\begin{thm}\label{lb16}
Let $X$ be a infinite set. Then $X\times\Nbb\approx X$.
\end{thm}





Our next goal is to prove an exponential law $a^{b+c}=a^b\cdot a^c$ for cardinalities. For that purpose, we first need to define the set-theoretic operations that correspond to the summation $b+c$ and the exponential $a^b$.


\begin{df}
We write $X=\bigsqcup_{\alpha\in\scr A}A_\alpha$ \index{A@$\bigsqcup_{\alpha\in\scr A}A_\alpha$, the disjoint union} and call $X$ the \textbf{disjoint union} \index{00@Disjoint union} of $(A_\alpha)_{\alpha\in\scr A}$,  if $X=\bigcup_{\alpha\in\scr A}A_\alpha$ and $(A_\alpha)_{\alpha\in\scr A}$ is a family of pairwise disjoint sets (i.e. $A_\alpha\cap A_\beta=\emptyset$ if $\alpha\neq\beta$). If moreover $\scr A=\{1,\dots,n\}$, we write $X=A_1\sqcup\cdots\sqcup A_n$.
\end{df}

\begin{df}
Let $X,Y$ be sets. Then \index{YX@$Y^X$, the set of functions $X\rightarrow Y$}
\begin{align}
Y^X=\{\text{functions }f:X\rightarrow Y\}
\end{align}
A more precise definition of $Y^X$ (in the spirit of \eqref{eq2}) is $\{f\in X\times Y \mid f:X\rightarrow Y\text{ is a function}\}$. Note that by Rem. \ref{lb40},
\begin{align}
Y^\emptyset=\{\emptyset\}  \label{eq10}
\end{align}
\end{df}

This new notation is compatible with the old one $Y^n=Y\times\cdots\times Y$:
\begin{eg}
Let $n\in\Zbb_+$. We have $Y^{\{1,\dots,n\}}\approx Y^n$ due to the bijection
\begin{align*}
Y^{\{1,\dots,n\}}\rightarrow Y^n\qquad f\mapsto (f(1),\dots,f(n))
\end{align*}
\end{eg}

\begin{rem}\label{lb18}
The above example suggests that in the general case that $X$ is not necessarily finite, we can view each function $f:X\rightarrow Y$ as $(f(x))_{x\in X}$, an \textbf{indexed family of elements} of $Y$ with index set $X$. Thus, intuitively and hence not quite rigorously, 
\begin{align}
Y^X=\underbrace{Y\times Y\times\cdots}_{\card(X)\text{ pieces}} \label{eq11}
\end{align}
This generalizes the intuition in Def. \ref{lb13} that a function $f:\Zbb_+\rightarrow Y$ is equivalently a sequence $(f(1),f(2),f(3),\dots)$.

The viewpoint that $Y^X$ is a \textbf{product space} with index set $X$ is very important and will be adopted frequently in this course. More generally, we can define:\hfill\qedsymbol
\end{rem}

\begin{df}
Let $(X_i)_{i\in I}$ be a family of sets with index set $I$. Their \textbf{product space} \index{00@Product space} \index{X@$\prod_{i\in I}X_i$} is defined by
\begin{align*}
\prod_{i\in I}X_i =\{f\in \fk X^I:f(i)\in X_i\text{ for all }i\in I \}
\end{align*}
where $\fk X=\bigcup_{i\in I}X_i$. If each $X_i$ is nonempty, then $\prod_{i\in I}X_i$ is nonempty by Axiom of Choice. An element of $\prod_{i\in I}X_i$ is also written as $(f_i)_{i\in I}$ when the $i$-th component of it is $f_i\in X_i$.
\end{df}

In particular, if all $X_i$ are equal to $X$, then $X^I=\prod_{i\in I}X$.



\begin{eg}\label{lb11}
Let $X$ be a set. For each $A\subset X$, define the \textbf{characteristic function} \index{00@Characteristic function} \index{zz@$\chi_A$, the characteristic function of $A$} $\chi_A:X\rightarrow\{0,1\}$ to be
\begin{align*}
\chi_A(x)=\left\{
\begin{array}{ll}
1&\text{if }x\in A\\
0&\text{if }x\notin A
\end{array}
\right.
\end{align*}
Then we have
\begin{align*}
2^X\approx \{0,1\}^X
\end{align*}
since the following map is bijective:
\begin{gather*}
2^X\rightarrow\{0,1\}^X\qquad A\mapsto\chi_A
\end{gather*}
Its inverse is $f\in\{0,1\}^X\mapsto f^{-1}(1)\in 2^X$.
\end{eg}

\begin{pp}[Exponential Law]\label{lb10}
Suppose that $X=A_1\sqcup\cdots\sqcup A_n$. Then
\begin{align*}
Y^X\approx Y^{A_1}\times \cdots\times Y^{A_n}
\end{align*}
\end{pp}

\begin{proof}
We have a bijection
\begin{gather}\label{eq9}
\begin{gathered}
\Phi:Y^X\rightarrow Y^{A_1}\times \cdots\times Y^{A_n}\\
f\mapsto (f|_{A_1},\dots,f|_{A_n})
\end{gathered}
\end{gather}
where we recall that $f|_{A_i}$ is the restriction of $f$ to $A_i$. 
\end{proof}

\begin{exe}
Assume that $A_1,\dots,A_n$ are subsets of $X$. Define $\Phi$ by \eqref{eq9}. Prove that $\Phi$ is injective iff $X=A_1\cup\cdots\cup A_n$. Prove that $\Phi$ is surjective iff $A_1,\dots, A_n$ are pairwise disjoint. 
\end{exe}

\begin{co}\label{lb12}
Let $X,Y$ be finite sets with cardinalities $m,n\in\Nbb$ respectively. Assume that $Y\neq\emptyset$. Then $Y^X$ is a finite set with cardinality $n^m$.
\end{co}

\begin{proof}
The special case that $m=0$ (i.e. $X=\emptyset$, cf. \eqref{eq10}) and $m=1$ is clear. When $m>1$, assume WLOG that $X=\{1,\dots,m\}$. Then $X=\{1\}\sqcup\cdots\sqcup\{m\}$. Apply Prop. \ref{lb10} to this disjoint union. We see that $Y^X\simeq Y\times \cdots\times Y\simeq\{1,\dots,n\}^m$ has $n^m$ elements.
\end{proof}



We end this section with some (in)equalities about the cardinalities of product spaces. To begin with, we write $X\precnsim Y$ (or $\card(X)<\card(Y)$) if $X\precsim Y$ and $X\napprox Y$.

\begin{pp}\label{lb14}
Let $X,Y$ be sets with $\card(Y)\geq 2$ (i.e. $Y$ has at least two elements). Then $X\precnsim Y^X$. In particular, $X\precnsim 2^X$.
\end{pp}

\begin{proof}
The case $X=\emptyset$ is obvious since $0<1$. So we assume $Y\neq\emptyset$. Clearly $2^X\simeq\{0,1\}^X$ is $\precsim Y^X$. So it suffices to prove $X\precnsim 2^X$. Since the map $X\rightarrow 2^X$ sending $x$ to $\{x\}$ is injective, $X\precsim 2^X$. Let us prove $X\napprox 2^X$.

Assume that $X\approx 2^X$. So there is a bijection $\Phi:X\rightarrow 2^X$ sending each $x\in X$ to a subset $\Phi(x)$ of $X$. Motivated by Russell's Paradox \eqref{eq12}, we define
\begin{align*}
S=\{x\in X:x\notin \Phi(x)\}
\end{align*}
Since $\Phi$ is surjective, there exists $y\in X$ such that $S=\Phi(y)$. If $y\in\Phi(y)$, then $y\in S$, and hence $y\notin \Phi(y)$ by the definition of $S$. If $y\notin\Phi(y)$, then $y\notin S$, and hence $y\in\Phi(y)$ by the definition of $S$. This gives a contradiction.
\end{proof}


\begin{rem}
Write $\{1,\dots,n\}^X$ as $n^X$ for short. \index{nX@$n^X=\{1,\dots,n\}^X$} Assuming that real numbers have decimal, binary, or (more generally) base-$n$ representations where $n\in\Zbb_{\geq 2}$, then  $\Rbb\approx n^{\Nbb}$. So by Prop. \ref{lb14}, $\Nbb\precnsim\Rbb$, i.e. \emph{$\Rbb$ is uncountable}. The base-$n$ representations of real numbers suggest that $\card(n^\Nbb)$ is independent of $n$. This fact can be proved by elementary methods without  resorting to the analysis of real numbers:
\end{rem}

\begin{thm}
Let $X$ be an infinite set. Then
\begin{align*}
2^X\approx 3^X\approx 4^X\approx\cdots\approx \Nbb^X
\end{align*}
\end{thm}

\begin{proof}
First, we assume that $X=\Nbb$. Clearly, for each $n\in\Zbb_{\geq 2}$ we have $2^X\precsim n^X\precsim \Nbb^X$. Since elements of $\Nbb^X$ are subsets of $X\times\Nbb$ (i.e. elements of $2^{X\times\Nbb}$), we have
\begin{align*}
\Nbb^X\subset 2^{X\times\Nbb}\simeq 2^X
\end{align*}
since $X\times\Nbb\approx X$ by Thm. \ref{lb15}. So $2^X\approx n^X\approx \Nbb^X$ by Schr\"oder-Bernstein.

As pointed out earlier (cf. Thm. \ref{lb16}), it can be proved by Zorn's Lemma that $X\times\Nbb\approx X$ for every infinite set $X$. So the same conclusion holds for such $X$.
\end{proof}

\newpage

\section{Metric spaces}


We first give an informal introduction to metric spaces, hoping to motivate the readers from a (relatively) historical perspective. It is okay if you do not understand all of the concepts mentioned in the introduction on the first read. Simply return to this section when you feel unmotivated while formally studying these concepts in later sections. (The same suggestion applies to all the introductory sections and historical comments in our notes.)









\subsection{Introduction: what is point-set topology?}\label{lb55}


\begin{displayquote}
\small The method which has been used with success by Volterra and Hilbert consists in observing that a function (for instance a continuous one) can be replaced by a countable infinity of parameters. One treats the problem first as though one had only a finite number of parameters and then one goes to the limit... We believe that this method has played a useful role because it followed intuition, but that its time has passed... The most fruitful method in functional analysis seems to us to treat the element of which the functional depends directly as a variable and in the form in which it presents itself naturally.

\hfill ---- Fr\'echet, 1925 ~~(cf. \cite[Sec. 13.8]{Jah})
\end{displayquote}




In this chapter, we begin the study of point-set topology by learning one of its most important notions: metric spaces. Similar to \cite{Rud-P}, we prefer to introduce metric spaces and basic point-set topology at the early stage of our study. An obvious reason for doing so is that metric spaces provide a uniform language for the study of basic analysis problems in $\Rbb,\Rbb^n,\Cbb^n$, and more generally in function spaces such as the space of continuous functions $C([a,b])$ on the interval $[a,b]\subset\Rbb$. With the help of such a language, for example, many useful criteria for the convergence of series in $\Rbb$ and $\Cbb$ (e.g. root test, ratio test) are generalized straightforwardly to criteria for the \emph{uniform} convergence of series of functions in $C([a,b])$.

Point-set topology was born in 1906 when Fr\'echet defined metric spaces, motivated mainly by the study of function spaces in analysis (i.e. \emph{functional analysis}). Indeed, point-set topology and functional analysis are the two faces of the same coin: they both originated from the study of \textbf{functionals}, \index{00@Functionals} i.e., functions of functions. See for example \eqref{eq24}. The core ideas of point-set topology are as follows:
\begin{enumerate}[label=(\arabic*)]
\item Take $X$ to be a set of functions defined on a ``classical space" (e.g. the set of all continuous functions $f:[a,b]\rightarrow\Cbb$). Then a functional is a function  $S:X\rightarrow \Cbb$. This is a generalization of functions on $\Rbb,\Cbb,\Rbb^n,\Cbb^n$ or on their subsets.
\item Unlike $\Rbb^n$, a function space $X$ is usually ``infinite dimensional". Thus, one may think that a functional $S$ is a function with infinite variables. In point-set topology, this viewpoint is abandoned; the philosophy of point-set topology is diametrically opposed to that of multivariable calculus.\footnote{Very often, the formula of $S(f)$ involves an integral. See e.g. \eqref{eq24}. Mathematicians (e.g. Volterra, L\'evy, Fredholm, and early Hilbert) used to study $S(f)$ by discretizing $S(f)$, i.e., by approximating integrals by finite sums. Thus, $S$ is approximated by a sequence of functions with $n$ variables where $n\rightarrow\infty$. This viewpoint is abandoned in point-set topology.} Instead, \ul{one should view a functional $S$ as a function with one variable $x$}, where $x$ denotes a general point of the function space $X$.
\item Rather than looking at each variable/component and doing explicit muti-variable calculations, one uses geometric intuitions to study the analytic properties of functionals.\footnote{This is similar to linear algebra where one prefers vectors, linear subspaces, and linear operators to $n$-tuples, sets of solutions, and matrices.} \ul{These geometric intuitions (e.g. distances, open balls, convergence) are borrowed from  $\Rbb$ and $\Rbb^n$}  and are mostly irrelevant to dimensions or numbers of variables.
\end{enumerate}



(Sequential) \textbf{compactness}, \textbf{completeness}, and \textbf{separability} are prominent geometric properties that are useful in the study of the analytic properties of functionals. The importance of these three notions  was  already recognized by Fr\'echet by the time he defined metric spaces. The study of these three properties will be a main theme of our course.


Consider sequential compactness for example. The application of compactness to function spaces originated from the problems in calculus of variations. For instance, let $L(x,y,z)$ be a polynomial or (more generally) a continuous function in $3$ variables. We want to find a ``good" (e.g. differentiable) function $f:[0,1]\rightarrow \Rbb$ minimizing or maximizing the expression
\begin{subequations}\label{eq24}
\begin{align}
S(f)=\int_0^1 L(t,f(t),f'(t))dt
\end{align}
This is the general setting of Lagrangian mechanics. In the theory of integral equations, one considers the extreme values and points of the functional
\begin{align}
S(f)=\int_0^1\int_0^1 f(x)K(x,y)\ovl{f(y)}dxdy
\end{align}
\end{subequations}
where $K:[0,1]^2\rightarrow\Rbb$ is continuous and $f:[0,1]\rightarrow\Cbb$ is subject to the condition $\int_0^1 |f(x)|^2dx\leq 1$. Any $f$ maximizing (resp. minimizing) $S(f)$ is an eigenvector of the linear operator $g\mapsto \int_0^1 K(x,y)g(y)dy$ with maximal (resp. minimal) eigenvalue.


As we shall learn, (sequential) compactness is closely related to the problem of finding (or proving the existence of) maximal/minimal values of a continuous function and the points at which the function attains its maximum/minimum. So, in 19th century, when people were already familiar with sequential compactness in $\Rbb^n$ (e.g. Bolzano-Weierstrass theorem, Heine-Borel theorem), they applied compactness to function spaces and functionals. The idea is simple: Suppose we are given $X$, a set of functions (say continuous and differentiable) from $[a,b]$ to $\Rbb$. We want to find $f\in X$ maximizing $S(f)$. Here is an explicit process (see also the proof of Lem. \ref{lb56}):
\begin{itemize}
\item[(A)] Find a sequence $(f_n)_{n\in\Zbb_+}$ in $X$ such that $S(f_n)$ increases to $M=\sup S(X)$. 
\item[(B)] Define convergence in $X$ in a suitable way, and verify that $S:X\rightarrow\Rbb$ is continuous (i.e. if $f_n$ converges to $f$ in the way we define, then $S(f_n)\rightarrow S(f)$). 
\item[(C)] Suppose we can find a subsequence $(f_{n_k})_{k\in\Zbb_+}$ converging to some $f\in X$, then $S$ attains its maximum at $f$. In particular, $S(f)=M$ and hence $M<+\infty$. 
\end{itemize}


To carry out step (B), we need to define suitable geometric structures for a function space $X$ so that the convergence of sequences in $X$ and the continuity of functions $S:X\rightarrow\Rbb$ can be defined and studied in a similar pattern as that for $\Rbb^n$. \textbf{Metric} (of a metric space) and \textbf{topology} (of a topological space) are such geometric structures. As we shall learn, the topology of a metric space is uniquely determined by the convergence of sequences in this space. 

Step (C) can be carried out if every sequence in $X$ has a convergent subsequent, i.e., if $X$ is sequentially compact. Thus, we need a good criterion for sequential compactness for subsets of a function space.  Arzel\`a-Ascoli theorem, the  $C([a,b])$-version of Heine-Borel theorem, is such a criterion. This famous theorem was proved in late 19th century (and hence before the birth of point-set topology), and it gave an important motivation for Fr\'echet to consider  metric spaces in general. We will learn this theorem at the end of the first semester.


To summarize: Metric spaces are defined not just for fun. We introduce such geometric objects because we want to study the convergence of sequences and the analytic properties of continuous functions using geometric intuitions. And moreover, the examples we are interested in are not just subsets of $\Rbb^n$, but also subsets of function spaces. With this in mind, we now begin our journey into point-set topology.


\subsection{Basic definitions and examples}



\begin{df}
Let $X$ be a set. A function $d:X\times X\rightarrow\Rbb_{\geq0}$ is called a \textbf{metric} if for all $x,y,z\in X$ we have
\begin{enumerate}[label=(\arabic*)]
\item $d(x,y)=d(y,x)$.
\item $d(x,y)=0$ iff $x=y$.
\item (Triangle inequality) \index{00@Triangle inequality} $d(x,z)\leq d(x,y)+d(y,z)$.
\end{enumerate}
The pair $(X,d)$, or simply $X$, is called \index{00@Metric space} a \textbf{metric space}. If $x\in X$ and $r\in(0,+\infty]$,\footnote{We want open and closed balls to be nonempty. So we assume $r\neq0$ only for open balls.} the set \index{Br@$B_X(x,r)=B(x,r)$ and $\ovl B_X(x,r)=\ovl B(x,r)$}
\begin{align*}
B_X(x,r)=\{y\in X:d(x,y)<r\}
\end{align*}
often abbreviated to $B(x,r)$, is called the \textbf{open ball} with center $x$ and radius $r$. If $r\in[0,+\infty)$,
\begin{align*}
\ovl B_X(x,r)=\{y\in X:d(x,y)\leq r\}
\end{align*}
also abbreviated to $\ovl B(x,r)$, is called the \textbf{closed ball} with center $x$ and radius $r$.
\end{df}


We make some comments on this definition.


\begin{rem}
That ``$d(x,y)=0$ iff $x=y$" is very useful. Think about $X$ as a set of functions $[0,1]\rightarrow\Rbb$ and $d$ is a metric on $X$. To show that $f,g\in X$ are equal, instead of checking that infinitely many values are equal (i.e. $f(t)=g(t)$ for all $t\in\Rbb$), it suffices to check that one value (i.e. $d(f,g)$) is zero.
\end{rem}

\begin{rem}
Triangle inequality clearly implies ``polygon inequality":
\begin{align}
d(x_0,x_n)\leq\sum_{j=1}^n d(x_{j-1},x_j)
\end{align}
\end{rem}

\begin{rem}\label{lb20}
Choose distinct points $x,y\in X$. Then $x,y$ are separated by two open balls centered at them: there exists $r,\rho>0$ such that $B(x,r)\cap B(y,\rho)=\emptyset$. This is called the \textbf{Hausdorff property}. 

To see this fact, note that $d(x,y)>0$. Choose $r,\rho$ such that $r+\rho\leq d(x,y)$. If $z\in B(x,r)\cap B(y,\rho)$, then $d(x,z)+d(y,z)<r+\rho\leq d(x,y)$, contradicting triangle inequality.

We will see (cf. Prop. \ref{lb21}) that Hausdorff property guarantees that any sequence in a metric space cannot converge to two different points. Intuition: one cannot find a point which is very close to $x$ and $y$ at the same time.  \hfill\qedsymbol
\end{rem}



We give some examples, and leave it to the readers to check that they satisfy the definition of metric spaces. We assume that square roots of positive real numbers can be defined. (We will rigorously define square roots after we define $e^x$ using the series $\sum_{n\in\Nbb}x^n/n!$.)


\begin{eg}
$\Rbb$ is a metric space if we define $d(x,y)=|x-y|$
\end{eg}


\begin{eg}
On $\Rbb^n$, we can define \textbf{Euclidean metric} \index{00@Euclidean metric}
\begin{align*}
d(x,y)=\sqrt{(x_1-y_1)^2+\cdots+(x_n-y_n)^2}
\end{align*}
if $x_\blt,y_\blt$ are the components of $x,y$. The following are also metrics:
\begin{gather*}
d_1(x,y)=|x_1-y_1|+\cdot+|x_n-y_n|\\
d_\infty(x,y)=\max\{|x_1-y_1|,\dots,|x_n-y_n|\}
\end{gather*}
\end{eg}

\begin{eg}
The \textbf{Euclidean metric} on $\Cbb^n$ is
\begin{align*}
d(z,w)=\sqrt{|z_1-w_1|^2+\cdots+|z_n-w_n|^2}
\end{align*}
which agrees with the Euclidean metric on $\Rbb^{2n}$. The following are also metrics:
\begin{gather*}
d_1(z,w)=|z_1-w_1|+\cdot+|z_n-w_n|\\
d_\infty(z,w)=\max\{|z_1-w_1|,\dots,|z_n-w_n|\}
\end{gather*}
\end{eg}

\begin{cv}\label{lb33}
Unless otherwise stated, the metrics on $\Rbb^n$ and $\Cbb^n$ (and their subsets) are assumed to be the Euclidean metrics.
\end{cv}


\begin{rem}
One may wonder what the subscripts $1,\infty$ mean. This notation is actually due to the general fact that
\begin{equation*}
d_p(z,w)=\sqrt[p]{|z_1-w_1|^p+\cdots+|z_n-w_n|^p}
\end{equation*}
is a metric where $1\leq p< +\infty$, and $d_\infty=\lim_{q\rightarrow +\infty}d_q$. It is not easy to prove that $d_p$ satisfies triangle inequality: one needs Minkowski inequality. For now, we will not use such general $d_p$. And we will discuss Minkowski inequality in later sections.
\end{rem}


\begin{eg}\label{lb19}
Let $X=X_1\times\cdots\times X_N$ where each $X_i$ is a metric space with metric $d_i$. Write $x=(x_1,\dots,x_N)\in X$ and $y=(y_1,\dots,y_N)\in Y$. Then the following are metrics on $X$:
\begin{gather*}
d(x,y)=d_1(x_1,y_1)+\cdots+d_N(x_N,y_N)\\
\delta(x,y)=\max\{d_1(x_1,y_1),\dots,d_N(x_N,y_N)\}\\
\rho(x,y)=\sqrt{d_1(x_1,y_1)^2+\cdots+d_N(x_N,y_N)^2}
\end{gather*}
With respect to the metric $\delta$, the open balls of $X$ are ``polydisks"
\begin{align*}
B_X(x,r)=B_{X_1}(x_1,r)\times\cdots\times B_{X_N}(x_N,r)
\end{align*}
\end{eg}


There is no standard choice of metric on the product of metric spaces. $d,\delta,\rho$ are all good, and they are equivalent in the following sense:

\begin{df}
We say that two metrics $d_1,d_2$ on a set $X$ are \index{00@Equivalent metrics} \textbf{equivalent} and write $d_1\approx d_2$, if there exist $\alpha,\beta>0$ such that  for any $x,y\in X$ we have
\begin{gather*}
d_1(x,y)\leq\alpha d_2(x,y)\qquad d_2(x,y)\leq\beta d_1(x,y)
\end{gather*}  
This is an equivalence relation. More generally, we may write $d_1\precsim d_2$ if $d_1\leq \alpha d_2$ for some $\alpha>0$. Then $d_1\approx d_2$ iff $d_1\precsim d_2$ and $d_2\precsim d_1$.
\end{df}



\begin{eg}
In Exp. \ref{lb19}, we have $\delta\leq \rho\leq d\leq N\delta$. So $\delta\approx\rho\approx d$.
\end{eg}

\begin{cv}\label{lb32}
Given finitely many metric spaces $X_1,\dots,X_N$, the metric on their product space $X=X_1\times\cdots\times X_N$ is chosen to be any one that is equivalent to the ones defined in Exp. \ref{lb19}. In the case that each $X_i$ is a subset of $\Rbb$ or $\Cbb$, we follow Convention \ref{lb33} and choose the metric on $X$ to be the Euclidean metric (unless otherwise stated).
\end{cv}


\begin{df}\label{lb43}
Let $(X,d)$ be a metric space. Then a \textbf{metric subspace} \index{00@Metric subspace} is denotes an object $(Y,d|_Y)$ where $Y\subset X$ and $d|_Y$ is the restriction of $d$ to $Y$, namely, for all $y_1,y_2\in Y$ we set
\begin{align*}
d|_Y(y_1,y_2)=d(y_1,y_2)
\end{align*}
\end{df}

\begin{cv}\label{lb76}
Suppose $Y$ is a subset of a given metric space $(X,d)$. Unless otherwise stated, the metric of $Y$ is chosen to be $d|_Y$ whenever $Y$ is viewed as a metric space. For example, the metric of any subset of $\Rbb^n$ is assumed to be the Euclidean metric, unless otherwise stated.
\end{cv}



\subsection{Convergence of sequences} \label{lb73}

\begin{df}
Let $(x_n)_{n\in\Zbb_+}$ be a sequence in a metric space $X$. Let $x\in X$. We say that $x$ is the \textbf{limit} of $x_n$ and write $\displaystyle\lim_{n\rightarrow\infty}x_n=x$ (or $x_n\rightarrow x$), if:
\begin{itemize}
\item For every real number $\varepsilon>0$ there exists $N\in\Zbb_+$ such that for every $n\geq N$ we have $d(x_n,x)<\varepsilon$. 
\end{itemize}
Equivalently, this means that every (nonempty) open ball centered at $x$ contains \textbf{all but finitely many} \index{00@All but finitely many $x_n$} $x_n$.\footnote{``All but finitely many $x_n$ satisfies..." means ``for all but finitely many $n$, $x_n$ satisfies...". It does NOT mean that ``all but finitely many elements of the set $\{x_n:n\in\Zbb_+\}$ satisfies...".} 
\end{df}

\begin{rem}\label{lb100}
The negation of $x_n\rightarrow x$ is clear: 
\begin{itemize}
\item There exists $\eps>0$ such that for all $N\in\Zbb_+$ there exists $n\geq N$ such that $d(x_n,x)\geq\eps$.
\end{itemize}
Namely, one changes each ``for all" to ``there exists", changes each ``there exists" to ``for all", and negate the last sentence.
\end{rem}


\begin{exe}
Show that in the above definition of limits,  it suffices to consider rational numbers $\varepsilon>0$. (Note: You need to use Prop. \ref{lb2}.) 
\end{exe}
This exercise implies that the definition of limits does not require the existence of real numbers, i.e., does not assume Thm. \ref{lb3}. Indeed, we will use limits of sequences (and ``double sequences") to prove Thm. \ref{lb3}.


In many textbooks and research papers, you will see phrases such as \index{00@Sufficiently large}
\begin{gather}
\text{$x_n$ satisfies property $P$ for } \textbf{sufficiently large} \text{ $n$}
\end{gather}
This means that ``there exists $N\in\Zbb_+$ such that $P$ holds for all $n\geq N$". (We also say that $x_n$ \textbf{eventually} satisfies $P$.) Then $\lim_{n\rightarrow\infty} x_n=x$ means that ``for every $\varepsilon>0$, we have $d(x_n,x)<\varepsilon$ for sufficiently large $n$". 

\begin{pp}\label{lb21}
Any sequence $(x_n)_{n\in\Zbb_+}$ in a metric space $X$ has at most one limit.
\end{pp}

\begin{proof}
Suppose $(x_n)_{n\in\Zbb_+}$ converges to $x,y\in X$ where $x\neq y$. By Hausdorff property (Rem. \ref{lb20}), there exist $r,\rho>0$ such that $B(x,r)\cap B(y,\rho)=\emptyset$. By the definition of $x_n\rightarrow x$, there exists $N_1\in\Zbb_+$ such that $x_n\in B(x,r)$ for all $n\geq N_1$. Similarly, $x_n\rightarrow y$ means that there is $N_2\in\Zbb_+$ such that $x_n\in B(y,\rho)$ for all $n\geq N_2$. Choose any $n\geq N_1,N_2$ (e.g. $n=\max\{N_1,N_2\}$). Then $x_n\in B(x,r)\cap B(y,\rho)=\emptyset$, impossible.
\end{proof}


\subsubsection{Methods for proving convergence and computing limits}



\begin{eg}
$\dps \lim_{n\rightarrow\infty}\frac 1n=0$.
\end{eg}


\begin{proof}
Choose any $\varepsilon\in\Qbb_{>0}$. By Archimedean property, there exists $N\in\Zbb_+$ such that $N\varepsilon>1$, i.e. $1/N<\varepsilon$. Thus, for all $n\geq N$ we have $1/n<\varepsilon$.
\end{proof}

\begin{pp}
Let $\Fbb\in\{\Qbb,\Rbb\}$ and $(x_n),(y_n)$ be sequences in $\Fbb$ converging to $x,y\in\Rbb$. If $x_n\leq y_n$ for all $n$, then $x\leq y$.
\end{pp}

\begin{proof}
If $y<x$, let $\varepsilon=x-y$. Then all but finitely many members of $(x_n)$ are in $(x-\varepsilon/2,x+\varepsilon/2)$, and all but finitely many members of $(y_n)$ are in $(y-\varepsilon/2,y+\varepsilon/2)$. Since $y+\eps/2<x-\eps/2$, there must exist $n$ such that $y_n<x_n$.
\end{proof}


\begin{df}
If $A$ and $B$ are posets (or more generally, preordered sets, see Def. \ref{lb116}), we say a function $f:A\rightarrow B$ is \textbf{increasing} \index{00@Increasing and decreasing} \index{00@Strictly increasing and strictly decreasing} (resp. \textbf{strictly increasing}), if for each $x,y\in A$ we have
\begin{gather*}
x\leq y\qquad\Longrightarrow\qquad f(x)\leq f(y)\\
\text{resp.}\\
x<y\qquad\Longrightarrow \qquad f(x)<f(y)
\end{gather*}
We leave the definitions of \textbf{decreasing} and \textbf{strictly decreasing} to the readers. We say that $f$ is \index{00@Monotonic} \index{00@Strictly monotonic} \textbf{monotonic} (resp. \textbf{strictly monotonic}), if $f$ is either increasing or decreasing (resp. either strictly increasing or strictly decreasing).
\end{df}


\begin{pp}\label{lb57}
Let $(x_n)_{n\in\Zbb}$ be a sequence in $[a,b]\subset\Rbb$. If $(x_n)$ is increasing (resp. decreasing), then $\dps\lim_{n\rightarrow \infty}x_n$ equals $\dps\sup\{x_n:n\in\Zbb_+\}$ (resp. $\dps\inf\{x_n:n\in\Zbb_+\}$).
\end{pp}

\begin{proof}
Assume $(x_n)$ increases. (The case of decreasing is similar and hence its proof is omitted.) Let $A=\sup\{x_n:n\in\Zbb_+\}<+\infty$. Then for each $\eps>0$ there is $N$ such that $x_N>A-\eps$ (since $A-\eps$ is not an upper bound). Since $(x_n)$ is increasing, for all $n\in\Nbb$ we have $A-\eps<x_n\leq A$ and so $|x_n-A|<\eps$.
\end{proof}



\begin{eg}\label{lb27}
Let $(x_n)_{n\in\Zbb_+}$ be a sequence in a metric space $X$, and let $x\in X$. It is easy to see that
\begin{align*}
\lim_{n\rightarrow\infty} x_n=x\qquad\Longleftrightarrow \qquad \lim_{n\rightarrow\infty} d(x_n,x)=0
\end{align*}
\end{eg}

\begin{eg}\label{lb28}
Suppose that $(a_n)$ and $(b_n)$ are sequences in $\Rbb_{\geq 0}$, that $a_n\leq b_n$ for all $n$, and that $b_n\rightarrow 0$. Then  $a_n\rightarrow 0$. 
\end{eg}
\begin{proof}
For each $\varepsilon>0$, $[0,\varepsilon)$ contains all but finitely many $b_n$, and hence all but finitely many $a_n$.
\end{proof}


More generally, we have:

\begin{pp}[\textbf{Squeeze theorem}]\label{lb29}\index{00@Squeeze theorem}
Suppose that $(x_n)$ is a sequence in a metric space $X$. Let $x\in X$. Suppose that there is a sequence $(a_n)$ in $\Rbb_{\geq 0}$ such that $\dps\lim_{n\rightarrow\infty}a_n=0$ and that $d(x_n,x)\leq a_n$ for all $n$. Then $\dps\lim_{n\rightarrow\infty} x_n=x$.
\end{pp}

\begin{proof}
This follows immediately from Exp. \ref{lb27} and \ref{lb28}.
\end{proof}

The above proposition explains why many people say that ``analysis is the art of inequalities": It transforms the problem of convergence to the problem of finding a sequence $(a_n)\in\Rbb_{\geq 0}$ converging to $0$ such that the inequality $d(x_n,x)\leq a_n$ holds. And very often, a good (hard) analyst is one who knows how to find such good sequences!






\begin{pp}\label{lb38}
Let $X=X_1\times\cdots\times X_N$ be a product of metric spaces $(X_i,d_i)$. Let $d$ be any of the three metrics of $X$ in Exp. \ref{lb19}. Let $\mbf x_n=(x_{1,n},\dots,x_{N,n})$ be a sequence in $X$. Let $\mbf y=(y_1,\dots,y_N)$. Then 
\begin{align*}
\lim_{n\rightarrow\infty} \mbf x_n=\mbf y\qquad\Longleftrightarrow \qquad \lim_{n\rightarrow\infty} x_{i,n}=y_i~~(\forall 1\leq i\leq N)
\end{align*}
\end{pp}

\begin{proof}
We let $d$ be the metric $\delta$ in Exp. \ref{lb19}, i.e. defined by $\max_j d_j(x_j,y_j)$. Now choose a sequence $(\mbf x_n)$ and an element $\mbf y$ in $X$. Then
\begin{align}
\mbf x_n\rightarrow \mbf y~~\Longleftrightarrow~~ d_X(\mbf x_n,\mbf y)\rightarrow 0 ~~\Longleftrightarrow~~ \max_{1\leq j\leq N} d_j(x_{j,n},y_j)\rightarrow 0  \label{eq13}
\end{align}


Suppose that the RHS of \eqref{eq13} is true. Fix any $1\leq i\leq N$. Then $d_i(x_{i,n},y_i)\leq \max_j d_j(x_{j,n},y_j)$. So $x_{i,n}\rightarrow y_i$ by Prop. \ref{lb29}.

Conversely, assume that for every $i$ we have $x_{i,n}\rightarrow y_i$. Then for every $\eps>0$ there is $K_i\in\Zbb_+$ such that $d_i(x_{i,n},y_i)<\varepsilon$ for every $n\geq K_i$. Let $K=\max\{K_1,\dots,K_N\}$. Then for all $n\geq K$ we have $\max_j d_j(x_{j,n},y_j)<\eps$. This proves the RHS of \eqref{eq13}.

If $d$ is one of the other two metrics in Exp. \ref{lb19}, one can either use a similar argument, or use the following important (but easy) fact.
\end{proof}





\begin{pp}
Let $d,\delta$ be two equivalent metrics on a set $X$. Let $(x_n)_{n\in\Zbb_+}$ and $x$ be in $X$. Then $(x_n)$ converges to $x$ under the metric $d$ iff  $(x_n)$ converges to $x$ under $\delta$. Namely, $d(x_n,x)\rightarrow 0$ iff $\delta(x_n,x)\rightarrow 0$.
\end{pp}

\begin{proof}
Prove it yourself. (Or see Prop. \ref{lb48}.)
\end{proof}

More useful formulas about limit will be given in Exp. \ref{lb111}.







\subsubsection{Criteria for divergence}\label{lb119}

\begin{df}
A subset $E$ of a metric space $(X,d)$ is called \index{00@Bounded subset} \textbf{bounded} if either $E=\emptyset$ or there exist $p\in X$ and $R\in\Rbb_{>0}$ such that $E\subset B_X(p,R)$. If $X$ is bounded, we also say that $d$ is a \textbf{bounded metric}. \index{00@Bounded metric}
\end{df}

\begin{rem}
Note that if $E$ is bounded, then  for \emph{any} $q\in X$ there exists $\wtd R\in\Rbb_{>0}$ such that $E\subset B_X(q,\wtd R)$. (Indeed, choose $\wtd R=R+d(p,q)$, then by triangle inequality, $B(p,R)\subset B(q,\wtd R)$.)
\end{rem}

Some easy examples are as follows.
\begin{eg}
In a metric space $X$, if $x\in X$ and $0<r<+\infty$, then $B(x,r)$ is bounded. Hence $\ovl B(x,r)$ is bounded (since it is inside $B(x,2r)$).
\end{eg}


%% Record #1 2023/09/18

Also, it is easy to see:
\begin{eg}\label{lb22}
A finite union of bounded subsets is bounded.
\end{eg}

\begin{pp}\label{lb24}
Let $(x_n)_{n\in\Zbb_+}$ be a convergent sequence in a metric space $X$. Then $(x_n)_{n\in\Zbb_+}$ is bounded.
\end{pp}

By saying that a sequence \index{00@Bounded sequence} $(x_n)_{n\in\Zbb_+}$ in $X$ is \textbf{bounded}, we mean that its range in $X$ (namely $\{x_n:n\in\Zbb_+\}$) is bounded.

\begin{proof}
Suppose that $x_n\rightarrow x$. Then for each $\varepsilon>0$, say $\varepsilon=1$, all but finitely many elements of $x_n$ (say $x_1,\dots,x_N$) are in $B(x,1)$. So this whole sequence is in $A=\{x_1\}\cup\cdots\{x_N\}\cup B(x,1)$. Since each $\{x_i\}$ is bounded, and since $B(x,1)$ is bounded, $A$ is bounded by Exp. \ref{lb22}.
\end{proof}


\begin{rem}\label{lb26}
Prop. \ref{lb24} gives our first criterion on divergence: If a sequence is unbounded (e.g. $x_n=n^2$), then it does not converge. But there are many bounded and divergent sequences. (See Exp. \ref{lb25}.) In this case, we need the second criterion: If a sequence has two subsequences converging to two different points, then this sequence diverge. (See Prop. \ref{lb23})
\end{rem}




\begin{df}
Let $(x_n)_{n\in\Zbb_+}$ be a sequence in a set $X$. If $(n_k)_{k\in\Zbb_+}$ is a strictly increasing sequence in $\Zbb_+$, we say that $(x_{n_k})_{k\in\Zbb_+}$ is a \textbf{subsequence} of $(x_n)_{n\in\Zbb_+}$. \index{00@Subsequence}
\end{df}



Thus, a subsequence of $(x_n)_{n\in\Zbb_+}$ is equivalently the restriction of the function $x:\Zbb_+\rightarrow X$ to an infinite subset of $\Zbb_+$.

\begin{pp}\label{lb23}
Let $(x_n)_{n\in\Zbb_+}$ be a sequence in a metric space $X$ converging to $x\in X$. Then every subsequence $(x_{n_k})_{k\in\Zbb_+}$ converges to $x$.
\end{pp}

\begin{proof}
For every $\varepsilon>0$, $B(x,\varepsilon)$ contains all but finitely many $\{x_n:n\in\Zbb_+\}$, and hence all but finitely many $\{x_{n_k}:k\in\Zbb_+\}$.
\end{proof}

\begin{eg}\label{lb25}
The sequence $x_n=(-1)^n$ in $\Rbb$ is divergent, because the subsequence $(x_{2k})_{k\in\Zbb_+}$ converges to $1$, whereas $(x_{2k-1})_{k\in\Zbb_+}$ converges to $-1$. 
\end{eg}




One may wonder if the two criteria in Rem. \ref{lb26} are complete in order to determine whether a sequence diverges. This is true for sequences in $\Rbb^n$. We will discuss this topic later. (See Cor. \ref{lb75}.)



\subsection{Continuous maps of metric spaces}\label{lb185}

Continuous maps are a powerful tool for showing that a sequence converges.


\begin{df}\label{lb31}
Let $f:X\rightarrow Y$ be a map of metric spaces. Let $x\in X$. We say that $f$ is \textbf{continuous at $x$} if one of the following equivalent conditions hold:
\begin{itemize}[align=left]
\item [(1)] For every sequence $(x_n)_{n\in\Zbb_+}$ in $X$, we have
\begin{align*}
\lim_{n\rightarrow\infty} x_n=x\qquad\Longrightarrow\qquad \lim_{n\rightarrow\infty} f(x_n)=f(x)
\end{align*}
\item[(2)] For every $\varepsilon>0$, there exists $\delta>0$ such that for every $p\in X$ satisfying $d(p,x)<\delta$, we have $d(f(p),f(x))<\varepsilon$.
\item[(2')] For every $\varepsilon>0$, there exists $\delta>0$ such that $B_X(x,\delta)\subset f^{-1}(B_Y(f(x),\varepsilon)))$.
\end{itemize}
We say that $f$ is a \textbf{continuous map/function}, if $f$ is continuous at every point of $X$.
\end{df}

\begin{proof}[Proof of the equivalence]
(2)$\Leftrightarrow$(2'): Obvious.

(2)$\Rightarrow$(1): Assume (2). Assume $x_n\rightarrow x$. For every $\varepsilon>0$, let $\delta>0$ be as in (2). Then since $x_n\rightarrow x$, there is $N\in\Zbb_+$ such that for all $n\geq N$ we have $d(x_n,x)<\delta$. By (2), we have $d(f(x_n),f(x))<\varepsilon$ for all $n\geq N$. This proves $f(x_n)\rightarrow f(x)$.

$\neg$(2)$\Rightarrow$ $\neg$(1): Assume that (2) is not true. Then there exists $\varepsilon>0$ such that for every $\delta>0$, there exists $p\in X$ such that $d(p,x)<\delta$ and $d(f(p),f(x))\geq\varepsilon$. Thus, for every $n\in\Zbb_+$, by taking $\delta=1/n$, we see that there exists $x_n\in X$ such that $d(x_n,x)<1/n$ and $d(f(x_n),f(x))\geq\varepsilon$. By Squeeze theorem (Prop. \ref{lb29}), $x_n\rightarrow x$. But $f(x_n)\nrightarrow f(x)$ (i.e. $d(f(x_n),f(x))\nrightarrow 0$). So (1) is not true.
\end{proof}

\begin{rem}
One can compare Def. \ref{lb31}-(1) to the definition of linear maps. A map is continuous iff it \emph{preserves the convergence of sequences}, i.e., iff it maps convergent sequences to convergent ones. A map (between vector spaces) is linear iff it perserves the addition and the scalar multiplication of vectors. In general, a good map between two sets with ``structures" is a map which preserves the structures. (Thus, linear combinations encode the linear structures of vector spaces. Similarly, the convergence of sequences remembers the ``topological" structures of metric spaces.) As another example, we will define an isometry of metric spaces to be one that preserves the metrics (the structures of metric spaces), see Exe. \ref{lb46}.
\end{rem}

\begin{rem}\label{lb115}
In this section, we mainly use Def. \ref{lb31}-(1) to study continuity. But in later sections we will also use Def. \ref{lb31}-(2'). An advantage of (2') is that it is more geometric. Indeed, if $X$ is a metric space and $E\subset X$, we say that $x\in E$ is an \textbf{interior point of $E$ in $X$} \index{00@Interior point} if there exists $\delta>0$ such that $B_X(x,\delta)\subset E$. For example, a point  $z\in\Cbb$ is an interior point of the closed unit disk $\ovl B_\Cbb(0,1)=\{w\in\Cbb:|w|\leq 1\}$ iff $|z|<1$. 

Thus, Def. \ref{lb31}-(2') says that for any map of metric spaces $f:X\rightarrow Y$ and $x\in X$, the following are equivalent:
\begin{itemize}
\item[(a)] $f$ is continuous at $x$.
\item[(b)] For each $\eps>0$, every $x\in X$ is an interior point of $f^{-1}\big(B_Y(f(x),\varepsilon)\big)$.
\end{itemize}
We say that a subset $U\subset X$ is \textbf{open} \index{00@Open set} if each point of $U$ is an interior point. For example, by triangle inequality, every open ball in a metric space is an open set. Thus, we have:
\begin{itemize}
\item A map of metric spaces $f:X\rightarrow Y$ is continuous iff the preimage under $f$ of every open ball of $Y$ is an open subset of $X$.
\end{itemize}

In the study of point-set topology, we will see that many properties can be studied in two approaches: using sequences (or using nets, the natural generalizations of sequences) and their convergence, and using open sets. The first example of such property is continuity, as we have seen in Def. \ref{lb31}. Another prominent example is sequential compactness vs. compactness. These two approaches represent two (very) different intuitions: one is dynamic, while the other is static and more geometric. (So it is surprising that these two very things are actually equivalent!) Sometimes both approaches work for a problem, but sometimes only one of them works, or one of them is much simpler. If you are a beginner in analysis and point-set topology, I suggest that whenever you see one approach applied to a problem, try to think about whether the other approach also works and which one is better.   \hfill\qedsymbol
\end{rem}


\subsubsection{Methods for proving continuity}


\begin{lm}\label{lb30}
Let $f:X\rightarrow Y$ be a map of metric spaces.  Let $(B_i)_{i\in I}$ be a collection of open balls in $X$ such that $X=\bigcup_{i\in I}B_i$. Suppose that for each $i$, the restriction $f|_{B_i}:B_i\rightarrow Y$ is continuous. Then $f$ is continuous. 
\end{lm}

This lemma shows that if we can prove that $f$ is ``locally" continuous, then $f$ is globally continuous. 

\begin{proof}
Choose $(x_n)$ in $X$ converging to $x\in X$. We shall show $f(x_n)\rightarrow f(x)$. Choose $i$ such that $x\in B_i$. Then one can find $\delta>0$ such that $B(x,\delta)\subset B_i$. (In the language of point-set topology: $x$ is an interior point of $B_i$.) To see this, write $B_i=B(y,r)$. Since $x\in B(y,r)$, we have $r-d(x,y)>0$. Choose $0<\delta\leq r-d(x,y)$. Then triangle inequality implies $B(x,\delta)\subset B(y,r)$. 

Since $x_n\rightarrow x$, there is $N\in\Zbb_+$ such that $x_n\in B(x,\delta)$ for all $n\geq N$. Thus, $(x_{k+N})_{k\in\Zbb_+}$ converges in $B_i$ to $x$. Since $f|_{B_i}$ is continuous, $\lim_{k\rightarrow\infty} f(x_{k+N})=f(x)$. So $f(x_n)\rightarrow f(x)$.
\end{proof}







\begin{df}
A map of metric spaces $f:X\rightarrow Y$ is called \index{00@Lipschitz continuous} \textbf{Lipschitz continuous} if there exists $L\in\Rbb_{>0}$ (called \textbf{Lipschitz constant}) \index{00@Lipschitz constant} such that for all $x_1,x_2\in X$,
\begin{align}
d_Y\big(f(x_1),f(x_2) \big)\leq L\cdot d_X(x_1,x_2) \label{eq14}
\end{align}
\end{df}

\begin{lm}\label{lb34}
Lipschitz continuous maps are continuous. 
\end{lm}

\begin{proof}
Suppose that $f:X\rightarrow Y$ is Lipschitz continuous with Lipschitz constant $L$. Suppose $x_n\rightarrow x$ in $X$. Then $L\cdot d(x_n,x)\rightarrow 0$. By \eqref{eq14} and Squeeze theorem (Prop. \ref{lb29}), $f(x_n)\rightarrow f(x)$. (You can also use Def. \ref{lb31}-(2) to prove this lemma.)
\end{proof}

\begin{eg}\label{lb35}
Let $\Fbb\in\{\Qbb,\Rbb,\Cbb\}$. The map $z\in\Fbb\setminus \{0\}\mapsto z^{-1}\in\Fbb$ is continuous.
\end{eg}



\begin{proof}
Let this map be $f$. Since $\Fbb$ is covered by open balls $B(z,\delta)$ where $z\in\Fbb\setminus\{0\}$ and $0<\delta<|z|$, by Lem. \ref{lb30}, it suffices to prove that $f$ is continuous when restricted to every such $B(z,\delta)$. Let $\eps=|z|-\delta>0$. Choose $x,y\in B(z,\delta)$. Then $|x|=|x-z+z|\geq |z|-|z-x|>\eps$ by triangle inequality. Similarly, $|y|>\eps$. So
\begin{align*}
|f(x)-f(y)|=|x^{-1}-y^{-1}|=|x-y|/|xy|\leq \eps^{-2}|x-y|
\end{align*}
So $f|_{B(z,\delta)}$ has Lipschitz constant $\eps^{-2}$, and hence is continuous.
\end{proof}

(Question: in the above proof, is the map $f:\Fbb\setminus\{0\}\rightarrow\Fbb$ Lipschitz continuous?)

We have given a fancy way of proving that  if $(z_n)$ is a sequence in $\Fbb\setminus\{0\}$ converging to $z\in\Fbb\setminus\{0\}$, then $z_n^{-1}\rightarrow z^{-1}$. You should think about how to prove this fact directly using $\eps-N$ language, and compare your proof with the above proof to find the similarities!




\begin{pp}\label{lb41}
Let $\Fbb\in\{\Qbb,\Rbb,\Cbb\}$. Then the following maps are continuous:
\begin{gather*}
+:\Fbb\times\Fbb\rightarrow\Fbb\qquad (x,y)\mapsto x+y\\
-:\Fbb\times\Fbb\rightarrow\Fbb\qquad  (x,y)\mapsto x-y\\
\times: \Fbb\times\Fbb\rightarrow\Fbb\qquad  (x,y)\mapsto xy\\
\div:\Fbb\times\Fbb^\times\rightarrow\Fbb\qquad  (x,y)\mapsto x/y
\end{gather*}
\end{pp}


Recall our Convention \ref{lb32} on the metrics of finite product spaces. 


\begin{proof}
We only prove that the last two are continuous: the first two can be treated in a similar (and easier) way.

Denote the multiplication map by $\mu$. We choose the metric on $\Fbb^2$ to be $d(\mbf x,\mbf x')=\max\{|x_1-x_1'|,|x_2-x_2'|\}$. Since $\Fbb\times\Fbb$ is covered by open balls of the form $B(0,r)=\{(x,y)\in\Fbb^2:|x|<r,|y|<r\}$ where $0<r<+\infty$, by Lem. \ref{lb30} and \ref{lb34}, it suffices to show that $\mu|_{B(0,r)}$ is Lipschitz continuous. This is true, since for each $(x,y),(x',y')\in B(0,r)$, we have
\begin{align}\label{eq22}
\begin{aligned}
&|\mu(x,y)-\mu(x',y')|=|xy-x'y'|\leq |(x-x')y|+|x'(y-y')|\\
<&2r\cdot \max\{|x-x'|,|y-y'|\}=2r \cdot d((x,y),(x',y'))  
\end{aligned}
\end{align}

By Exp. \ref{lb35} and Prop. \ref{lb37}, the map $(x,y)\in\Fbb\times\Fbb^\times\mapsto (x,y^{-1})\in\Fbb\times\Fbb$ is continuous. So its composition with the continuous map $\mu$ is continuous, thanks to Prop. \ref{lb36}. So $\div$ is continuous. 
\end{proof}

\begin{pp}\label{lb36}
Suppose that $f:X\rightarrow Y$ and $g:Y\rightarrow Z$ are continuous maps of metric spaces. Then $g\circ f:X\rightarrow Z$ is continuous.
\end{pp}

\begin{pp}\label{lb37}
Suppose that $f_i:X_i\rightarrow Y_i$ is a map of metric spaces, where $1\leq i\leq N$. Then the product map \index{00@Product map}
\begin{gather*}
f_1\times\cdots\times f_N:X_1\times\cdots\times X_N\rightarrow Y_1\times\cdots\times Y_N\\
(x_1,\dots,x_N)\mapsto (f_1(x_1),\dots,f_N(x_N))
\end{gather*}
is continuous if and only if $f_1,\dots,f_N$ are continuous.
\end{pp}

\begin{proof}[Proof of Prop. \ref{lb36} and \ref{lb37}]
Immediate from Def. \ref{lb31}-(1) and Prop. \ref{lb38}.
\end{proof}


\begin{co}[\textbf{Squeeze theorem}]\index{00@Squeeze theorem}\label{lb61}
Let $\Fbb\in\{\Qbb,\Rbb\}$ and $(x_n),(y_n),(z_n)$ be sequences in $\Rbb$. Assume that $x_n\leq y_n\leq z_n$ for all $n$. Assume that $x_n$ and $z_n$ both converge to $A\in\Rbb$. Then $\lim_{n\rightarrow\infty}y_n=A$. 
\end{co}

\begin{proof}
Let $a_n=y_n-x_n$ and $b_n=z_n-x_n$. Then $0\leq a_n\leq b_n$, and $\lim_n b_n=\lim_n z_n-\lim_n x_n= 0$ because the subtraction map is continuous (Prop. \ref{lb41}). By Exp. \ref{lb28}, $a_n\rightarrow 0$. Since $x_n\rightarrow A$, $y_n=x_n+a_n$ converges to $A$, since the addition map is continuous by Prop. \ref{lb41}.
\end{proof}

Again, this is a fancy way of proving Squeeze theorem. The readers should know how to prove it directly from the definition of limits of sequences.

We give some more examples of continuous maps.

\begin{eg}
By Prop. \ref{lb41}, $f(x,y,z)=x^2y+5y^4z^7-3xyz^2$ is a continuous function on $\Cbb^3$. Clearly $z\in\Cbb\mapsto \ovl z\in\Cbb$ is continuous. So $g(x,y,z)=f(\ovl x,\ovl y,z)+2\ovl{f(z,x^2,xy^{-9})}-5xy^{-2}\ovl{z^{-3}}$ is a continuous function on $\Cbb\times\Cbb^\times\times\Cbb^\times$.
\end{eg}


\begin{eg}\label{lb44}
Let $f,g:X\rightarrow \Fbb$ be continuous functions where $\Fbb\in\{\Qbb,\Rbb,\Cbb\}$. Then by Prop. \ref{lb41} and \ref{lb36}, $f\pm g$ and $fg$ are continuous, and $f/g$ is continuous when $0\notin g(X)$. Here
\begin{align}
(f\pm g)(x)=f(x)\pm g(x)\qquad (fg)(x)=f(x)g(x)\qquad (f/g)(x)=f(x)/g(x)
\end{align} 
\end{eg}


\begin{eg}\label{lb54}
Let $f:X\rightarrow Y$ be a map of metric spaces. Let $E,F$ be subsets of $X,Y$ respectively. (Recall that the metrics of subsets are chosen as in Def. \ref{lb43}.) 
\begin{itemize}
\item The inclusion map $\iota_E:E\rightarrow X,x\mapsto x$ is clearly continuous. Thus, if $f$ is continuous, then $f|_E:E\rightarrow Y$ is continuous, since $f|_E=f\circ\iota_E$.
\item If $f(X)\subset F$, then we can restrict the codomain of $f$ from $Y$ to $F$: let $\wtd f:X\rightarrow F$ be $\wtd f(x)=f(x)$. Then it is clear that $f$ is continuous iff $\wtd f$ is continuous.
\end{itemize}
\end{eg}




\begin{pp}
Let $X_1,\dots,X_N$ be metric spaces. The following  projection is clearly continuous:
\begin{gather*}
\pi_{X_i}:X_1\times\cdots\times X_N\rightarrow X_i\qquad(x_1,\dots,x_N)\mapsto x_i
\end{gather*}
\end{pp}

\begin{pp}
Let $f_i:X\rightarrow Y_i$ be maps where $X,Y_1,\dots,Y_N$ are continuous. Then 
\begin{gather*}
f_1\vee \cdots\vee f_N:X\rightarrow Y_1\times\cdots\times Y_N\qquad x\mapsto (f_1(x),\dots,f_N(x))
\end{gather*}
is continuous iff $f_1,\dots,f_N$ are continuous.
\end{pp}


\begin{eg}
Let $X$ be a metric space. Then $d:X\times X\rightarrow\Rbb,(x,y)\mapsto d(x,y)$ is Lipschiz continuous with Lipschitz constant $1$ (by triangle inequality). So $d$ is continuous.
\end{eg}

\begin{pp}\label{lb42}
Let $X$ be a metric space and $E\subset X$. Define \textbf{distance function} \index{00@Distance function $d(\cdot,E)$} \index{dE@$d(x,E)$} 
\begin{gather*}
d(\cdot,E):X\rightarrow\Rbb_{\geq0}\qquad
d(x,E)=\inf_{e\in E}d(x,e)
\end{gather*}
Then $d(\cdot,E)$ is has Lipschitz constant $1$. So $d(\cdot,E)$ is continuous.
\end{pp}


\begin{proof}
Choose any $x,y\in X$. By triangle inequality, for each $e\in E$ we have $d(x,e)\leq d(x,y)+d(y,e)$. Since $d(x,E)\leq d(x,e)$, we get  $d(x,E)\leq d(x,y)+d(y,e)$. Applying $\inf_{e\in E}$ to the RHS gives $d(x,E)\leq d(x,y)+d(y,E)$. Hence $d(x,E)-d(y,E)\leq d(x,y)$. Exchanging $x$ and $y$ gives
\begin{align}
\big|d(x,E)-d(y,E)\big|\leq d(x,y)
\end{align}
This proves that $d(\cdot,E)$ has Lipschitz constant $1$.
\end{proof}

\begin{df}
More generally, if $E,F$ are subsets of a metric space $E$, we can define \index{DEF@$d(E,F)$}
\begin{align}
d(E,F)=\inf_{e\in E,f\in F}d(e,f)
\end{align}
to be the \textbf{distance between $E$ and $F$}.
\end{df}

\begin{exe}
Let $E,F\subset X$. Prove that
\begin{align}
d(E,F)=\inf_{f\in F}d(E,f)
\end{align}
\end{exe}

\begin{eg}\label{lb45}
If $X$ is a metric space and $p\in X$, then by Prop. \ref{lb42} (or simply by triangle inequality), the function $d_p:x\in X\mapsto d(x,p)\in\Rbb$ has Lipschitz constant $1$ and hence is continuous. In particular, if $\Fbb\in\{\Rbb,\Cbb\}$,  the function $z\in\Fbb\mapsto |z|$ is continuous (since $|z|=d_\Fbb(z,0)$). Thus, if $f:X\rightarrow\Fbb$ is continuous, then $|f|:X\rightarrow\Rbb_{\geq0}$ is continuous where
\begin{align}
|f|(x)=|f(x)|
\end{align}
\end{eg}


\begin{eg}
Let $N\in\Zbb_+$. Then the following function is continuous:
\begin{align*}
\max:\Rbb^N\rightarrow \Rbb\qquad (x_1,\dots,x_N)\mapsto\max\{x_1,\dots,x_N\}\in\Rbb
\end{align*}
Similarly, the minimum function is continuous.
\end{eg}

\begin{proof}
To avoid confusion, we write $\max$ as $\max_N$. The case $N=1$ is obvious. When $N=2$, we have
\begin{align}
\max(x_1,x_2)=\frac{x_1+x_2+|x_1-x_2|}2
\end{align}
So $\max_2$ is continuous by Exp. \ref{lb44} and \ref{lb45}.

We use induction. Suppose we have proved that $\max_N$ is continuous. Then $\max_N\times\id_\Rbb:\Rbb^N\times \Rbb\rightarrow\Rbb\times\Rbb$ is continuous. So $\max_{N+1}=\max_2\circ(\max_N\times\id_\Rbb)$ is continuous.
\end{proof}


\subsection{Homeomorphisms and isometric isomorphisms; convergence in $\ovl{\Rbb}$}

\subsubsection{General theory}



\begin{df}\label{lb189}
A bijection of metric spaces $f:X\rightarrow Y$ is called a \textbf{homeomorphism} if one of the following equivalent (cf. Def. \ref{lb31}) statements holds:
\begin{itemize}
\item[(1)] $f:X\rightarrow Y$ and its inverse map $f^{-1}:Y\rightarrow X$ are continuous.
\item[(2)] For each sequence $(x_n)$ in $X$ and each $x\in X$, we have $\dps \lim_{n\rightarrow\infty}x_n=x$ iff $\dps\lim_{n\rightarrow\infty}f(x_n)=f(x)$.
\end{itemize}
If such $f$ exists, we say that $X,Y$ are \textbf{homeomorphic}.
\end{df}

A special case of the above definition is:
\begin{df}\label{lb144}
Let $X$ be a set with metrics $d,\delta$. We say that $d$ and $\delta$ induce the \textbf{same topology} on $X$ (or that $d,\delta$ are \index{00@Topologically equivalent metrics} \textbf{topologically equivalent}) if one of the following clearly equivalent statements holds:
\begin{itemize}
\item[(1)] The map $(X,d)\rightarrow (X,\delta),x\mapsto x$ is a homeomorphism.\footnote{We prefer not to call this map the identity map, because the metrics on the source and on the target are different.}
\item[(2)] For each sequence $(x_n)$ in $X$ and each $x\in X$, $(x_n)$ converges to $x$ under the metric $d$ iff $(x_n)$ converges to $x$ under $\delta$.
\end{itemize}
\end{df}


\begin{pp}\label{lb48}
Suppose that $d,\delta$ are equivalent metrics on a set $X$. Then $d,\delta$ are topologically equivalent.
\end{pp}

\begin{proof}
Suppose $\delta\leq\alpha d$ and $d\leq\beta\delta$ for some $\alpha,\beta>0$. Then the map $f:(X,d)\rightarrow (X,\delta),x\mapsto x$ and its inverse $f^{-1}$ have Lipschitz constants $\alpha$ and $\beta$ respectively. So $f,f^{-1}$ are continuous.
\end{proof}






\begin{exe}\label{lb46}
Let $f:X\rightarrow Y$ be a map of metric spaces. We say that $f:X\rightarrow Y$ is an \textbf{isometry} (or is \textbf{isometric}) \index{00@Isometry and isometric isomorphism} if for all $x_1,x_2\in X$ we have
\begin{align}
d_Y(f(x_1),f(x_2))=d_X(x_1,x_2) \label{eq15}
\end{align}
Show that an isometry is injective and continuous.

We say that $f$ is an \textbf{isometric isomorphism} if $f$ is a surjective isometry. If an isometric isomorphism between two metric spaces $X,Y$ exists, we say that $X$ and $Y$ are \textbf{isometric metric spaces}.\index{00@Isometric metric spaces} Show that an isometric isomorphism is a homeomorphism.   \hfill\qedsymbol
\end{exe}

\begin{rem}
Isometric isomorphisms are important examples of homeomorphisms. That $f:X\rightarrow Y$ is an isometric isomorphism means that $X$ and $Y$ are equivalent as metric spaces, and that this equivalence can be implemented by the bijection $f$. 

We now look at isometric isomorphisms in a different direction. Suppose that $f:X\rightarrow Y$ is a bijection of sets. Suppose that $Y$ is a metric space. Then there is unique metric $d_X$ on $X$ such that $f$ is an isometric isomorphism: one defines $d_X$ using \eqref{eq15}. We write such $d_X$ as $f^*d_Y$, \index{fdY@$f^*d_Y$: pullback metric}  i.e.,
\begin{align*}
f^*d_Y(x_1,x_2)=d_Y(f(x_1),f(x_2))
\end{align*}
and call $f^*d_Y$ the \textbf{pullback metric} \index{00@Pullback metrics} of $d_Y$ by $f$. \hfill\qedsymbol
\end{rem}

Pullback metrics are a very useful way of constructing metrics on a set. We consider some examples below. 


\begin{exe}\label{lb49}
Two metrics inducing the same topology are not necessarily equivalent metrics. For example, let $f:[0,1]\rightarrow [0,1]$ be $f(x)=x^2$. Let $X=[0,1]$, and let $d_X$ be the  Euclidean metric: $d_X(x,y)=|x-y|$. So
\begin{align*}
f^*d_X(x,y)=|x^2-y^2|
\end{align*}
is a metric on $X$. It is not hard to check that $f:(X,d_X)\rightarrow (X,d_X)$ is a homeomorphism.  So $d_X$ and $f^*d_X$ give the same topology on $[0,1]$ (cf. Exe. \ref{lb50}). Show that $f^*d_X$ and $d_X$ are not equivalent metrics.
\end{exe}

\begin{exe}\label{lb50}
Let $f:X\rightarrow Y$ be a bijection of sets with metrics $d_X,d_Y$. Show that $d_X$ and $f^*d_Y$ give the same topology on $X$ iff $f:(X,d_X)\rightarrow(Y,d_Y)$ is a homeomorphism. 

In particular, if $f:X\rightarrow X$ is a bijection, and $d_X$ is a metric on $X$. Then $d_X$ and $f^*d_X$ give the same topology on $X$ iff $f:(X,d_X)\rightarrow (X,d_X)$ is a homeomorphism. 
\end{exe}


\subsubsection{Convergence in $\ovl\Rbb$}


Our second application of pullback metrics is the convergence in $\ovl\Rbb$.




\begin{df}\label{lb47}
We say that a sequence $(x_n)$ in $\ovl\Rbb$ \textbf{converges to} \index{00@Convergence in $\ovl{\Rbb}$} $+\infty$ (resp. $-\infty$), if for every $A\in\Rbb$ there is $N\in\Zbb_+$ such that for all $n\geq N$ we have $x_n>A$ (resp. $x_n<A$). 

Suppose $x\in\Rbb$. We say that a sequence $(x_n)$ in $\ovl\Rbb$ \textbf{converges to} $x$, if there is $N\in\Zbb_+$ such that $x_n\in\Rbb$ for all $n\geq N$, and that the subsequence $(x_{k+N})_{k\in\Zbb_+}$ converges in $\Rbb$ to $x$.  \hfill\qedsymbol
\end{df}



This notion of convergence is weird: it is not defined by a metric. So one wonders if there is a metric $d$ on $\ovl\Rbb$ such that convergence of sequences under $d$ agrees with that in Def. \ref{lb47}. We shall now find such a metric.

\begin{lm}\label{lb59}
Let $-\infty\leq a<b\leq +\infty$ and $-\infty\leq c<d\leq +\infty$. Then there is a strictly increasing bijective map $[a,b]\rightarrow[c,d]$.
\end{lm}
Note that this map clearly sends $a$ to $c$ and $b$ to $d$. So it restricts to strictly increasing bijections $(a,b)\rightarrow(c,d)$, $(a,b]\rightarrow(c,d]$, $[a,b)\rightarrow[c,d)$.

\begin{proof}
We have a strictly increasing bijection $f:\Rbb\rightarrow(-1,1)$ defined by \eqref{eq20}.  $f$ can be extended to a strictly increasing bijective map $\ovl\Rbb\rightarrow[-1,1]$ if we set $f(\pm\infty)=\pm1$. Thus, $f$ restricts to a strictly increasing bijection $[a,b]\rightarrow [f(a),f(b)]$. Choose a linear function $g(x)=\alpha x+\beta$ (where $\alpha>0$) giving an increasing bijection $[f(a),f(b)]\rightarrow[0,1]$. Then $h=g\circ f:[a,b]\rightarrow[0,1]$ is a strictly increasing bijection. Similarly, we have a strictly increasing bijection $k:[c,d]\rightarrow[0,1]$. Then $k^{-1}\circ h:[a,b]\rightarrow[c,d]$ is a strictly increasing bijection.
\end{proof}


\begin{thm}\label{lb51}
Let $\varphi:\ovl\Rbb\rightarrow[a,b]$ be a strictly increasing bijective map where $[a,b]\subset\Rbb$ is equipped with the Euclidean metric $d_{[a,b]}$. Then a sequence $(x_n)$ in $\ovl\Rbb$ converges to $x\in\ovl\Rbb$ in the sense of Def. \ref{lb47} iff $\varphi(x_n)$ converges to $\varphi(x)$ under the metric $d_{[a,b]}$. In other words, the convergence in $\ovl\Rbb$ is given by the metric $\varphi^*d_{[a,b]}$.
\end{thm}

\begin{proof}
Let $y=\varphi(x)$ and $y_n=\varphi(x_n)$. We need to prove that $x_n\rightarrow x$ (in the sense of Def. \ref{lb47}) iff $y_n\rightarrow y$ (under the Euclidean metric). Write $\psi=\varphi^{-1}$, which is a strictly increasing map $[a,b]\rightarrow\ovl\Rbb$. Note that $\varphi(+\infty)=b$ and $\varphi(-\infty)=a$. 

Case 1: $x\in\Rbb$. By discarding the first several terms, we may assume that $(x_n)$ is always in $\Rbb$. If $x_n\rightarrow x$, then for every $\eps>0$, all but finitely many $x_n$ are inside the open interval $(\psi(y-\varepsilon),\psi(y+\varepsilon))$. So all but finitely many $y_n$ are inside $(y-\varepsilon,y+\varepsilon)$. So $y_n\rightarrow y$. That $y_n\rightarrow y$ implies $x_n\rightarrow x$ is proved in a similar way.

Case 2: $x=\pm\infty$. We consider $x=+\infty$ only; the other case is similar. Note that if $0<\eps<b-a$, then $B_{[a,b]}(b,\varepsilon)=(b-\varepsilon,b]$.  If $x_n\rightarrow+\infty$, then for each  $0<\eps<b-a$, all but finitely many $x_n$ are $>\psi(b-\eps)$. So all but finitely many $y_n$ are inside $(b-\eps,b]$. This proves $y_n\rightarrow b$. Conversely, if $y_n\rightarrow b$, then for each $A\in\Rbb$, all but finitely many $y_n$ are inside $(\varphi(A),b]$ and hence $>\varphi(A)$. So all but finitely many $x_n$ are $>A$.
\end{proof}


\begin{cv}\label{lb77}
Unless otherwise stated, a metric on $\ovl\Rbb$ is one that makes Def. \ref{lb47} true, for instance $\varphi^*d_{[a,b]}$ in Thm. \ref{lb51}. Unless otherwise stated, we do NOT view $\Rbb$ (or any subset of $\Rbb$) as a metric subspace of $\ovl\Rbb$. Namely, we do not follow Convention \ref{lb76} for $\Rbb\subset\ovl\Rbb$, or more generally for $\Rbb^N\subset\ovl\Rbb^N$. Instead, we choose Euclidean metrics on $\Rbb^N$, following Convention \ref{lb33}. 
\end{cv}




The main reason for not following Convention \ref{lb76} here is that metrics on $\ovl\Rbb$ are all bounded (by Prop. \ref{lb71}). Thus, every subset of $\Rbb$ is bounded if we view $\Rbb$ as a metric subspace of $\ovl\Rbb$. However, we want a subset of $\Rbb$ to be bounded precisely when it is contained in $[a,b]$ for some $-\infty<a<b<+\infty$. (Recall also Def. \ref{lb114}.)



After learning topological spaces, we shall forget about the metrics on $\ovl\Rbb$ and only care about its topology. (See Conv. \ref{lb173}.)






\begin{rem}\label{lb58}
By Thm. \ref{lb51}, the properties of $[a,b]$ about convergence of sequences and inequalities can be transported to $\ovl\Rbb$, for example:
\begin{enumerate}
\item If $(x_n),(y_n)$ are sequences in $\ovl\Rbb$ converging to $A,B\in\ovl\Rbb$, and if $x_n\leq y_n$ for all $n$, then $A\leq B$.
\item \textbf{Squeeze theorem}: \index{00@Squeeze theorem} Suppose that $(x_n),(y_n),(z_n)$ are sequences in $\ovl\Rbb$, $x_n\leq y_n\leq z_n$ for all $n$, and $x_n$ and $z_n$ both converge to $A\in\ovl\Rbb$. Then $y_n\rightarrow A$.
\item Prop. \ref{lb57} also holds for $[-\infty,+\infty]=\ovl\Rbb$: if $(x_n)$ is an increasing resp. decreasing sequence in $\ovl\Rbb$, then $\lim_n x_n$ exists in $\ovl\Rbb$ and equals $\sup_n x_n$ resp. $\inf_n x_n$.
\end{enumerate}
We will see more examples when studying $\limsup$ and $\liminf$ in the future.
\end{rem}


We have shown that there is a metric on $\ovl\Rbb$ which defines the convergence in Def. \ref{lb47}. However, there is no standard choice of such a metric on $\ovl\Rbb$. Even worse, two possible choices of metrics might not be equivalent: Let $\varphi,\psi:\ovl\Rbb\rightarrow[0,1]$ be a strictly increasing bijections where $\psi\circ\varphi^{-1}:[0,1]\rightarrow[0,1]$ is $x\mapsto x^2$. Then by Exe. \ref{lb49}, $\varphi^*d_{[0,1]}$ and $\psi^*d_{[0,1]}$ are non-equivalent but topologically equivalent metrics on $\ovl\Rbb$. This is the first example that metrics are not convenient for the description of convergence. When studying the convergence in $\ovl\Rbb$, thinking about metrics is distracting. In the future, we will see a better notion for the study of convergence: the notion of topological spaces.

We end this section with a generalization of Thm. \ref{lb51}.

\begin{thm}\label{lb65}
Let $\varphi$ be a strictly increasing bijection in one of the following forms
\begin{gather*}
[a,b]\rightarrow [c,d]\qquad (a,b)\rightarrow(c,d)\\
(a,b]\rightarrow (c,d]\qquad [a,b)\rightarrow [c,d)
\end{gather*}
where $-\infty\leq a\leq b\leq +\infty$ and $-\infty\leq c\leq d\leq +\infty$. Then $\varphi$ is a homeomorphism, i.e., if $(x_n)$ and $x$ are in the domain, then $x_n\rightarrow x$ iff $\varphi(x_n)\rightarrow \varphi(x)$ (in the sense of Def. \ref{lb47}).
\end{thm}

\begin{proof}
The case $a=b$ is obvious. So we consider $a<b$, and hence $c<d$. We consider the left-open-right-closed case for example. The other cases are treated in a similar way. If the theorem can be proved for $(-\infty,+\infty]\rightarrow(c,d]$, then it can also be proved $(-\infty,+\infty]\rightarrow(a,b]$. By composing the inverse of the second map with the first map, we see that the theorem holds for $(a,b]\rightarrow (c,d]$. 

Let us consider $\varphi:(-\infty,+\infty]\rightarrow(c,d]$. $\varphi$ can be extended to a strictly increasing bijection $\varphi:\ovl\Rbb\rightarrow[c,d]$ by letting $\varphi(-\infty)=c$. It suffices to prove that this $\varphi$ is a homeomorphism. When $-\infty<c<d<+\infty$, then the theorem holds by Thm. \ref{lb51}. If one of $c,d$ is $\pm\infty$, the same argument as in the proof of Thm. \ref{lb51} proves that $\varphi$ is a homeomorphism. We leave it to the readers to fill in the details.
\end{proof}



%% Record  #2  2023/9/20


\subsection{Problems and supplementary material}

\begin{df}
Let $A$ be a subset of $\Rbb$  satisfying $x+y\in A$ for all $x,y\in A$. (Or more generally, let $A$ be an abelian semigroup.) We say that a function $f:A\rightarrow \Rbb$ is \textbf{subadditive} \index{00@Subadditivity} if for every $x,y\in A$ we have $f(x+y)\leq f(x)+f(y)$.
\end{df}

\begin{prob}\label{lb52}
Consider the following increasing functions:
\begin{gather*}
f_1:\Rbb_{\geq 0}\rightarrow[0,1)\qquad f_1(x)=\frac{x}{1+x}\\
f_2:\Rbb_{\geq 0}\rightarrow[0,1]\qquad f_2(x)=\min\{x,1\}
\end{gather*}
Prove that they are subadditive functions. 
\end{prob}

\begin{prob}\label{lb53}
Let $f:\Rbb_{\geq0}\rightarrow \Rbb_{\geq0}$ be an increasing subadditive function satisfying the following conditions:
\begin{itemize}
\item[(1)] $f^{-1}(0)=\{0\}$.
\item[(2)] For any $(x_n)_{n\in\Zbb_+}$ in $\Rbb_{\geq0}$ we have $x_n\rightarrow 0$ iff $f(x_n)\rightarrow 0$.
\end{itemize}
Let $(X,d)$ be a metric space. Define
\begin{align*}
\delta:X\times X\rightarrow [0,A)\qquad \delta(x,y)=f\circ d(x,y)
\end{align*}  
Prove that $\delta$ is a metric, and that $\delta$ and $d$ are topologically equivalent.
\end{prob}


\begin{pp}\label{lb195}
Let $(X,d)$ be a metric space. Then there is a bounded metric $\delta$ on $X$ such that $d$ and $\delta$ are topologically equivalent.
\end{pp}
\begin{proof}
Let $f$ be either $f_1$ or $f_2$ defined in Pb. \ref{lb52}. Then $f$ satisfies the assumptions in Pb. \ref{lb53}. So $\delta=f\circ d$ is a desired metric due to Pb. \ref{lb53}. We write down the formulas explicitly:
\begin{align*}
\delta_1(x,y)=\frac{d(x,y)}{1+d(x,y)}\qquad \delta_2(x,y)=\min\{d(x,y),1\}
\end{align*}
\end{proof}

\begin{prob}\label{lb78}
Let $(X_i,d_i)_{i\in\Zbb_+}$ be a sequence of metric spaces. Assume that $d_i\leq 1$ for each $i$. Let $\dps S=\prod_{i\in\Zbb_+} X_i$. For each elements $f=(f(i))_{i\in\Zbb_+}$ and $g=(g(i))_{i\in\Zbb_+}$ of $S$, define
\begin{align}
d(f,g)=\sup_{i\in\Zbb_+} \frac {d_i(f(i),g(i))}{i}  \label{eq16}
\end{align} 
Prove that $d$ is a metric on $S$. Let $f_n=(f_n(i))_{i\in\Zbb_+}$ be a sequence in $S$. Let $g\in S$. Prove that the following are equivalent:
\begin{enumerate}[label=(\alph*)]
\item $\dps \lim_{n\rightarrow\infty} f_n=g$ under the metric $d$.
\item $f_n$ \textbf{converges pointwisely} to $g$, namely, $\dps\lim_{n\rightarrow\infty} f_n(i)=g(i)$ for every $i\in\Zbb_+$.
\end{enumerate}
\end{prob}

\begin{rem}
The above problem gives our first non-trivial example of function spaces  as metric spaces, where the domain of functions is a countable set. After learning series, the readers can check that 
\begin{align}
\delta(f,g)=\sum_{i\in\Zbb_+}2^{-i} d_i(f(i),g(i))   \label{eq61}
\end{align}
also defines a metric, and that (a) (with $d$ replaced by $\delta$) and (b) are equivalent. So $\delta$ and $d$ (defined by \eqref{eq16}) induce the same topology on $X$, called the \textbf{pointwise convergence topology} or simply \textbf{product topology}. Unfortunately, if the index set $\Zbb_+$ is replaced by an uncountable set, there is in general no metric inducing the product topology. We will prove this in Pb. \ref{lb203}.
\end{rem}













\begin{sprob}\label{lb194}
Let $X=\bigsqcup_{\alpha\in \scr A}X_\alpha$ be a disjoint union of metric spaces $(X_\alpha,d_\alpha)$. Assume that $d_\alpha\leq 1$ for all $i$. For each $x,y\in X$, define
\begin{gather*}
d(x,y)=\left\{
\begin{array}{ll}
d_\alpha(x,y)&\text{ if $x,y\in X_\alpha$ for some $\alpha\in\scr A$}\\[0.5ex]
\frac 12&\text{ otherwise}
\end{array}
\right.
\end{gather*}
\begin{enumerate}
\item Prove that $d$ defines a metric on $X$. 
\item Choose $(x_n)_{n\in\Zbb_+}$ in $X$ and $x\in X$. What does $\dps\lim_{n\rightarrow\infty}x_n=x$ mean in terms of the convergence in each $X_\alpha$?
\end{enumerate}
\end{sprob}

Think about the question: Let $X$ be a set. For each $x,y\in X$ define $d(x,y)=0$ if $x=y$, and $d(x,y)=1$ if $x\neq y$. What does convergence in $(X,d)$ mean?



\newpage



\section{Sequential compactness and completeness}



\subsection{Sequential compactness}


\subsubsection{Basic properties of sequentially compact spaces}

\begin{df}
Let $X$ be a metric space. We say that $X$ is \textbf{sequentially compact} \index{00@Sequentially compact} if every sequence in $X$ has a subsequence converging to some point of $X$.
\end{df}





The notion of sequential compactness is extremely useful for finding solutions in an analysis problem. In general, suppose we want to find a point $x\in X$ which makes a property $P(x)$ to be true. Suppose that we can find an ``approximate solution", i.e. an $y\in X$ such that $P(y)$ is close to being true. Thus, we can find a sequence $(x_n)$ in $X$ such that $P(x_n)$ is closer and closer to being true when $n\rightarrow\infty$. Now, if $X$ is sequentially compact, then $(x_n)$ has a subsequence $(x_{n_k})$ converging to $x\in X$. Then $P(x)$ is true, and hence $x$ is a solution for the problem. (See also Sec. \ref{lb55}.) Let us see an explicit example:

\begin{lm}[Extreme value theorem]\label{lb56}
Let $X$ be a sequentially compact metric space. Let $f:X\rightarrow\Rbb$ be a continuous function. Then $f$ attains its maximum and minimum at points of $X$. In particular, $f(X)$ is a bounded subset of $\Rbb$.
\end{lm}

This extremely important result is the main reason for introducing sequentially compact spaces. We call this a lemma, since we will substantially generalize this result later. (See Exe. \ref{lb63}.)

Note that the \textbf{boundedness} of subsets of $\Rbb$ (or more generally, of $\Rbb^N$) is always understood under the Euclidean metric of $\Rbb$, not under any metric of $\ovl\Rbb$ or $\ovl\Rbb^N$. (Recall Convention \ref{lb77}.)

\begin{proof}
We show that $f$ attains its maximum on $X$. The proof for minimum is similar. Let $A=\sup f(X)$. Then $A\in (-\infty,+\infty]$. If $A<+\infty$, then for each $n\in\Zbb_+$ there is $x_n\in X$ such that $A-1/n<f(x_n)\leq A$ (since $A-1/n$ is not an upper bound of $f(X)$). If $A=+\infty$, then for each $n$ there is $x_n\in X$ such that $f(x_n)>n$. In either case, we have a sequence $(x_n)$ in $X$ such that $f(x_n)\rightarrow A$ in $\ovl \Rbb$.

Since $X$ is sequentially compact, $(x_n)$ has a subsequence $(x_{n_k})_{k\in\Zbb_+}$ converging to some $x\in X$. Now, consider $f$ as a map $f:X\rightarrow\ovl\Rbb$, which is continuous (cf. Exp. \ref{lb54}). Since $f(x_n)\rightarrow A$, its subsequence $f(x_{n_k})$ also converges to $A$. But since $x_{n_k}\rightarrow x$ and $f$ is continuous at $x$, we have $A=f(x)$. So $f$ attains its maximum at $x$. Since $f(X)\subset\Rbb$, we have $A\in\Rbb$.
\end{proof}

The following are some elementary examples of sequential compactness:


\begin{exe}
Show that finite unions of sequentially compact spaces is sequentially compact. (In particular, a finite set is sequentially compact.) 

More precisely, let $X$ be a metric space. Assume $X=A_1\cup\cdots\cup A_N$ where each metric subspace $A_i$ is sequentially compact. Show that $X$ is sequentially compact.  
\end{exe}

\begin{pp}\label{lb72}
Let $X_1,\dots,X_N$ be sequentially compact metric spaces. Then $X=X_1\times\cdots\times X_N$ is sequentially compact.
\end{pp}

\begin{proof}
Since $X=(X_1\times\cdots\times X_{N-1})\times X_n$, by induction, it suffices to assume $N=2$. So we write $X=A\times B$ where $A,B$ are sequentially compact. Let $(a_n,b_n)$ be a sequence in $X$. Since $A$ is sequentially compact, $(a_n)$ has a convergent subsequence $(a_{n_k})$. Since $B$ is sequentially compact, $(b_{n_k})$ has a convergent subsequence $(b_{n_{k_l}})$. So $(a_{n_{k_l}},b_{n_{k_l}})$ is a convergent subsequence of $(a_n,b_n)$.
\end{proof}


\begin{pp}\label{lb62}
Let $f:X\rightarrow Y$ be a continuous  map of metric spaces. Assume that $X$ is sequentially compact. Then $f(X)$, as a metric subspace of $Y$, is sequentially compact.
\end{pp}

\begin{proof}
Choose any sequence $(y_n)$ in $f(X)$. We can write $y_n=f(x_n)$ where $x_n\in X$. Since $X$ is sequentially compact, $(x_n)$ has a subsequence $(x_{n_k})$ converging to some $x\in X$. Since $f$ is continuous, $y_{n_k}=f(x_{n_k})$ converges to $f(x)$.
\end{proof}


\begin{exe}\label{lb63}
Prove that if $Y$ is a sequentially compact subset of $\Rbb$, then $\sup Y\in Y$ and $\inf Y\in Y$. Therefore, Prop. \ref{lb62} generalizes Lem. \ref{lb56}.
\end{exe}

\begin{pp}\label{lb71}
Let $X$ be a sequentially compact metric space. Then $X$ is bounded under its metric $d$.
\end{pp}

\begin{proof}
Choose any $p\in X$. The function $d_p:x\in X\mapsto d(x,p)\in\Rbb_{\geq 0}$ is continuous by Exp. \ref{lb45}. So, by Lem. \ref{lb56}, $d_p$ is bounded by some $0<R<+\infty$. So $X=\ovl B_X(p,R)\subset B_X(p,2R)$.
\end{proof} 






\subsubsection{Limits inferior and superior, and Bolzano-Weierstrass}\label{lb69}

The goal of this subsection is to prove that closed intervals are sequentially compact. 


\begin{df}
Let $(x_n)$ be a sequence in a metric space $X$. We say that $x\in X$ is a \textbf{cluster point} \index{00@Cluster point of a sequence} of $(x_n)$, if $(x_n)$ has a subsequence $(x_{n_k})$ converging to $x$.
\end{df}







\begin{df}\label{lb60}
Let $(x_n)$ be a sequence in $\ovl\Rbb$. Define
\begin{gather}
\alpha_n=\inf\{x_k:k\geq n \}\qquad \beta_n=\sup\{x_k:k\geq  n \}
\end{gather}
It is clear that $\alpha_n\leq x_n\leq \beta_n$, that $(\alpha_n)$ is increasing and $(\beta_n)$ is decreasing. Define \index{liminfsup@$\liminf,\limsup$}
\begin{subequations}
\begin{gather}
\liminf_{n\rightarrow\infty}x_n=\sup\{\alpha_n:n\in\Zbb_+\}=\lim_{n\rightarrow\infty} \alpha_n \label{eq18}\\
\limsup_{n\rightarrow\infty}x_n=\inf\{\beta_n:n\in\Zbb_+\}=\lim_{n\rightarrow\infty} \beta_n\label{eq19}
\end{gather}
\end{subequations}
(cf. Rem. \ref{lb58}), called respectively the \textbf{limit inferior} and the \textbf{limit superior} \index{00@Limit inferior and superior} of $(x_n)$.
\end{df}

\begin{rem}
Let $(x_n),(y_n)$ be sequences in $\ovl\Rbb$. Suppose that $x_n\leq y_n$ for every $n$. It is clear that
\begin{gather*}
\liminf_{n\rightarrow\infty}x_n\leq\limsup_{n\rightarrow\infty} x_n\qquad \liminf_{n\rightarrow\infty}x_n\leq \liminf_{n\rightarrow\infty}y_n\qquad \limsup_{n\rightarrow\infty} x_n\leq \limsup_{n\rightarrow\infty} y_n
\end{gather*}
\end{rem}


\begin{thm}\label{lb68}
Let $(x_n)$ be a sequence in $\ovl\Rbb$, and let $S$ be the set of cluster points of $(x_n)$. Then $\dps\liminf_{n\rightarrow\infty}x_n$ and $\dps\limsup_{n\rightarrow\infty}x_n$ belong to $S$. They are respectively the minimum and the maximum of $S$.
\end{thm}

In particular, every sequence in $\ovl\Rbb$ has at least one cluster point.

\begin{proof}
We use the notations in Def. \ref{lb60}. Let $A=\eqref{eq18}$ and $B=\eqref{eq19}$. If $x\in S$, pick a subsequence $(x_{n_k})$ converging to $x$. Since $\alpha_{n_k}\leq x_{n_k}\leq \beta_{n_k}$, we have $A\leq x\leq B$ by Rem. \ref{lb58}. It remains to show that $A,B\in S$. We prove $B\in S$ by constructing a subsequence $(x_{n_k})$ converging to $B$; the proof of $A\in S$ is similar. 

Consider first of all the special case that $(x_n)$ is bounded, i.e., is inside $[a,b]\subset\Rbb$. Choose an arbitrary $n_1\in\Zbb_+$. Suppose $n_1<\dots<n_k$ has been constructed. By the definition of $\beta_{1+n_k}$, there is $n_{k+1}\geq 1+n_k$ such that $x_{n_{k+1}}$ is close to $\beta_{1+n_k}$, say
\begin{align}
\beta_{1+n_k}-\frac 1k<x_{n_{k+1}}\leq \beta_{1+n_k}  \label{eq17}
\end{align}
Since the left most and the right most of \eqref{eq17} both converge to $B$ as $k\rightarrow\infty$, by Squeeze theorem (Cor. \ref{lb61}) we conclude $\lim_k x_{n_k}=B$. 

In general, by Lem. \ref{lb59} and Thm. \ref{lb65}, there is an increasing (i.e. order-preserving) homeomorphism (i.e. topopogy-preserving map) $\varphi:\ovl\Rbb\rightarrow[0,1]$. Then $\varphi(\beta_n)=\sup\{\varphi(x_k):k\geq n\}$ (cf. Exe. \ref{lb66}) and $\varphi(B)=\lim_n\varphi(\beta_n)$. So $\varphi(B)=\limsup_n \varphi(x_n)$. By the above special case, $(\varphi(x_n))$ has a subsequence $(\varphi(x_{n_k}))$ converging to $\varphi(B)$. So $(x_{n_k})$ converges to $B$. 
\end{proof}

\begin{rem}
One can also prove the above general case directly using a similar idea as in the special case. And you are encouraged to do so! (Pay attention to the case $B=\pm\infty$.) 

The proof given above belongs to a classical proof pattern: To prove that a space $X$ satisfies some property, one first prove it in a convenient case. Then, in the general case, one finds an ``isomorphism" (i.e. ``equivalence" in a suitable sense) $\varphi:X\rightarrow Y$ where $Y$ is in the convenient case. Then the result on $Y$ can be translated via $\varphi^{-1}$ to $X$, finishing the proof. 

For example, to solve a linear algebra problem about linear maps between finite-dimensional vector spaces $V,W$, one first proves it in the special case that $V=\Fbb^m$ and $W=\Fbb^n$. Then, the general case can be translated to the special case via an equivalence as in Exp. \ref{lb67}.  \hfill\qedsymbol
\end{rem}


\begin{exe}\label{lb66}
Let $X,Y$ be posets. Let $\varphi:X\rightarrow Y$ be an increasing bijection whose inverse is also increasing. (Namely, $\varphi$ induces an equivalence of posets). Suppose $E\subset X$ has supremum $\sup E$. Explain why $\varphi(E)$ has supremum $\varphi(\sup E)$.
\end{exe}


It is now fairly easy to prove the famous

\begin{thm}[Bolzano-Weierstrass]\index{00@Bolzano-Weierstrass theorem}
Let $[a_1,b_1],\dots,[a_N,b_N]$ be closed intervals in $\ovl\Rbb$. Then $[a_1,b_1]\times\cdots\times [a_N,b_N]$ is sequentially compact. 
\end{thm}

\begin{proof}
By Prop. \ref{lb72}, it suffices to assume $N=1$. Write $a_1=a,b_1=b$. Let $(x_n)$ be a sequence in $[a,b]$. By Thm. \ref{lb68}, $(x_n)$ has a subsequence $(x_{n_k})$ converging to some $x\in\ovl\Rbb$. (E.g. $x=\limsup_n x_n$.) Since $a\leq x_{n_k}\leq b$, we have $a\leq x\leq b$ by Rem. \ref{lb58}.
\end{proof}

Bolzano-Weierstrass theorem illustrates why we sometimes prefer to work with $\ovl\Rbb$ instead of $\Rbb$: $\ovl\Rbb$ is sequentially compact, while $\Rbb$ is not. That every sequence has limits superior and inferior in $\ovl\Rbb$ but not necessarily in $\Rbb$ is closely related to this fact. In the language of point-set topology, $\ovl\Rbb$ is a \textbf{compactification} of $\Rbb$.


Bolzano-Weierstrass theorem (restricted to $\Rbb^N$) will be generalized to \textbf{Heine-Borel theorem}, which says that a subset of $\Rbb^N$ is sequentially compact iff it is bounded and closed (cf. Def. \ref{lb99} for the definition of closed subsets). See Thm. \ref{lb98}.





\subsubsection{A criterion for convergence in sequentially compact spaces}

At the end of Sec. \ref{lb73}, we have raised the following question: Suppose that $(x_n)$ is a bounded sequence in a metric space $X$ such that any two convergent subsequences converge to the same point. Does $(x_n)$ converge?

When $X$ is sequentially compact, $(x_n)$ is automatically bounded due to Prop. \ref{lb71}. The answer to the above question is yes:

\begin{thm}\label{lb74}
Let $X$ be a sequentially compact metric space. Let $(x_n)$ be a sequence in $X$. Then the following are equivalent.
\begin{itemize}
\item[(1)] The sequence $(x_n)$ converges in $X$.
\item[(2)] Any two convergent subsequences of $(x_n)$ converge to the same point. In other words, $(x_n)$ has only one cluster point. 
\end{itemize}
\end{thm}


\begin{proof}
(1)$\Rightarrow$(2): By Prop. \ref{lb23}.

(2)$\Rightarrow$(1): Assume that $(x_n)$ has at most one cluster point. Since $X$ is sequentially compact, $(x_n)$ has at least one cluster point $x\in X$. We want to prove $\lim_{n\rightarrow\infty} x_n=x$. Suppose not. Then there exists $\eps>0$ such that for every $N\in\Zbb_+$ there is $n\geq N$ such that $d(x_n,x)\geq \eps$. Thus, one can inductively construct a subsequence $(x_{n_k})$ of $(x_n)$ such that $d(x_{n_k},x)\geq\eps$ for all $k$. Since $X$ is sequentially compact, $(x_{n_k})$ has a subsequence $x'_n$ converging to $x'\in X$. So $d(x'_n,x)\geq\eps$ for all $n$. Since the function $y\in X\mapsto d(y,x)$ is continuous (Exp. \ref{lb45}), we have $\lim_{n\rightarrow\infty}d(x_n',x)=d(x',x)$. This proves that $d(x',x)\geq\eps>0$. However, $x',x$ are both cluster points of $(x_n)$, and so $x=x'$. This gives a contradiction. 
\end{proof}

\begin{rem}
Thm. \ref{lb74} can be used in the following way. Suppose that we want to prove that a given sequence $(x_n)$ in a sequentially compact space $X$ converges to $x$. Then it suffices to prove that if $(x_n')$ is a subsequence of $(x_n)$ converging to some $y\in X$, then $y=x$. This is sometimes easier to prove than directly proving the convergence of $(x_n)$. We will use this strategy in the proof of L'H\^ospital's rule, for example.
\end{rem}





\begin{co}\label{lb75}
Let $(x_n)$ be a sequence in $\Rbb^N$. The following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item The sequence $(x_n)$ converges in $\Rbb^N$.
\item The sequence $(x_n)$ is bounded. Moreover, any two convergent subsequences of $(x_n)$ converge to the same point of $\Rbb^N$.
\end{enumerate}
\end{co}

\begin{proof}
(1)$\Rightarrow$(2): By Prop. \ref{lb24} and \ref{lb23}. 

(2)$\Rightarrow$(1): Assume (2). Since $(x_n)$ is bounded, it can be contained in $X=I_1\times\cdots\times I_N$ where each $I_i$ is a closed interval in $\Rbb$. Clearly, any two cluster points of $(x_n)$ are inside $X$, and are equal by (2). By Bolzano-Weierstrass, $X$ is sequentially compact. Thus, by Thm. \ref{lb74}, $(x_n)$ converges in $X$ and hence in $\Rbb^N$.
\end{proof}

\begin{co}\label{lb113}
The following are true.
\begin{itemize}
\item[1.] Let $(x_n)$ be a sequence in $\ovl\Rbb$. Then $(x_n)$ converges in $\ovl\Rbb$ iff $\dps\limsup_{n\rightarrow\infty} x_n$ equals $\dps\liminf_{n\rightarrow\infty} x_n$. 
\item[2.] Let $(x_n)$ be a sequence in $\Rbb$. Then $(x_n)$ converges in $\Rbb$ iff $\dps\limsup_{n\rightarrow\infty} x_n$ equals $\dps\liminf_{n\rightarrow\infty} x_n$ and $(x_n)$ is bounded.
\end{itemize}
\end{co}

Note that if $(x_n)$ converges in $\ovl\Rbb$, we must have $\lim x_n=\limsup x_n=\liminf x_n$ by Thm. \ref{lb68}.

\begin{proof}
1. Let $A=\liminf x_n$ and $B=\limsup x_n$. Let $S$ be the set of cluster points of $(x_n)$.  By Thm. \ref{lb68}, $A=\min S,B=\max S $. So $A=B$ iff $S$ has only one element. This is equivalent to the convergence of $(x_n)$ in $\ovl\Rbb$ due to Thm. \ref{lb74} (since $\ovl\Rbb$ is sequentially compact by Bolzano-Weierstrass.)

2. If $(x_n)$ converges, then $A=B$ by part 1. And $(x_n)$ is bounded due to Prop. \ref{lb24}. Conversely, if $A=B$ and if $(x_n)$ is bounded, say $\alpha\leq x_n\leq \beta$ for all $n$ where $-\infty<\alpha<\beta<+\infty$. Then $\alpha\leq A\leq B\leq\beta$. So $A,B\in\Rbb$. By part 1, $(x_n)$ converges to $A\in\Rbb$.
\end{proof}



\subsection{Outlook: sequentially compact function spaces}


In Sec. \ref{lb55}, we mentioned that metric spaces and (more generally) point-set topology were introduced by mathematicians in order to study (typically infinite dimensional) function spaces with the help of the geometric intuition of $\Rbb^N$.  Now we have learned a couple of important results about sequentially compact spaces. But we have not met any example arising from function spaces. So let me show one example to the curious readers: The product space $[0,1]^{\Zbb_+}$, equipped with the metric defined in Pb. \ref{lb78}, is sequentially compact. We will prove this result at the end of this chapter. (Indeed, we will prove a slightly more general version. See  Thm. \ref{lb89}.) This is a famous result, not only because it has many important applications (some of which will be hinted at in this section), but also because its proof uses the clever  ``diagonal method".  

Moreover, we will later prove an even more surprising fact: every sequentially compact metric space is homeomorphic to a closed subset of $[0,1]^{\Zbb_+}$. Thus, all sequentially compact metric spaces can be constructed explicitly, in some sense.

The readers may still complain that functions on $\Zbb_+$ are very different from those we often see and use in analysis and (especially) in differential equations: We are ultimately interested in functions on $\Rbb$ or on $[a,b]$, but not on countable sets. This is correct. But $[0,1]^{\Zbb_+}$ (and its closed subsets) are in fact very helpful for the study of spaces of functions on $\Rbb$ and on $[a,b]$. In this course, we shall learn two major examples that the sequential compactness of $[0,1]^{\Zbb_+}$ helps with:
\begin{enumerate}
\item $A=\Qbb\cap[a,b]$ is a countable dense subset of $[a,b]$. Thus, if we let $C([a,b])$ denote the set of continuous $\Rbb$-functions on $[a,b]$, then the restriction map $f\in C([a,b])\mapsto f|_A\in\Rbb^A$ is injective. In many applications, we are interested in a subset $\mc X\subset C([a,b])$ of uniformly bounded functions, say all $f\in\mc X$ take values in $[-1,1]$. Then we have an injective map
\begin{align*}
\Phi:\mc X\rightarrow [-1,1]^A\qquad f\mapsto f|_A
\end{align*}
If $\mc X$ satisfies a condition called ``\textbf{equicontinuous}", then  a sequence $f_n$ in $\mc X$ converges \emph{uniformly} to $f\in C([a,b])$ iff $f_n|_A$ converges \emph{pointwisely} to $f|_A$. (See Rem. \ref{lb145}.) Thus, from the sequential compactness of $[-1,1]^A$ under pointwise convergence topology, one concludes that every sequence in $\mc X$ has a subsequence converging uniformly in $C([a,b])$. This remarkable sequential compactness result on (the closure of) $\mc X$ is called \textbf{Arzel\`a-Ascoli theorem}, and will be used to prove the fundamental Peano existence theorem in ordinary differential equations. We also see that the fact that $[a,b]$ has a countable dense subset $A$ plays a crucial role. This property of metric spaces is called ``\textbf{separable}" and will be studied later.

\item \textbf{Fourier series} are powerful for the study of partial differential equations. A continuous function $f:[-\pi,\pi]\rightarrow\Cbb$ satisfying $f(-\pi)=f(\pi)$ has Fourier series expansion $f(x)=\sum_{n\in\Zbb}a_n e^{\im nx}$ where $a_n\in\Cbb$. However, for the sake of studying differential equations, one needs to consider series $\sum_{n\in\Zbb}a_n e^{\im nx}$ converging to a function much worse than a continuous function. For example, in the study of integral equations (which are closely related to certain partial differential equations), Hilbert and Schmidt discovered that one has to consider all $f(x)=\sum_{n\in\Zbb}a_n e^{\im nx}$ satisfying $\sum_n |a_n|^2\leq 1$. Therefore, one lets $\ovl B=\{z\in\Cbb:|z|\leq 1\}$ and considers $\wht f:n\in\Zbb\mapsto a_n\in\Cbb$ as an element of $\ovl B^\Zbb$. The sequential compactness of $\ovl B^\Zbb$ helps one find the $\wht f$ such that the corresponding $f(x)=\sum_n \wht f(n)\cdot e^{\im nx}$ is a desired solution of the integral equation. 
\end{enumerate}




\subsection{Complete metric spaces and Banach spaces}

In this section, we let $\Fbb\in\{\Rbb,\Cbb\}$, and assume that all vector spaces are over $\Fbb$.


\subsubsection{Cauchy sequences and complete metric spaces}

\begin{df}
A sequence $(x_n)$ in a metric space $X$ is called a \textbf{Cauchy sequence}, \index{00@Cauchy sequence}if:
\begin{itemize}
\item For every $\eps>0$  there exists $N\in\Zbb_+$ such that for all $m,n\geq N$ we have $d(x_m,x_n)<\eps$.
\end{itemize}
\end{df}

Here, ``$\eps>0$" can mean either ``$\eps\in\Rbb_{>0}$" or ``$\eps\in\Qbb_{>0}$". The choice of this meaning does not affect the definition. The above definition can be abbreviated to ``for every $\eps>0$, we have $d(x_m,x_n)<\eps$ for sufficiently large $m,n$". 

\begin{rem}
It is an easy consequence of triangle inequality that $(x_n)$ is a Cauchy sequence iff
\begin{itemize}
\item For every $\eps>0$ there exists $N\in\Zbb_+$ such that for all $n\geq N$ we have $d(x_n,x_N)<\eps$.
\end{itemize}
Also, it is clear that every Cauchy sequence is bounded.
\end{rem}


\begin{pp}\label{lb83}
Every convergent sequence in a metric space $X$ is a Cauchy sequence.
\end{pp}

\begin{proof}
Assume $(x_n)$ converges to $x$ in $X$. Then for every $\eps>0$ there is $N\in\Zbb_+$ such that $d(x,x_n)<\eps/2$ for all $n\geq N$. Since this is true for every $m\geq N$, we have $d(x_m,x_n)\leq d(x,x_n)+d(x,x_m)<\eps/2+\eps/2=\eps$.
\end{proof}


\begin{df}
A metric space $X$ is called \textbf{complete} \index{00@Complete metric space} if every Cauchy sequence in $X$ converges.
\end{df}




We have many examples of complete metric spaces:

\begin{thm}\label{lb79}
If $(x_n)$ is a Cauchy sequence in a metric space $X$ with at least one cluster point, then $(x_n)$ converges in $X$. Consequently, every sequentially compact metric space is complete.
\end{thm}

\begin{proof}
Let $(x_n)$ be a Cauchy sequence in $X$ with subsequence $(x_{n_k})$ converging to $x\in X$. Let us show that $x_n\rightarrow x$. 

Since $(x_n)$ is Cauchy, for every $\eps>0$ there is $N\in\Zbb_+$ such that $d(x_n,x_m)<\eps/2$ for all $m,n\geq N$. Since $x_{n_k}\rightarrow x$, there is $k\geq N$ such that $d(x_{n_k},x)<\eps/2$. Since $n_k$ is strictly increasing over $k$, we have $n_k\geq k$. So $n_k\geq N$. So we can let $m=n_k$. This gives $d(x_n,x_{n_k})<\eps/2$. Therefore $d(x_n,x)\leq d(x_n,x_{n_k})+d(x_{n_k},x)<\eps$ for all $n\geq N$.
\end{proof}

\begin{eg}\label{lb84}
Let  $X=[a_1,b_1]\times\cdots\times [a_N,b_N]$  where each $[a_i,b_i]$ is a closed interval in $\Rbb$, then $X$ is  sequentially compact by Bolzano-Weierstrass. Thus, by Thm. \ref{lb79}. $X$ is complete.
\end{eg}


\begin{co}\label{lb80}
$\Rbb^N$ and $\Cbb^N$ are complete (under the Euclidean metrics).
\end{co}

\begin{proof}
Since $\Cbb^N$ is isometrically isomorphic to $\Rbb^{2N}$, it suffices to prove that $\Rbb^N$ is complete. Choose a Cauchy sequence $(x_n)$ in $\Rbb^N$. Since $(x_n)$ is bounded, $(x_n)$ is contained inside $X=I_1\times\cdots\times I_N$ where each $I_i=[a,b]$ is in $\Rbb$. By Exp. \ref{lb84}, $X$ is complete. So $(x_n)$ converges to some $x\in X$.
\end{proof}





\begin{df}\label{lb99}
We say that a subset $A$ of a metric space $X$ is \textbf{closed} \index{00@Closed subset} if the following condition is true: For every sequence $(x_n)$ in $A$ converging to a point $x\in X$, we have $x\in A$.
\end{df}


Thus, the word ``closed" here means ``closed under taking limits".


\begin{pp}\label{lb86}
Let $A$ be a metric subspace of a metric space $X$. Recall  that the metric of $A$ inherits from that of $X$ (cf. Def. \ref{lb43}). Consider the statements:
\begin{enumerate}[label=(\arabic*)]
\item $A$ is complete.
\item $A$ is a closed subset of $X$.
\end{enumerate}
Then (1)$\Rightarrow$(2). If $X$ is complete, then (2)$\Rightarrow$(1).
\end{pp}


\begin{proof}
First, assume that $X$ is complete and (2) is true. Let $(x_n)$ be a Cauchy sequence in $A$. Then it is a Cauchy sequence in $X$. So $x_n\rightarrow x\in X$ because $X$ is complete. So $x\in A$ by the definition of closedness. This proves (1).

Next, we assume (1). Choose a sequence $(x_n)$ in $A$ converging to a point $x\in X$. By Prop. \ref{lb83}, $(x_n)$ is a Cauchy sequence in $X$, and hence a Cauchy sequence in $A$. Since $A$ is complete, there is $a\in A$ such that $x_n\rightarrow a$. So we must have $x=a$ because any sequence has at most one limit in a metric space. This proves $x\in A$. So (2) is proved.
\end{proof}

A similar result holds for sequential compactness. See Pb. \ref{lb90}.

\begin{eg}
Let $-\infty<a<b<+\infty$. Then $(a,b)$ is not complete (under the Euclidean metric), because $(a,b)$ is not closed in the metric space $\Rbb$. (For sufficiently large $n$, $b-1/n$ is in $(a,b)$, but $\lim_{n\rightarrow\infty} (b-1/n)=b$ is not in $b$.) 
\end{eg}

\begin{eg}
By Prop. \ref{lb2}, for each $x\in\Rbb\setminus\Qbb$, we can choose an increasing sequence in $\Qbb$ converging to $x$. So $\Qbb$ is not closed in $\Rbb$. So $\Qbb$ is not complete under the Euclidean topology.
\end{eg}


\begin{eg}\label{lb97}
Let $X$ be a metric space. Let $p\in X$ and $0\leq R<+\infty$. Then $\ovl B_X(x,R)$ is a closed subset of $X$. Therefore, if $X$ is complete, then $\ovl B_X(p,R)$ is complete by Prop. \ref{lb86}.
\end{eg}

\begin{proof}[Proof of closedness]
Let $(x_n)$ be a sequence in $\ovl B(p,R)$ converging to $x\in X$. Then $d(p,x_n)\leq R$. Since the function $y\in X\mapsto d(p,y)\in\Rbb$ is continuous (Exp. \ref{lb45}),  we have $d(p,x)=\lim_{n\rightarrow\infty}d(p,x_n)\leq R$. So $x\in\ovl B(p,R)$.
\end{proof}



\begin{exe}
Let $d,\delta$ be two equivalent metrics on a set $X$. Show that a sequence $(x_n)$ in $X$ is Cauchy under $d$ iff $(x_n)$ is Cauchy under $\delta$. 

Note that if, instead of assuming $d,\delta$ are equivalent, we only assume that $d,\delta$ are topologically equivalent. Then the above conclusion is not necessarily true:
\end{exe}


\begin{exe}
Find a non-complete metric $\delta$ on $\Rbb$ topologically equivalent to the Euclidean metric.
\end{exe}



%% Record  #3  2023/9/25





\subsubsection{Normed vector spaces and Banach spaces}



A major application of complete metric spaces is to show that many series converge without knowing to what exact values these series converge. A typical example is the convergence of $\sum_{n\in\Zbb_+}\sin(\sqrt 2n)/n^2$ in $\Rbb$. We are also interested in the convergence of series in function spaces, for instance: the uniform convergence of $f(x)=\sum_{n\in\Zbb_+}\sin(\sqrt 2nx^3)/n^2$ on $\Rbb$; a suitable convergence of the Fourier series $\sum_{n\in\Zbb}a_ne^{\im n x}$. But we cannot take sum in a general metric space since it has no vector space structures. Therefore, we need a notion which combines complete metric spaces with vector spaces. Banach spaces are such a notion. 



\begin{df}\label{lb91}
Let $V$ be a vector space over $\Fbb$ with zero vector $0_V$. A function $\lVert\cdot\lVert:V\rightarrow\Rbb_{\geq 0}$ is called a \textbf{norm} \index{00@Norm} if for every $u,v\in V$ and $\lambda\in\Fbb$, the following hold:
\begin{itemize}
\item (Subadditivity) $\lVert u+v\lVert\leq \lVert u\lVert+\lVert v\lVert$. \index{00@Subadditivity}
\item (Absolute homogeneity) $\lVert\lambda v\lVert=|\lambda|\cdot \lVert v\lVert$. In particular, (by taking $\lambda=0$) we have $\lVert 0_V\lVert=0$.
\item If $\lVert v\lVert=0$ then $v=0_V$.
\end{itemize}
We call $(V,\lVert\cdot\lVert)$ (often abbreviated to $V$) a \textbf{normed vector space}. \index{00@Normed vector space}
\end{df}

\begin{rem}
Let $V$ be a vector space. If $V$ is a normed vector space, then
\begin{align}
d(u,v)=\lVert u-v\lVert  \label{eq21}
\end{align} 
clearly defines a metric. (Note that triangle inequality follows from subadditivity.) Unless otherwise stated, we always assume that the metric of a normed vector space is defined by \eqref{eq21}.
\end{rem}




\begin{df}
Let $V$ be a normed vector space. We say that $V$ is a \textbf{Banach space} \index{00@Banach space} if $V$ is a complete metric space where the metric is the canonical one \eqref{eq21}. If $V$ is over the field $\Cbb$ (resp. $\Rbb$), we call $V$ a \textbf{complex} (resp. \textbf{real}) \textbf{Banach space}.
\end{df}




\begin{eg}
We always assume that the norm on $\Fbb^N$ is the \textbf{Euclidean norm} \index{00@Euclidean norm}
\begin{align}
\lVert (a_1,\dots,a_N)\lVert=\sqrt{|a_1|^2+\cdots+|a_N|^2}
\end{align}
The canonical metric it gives is the Euclidean metric. Thus, by Cor. \ref{lb80}, $\Fbb^N$ is a Banach space.
\end{eg}



If $(\lambda_n)$ is a sequence in $\Fbb$ converging to $\lambda$, and if $(x_n)$ is a sequence in $\Fbb^N$ converging to $x$, then one can show that $\lambda_nx_n$ converges to $\lambda x$ by checking that each component of $\lambda_nx_n$ converges to the corresponding component of $\lambda x$. This is due to Prop. \ref{lb38}. However, if $(x_n)$ is in general a sequence in a normed vector space, this method fails. So we need a different argument:

\begin{pp}\label{lb82}
Let $V$ be a normed vector space. The following maps are continuous
\begin{gather*}
+: V\times V\rightarrow V\qquad (u,v)\mapsto u+v\\
-: V\times V\rightarrow V\qquad (u,v)\mapsto u-v\\
\times_\Fbb: \Fbb\times V\rightarrow V\qquad (\lambda,v)\mapsto \lambda v\\
\lVert\cdot\lVert:V\rightarrow\Rbb_{\geq 0}\qquad v\mapsto \lVert v\lVert
\end{gather*}
\end{pp}

We didn't mention the continuity of the division map $(\lambda,v)\in\Fbb^\times\times V\mapsto\lambda^{-1}v$ since it follows from that of $\times_\Fbb$ and of the inversion map $\lambda\mapsto\lambda^{-1}$ by Exp. \ref{lb35}.

\begin{proof}
One can check that the addition map, the subtraction map, and the last map $\lVert\cdot\lVert$ are Lipschitz continuous. 

Define metric $d((\lambda,v),(\lambda',v'))=\max\{|\lambda-\lambda'|,\lVert v-v'\lVert \}$ on $\Fbb\times V$. Then $\Fbb\times V$ is covered by open balls of the form $B(0,r)=\{(\lambda,v)\in\Fbb\times V:|\lambda|<r,\lVert v\lVert<r\}$. Similar to the argument in \eqref{eq22}, one uses subadditivity (i.e. triangle inequality) and absolute homogeneity to show that $\times_\Fbb$ has Lipschitz constant $2r$ on $B(0,r)$. So $\times_\Fbb$ is continuous by Lem. \ref{lb30} and \ref{lb34}.
\end{proof}








\subsection{The Banach spaces $l^\infty(X,V)$ and $C(X,V)$}


In this section, we let $\Fbb\in\{\Rbb,\Cbb\}$ and assume that the vector spaces $V$ are over $\Fbb$. As the title suggests, in this section we shall introduce two important examples of Banach spaces: the space of uniformly bounded functions $l^\infty(X,V)$ and its  subspace of continuous functions $C(X,V)$ (when $X$ is a sequentially compact metric space).  In order for these two spaces to be Banach spaces, we must assume that $V$ is also Banach. 

In application, the main examples are $V=\Rbb,\Cbb,\Rbb^N,\Cbb^N$. Indeed, $C([a,b],\Rbb^N)$ is one of the main examples of function spaces considered by Fr\'echet when he defined metric spaces. Therefore, the readers can assume that $V$ is one of such spaces if they want to make life easier. Just keep in mind that we sometimes also consider the case where $V$ itself is a function space.

\begin{df}\label{lb150}
Let $X$ be a set and let $V$ be a vector space. The set $V^X$ \index{VX@$V^X$ as a vector space} is a vector space if we define for each $f,g\in V^X$ and $\lambda\in\Fbb$:
\begin{gather*}
f+g:X\rightarrow V\qquad (f+g)(x)=f(x)+g(x)\\
\lambda f:X\rightarrow V\qquad (\lambda f)(x)=\lambda f(x)
\end{gather*}
We also define the \textbf{absolute value function}\index{00@Absolute function $\lvert f\lvert$} \index{f@$\lvert f\lvert$}
\begin{align}
|f|:X\rightarrow\Rbb_{\geq 0}\qquad x\in X\mapsto \lVert f(x)\lVert
\end{align}
The symbol $|f|$ is sometimes also written as $\lVert f\lVert$ when it will not be confused with $\lVert f\lVert_{\infty}$ or other norms of $f$.
\end{df}



\begin{df}
Let $X$ be a set and let $V$ be a normed vector space. For each $f\in V^X$, define the \index{l@$\lVert\cdot\lVert_{l^\infty}=\lVert f\lVert_{l^\infty(X,V)}=\lVert\cdot\lVert_\infty$} \pmb{$l^\infty$}\textbf{-norm}
\begin{align}
\lVert f\lVert_{l^\infty(X,V)}\equiv\lVert f\lVert_{l^\infty}\equiv \lVert f\lVert_\infty=\sup_{x\in X}\lVert f(x)\lVert
\end{align}
where $\lVert f(x)\lVert$ is defined by the norm of $V$. Define the \pmb{$l^\infty$}\textbf{-space} \index{l@$l^\infty(X,V)$} 
\begin{align}
l^\infty(X,V)=\{f\in V^X:\lVert f\lVert_\infty<+\infty\}
\end{align}
which is a vector subspace of $V^X$. Then $l^\infty(X,V)$ is a normed vector space under the $l^\infty$-norm. A function $f:X\rightarrow V$ is called \textbf{uniformly bounded} \index{00@Uniformly bounded function} if $f\in l^\infty(X,V)$.
\end{df}





\begin{exe}\label{lb143}
Prove that for every $f,g\in V^X$ and $\lambda\in\Fbb$ we have
\begin{gather}\label{eq23}
\begin{gathered}
\lVert f+g\lVert_\infty\leq \lVert f\lVert_\infty+\lVert g\lVert_\infty\\
\lVert \lambda f\lVert_\infty=|\lambda|\cdot \lVert f\lVert_\infty
\end{gathered}
\end{gather}
(Note that clearly we have that $\lVert f\lVert_\infty=0$ implies $f=0$.) Here, we understand $0\cdot (+\infty)=0$. Use these relations to verify that $l^\infty(X,V)$ is a linear subspace of $V^X$ (i.e. it is closed under addition and scalar multiplication) and that $\lVert\cdot\lVert_\infty$ is a norm on $l^\infty(X,V)$.  \hfill\qedsymbol
\end{exe}

\begin{df}\label{lb148}
Let $V$ be a normed vector space. We say that a sequence $(f_n)$ in $V^X$ \textbf{converges uniformly} \index{00@Uniform convergence} to $f\in V^X$ if $\lim_{n\rightarrow\infty}\lVert f-f_n\lVert_\infty=0$. In this case, we write ${f_n}\rightrightarrows f$. \index{fnf@$f_n\rightrightarrows f$}

We say that $(f_n)$ \textbf{converges pointwisely} \index{00@Pointwise convergence} to $f\in V^X$ if for every $x\in X$ we have $\lim_{n\rightarrow\infty} f_n(x)=f(x)$, i.e. $\lim_{n\rightarrow\infty} \lVert f_n(x)-f(x)\lVert=0$. 

The same definition will be applied to nets $(f_\alpha)_{\alpha\in I}$ in $V^X$ after learning net convergence in Sec. \ref{lb147}. \hfill\qedsymbol
\end{df}


In more details, the uniform convergence of $f_n$ to $f$ means that ``for every $\eps>0$ there is $N\in\Zbb_+$ such that for all $n\geq N$ and  \emph{for all $x\in X$}, we have $\lVert f_n(x)-f(x)\lVert<\eps$". If we place the words ``for all $x\in X$" at the very beginning of the sentence, we get pointwise convergence.


Uniform convergence implies pointwise convergence: If $\lVert f-f_n\lVert_\infty\rightarrow 0$, then for each $x\in X$ we have $\lVert f_n(x)-f(x)\lVert\rightarrow 0$ since $\lVert f(x)-f_n(x)\lVert\leq\lVert f-f_n\lVert_\infty$. 



\begin{eg}
Let $f_n:(0,1)\rightarrow\Rbb$ be $f_n(x)=x^n$. Then $f_n$ converges pointwisely to $0$ (cf. Exp. \ref{lb110}). But $\sup_{x\in(0,1)}|x^n-0|=1$ does not converge to $0$. So $f_n$ does not converge uniformly to $0$.
\end{eg}



\begin{rem}
The uniform convergence of sequences in $l^\infty(X,V)$ is induced by the $l^\infty$-norm, and hence is induced by the metric $d(f,g)=\lVert f-g\lVert_\infty$. However, this formula cannot be extended to a metric on $V^X$, since for arbitrary $f,g\in V^X$, $\lVert f-g\lVert_\infty$ is possibly $+\infty$. 



In fact, it is true that the uniform convergence of sequences in $V^X$ is induced by a metric, see Pb. \ref{lb81}. When $X$ is countable, we have seen in Pb. \ref{lb78} that the pointwise convergence in $V^X$ is also given by a metric. \hfill\qedsymbol
\end{rem}












\begin{thm}\label{lb85}
Let $X$ be a set, and let $V$ be a Banach space (over $\Fbb$). Then $l^\infty(X,V)$ is a Banach space (over $\Fbb$).
\end{thm}


\begin{proof}
Let $(f_n)$ be a Cauchy sequence in $l^\infty(X,V)$. Then for every $\eps>0$ there is $N\in\Zbb_+$ such that for all $m,n\geq N$ we have that $\sup_{x\in X}\lVert f_n(x)-f_m(x)\lVert <\eps$, and hence $\lVert f_n(x)-f_m(x)\lVert <\eps$ for each $x\in X$. This shows that for each $x\in X$, $(f_n(x))$ is a Cauchy sequence in $V$, which converges to some element $f(x)\in V$ because $V$ is complete.

We come back to the statement that for each $\eps>0$, there exists $N\in\Zbb_+$ such that for all $n\geq N$ and all $x$,
\begin{align*}
\lVert f_n(x)-f_m(x)\lVert <\eps  
\end{align*}
for every $m\geq N$. Let $m\rightarrow\infty$. Then by the continuity of subtraction and taking norm (cf. Prop. \ref{lb82}.), we obtain $\lVert f_n(x)-f(x)\lVert\leq \eps$ for all $n\geq N$ and $x\in X$. In other words, $\lVert f_n-f\lVert_\infty\leq\eps$ for all $n\geq N$. In particular, $\lVert f\lVert_\infty\leq\lVert f_N\lVert_\infty +\lVert f_N-f\lVert_\infty<+\infty$ by \eqref{eq23}. This proves $f\in l^\infty(X,V)$ and $f_n\rightrightarrows f$.
\end{proof}


Mathematicians used to believe that ``if a sequence of continuous functions $f_n:[0,1]\rightarrow\Rbb$ converges pointwisely to a function $f:[0,1]\rightarrow\Rbb$, then $f$ is continuous". Cauchy, one of the main figures in 19th century working on putting analysis on a rigorous ground, has given a problematic proof of this wrong statement. Counterexamples were later found in the study of Fourier series: Let $f:\Rbb\rightarrow\Rbb$ be a function with period $2\pi$ such that $f(x)=x$ when $-\pi<x<\pi$, and $f(x)=0$ when $x=\pm \pi$. Then the Fourier series  of this noncontinuous function $f$ converges pointwisely to $f$, yet the partial sums of this series are clearly continuous functions. Later, it was realized that uniform convergence is needed to show the continuity of the limit function. (See Thm. \ref{lb87}.) This was the first time the importance of uniform convergence was realized.

\begin{df}
Let $X,Y$ be  metric spaces (or more generally, topological spaces to be defined later). Then $C(X,Y)$ \index{CXY@$C(X,Y)$, the set of continuous functions $X\rightarrow Y$. See Conv. \ref{lb85} also} denotes the set of continuous functions from $X$ to $Y$. 
\end{df}

\begin{lm}
Let $X$ be a metric space, and let $V$ be a normed vector space. Then $C(X,V)$ is a linear subspace of $V^X$. If $X$ is sequentially compact, then $C(X,V)$ is a linear subspace of $l^\infty(X,V)$.
\end{lm}

\begin{proof}
Using Prop. \ref{lb82}, one checks easily that $C(X,V)$ is a linear subspace of $V^X$.  For any $f\in C(X,V)$, the absolute value function $|f|:x\in X\mapsto\lVert f(x)\lVert$ is continuous. Thus, assuming that $X$ is sequentially compact, then by Lem. \ref{lb56}, $|f|$ is bounded on $X$. This proves that $\lVert f\lVert_\infty<+\infty$. Thus $C(X,V)$ is a subset (and hence a linear subspace) of $l^\infty(X,V)$. 
\end{proof}



\begin{thm}\label{lb87}
Let $X$ be a metric space, and let $V$ be a normed vector space. Then $C(X,V)\cap l^\infty(X,V)$ is a closed linear subspace of $l^\infty(X,V)$. In particular, if $X$ is sequentially compact, then $C(X,V)$ is a closed linear subspace of $l^\infty(X,V)$.
\end{thm}



\begin{proof}
Choose a sequence $(f_n)$ in $C(X,V)\cap l^\infty(X,V)$ converging in $l^\infty(X,V)$ to $f$. Namely, $f_n\rightrightarrows f$. We want to prove that $f$ is continuous. We check that $f$ satisfies Def. \ref{lb31}-(2'). (One can also use Def. \ref{lb31}-(1). The proofs using these two definitions are not substantially different.)

Fix $p\in X$. Choose any $\eps>0$. Since $f_n\rightrightarrows f$, there exists $N\in\Zbb_+$ such that for all $n\geq N$ and we have $\lVert f-f_n\lVert_\infty<\eps$. Since $f_N$ is continuous, there exists $r>0$ such that for each $x\in B_X(p,r)$ we have $\lVert f_N(x)-f_N(p)\Vert<\eps$. Thus, for each $x\in B_X(p,r)$ we have
\begin{align*}
\lVert f(x)-f(p)\lVert\leq \lVert f(x)-f_N(x)\lVert +\lVert f_N(x)-f_N(p)\lVert+\lVert f_N(p)-f(p)\lVert<3\eps
\end{align*}
This finishes the proof.
\end{proof}





\begin{cv}\label{lb88}
Unless otherwise stated, if $X$ is sequentially compact metric space (or more generally, a compact topological space to be defined latter), and if $V$ is a normed vector space, the norm on $C(X,V)$ is chosen to be the $l^\infty$-norm.
\end{cv}


\begin{co}\label{lb101}
Let $X$ be a metric space, and let $V$ be a Banach space. Then  $C(X,V)\cap l^\infty(X,V)$ is a Banach space (under the $l^\infty$-norm). In particular, if $X$ is sequentially compact, then $C(X,V)$ is a Banach space.
\end{co}

\begin{proof}
This follows immediately from Prop. \ref{lb86}, Thm. \ref{lb87}, and the fact that $l^\infty(X,V)$ is complete (Thm. \ref{lb85}).
\end{proof}










\subsection{Problems and supplementary material}



\begin{prob}\label{lb64}
Let $(x_n)$ be a sequence in a metric space $X$. Let $x\in X$. Prove that the following are equivalent.
\begin{itemize}
\item[(1)] $x$ is a cluster point of $(x_n)$, i.e., the limit of a convergent subsequence of $(x_n)$.
\item[(2)] For each $\eps>0$ and each $N\in\Zbb_+$, there exists $n\geq N$ such that $d(x_n,x)<\eps$.
\end{itemize}
\end{prob}


\begin{rem}
Condition (2) is often abbreviated to ``for each $\eps>0$, the sequence $(x_n)$ is frequently in $B(x,\eps)$". In general, we say ``$(x_n)$ \textbf{frequently} satisfies P" if for each $N\in\Zbb_+$ there is $n\geq N$ such that $x_n$ satisfies P. We say that ``$(x_n)$ \textbf{eventually} satisfies P" if there exists $N\in\Zbb_+$ such that for every $n\geq N$, $x_n$ satisfies P. \index{00@Eventually} \index{00@Frequently}  

Thus ``$(x_n)$ eventually satisfies P" means the same as ``all but finitely many $x_n$ satisfies P". Its negation is ``$(x_n)$ frequently satisfies $\neg$P".   \hfill\qedsymbol
\end{rem}

\begin{rem}
Condition (2) of Pb. \ref{lb64} is sometimes easier to use than (1). For example, compared to the original definition of cluster points, it is much easier to find an explicit negation of (2) by using the rule suggested in Rem. \ref{lb100}: There exist $\eps>0$ and $N\in\Zbb_+$ such that $d(x_n,x)\geq\eps$ for all $n\geq N$. (Or simply: there exists $\eps>0$ such that $x_n$ is eventually not in $B(x,\eps)$.) 
\end{rem}



\begin{prob}\label{lb70}
Use Pb. \ref{lb64}-(2) to prove that if $(x_n)$ is a sequence in $\ovl\Rbb$, then $\dps\limsup_{n\rightarrow\infty} x_n$ is a cluster point of $(x_n)$.
\end{prob}

\begin{rem}
You will notice that your proof of Pb. \ref{lb70} is slightly simpler than the proof we gave for Thm. \ref{lb68}. This is because our construction of subsequence as in \eqref{eq17} has been incorporated into your proof of (2)$\Rightarrow$(1) in Pb. \ref{lb64}.
\end{rem}

\begin{prob}
Let $f:X\rightarrow Y$ be a continuous map of metric spaces. Assume that $f$ is bijective and $X$ is sequentially compact.  Prove that $f$ is a homeomorphism using the following hint.
\end{prob}

\begin{proof}[Hint]
You need to prove that if $(y_n)$ is a sequence in $Y$ converging to $y\in Y$, then $x_n=f^{-1}(y_n)$ converges to $x=f^{-1}(y)$. Prove that $(x_n)$ has only one cluster point, and hence converges to some point $x'\in X$ (why?). Then prove $x'=x$. (In the future, we will use the language of open sets and closed sets to prove this result again. Do not use this language in your solution.)
\end{proof}




\begin{thm}[\textbf{Tychonoff theorem, countable version}]\index{00@Tychonoff theorem, countable version}  \label{lb89}
Let $(X_n)_{n\in\Zbb_+}$ be a sequence of sequentially compact metric spaces. Then the product space $\dps S=\prod_{n\in\Zbb_+} X_n$ is sequentially compact under the metric defined  as in Pb. \ref{lb78}.
\end{thm}

The method of choosing subsequence in the following proof is the reknowned \textbf{diagonal method}. \index{00@Diagonal method}

\begin{proof}
Let $(x_m)_{m\in\Zbb_+}$ be a sequence in $S$. Since $(x_m(1))_{m\in\Zbb_+}$ is a sequence in the sequentially compact space $X_1$, $(x_m)_{m\in\Zbb_+}$ has a subsequence $x_{1,1},x_{1,2},x_{1,3}\dots$ whose value at $n=1$ converges in $X_1$. Since $X_2$ is sequentially compact, we can choose a subsequence $x_{2,1},x_{2,2},x_{2,3},\dots$ of the previous subsequence such that its values at $n=2$ converge in $X_2$. Then pick a subsequence from the previous one whose values at $3$ converge in $X_3$. 

By repeating this process, we get an $\infty\times\infty$ matrix $(x_{i,j})_{i,j\in\Zbb_+}$:
\begin{equation}
\begin{tikzcd}[sep=0cm]
{x_{1,1}} & {x_{1,2}} & {x_{1,3}} & \cdots \\
{x_{2,1}} & {x_{2,2}} & {x_{2,3}} & \cdots \\
{x_{3,1}} & {x_{3,2}} & {x_{3,3}} & \cdots \\
\vdots    & \vdots    & \vdots    & \ddots
\end{tikzcd}
\end{equation}
such that the following hold:
\begin{itemize}
\item The $1$-st line is a subsequence of the original sequence $(x_m)_{m\in\Zbb_+}$.
\item The $(i+1)$-th line is a subsequence of the $i$-th line.
\item For each $n$, $\lim_{j\rightarrow\infty} x_{n,j}(n)$ converges in $X_n$.
\end{itemize}
Then the diagonal line $(x_{i,i})_{i\in\Zbb_+}$ is a subsequence of the original sequence $(x_m)_{m\in\Zbb_+}$. Moreover, for each $n$, $(x_{i,i})_{i\geq n}$ is a subsequence of the $n$-th line, whose value at $n$ therefore converges in $X_n$. Thus $\lim_{i\rightarrow\infty} x_{i,i}(n)$ converges in $X_n$. Thus, by Pb. \ref{lb78}, $(x_{i,i})_{i\in\Zbb_+}$ converges under any metric inducing the product topology.
\end{proof}




\begin{prob}\label{lb90}
Let $X$ be a sequentially compact metric space. Let $A\subset X$ be a metric subspace.  Consider the statements:
\begin{enumerate}[label=(\arabic*)]
\item $A$ is sequentially compact.
\item $A$ is a closed subset of $Y$.
\end{enumerate}
Prove that (1)$\Rightarrow$(2). Prove that if $Y$ is sequentially compact, then (2)$\Rightarrow$(1).
\end{prob}


The above problem implies immediately:

\begin{thm}[\textbf{Heine-Borel theorem}]\label{lb98}  \index{00@Heine-Borel theorem} 
Let $A$ be a subset of $\Rbb^N$. Then $A$ is sequentially compact iff $A$ is a bounded closed subset of $\Rbb^N$.
\end{thm}

\begin{proof}
Suppose that $A$ is sequentially compact. Then $A$ is bounded under the Euclidean metric by Prop. \ref{lb71}. By Pb. \ref{lb90}, $A$ is a closed subset of $\Rbb^N$.

Conversely, assume that $A$ is a bounded and closed subset of $\Rbb^N$. Then $A\subset B$ where $B$ is the product of $N$ pieces of closed intervals in $\Rbb$. Then $B$ is sequentially compact by Bolzano-Weierstrass. Since $A$ is closed in $\Rbb^N$, it is not hard to check that $A$ is closed in $B$.\footnote{If $Z$ is a metric space, if $X\subset Y\subset Z$, and if $X$ is closed in $Z$, then it is easy to check that $X$ is closed in $Y$.} Thus $A$ is sequentially compact by Pb. \ref{lb90}.
\end{proof}




\begin{eg}
Choose any $p\in \Rbb^N$ and $0\leq R<+\infty$. Then $\ovl B_{\Rbb^N}(p,R)$ is a bounded closed subset of $\Rbb^N$ (Exp. \ref{lb97}), and hence is sequentially compact by Heine-Borel.
\end{eg}

\begin{rem}
Think about the question: Equip $\Rbb^{\Zbb_+}$ with metric
\begin{align*}
d(x,y)=\sup_{n\in\Zbb_+}\frac {\min\{|x(n),y(n)|,1\}}{n}
\end{align*} 
What are the sequentially compact subsets of $\Rbb^{\Zbb_+}$? (Namely, think about how to generalize Heine-Borel theorem to $\Rbb^{\Zbb_+}$.)
\end{rem}



\begin{prob}
Do Exercise \ref{lb143}.
\end{prob}




\begin{prob}\label{lb81}
Let $V$ be a normed vector space. For every $f,g\in V^X$ define
\begin{align}
d(f,g)=\min\{1,\lVert f-g\lVert_\infty \}\label{eq55}
\end{align}
\begin{enumerate}
\item Show that $d$ defines a metric on $V^X$. 
\item Show for every sequence $(f_n)$ in $V^X$ and every $g\in V^X$, we have $f_n\rightarrow g$ under the metric $d$ iff $f_n\rightrightarrows g$.
\end{enumerate}
\end{prob}

\begin{df}\label{lb146}
Let $X$ be a set, and let $V$ be a normed vector space. A metric on $V^X$ is called a \textbf{uniform convergence metric} \index{00@Uniform convergence metric} if it is topologically equivalent to \eqref{eq55}. Thus, by Def. \ref{lb144}, a uniform convergence metric is one such that a sequence $(f_n)$ in $V^X$ converges to $f$ under this metric iff $f_n\rightrightarrows f$.
\end{df}




\begin{prob}\label{lb103}
Let $X,Y$ be metric spaces, and assume that $Y$ is sequentially compact. Let $V$ be a normed vector space. Choose $f\in C(X\times Y,V)$, i.e., $f:X\times Y\rightarrow V$ is continuous. For each $x\in X$, let
\begin{align*}
f_x:Y\rightarrow V\qquad y\mapsto f(x,y)
\end{align*}
Namely $f_x(y)=f(x,y)$. It is easy to check that $f_x\in C(Y,V)$. Define a new function
\begin{gather}
\begin{gathered}
\Phi(f):X\rightarrow C(Y,V)\qquad x\mapsto f_x
\end{gathered}
\end{gather}
Recall that $C(Y,V)$ is equipped with the $l^\infty$-norm. 
\begin{enumerate}
\item Prove that $\Phi(f)$ is continuous. In other words, prove that if $(x_n)$ is a sequence in $X$ converging to  $x\in X$, then $f_{x_n}\rightrightarrows f_x$ on $Y$, i.e.
\begin{align*}
\lim_{n\rightarrow\infty}\lVert f_{x_n}-f_x\lVert_{l^\infty(Y,V)}=0
\end{align*}
\item[$\star$ 2.]  Give an example of $f\in C(X\times Y,\Rbb)$ where $Y$ is not sequentially compact, $(x_n)$ converges to $x$ in $X$, and $f_{x_n}$ does not converge uniformly to $f_x$. (Note: you may consider $X=Y=\Rbb$.)
\end{enumerate}

\end{prob}

\begin{proof}[Hint]
In part 1, to prove that $\Phi(f)$ is continuous,   one can  prove the equivalent fact that for every fixed $x\in X$ the following is true:
\begin{itemize}
\item For every $\eps>0$ there exists $\delta>0$ such that for all $p\in B_X(x,\delta)$, we have $\sup_{y\in Y}\lVert f(p,y)-f(x,y)\lVert<\eps$. 
\end{itemize}
(Cf. Def. \ref{lb31}.) Prove this by contradiction and by using the sequential compactness of $Y$ appropriately.
\end{proof}


\begin{rem}\label{lb102}
Let $X=\Zbb_+\cup\{\infty\}$, equipped with the metric
\begin{align*}
d(m,n)=|m^{-1}-n^{-1}|
\end{align*} 
In other words, the metric on $X$ is $\tau^*d_\Rbb$ where $d_\Rbb$ is the Euclidean metric on $\Rbb$, and $\tau:X\rightarrow \Rbb,n\mapsto n^{-1}$. It is not hard to show that $X$ is sequentially compact: either prove it directly, or apply Heine-Borel to $\tau(X)$.

Let $Y$ be a metric space. Let $(y_n)_{n\in\Zbb_+}$ be a sequence in $Y$, and let $y_\infty\in Y$. It is not hard to see that the following two statements are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item The function $F:X\rightarrow Y,n\mapsto y_n$ is continuous.
\item The sequence $(y_n)_{n\in\Zbb_+}$ converges to $y_\infty$.
\end{enumerate}
The following problem is a generalization of this equivalence.  \hfill\qedsymbol
\end{rem}



\begin{sprob}\label{lb104}
Let $V$ be a normed vector space. Let $Y$ be a metric space. Let $X=\Zbb_+\cup\{\infty\}$ with metric defined as in Rem. \ref{lb102}. Let $(f_n)_{n\in\Zbb_+}$ be a sequence in $C(Y,V)$. Let $f_\infty\in V^Y$. Prove that the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item The following function is continuous:
\begin{align}
F:X\times Y\rightarrow V\qquad (n,y)\mapsto f_n(y)
\end{align}
In particular, by restricting $F$ to $\infty\times Y$, we see that $f_\infty\in C(Y,V)$.
\item $(f_n)_{n\in\Zbb_+}$ converges pointwisely to $f_\infty$. Moreover, $(f_n)_{n\in\Zbb_+}$ is \textbf{pointwisely equicontinuous}, \index{00@Pointwisely equicontinuous} which means the following:
\begin{itemize}
\item For every $y\in Y$ and every $\eps>0$, there exists $\delta>0$ such that for all $p\in B_Y(y,\delta)$ we have
\begin{align*}
\sup_{n\in\Zbb_+}\lVert f_n(p)-f_n(y)\lVert<\eps
\end{align*}
\end{itemize}
\end{enumerate}
\end{sprob}

\begin{proof}[Note]\renewcommand{\qedsymbol}{}
In part (1), the only nontrivial thing to prove  is that $F$ is continuous at $(\infty,y)$ for every $y\in Y$.
\end{proof}





\begin{rem}
There is a concise way to define pointwise equicontinuity: a sequence $(f_n)_{n\in\Zbb_+}$ in $V^Y$ is pointwisely equicontinuous iff the function
\begin{gather}
Y\mapsto V^{\Zbb_+}\qquad y\mapsto (f_1(y),f_2(y),\dots)
\end{gather}
is continuous, where $V^{\Zbb_+}$ is equipped with any uniform convergence metric (cf. Def. \ref{lb146}). 
\end{rem}

\begin{srem}
In Pb. \ref{lb104}, there is a quick and tricky way to conclude (1)$\Rightarrow$(2): Use Pb. \ref{lb103} and the sequential compactness of $X$. (Do not use this method in your solution. Prove (1)$\Rightarrow$(2) directly; it is a good exercise and is not difficult.)
\end{srem}



\begin{srem}\label{lb145}
Pb. \ref{lb103} and \ref{lb104}, together with Thm. \ref{lb87}, imply the following fact (can you see why?): 
\begin{itemize}
\item Let $Y$ be a sequentially compact metric space. Let $V$ be a normed vector space. Let $(f_n)_{n\in\Zbb_+}$ be a pointwisely equicontinuous sequence of functions $Y\rightarrow V$ converging pointwisely to some $f:Y\rightarrow V$. Then $f_n\rightrightarrows f$ on $Y$. 
\end{itemize}
You can also try to give a straightforward proof of this fact without using Pb. \ref{lb103} and \ref{lb104}.
\end{srem}








\newpage




\section{Series}

In this chapter, we assume that vector spaces are over $\Fbb\in\{\Rbb,\Cbb\}$ unless otherwise stated.





\subsection{Definitions and basic properties}


\begin{df}
Let $V$ be a Banach space (over $\Fbb$). A \textbf{series} \index{00@Series in a Banach space} in $V$ is an expression of the form
\begin{align}
\sum_{i=1}^\infty v_i  \label{eq25}
\end{align}
where $(v_i)_{i\in\Zbb_+}$ is a sequence in $V$. If $s\in V$, we say that the series \eqref{eq25} \textbf{converges to $s$} if
\begin{align*}
s=\lim_{n\rightarrow\infty} \sum_{i=1}^n v_i
\end{align*}
namely, $s_n\rightarrow s$ where $s_n$ is the \textbf{partial sum} \index{00@Partial sum} $s_n=\sum_{i=1}^n v_i$. In this case, we write
\begin{align*}
s=\sum_{i=1}^\infty v_i
\end{align*}
\end{df}


\begin{rem}\label{lb93}
Since $V$ is complete, the series \eqref{eq25} converges iff the sequence of partial sum $(s_n)$ is a Cauchy sequence: for every $\eps>0$ there exists $N\in\Zbb_+$ such that for all $n> m\geq N$ we have $\lVert s_n-s_m\lVert<\eps$, i.e.,
\begin{align}
\Big\lVert \sum_{i=m+1}^n v_i\Big\lVert<\eps  \label{eq28}
\end{align}
\end{rem}


\begin{pp}\label{lb92}
Suppose that $\sum_{i=1}^\infty v_i$ is a convergent series in a Banach space $V$. Then $\dps\lim_{n\rightarrow\infty} v_n=0$.
\end{pp}

\begin{proof}
Let $s_n=v_1+\cdots+v_n$, which converges to $s\in V$. Then $\lim_{n\rightarrow\infty} s_{n+1}=s$. So $v_n=s_{n+1}-s_n\rightarrow s-s=0$ since subtraction in continuous (Prop. \ref{lb82}).
\end{proof}

Thus, for example, $\sum_{n=1}^\infty (-1)^n$ diverges in the Banach space $\Rbb$ since $\lim_{n\rightarrow\infty} (-1)^n$ does not converge to $0$.





\begin{df}
Consider a \textbf{series} in $\ovl\Rbb_{\geq0}$: \index{00@Series in $\ovl\Rbb_{\geq0}$}
\begin{align}
\sum_{i=1}^\infty a_i \label{eq26}
\end{align}
namely, each $a_i$ is in $\ovl\Rbb_{\geq 0}$. Note that the partial sum $s_n=\sum_{i=1}^n a_i$ is increasing. We say that $\lim_{n\rightarrow\infty} s_n$ (which exists in $\ovl\Rbb_{\geq0}$ and equals $\sup\{s_n:n\in\Zbb_+\}$, cf. Rem. \ref{lb58}) is the value of the series \eqref{eq26} and write
\begin{align*}
\sum_{i=1}^\infty a_i=\lim_{n\rightarrow\infty} s_n
\end{align*}
\end{df}


\begin{df}
We say that a series $\sum_{i=1}^\infty a_i$ in $\Rbb_{\geq 0}$ \textbf{converges} if it converges in $\Rbb$ (but not just converges in $\ovl\Rbb_{\geq 0}$, which is always true). Clearly, $\sum_{i=1}^\infty a_i$ converges iff
\begin{align*}
\sum_{i=1}^\infty a_i<+\infty
\end{align*}
More generally, we say that a series $\sum_{i=1}^\infty v_i$ in a Banach space $V$ \textbf{converges absolutely}, \index{00@Absolute convergent series} if
\begin{align*}
\sum_{i=1}^\infty~ \lVert v_i\lVert <+\infty
\end{align*}
\end{df}

\begin{rem}
By the Cauchy condition of convergence, $\sum_{i=1}^\infty v_i$ converges absolutely iff for every $\eps>0$ there exists $N\in\Zbb_+$ such that for all $n> m\geq N$ we have 
\begin{align}
\sum_{i=m+1}^n~\lVert v_i\lVert<\eps \label{eq27}
\end{align}
By comparing \eqref{eq27} with \eqref{eq28} and using the subadditivity of the norm (recall Def. \ref{lb91}), we immediately see:
\end{rem}

\begin{pp}\label{lb94}
Let $\sum_{i=1}^\infty v_i$ be a series in a Banach space. The following are true.
\begin{enumerate}
\item If $\sum_{i=1}^\infty v_i$ converges absolutely, then it converges.
\item For each $i$ we choose $a_i\in\Rbb_{\geq0}$ satisfying $\lVert v_i\lVert\leq a_i$. Suppose that $\sum_{i=1}^\infty a_i<+\infty$. Then $\sum_{i=1}^\infty v_i$ converges absolutely.
\end{enumerate}
\end{pp}

\begin{proof}
Part 1 has been explained above. In part 2, we have $\sum\lVert v_i\lVert \leq \sum a_i<+\infty$. So $\sum v_i$ converges absolutely.
\end{proof}


\begin{exe}
Suppose that $\sum_{i=1}^\infty u_i$ and $\sum_{i=1}^\infty v_i$ are convergent (resp. absolutely convergent) series in a Banach space $V$. Let $\lambda\in\Fbb$. Show that the LHS of the following equations converges (resp. converges absolutely) in $V$, and that the following equations hold:
\begin{gather*}
\sum_{i=1}^\infty (u_i+v_i)=\sum_{i=1}^\infty u_i+\sum_{i=1}^\infty v_i\\
\sum_{i=1}^\infty \lambda v_i=\lambda\cdot\sum_{i=1}^\infty v_i
\end{gather*}
\end{exe}


\begin{rem}
We have seen that absolute convergence implies convergence. In fact, at least when $V=\Fbb^N$, absolute convergence is in many ways more natural than convergence. For example, we will learn that if a series $\sum_i v_i$ in $\Fbb^N$ converges absolutely, then the value of $\sum_i v_i$ is invariant under rearrangement of the series: for every bijection $\varphi:\Zbb_+\rightarrow\Zbb_+$ we have $\sum_i v_i=\sum_i v_{\varphi(i)}$. In the next semester, we shall learn Lebesgue integral theory and, more generally, measure theory. When applying measure theory to infinite sums over the countable set $\Zbb_+$, many good results (e.g. dominated convergence theorem, Fubini theorem)  hold only for absolute convergence series, but not for arbitrary convergent series in general. In fact, there is no analog of convergent (but not absolutely convergent) series in measure theory at all!

When $V$ is not necessarily finite-dimensional, the situation is subtler: there is a version of convergence which lies between the usual convergence and absolute convergence, and which coincides with absolute convergence when $V=\Fbb^N$. This version of convergence is defined using nets instead of sequences. Moreover, many good properties (as mentioned above) hold for this convergence, and these properties can be proved in a very conceptual way (rather than using brute-force computation). We will learn this convergence in the next chapter.   \hfill\qedsymbol
\end{rem}



\subsection{Basic examples}


Let us study the \textbf{geometric series} $\sum_{n=0}^\infty z^n$ where $z\in\Cbb$. We first note the useful formula: for each $z,w\in\Cbb$ and $n\in\Nbb$,
\begin{align}
(z+w)^n=\sum_{k0}^n{n\choose k}z^kw^{n-k}  \label{eq60}
\end{align}
In particular,
\begin{align}
(1+z)^n=1+nz+\frac{n(n-1)}{2}z^2+\frac{n(n-1)(n-2)}6 z^3+\cdots+nz^{n-1}+z^n \label{eq29}
\end{align}


\begin{eg}\label{lb110}
Assume $z\in\Cbb$ and $|z|<1$. Then $\lim_{n\rightarrow\infty}z^n=0$. 
\end{eg}

\begin{proof}
If $z=0$ then it is obvious. Assume that $0<|z|<1$. Choose $\delta>0$ such that $|z|=1/(1+\delta)$. By \eqref{eq29}, $(1+\delta)^n\geq 1+n\delta$. So
\begin{align*}
0\leq |z^n|\leq (1+n\delta)^{-1}
\end{align*}
Since $\dps\lim_{n\rightarrow\infty} (1+n\delta)^{-1}=0$, we have $|z^n|\rightarrow0$ by squeeze theorem. Hence $z^n\rightarrow0$.
\end{proof}

\begin{eg}\label{lb106}
Let $z\in\Cbb$. If $|z|<1$, then $\dps\sum_{n=0}^\infty z^n$ converges absolutely, and
\begin{align}
\sum_{n=0}^\infty z^n=\frac 1{1-z}
\end{align}
where $0^0$ is understood as $1$. If $|z|\geq 1$, then $\dps\sum_{n=0}^\infty z_n$ diverges in $\Cbb$.
\end{eg}


\begin{proof}
The partial sum $s_n=1+z+z^2+\cdots +z^n$ equals $(1-z^{n+1})/(1-z)$ when $z\neq 1$. Therefore, when $|z|<1$, $s_n\rightarrow 1/(1-z)$. When $|z|\geq 1$, we have $|z^n|\geq 1$ and hence $z^n\nrightarrow 0$. So $\sum_{n=0}^\infty z^n$ diverges by Prop. \ref{lb92}.
\end{proof}


\begin{eg}\label{lb95}
The \textbf{harmonic series} $\dps\sum_{n=1}^\infty \frac 1n$ diverges (in $\Rbb$).
\end{eg}


\begin{proof}
We want to show that the Cauchy condition (cf. Rem. \ref{lb93}) does not hold. Thus, we want to prove that there exists $\eps>0$ such that for every $N\in\Zbb_+$ there exist $n>m\geq N$ such that $|(m+1)^{-1}+(m+2)^{-1}+\cdots+n^{-1}|\geq\eps$.

To see this, for each $N$ we choose  $m=2^N$ and $n=2^{N+1}$. Then $n>m>N$, and
\begin{align*}
&\Big|\sum_{i=m+1}^n i^{-1}\Big|=\Big|\frac 1{2^N+1}+\frac 1{2^N+2}+\cdots +\frac 1{2^N+2^N}  \Big|\\
\geq&\underbrace{\Big|\frac 1{2^{N+1}}+\frac 1{2^{N+1}}+\cdots +\frac 1{2^{N+1}}  \Big|}_{2^N\text{ terms}}=\eps
\end{align*}
where $\eps=\frac 12$.
\end{proof}

\begin{comment}
\begin{rem}
For every $p\in\Rbb$, assume that $n^p$ (where $n\in\Zbb_+$) is defined and that the properties we learned in high school mathematics are satisfied. If $p\leq 1$, then clearly $\sum_{n=1}^\infty n^{-p}=+\infty$ since $1/n^p\geq 1/n$. It is in fact true that for every $p>1$ we have $\sum_{n=1}^\infty n^{-p}<+\infty$. The easiest (but not the most elementary) way to see this is by using integrals: This series equals $1+\int_{x=1}^{+\infty}f(x)dx$ where $f:[1,+\infty)\rightarrow\Rbb_{\geq0}$ equals $(n+1)^{-p}$ when restricted to $[n,n+1)$. So $f(x)\leq x^{-p}$ on $[1,+\infty)$. Hence $\int_{x=1}^{+\infty}f(x)dx\leq \int_{x=1}^{+\infty}x^{-p}dx=(1-p)^{-1}x^{1-p}|_{x=1}^{+\infty}=(p-1)^{-1}<+\infty$.
\end{rem}
\end{comment}


\begin{exe}\label{lb96}
Choose any $p\in\Zbb$. Prove that $\dps\sum_{n=1}^\infty n^{-p}$ converges iff $p\geq 2$.
\end{exe}

\begin{proof}[Hint]
Use Prop. \ref{lb94} and Exp. \ref{lb95} to reduce the problem to the case $p=2$. Prove this case by proving $\sum_{n=1}^\infty 1/n(n+1)=1<+\infty$.
\end{proof}



\begin{df}
Let $V$ be a Banach space, let $X$ be a set, and let $(f_n)$ be a sequence in $l^\infty(X,V)$, and let $g\in l^\infty(X,V)$. We say that the series of functions $\dps\sum_{i=1}^\infty f_i$ \textbf{converges uniformly to $g$} \index{00@Uniform convergence of series of functions} (on $X$) if it converges to $g$ as a series in the Banach space $l^\infty(X,V)$ and under the $l^\infty$-norm. Equivalently, this means that the partial sum function $s_n=f_1+\cdots+f_n$ converges uniformly to $g$ as $n\rightarrow\infty$.
\end{df}


\begin{eg}
The series of functions $\dps\sum_{n=1}^\infty \frac{\sin|nz^3|}{n^2}$ converges uniformly on $\Cbb$ to a continuous function $g:\Cbb\rightarrow\Rbb$ which is uniformly bounded (i.e. $\dps\sup_{z\in\Cbb}|g(z)|<+\infty$).
\end{eg}

\begin{proof}
Let $f_n(z)=\sin|nz^3|/n^2$. Then each $f_n$ is in $\fk X=C(\Cbb,\Rbb)\cap l^\infty(\Cbb,\Rbb)$ where $\fk X$ is a real Banach space under the $l^\infty$-norm by Cor. \ref{lb101}. Note that $\lVert f_n\lVert_\infty\leq n^{-2}$. By Exe. \ref{lb96}, $\sum_{n=1}^\infty n^{-2}<+\infty$. Therefore, by Prop. \ref{lb94}, the series $\sum_n f_n$ converges in $\fk X$, i.e., it converges uniformly to an element $g\in \fk X$. (In particular, $\sum_n f_n(z)=g(z)$ for all $z\in\Cbb$.)
\end{proof}


\subsection{Root test and ratio test; power series}


Root test and ratio test are useful criteria for proving the convergence or divergence of series, especially  power series. In addition, the method of power series provides a unified and elegant proof for many useful formulas about limit (see Prop. \ref{lb109} and Exp. \ref{lb111}). We begin our discussion with the following easy observation:

\begin{rem}\label{lb105}
Let $(x_n)$ be a sequence in $\ovl\Rbb$, and let $A\in\ovl\Rbb$. The following are true.
\begin{enumerate}
\item If $\dps\limsup_{n\rightarrow\infty} x_n<A$, then $x_n<A$ is eventually true.
\item If $\dps\limsup_{n\rightarrow\infty} x_n>A$, then $x_n>A$ is frequently true.
\end{enumerate}
By taking negative, we obtain similar statements for $\liminf$.
\end{rem}


\begin{proof}
Recall that $\limsup x_n=\inf_{n\in\Zbb_+}\alpha_n$ where where $\alpha_n=\sup\{x_n,x_{n+1},\dots\}$. 



Assume that  $\inf_{n\in\Zbb_+}\alpha_n<A$. Then $A$ is not a lower bound of $\{\alpha_n:n\in\Zbb_+\}$. Thus, there exists $N\in\Zbb_+$ such that $\alpha_N<A$. Then $x_n<A$ for all $n\geq N$.

Assume that $\inf_{n\in\Zbb_+}\alpha_n>A$. Then for each $N\in\Zbb_+$ we have $\alpha_N>A$. So $A$ is not an upper bound of $\{x_n,x_{n+1},\dots\}$.  So there is $n\geq N$ such that $x_n>A$.
\end{proof}



\begin{pp}[\textbf{Root test}]\index{00@Root test} 
Let $\dps\sum_{n=1}^\infty v_n$ be a series in a Banach space $V$. Let $\dps\beta=\limsup_{n\rightarrow\infty}\sqrt[n]{\lVert v_n\lVert}$. Then:
\begin{enumerate}
\item If $\beta<1$, then $\sum v_n$ converges absolutely, and hence converges in $V$.
\item If $\beta>1$, then $\sum v_n$ diverges in $V$.
\end{enumerate}
\end{pp}


\begin{proof}
Suppose $\beta<1$. Then we can choose $\gamma$ such that $\beta<\gamma<1$. So $\limsup \sqrt[n]{\lVert v_n\lVert}<\gamma$. By Rem. \ref{lb104}, there exists $N\in\Zbb_+$ such that for all $n\geq N$, we have $\sqrt[n]{\lVert v_n\lVert}<\gamma$, and hence $\lVert v_n\lVert <\gamma^n$. Since $\sum_{n=0}^\infty \gamma^n=(1-\gamma)^{-1}<+\infty$ (Exp. \ref{lb106}), the series $\sum_{n=N}^\infty v_n$ converges absolutely by Prop. \ref{lb94}. So the original series converges absolutely.

Assume that $\beta>1$. Then by Rem. \ref{lb105}, for each $N$ there is $n\geq N$ such that $\sqrt[n]{\lVert v_n\lVert}>1$ and hence $\lVert v_n-0\lVert>1$. So $v_n\nrightarrow 0$. So $\sum v_n$ diverges by Prop. \ref{lb92}.
\end{proof}

\begin{eg}
Let $V=\Rbb$ and $v_n=1/n$ resp. $v_n=1/n^2$. Then $\beta=1$, and $\sum v_n$ diverges resp. converges absolutely due to Exe. \ref{lb96}. So Root test gives no information on the convergence of series when $\beta=1$. The same can be said about ratio test.
\end{eg}




\begin{pp}[\textbf{Ratio test}]\index{00@Ratio test}  
Let $\dps\sum_{n=1}^\infty v_n$ be a series in a Banach space $V$ such that $v_n\neq 0$ for all $n$. Let $\dps\alpha=\liminf_{n\rightarrow\infty}\frac{\lVert v_{n+1}\lVert}{\lVert v_n\lVert}$ and $\dps\beta=\limsup_{n\rightarrow\infty}\frac{\lVert v_{n+1}\lVert}{\lVert v_n\lVert}$. Then:
\begin{enumerate}
\item If $\beta<1$, then $\sum v_n$ converges absolutely, and hence converges in $V$.
\item If $\alpha>1$, then $\sum v_n$ diverges in $V$.
\end{enumerate}
\end{pp}

\begin{proof}
Suppose $\beta<1$. Choose $\gamma$ such that $\beta<\gamma<1$. Then by Rem. \ref{lb105}, there is $N$ such that for all $n\geq N$ we have $\lVert v_{n+1}\lVert/\lVert v_n\lVert<\gamma$. So $\lVert v_n\lVert <\gamma^{n-N}\lVert v_N\lVert$. So $\sum_{n\geq N}\lVert v_n\lVert \leq \lVert v_N\lVert \cdot\sum_{n\geq N}\gamma^{n-N}=\lVert v_N\lVert\cdot (1-\gamma)^{-1}<+\infty$. So $\sum v_n$ converges absolutely.

Suppose $\alpha>1$. Then by Rem. \ref{lb105}, there is $N$ such that for all $n\geq N$ we have $\lVert v_{n+1}\lVert/\lVert v_n\lVert>1$. So $\lVert v_n\lVert\geq\lVert v_N\lVert>0$ for all $n\geq N$. So $v_n\nrightarrow 0$ and hence $\sum v_n$ diverges, as in the proof of root test.
\end{proof}









\begin{df}
A \textbf{power series} in a complex Banach space $V$ \index{00@Power series} is an expression of the form $\dps\sum_{n=0}^\infty v_nz^n$ where the \textbf{coefficients} $v_0,v_1,v_2,\dots$ are elements of $V$, and $z$ is a \textbf{complex variable},\index{00@Complex variable} i.e., a symbol which can take arbitrary values in $\Cbb$. If the power series $\sum v_nz^n$ converges at $z_0\in\Cbb$, we often let $\sum v_n z_0^n$ denote this limit.
\end{df}


\begin{pp}\label{lb108}
Let $\sum v_n z^n$ be a power series in a complex Banach space $V$. Then there is a unique $0\leq R\leq+\infty$ satisfying the following properties:
\begin{enumerate}[label=(\alph*)]
\item If $z\in\Cbb$ and $|z|<R$, then $\sum v_n z^n$ converges absolutely in $V$.
\item If $z\in\Cbb$ and $|z|>R$, then $\sum v_n z^n$ diverges in $V$.
\end{enumerate}
Such $R$ is called the \textbf{radius of convergence} \index{00@Radius of convergence} of $\sum v_nz^n$. Moreover, we have
\begin{align}
R=\frac 1{\dps\limsup_{n\rightarrow\infty}\sqrt[n]{\lVert v_n\lVert}}=\liminf_{n\rightarrow\infty}\frac 1{\sqrt[n]{\lVert v_n\lVert}}  \label{eq30}
\end{align}
\end{pp}



\begin{proof}
Clearly, there are at most one $R$ satisfying (a) and (b). Let us define $R$ using \eqref{eq30} (note that the second and the third terms of \eqref{eq30} are clearly equal), and prove that $R$ satisfies (a) and (b). Let
\begin{gather*}
\beta(z)=\limsup_{n\rightarrow\infty} \sqrt[n]{\lVert v_n z^n\lVert}
\end{gather*}
Then $\beta(z)=|z|/R$. So (a) and (b) follow immediately from root test.
\end{proof}


\begin{rem}
Note that if one can find $0\leq r\leq R$ such that $\sum v_nz^n$ converges whenever $|z|<r$, then $r\leq R$ where $R$ is the radius of convergence: otherwise, the series diverges for any positive $z$ satisfying $R<z<r$, impossible.

It follows that if  $\sum v_nz^n$ converges for all $|z|<r$, then $\sum v_nz^n$ converges \emph{absolutely} for all $|z|<r$.  \hfill\qedsymbol
\end{rem}


Prop. \ref{lb108} provides a useful method for computing limits of a positive sequence:

\begin{pp}\label{lb109}
Let $(\lambda_n)$ be a sequence in $\Rbb_{>0}$. Then
\begin{align}
\liminf_{n\rightarrow\infty}\frac{\lambda_{n+1}}{\lambda_n}\leq \liminf_{n\rightarrow\infty}\sqrt[n]{\lambda_n}\leq \limsup_{n\rightarrow\infty}\sqrt[n]{\lambda_n}\leq \limsup_{n\rightarrow\infty} \frac{\lambda_{n+1}}{\lambda_n}  \label{eq35}
\end{align}
In particular, (by Cor. \ref{lb113}) we have
\begin{align}
\lim_{n\rightarrow\infty}\sqrt[n]{\lambda_n}=\lim_{n\rightarrow\infty} \frac{\lambda_{n+1}}{\lambda_n}\label{eq31}
\end{align}
provided that the limit on the RHS of \eqref{eq31} exists in $\ovl\Rbb$.
\end{pp}

The four numbers in \eqref{eq35} can be completely different. See \cite[Exp. 3.35]{Rud-P}.

\begin{proof}
Let $R$ be the radius of convergence of $\sum \lambda_n z^n$. Then $R=1/\limsup\sqrt[n]{\lambda_n}$ by \eqref{eq31}. Thus, by Prop. \ref{lb108}, if $|z|>R$ then $\sum \lambda_n z^n$ diverges, and hence $\limsup|\lambda_{n+1}z^{n+1}|/|\lambda_n z^n|\geq 1$ by ratio test. Therefore, 
\begin{align*}
|z|>\frac 1{\dps\limsup\sqrt[n]{\lambda_n}}\qquad\Longrightarrow \qquad |z|\cdot\limsup\frac{\lambda_{n+1}}{\lambda_n}\geq 1
\end{align*}
This proves
\begin{align*}
\limsup\sqrt[n]{\lambda_n}\leq \limsup \frac{\lambda_{n+1}}{\lambda_n}
\end{align*}
Replacing $\lambda_n$ by $\lambda_n^{-1}$, we get
\begin{align*}
\frac 1{\dps\liminf \sqrt[n]{\lambda_n}}=\limsup\sqrt[n]{\lambda_n^{-1}}\leq \limsup \frac{\lambda_n}{\lambda_{n+1}}=\frac 1{\dps \liminf\frac{\lambda_{n+1}}{\lambda_n}}
\end{align*}
This proves \eqref{eq35}.
\end{proof}

\begin{eg}\label{lb111}
Let $a\in\Rbb_{>0}$ and $p\in\Zbb$. The following formulas follow immediately from Prop. \ref{lb109} (especially, from \eqref{eq31}):
\begin{subequations}
\begin{gather}
\lim_{n\rightarrow\infty} \sqrt[n]{a}=1 \label{eq32}\\
\lim_{n\rightarrow\infty}\sqrt[n]{n!}=+\infty  \label{eq33}\\
\lim_{n\rightarrow\infty}\sqrt[n]{n^p}=1  \label{eq34}
\end{gather}
Note that \eqref{eq34} follows from 
\begin{align}
\lim_{n\rightarrow\infty}\Big(\frac n{n+1}\Big)^p=1 
\end{align}
(This is clearly true when $p=\pm1$, and hence is true for any $p$ by induction.) By \eqref{eq34}, the radius of convergence of $\sum_n n^p z^n$ is $1$. Therefore, by Prop. \ref{lb108},  $\sum n^pA^{-n}$ converges absolutely when $A>1$. Thus, by Prop. \ref{lb92},
\begin{align}
\lim_{n\rightarrow\infty} \frac{n^p}{A^n}=0 \qquad(\text{if }A>1)
\end{align}
This means that ``polynomials grow slower than exponentials".
\end{subequations}

The same conclusions hold for arbitrary $p\in\Rbb$ once we know how to define $x^p$ and prove the continuity of $x\in\Rbb_{>0}\mapsto x^p$. \hfill\qedsymbol
\end{eg}


\begin{sexe}
Prove \eqref{eq32} directly. Then use \eqref{eq32} to give a direct proof of Prop. \ref{lb109}. Do not use root test, ratio test, or any results about power series.
\end{sexe}


%% Record #4 2023/09/27





\begin{df}\label{lb107}
By \eqref{eq33}, the power series \index{exp@$e^z=\exp(z)$}
\begin{align*}
\exp(z)\equiv e^z=\sum_{n=0}^\infty \frac{z^n}{n!}
\end{align*}
has radius of convergence $+\infty$, and hence converges absolutely on $\Cbb$. (In particular, $\lim_{n\rightarrow\infty} z^n/n!=0$ for all $z\in\Cbb$.) This gives a function $\exp:\Cbb\rightarrow\Cbb$, called the \textbf{exponential function}. \index{00@Exponential function} 
\end{df}















Part (a) of Prop. \ref{lb108} can be strengthened in the following way.

\begin{thm}\label{lb112}
Let $\sum v_n z^n$ be a power series with coefficients in a complex Banach space $V$. Let $R$ be its radius of convergence, and assume that $0<R\leq+\infty$. For each $z\in B_\Cbb(0,R)$, let $f(z)$  denote the value of this series at $z$ (which is an element of $V$). Then $f:B_\Cbb(0,R)\rightarrow V$ is continuous. Moreover,  for each $0<\rho<R$, the series of functions $\sum v_n z^n$ converges uniformly on $\ovl B_\Cbb(0,\rho)$ to $f$. 
\end{thm}

Note that by calling $\sum v_n z^n$ a series of functions, we understand each term $v_nz^n$ as a function $\Cbb\rightarrow V$.

\begin{proof}
For each $0<\rho<R$, let $X_\rho=\ovl B_\Cbb(0,\rho)$. Then $X_\rho$ is clearly a bounded closed subset of $\Cbb$, and hence is sequentially compact by Heine-Borel Thm. \ref{lb98}. Let $g_n=v_nz^n$, which is a continuous function $X_\rho\rightarrow V$. We view $g_n$ as an element of the Banach space (cf. Cor. \ref{lb101}) $C(X_\rho,V)$. Then $\lVert g_n\lVert_\infty=\rho^n\lVert v_n\lVert$. Thus
\begin{align*}
\limsup_{n\rightarrow\infty}\sqrt[n]{\lVert g_n\lVert_\infty}=\limsup_{n\rightarrow\infty}\rho\sqrt[n]{\lVert v_n\lVert}=\rho/R<1
\end{align*}
Therefore, by root test, the series $\sum g_n$ converges in the Banach space $C(X_\rho,V)$ to some $f_\rho\in C(X_\rho,V)$.

We have proved that for each $0<\rho<R$, the series of functions $\sum v_nz^n$ converges uniformly on $X_\rho$ to a continuous function $f_\rho$. Let $f:B_\Cbb(0,R)\rightarrow V$ whose value at each $z$ is the value of the original series at $z$. Thus, if $|z|\leq\rho$, then $f_\rho(z)=f(z)$. Namely, $f|_{X_\rho}=f_\rho$. This shows that $\sum v_nz^n$ converges uniformly on $X_\rho$ to $f$. It also shows that $f|_{B_\Cbb(0,\rho)}$ is continuous (because $f_\rho$ is continuous). Therefore, since $B_\Cbb(0,R)$ is covered by all open disks $B_\Cbb(0,\rho)$ (where $0<\rho<R$), we conclude from Lem. \ref{lb30} that $f$ is continuous on $B_\Cbb(0,R)$.
\end{proof}

\begin{eg}
By Thm. \ref{lb112}, the exponential function $\exp:\Cbb\rightarrow\Cbb$ is continuous; moreover, $\sum_{n=0}^\infty z^n/n!$ converges uniformly to $e^z$ on $\ovl B_{\Cbb}(0,R)$ for every $0<R<+\infty$, and hence on every bounded subset of $\Cbb$.
\end{eg}


%% Proofread










\begin{comment}

\subsection{Problems and supplementary material}

\begin{sprob}
Consider a power series $\sum a_nz^n$ where $a_n\in\Rbb_{\geq 0}$ for each $n$. Let $R$ be its radius of convergence. Prove that the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $\sum a_n<+\infty$.
\item $\sum a_nz^n$ converges uniformly on $\ovl B_\Cbb(0,R)$ to a continuous function.
\item $\sum a_nz^n$ converges uniformly on $B_\Cbb(0,R)$.
\end{enumerate}
\end{sprob}
\end{comment}


\newpage


\section{Nets and discrete integrals}


\subsection{Introduction: why do we need nets?}



Nets were introduced by Moore and Smith in 1922 as a generalization of sequences. The most well-known motivation for introducing nets is that sequences are not enough for the study of non-metrizable topological spaces (i.e. topological spaces whose topologies are not induced by metrics). Here are two examples:
\begin{itemize}
\item In a general topological space, the definition of continuous maps using sequential convergence (as in Def. \ref{lb31}-(1)) is weaker than the definition using interior points and open sets (as in Def. \ref{lb31}-(2'), see also Rem. \ref{lb109}). Therefore, the dynamic intuition of sequences is not equivalent to the static intuition of open sets. 
\item Some important  topological spaces are compact (i.e. every open cover has a finite subcover) is not sequentially compact. $[0,1]^I$ (where $I$ is uncountable), equipped with the ``product topology" (i.e. ``pointwise convergence topology"), is such an example. 
\end{itemize}
As we shall see, nets provide a remedy for these issues: For a general topological space, the definition of continuity using net convergence is equivalent to that using open sets; compactness is equivalent to ``net compactness", where the latter means that every net has a convergent subset. Thus, by generalizing sequences to nets, the dynamic intuition and the static and geometric intuition are unified again.


Nevertheless, the most common topological spaces appeared in analysis are metrizable. This raises the question: Why should we care about nets, given that our primary interest is in metrizable topological spaces? Here is my answer: Even though we are mainly interested in metrizable spaces, we can still find nets helpful in the following aspects. 

First of all, many convergence processes cannot be described by sequential convergence, but can be described by net convergence. For example, the following limits can be formulated and understood in the language of net convergence:
\begin{enumerate}[label=(\arabic*)]
\item The limit of a function $\lim_{x\rightarrow x_0}f(x)$ where $f:X\rightarrow Y$ is a map of metric spaces and $x_0\in X$.
\item The limit $\dps\lim_{m,n\rightarrow\infty}a_{m,n}$ where $(a_{m,n})_{m,n\in\Zbb_+}$ is a \textbf{double sequence} in a metric space $X$. Note that this is not the same as (but is more natural than) the \textbf{iterated limit} $\dps\lim_{n\rightarrow\infty}\lim_{m\rightarrow\infty} a_{m,n}$. Moreover, the limit $\dps\lim_{m,n\rightarrow\infty}a_{m,n}$ is the key to understanding the problem of commutativity of iterated integrals:
\begin{align*}
\lim_{n\rightarrow\infty}\lim_{m\rightarrow\infty} a_{m,n}\xlongequal{?}\lim_{m\rightarrow\infty}\lim_{n\rightarrow\infty} a_{m,n}
\end{align*}
\item The Riemann integral $\int_a^b f(x)dx$. This is the limit of the Riemann sum $\lim\sum f(\xi_i)(a_i-a_{i-1})$  as the partition of the interval $[a,b]$ is getting finer and finer.
\end{enumerate} 
Moreover, as for (3), we shall see that the net version of Cor. \ref{lb113} provides a quick and conceptual proof of the following fact: If the upper and lower Darboux integrals are equal, then the Riemann integral exists and are equal to the two Darboux integrals. Indeed, the upper and lower Darboux integrals are respectively the $\limsup$ and $\liminf$ of a net in $\Rbb$.

Second, nets provide a conceptual solution to many problems about \textbf{double series}. Let $(a_{m,n})_{m,n\in\Zbb_+}$ be a double sequence in $\Rbb$. Think about the following questions, which arise naturally when one is trying to prove $e^ze^w=e^{z+w}$.
\begin{enumerate}[label=(\alph*)]
\item When is it true that $\dps \sum_{n=1}^\infty\sum_{m=1}^\infty a_{m,n}=\sum_{m=1}^\infty\sum_{n=1}^\infty a_{m,n}$ ?
\item Since $\card(\Zbb_+\times\Zbb_+)=\card(\Zbb_+)$, why not use an ordinary series to study a double series? So let us \textbf{parametrize} $\Zbb_+\times\Zbb_+$ by $\Zbb_+$: choose a bijection $\varphi:\Zbb_+\rightarrow \Zbb_+\times\Zbb_+$. When is it true that $\dps  \sum_{k=1}^\infty a_{\varphi(k)}=\sum_{n=1}^\infty\sum_{m=1}^\infty a_{m,n}$ ?
\item Choose another parametrization (i.e. bijection) $\psi:\Zbb_+\rightarrow\Zbb_+\times\Zbb_+$. When is it true that $\dps  \sum_{k=1}^\infty a_{\varphi(k)}=\sum_{k=1}^\infty a_{\psi(k)}$ ?
\item More generally, let $X$ be a countably infinite set, and let $f:X\rightarrow\Rbb$. Intuitively, we can take an infinite sum $\dps\sum_{x\in X}f(x)$. How to define it rigorously? One may think about choosing a parametrization, i.e., a bijection $\varpi:\Zbb_+\rightarrow X$. Then one defines the infinite sum by $\sum_{k=1}^\infty f(\varphi(k))$. Is this definition independent of the choice of parametrization?
\item As a special case of (d), when is a series invariant under \textbf{rearrangement}? Namely, choose a bijection $\varphi:\Zbb_+\rightarrow\Zbb_+$, and choose a sequence $(a_n)$ in $\Rbb$, then when is it true that $\dps\sum_{n=1}^\infty a_n=\sum_{n=1}^\infty a_{\varphi(n)}$ ?
\end{enumerate}

Modern differential geometry (whose ``intrinsic" spirit stems from Gauss's Theorema Egregium) teaches us that in order to answer these questions, one should first define the infinite sum $\sum_{x\in X}f(x)$ in a parametrization-independent way. (The reason we call a bijection $\varphi:\Zbb_+\rightarrow X$ a parametrization is that we want the readers to compare it with the parametrizations of curves, surfaces, and more generally manifolds.)  We will call this sum a \textbf{discrete integral}. Then, one tries to answer when this definition agrees with those that depend on parametrizations (such as the sums in (a)-(e) above). These goals can be achieved with the help of nets.



\subsection{Nets}\label{lb147}


\subsubsection{Directed sets and nets}

\begin{df}\label{lb116}
A relation $\leq$ on a set $I$ is called a \textbf{preorder} \index{00@Preorder, and preordered set} if for all $\alpha,\beta,\beta\in I$, the following are satisfied:
\begin{itemize}
\item (Reflexivity) $\alpha\leq \alpha$.
\item (Transitivity) If $\alpha\leq \beta$ and $\beta\leq \gamma$ then $a\leq \gamma$.
\end{itemize}
The pair $(I,\leq)$ (or simply $I$) is called a \textbf{preordered set}.
\end{df}

Therefore, a partial order is a preorder satisfying antisymmetry: $(\alpha\leq \beta)\land(\beta\leq\alpha)\Rightarrow (\alpha=\beta)$.

\begin{df}
A preordered set $(I,\leq)$ is called a \textbf{directed set} \index{00@Direct set} if 
\begin{align}
\forall\alpha,\beta\in I~~~\exists\gamma\in I~~\text{ such that }\alpha\leq \gamma,\beta\leq\gamma  \label{eq37}
\end{align}
If $I$ is a directed set and $X$ is a set, then a function $x:I\rightarrow X$ is called a \textbf{net} \index{00@Net $(x_\alpha)_{\alpha\in I}$} with directed set/index set $I$. We often write $x(\alpha)$ as $x_\alpha$ if $\alpha\in I$, and write $x$ as $(x_\alpha)_{\alpha\in I}$.
\end{df}


\begin{eg}
$(\Zbb_+,\leq)$ is a directed set. A net with index set $\Zbb_+$ in a set $X$ is precisely a sequence in $X$.
\end{eg}

\begin{df}\label{lb117}
Suppose that $(I,\leq_I )$ and $(J,\leq_J)$ are preordered set (resp. directed set), then the \textbf{product} \index{00@Product preordered/directed set} $(I\times J,\leq)$ is a preordered set (resp. directed set) if for every $\alpha,\alpha'\in I,\beta,\beta'\in J$ we define
\begin{align}\label{eq36}
(\alpha,\beta)\leq (\alpha',\beta')\qquad\Longleftrightarrow\qquad \alpha\leq_I \alpha'~~\text{and}~~\beta\leq_J\beta'
\end{align}
Unless otherwise stated, the preorder on $I\times J$ is assumed to be defined by \eqref{eq36}.
\end{df}


\begin{eg}
$\Zbb_+\times\Zbb_+$ (or similarly, $\Nbb\times\Nbb$) is naturally a directed set whose preorder is defined by \eqref{eq36}. A net $(x_{m,n})_{(m,n)\in\Zbb_+\times\Zbb_+}$ with index set $\Zbb_+\times\Zbb_+$ is called a \textbf{double sequence} \index{00@Double sequence} and is written as $(x_{m,n})_{m,n\in\Zbb_+}$ or simply $(x_{m,n})$. (We will even write it as $(x_{mn})$ when no confusion arises.)

More generally, we call $(x_{\alpha,\beta})_{(\alpha,\beta)\in I\times J}=(x_{\alpha,\beta})_{\alpha\in I,\beta\in J}$ a \textbf{double net} \index{00@Double net} if its index set is $I\times J$ for some directed sets $I,J$. \hfill\qedsymbol
\end{eg}




\begin{eg}\label{lb130}
If $X$ is a set, then $(2^X,\subset)$ and $(\fin(2^X),\subset)$ \index{fin@$\fin(2^X)$} are directed sets where
\begin{align}
\fin(2^X)=\{A\subset X:A\text{ is a finite set}\}
\end{align}
We will use nets with index set $\fin(2^X)$ to study infinite sums.
\end{eg}


\begin{eg}
Let $X$ be a metric space and $x\in X$. Then $X_x=(X,\leq)$ is a directed set if for each $p_1,p_2\in X$ we define
\begin{align}
p_1\leq p_2~~\text{in }X_x\qquad\Longleftrightarrow\qquad d(p_1,x)\geq d(p_2,x)
\end{align}
(Namely, a larger element of $X_x$ is one closer to $x$.) Nets with this directed set will be used to study the continuity (and the limits) of functions. Note that $X_x$ is our first example of directed set which is not a poset! ($d(p_1,x)=d(p_2,x)$ does not imply $p_1=p_2$.)
\end{eg}


\subsubsection{Limits of nets}

If $I$ is an preordered set and $\beta\in I$, we write \index{I@$I_{\geq\beta}$}
\begin{gather}
I_{\geq\beta}=\{\alpha\in I:\alpha\geq\beta\}
\end{gather}
\begin{df}
Let $P$ be a property about elements of a set $X$, i.e., $P$ is a function $X\rightarrow\{\text{true, false}\}$. Let $(x_\alpha)_{\alpha\in I}$ be a net in $X$. 

We say that $x_\alpha$ \textbf{eventually} \index{00@Eventually} satisfies $P$ (equivalently, we say that $x_\alpha$ satisfies $P$ for \textbf{sufficiently large} \index{00@Sufficiently large} $\alpha$) if:
\begin{itemize}
\item There exists $\beta\in I$ such that for every $\alpha\in I_{\geq\beta}$, the element $x_\alpha$ satisfies $P$.
\end{itemize}
``Sufficiently large" is also called ``\textbf{large enough}". \index{00@Large enough=sufficiently large}

We say that $x_\alpha$ \textbf{frequently} \index{00@Frequently} satisfies $P$ if:
\begin{itemize}
\item For every $\beta\in I$ there exists $\alpha\in I_{\geq\beta}$ such that $x_\alpha$ satisfies $P$.
\end{itemize}
\hfill\qedsymbol
\end{df}


\begin{rem}
Note that unlike sequences, for a general net, ``$x_\alpha$ eventually satisfies $P$" does not imply ``all but finitely many $x_\alpha$ satisfy $P$" because the complement of $I_{\geq\beta}$ is not necessarily a finite set.  
\end{rem}


\begin{rem}
Let $P$ and $Q$ be two properties about elements of $X$. Then
\begin{subequations}
\begin{gather}
\neg(\text{$x_\alpha$ eventually satisfies $P$})~~=~~(\text{$x_\alpha$ frequently satisfies $\neg P$})
\end{gather}
By the crucial condition \eqref{eq37} for directed sets, we have
\begin{gather}\label{eq38}
\begin{gathered}
(x_\alpha\text{ eventually satisfies }P)\land(x_\alpha\text{ eventually satisfies }Q)\\
\Downarrow \\
x_\alpha\text{ eventually satisfies }P\land Q
\end{gathered}
\end{gather}
By taking contraposition and replacing $P,Q$ by $\neg P,\neg Q$, we have
\begin{gather}
\begin{gathered}
x_\alpha\text{ frequently satisfies }P\lor Q\\
\Downarrow\\
(x_\alpha\text{ frequently satisfies }P)\lor(x_\alpha\text{ frequently satisfies }Q)
\end{gathered}
\end{gather}
\end{subequations}
\end{rem}

\begin{df}\label{lb174}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a metric space $X$. Let $x\in X$. We say that $(x_\alpha)$ \textbf{converges to} $x$ and write \index{lim@$\lim_{\alpha\in I}x_\alpha\equiv \lim_\alpha x_\alpha$}
\begin{align*}
\lim_{\alpha\in I}x_\alpha\equiv \lim_\alpha x_\alpha=x
\end{align*}
or simply $x_\alpha\rightarrow x$ if the following statement holds:
\begin{itemize}
\item For every $\eps>0$, $x_\alpha$ is eventually in $B_X(x,\eps)$.
\end{itemize}
Clearly, $x_\alpha\rightarrow x$ iff $d(x_\alpha,x)\rightarrow 0$.
\end{df}

\begin{df}
Let $(x_{m,n})_{m,n\in\Zbb_+}$ be a double sequence in a metric space. Then we write
\begin{align}
\lim_{(m,n)\in\Zbb_+\times\Zbb_+} x_{m,n}\equiv \lim_{m,n\rightarrow\infty} x_{m,n}
\end{align}
and call it the \textbf{(double) limit} \index{00@Double limit} of $(x_{m,n})$.
\end{df}

\begin{rem}
Let us spell out the meaning of $\lim_{m,n\rightarrow\infty} x_{m,n}=x$: For each $\eps>0$ there exists $M,N\in\Zbb_+$ such that $d(x_{m,n},x)<\eps$ for all $m\geq M$ and $n\geq N$. Clearly, this is equivalent to the statement:
\begin{itemize}
\item For each $\eps>0$ there exists $N\in\Zbb_+$ such that $d(x_{m,n},x)<\eps$ for all $m,n\geq N$.
\end{itemize}
Therefore, if $(x_n)$ is a sequence in $X$, then
\begin{align}
\text{$(x_n)$ is a Cauchy sequence}\qquad\Longleftrightarrow\qquad \lim_{m,n\rightarrow\infty} d(x_m,x_n)=0
\end{align}
Thus, the Cauchyness of sequences can be studied in terms of double limits, and hence in terms of nets.
\end{rem}




\begin{pp}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a metric space $X$ converging to $x,y$. Then $x=y$.
\end{pp}

\begin{proof}
Suppose that $x\neq y$. Then there are $r,\rho>0$ such that $B(x,r)\cap B(y,\rho)=\emptyset$, say $r=\rho=d(x,y)/2$. Since $x_\alpha\rightarrow x$, $x_\alpha$ is eventually in $B(x,r)$. Since $x_\alpha\rightarrow y$, $x_\alpha$ is eventually in $B(y,\rho)$. Therefore, by the logic \eqref{eq38}, $x_\alpha$ is eventually in $B(x,r)\cap B(y,\rho)$, impossible.
\end{proof}

\begin{thm}\label{lb121}
Let $f:X\rightarrow Y$ be map of metric spaces continuous at $x\in X$. Let $(x_\alpha)_{\alpha\in I}$ be a net in $X$ converging to $x$. Then  $\dps\lim_\alpha f(x_\alpha)=f(x)$.
\end{thm}

\begin{proof}
Choose any $\eps>0$. By Def. \ref{lb31}-(2) and the continuity of $f$ at $x$, there exists $\delta>0$ such that for all $p\in B(x,\delta)$ we have $f(p)\in B(f(x),\eps)$. Since $x_\alpha\rightarrow x$, $x_\alpha$ is eventually in $B(x,\delta)$. Therefore $f(x_\alpha)$ is eventually in $B(f(x),\eps)$.
\end{proof}


This theorem implies, for example, that if $(v_\alpha)$ is a net in a complex normed vector space converging to $v$, and if $(\lambda_\alpha)$ is a net in $\Cbb$ converging to $\lambda$, then $\lambda_\alpha v_\alpha$ converges to $\lambda v$ because the scalar multiplication map is continuous (Prop. \ref{lb82}).



\begin{exe}\label{lb123}
Prove the generalization of Rem. \ref{lb58}:
\begin{enumerate}
\item If $(x_\alpha)_{\alpha\in I},(y_\alpha)_{\alpha\in I}$ are nets in $\ovl\Rbb$ converging to $A,B\in\ovl\Rbb$, and if $x_\alpha\leq y_\alpha$ for all $\alpha$, then $A\leq B$.
\item \textbf{Squeeze theorem}: \index{00@Squeeze theorem} Suppose that $(x_\alpha)_{\alpha\in I},(y_\alpha)_{\alpha\in I},(z_\alpha)_{\alpha\in I}$ are nets in $\ovl\Rbb$, $x_\alpha\leq y_\alpha\leq z_\alpha$ for all $\alpha$, and $x_\alpha$ and $z_\alpha$ both converge to $A\in\ovl\Rbb$. Then $y_\alpha\rightarrow A$.
\item If $(x_\alpha)$ is an increasing resp. decreasing net in $\ovl\Rbb$, then $\lim_\alpha x_\alpha$ exists in $\ovl\Rbb$ and equals $\sup_\alpha x_\alpha$ resp. $\inf_\alpha x_\alpha$.
\end{enumerate}
\end{exe}








\subsubsection{Subnets}




\begin{df}
A subset $E$ of a directed set $I$ is called \textbf{cofinal} \index{00@Cofinal subset} if:
\begin{align*}
\forall\alpha\in I~~~\exists\beta\in E~~~\text{such that }\alpha\leq\beta
\end{align*}
By the transitivity in Def. \ref{lb116} and property \eqref{eq37}, we clearly have
\begin{align*}
\forall\alpha_1,\dots,\alpha_n\in I~~~\exists\beta\in E~~~\text{such that }\alpha_1\leq\beta,\dots,\alpha_n\leq\beta
\end{align*}
\end{df}



\begin{df}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a set $X$. A \textbf{subnet} \index{00@Subnet} of $(x_\alpha)_{\alpha\in I}$ is, by definition, of the form $(x_{\alpha_s})_{s\in S}$ where $S$ is a directed set, and
\begin{align*}
(\alpha_s)_{s\in S}:S\rightarrow I\qquad s\mapsto \alpha_s
\end{align*}
is an increasing function whose range $\{\alpha_s:s\in S\}$ is cofinal in $I$.
\end{df}

\begin{eg}
A subsequence is a subnet.
\end{eg}

\begin{eg}\label{lb118}
Let $(x_{m,n})_{m,n\in\Zbb_+}$ be a net with index set $\Zbb_+\times\Zbb_+$. Then $(x_{k,k})_{k\in\Zbb_+}$ and $(x_{2k,k})_{k\in\Zbb_+}$ are subnets. $(x_{k,1})_{k\in\Zbb_+}$ is not a subnet, because the cofinal condition is not satisfied. More generally, it is not hard to show that for every function $\varphi,\psi:\Zbb_+\rightarrow\Zbb_+$, $(x_{\varphi(k),\psi(k)})_{k\in\Zbb_+}$ is a subnet iff $\varphi,\psi$ are increasing and $\lim_{k\rightarrow\infty}\varphi(k)=\lim_{k\rightarrow\infty}\psi(k)=+\infty$.
\end{eg}

\begin{exe}
Prove the following facts:
\begin{itemize}
\item The cofinal subset of a cofinal subset of a directed set $I$ is a cofinal subset of $I$.
\item  The subnet of a subnet of a net $(x_\alpha)$ is a subnet of $(x_\alpha)$. 
\end{itemize}
Note that in your proof you need to use the transitivity in Def. \ref{lb116}.
\end{exe}


It is important that the index set of a subnet is not necessarily a subset of the index set of the original net. Here is an example whose importance can be seen in the proofs of Exp. \ref{lb125} and Prop. \ref{lb126}.


\begin{eg}\label{lb124}
Let $J$ be a directed set. Then every net $(x_\alpha)_{\alpha\in I}$ has subnet $(x_\alpha)_{(\alpha,\beta)\in I\times J}$. The corresponding increasing map of directed sets is the projection $I\times J\rightarrow I$ onto the first component. 
\end{eg}



To appreciate the importance of cofinalness (as well as transitivity), we prove the following generalization of Prop. \ref{lb23}. This result has a wide range of surprising applications that are unavailable when one only considers sequences. (We will see them soon in this chapter. For instance, this result explains why the values of absolutely convergent series and invariant under rearrangement.) So I call this result a theorem.


\begin{thm}\label{lb120}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a metric space (or more generally, a topological space) $X$ converging to $x\in X$. Then every subnet $(x_{\alpha_s})_{s\in S}$ converges to $x$.
\end{thm}

The following proof for metric spaces can be generalized straightforwardly to topological spaces. The readers can come back and check the details after learning topological spaces.

\begin{proof}
Choose any $\eps>0$. Since $x_\alpha\rightarrow x$, there exists $\beta\in I$ such that for all $\alpha\geq\beta$ we have $d(x_\alpha,x)<\eps$. By the cofinalness, there exists $t\in S$ such that $\alpha_t\geq\beta$. Thus, since $s\in S\mapsto \alpha_s\in I$ is increasing, for every $s\geq t$, we have $\alpha_s\geq\alpha_t\geq\beta$ and hence $\alpha_s\geq\beta$ by the transitivity in Def. \ref{lb116}. So $d(x_{\alpha_s},x)<\eps$ for all $s\geq t$. This finishes the proof.
\end{proof}

This proposition does not hold if one does not assume cofinalness in the definition of subnets:

\begin{eg}
Let $(x_n)$ be a sequence in $\Rbb$ converging to $x\in\Rbb$. Since $(x_n)$ is a Cauchy sequence, we know that $\lim_{m,n\rightarrow\infty}x_m-x_n=0$. We have seen in Exp. \ref{lb118} that $(x_{2k}-x_k)_{k\in\Zbb_+}$ is a subnet of $(x_{m,n})$. Therefore, $\lim_{k\rightarrow\infty} x_{2k}-x_k=0$. But $(x_k-x_1)_{k\in\Zbb_+}$ is not a subnet since the cofinal condition is not satisfied. And if $x\neq x_1$, then $\lim_k (x_k-x_1)=x-x_1\neq 0$, i.e.,
\begin{align*}
\lim_{k\rightarrow\infty}(x_k-x_1)\neq \lim_{m,n\rightarrow\infty} (x_m-x_n)
\end{align*}
\end{eg}


In Subsec. \ref{lb119}, we have seen two criteria for the divergence of sequence: a sequence diverges if it is unbounded, or if it has two subsequences converging to different points. By Thm. \ref{lb120}, the second criterion can be generalized to nets. However, the following example shows that the first criterion does not has its net version:


\begin{eg}
A convergent net $(x_\alpha)_{\alpha\in I}$ in a metric space $X$ is not necessarily \textbf{bounded}. Namely, it is not necessarily true that $\{x_\alpha:\alpha\in I\}$ is a bounded subset of $X$. Let $f:\Rbb_{>0}\rightarrow\Rbb$ be a net with directed set $(\Rbb_{> 0},\leq)$. Then this net is not bounded, although $\lim f(x)=0$.
\end{eg}


\begin{eg}
The double sequence $x_{m,n}=n/(m+n)$ in $\Rbb$ has subnets $x_{n,n}=n/(n+n)=1/2$ and $x_{2n,n}=1/3$. Since these two subnets converge to different values, Thm. \ref{lb120} implies that $\lim_{m,n}x_{m,n}$ does not exist. However, the \textbf{iterated limits}\index{00@Iterated limit} exist and take different values:
\begin{gather*}
\lim_{m\rightarrow\infty}\lim_{n\rightarrow\infty}\frac{n}{m+n}=1\qquad \lim_{n\rightarrow\infty}\lim_{m\rightarrow\infty}\frac{n}{m+n}=0
\end{gather*}
As we shall see, this gives another criterion for the divergence of double series: If the two iterated limits exist and are different, then the double series diverge.
\end{eg}


Finally, we do an example of convergent double sequence:

\begin{eg}\label{lb125}
Let $\dps x_{m,n}=(m^{-2}-n^{-1})\sin\frac{\pi(m+\sqrt n)}{4}$. Then $\dps\lim_{m,n\rightarrow\infty}x_{m,n}=0$.
\end{eg}

\begin{proof}
The sequence $(m^{-2})_{m\in\Zbb_+}$ converges to $0$. By Exp. \ref{lb124}, the double sequence $(m^{-2})_{m,n\in\Zbb_+}$ is its subnet, and hence converges to $0$ by Thm. \ref{lb120}. Similarly, the double sequence $(n^{-1})_{m,n\in\Zbb_+}$ converges to $0$. Therefore, $m^{-2}+n^{-1}$ converges to $0$ due to Thm. \ref{lb121} and the continuity of the addition map $(x,y)\in\Rbb^\mapsto x+y\in\Rbb$ (Prop. \ref{lb41}). Since $0\leq |x_{m,n}|\leq m^{-2}+n^{-1}$, we conclude $|x_{m,n}|\rightarrow 0$ (and hence $x_{m,n}\rightarrow0$) by squeeze theorem (Exe. \ref{lb123}).
\end{proof}







\subsubsection{Double limits and iterated limits}

\begin{thm}\label{lb122}
Let $(x_{\alpha,\beta})_{\alpha\in I,\beta\in J}$ be a double net in a metric space $X$. Assume that the following are true:
\begin{enumerate}[label=(\arabic*)]
\item The limit $\dps\lim_{(\alpha,\beta)\in I\times J}x_{\alpha,\beta}$ exists in $X$.
\item For each $\alpha\in I$, the limit $\dps\lim_{\beta\in J}x_{\alpha,\beta}$ exists in $X$.
\end{enumerate}
Then LHS limit in the following equation exists and equals the RHS:
\begin{align}
\lim_{\alpha\in I}\lim_{\beta\in J}x_{\alpha,\beta}=\lim_{(\alpha,\beta)\in I\times J}x_{\alpha,\beta}
\end{align}
In particular, suppose that the following is also true:
\begin{itemize}
\item[(3)] For each $\beta\in J$, the limit $\dps\lim_{\alpha\in J}x_{\alpha,\beta}$ exists in $X$. 
\end{itemize}
Then the following limits exist and are equal:
\begin{align}
\lim_{\alpha\in I}\lim_{\beta\in J}x_{\alpha,\beta}=\lim_{\beta\in J}\lim_{\alpha\in I}x_{\alpha,\beta}
\end{align}
\end{thm}


\begin{proof}
Let $\dps x_\alpha=\lim_\beta x_{\alpha,\beta}$ and $\dps x=\lim_{\alpha,\beta}x_{\alpha,\beta}$. We want to show that $\dps\lim_\alpha x_\alpha=x$. Choose any $\eps>0$. Then there exist $A\in I,B\in J$ such that for every $\alpha\geq A$ and $\beta\geq B$ we have $d(x_{\alpha,\beta},x)<\eps/3$. In particular,  $d(x_{\alpha,\beta},x)\leq \eps/2$. Using Thm. \ref{lb121} and the fact that $p\in X\mapsto d(p,x)\in\Rbb$ is continuous (Exp. \ref{lb45}), we see that for every $\alpha\geq A$ we have $\dps d(x_\alpha,x)=\lim_{\beta\in J_{\geq B}} d(x_{\alpha,\beta},x)\leq \eps/2<\eps$.
\end{proof}

The readers may skip the next remark and proof and come back to them when they have learned about topological spaces.

\begin{srem}
Thm. \ref{lb122} can be generalized to the case that $X$ is a regular topological space. By saying that the topological space $X$ is \textbf{regular}, \index{00@Regular topological space} we mean that for every $x\in X$ and every open set $U$ containing $x$, there is a smaller open set $V$ containing $x$ such that the closure $\ovl V$  (cf. Def. \ref{lb183}) is contained in $U$.
\end{srem}

\begin{proof}[$\star$ Proof]
Let $\dps x_\alpha=\lim_\beta x_{\alpha,\beta}$ and $\dps x=\lim_{\alpha,\beta}x_{\alpha,\beta}$. Choose any open set $U$ containing $x$. We want to prove that $x_\alpha$ is eventually in $U$. Choose an open set $V$ containing $x$ such that $\ovl V\subset U$. Then there are $A\in I,B\in J$ such that for all $\alpha\geq A$ and $\beta\geq B$ we have $x_{\alpha,\beta}\in V$. Thus, for each $\alpha\geq A$, since $x_{\alpha,\beta}$ approaches $x_\alpha$, we have $x_\alpha\in \ovl V$ and hence $x_\alpha\in U$.
\end{proof}


\begin{co}
Let  $(x_{\alpha,\beta})_{\alpha\in I,\beta\in J}$ be a double net in $\ovl\Rbb$. Assume that $x_{\blt,\blt}$ is increasing, i.e., $x_{\alpha,\beta}\leq x_{\alpha',\beta'}$ if $\alpha\leq\alpha'$ and $\beta\leq \beta'$. Then the following equation \eqref{eq39} hold, where all the limits \eqref{eq39} exist in $\ovl\Rbb$:
\begin{align}
\lim_{\alpha\in I}\lim_{\beta\in J}x_{\alpha,\beta}=\lim_{\beta\in J}\lim_{\alpha\in I}x_{\alpha,\beta}=\lim_{(\alpha,\beta)\in I\times J}x_{\alpha,\beta}=\sup\{x_{\alpha,\beta}:\alpha\in I,\beta\in J\}  \label{eq39}
\end{align}
\end{co}

Clearly, a similar result holds for decreasing double nets in $\ovl\Rbb$.

\begin{proof}
By Exe. \ref{lb123}, the three limits $\dps\lim_\alpha x_{\alpha,\beta}$, $\dps\lim_\beta x_{\alpha,\beta}$, and $\dps\lim_{\alpha,\beta}x_{\alpha,\beta}$ exist in $\ovl\Rbb$. Therefore, by Thm. \ref{lb122}, the three limits in \eqref{eq39} exist and are equal. The last equality in \eqref{eq39} is also due to Exe. \ref{lb123}.
\end{proof}


\subsubsection{Cauchy nets}

\begin{df}
A net $(x_\alpha)_{\alpha\in I}$ in a metric space $X$ is called a Cauchy net \index{00@Cauchy net} if
\begin{align*}
\lim_{\alpha,\beta\in I}d(x_\alpha,x_\beta)=0
\end{align*}
Equivalently, this means that 
\begin{align}
\forall\eps>0~~~\exists \gamma\in I~~~\text{such that }\forall\alpha,\beta\geq\gamma~~~\text{we have }d(x_\alpha,x_\beta)<\eps
\end{align}
\end{df}

\begin{exe}
Show that the subnet of a Cauchy net is Cauchy.
\end{exe}


\begin{pp}\label{lb126}
A convergent net in a metric space is a Cauchy net.
\end{pp}

\begin{proof}
Let $(x_\alpha)_{\alpha\in I}$ converge to $x$ in a metric space $X$. Then $\lim_\alpha d(x_\alpha,x)=0$. Since $(d(x_\alpha,x))_{\alpha,\beta\in I}$ is a subnet (cf. Exp. \ref{lb124}), we have $\lim_{\alpha,\beta} d(x_\alpha,x)=0$ by Thm. \ref{lb120}. Similarly, we have $\lim_{\alpha,\beta}d(x,x_\beta)=0$. Since $0\leq d(x_\alpha,x_\beta)\leq d(x_\alpha,x)+d(x,x_\beta)$, by Squeeze theorem (Exe. \ref{lb123}) we have $\lim_{\alpha,\beta}d(x_\alpha,x_\beta)=0$.
\end{proof}


\begin{exe}
Prove Prop. \ref{lb126} directly using the definitions of convergent nets and Cauchy nets.
\end{exe}

\begin{pp}\label{lb127}
Let $(x_\alpha)_{\alpha\in I}$ be a Cauchy net in a metric space $X$. Suppose that $(x_\alpha)_{\alpha\in I}$ has a convergent subnet $(x_{\alpha_s})_{s\in S}$ converging to $x\in X$. Then $(x_\alpha)_{\alpha\in I}$ converges to $x$.
\end{pp}

\begin{proof}
Choose any $\eps>0$. Since $(x_\alpha)$ is a Cauchy net, there exists $\gamma\in I$ such that $d(x_\alpha,x_\beta)\leq \eps$ for all $\alpha,\beta\geq \gamma$. Since $(\alpha_s)_{s\in S}$ has cofinal range, $\alpha_{s_0}\geq \gamma$ for some $s_0\in S$. Thus $\alpha_s\geq \gamma$ for all $s\geq s_0$ because $(\alpha_s)_{s\in S}$ is increasing and because of the transitivity in Def. \ref{lb116}. Thus, for every $\beta\geq\gamma$, $d(x_{\alpha_s},x_{\beta})\leq\eps$ for sufficiently large $s$. By taking limit over $s$ and using the continuity of $y\in X\mapsto d(y,x_\beta)$ as well as Thm. \ref{lb121}, we get $d(x,x_\beta)\leq \eps$ for all $\beta\geq\gamma$.
\end{proof}

\begin{df}\label{lb155}
Two nets $(x_\alpha)_{\alpha\in I}$ and $(y_\alpha)_{\alpha\in I}$ in a metric space $X$ are called \textbf{Cauchy-equivalent} \index{00@Cauchy-equivalent} if
\begin{align*}
\lim_{\alpha\in I}d(x_\alpha,y_\alpha)=0
\end{align*}
Two Cauchy nets are simply called \textbf{equivalent} if they are Cauchy-equivalent. It is not hard to see that Cauchy-equivalence is an equivalence relation (recall Def. \ref{lb156}) on $X^I$.
\end{df}


\begin{exe}\label{lb128}
Let $(x_\alpha)_{\alpha\in I}$ and $(y_\alpha)_{\alpha\in I}$ be Cauchy-equivalent nets in a metric space $X$. Prove that $(x_\alpha)$ is Cauchy iff $(y_\alpha)$ is Cauchy. Let $x\in X$. Prove that $(x_\alpha)$ converges to $x$ iff $(y_\alpha)$ converges to $x$. 
\end{exe}



\begin{thm}\label{lb129}
Every Cauchy net $(x_\alpha)_{\alpha\in I}$ in a complete metric space $X$ is convergent.
\end{thm}

We give a hint of the proof and leave the details to the readers as an exercise.

\begin{proof}[Hint]
Construct an increasing sequence $(\alpha_n)_{n\in\Zbb_+}$ in $I$ such that for every $\beta,\gamma\geq\alpha_n$ we have $d(x_\beta,x_\gamma)<1/n$. Prove that $(x_{\alpha_n})_{n\in\Zbb_+}$ is a Cauchy sequence, and hence converges to some $x\in X$. Prove that $(x_\alpha)_{\alpha\in I}$ converges to $x$. (Warning: $(x_{\alpha_n})_{n\in\Zbb_+}$ is not necessarily a subnet of $(x_\alpha)_{\alpha\in I}$.)
\end{proof}

\begin{comment}
\begin{proof}
Let $(x_\alpha)_{\alpha\in I}$ be a Cauchy net in a complete metric space $X$. Then $I\times \Nbb$ is a directed set. Define
\begin{align*}
S=\{(\alpha,n)\in I\times\Nbb:\forall \beta,\gamma\geq\alpha\text{ we have }d(x_\beta,x_\gamma)<1/n\}
\end{align*}
Then $(x_\alpha)_{(\alpha,n)\in S}$ is a subnet of $X$. Recall that every subnet of a Cauchy net is Cauchy. By Prop. \ref{lb127}, it suffices to show that the Cauchy net $(x_\alpha)_{(\alpha,n)\in S}$ converges.

For each $n\in\Zbb_+$, choose $\beta_n$ such that $(\beta_n,n)\in S$: the existence of $\beta_n$ is due to the Cauchyness of $(x_\alpha)_{\alpha\in I}$. Thus, if $(\alpha,n)\in S$, we have $d(x_\alpha,x_{\beta_n})<1/n$, and hence
\begin{align*}
\lim_{(\alpha,n)\in S}d(x_\alpha,x_{\beta_n})=0
\end{align*}
Therefore, by Exe. \ref{lb128}, it suffices to prove that the equivalent Cauchy net $(x_{\beta_n})_{(\alpha,n)\in S}$ is convergent. But this is a subnet of the sequence $(x_{\beta_n})_{n\in\Nbb}$. And clearly, the Cauchyness of $(x_{\beta_n})_{(\alpha,n)\in S}$ implies that of $(x_{\beta_n})_{n\in\Nbb}$. So the Cauchy sequence $(x_{\beta_n})_{n\in\Nbb}$ converges because $X$ is complete. So its subnet $(x_{\beta_n})_{(\alpha,n)\in S}$ converges.
\end{proof}
\end{comment}



\subsection{Discrete integrals $\sum_{x\in X}f(x)$}

In this section, we fix $V$ to be a Banach space over $\Fbb\in\{\Rbb,\Cbb\}$. We fix a (non-necessarily countable) sets $X$. Note that if $f:X\rightarrow V$ is a function and $X$ is finite, then $\sum_{x\in X}f(x)$ can be understood in its most obvious way.



\begin{df}\label{lb131}
Let $f:X\rightarrow V$ be a map. The expression
\begin{align*}
\sum_{x\in X}f(x)
\end{align*}
(or simply $\sum_X f$) is called a \textbf{discrete integral}.\index{00@Discrete integral} If $v\in V$, we say that $\sum_{x\in X}f(x)$ equals (or \text{converges} to) $v$, if
\begin{align}
\lim_{A\in\fin(2^X)}\sum_{x\in A}f(x)=v
\end{align}
In this case, we write
\begin{align}
\sum_{x\in X}f(x)=v \label{eq40}
\end{align}
\end{df}

\begin{rem}
Recall Exp. \ref{lb130} that $\fin(2^X)$ the directed set of finite subsets of $2^X$. Its preorder is ``$\subset$". So \eqref{eq40} means more precisely that:
\begin{itemize}
\item For every $\eps>0$, there exists a finite set $B\subset X$ such that for every finite set $A$ satisfying $B\subset A\subset X$, we have $\lVert v-\sum_{x\in A}f(x)\lVert<\eps$.
\end{itemize}
\end{rem}


\begin{rem}\label{lb141}
One of the advantages of discrete integrals over series is that  discrete integrals are clearly invariant under rearrangement: For every bijection $\varphi:X\rightarrow X$, if one side of the following equation converges in $V$, then the other side converges, and the equation holds true:
\begin{align}
\sum_{x\in X}f(x)=\sum_{x\in X}f(\varphi(x))
\end{align} 
or simply $\sum_Xf=\sum_Xf\circ\varphi$.
\end{rem}


\begin{rem}\label{lb133}
We spell out the meaning of Cauchy net for the net $(\sum_A f)_{A\in\fin(2^X)}$:
\begin{itemize}
\item[(1)] For every $\eps>0$, there exists a finite set $B\subset X$ such that for any finite sets $A_1,A_2$ satisfying $B\subset A_1\subset X,B\subset A_2\subset X$, we have
\begin{align*}
\Big\lVert \sum_{A_1\setminus A_2}f-\sum_{A_2\setminus A_1}f \Big\lVert<\eps
\end{align*} 
\end{itemize}
Note that the term inside the norm is $\sum_{A_1}f-\sum_{A_2}f$. This is also equivalent to:
\begin{itemize}
\item[(2)] For every $\eps>0$, there exists a finite set $B\subset X$ such that for any finite set $E\subset X\setminus B$, we have 
\begin{align*}
\Big\lVert \sum_Ef\Big\lVert<\eps
\end{align*}
\end{itemize}
We shall mainly use (2) as the Cauchy criterion for the convergence of $\sum_Xf$.
\end{rem}

\begin{proof}[Proof of the equivalence]
(2) follows from (1) by taking $A_1=B$ and $A_2=B\cup E$. (1) follows from (2) by taking $E_1=A_1\setminus A_2$ and $E_2=A_2\backslash A_1$ and then concluding $\lVert \sum_{E_1}f-\sum_{E_2}f\lVert<2\eps$.
\end{proof}


\begin{df}\label{lb132}
Let $g:X\rightarrow\ovl\Rbb_{\geq0}$ be a map. Note that the net $(\sum_A g)_{A\in\fin(2^X)}$ is increasing. Hence, its limit exists in $\ovl\Rbb$ and equals $\sup_{A\in\fin(2^X)}\sum_Ag$ (by Exe. \ref{lb123}). We write this as $\sum_Xg$, or more precisely:
\begin{align}
\sum_Xg\equiv\sum_{x\in X}g(x)\xlongequal{\mathrm{def}} \lim_{A\in \fin(2^X)}\sum_A g=\sup_{A\in \fin(2^X)}\sum_A g
\end{align}
We say that $\sum_Xg$ \textbf{converges} or \textbf{converges absolutely}, if $\sum_Xg<+\infty$. 
\end{df}

\begin{rem}
Note that when $g:X\rightarrow\Rbb_{>0}$, the convergence in Def. \ref{lb132} agrees with that in Def. \ref{lb131}. Therefore, Rem. \ref{lb133} still gives a Cauchy criterion for convergence.
\end{rem}



\begin{df}
Let $f:X\rightarrow V$. We say that $\sum_Xf$ \textbf{converges absolutely} \index{00@Absolutely convergent discrete integral} if 
\begin{align*}
\sum_{x\in X}\lVert f(x)\lVert<+\infty
\end{align*}
\end{df}



\begin{pp}\label{lb142}
Let $f:X\rightarrow V$. If $\sum_Xf$ converges absolutely, then it converges, and
\begin{align}
\Big\lVert \sum_{x\in X} f(x) \Big\lVert\leq\sum_{x\in X} \lVert f(x)\lVert \label{eq41}
\end{align}
We write this simply as $\lVert\sum_X f\lVert\leq\sum_X |f|$. (Recall Def. \ref{lb150}.)
\end{pp}

\begin{proof}
\eqref{eq41} clearly holds when $X$ is finite. In the general case, assume that $\sum_Xf $ converges absolutely. Then by Cauchy criterion (Rem. \ref{lb133}-(2)), for every $\eps>0$ there is $A\in \fin(2^X)$ such that for each finite $E\subset X\setminus A$ we have $\sum_E|f|<\eps$, and hence $\lVert \sum_E f\lVert<\eps$. Therefore $\sum_Xf$ converges by Cauchy criterion again.

By the continuity of the norm function $v\in V\mapsto \lVert v\lVert\in\Rbb_{\geq0}$, and by Thm. \ref{lb121}, we have
\begin{align*}
\Big\lVert \sum_X f \Big\lVert=\Big\lVert \lim_A \sum_Af \Big\lVert=\lim_A \Big\lVert \sum_Af \Big\lVert
\end{align*}
Since $\lVert \sum_A f\lVert\leq\sum_A|f|$, by Exe. \ref{lb123}, the above expression is no less than
\begin{align*}
\lim_A\sum_A|f|=\sum_X|f|
\end{align*}
\end{proof}

The following proposition gives another demonstration that discrete integrals are more natural than series. We leave the proof to the readers.

\begin{pp}\label{lb134}
Let $f:X\rightarrow\Rbb^N$ where $N\in\Zbb_+$. Then
\begin{align*}
\sum_{x\in X}f(x)~~\textrm{converges}\qquad\Longleftrightarrow\qquad \sum_{x\in X}f(x)~~\text{converges absolutely}
\end{align*}

\end{pp}

\begin{proof}[Hint]
Reduce to the case $N=1$. Consider $A=\{x\in X:f(x)\geq 0\}$ and $B=X\setminus A$. 
\end{proof}

When $\Rbb^N$ is replaced by an infinite-dimensional Banach space, the convergence of a discrete integral may not imply absolute convergence. See Pb. \ref{lb149}.



\subsection{Fubini theorem for discrete integrals}\index{00@Fubini theorem (for discrete integrals)}\label{lb138}

Fix a Banach space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$. Let $X,Y$ be sets.

\begin{thm}[\textbf{Fubini theorem-A}]\label{lb135} 
Let $f:X\times Y\rightarrow V$. Assume that $\sum_{X\times Y}f$ converges. Then $\sum_Y f(x,\cdot)$ converges for each $x\in X$, and $\sum_X f(\cdot,y)$ converges for each $y\in Y$, and 
\begin{align}\label{eq45}
\sum_{x\in X}\sum_{y\in Y}f(x,y)=\sum_{y\in Y}\sum_{x\in X}f(x,y)=\sum_{(x,y)\in X\times Y}f(x,y)
\end{align}
where all discrete integrals converge in $V$.
\end{thm}

We abbreviate \eqref{eq45} to $\sum_X\sum_Yf=\sum_Y\sum_Xf=\sum_{X\times Y}f$.

\begin{proof}
For each $x\in X$, let $f_x(y)=f(x,y)$. Let us prove that $\sum_Y f_x$ converges.
Choose any $\eps>0$. Since $\sum_{X\times Y}f$ converges, by Cauchy criterion (Rem. \ref{lb133}-(2)), there exists a finite $S\subset X\times Y$ such that the sum of $f$ over any finite subset outside $S$ has norm $<\eps$. The projection $X\times Y\rightarrow Y$ maps $S$ to a finite set $B\subset Y$. Thus, for each finite $E\subset Y\setminus B$, we have $\lVert\sum_E f_x\lVert<\eps$ since $x\times E$ is outside $S$. Therefore $\sum_Y f_x$ converges. By the same reasoning, $\sum_Xf(\cdot,y)$ converges for all $y$.

Recall that $\sum_{X\times Y}f$ is the limit of the net $(\sum_S f)_{S\in\fin(2^{X\times Y})}$. This net has subnet
\begin{align*}
\Big(\sum_{(x,y)\in A\times B} f(x,y)\Big)_{A\in \mc I,B\in \mc J}\qquad \text{ where }\mc I=\fin(2^X)~~\mc J=\fin(2^Y)
\end{align*}
(Its index set is $\mc I\times\mc J$.) Thus, by Thm. \ref{lb120},
\begin{align}
\sum_{(x,y)\in X\times Y}f(x,y)=\lim_{A\in\mc I,B\in\mc J} \sum_{(x,y)\in A\times B} f(x,y) \label{eq43}
\end{align}
We are now going to use Thm. \ref{lb122} to show that
\begin{align}
\lim_{A\in\mc I,B\in\mc J} \sum_{(x,y)\in A\times B} f(x,y)=\lim_{A\in\mc I}\lim_{B\in\mc J} \sum_{(x,y)\in A\times B} f(x,y) \label{eq42}
\end{align}
where the RHS limit exists. For that purpose, we need to check for each $A\in\mc I$ the convergence of $\lim_B\sum_{(x,y)\in A\times B}f(x,y)$. Since $\sum_Yf_x$ converges, we have
\begin{align}
&\lim_{B\in\mc J}\sum_{(x,y)\in A\times B}f(x,y)=\lim_{B\in\mc J}\sum_{x\in A}\sum_{y\in B}f(x,y)\nonumber\\
=&\sum_{x\in A}\lim_{B\in\mc J}\sum_{y\in B}f(x,y)=\sum_{x\in A}\sum_{y\in Y}f(x,y)\label{eq44}
\end{align}
(Note that $\sum_A$ is a finite sum and hence commutes with $\lim_B$.) Thus, the assumption in Thm. \ref{lb122} ensuring \eqref{eq42} has now been proved true. So \eqref{eq42} is true. Moreover, combining \eqref{eq43}, \eqref{eq42}, \eqref{eq44}  together, we get
\begin{align*}
\sum_{(x,y)\in X\times Y}f(x,y)=\lim_{A\in\mc I}\sum_{x\in A}\sum_{y\in Y}f(x,y)=\sum_{x\in X}\sum_{y\in Y}f(x,y)
\end{align*}
where the second and the third limits exist. This proves a half of \eqref{eq45}. The other half can be proved in the same way.
\end{proof}








\begin{thm}[\textbf{Fubini theorem-B}]\label{lb137}
Let $g:X\times Y\rightarrow\ovl\Rbb_{\geq0}$. Then the five discrete integrals in \eqref{eq46} exist in $\ovl\Rbb_{\geq0}$, and \eqref{eq46} holds in $\ovl\Rbb_{\geq0}$:
\begin{align}\label{eq46}
\sum_{x\in X}\sum_{y\in Y}f(x,y)=\sum_{y\in Y}\sum_{x\in X}f(x,y)=\sum_{(x,y)\in X\times Y}f(x,y)
\end{align}
\end{thm}

\begin{proof}
The existence in $\ovl\Rbb_{\geq0}$ of the five discrete integrals is clear. (Recall Def. \ref{lb32}.) Formula \eqref{eq46} can be proved in the same way as \eqref{eq45}. Note that when applying Thm. \ref{lb122} to prove \eqref{eq46}, the assumption in Thm. \ref{lb122} on the existence of limits is satisfied because all nets involved are increasing in $\ovl\Rbb$. (Recall Exe. \ref{lb123}.)
\end{proof}

\begin{co}[\textbf{Fubini theorem-C}]
Let $f:X\times Y\rightarrow V$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $\sum_{X\times Y}f$ converges absolutely.
\item $\sum_{x\in X}\sum_{y\in Y}\lVert f(x,y)\lVert<+\infty$.
\item $\sum_{y\in Y}\sum_{x\in X} \lVert f(x,y)\lVert<+\infty$.
\end{enumerate}
\end{co}

\begin{proof}
Immediate from Thm. \ref{lb137}. It is also not hard to prove it directly.
\end{proof}





\subsection{Parametrization theorem for discrete integrals}

We fix a Banach space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$. In the following sections, we shall apply the results about discrete integrals to the study of series and double series. For the convenience of applications (e.g. the proof of  $e^ze^w=e^{z+w}$), we enlarge the concept of series a little:

\subsubsection{Series over $\Zbb$}\label{lb151}


\begin{df}
A \textbf{series over $\Zbb$} \index{00@Series over $\Zbb$} is an expression
\begin{align*}
\sum_{n=-\infty}^{+\infty} f(n)
\end{align*}
where $f$ is a function from $\Zbb$ to either $V$ or $\ovl\Rbb_{\geq0}$. We say that this series \textbf{converges to}  (or equals) $\mu\in V$ resp.  equals $\mu\in\ovl\Rbb_{\geq0}$, if
\begin{align}
\lim_{m,n\rightarrow+\infty} \sum_{i=-m}^n f(i)=\mu \label{eq47}
\end{align}
In this case, we write
\begin{align*}
\sum_{n=-\infty}^{+\infty} f(n)=\mu
\end{align*}
We say that $\sum_{n=-\infty}^{+\infty}f(n)$ \textbf{converges absolutely} \index{00@Absolute convergent series over $\Zbb$} if $\sum_{n=-\infty}^{+\infty}\lVert f(n)\lVert<+\infty$.
\end{df}

\begin{rem}
Note that in the case of $\ovl\Rbb_{\geq0}$, the limit on the LHS of \eqref{eq47} must exist in $\ovl\Rbb_{\geq0}$. Again, this is due to the fact that the involved net is increasing, and so one can use Exe. \ref{lb123}.
\end{rem}



\begin{exe}\label{lb152}
Let $\sum_{n=-\infty}^{+\infty} f(n)$ be a series in either $V$ or $\ovl\Rbb_{\geq0}$.
\begin{enumerate}
\item Fix $k\in\Zbb$. Prove that $\sum_{n=-\infty}^{+\infty} f(n)$ exists iff the following limits both exist
\begin{subequations}
\begin{gather}
\sum_{n=k}^{+\infty} f(n)=\lim_{n\rightarrow+\infty} \sum_{i=k}^nf(i)\\
\sum_{n=-\infty}^{k-1} f(n)=\lim_{n\rightarrow-\infty} \sum_{i=n}^{k-1}f(i)
\end{gather}
\end{subequations}
Moreover, if these limits exist, then
\begin{align}
\sum_{n=-\infty}^{+\infty}f(n)=\sum_{n=k}^{+\infty} f(n)+\sum_{n=-\infty}^{k-1} f(n)
\end{align}
\item In the case that $f$ has codomain $V$, prove that $\sum_{n=-\infty}^{+\infty} f(n)$ converges if it converges absolutely.
\item Prove that if $f$ is zero outside $\Zbb_+$, then
\begin{align}
\sum_{n=-\infty}^{+\infty}f(n)=\sum_{n=1}^{+\infty}f(n)  \label{eq48}
\end{align}
\end{enumerate}
\end{exe}

Thus, by \eqref{eq48}, our following results about series over $\Zbb$ can be directly applied to series over $\Zbb_+$ (or over $\Zbb_{\geq k}$ where $k\in\Zbb$).



\subsubsection{Parametrization theorem}

The following theorem relates series and discrete integrals. The structure of this theorem is similar to that of Fubini theorem-A,B,C in Sec. \ref{lb138}.

\begin{thm}[\textbf{Parametrization theorem}]\label{lb136}
Let $X$ be an infinite countable set. Let $\varphi:\Zbb\rightarrow X$ be a bijection (called a \textbf{parametrization} of $X$). \index{00@Parametrization (in discrete integrals)} The following are true.
\begin{enumerate}
\item Let $f:X\rightarrow V$. If the RHS of \eqref{eq49} converges in $V$, then the LHS converges, and \eqref{eq49} holds:
\begin{align}
\sum_{n=-\infty}^{+\infty}f\circ\varphi(n)=\sum_{x\in X}f(x)\label{eq49}
\end{align}
\item Let $f:X\rightarrow\ovl\Rbb_{\geq0}$. Then \eqref{eq49} holds in $\ovl\Rbb_{\geq0}$.
\item Let $f:X\rightarrow V$. Then the discrete integral $\dps\sum_{x\in X} f(x)$ converges absolutely iff the series $\dps\sum_{n=-\infty}^{+\infty} f\circ\varphi(n)$ converges absolutely.
\end{enumerate}
The same conclusions hold if we assume that $\varphi:\Zbb_+\rightarrow X$ is a bijection.
\end{thm}



\begin{proof}
We prove the case $\varphi:\Zbb\rightarrow X$; the other case is similar. 

Assume that $\sum_Xf$ converges, which means that the limit of the net $(\sum_Af)_{A\in\fin(2^X)}$ converges to some $v\in V$. Therefore, by Thm. \ref{lb120}, the subnet
\begin{align*}
\Big(\sum_{x\in A_{m,n}}f(x)\Big)_{m,n\in\Zbb_+}=\Big(\sum_{i=-m}^n f\circ\varphi(i)\Big)_{m,n\in\Zbb_+}
\end{align*}
converges to $v$, where $A_{m,n}=\{\varphi(i):i\in\Zbb,-m\leq i\leq n\}$. This proves part 1. The same method proves part 2. Part 3 follows directly from part 2.
\end{proof}

\subsection{Application to (double) series and power series; $e^ze^w=e^{z+w}$}

Fix a Banach space $V$ over $\Fbb\in\{\Rbb,\Cbb\}$.

\subsubsection{General results about series and double series}

\begin{co}\label{lb140}
Let $f:\Zbb\rightarrow V$, and let $\psi:\Zbb\rightarrow\Zbb$ be a bijection. Suppose that
\begin{align}
\sum_{n=-\infty}^{+\infty}\lVert f(n)\lVert<+\infty \label{eq54}
\end{align}
Then \eqref{eq50} holds true, where the RHS of \eqref{eq50} converges absolutely:
\begin{align}
\sum_{n=-\infty}^{+\infty} f(n)=\sum_{n=-\infty}^{+\infty}f\circ\psi(n) \label{eq50}
\end{align}
\end{co}
The same conclusion clearly holds if $\Zbb$ is replaced by $\Zbb_+$.

\begin{proof}
By \eqref{eq54} and Thm. \ref{lb136}-3, the discrete integral $\sum_\Zbb f$ converges absolutely, and hence converges. By Thm. \ref{lb136}-1, the LHS resp. RHS of \eqref{eq50} converges to the value of $\sum_\Zbb f$ if we choose the parametrization to be $\id_\Zbb$ resp. $\psi$ again. This proves \eqref{eq50} and the convergence of the RHS of \eqref{eq50}. Applying the same conclusion to $\lVert f(\cdot)\lVert$ proves the absolute convergence of the RHS of \eqref{eq50}.
\end{proof}


\begin{co}\label{lb139}
Let $f:\Zbb^2\rightarrow V$. Let $\Phi:\Zbb^2\rightarrow\Zbb^2$ be a bijection. Suppose that
\begin{align}\label{eq51}
\sum_{m=-\infty}^{+\infty}\sum_{n=-\infty}^{+\infty}\lVert f(m,n)\lVert<+\infty
\end{align}
Then \eqref{eq52} holds true, where the six series involved in \eqref{eq52} converge absolutely.
\begin{align}\label{eq52}
\sum_{m=-\infty}^{+\infty}\sum_{n=-\infty}^{+\infty} f(m,n)=\sum_{n=-\infty}^{+\infty}\sum_{m=-\infty}^{+\infty}f(m,n)=\sum_{k=-\infty}^{+\infty}\sum_{l=-\infty}^{+\infty} f\circ\Phi(k,l)
\end{align}
\end{co}

Similar results clearly hold if $\Zbb^2$ is replaced by $\Zbb_+^2$: One extends the domain of $f$ and the domain and codomain of $\Phi$ from $\Zbb_+^2$ to $\Zbb^2$. Then one apply Cor. \ref{lb139}. 

Also, note that the second term of \eqref{eq52} is redundant: it follows from the equality of the first and the third terms of \eqref{eq52} if we choose $\Phi(k,l)=(l,k)$.


\begin{proof}
By Cor. \ref{lb140} and Thm. \ref{lb137}, we have
\begin{align}
\sum_{m=-\infty}^{+\infty}\sum_{n=-\infty}^{+\infty}\lVert f(m,n)\lVert=\sum_{x\in\Zbb}\sum_{y\in \Zbb}\lVert f(x,y)\lVert=\sum_{(x,y)\in\Zbb^2}\lVert f(x,y)\lVert\label{eq53}
\end{align}
where all the limits exist in $\ovl\Rbb_{\geq0}$. Therefore, by \eqref{eq51}, the discrete integral $\sum_{\Zbb^2}f$ is absolutely convergent and hence convergent. 

Similar to the argument in \eqref{eq53}, Cor. \ref{lb140} and Thm. \ref{lb135} imply that the first two terms of \eqref{eq52}  exist and are both equal to the discrete integral $\sum_{\Zbb^2}f$. Since $\sum_{\Zbb^2}f=\sum_{\Zbb^2}f\circ\Phi$ (recall Rem. \ref{lb141}), by Cor. \ref{lb140} and Thm. \ref{lb135} again, the last term of \eqref{eq52} converges to $\sum_{\Zbb^2}f\circ\Phi$.

We have proved that the six series in \eqref{eq52} converge, and \eqref{eq52} holds. Replacing $f(\cdot,\cdot)$ with $\lVert f(\cdot,\cdot)\lVert$ and applying a similar argument, we see that the six series in \eqref{eq52} converge absolutely. %(Note that one needs Prop. \ref{lb142} to show that $\sum\lVert \sum(\cdots)\lVert\leq\sum\sum\lVert(\cdots)\lVert<+\infty$.)
\end{proof}


\begin{rem}
Using the same method as in the above proof, one can easily prove a more general version of Cor. \ref{lb139}: Let $N\in\Zbb_+$. Let $f:\Zbb^2\rightarrow V$ such that \eqref{eq51} holds true. Let $\Psi:\Zbb^N\rightarrow\Zbb^2$ be a bijection. Then the $N$ series involved in the expression of \eqref{eq58} (from innermost to outermost) converge absolutely:
\begin{align}\label{eq58}
\sum_{n_1=-\infty}^{+\infty}\cdots \sum_{n_N=-\infty}^{+\infty}f\circ\Psi(n_1,\dots,n_N)
\end{align}
Moverover, the outermost series of \eqref{eq58} converges to \eqref{eq52}. And of course, a similar result holds if $\Zbb^2$ is replaced by $\Zbb^M$ for every $M\in\Zbb_+$. We leave it to the readers to fill in the details.
\end{rem}



%We remark that \eqref{eq52} is the most important reason we introduced series over $\Zbb$: If we restrict to series over $\Zbb_+$, the proof of \eqref{eq52} will involve more technical discussions.

\begin{co}\label{lb153}
Assume that
\begin{align*}
A=\sum_{n=-\infty}^{+\infty} a_n\qquad B=\sum_{n=-\infty}^{+\infty}b_n
\end{align*}
are absolutely convergent series in $\Cbb$. Then for each $k\in\Zbb$, the series
\begin{align*}
c_k=\sum_{l=-\infty}^{+\infty}a_{k-l}b_l
\end{align*}
converges absolutely. Moreover, the LHS of the \eqref{eq59} converges absolutely to the RHS:
\begin{align}\label{eq59}
\sum_{k=-\infty}^{+\infty}c_k=AB
\end{align}
\end{co}


\begin{proof}
Apply Cor. \ref{lb139} to the case that $f(m,n)=a_mb_n$ and $\Phi(k,l)=(k-l,l)$.
\end{proof}


\subsubsection{Application to power series}


\begin{co}
Let $\dps f(z)=\sum_{n=0}^{+\infty}a_nz^n$ and $\dps g(z)=\sum_{n=0}^{+\infty}b_nz^n$ be power series in $\Cbb$ with radii of convergence $R_1,R_2$ respectively. Let $R=\min\{R_1,R_2\}$. For each $k\in\Zbb_+$, let
\begin{align*}
c_k=\sum_{l=0}^k a_{k-l}b_l
\end{align*}
Then the power series $\dps h(z)=\sum_{k=0}^{+\infty}c_kz^k$ has radius of convergence $\geq R$. Moreover, for each $z\in\Cbb$ satisfying $0\leq |z|<R$, we have
\begin{align*}
h(z)=f(z)\cdot g(z)
\end{align*}
\end{co}

\begin{proof}
For each $0\leq |z|<R$, apply Cor. \ref{lb153} by replacing the $a_n,b_n,c_k$ of Cor. \ref{lb153} with $a_nz^n,b_nz^n,c_kz^k$. This shows that $h(z)$ converges absolutely to $f(z)\cdot g(z)$. Since this is true for all $|z|<R$, $h(z)$ must have radius of convergence at least $R$ by Rem. \ref{lb108}.
\end{proof}

The above result also holds more generally for Laurent series. See Exe. \ref{lb154}.

\begin{co}
For each $z,w\in\Cbb$ we have 
\begin{align*}
e^ze^w=e^{z+w}
\end{align*}
\end{co}

\begin{proof}
Apply Cor. \ref{lb153} to the case $a_n=z^n/n!$ and $b_n=w^n/n!$. (We set $a_n=b_n=0$ if $n<0$.) Then
\begin{align*}
c_k=\sum_{l=0}^{k} \frac{z^{k-l}}{(k-l)!}\cdot\frac{w^l}{l!}=\sum_{l=0}^k {k\choose l}\frac{z^{k-l}w^l}{k!}=\frac{(z+w)^k}{k!}
\end{align*}
by \eqref{eq60}.
\end{proof}




\subsection{Summary}


The following are some fundamental questions about series and double series:
\begin{itemize}
\item[(a)] Are they invariant under rearrangement? (Cf. \eqref{eq50}.) 
\item[(b)] Does the order of iterate series affect the value of double series? (Cf. the first equality in \eqref{eq52}.)
\item[(c)] A mixture of the above two questions. (Cf. the last term of \eqref{eq52}.)
\end{itemize}
We address these questions by relating them to discrete integral, a version of infinite sums which is parametrization-independent. The following are some key features of this theory.
\begin{enumerate}
\item (General principle)  A discrete integral is to a series (defined by parametrization) as a net to a subnet.
\item (Net $\Rightarrow$ Subnet) All subnets of a convergent net converge to the same value: the limit of the original net.
\item (Discrete integral $\Rightarrow$ Series) Therefore, different series converge to the same value if they are different parametrizations of the same convergent discrete integral.
\item (Discrete integrals $\Rightarrow$ Series) Fubini-type theorems (any theorems about exchanging the orders of iterate sums/integrals) hold for double discrete integrals. Therefore, they hold when passing to subnets, in particular, when passing to double series.
\item (Subnet $\Rightarrow$ Net) Every increasing net in $\ovl\Rbb_{\geq0}$  has a limit in $\ovl\Rbb_{\geq0}$. Therefore, if an increasing net in $\Rbb_{\geq0}$ has a subnet converging to a number $<+\infty$, then the original net converges in $\Rbb_{\geq 0}$ (to a finite number).
\item (General principle) The discrete integral $\sum_{x\in X}\lVert f(x)\lVert$ is defined by the limit of an increasing net in $\ovl\Rbb_{\geq0}$.
\item (Series $\Rightarrow$ Discrete integral) Therefore, if any series or double series corresponds in a reasonable way to a discrete integral, then the absolute convergence of this (double) series (more specifically: \eqref{eq54} or \eqref{eq51}) implies the absolute convergence (and hence convergence) of the original discrete integral. This implies the absolute convergence of any other (double) series arising from that discrete integral.
\item (Conclusion) Thus, when a (double) series converges absolutely (in the form of \eqref{eq54} or \eqref{eq51}), the three problems (a), (b), (c) have satisfying answers. The reason absolutely convergent (double) series are so good is because increasing nets in $\ovl\Rbb_{\geq0}$ are very good!
\item (Counterexamples) Non-absolutely convergent series in $\Rbb$ have rearrangements converging to different values. This is because non-convergent nets may have two subnets converging to different values, cf. Pb. \ref{lb204}. (Recall from Prop. \ref{lb134} that for discrete integrals in $\Rbb$, absolute convergence is equivalent to convergence.)
\end{enumerate}











\subsection{Problems and supplementary material}


Let $X$ be a set, and let $V$ be a Banach space over $\Rbb\in\{\Rbb,\Cbb\}$.

\begin{prob}
Prove Thm. \ref{lb129}, namely, prove that every Cauchy net $(x_\alpha)_{\alpha\in I}$ in a complete metric space $X$ is convergent.
\end{prob}

\begin{prob}
Let $f:X\rightarrow V$. Define the \textbf{support} \index{00@Support $\Supp(f)$} \index{Supp@$\Supp(f)$} of $f$ to be
\begin{align}
\Supp(f)=\{x\in X:f(x)\neq 0\}
\end{align}
Prove that if $\sum_Xf$ converges absolutely, then $\Supp(f)$ is a countable set.
\end{prob}

\begin{proof}[Hint]
Consider $\{x\in X:|f(x)|\geq\eps\}$ where $\eps>0$.
\end{proof}




\begin{prob}
Prove Prop. \ref{lb134}. 
\end{prob}


\begin{sprob}\label{lb204}
Prove \textbf{Riemann rearrangement theorem}, which says the following: Let $\sum_{n=1}^{+\infty} x_n$ be a series in $\Rbb$ which converges and which does not converge absolutely. Choose any  $A\in\ovl\Rbb$. Then $\sum_{n=1}^{+\infty} x_n$ has a rearrangement converging to $A$ (i.e., there is bijection $\varphi:\Zbb_+\rightarrow\Zbb_+$ such that $\sum_{n=1}^\infty f\circ\varphi(n)=A$).
\end{sprob}


\begin{rem}
By Riemann rearrangement theorem, it is clear that every convergent series in $\Rbb^N$ which is not absolutely convergent must have two  rearrangements converging to two different points. However, when $\Rbb^N$ is replaced by an infinite dimensional Banach space, one may find a series $\sum_{n=1}^{+\infty} v_n$ which does not converge absolutely but converge to some $v$, and every rearrangement of $\sum_{n=1}^{+\infty} v_n$ converges to $v$. See Pb. \ref{lb149}.
\end{rem}


\begin{prob}\label{lb149}
Consider the case that $V$ is the real Banach space $V=l^\infty(\Zbb_+,\Rbb)$. For each $n\in\Zbb_+$, let $e_n\in V$ be the characteristic function $\chi_{\{n\}}$. Namey, $e_n$ takes value $1$ at $n$, and takes $0$ at the other points. Prove that the discrete integral
\begin{align}
\sum_{n\in\Zbb_+}\frac 1{n}e_n \label{eq57}
\end{align}
converges in $V$, and find the limit. Prove that \eqref{eq57} does not converge absolutely.
\end{prob}


\begin{rem}
A more important example that will be considered later is $V=l^2(\Zbb_+,\Cbb)$, the set of all functions $f:\Zbb_+\rightarrow\Cbb$ satisfying that the \pmb{$l^2$}\textbf{-norm} $\lVert f\lVert_{l^2}=\sqrt{\sum_{n\in\Zbb_+} |f(n)|^2}$ is finite. Then $V$ is in fact a Banach space. (Actually, it is a so-called \textbf{Hilbert space}.) Again, let $e_n=\chi_{\{n\}}$. (These $e_n$ will be called an \textbf{orthonormal basis} of $V$) Then for each $f\in V$, the discrete integral $\sum_{n\in\Zbb_+}f(n)\cdot e_n$ converges to $f$. But it does not converge absolutely if $\sum_{n\in\Zbb_+}|f(n)|=+\infty$. Take for example $f(n)=n^{-1}$. We will study these objects in the second semester.
\end{rem}



\begin{df}
For each $f\in V^X$, define the \pmb{$l^1$}\textbf{-norm} \index{l1@$\lVert\cdot\lVert_{l^1}=\lVert\cdot\lVert_{1}$}
\begin{align*}
\lVert f\lVert_{l^1(X,V)}\equiv\lVert f\lVert_{l^1}\equiv\lVert f\lVert_1=\sum_{x\in X}\lVert f(x)\lVert
\end{align*}
Define the $l^1$-space \index{l1XV@$l^1(X,V)$}
\begin{gather*}
l^1(X,V)=\{f\in V^X:\lVert f\lVert_{l^1}<+\infty \}
\end{gather*}
Namely, $l^1(X,V)$ is the set of all $f\in V^X$ where $\sum_Xf$ converges absolutely. In particular, $\sum_Xf$ converges for such $f$. 
\end{df}


\begin{exe}
Prove that for each $f,g\in V^X$ and $\lambda\in\Fbb$, we have
\begin{gather}
\lVert f+g\lVert_1\leq \lVert f\lVert_1+\lVert g\lVert_1\qquad \lVert\lambda f\lVert=|\lambda|\cdot\lVert f\lVert
\end{gather}
Show that $l^1(X,V)$ is a linear subspace of $l^\infty(X,V)$, and that $\lVert\cdot\lVert_{l^1}$ is a norm on $l^1(X,V)$
\end{exe}

\begin{prob}
Prove that $l^1(X,V)$ is a Banach space. Namely, prove that the metric on $l^1(X,V)$ defined by the $l^1$-norm is complete.
\end{prob}


\begin{prob}
Prove the \textbf{dominated convergence theorem} for discrete integrals: Let $(f_\alpha)_{\alpha\in I}$ be a net in $V^X$ satisfying the following conditions:
\begin{enumerate}[label=(\arabic*)]
\item There exists $g\in l^1(X,\Rbb)$ satisfying $g\geq0$ (i.e. $g(x)\geq0$ for all $x\in X$) such that for every $\alpha\in I,x\in X$ we have
\begin{align*}
\lVert f_\alpha(x)\lVert\leq g(x)
\end{align*}
We simply write the above condition as $|f_\alpha|\leq g$.
\item $(f_\alpha)_{\alpha\in I}$ converges pointwisely some $f\in V^X$. Namely, $\lim_\alpha f_\alpha(x)=f(x)$ for every $x\in X$.
\end{enumerate}
Prove that $f\in l^1(X,V)$. Prove that the LHS of \eqref{eq56} exists and equals the RHS: 
\begin{align}\label{eq56}
\lim_{\alpha\in I}\sum_{x\in X}f_\alpha(x)=\sum_{x\in X}f(x)
\end{align}
\end{prob}


\begin{sprob}
Assume $v_n\in V$ for each $n$. Let $z$ be a complex variable. Then the expression
\begin{align*}
f(z)=\sum_{n=-\infty}^{+\infty}v_nz^n
\end{align*}
is called a \textbf{Laurent series} \index{00@Laurent series} in $V$.

Prove that there exist unique $r,R\in\ovl\Rbb_{\geq0}$ such that $f(z)$ converges absolutely when $|r|<z<|R|$, and that $f(z)$ diverges when $|z|<r$ or $|z|>R$. Prove that
\begin{align}
r=\limsup_{n\rightarrow+\infty} \sqrt[n]{\lVert v_{-n}\lVert}\qquad R=\frac{1}{\dps\limsup_{n\rightarrow+\infty} \sqrt[n]{\lVert v_n\lVert}}
\end{align}
(Recall that by Exe. \ref{lb152}, $f(z)$ diverges iff either $\sum_{n=0}^\infty v_nz^n$ or $\sum_{n=-\infty}^{-1} v_nz^n$ diverges.) We call $r$ and $R$ the \textbf{radii of convergence} of $f(z)$. \hfill\qedsymbol
\end{sprob}

\begin{sexe}\label{lb154}
Consider Laurent series $f(z)=\sum_{n=-\infty}^{+\infty}a_nz^n$ (with radii of convergence $r_1<R_1$) and $g(z)=\sum_{n=-\infty}^{+\infty}b_nz^n$ (with radii of convergence $r_2<R_2$) in $\Cbb$. Let
\begin{align*}
r=\max\{r_1,r_2\}\qquad R=\min\{R_1,R_2\}
\end{align*}
Assume that $r<R$. Prove that for each $k\in\Zbb$, the series
\begin{align*}
c_k=\sum_{l=-\infty}^{+\infty}a_{k-l}b_l
\end{align*}
converges absolutely. Prove that for each $z\in\Cbb$ satisfying $r<|z|<R$, the LHS of the following equation converges absolutely to the RHS:
\begin{align}
\sum_{k=-\infty}^{+\infty}c_kz^k= f(z)g(z)
\end{align}
\end{sexe}




\newpage


\section{Construction of $\Rbb$ from $\Qbb$}  \label{lb167}


The goal of this chapter is to construct real numbers from rationals. More precisely, our goal is to prove Thm. \ref{lb3}. We use the method from Cantor to construct real numbers using equivalence classes of Cauchy sequences in $\Qbb$. The idea is quite simple: If we admit the existence of $\Rbb$ satisfying Thm. \ref{lb13}, then by Prop. \ref{lb2}, each $x\in\Rbb$ is the limit of a sequence $(x_n)$ in $\Qbb$, which must be a Cauchy sequence. Moreover, if $(y_n)$ is a sequence in $\Qbb$ converging to $y\in\Rbb$, then $x-y=\lim_{n\rightarrow\infty}(x_n-y_n)$. So by Def. \ref{lb155}, we have $x=y$ iff $(x_n)$ and $(y_n)$ are Cauchy equivalent. Motivated by this, we now do not assume the existence of $\Rbb$, and make the following definition:

\begin{df}
We let $\scr R$ be the set of Cauchy sequences in $\Qbb$, \footnote{Only in this chapter do we use $\scr R$ for this meaning.} namely, the set of $(x_n)_{n\in\Zbb_+}\in\Qbb^{\Zbb_+}$ satisfying 
\begin{align*}
\lim_{m,n\rightarrow+\infty} (x_m-x_n)=0
\end{align*}
We say that two elements $(x_n),(y_n)$ of $\scr R$ are Cauchy-equivalent and write $(x_n)\sim(y_n)$ if $\lim_{n\rightarrow\infty}(x_n-y_n)=0$.
\end{df}


Note that the above definition does not rely on the existence of $\Rbb$, because the limit of nets in $\Qbb$ can be defined using only rational numbers: a net $(\xi_\alpha)_{\alpha\in I}$ converges to $\xi$ iff for every $\eps\in\Qbb_{>0}$, $\xi_\alpha$ is eventually satisfies $|\xi_\alpha-\xi|<\eps$. The readers can check that all the properties about limit used in this chapter does not rely on the existence of $\Rbb$.

Cauchy-equivalence is clearly an equivalence condition on $\scr R$: For example, if $\lim (x_n-y_n)=\lim(y_n-z_n)=0$ then $|x_n-z_n|\leq |x_n-y_n|+|y_n-z_n|\rightarrow 0$. So $|x_n-z_n|\rightarrow0$. This proves the transitivity. The other two conditions are obvious. Therefore, we can define:

\begin{df}
We let $\Rbb=\scr R/\sim$ where $\sim$ is the Cauchy-equivalence relation. (Recall Def. \ref{lb157}). The equivalence class of $(x_n)_{n\in\Zbb_+}$ is denoted by $[x_n]_{n\in\Zbb_+}=[x_1,x_2,\dots]$, simply written as $[x_n]$. The zero element $0$ of $\Rbb$ is defined to be $[0,0,\dots]$. 
\end{df}




\begin{exe}\label{lb160}
Choose $[x_n]\in\Rbb$ (i.e. $(x_n)\in\scr R$) . The following are equivalent:
\begin{itemize}
\item[(1)] $[x_n]\neq 0$. Namely, $\lim_n x_n$ does not converge to $0$.
\item[(2)] There exists $\eps\in\Qbb_{>0}$ such that either $x_n>\eps$ eventually, or $x_n<-\eps$ eventually. In particular, $x_n\neq 0$ eventually.
\end{itemize}
Consequently, the map $a\in\Qbb\mapsto [a,a,\dots]\in\Rbb$ is injective. With the help of this injective map, $\Qbb$ can be viewed as a subset of $\Rbb$.
\end{exe}


\begin{exe}\label{lb159}
Let $[x_n]\in\Rbb$ and $a\in\Qbb$. Suppose that $x_n\geq a$ (resp. $x_n\leq a$) frequently.  Then for every $\eps\in\Qbb_{>0}$, we have that $x_n\geq a-\eps$ (resp. $x_n\leq a+\eps$) eventually.
\end{exe}





\begin{df}\label{lb158}
If $\xi,\eta\in\Rbb$, write $\xi=[x_n]$ and $\eta=[y_n]$. In the case that $\eta\neq0$, we assume $y_n\neq 0$ for all $n$, which is possible by Exe. \ref{lb160}. Define
\begin{gather*}
[x_n]+ [y_n]=[x_n+ y_n]\\
-[x_n]=[x_n]\\
[x_n]\cdot [y_n]=[x_ny_n]\\
1/[y_n]=[1/y_n]\qquad(\text{if }[y_n]\neq0)
\end{gather*}
\end{df}


\begin{exe}
Prove that the above formulas are well-defined: For example, if $(x_n)\sim(x_n')$ in $\scr R$, then $(x_ny_n)\sim (x_n'y_n)$. (You may need the easy fact that every Cauchy sequence is bounded.)
\end{exe}

\begin{rem}\label{lb166}
It is clear that Def. \ref{lb158} makes $\Rbb$ a \textbf{field}, \index{00@Field} which means that for every $\alpha,\beta,\gamma\in\Rbb$, the following are satisfied:
\begin{gather*}
\alpha+\beta=\beta+\alpha\qquad  (\alpha+\beta)+\gamma=\alpha+(\beta+\gamma)\qquad 0+\alpha=\alpha\qquad \alpha+(-\alpha)=0\\
\alpha\beta=\beta\alpha\qquad (\alpha\beta)\gamma=\alpha(\beta\gamma)\qquad 1\cdot\alpha=\alpha\qquad(\alpha+\beta)\gamma=\alpha\gamma+\beta\gamma\\
\alpha\cdot \frac 1\alpha=1\qquad(\text{if }\alpha\neq0)
\end{gather*}
Moreover, $\Qbb$ is a subfield of $\Rbb$ where the addition, taking negative, multiplication, and inverse of $\Rbb$ restrict to those of $\Qbb$.
\end{rem}

\begin{df}\label{lb164}
Let $[x_n],[y_n]\in\Rbb$. We write $[x_n]<[y_n]$ if one of the following equivalent (due to Exe. \ref{lb159}) statements hold:
\begin{itemize}
\item There exists $\eps\in\Qbb_{>0}$ such that $y_n-x_n>\eps$ eventually. 
\item There exists $\eps\in\Qbb_{>0}$ such that $y_n-x_n>\eps$ frequently. 
\end{itemize}
It is not hard show that $``<"$ is well-defined, and that (by Exe. \ref{lb160}) if $[x_n]<[y_n]$ then $[x_n]\neq [y_n]$. We write $[x_n]\leq [y_n]$ if $[x_n]<[y_n]$ or $x_n=y_n$.
\end{df}

\begin{lm}
$(\Rbb,\leq)$ is a totally ordered set.
\end{lm}

\begin{proof}
Choose $[x_n],[y_n],[z_n]\in\Rbb$. If $[x_n]<[y_n]$ and $[y_n]<[z_n]$, then clearly $[x_n]<[z_n]$. This proves that $\leq$ is a preorder. 

Suppose $[x_n]\leq[y_n]$ and $[y_n]\leq[x_n]$. Let us prove $[x_n]=[y_n]$. Suppose not. Then $[x_n]<[y_n]$ and $[y_n]<[x_n]$. So there is $\eps>0$ such that $y_n-x_n>\eps$ eventually, and $x_n-y_n>\eps$ eventually. Impossible. So $\leq$ is a partial order.

Suppose $[x_n]\neq [y_n]$. Then $(x_n-y_n)\nsim 0$. So Exe. \ref{lb160} implies that either $[x_n]<[y_n]$ or $[y_n]<[x_n]$. So $\leq$ is a total order.
\end{proof}

\begin{lm}\label{lb165}
Let $[x_n],[y_n]\in\Rbb$. Then the following are equivalent.
\begin{itemize}
\item $[x_n]\geq[y_n]$.
\item For every $\eps\in\Qbb_{>0}$, $x_n-y_n\geq-\eps$ frequently.
\item For every $\eps\in\Qbb_{>0}$, $x_n-y_n\geq-\eps$ eventually.
\end{itemize}
\end{lm}

\begin{proof}
Since $\leq$ is a preorder, the negation of $>$ is $\leq$. So the statements follow immediately by negating Def. \ref{lb164}.
\end{proof}



\begin{lm}
$\Rbb$ is an ordered field extension of $\Qbb$, and $\Rbb$ is Archimedean.
\end{lm}

\begin{proof}
The order of $\Rbb$ clearly restricts to that of $\Qbb$. We want to prove that $\Rbb$ is an ordered field. (Recall Def. \ref{lb161}). Clearly, if $[x_n]<[y_n]$ and $[z_n]\in\Rbb$, then $[x_n]+[y_n]=[x_n+z_n]<[y_n+z_n]=[y_n]+[z_n]$. If $[x_n]>0$ and $[y_n]>0$, then there are $\eps>0$ such that $x_n>\eps$ eventually and $y_n>\eps$ eventually. So $x_ny_n>\eps^2$ eventually. So $[x_n][y_n]>0$. This proves that $\Rbb$ is an ordered field.

Now let $[x_n]>0$ and $[y_n]\in\Rbb$. So there exist $\eps\in\Qbb_{>0}$ such that $x_n>\eps$ eventually. Since $(y_n)$ is Cauchy, one checks easily that $(y_n)$ is bounded. So there is $M\in\Qbb_{>0}$ such that $|y_n|\leq M$ for all $n$. Since $\Qbb$ is Archimedean, there exists $k\in\Zbb_+$ such that $k\eps>M+1$. So $kx_n>M+1$ eventually. So $k[x_n]>M$. This proves that $\Rbb$ is Archimedean.
\end{proof}




To finish the proof of Thm. \ref{lb3}, it remains to prove that $\Rbb$ satisfies the least-upper-bound property.


\begin{lm}\label{lb162}
Thm. \ref{lb3} holds if every bounded increasing sequence in $\Rbb$ converges.
\end{lm}

\begin{proof}
Suppose that every bounded increasing sequence in $\Rbb$ converges. Choose any nonempty $E\subset \Rbb$ bounded from above. We shall show that $E$ has a least upper bound.

Let $F$ be the set of upper bounds of $E$. Namely, $F=\{\eta\in\Rbb:\eta\geq\xi,\forall\xi\in E\}$. So $F\neq\emptyset$. We construct an increasing sequence $(\xi_k)$ in $E$ and an decreasing sequence $(\eta_k)$ in $F$ as follows. Since $E,F$ are nonempty, we choose arbitrary $\xi_1\in E$ and $\eta_1\in F$. Then $\xi_1\leq \eta_1$. Suppose $\xi_1\leq\cdots\leq\xi_k\in E$ and $\eta_1\geq\cdots\geq\eta_k\in F$ have been constructed. Let $\psi_k=(\xi_k+\eta_k)/2$. Let
\begin{gather*}
\left\{
\begin{array}{ll}
\xi_{k+1}=\psi_k,\eta_{k+1}=\eta_k &\text{ if }\psi_k\in E\\
\xi_{k+1}=\xi_k,\eta_{k+1}=\psi_k &\text{ if }\psi_k\in F
\end{array}
\right.
\end{gather*}
Then the sequences we have constructed satisfy $\lim_{k\rightarrow\infty}(\eta_k-\psi_k)=0$.

By assumption, $\alpha=\lim_{k\rightarrow\infty}\xi_k$ exists, and it equals $\lim_k \eta_k$.  So $\alpha$ is an upper bound of $E$. (If $\lambda\in E$, then $\lambda\leq \eta_k$ for all $k$ since $\eta_k\in F$. So $\lambda\leq\lim_k\eta_k=A$.) We now show that $\alpha$ is the least upper bound. Let $\eps>0$. Since $\xi_k\rightarrow\alpha$, there is $k$ such that $\alpha-\xi_k<\eps$. So $\xi_k>\alpha-\eps$, and hence $\alpha-\eps$ is not an upper bound of $E$.
\end{proof}


\begin{lm}\label{lb163}
Thm. \ref{lb3} holds if every bounded increasing sequence in $\Qbb$ converges to an element of $\Rbb$.
\end{lm}

\begin{proof}
Suppose that every increasing sequence in $\Qbb$ converges in $\Rbb$. By Lem. \ref{lb162}, it suffices to prove that every increasing sequence $(\xi_k)$ in $\Rbb$ converges. If $\{\xi_{k}:k\in\Zbb_+\}$ is a finite subset of $\Rbb$, then $(\xi_k)$ clearly converges. If $\{\xi_{k}:k\in\Zbb_+\}$ is infinite, then $(\xi_k)$ clearly has a strictly increasing subsequence $(\xi_{k_l})$. If we can prove that $(\xi_{k_l})$ converges to some $\psi\in\Rbb$, then $(\xi_k)$ converges to $\psi$. (Choose any $\eps>0$. Choose $L\in\Zbb_+$ such that $|\psi-\xi_{k_L}|<\eps$ and hence $0\leq \psi-\xi_{k_L}<\eps$. Then for all $k\geq k_L$ we have $0\leq\psi-\xi_k<\eps$.)

Thus, it remains to prove that every strictly increasing sequence $(\eta_k)$ in $\Rbb$ converges. Since we have proved that $\Rbb$ is an Archimedean ordered field extension of $\Qbb$, by Prop. \ref{lb2}, for each $k$, there exists $a_k\in\Qbb$ such that $\xi_k< a_k< \xi_{k+1}$. By assumption, $(a_k)$ converges to some $\alpha\in\Rbb$. Since $a_{k-1}<\xi_k< a_k$, by squeeze theorem, $(\xi_k)$ converges to $\alpha$.
\end{proof}




\begin{proof}[\textbf{Proof of Thm. \ref{lb3}}]
By Lem. \ref{lb163}, it suffices to show that every bounded increasing sequence $(a_k)$ in $\Qbb$ converges in $\Rbb$. Let $M\in\Qbb$ such that $a_k\leq M$ for all $k$.

We first prove that $(a_k)$ is a Cauchy sequence. If not, then there exists $\eps\in\Qbb_{>0}$ such that for every $K\in\Zbb_+$ there is $k>K$ such that $|a_k-a_K|>\eps$, and hence $a_k-a_K>\eps$. Thus, we can find a subsequence $(a_{k_l})$ such that $a_{k_{l+1}}-a_{k_l}>\eps$. By the Archimedean property for $\Qbb$, there is $l\in\Zbb_+$ such that $a_{k_1}+l\cdot\eps>M$. So $a_{k_{l+1}}>M$, impossible.



Note that each $a_k$ is identified with $\xi_k=[a_k,a_k,\dots]$. Let $\psi=[a_1,a_2,a_3,\dots]$, which is an element of $\Rbb$ since we just proved that $(a_n)\in\scr R$. Then for each $k$, $\psi-\xi_k=[a_1-a_k,a_2-a_k,\dots]$, where the terms are eventually $\geq0$. So $\xi_k\leq\psi$ by Lem. \ref{lb165}. We have proved that $\psi$ is an upper bound for the sequence $(\xi_k)$.

Let us prove that $\lim_k\xi_k=\psi$. Choose any $\eps\in\Qbb_{>0}$. Let us prove that there exists $k$ such that $\psi-\eps<\xi_k$. Then for every $k'\geq k$ we have $\psi-\eps<\xi_{k'}\leq\psi$, finishing the proof of $\lim_k\xi_k=\psi$.

We have proved that $a_1,a_2,\dots$ is a Cauchy sequence in $\Qbb$. So there exists $k$ such that $a_l-a_k<\eps/2$ for all $l\geq k$. Thus, for all $l\geq k$ we have $a_k-(a_l-\eps)>\eps/2$. Thus, the $l$-th term of $\xi_k=[a_k,a_k,\dots]$ minus that of $\psi-\eps=[a_1-\eps,a_2-\eps,\dots]$ is $>\eps/2$ for sufficiently large $l$. By Def. \ref{lb164}, we have that $\psi-\eps<\xi_k$.
\end{proof}

\newpage

\section{Topological spaces}


\subsection{The topologies of metric spaces}\label{lb169}

In this chapter, we begin our study of topological spaces, which were introduced by Hausdorff in 1914 as a generalization of metric spaces. As we have seen, focusing on metrics in order to study convergence and continuity is often distracting. For example, in $\ovl\Rbb$, we only care about how the convergence of sequences look like, but not about the particular metrics. The same is true about the countable product of metric spaces $S=\prod_{i\in\Zbb_+}X_i$: the metrics \eqref{eq16} and \eqref{eq61} give the same topology, although they look very different. Moreover, the shapes of the open balls defined by these two metrics are not very simple. This makes it more difficult to study the continuity of functions on $S$ by using (2) or (2') of Def. \ref{lb31}.




Topological spaces generalize metric spaces by giving a set of axioms satisfied by the open set of the spaces.

\begin{df}\label{lb168}
Let $X$ be a metric space, and let $E\subset X$. A point $x\in E$ is called an \textbf{interior point} of $E$ if $B_X(x,r)\subset E$ for some $r>0$. We say that $E$ is an \textbf{open (sub)set} of $X$, \index{00@Open set of a metric spaces} if every point of $E$ is an interior point.
\end{df}

\begin{df}
Let $\mc T$ be the set of open sets of $X$. We call $\mc T$ the \textbf{topology of the metric space} $X$. \index{00@Topology of a metric space}
\end{df}

\begin{eg}
By triangle inequality, every open ball of a metric space $X$ is open. $\emptyset$ and $X$ are open subsets of $X$. If $p,q\in\Rbb^N$ and $d(p,x)=r$ (where $0\leq r<+\infty$), then $p$ is not an interior point of $\ovl B_{\Rbb^N}(x,r)$. So the closed balls of $\Rbb^N$ are not open sets. In particular, $[a,b]$ are not open subsets of $\Rbb$ since $a,b$ are not interior points.
\end{eg}

\begin{eg}
It is not hard to see that a finite intersection of open sets is open.
\end{eg}



In topological spaces, open sets play the role of open balls in metric spaces due to the following facts:

\begin{exe}
Let $(x_n)$ be a sequence in a metric space $X$. Let $x\in X$. Show that the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $(x_n)$ converges to $x$.
\item For every \textbf{neighborhood $U$ of $x$} (i.e. every open set containing $x$) there is $N\in\Zbb_+$ such that for every $n\geq N$ we have $x_n\in U$.
\end{enumerate}
\end{exe}
\begin{exe}
Let $f:X\rightarrow Y$ be a map of metric spaces. Let $x\in X$ and $y=f(x)$. Prove that the following are equivalent. 
\begin{enumerate}[label=(\arabic*)]
\item $f$ is continuous at $x$.
\item For every neighborhood of $y$ there is a neighborhood $U$ of $x$ such that $f(U)\subset V$ (equivalently, $U\subset f^{-1}(V)$.)
\end{enumerate}
\end{exe}


But there is an important difference between the intuitions of open sets and open balls: We want the open balls at a point $x$ to be small so that they can be used to describe the approximation to $x$. However, an arbitrary open set can be very large. For example, when studying convergence and continuity in $\Rbb$, we really want a neighborhood of $1$ to be $(1-\eps,1+\eps)$ but not the more complicated and bigger one $(-\infty,-2)\cup (0,100-\eps)$. Indeed, open sets can be very big:


\begin{lm}
Let $X$ be a metric space. If $(U_\alpha)_{\alpha\in I}$ is a family of open subsets of $X$, then $W=\bigcup_{\alpha\in I}U_\alpha$ is open in $X$.
\end{lm}

\begin{proof}
Choose $x\in W$. Then $x\in U_\alpha$ for some $\alpha$. So $B_X(x,r)\subset U_\alpha$ for some $r>0$. So $x$ is an interior point of $W$.
\end{proof}



Thus, people very often choose a class $\mc B$ of smaller open sets (such as the set of open balls) to study the analytic properties of a topological space. 
\begin{df}\label{lb170}
Let $\mc B$ be a set of open sets of a metric space (or more generally, a topological space) $X$. We say that $\mc B$ is a \textbf{base of the topology} \index{00@Base of topology} $\mc T$ of $X$ if one of the following (clearly) equivalent statements holds:
\begin{itemize}
\item For every point $x\in X$ and every neighborhood $W$ of $x$ there exists $U\in\mc B$ such that $x\in U$ and $U\subset W$.
\item Every open subset of $X$ is a union of some members of $\mc B$.
\end{itemize}
\end{df}

Thus, according to Def. \ref{lb168}, the set of open balls of a metric space $X$ form a base of the topology of $X$. Nevertheless, even in the case of metric spaces, we sometimes consider more convenient bases than the set of open balls. We will see this when we study the topologies of infinite product spaces.


\subsection{Topological spaces}


\subsubsection{Definitions and basic examples}

\begin{df}\label{lb178}
We say that a pair $(X,\mc T)$ (or simply $X$) is a \textbf{topological space} \index{00@Topological space} if $X$ is a set, and if $\mc T$ (called the \textbf{topology} of $X$) is a set of subsets of $X$ satisfying the following conditions
\begin{itemize}
\item $\emptyset\in\mc T$ and $X\in \mc T$.
\item (Union property) If $(U_\alpha)_{\alpha\in I}$ is a family of elements of $\mc T$, then $\bigcup_{\alpha\in I}U_\alpha$ is an element of $\mc T$.
\item (Finite intersection property) If $n\in\Zbb_+$ and $U_1,\dots,U_n\in\mc T$, then $U_1\cap\cdots\cap U_n$ is an element of $\mc T$.
\end{itemize}
Elements of $\mc T$ are called \textbf{open (sub)sets} \index{00@Open set} of $X$.
\end{df}


\begin{df}
Let $X$ be a topological space, and $x\in X$. A subset $U\subset X$ is called $U$  a \index{00@Neighborhood=open set containing the point} \textbf{neighborhood} of $x$, if $U$ is an open subset of $X$ containing $x$.\footnote{We are following the convention in \cite{Mun,Rud-R}. But many people refer to the word "neighborhood" with slightly different meaning: a subset $A$ is called a neighborhood of $x$ if there is an open set $U$ such that $x\in U\subset A$. And our neighborhoods are called ``open neighborhoods" by them.} We define $(\Nbh_X(x),\leq)$, \index{00@$\Nbh_X(x)=\Nbh(x)$}  the \textbf{directed set of neighborhoods of $x$}, \index{00@Directed set of neighborhoods of a point} to be 
\begin{gather}
\begin{gathered}
\Nbh_X(x)=\{\text{neighborhoods of }x\text{ in }X\}\\
U\leq U'\qquad\Longleftrightarrow \qquad U\supset U'
\end{gathered}
\end{gather} 
We abbreviate this set to $\Nbh_X(x)$ or simply $\Nbh(x)$.
\end{df}


\begin{eg}
In Subsec. \ref{lb169}, we have proved that the topology of a metric space satisfies the above axioms of a topological space. 

In particular,   if $X$ is a normed vector space, the topology induced by the metric $d(x,x')=\lVert x-x'\lVert$ is called the \textbf{norm topology}. \index{00@Norm topology} If $X$ is a subset of $\Rbb^N$ or $\Cbb^N$, the topology on $X$ induced by the Euclidean metric is called the \textbf{Euclidean topology}. \index{00@Euclidean topology}  \hfill\qedsymbol
\end{eg}

\begin{df}
A topological space $(X,\mc T)$ is called \textbf{metrizable}, \index{00@Metrizable topological space} if there is a metric on $X$ inducing the topology $\mc T$. 
\end{df}


We have seen that the open balls of a metric space generate a topology. In general, one may ask what possible subsets of $2^X$ generate a topology on a set $X$. Here is a description, whose proof is left to the readers as an exercise.

\begin{pp}\label{lb171}
Let $X$ be a set, and let $\mc B\subset 2^X$. Define
\begin{align}
\mc T=\{\text{Unions of elements of }\mc B\}
\end{align}
The following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $(X,\mc T)$ is a topological space.
\item The following are satisfied:
\begin{itemize}
\item[(2-a)] $X=\bigcup_{U\in\mc B}U$.
\item[(2-b)] If $U_1,U_2\in\mc B$, then $U_1\cap U_2\in\mc T$ (i.e., for each $x\in U_1\cap U_2$ there exists $V\in\mc B$ such that $x\in V$ and $V\subset U_1\cap U_2$).
\end{itemize} 
\end{enumerate}
\end{pp}

When (1) or (2) holds, we call $\mc T$ the \textbf{topology generated by $\mc B$}. \index{00@Topology generated by the base} Clearly, $\mc B$ is a base of $\mc T$ (cf. Def. \ref{lb170}).





\begin{exe}\label{lb172}
Let $X$ be a set. Let $\mc B,\mc B'$ be subsets of $2^X$ generating topologies $\mc T,\mc T'$ respectively. Prove that the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $\mc T=\mc T'$.
\item Each $U\in\mc B$ is a union of elements of $\mc B'$. Each $U'\in\mc B'$ is a union of elements of $\mc B$.
\item For each $U\in\mc B$ and $x\in U$, there exists $U'\in\mc B'$ such that $x\in U'\subset U$. For each $U'\in\mc B$ and $x\in U'$, there exists $U\in\mc B$ such that $x\in U\subset U'$.
\end{enumerate} 
\end{exe}

\begin{eg}
If $(X,\mc T)$ is a topological space, then $\mc T$ is a base of $\mc T$.
\end{eg}

\begin{eg}
Let $(X,d)$ be a metric space with topology $\mc T$. Let $\mc B=\{B_X(x,r):x\in X,0<r<+\infty\}$. Then $\mc B$ is a base of $\mc T$. For each $\eps>0$, the set $\mc B'=\{B_X(x,r):x\in X,0<r<\eps\}$ is also a base of $\mc T$.
\end{eg}

\begin{eg}
Let $\mc B\subset 2^{\ovl\Rbb}$ be defined by
\begin{gather}
\mc B=\{(a,b),(c,+\infty],[-\infty,d):a,b,c,d\in\Rbb \}  \label{eq62}
\end{gather}
Using Prop. \ref{lb171}, one easily checks that $\mc B$ is a base of a topology $\mc T$. We call this the \textbf{standard topology} of $\ovl\Rbb$. \index{00@Topology of $\ovl\Rbb$}

Let $\varphi:\ovl\Rbb\rightarrow[u,v]$ be a strictly increasing bijection where $-\infty<u<v<+\infty$. Let $d_{[u,v]}$ be the Euclidean metric, and let $\mc T'$ be the topology on $\ovl\Rbb$ defined by $d_{\ovl\Rbb}=\varphi^*d_{[u,v]}$. Then the set of open balls under $\mc T'$ is
\begin{align*}
\mc B'=\{&(\varphi^{-1}(y-\eps),\varphi^{-1}(y+\eps)), (\varphi^{-1}(v-\eps'),+\infty],[-\infty,\varphi^{-1}(u+\eps)):\\
&y\in(u,v)\text{ and } \eps,\eps',\eps''\in\Rbb_{>0} \}
\end{align*}
(Note that the three types of intervals in the definition of $\mc B'$ are open balls centered at $\varphi^{-1}(y),+\infty,-\infty$ respectively.) Using Exe. \ref{lb172}, one easily checks $\mc T=\mc T'$. \hfill\qedsymbol 
\end{eg}

\begin{cv}\label{lb173}
Unless otherwise stated, the topology on $\ovl\Rbb$ is defined to be the standard one, i.e., the one generated by \eqref{eq62}. We shall forget about the metric on $\ovl\Rbb$, and view $\ovl\Rbb$ only as a (metrizable) topological space.
\end{cv}



\begin{df}\label{lb180}
Let $A$ be a subset of a topological space $(X,\mc T_X)$. Then
\begin{align*}
\mc T_A=\{U\cap A:U\in \mc T_X\}
\end{align*} 
is clearly a topology on $A$, called the \textbf{subspace topology}. \index{00@Subspace topology} Unless otherwise stated, when viewing a subset as a topological subspace, we always choose the subspace topology for the subset.
\end{df}


\begin{exe}
Let $A$ be a subset of a topological space $X$, equipped with the subspace topology. Let $(x_\alpha)$ be a net in $A$, and let $x\in A$. Show that $x_\alpha\rightarrow x$ in $A$ iff $x_\alpha\rightarrow x$ in $X$.
\end{exe}

\begin{exe}
Let $(X,d_X)$ be a metric space, inducing a topology $\mc T_X$. Let $A$ be a metric subspace of $X$. (So $A\subset X$, and $d_X$ restricts to $d_A$.) Prove that the topology on $A$ induced by $d_A$ is the subspace topology.
\end{exe}


According to the above exercise, if $X$ is a metric space, then viewing a subset $A$ as a topological subspace is compatible with viewing $A$ as a metric subspace.



\subsubsection{Convergence of nets}



\begin{df}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a topological space $X$. Let $x\in X$. We say that $(x_\alpha)$ \textbf{converges to} $x$ and write \index{lim@$\lim_{\alpha\in I}x_\alpha\equiv \lim_\alpha x_\alpha$}
\begin{align*}
\lim_{\alpha\in I}x_\alpha\equiv \lim_\alpha x_\alpha=x
\end{align*}
or simply $x_\alpha\rightarrow x$ if the following statement holds:
\begin{itemize}
\item For every $U\in\Nbh_X(x)$, we have that $x_\alpha$ is eventually in $U$.
\end{itemize}
Clearly, if $\mc B$ is a base of topology, then $x_\alpha\rightarrow x$ iff:
\begin{itemize}
\item For every $U\in\mc B$ containing $x$, we have that $x_\alpha$ is eventually in $U$.
\end{itemize}
In the case that $X$ is a metric space (and the topology of $X$ is induced by the metric), the definition here agrees with Def. \ref{lb174}.
\end{df}

\begin{exe}
Let $(x_\alpha)$ be a net in $X$ converging to $x\in X$. Prove that every subnet of $(x_\alpha)$ converges to $x$.
\end{exe}



\begin{eg}
Let $X$ be a set. Let $\mc T=\{\emptyset,X\}$. Then every net in $X$ converge to every point of $X$. Thus, if $X$ has at least two elements, then the limit of a net in $X$ is not unique. Therefore, a general topological space might be very pathological. To avoid this uniqueness issue, we introduce the following notion:
\end{eg}



\begin{df}
Let $X$ be a topological space with a base of topology $\mc B$. We say that $X$ is a \textbf{Hausdorff space} if the following equivalent conditions are satisfied:
\begin{itemize}
\item[(1)] (Hausdorff condition) If $x,y\in X$ and $x\neq y$, then there exist neighborhoods $U$ of $x$ and $V$ of $y$ such that $U\cap V=\emptyset$.
\item[(1')] If $x,y\in X$ and $x\neq y$, then there exist $U\in\mc B$ containing $x$ and $V\in\mc B$ containing $y$ such that $U\cap V=\emptyset$.
\item[(2)] If $(x_\alpha)_{\alpha\in I}$ is a net in $X$ converging to both $x$ and $y$, then $x=y$.
\end{itemize}
\end{df}

\begin{proof}[Proof of the equivalence]
(1)$\Leftrightarrow$(1'): Obvious.

(1)$\Rightarrow$(2): Suppose that $(x_\alpha)$ converges to $x$ and $y$. Suppose $x\neq y$. By (1),  we have disjoint neighborhoods $U\ni x$ and $V\ni y$. Since $x_\alpha\rightarrow x$, $x_\alpha$ is eventually in $U$. Similarly, $x_\alpha$ is eventually in $V$. Therefore, by the logic \eqref{eq38}, $x_\alpha$ is eventually in $U\cap V=\emptyset$, impossible.

$\neg$(1)$\Rightarrow$ $\neg$(2): Suppose that (1) is not true. Then there exist $x\neq y$ such that every neighborhood of $x$ intersects every neighborhood of $y$. Let
\begin{align*}
I=\{(U,V):U,V\text{ are respectively neighborhoods of }x,y\}
\end{align*}
Then $I$ is a directs set if we let $(U,V)\leq (U',V')$ mean $U\supset U'$ and $V\supset V'$. Moreover, for each $\alpha=(U,V)\in I$, by assumption, there exists $x_\alpha\in U\cap V$. Then $(x_\alpha)_{\alpha\in I}$ is a net in $X$. We leave it to the readers to check that $x_\alpha\rightarrow x$ and $x_\alpha\rightarrow y$.
\end{proof}


\begin{rem}
In Hausdorff's 1914 paper introducing topological spaces, the Hausdorff condition is one of the axioms of topological spaces. Non-Hausdorff topological spaces were studied much later. The reason that Hausdorff spaces appeared first may be as follows: The original motivation for topological spaces lies in the study of analysis (especially functional analysis). But in analysis, almost all spaces are Hausdorff, because we want the limits of sequences or nets to be unique. 

In differential geometry and in topology\footnote{Here, I mean genuine topology, such as algebraic topology, differential topology, geometric topology, etc., but not point-set topology, which is analysis under the guise of topology.}, people are also mainly concerned with topological spaces that are Hausdorff. This is related to the fact that in these areas people often use tools from analysis. But in algebraic geometry, the main examples of topological spaces (e.g. varieties and schemes, whose topologies are called \textbf{Zariski topology}) are not Hausdorff.  As a related fact, sequences and nets are not effective tools in the study of algebraic geometry.  \hfill\qedsymbol
\end{rem}

\subsection{Closures, interiors, and closed sets}


In this section, we fix a topological space $X$.


\subsubsection{Closure points; dense subsets}





\begin{df}\label{lb183}
Let $A$ be a subset of $X$. We say that $x\in X$ is a \textbf{closure point} \index{00@Closure, closure point} of $A$, if the following equivalent conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item There is a net $(x_\alpha)_{\alpha\in I}$ in $A$ converging to $x$.
\item Each $U\in \Nbh_X(x)$ intersects $A$. 
\end{enumerate}
The \textbf{closure} of $A$ is defined to be \index{Acl@$\ovl A=\Cl_X(A)$, closure}
\begin{align*}
\ovl A\equiv\Cl(A)\equiv\Cl_X(A)=\{\text{Closure points of }A\}
\end{align*}
Clearly $A\subset \ovl A$. Clearly, if $A\subset B\subset X$, then $\ovl A\subset\ovl B$.
\end{df}

Unless otherwise stated, if several subsets are involved, we always understand $\ovl A$ as $\Cl_X(A)$ where $X$ is the ambient topological space.

\begin{proof}[Proof of equivalence]
(1)$\Rightarrow$(2): Assume (1). Choose any $U\in\Nbh_X(x)$. Since $x_\alpha\rightarrow x$, we have that $x_\alpha$ is eventually in $U$. So $U$ must contain some $x_\alpha$. But $x_\alpha\in A$. So $U\cap A\neq\emptyset$.

(2)$\Rightarrow$(1): Let $\mc I$ be the set of open subsets of $X$ containing $x$. Then $(\mc I,\supset)$ is a directed set. By (2), for each $U\in\mc I$ we can choose $x_U\in U\cap A$. Then $(x_U)_{U\in\mc I}$ is a net in $A$ converging to $x$. (Note that one needs the finite intersection property in Def. \ref{lb178} to prove that $\mc I$ is a directed set.)
\end{proof}

\begin{exe}
Let $\mc B$ be a base of the topology of $X$. Show that $x\in X$ is a closure point of $A$ iff every $U\in\mc B$ containing $x$ must intersect $A$.
\end{exe}

\begin{exe}
Let $A$ be a subset of a metric space. Show that $x\in X$ is a closure point of $A$ iff there is a sequence $(x_n)_{n\in\Zbb_+}$ in $A$ converging to $x$.
\end{exe}


\begin{rem}\label{lb176}
There is a notion closely related to closure points, called accumulation points. Let $A$ be a subset of $X$. A point $x\in X$ is called a \textbf{accumulation point} \index{00@Accumulation point of a subset}  (or \textbf{limit point} or \textbf{cluster point}) of $A$, if $x$ is a closure point of $A\setminus\{x\}$.

We will not use the notion of accumulation points, although this concept is widely used in many textbooks on analysis or point-set topology. We use closure points instead. (But note that if $x\notin A$, then $x$ is a closure point iff $x$ is an accumulation point.) On the other hand, the following opposite notion of accumulation points is important and has a clear geometric picture:
\end{rem}

\begin{df}
We say that $x\in X$ is an \textbf{isolated point} of $X$, if the following (clearly) equivalent conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item $x\notin\ovl {X\setminus\{x\}}$.
\item There is no net in $X\setminus\{x\}$ converging to $x$.
\item There is a neighborhood of $x$ disjoint from $X\setminus\{x\}$.
\end{enumerate}
If $X$ is a metric space, then $x$ is an isolated point iff there is no sequence in $X\setminus\{x\}$ converging to $x$.
\end{df}


We return to the study of closures.

\begin{pp}\label{lb177}
Let $A$ be a subset of $X$. Then $\ovl{\ovl A}=\ovl A$.
\end{pp}

\begin{proof}
Choose any $x\in \ovl{\ovl A}$. To prove $x\in \ovl A$, we choose any  $U\in\Nbh_X(x)$, and try to prove $U\cap A\neq\emptyset$. Since $x$ is a closure point of $\ovl A$, $U$ intersects $\ovl A$. Pick $y\in U\cap\ovl A$. Then $y$ is a closure point of $A$, and $U\in\Nbh_X(y)$. So $U$ intersects $A$. 
\end{proof}


One should think of $\ovl{\ovl A}=\ovl A$ not only as a ``geometric" fact about closures. Instead, one should also understand its analytic content: A closure point of $A$ is a point which can be approximated by elements of $A$. Thus, $\ovl{\ovl A}=\ovl A$ says that ``approximation is transitive": If $x$ can be approximated by some elements which can be approximated by elements of $A$, then $x$ can be approximated by elements of $A$. Alternatively, one can use the language of density:

\begin{df}
A subset $A$ of $X$ is called \textbf{dense} (in $X$) \index{00@Dense subset} if $\ovl A= X$.
\end{df}



\begin{rem}\label{lb182}
Let $A\subset B\subset X$.  From Def. \ref{lb183}-(1), it is clear that
\begin{align}
\Cl_B(A)=\Cl_X(A)\cap B \label{eq64}
\end{align}
Thus, $A$ is dense in $B$ iff $B\subset \Cl_X(A)$.
\end{rem}

Thus, the following property has the same meaning as $\ovl{\ovl A}=A$.
\begin{co}
Let $A\subset B\subset X$. Assume that $A$ is dense in $B$, and $B$ is dense in $X$, then $A$ is dense in $X$.
\end{co}
\begin{proof}
Choose any $x\in X$. Then $x\in\Cl_X(B)$ since $B$ is dense in $X$. Since $A$ is dense in $B$, we have $B\subset \Cl_X(A)$. Therefore $x\in\Cl_X(\Cl_X(A))$, and hence $x\in\Cl_X(A)$ by Prop. \ref{lb177}.
\end{proof}

\begin{eg}
Let $X=C([0,1],\Rbb)$, equipped with the $l^\infty$-norm. Let $B$ be the set of polynomials with real coefficients, regarded as continuous functions on $[0,1]$. By Weierstrass approximation theorem (which will be studied in the future), $B$ is a dense subset of $X$. Then the set $A$ of polynomials with rational coefficients is clearly a dense subset of $B$ under the $l^\infty$-norm. (Proof: Let $f(x)=a_0+a_1x+\cdots+a_{k}x^k$. For each $0\leq i\leq k$, choose a sequence $(a_{i,n})_{n\in\Zbb_+}$ in $\Qbb$ converging to $a_i$. Let $f_n(x)=a_{0,n}+a_{1,n}x+\cdots+a_{k,n}x^k$. Then $f_n\rightrightarrows f$ on $[0,1]$.) Therefore, $A$ is dense in $X$. To summarize:
\begin{itemize}
\item Since each continuous function on $[0,1]$ can be uniformly approximated by polynomials with $\Rbb$-coefficients, and since each polynomial can be uniformly approximated polynomials with $\Qbb$-coefficients, therefore each continuous function on $[0,1]$ can be uniformly approximated by polynomials with $\Qbb$-coefficients.
\end{itemize}
\end{eg}


\subsubsection{Interior points}

Interior points are dual to closure points:

\begin{df}\label{lb187}
Let $A$ be a subset of $X$. A point $x\in X$ is called an \textbf{interior point} \index{00@Interior point} of $A$ if the following equivalent conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item There exists $U\in \Nbh_X(x)$ such that $U\subset A$.
\item $x$ is not a closure point of $X\setminus A$. 
\end{enumerate}
The set of interior points of $A$ is called the \textbf{interior} \index{00@Interior} of $A$ and is denoted by $\Int(A)$. \index{Int@$\Int(A)$} So
\begin{align}
X\setminus\Int(A)=\ovl{X\setminus A}\qquad(\text{or simply }\Int(A)^c=\ovl{A^c})
\end{align}
according to (2). In particular, $\Int(A)\subset A$.
\end{df}

\begin{proof}[Proof of equivalence]
$A$ contains no neighborhoods of $x$ with respect to $X$ iff $A^c$ intersects every neighborhood of $x$ iff $x$ is a closure point of $A^c$.
\end{proof}

It is clear that if $\mc B$ is a base of topology, then $x\in\Int(A)$ iff there exists $U\in\mc B$ such that $x\in U\subset A$.

In analysis, interior points are not as commonly used as closure points. The following property is an important situation where interior points are used:

\begin{pp}\label{lb179}
Let $U$ be a subset of $X$. Then $U$ is open iff every point of $U$ is an interior point.
\end{pp}

In other words, $U$ is open iff $U=\Int(U)$.

\begin{proof}
If $U$ is open and $x\in U$, then $U\in \Nbh_X(x)$. So $x$ is an interior point of $U$.

Conversely, suppose that each $x\in U$ is interior. Choose $V_x\in\Nbh_X(x)$. Then $U=\bigcup_{x\in U}V_x$. So $U$ is open by the union property in Def. \ref{lb178}.
\end{proof}

Note that this is the first time we seriously use the fact that a union of open sets is open. 




\subsubsection{Closed sets and open sets}


\begin{df}
We say that $A\subset X$ is a \textbf{closed (sub)set} \index{00@Closed subset} of $X$ if $\ovl A=A$.
\end{df}

\begin{exe}
Show that the above definition of closed subsets agrees with Def. \ref{lb99} when $X$ is a metric space.
\end{exe}

\begin{exe}
Show that a finite subset of a Hausdorff space is closed. Give an example of non-closed finite subset of a non-Hausdorff topological space.
\end{exe}


\begin{rem}
The closure $\ovl A$ is the smallest closed set containing $A$. (Proof: By Prop. \ref{lb177},  $\ovl A$ is closed. If $B$ is closed and contains $A$, then $\ovl A\subset\ovl B=B$.)
\end{rem}



\begin{thm}\label{lb181}
Let $A$ be a subset of $X$. Then $A$ is closed iff $X\setminus A$ is open.
\end{thm}

\begin{proof}
Let $B=X\setminus A$. Then $A$ is closed iff every closure point of $A$ is in $A$, iff every non-interior point of $B$ is not in $B$, iff every point in $B$ is an interior point of $B$. By Prop. \ref{lb179}, this is equivalent to that $B$ is open.
\end{proof}

\begin{co}\label{lb186}
$\emptyset$ and $X$ are closed subsets of $X$. An intersection of closed subsets is closed. A finite union of closed subsets is closed.
\end{co}

\begin{proof}
Take the complement of Def. \ref{lb178}, and apply Thm. \ref{lb181}.
\end{proof}


\begin{co}\label{lb190}
Let $Y$ be a subset of $X$, and let $A\subset Y$. Then the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $A$ is a closed subset of $Y$.
\item $A=B\cap Y$ for some closed subset $B$ of $X$.
\end{enumerate}
\end{co}

Note that the ``open subset" version of this corollary is true due to the definition of the subspace topology of $Y$ (cf. Def. \ref{lb180}).

\begin{proof}[First proof]
$A$ is closed in $Y$ iff $Y\setminus A=Y\cap A^c$ is open in $Y$, iff $Y\cap A^c$ equals $Y\cap U$ for some open subset $U\subset X$, iff $Y\cap A$ (which is $A$) equals $Y\cap U^c$ for some open subset $U\subset X$. This finishes the proof, thanks to Thm. \ref{lb181}.
\end{proof}

\begin{proof}[Second proof]
Recall by \eqref{eq64} that $\ovl A\cap Y$ is the closure of $A$ in $Y$. Then $A$ is closed in $Y$ iff $A=\ovl A\cap Y$. This proves (1)$\Rightarrow$(2) since $\ovl A$ is closed by Prop. \ref{lb177}. Assume (2). Then $A=B\cap Y$ where $B=\ovl B$. So $\ovl A\cap Y=\ovl{B\cap Y}\cap Y\subset \ovl B\cap Y=B\cap Y=A$. This proves (1).
\end{proof}


As an immediate consequence of Def. \ref{lb178} and Cor. \ref{lb189}, we have:

\begin{exe}
Let $A\subset B\subset X$. 
\begin{enumerate}
\item Prove that if $B$ is open in $X$, then $A$ is open in $B$ iff $A$ is open in $X$.
\item Prove that if $B$ is closed in $X$, then $A$ is closed in $B$ iff $A$ is closed in $X$.
\end{enumerate}
\end{exe}




\begin{rem}
Many people define a closed set to be the complement of an open set, and then proves that a set $A$ is closed iff $A=\ovl A$. I went the other way because I believe that $A=\ovl A$ is more essential for understanding of closedness from the viewpoint of analysis. In Thm. \ref{lb87}, we have already seen a classical example of closed set in analysis: $C([0,1],\Rbb)$ is a closed subset of $l^\infty([0,1],\Rbb)$, which has the clear analytic meaning that the uniform limit of a sequence/net of continuous functions $[0,1]\rightarrow\Rbb$ is continuous. And we will see many more examples of this type in the future.
\end{rem}

\begin{rem}
I defined closedness using $A=\ovl A$, and hence using the limits of nets. This is because the intuition of closed sets is very closely related to the intuition of limits of nets/sequences. On the other hand, the intuition of open sets is very different. Let me say a few words about this.

Without a doubt, the keyword I give for the intuition of limits of nets is ``\ul{approximation}": Limit is not only a dynamic process, but also gives an impression of "getting smaller and smaller". When dealing with closed sets, we often do the same thing! We take an intersection of possibly infinitely many closed subsets, and the result we get is still a closed set (cf. Cor. \ref{lb185}). 

The keyword I give for open sets is ``local", or more precisely, ``\ul{local-to-global}" (as opposed to ``getting smaller and smaller"!). This is not only because a union of open sets is open, but also because open sets are very often used to prove a global result by reducing to local problems. One easy example is Exe. \ref{lb184}, which says that in order to prove that a function is continuous on the whole space $X$, it suffices to prove this locally. (We have already used this strategy in Sec. \ref{lb185}.) Here is a more advanced example: to define the integral for a function on a large set, one can first define it locally (i.e. on small enough open subsets), and then patch these local values together. We will see many examples in the future, for example, in the following chapter about compactness.
\end{rem}

\begin{rem}
Very often, a theorem is an important result establishing two seemingly different (systems of) intuitions, and hence two different ways of mathematical thinking. This is why I call ``closed sets are the complements of open sets" a theorem. The term ``complement" implies that this theorem often manifests itself in the following way: If solving a problem using open sets is a direct proof, then solving the problem using limits of sequences/nets is a proof by contradiction/contrapositive. And vise versa.
\end{rem}


\subsection{Continuous maps and homeomorphisms}



Unless otherwise stated,  $X$ and $Y$ are topological spaces.


\subsubsection{Continuous maps}



\begin{df}\label{lb188}
Let $f:X\rightarrow Y$ be a map. Let $x\in X$. We say that $f$ is \textbf{continuous at} \index{00@Continuity} $x$ if the following equivalent conditions hold:
\begin{enumerate}
\item[(1)] For every net $(x_\alpha)_{\alpha\in I}$ in $X$ converging to $x$, we have $\lim_{\alpha\in I}f(x_\alpha)=f(x)$.
\item[(2)] For every $V\in \Nbh_Y(y)$, there exists $U\in\Nbh_X(x)$ such that for every $p\in U$ we have $f(p)\in V$.
\item[(2')] For every $V\in \Nbh_Y(y)$, the point $x$ is an interior point of $f^{-1}(f(x))$.
\end{enumerate}
We say that $f$ is a \textbf{continuous} function/map, if $f$ is continuous at every point of $X$. 
\end{df}

It is clear that ``for every $V\in\Nbh_{Y}(y)$" in (2) and (2') can be replaced by ``for every $V\in\mc B$ containing $y$" if $\mc B$ is a base of the topology of $Y$. 


\begin{proof}[Proof of equivalence]
Clearly (2) is equivalent to (2'). The proof of (2)$\Rightarrow$(1) is similar to the case of sequences in metric spaces. (See Def. \ref{lb31}.) We leave the details to the reader.

$\neg$(2)$\Rightarrow$ $\neg$(1): Assume that (2) is not true. Then there is a neighborhood $V$ of $y$ such that for every neighborhood $U$ of $x$ there exists $x_U\in U$ such that $f(x_U)\notin V$. Then $(x_U)_{U\in\Nbh_X(x)}$ is a net in $X$, and $\lim_Ux_U=x$ since $x_U\in U$. However, for each $U$ we have $f(x_U)\in Y\setminus V$. So $\lim_U f(x_U)$ cannot converge to $y$.
\end{proof}

\begin{exe}
Show that when $X,Y$ are metric spaces, Def. \ref{lb188} agrees with Def. \ref{lb31}.
\end{exe}

\begin{exe}
Let $f:X\rightarrow Y$ and $g:Y\rightarrow Z$ be maps of topological spaces. Assume that $f$ is continuous at $x\in X$, and $g$ is continuous at $f(x)$. Prove that $g\circ f:X\rightarrow Z$ is continuous at $x$.
\end{exe}

\begin{exe}\label{lb196}
Let $f,g:X\rightarrow Y$ be continuous. Let $A$ be a dense subset of $X$. Prove that $f=g$ iff $f|_A=g|_A$. Thus, continuous functions are determined by their values on a dense subset. 
\end{exe}



The proof of (1)$\Rightarrow$(2) in Def. \ref{lb188} is indirect (since it is a proof by contrapositive) and uses the axiom of choice. (The merit of this proof is that it is parallel to the proof for metric spaces in Sec. \ref{lb185}.) One can also give a direct proof. Indeed, there is a particular net $(x_\alpha)$ converging to $x$ such that if $\lim f(x_\alpha)=f(x)$ then (2) is true:

\begin{exe}\label{lb198}
Define $(\Pnbh_X(x),\leq)$, \index{PNbh@$\Pnbh_X(x)$} the \textbf{directed set of pointed neighborhoods} of $x$,  to be
\begin{gather}
\begin{gathered}
\Pnbh_X(x)=\big\{(p,U):U\in\Nbh_X(x),p\in U  \big\}\\
(p,U)\leq(p',U')\qquad\Longleftrightarrow\qquad U\supset U'
\end{gathered}
\end{gather}
For each $\alpha=(p,U)\in\Pnbh_X(x)$, let $x_\alpha=p$. Then $(x_\alpha)_{\alpha\in\Pnbh_X(x)}$ is a net in $X$ converging to $x$. Prove that $f$ is continuous at $x$ iff $\lim_\alpha f(x_\alpha)=f(x)$.
\end{exe}



\begin{pp}\label{lb191}
Let $f:X\rightarrow Y$ be a map. The following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $f$ is continuous.
\item If $V\subset Y$ is open in $Y$, then $f^{-1}(V)$ is open in $X$.
\item If $F\subset Y$ is closed in $Y$, then $f^{-1}(F)$ is closed in $Y$.
\end{enumerate}
\end{pp}

\begin{proof}
(1)$\Leftrightarrow$(2): By Def. \ref{lb188}-(2') and Prop. \ref{lb179}. (2)$\Leftrightarrow$(3): By Thm. \ref{lb181} and the fact that $f^{-1}(B^c)=f^{-1}(B)^c$ for every $B\subset Y$.
\end{proof}



\begin{rem}
We first defined the continuity of $f$ at a point, and then used this to define a continuous function $f$ to be one continuous at every point. However, it seems that the notion of continuity at a point is used only in analysis. In geometry and in topology, only continuous maps (but not a map continuous at a point) are used, and they are defined by Prop. \ref{lb191}-(2).

One might think that continuous functions are special cases of functions  which are continuous at given points. But in fact, the latter notion can also be derived from the former: \hfill\qedsymbol
\end{rem}

\begin{sexe}
Let $f:(X,\mc T)\rightarrow (Y,\mc T')$ be a map of topological spaces. Let $x\in X$. Define a new topological space $(X_x,\mc T_x)$ as follows. $X_x$ equals $X$ as a set. The topology $\mc T_x$ of $X_x$ is generated by the base
\begin{align}
\mc B_x=\Nbh_X(x)\cup\big\{\{p\}:p\neq x\big\}
\end{align}
Prove that if $X$ is Hausdorff, then $X_x$ is Hausdorff. Prove that the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $f:X\rightarrow Y$ is continuous at $x$.
\item $f:X_x\rightarrow Y$ is continuous.
\end{enumerate}
\end{sexe}





\subsubsection{Homeomorphisms}

\begin{df}
A map $f:X\rightarrow Y$ is called \textbf{open} (resp. \textbf{closed}) \index{00@Open map} \index{00@Closed map} if for every open (resp. closed) subset $A\subset X$, the image $f(A)$ is open (resp. closed) in $Y$.
\end{df}


\begin{df}
A bijection $f:X\rightarrow Y$ is called a \textbf{homeomorphism} \index{00@Homeomorphism} if the following clearly equivalent conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item $f$ and $f^{-1}$ are continuous.
\item For every net $(x_\alpha)$ in $X$ and each $x\in X$, we have that  $\lim_\alpha x_\alpha=x$ iff $\lim_\alpha f(x_\alpha)=f(x)$.
\item $f$ is continuous and open.
\item $f$ is continuous and closed.
\end{enumerate}
If a homeomorphism $f:X\rightarrow Y$ exists, we say that $X,Y$ are \textbf{homeomorphic}.
\end{df}

Recall from Def. \ref{lb189} that when $X,Y$ are metric spaces, the sequence version of (2) holds. 

\begin{rem}
Let $\mc T_1,\mc T_2$ be two topologies on a set $X$. Clearly, we have $\mc T_1=\mc T_2$ iff
\begin{gather}
\varphi:(X,\mc T_1)\rightarrow(X,\mc T_2)\qquad x\mapsto x
\end{gather}
is a homeomorphism. Thus, the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $\mc T_1=\mc T_2$.
\item For every net $(x_\alpha)$ in $X$ and $x\in X$, we have that $\lim_\alpha x_\alpha=x$ under $\mc T_1$ iff $\lim_\alpha x_\alpha=x$ under $\mc T_2$.
\end{enumerate}
This equivalence implies that
\begin{align*}
\boxed{\text{ topologies are determined by net convergence }}
\end{align*}
Therefore, instead of using open sets or bases of topologies to describe a topology, one can also describe a topology $\mc T$ on a set $X$ in the following way:
\begin{gather}\label{eq65}
\begin{gathered}
\text{$\mc T$ is the unique topology on $X$ such that}\\
\text{a net $(x_\alpha)$ in $X$ converges to $x\in X$ iff ...}
\end{gathered}
\end{gather}
Similarly, by Def. \ref{lb189}, metrizable topologies are determined by sequential convergence. Therefore, metrizable topologies can be described in the following way:
\begin{gather}
\begin{gathered}
\text{$\mc T$ is the unique metrizable topology on $X$ such that}\\
\text{a sequence $(x_n)$ in $X$ converges to $x\in X$ iff ...}
\end{gathered}
\end{gather}
\end{rem}


\subsection{Examples of topological spaces described by net convergence}

\begin{eg}
Let $A$ be a subset of a topological space $(X,\mc T_A)$. Then the subspace topology $\mc T_A$ of $A$ is the unique topology such that a net $(x_\alpha)$ in $A$ converges to $x\in A$ under $\mc T_A$ iff it converges to $x$ under $\mc T$.
\end{eg}

\begin{seg}\label{lb193}
Let $X=\bigsqcup_{\alpha\in \scr A}X_\alpha$ be a disjoint union where each $(X_\alpha,\mc T_\alpha)$ is a topology space. Then
\begin{align*}
\mc B=\bigcup_{\alpha\in\scr A}\mc T_\alpha
\end{align*}
is clearly a base generating a topology $\mc T$ on $X$, called \textbf{disjoint union topology}. \index{00@Disjoint union of topological spaces}   $\mc T$ is the unique topology on $X$ such that for every net $(x_\mu)_{\mu\in I}$ in $X$ and any $x\in X$, the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $(x_\mu)_{\mu\in I}$ converges to $x$ under $\mc T$.
\item There exists $\nu\in I$ such that for every $\mu\geq\nu$, the element $x_\mu$ belongs to the unique $X_\alpha$ containing $x$. Moreover, $\lim_{\mu\in I_{\geq\nu}}x_\mu=x$ in $X_\alpha$.
\end{enumerate}
We call $(X,\mc T)$ the \textbf{disjoint union topological space} \index{00@Disjoint union topological space} of $(X_\alpha)_{\alpha\in\scr A}$.
\end{seg}

The following exercise says that ``disjoint union of topological spaces" is synonymous with ``disjoint union of open subsets".

\begin{sexe}
Assume that $X=\bigsqcup_{\alpha\in\scr A}X_\alpha$. Assume that $X$ has a topology $\mc T$, and equip each $X_\alpha$ with the subspace topology. Show that $(X,\mc T)$ is the disjoint union topological space of $(X_\alpha)_{\alpha\in\scr A}$ iff each $X_\alpha$ is an open subset of $(X,\mc T)$.
\end{sexe}

Thus, for example, $\bigcup_{n\in\Nbb} [2n,2n+1)$ (under the Euclidean topology) is the disjoint union topological space of the family $\big([2n,2n+1)\big)_{n\in\Nbb}$.


\begin{sexe}
In Exp. \ref{lb193}, assume that each $(X_\alpha,\mc T_\alpha)$ is metrizable. Prove that $(X,\mc T)$ is metrizable. More precisely: Choose a metric $d_\alpha$ inducing $\mc T_\alpha$, and assume that $d_\alpha\leq 1$ (cf. Prop. \ref{lb195}). Define a metric $d$ on $X$ as in Pb. \ref{lb194}. Solve \emph{the net version} of part 2 of Pb. \ref{lb194}. Conclude from this that $d$ induces the topology $\mc T$. (Warning: we cannot conclude this from the original sequential version of Pb. \ref{lb194}-2.)
\end{sexe}


\begin{df}
Let $(X_\alpha)_{\alpha\in\mc A}$ be a family of topological spaces. Elements of the product space
\begin{align*}
S=\prod_{\alpha\in\scr A}X_\alpha
\end{align*}
are denoted by $x=(x(\alpha))_{\alpha\in\scr A}$. One checks easily that
\begin{align}
\begin{aligned}
\mc B=\Big\{&\prod_{\alpha\in\scr A} U_\alpha: \text{each $U_\alpha$ is open in $X_\alpha$},\\
& \text{$U_\alpha=X_\alpha$ for all but finitely many $\alpha$}\Big\}
\end{aligned}
\end{align}
is a base of a topology $\mc T$, called the \textbf{product topology} \index{00@Product topology} or \textbf{pointwise convergence topology} \index{00@Pointwise convergence topology} of $S$. We call $(S,\mc T)$ the \textbf{product topological space}. \index{00@Product topological space} 

Equivalently, let
\begin{gather}
\pi_\alpha:S\rightarrow X_\alpha \qquad x\mapsto x(\alpha)
\end{gather}
be the \textbf{projection map onto the $X_\alpha$ component}. Then
\begin{align}
\mc B=\Big\{\bigcap_{\alpha\in E} \pi_\alpha^{-1}(U_\alpha):E\in\fin(2^{\scr A}), \text{ $U_\alpha$ is open in $X_\alpha$ for each $\alpha\in E$}    \Big\}
\end{align}
Unless otherwise stated, a product of topological spaces is equipped with the product topology.  \hfill\qedsymbol
\end{df}



\begin{eg}
Let $S=X_1\times\cdots\times X_N$ be a finite product of topological spaces. Then the product topology has a base
\begin{align}
\mc B=\{ U_1\times\cdots \times U_N:\text{ each $U_i$ is open in $X_i$}\}
\end{align}
\end{eg}


\begin{thm}\label{lb192}
Let $S=\prod_{\alpha\in\scr A}X_\alpha$ be a product of topological spaces, equipped with the product topology. Then each projection map $\pi_\alpha$ is continuous. Moreover, for every net $(x_\mu)_{\mu\in I}$ in $S$ and every $x\in S$, the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item $\dps\lim_{\mu\in I}x_\mu=x$ in $S$.
\item For every $\alpha\in\scr A$, we have $\dps\lim_{\mu\in I}x_\mu(\alpha)=x(\alpha)$ in $X_\alpha$.
\end{enumerate}
\end{thm}

\begin{proof}
We leave the proof to the readers. Note that the continuity of $\pi_\alpha$ follows easily from the base-of-topology version of Prop. \ref{lb191}-(2). And from the continuity of $\pi_\alpha$ one easily deduce (1)$\Rightarrow$(2).
\end{proof}

\begin{rem}
In the spirit of \eqref{eq65}, one says that:
\begin{itemize}
\item The product topology $\mc T$ on $S=\prod_{\alpha\in\scr A}X_\alpha$ is the unique topology such that a net $(x_\mu)$ converges to $x$ under $\mc T$ iff $x_\mu$ converges pointwisely to $x$ as a net of functions on $\scr A$.
\end{itemize}
\end{rem}


\begin{co}
If each $X_\alpha$ is a Hausdorff space, then $S=\prod_{\alpha\in\scr A}X_\alpha$ is Hausdorff.
\end{co}

\begin{proof}
Either prove this directly using the base of topology, or prove that any net cannot converge to two different values using Thm. \ref{lb192}.
\end{proof}

\begin{co}
Let $(X_i)_{i\in\Zbb_+,i\leq N}$ (where $N\in\Zbb_+\cup\{\infty\}$) be a possibly finite sequence of metric spaces. Then $S=\prod_i X_i$ is metrizable. More precisely, for each $i$, choose a metric $d_i$ on $X_i$ topologically equivalent to the original one such that $d_i\leq 1$ (cf. Prop. \ref{lb194}). Then the metric $d$ on $S$ defined by
\begin{align}
d(f,g)=\sup_{i\in\Zbb_+,i\leq N} \frac {d_i(f(i),g(i))}{i} 
\end{align}
induce the product topology.
\end{co}

We note that the product topology is also induced by
\begin{align}
\delta(f,g)=\sum_{i\in\Zbb_+,i\leq N}2^{-i} d_i(f(i),g(i))
\end{align}

\begin{proof}
The same method for solving Pb. \ref{lb78} also applies to its net version: One shows that a net $(f_\alpha)$ in $S$ converges to $f$ under $d$ (or under $\delta$) iff $(f_\alpha)$ converges pointwisely to $f$. Thus, by Thm. \ref{lb192}, $d$ and $\delta$ induce the product topology.
\end{proof}

The next example discusses the topologies induced by uniform convergence metrics. (Recall Def. \ref{lb146}.) In this example, $Y$ is usually a normed vector space.

\begin{eg}
Let $X$ be a set, and let $(Y,d_Y)$ be a metric space. Then there is a unique topology $\mc T$ on $Y^X$ such that for every net $(f_\alpha)_{\alpha\in I}$ in $Y^X$ and every $f\in Y^X$, the following are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item The net $(f_\alpha)$ converges to $f$ under $\mc T$.
\item We have $\dps\lim_{\alpha\in I}~\sup_{x\in X} d_Y(f_\alpha(x),f(x))=0$.
\end{enumerate}
For example, one checks easily that $\mc T$ is induced by any \textbf{uniform convergence metric}, \index{00@Uniform convergence metric} i.e., any metric on $Y^X$ topologically equivalent to $d$ where
\begin{align}
d(f,g)=\min\Big\{1,\sup_{x\in X} d_Y(f(x),g(x))\Big\}
\end{align}
So $\mc T$ is metrizable. We call $\mc T$ the \textbf{uniform convergence topology} \index{00@Uniform convergence topology} on $Y^X$.
\end{eg}

\begin{rem}
Note that the uniform convergence topology depends on the equivalence class (not just the topological equivalence class) of $d_Y$. Thus, one needs metrics when talking about uniform convergence. On the other hand, the study of pointwise convergence does not require metrics.
\end{rem}













\subsection{Problems and supplementary material}


Let $X$ and $Y$ be topological spaces.

\subsubsection{Open sets, closed sets, closures}



\begin{prob}
Let $A,B\in X$. Let $(A_\alpha)_{\alpha\in \scr A}$ be a family of subsets of $X$. Prove that
\begin{subequations}
\begin{gather}
\ovl{A\cup B}=\ovl A\cup \ovl B\\
\ovl{\bigcap_{\alpha\in \scr A}A_\alpha}\subset\bigcap_{\alpha\in\scr A}\ovl{A_\alpha}
\end{gather}
\end{subequations}
\end{prob}

\begin{prob}
Let $(x_\alpha)_{\alpha\in I}$ be a net in a $X$. Let $x\in X$. Prove that the following statements are equivalent:
\begin{enumerate}[label=(\arabic*)]
\item $(x_\alpha)_{\alpha\in I}$ has a subnet converging to $x$.
\item For every neighborhood $U$ of $x$, we have that $x_\alpha$ is frequently in $U$.
\item $x$ belongs to $\dps\bigcap_{\alpha\in I}\ovl{\{x_\beta:\beta\geq\alpha\}}$.
\end{enumerate}
Any $x\in X$ satisfying one of these two requirements is called a \textbf{cluster point} \index{00@Cluster point of a net} of $(x_\alpha)_{\alpha\in I}$.
\end{prob}

\begin{proof}[Hint]
(2)$\Leftrightarrow$(3) is a direct translation. Assume (2). To prove (1), construct a subnet with index set
\begin{align*}
I=\{(\alpha,U):U \text{ is a neighborhood of }x,\text{ and }x_\alpha\in U \}
\end{align*}
You should verify that what you have constructed is indeed a subnet (and in particular, $I$ is indeed a directed set), and that it converges to $x$. Especially, you should point out where (2) is used in your verification.
\end{proof}





\begin{rem}
We mainly use (1) and (2) when studying cluster points of nets. Occasionally we also use (3). (For example, in the study of compact topological spaces, where intersections of closed subsets are often of interest, we will use (3).)
\end{rem}

\begin{rem}
Although the word ``cluster point" is also used for a subset $A$ of $X$ (cf. Rem. \ref{lb176}), it is not parallel to the notion of cluster points of net. The true analogous concept of ``cluster points of a net" is ``closure points of a subset".
\end{rem}


\begin{prob}
Assume that $X$ is a metric space. Let $E\subset X$. Recall that $d(x,E)=d(E,x)=\inf_{e\in E}d(e,x)$. Prove that
\begin{align}
\{x\in X:d(x,E)=0\}=\ovl E
\end{align}
\end{prob}


\begin{rem}
If $E,F$ are disjoint subsets of a metric space $X$, a continuous function $f:X\rightarrow[0,1]$ is called an \textbf{Urysohn function} \index{00@Urysohn function of a metric space} with respect to $E,F$, if
\begin{align*}
f^{-1}(1)=E\qquad f^{-1}(0)=F
\end{align*} 
For example, it is easy to check that
\begin{gather}
f:X\rightarrow[0,1]\qquad f(x)=\frac{d(x,F)}{d(x,E)+d(x,F)}
\end{gather}
is an Urysohn function.
\end{rem}


\begin{sprob}
A topological space $X$ is called \textbf{normal} \index{00@Normal topological space} if for every disjoint $E,F\subset X$, there exist disjoint open subsets $U,V\subset X$ such that $E\subset U$ and $F\subset V$. 
\begin{enumerate}
\item Prove that $X$ is normal iff for each $E\subset W\subset X$ where $E$ is closed and $W$ is open, there exists an open subset $U\subset X$ such that $E\subset U\subset \ovl U\subset W$.
\item Prove that if $X$ is metrizable, then $X$ is normal.
\end{enumerate}
\end{sprob}

\subsubsection{Continuous maps}


\begin{exe}\label{lb184}
Let $f:X\rightarrow Y$ be a map of topological spaces.
\begin{enumerate}
\item Suppose that $F$ is a subset of $Y$ containing $f(X)$. Show that $f:X\rightarrow Y$ is continuous iff $f:X\rightarrow F$ is continuous.
\item (Local to global principle) Suppose that $X=\bigcup_{\alpha\in I}U_\alpha$ where each $U_\alpha$ is an open subset of $X$, Prove that $f$ is continuous iff $f|_{U_\alpha}:U_\alpha\rightarrow Y$ is continuous for every $\alpha$. 
\end{enumerate}
\end{exe}

\begin{rem}
The above local-to-global principle for continuous functions can be rephrased in the following way. Suppose that $X=\bigcup_{\alpha\in I}U_\alpha$ where each $U_\alpha$ is an open subset of $X$. Suppose that for each $\alpha$ we have a continuous map $f_\alpha:U_\alpha\rightarrow Y$. Assume that for each $\alpha,\beta\in I$ we have
\begin{align*}
f_\alpha|_{U_\alpha\cap U_\beta}=f_\beta|_{U_\alpha\cap U_\beta}
\end{align*}
Then there is a (necessarily unique) continuous function $f:X\rightarrow Y$ such that $f|_{U_\alpha}=f_\alpha$ for every $\alpha$.
\end{rem}



\begin{df}\label{lb175}
Let $(I,\leq)$ be a directed set. Let $\infty_I$ (often abbreviated to $\infty$) be a new symbol not in $I$. Then
\begin{align*}
I^*=I\cup\{\infty_I\}
\end{align*}
is also a directed set if we extend the preorder $\leq$ of $I$ to $I^*$ by setting
\begin{align*}
\alpha\leq\infty_I\qquad(\forall\alpha\in I^*)
\end{align*}
For each $\alpha\in I$, let
\begin{align*}
I^*_{\geq\alpha}=\{\beta\in I^*:\beta\geq\alpha\}
\end{align*}
The \textbf{standard topology} \index{00@Topology of $\mc I^*=I\cup\{\infty_I\}$ where $I$ is an index set} of $I^*$ is defined to be the one induced by the base
\begin{align}\label{eq63}
\mc B=\big\{\{\alpha\}:\alpha\in I \big\}\cup \big\{I^*_{\geq\alpha}:\alpha\in I \big\}
\end{align}
\end{df}



\begin{prob}
Let $(I,\leq)$ be a directed set. Let $I^*$ be as in Def. \ref{lb175}.
\begin{enumerate}
\item Check that $\mc B$ (defined by \eqref{eq63}) is a base of a topology. (Therefore, $\mc B$ generates a topology $\mc T$ on $I^*$.) Moreover, show that $(I^*,\mc T)$ is Hausdorff.
\item Let $(x_\alpha)_{\alpha\in I}$ be a net in a topological space $X$. Let $x_\infty\in X$. (So we have a function $x:I^*\rightarrow X$.) Prove that 
\begin{align}
x\text{ is a continuous function}\qquad\Longleftrightarrow\qquad \lim_{\alpha\in I} x_\alpha=x_\infty
\end{align}
\end{enumerate} 
\end{prob}


\subsubsection{Limits of functions}



\begin{rem}
By Exe. \ref{lb196}, if $A\subset X$ and $f:\ovl A\rightarrow Y$ is continuous, then the value of $f$ is uniquely determined by $f|_A$. We now consider the opposite question of \ul{extension of continuous functions}: Suppose that $f:A\rightarrow Y$ is continuous. Can we extend $f$ to a continuous function $f:\ovl A\rightarrow Y$? (We know that such extension must be unique if it exists.) The classical concept of the limits of functions can be understood in this light.
\end{rem}


\begin{df}\label{lb197}
Let $A$ be a subset of $X$. Let $f:A\rightarrow Y$ be a map. Let $x\in\ovl A\setminus A$. Let $y\in Y$. We say that the \textbf{limit of the function} \index{00@Limit of a function} $f$ at $x$ is $y$ and write \index{lim@$\lim_{p\rightarrow x}f(p)$}
\begin{align*}
\lim_{
\begin{subarray}{c}
p\in A\\
p\rightarrow x
\end{subarray}
} f(p)\equiv\lim_{p\rightarrow x}f(p)=y
\end{align*}
if the following equivalent conditions hold:
\begin{enumerate}[label=(\arabic*)]
\item If we extend $f$ to a function $A\cup\{x\}\rightarrow Y$ satisfying $f(x)=y$, then $f:A\cup\{x\}\rightarrow Y$ is continuous at $x$.
\item For every $V\in\Nbh_Y(y)$, there exists $U\in\Nbh_X(x)$ such that for every $p\in U\cap A$, we have $f(p)\in V$.
\item For every net $(x_\alpha)_{\alpha\in I}$ in $A$ converging to $x$, we have $\lim_\alpha f(x_\alpha)=y$.
\end{enumerate}
\end{df}


\begin{exe}
Prove the equivalence of the three statements in Def. \ref{lb197}. Note that when applying Def. \ref{lb188} to the extended function $f:A\cup\{x\}\rightarrow Y$, the two equivalent statements you get are not completely the same as (2) and (3) of Def. \ref{lb197}. (For example, you will get a statement about nets in $A\cup\{x\}$ rather than nets in $A$.) But the proof for Def. \ref{lb197} is similar to that for Def. \ref{lb188}.
\end{exe}

\begin{rem}
The limit of a function at a point is indeed a special case of net limit. Assume the setting of Def. \ref{lb197}. In the same spirit of Exe. \ref{lb198}, define a directed set $(\Pnbh_A(x),\leq)$ where
\begin{gather}
\begin{gathered}
\Pnbh_A(x)=\big\{(p,U\cap A):U\in\Nbh_X(x),p\in U\cap A  \big\}\\
(p,U\cap A)\leq(p',U'\cap A)\qquad\Longleftrightarrow\qquad U\cap A\supset U'\cap A
\end{gathered}
\end{gather}
For each $\alpha=(p,U\cap A)\in\Pnbh_A(x)$, let $x_\alpha=p$. Then $(x_\alpha)_{\alpha\in\Pnbh_A(x)}$ is a net converging to $x$. And
\begin{align}
\lim_{p\rightarrow x} f(p)=\lim_{\alpha\in\Pnbh_A(x)}f(x_\alpha)
\end{align}
\end{rem}

\begin{rem}\label{lb202}
Let $f:A\rightarrow Y$, and let $x\in\ovl A\setminus A$. Suppose that $Y$ is Hausdorff. Assume that there exist two nets $(x_\alpha)_{\alpha\in I}$ and $(y_\beta)_{\beta\in J}$ in $A$ converging to $x$ such that $(f(x_\alpha))$ and $(f(y_\beta))$ converge to two different values. Then by Def. \ref{lb197}-(2), the limit $\lim_{p\rightarrow x}f(p)$ does not exist.
\end{rem}


\begin{prob}\label{lb199}
Assume the setting of Def. \ref{lb197}. Assume that $A=A_1\cup\cdots\cup A_N$. Prove that the following are equivalent.
\begin{enumerate}[label=(\arabic*)]
\item We have $\dps \lim_{p\rightarrow x} f(p)=y$.
\item For every $1\leq i\leq N$ such that $x\in\ovl{A_i}$, we have $\dps\lim_{p\rightarrow x} f|_{A_i}(p)=y$
\end{enumerate}
\end{prob}




\begin{rem}
In many textbooks, $\lim_{p\rightarrow x}f(x)$ is also defined more generally when $x$ is an accumulation point of $A$, i.e., when $x\in\ovl{A\setminus\{x\}}$. In this case, the limit of $f$ at $x$ simply means \index{lim@$\lim_{p\rightarrow x}f(p)$}
\begin{align}\label{eq66}
\lim_{p\rightarrow x}f(p)
\xlongequal{\mathrm{def}} \lim_{p\rightarrow x}f|_{A\setminus\{x\}}(p)
\end{align}
This more general case is important in classical analysis, but is less useful in abstract analysis. (As a matter of fact, accumulation points are less convenient than closure points.) In order not to deviate too far from the traditional analysis textbooks, let's take a look at some examples.
\end{rem}


\begin{df}\label{lb200}
Let $A\subset\Rbb$ and $x\in\Rbb$. Let $f:A\rightarrow Y$ be a function. If $x$ is a closure point of $A\cap\Rbb_{<x}$ resp. $A\cap \Rbb_{>x}$, we define the \textbf{left limit} resp. \textbf{right limit} \index{00@Left and right limit} \index{lim@$\lim_{t\rightarrow x^-}$ and $\lim_{t\rightarrow x^+}$} to be
\begin{subequations}
\begin{gather}
\lim_{t\rightarrow x^-}f(t)=\lim_{t\rightarrow x}f|_{A\cap \Rbb_{<x}}(t)\\
\lim_{t\rightarrow x^+}f(t)=\lim_{t\rightarrow x}f|_{A\cap \Rbb_{>x}}(t)
\end{gather}
\end{subequations}
If $x\in\ovl\Rbb$ and $x$ is a closure point of $A\setminus \{x\}$, then $\lim_{t\rightarrow x}f(t)$ is understood by \eqref{eq66}.
\end{df}

\begin{rem}\label{lb201}
In Def. \ref{lb200}, if $x\in\Rbb$ is a closure point of $A\setminus\{x\}$, then by Pb. \ref{lb199},
\begin{align}
\lim_{p\rightarrow x}f(p)=y\qquad\Longleftrightarrow\qquad \lim_{p\rightarrow x^-}f(p)=\lim_{p\rightarrow x^+}f(p)=y
\end{align}
In particular, the existence of the limit on the LHS is equivalent to the existence and the equality of the two limits on the RHS.
\end{rem}



\begin{eg}
Let $g,h:\Rbb\rightarrow \Rbb$ be continuous functions. Let $c\in\Rbb$. Define $f:\Rbb\rightarrow\Rbb$ to be
\begin{align*}
f(x)=\left\{
\begin{array}{ll}
g(x)&\text{ if }x<0\\
c&\text{ if }x=0\\
h(x)&\text{ if }x>0\\
\end{array}
\right.
\end{align*}
Since $g|_{(-\infty,0]}$ is continuous, by Def. \ref{lb197}-(1) we have that $\lim_{x\rightarrow 0^-}f(x)=\lim_{x\rightarrow 0,t<0}g(t)=g(0)$. Similarly, $\lim_{x\rightarrow 0^+}f(x)=h(0)$. Therefore, by Rem. \ref{lb201}, $\lim_{x\rightarrow0}f(x)$ exists iff $g(0)=h(0)$, and it converges to $g(0)$ if $g(0)=h(0)$. The value $c$ is irrelevant to the limits.
\end{eg}


\begin{eg}
Let $f:X=\Rbb^2\setminus\{(0,0)\}\rightarrow \Rbb$ be $f(x,y)=\frac{x}{x+y}$. Then $(1/n,0)$ and $(0,1/n)$ are sequences in $X$ converging to $0$. But $f(1/n,0)=1$ and $f(0,1/n)=0$. So $\lim_{(x,y)\rightarrow(0,0)}f(x,y)$ does not exist by Rem. \ref{lb202}.
\end{eg}




\begin{prob}
Find $\dps\lim_{(x,y)\rightarrow(0,0)}f(x,y)$, or explain why it does not exist:
\begin{gather*}
f(x,y)=\frac{x^2-y^2}{x^2+y^2}\\
f(x,y)=\frac{(xy)^2}{(xy)^2+(x-y)^2}\\
f(x,y)=\frac{x^6y^2}{(x^4+y^2)^2}
\end{gather*}
\end{prob}


\subsubsection{Product spaces}













\begin{prob}
Prove Thm. \ref{lb192}.
\end{prob}


\begin{exe}
Let $(X_\alpha)_{\alpha\in\scr A}$ and $(Y_\alpha)_{\alpha\in\scr A}$ be families of nonempty topological spaces. Let $Z$ be a nonempty topological space. For each $\alpha\in\scr A$, choose maps $f_\alpha:X_\alpha\rightarrow Y_\alpha$ and $g_\alpha:Z\rightarrow X_\alpha$. 
\begin{enumerate}
\item Prove that 
\begin{align}
\prod_{\alpha\in\scr A}f_\alpha:\prod_\alpha X_\alpha\rightarrow\prod_\alpha Y_\alpha\qquad (x(\alpha))_{\alpha\in\scr A}\mapsto (f_\alpha(x_\alpha))_{\alpha\in\scr A}
\end{align}
is continuous iff each $f_\alpha$ is continuous.
\item Prove that
\begin{align}
\bigvee_{\alpha\in\scr A}g_\alpha:Z\rightarrow \prod_\alpha X_\alpha \qquad z\mapsto (g_\alpha(z))_{\alpha\in\scr A}
\end{align}
is continuous iff each $g_\alpha$ is continuous.
\end{enumerate}
\end{exe}


\begin{df}
Let $X$ be a topological space. A set $\mc U_x$ of neighborhoods of $x$ is called a \textbf{neighborhood base} of $x$, if for every $V\in\Nbh_X(x)$ there exists $U\in\mc U_x$ such that $U\subset V$. We call $X$ \textbf{first countable} if every point $x$ has a neighborhood base which is a countable set.  
\end{df}


\begin{eg}
If $X$ is a metric space, then $X$ is first countable, since for every $x\in X$, $\{B_X(x,1/n):n\in\Zbb_+\}$ is a neighborhood base.
\end{eg}


\begin{prob}\label{lb203}
Let $(X_\alpha)_{\alpha\in\scr A}$ be an uncountable family of metric spaces, where each $X_\alpha$ has at least two elements. Let $S=\prod_{\alpha\in\scr A}X_\alpha$ be the product space, equipped with the product topology. Prove that $S$ is not first countable, and hence not metrizable.
\end{prob}













\begin{comment}
We list the properties proved before which do not rely on the existence of $\Qbb$:
\begin{enumerate}[label=(\roman*)]
\item A metric space $X$ is called a \textbf{$\Qbb$-metric space} if the distance function $d:X\times X\rightarrow\Qbb_{\geq0}$ takes value in $\Qbb_{\geq0}$.
\item If $X,Y$ are $\Qbb$-metric spaces, then $X\times Y$ is a $\Qbb$-metric space if we define $d((x,y),(x',y'))=\max\{d(x,x'),d(y,y')\}$.
\item The definition of continuous maps between $\Qbb$-metric spaces as in Def. \ref{lb31}.
\item The continuity of $+,-,\cdot,/$ in $\Qbb$, namely, Prop. \ref{lb41} for $\Qbb$.
\item If $f:X\rightarrow Y$ is a continuous map of $\Qbb$-metric spaces, $(x_\alpha)$ is a net in $X$ converging to $x$, then $f(x_\alpha)$ converges to $f(x)$. ($\Qbb$-version of Thm. \ref{lb121}.)
\item If $(x_\alpha),(y_\alpha)$ are nets in $\Qbb$ converging to $A,B\in\Qbb$, if $x_\alpha\leq y_\alpha$ for all $\alpha$, then $A\leq B$. 
\end{enumerate}
\end{comment}



















\newpage

\printindex	






	\begin{thebibliography}{999999}
		\footnotesize	

\bibitem[Axl]{Axl}
Axler, S. (2015). Linear algebra done right. 3rd ed.

\bibitem[Jah]{Jah}
Jahnke, H. N. (2003). A history of analysis (No. 24). American Mathematical Soc..

\bibitem[Mun]{Mun}
Munkres, J. (2000). Topology. Second Edition.



\bibitem[Rud-P]{Rud-P}
Rudin, W. (1976). Principles of Mathematical Analysis. 3rd ed.

\bibitem[Rud-R]{Rud-R}
Rudin, W. (1987). Real and complex analysis. 3rd ed. 


		
\end{thebibliography}

\noindent {\small \sc Yau Mathematical Sciences Center, Tsinghua University, Beijing, China.}

\noindent {\textit{E-mail}}: binguimath@gmail.com\qquad bingui@tsinghua.edu.cn
\end{document}









